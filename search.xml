<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Java agent</title>
      <link href="/2021/01/04/jvm/za-xiang/java-agent/"/>
      <url>/2021/01/04/jvm/za-xiang/java-agent/</url>
      
        <content type="html"><![CDATA[<h1>JVMTI 及 Instrument</h1><p>JVM Tool Interface（JVM TI）是一个作为工具作用的原生(native)接口。它提供了一种方式去检查 JVM 程序的状态或者控制它们的运行。用途包括但不限于：指标分析、调试、监控、线程分析、覆盖率分析工具。</p><p>JVM TI 在 JDK 5.0 引用。它替换了 JVMPI（JVM Profiler Interface） 和 JVMDI（JVM Debug Interface），这两者在 JDK6 不再提供。</p><blockquote><p>在《深入理解Java虚拟机》第三版的 4.3.3 节对于 VisualVM 的介绍中，介绍了它的一个插件 BTrace。</p><p>Instrument是JVMTI（Java Virtual Machine Tool Interface,JVMTI）中的主要组成部分, 它提供了一套 agent（代理）机制。HotSpot虚拟机允许在不停止运行的情况下,更新已经加载的类的代码。</p><p>BTrace的作用是在不中断目标程序运行的前提下,通过HotSpot虚拟机的 Instrument 功能动态加入原本并不存在的调试代码。另外，阿里的 Arthas 也是基于此实现的</p></blockquote><h1>Java Agent</h1><p><code>java.lang.instrument</code> 包提供了可以通过 Java 语言编写 JVM 的 agent（Provides services that allow Java programming language agents to instrument programs running on the JVM.）。</p><p>以下是一个 agent 机制的示意图：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201229111156.jpeg" alt="JVM architecture"></p><p>通过 java agent，我们可以使用 Java 语言编写监测 JVM 程序的逻辑，以此可以实现监控、覆盖率分析、事件日志记录等需求，其原理就是对方法的字节码进行修改，这种方式对于原应用程序来说侵入性较低。</p><p>要通过 Java Agent 实现前面提到的功能需要两个步骤：</p><ol><li>编写 Agent 逻辑</li><li>加载 Agent 到应用程序 JVM 中</li></ol><h2 id="编写-Agent"><a class="header-anchor" href="#编写-Agent">¶</a>编写 Agent</h2><p>Java gents 机制的实现基础由 <code>java.lang.instrument</code> 包提供。这个包的结构较为简单且是自包含（不依赖其它）的，里面包含了两个异常类、一个 data 类、一个 class definition以及两个接口。当我们需要实现一个 Java agent 的时候需要用到两个类：<code>ClassFileTransformer</code> 和 <code>Instrumentation</code>。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201224110021.png" alt="image-20201224110021760"></p><h3 id="ClassFileTransformer"><a class="header-anchor" href="#ClassFileTransformer">¶</a>ClassFileTransformer</h3><h4 id="transform-方法"><a class="header-anchor" href="#transform-方法">¶</a>transform 方法</h4><p>这一个接口提供了转换 class 文件的功能，这个转换动作会在 class 被 JVM <code>define</code> 之前进行。来看一下它唯一的一个方法：</p><pre class="line-numbers language-language-java"><code class="language-language-java">byte[]transform(ClassLoader loader,                   String className,                   Class<?> classBeingRedefined,                   ProtectionDomain protectionDomain,                   byte[] classfileBuffer)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个方法就是被用来对字节码做转换，也就是我们要对 class 字节码做增强的地方。</p><h5 id="参数"><a class="header-anchor" href="#参数">¶</a>参数</h5><ol><li>第一个参数：当前要 define class 的类加载器，如果是 null 则表示该类由 bootstrap 加载器加载的</li><li>第二个参数：当前要 define class 的类名，格式为 JVM 规范的内部格式，例如：“java/util/List”</li><li>第三个参数：如果当前调用是由类重定义（redefine）或者类重转换（retransform）触发的，传入的就是将要被重定义或者重转换的 Class 对象；如果当前调用仅仅是因为类加载而被触发，传入 null</li><li>第四个参数：the protection domain of the class being defined or redefined</li><li>第五个参数：该 class 文件的字节码格式的字节 buffer（不能修改这个数组）</li></ol><h5 id="返回值"><a class="header-anchor" href="#返回值">¶</a>返回值</h5><p>是修改之后要返回的字节码文件的字节 buffer。</p><h4 id="转换器类型"><a class="header-anchor" href="#转换器类型">¶</a>转换器类型</h4><p>这里将 ClassFileTransformer 接口称为一个 class 转换器，一共有两种转换器：</p><ol><li>可以重转换（retransformation capable）的转换器，在调用 <code>Instrumentation.addTransformer</code> 注册转换器的时候指定第二个参数 <code>canRetransform</code> 为 true。</li><li>不可重转换（retransformation incapable）的转换器，相反在注册转换器的时候 <code>canRetransform</code> 设置为 false。</li></ol><h4 id="转换器被触发的方式"><a class="header-anchor" href="#转换器被触发的方式">¶</a>转换器被触发的方式</h4><p>当一个转换器通过 <code>addTransformer</code> 注册之后，其 <code>transform</code> 方法被调用的时机如下：</p><ol><li>每一个新的 class 被定义（new class definition）：由<code>ClassLoader.defineClass</code> 或者它对应的 native 方法触发。</li><li>每一个 class 被重定义（class redefinition）：由 <code>Instrumentation.redefineClasses</code> 或者它对应的 native 方法触发。</li><li>每一个 class 被重转换（class retransformation）<strong>并且当前转换器是可重转换的</strong>：由 <code>Instrumentation.retransformClasses</code> 或者它对应的 native 方法触发。</li></ol><p><code>transform</code> 方法会在 class 字节码被 <strong>校验</strong> 或者 <strong>应用</strong> 之前被调用。</p><h4 id="多转换器"><a class="header-anchor" href="#多转换器">¶</a>多转换器</h4><p>如果存在多个转换器，这些转换器将会被组合成一条链条进行按序调用（前一个转换器输出的字节码数组作为下一个转换器的字节码输入）。下面是多转换器的执行顺序：</p><ul><li>不可重转换的转换器</li><li>不可重转换的 native 转换器</li><li>可以重转换的转换器</li><li>可以重转换的 native 转换器</li></ul><p>对于重转换（class retransformations）来说，不可重转换的转换器不会被调用，而是继续使用前一个转换器的输出作为下一个转换器的输入。</p><p>以上四组转换器，同组内的执行顺序和注册顺序一致。native 转换器可以通过 JVM TI 中的 <code>ClassFileLoadHook</code> 事件进行注册（Java Agent 是JVM TI Instrumentation 提供的其中一个 Java 钩子，通过 JNI 可以使用更多的钩子）。</p><h4 id="输入第一个转换器的字节码数组"><a class="header-anchor" href="#输入第一个转换器的字节码数组">¶</a>输入第一个转换器的字节码数组</h4><ul><li>对于新的 class 被定义：通过 <code>ClassLoader.defineClass</code> 传入的字节码</li><li>对于 class 重定义：通过 <code>Instrumentation.redefineClasses</code> 传入的可变参数中的每一个元素的 <code>ClassDefinition.getDefinitionClassFile()</code> 的返回值</li><li>对于 class 重转换：the bytes passed to the new class definition or, if redefined, the last redefinition, with all transformations made by retransformation incapable transformers reapplied automatically and unaltered（不是很理解，是指将不可重转换的转换器都执行了一遍，但是不会理会它的返回值？）</li></ul><h4 id="其它注意"><a class="header-anchor" href="#其它注意">¶</a>其它注意</h4><ol><li>如果转换器认为对于当前类无需做转换工作，应该返回 null；否则，应该创建一个新的字节数组，将 <code>classfileBuffer</code> 形参的内容拷贝到新数组中进行修改，然后返回该数组。<code>classfileBuffer</code> 本身不允许修改。也就是说 JVM 会根据转换器的返回结果是否为 null 而选择是使用其返回值还是传递给它的形参字节数组作为该 class 的新的字节码流。</li><li>在发生类的重转换或者重定义的场景中，转换器必须支持这样的一个语义：如果一个已经在进行类初始定义阶段被该转换器修改的类在后续再进行一个重转换或者重定义的时候，该转换器必须要确保第二次转换的 class 字节码相对于第一次转换的输出是有效、合理的。</li><li>如果当前转换器抛出了一个未捕获的异常，后续的转换器将会被继续调用，一切照常，类似于该转换器返回了 null。为了防止转换器中的一些未知行为抛出一些未检查异常，可以在转换器中捕获 <code>Throwable</code> 。如果转换器认为 <code>classFileBuffer</code> 不是一个有效格式的 class 字节码，它应该抛出 <code>IllegalClassFormatException</code> ，这会得到和返回 null 一样的效果，同时还起到一个对于非法格式字节码的记录（logging）和调试（debugging）的效果。</li></ol><h3 id="Instrumentation"><a class="header-anchor" href="#Instrumentation">¶</a>Instrumentation</h3><p>这个 class 提供了修改 Java 程序代码（instrument Java programming language code）的服务，其中的注册服务允许我们注册自定义的 class 转换器 <code>ClassFileTransformer</code> 。</p><p>Instrumentation 指的是在方法中添加收集供工具使用的一些数据的额外的字节码。因为这些修改的侵入性很低，这些工具不会修改应用的状态或者行为。这些友好的工具包含：monitoring agents、profilers、覆盖率分析器（coverage analyzers）、事件记录器（event loggers）</p><blockquote><p>monitoring 和 profiling 的概念，总的来说，前者应该是要包含后者的，即包含指标收集、分析、告警；后者则对于分析方面更专业</p><ul><li><p>program profiling</p><p>In software engineering, <strong>profiling</strong> (“program <strong>profiling</strong>”, “software <strong>profiling</strong>”) <strong>is</strong> a form of dynamic program analysis that measures, for example, the space (memory) or time complexity of a program, the usage of particular instructions, or the frequency and duration of function calls.</p></li><li><p>monitoring</p><p>In <strong>computer science</strong>, event <strong>monitoring is</strong> the process of collecting, analyzing, and signaling event occurrences to subscribers such as operating system processes, active database rules as well as human operators.</p></li></ul></blockquote><p>这里有两种方式获取 Instrumentation 服务实例的方式：</p><ol><li>当 JVM 在启动的时候指定了一个 agent class，它将会将一个 Instrumentation 实例传到 agent class 的 <code>premain</code> 方法（通过在 manifest 中添加一项 <code>Premain-Class</code> 指定该 agent class）</li><li>当 JVM 是启动之后才加载 agents 的时候，Instrumentation 实例将会被传递到 agent class 的 <code>agentmain</code> 方法（通过在 manifest 中添加一项 <code>Agent-Class</code> 指定该 agent class）</li></ol><p>下面来看一下 Instrumentation 提供的服务（方法）。</p><h4 id="1-注册转换器"><a class="header-anchor" href="#1-注册转换器">¶</a>1&gt;注册转换器</h4><pre class="line-numbers language-language-java"><code class="language-language-java">voidaddTransformer(ClassFileTransformer transformer, boolean canRetransform)  voidaddTransformer(ClassFileTransformer transformer) // same as addTransformer(transforrmer, false)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="参数-v2"><a class="header-anchor" href="#参数-v2">¶</a>参数</h5><ol><li>要注册的 class 转换器</li><li>该转换器是否可重转换</li></ol><h5 id="描述"><a class="header-anchor" href="#描述">¶</a>描述</h5><p>注册传入的 class 转换器，所有在后续发生的 class 定义对于当前注册的 class 转换器都是可见的，除了那些被任何已注册转换器依赖的 class 的定义。转换器被调用的时机和顺序参考上面的描述。同一个转换器可以被注册多次，但强烈建议不要这样做，而是创建一个新的转换器对象。</p><h4 id="2-注销转换器"><a class="header-anchor" href="#2-注销转换器">¶</a>2&gt;注销转换器</h4><pre class="line-numbers language-language-java"><code class="language-language-java">boolean removeTransformer(ClassFileTransformer transformer)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="参数-v3"><a class="header-anchor" href="#参数-v3">¶</a>参数</h5><ol><li>要注销的转换器</li></ol><h5 id="返回值-v2"><a class="header-anchor" href="#返回值-v2">¶</a>返回值</h5><ul><li>如果转换器可以找到并且删除了，返回 true</li><li>如果无法找到该转换器，返回 false</li></ul><h5 id="描述-v2"><a class="header-anchor" href="#描述-v2">¶</a>描述</h5><p>注销指定的转换器，之后再进行的 class 定义将不会应用该转换器。Removes the most-recently-added matching instance of the transformer. Due to the multi-threaded nature of class loading, it is possible for a transformer to receive calls after it has been removed. Transformers should be written defensively to expect this situation.（移除匹配到的最晚添加的实例，因为类加载的多线程特性，可能会出现一个转换器在被注销之后还被调用的情况。在编写转换器的时候应该要考虑、预防这种情况）。</p><h4 id="3-查看当前-JVM-是否支持-class-重转换"><a class="header-anchor" href="#3-查看当前-JVM-是否支持-class-重转换">¶</a>3&gt;查看当前 JVM 是否支持 class 重转换</h4><pre class="line-numbers language-language-java"><code class="language-language-java">boolean isRetransformClassesSupported()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="描述-v3"><a class="header-anchor" href="#描述-v3">¶</a>描述</h5><p>class 重转换是 JVM 的一个可选能力。当且仅当在 agent JAR 文件中的 manifest 中添加 <code>Can-Retransform-Classes</code> 属性为 true 的时候，JVM 才会支持重转换。在一个 JVM 实例中，对该方法的多次调用总是会返回相同的值。</p><h4 id="4-重转换-classes"><a class="header-anchor" href="#4-重转换-classes">¶</a>4&gt;重转换 classes</h4><pre class="line-numbers language-language-java"><code class="language-language-java">void retransformClasses(Class<?>... classes)                 throws UnmodifiableClassException<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="参数-v4"><a class="header-anchor" href="#参数-v4">¶</a>参数</h5><ol><li>需要被重转换的 classes 数组；设置一个长度为 0 的空数组，该方法则什么也不做</li></ol><h5 id="描述-v4"><a class="header-anchor" href="#描述-v4">¶</a>描述</h5><p>对于提供的 classes 集合进行重转换。该方法使得已经被加载的 classes 可以被 instrument，无论这些 classes 是否已经被转换器处理过，都会再被转换一次，以下是它的执行步骤：</p><ol><li><p>从 initial class file bytes 开始。</p><blockquote><p>initial class file bytes 指的是传递给 <code>ClassLoader.defineClass</code> 或者 <code>redefineClasses</code> 的字节数组（在任何转换器被调用之前）。不过它们（传递给方法之前和方法处理后）可能不是完全一模一样的。</p><ul><li>常量池的布局和内容可能不太一样</li><li>常量池的条目可能变多或者变少</li><li>常量池条目的顺序可能不太一样</li><li>一些属性可能不存在了</li><li>字节码内部元素的顺序没有被保证，例如方法之间的顺序，因为这些顺序是没有意义的</li></ul><p>但是在方法内的字节码中引用的常量池索引时候一致的。</p></blockquote></li><li><p>for each transformer that was added with <code>canRetransform</code> false, the bytes returned by <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/instrument/ClassFileTransformer.html#transform-java.lang.ClassLoader-java.lang.String-java.lang.Class-java.security.ProtectionDomain-byte:A-" target="_blank" rel="noopener"><code>transform</code></a> during the last class load or redefine are reused as the output of the transformation; note that this is equivalent to reapplying the previous transformation, unaltered; except that <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/instrument/ClassFileTransformer.html#transform-java.lang.ClassLoader-java.lang.String-java.lang.Class-java.security.ProtectionDomain-byte:A-" target="_blank" rel="noopener"><code>transform</code></a> is not called</p></li><li><p>对于可以重转换的转换器，它们的 <code>transform</code> 方法将会被调用。</p></li><li><p>转换后的 class 文件字节码将会被为该 class 的新的定义</p></li></ol><p>The order of transformation is described in the <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/instrument/ClassFileTransformer.html#transform-java.lang.ClassLoader-java.lang.String-java.lang.Class-java.security.ProtectionDomain-byte:A-" target="_blank" rel="noopener"><code>transform</code></a> method. This same order is used in the automatic reapplication of retransformation incapable transforms.</p><p>这个方法操作的是一个集合，允许一次性操作多个互相影响的 classes。<strong>如果被重转换的方法已经存在一些栈帧，这些栈帧的字节码将会保持和原方法一致不变，而重转换后的方法将会在后续的新的调用中被使用。</strong></p><p>This method does not cause any initialization except that which would occur under the customary JVM semantics. In other words, redefining a class does not cause its initializers to be run. The values of static variables will remain as they were prior to the call.</p><p>Instances of the retransformed class are not affected.</p><p>重转换可能还会修改方法体、常量池和属性表，但是一定不能添加、移除、重命名字段或者方法、修改方法签名或者修改继承关系。这些限制可能会在未来的 Java 版本中被移除。class 字节码在重转换完成之后才会进行检查、校验、安装/应用，如果最终转换后得到的字节码是错误的，这个方法将会抛出一个异常。</p><p>如果这个方法抛出了异常，将不会有 classes 被重转换。</p><h4 id="5-是否支持重定义-classes"><a class="header-anchor" href="#5-是否支持重定义-classes">¶</a>5&gt;是否支持重定义 classes</h4><pre class="line-numbers language-language-java"><code class="language-language-java">boolean isRedefineClassesSupported()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>返回当前 JVM 是否支持重定义 classes。当且仅当在 agent JAR 的 manifest 中存在 <code>Can-Redefine-Classes</code> 属性为 true 且 JVM 拥有重定义 classes 的能力的时候返回 true。</p><h4 id="6-重定义-classes"><a class="header-anchor" href="#6-重定义-classes">¶</a>6&gt;重定义 classes</h4><pre class="line-numbers language-language-java"><code class="language-language-java">redefineClassesvoid redefineClasses(ClassDefinition... definitions)              throws ClassNotFoundException,                     UnmodifiableClassException<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>重定义给定的 class （定义）。</p><p>这个方法在无需使用现有 classes 的引用的情况下替换它们的定义，类似在调试代码的时候进行热重载那样重新编译某些类。当某些类需要被转换的时候，<code>retransformClasses</code> 就会被调用。</p><p>This method operates on a set in order to allow interdependent changes to more than one class at the same time (a redefinition of class A can require a redefinition of class B).</p><p><strong>如果被重定义的方法已经存在一些栈帧，这些栈帧的字节码将会保持和原方法一致不变，而重定义后的方法将会在后续的新的调用中被使用。</strong></p><p>This method does not cause any initialization except that which would occur under the customary JVM semantics. In other words, redefining a class does not cause its initializers to be run. The values of static variables will remain as they were prior to the call.</p><p>Instances of the redefined class are not affected.</p><p>重转换可能还会修改方法体、常量池和属性表，但是一定不能添加、移除、重命名字段或者方法、修改方法签名或者修改继承关系。这些限制可能会在未来的 Java 版本中被移除。class 字节码在重转换完成之后才会进行检查、校验、安装/应用，如果最终得到的字节码是错误的，这个方法将会抛出一个异常。</p><p>如果这个方法抛出了异常，将不会有 classes 被重定义。</p><h4 id="7-判断一个-class-是否可以被修改"><a class="header-anchor" href="#7-判断一个-class-是否可以被修改">¶</a>7&gt;判断一个 class 是否可以被修改</h4><pre class="line-numbers language-language-java"><code class="language-language-java">boolean isModifiableClass(Class<?> theClass)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>判断一个 class 是否可以通过重转换和重定义来修改，可以则返回 true，否则返回 false。</p><p>class 的重转换必须 <code>isRetransformClassesSupported()</code> 为 true；重定义必须要 <code>isRedefineClassesSupported()</code> 为 true。但是这两个方法的返回值不会对当前方法产生影响，这个方法是具体的类维度的定义。</p><p>原生类（如 <code>java.lang.Integer.TYPE</code>）以及数组类永远不能被修改</p><h4 id="8-获取当前-JVM-已经加载的所有-classes"><a class="header-anchor" href="#8-获取当前-JVM-已经加载的所有-classes">¶</a>8&gt;获取当前 JVM 已经加载的所有 classes</h4><pre class="line-numbers language-language-java"><code class="language-language-java">Class[] getAllLoadedClasses()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="9-获取某个类加载器已经初始化的类"><a class="header-anchor" href="#9-获取某个类加载器已经初始化的类">¶</a>9&gt;获取某个类加载器已经初始化的类</h4><pre class="line-numbers language-language-java"><code class="language-language-java">Class[] getInitiatedClasses(ClassLoader loader)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>获取传入类加载器已经加载的所有类，如果传入为 null，将视为传入了 boostrap 类加载。</p><h4 id="10-获取对象的大小"><a class="header-anchor" href="#10-获取对象的大小">¶</a>10&gt;获取对象的大小</h4><pre class="line-numbers language-language-java"><code class="language-language-java">long getObjectSize(Object objectToSize)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>返回传入对象的大小，这个大小取决于具体虚拟机的实现，且是一个近似值。这个值仅适合在同一个 JVM 内进行比较，另外这个估算值也是可能会变化的。</p><h4 id="11-添加额外的-jar"><a class="header-anchor" href="#11-添加额外的-jar">¶</a>11&gt;添加额外的 jar</h4><pre class="line-numbers language-language-java"><code class="language-language-java">void appendToBootstrapClassLoaderSearch(JarFile jarfile)void appendToSystemClassLoaderSearch(JarFile jarfile)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol><li><p>方法一是添加包含 instrumentation classes 的 jar，当 boostrap 类加载器无法加载某个类的时候，就会在该 jar 中搜索该类进行加载，这个方法可以被调用多次添加多个 jar，避免 jar 中包含除了 instrumentation 之外的 class，导致潜在的类同名加载冲突。一个合适的避免冲突的方法就是给 instrumentation 的类放在一个唯一的包名下。</p></li><li><p>方法二是添加包含 instrumentation classes 的 jar，当 system 类加载器无法加载某个类的时候，就会在该 jar 中搜索该类进行加载，这个方法可以被调用多次添加多个 jar，避免 jar 中包含除了 instrumentation 之外的 class，导致潜在的类同名加载冲突。</p><p>当 system 类加载器实现一个名为 <code>appendToClassPathForInstrumentatiion</code> 的、且只有一个 <code>java.lang.String</code> 参数的方法时，才支持这种添加 jar 的方式。JVM 通过 <code>jarfile.getName()</code> 返回的结果传入到该方法的参数中实现添加 jar。</p></li></ol><h4 id="12-isNativeMethodPrefixSupported"><a class="header-anchor" href="#12-isNativeMethodPrefixSupported">¶</a>12&gt;isNativeMethodPrefixSupported</h4><h4 id="13-setNativeMethodPrefix"><a class="header-anchor" href="#13-setNativeMethodPrefix">¶</a>13&gt;setNativeMethodPrefix</h4><h2 id="两种加载-Agent-的方式"><a class="header-anchor" href="#两种加载-Agent-的方式">¶</a>两种加载 Agent 的方式</h2><p>我们需要编写一个 agent 类，这个类中包含一些会被 JVM 通过某种方式运行的钩子方法，然后在钩子方法中可以获取到 JVM 传入的 <code>Instrumentation</code> 实例添加我们的自定义类转换器。</p><h3 id="静态加载"><a class="header-anchor" href="#静态加载">¶</a>静态加载</h3><p>在启动程序的时候指定 agent：</p><ol><li><p>将我们写好的 agent 打包成一个 jar，在启动 Java 程序的时候指定一个 JVM 参数 <code>javaagent</code></p><pre class="line-numbers language-language-shell"><code class="language-language-shell">java -javaagent:<agent jar包路径>[=options] -jar <JVM程序jar包路径><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个选项可以用在一个命令上使用多次，从而创建多个 agent。多个 agent 可能使用同一个 jar。</p></li><li><p>在 agent jar 中的 manifest 添加一项 <code>Premain-class</code> 为我们的 agent 类的全限定名，例如</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">Premain-Class : org.example.JavaAgent<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>agent 类中的必须存在以下钩子方法中的一个</p><pre class="line-numbers language-language-java"><code class="language-language-java">public static void premain(String agentArgs, Instrumentation inst);public static void premain(String agentArgs);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>JVM 会先尝试寻找前者调用；如果 agent 中没有实现该方法，就会尝试调用后者；如果还找不到，JVM 就会停止运行。第一步中的 <code>options</code> 字符串会传递到 <code>premain</code> 方法的第一个字符串参数中。</p></li></ol><p>静态指定 agent 的方式在程序启动的时候在任何代码执行之前进行字节码修改（先按照 agent 的定义顺序执行 <code>premain</code> 方法，所有 <code>premain</code> 方法执行完成之后才会执行 <code>main</code> 方法）。</p><p>agent class 是通过 system class loader 加载的（<code>ClassLoader.getSystemClassLoader</code>）。这个类加载器同时会加载应用的 main 方法类。<code>premain</code> 方法和 <code>main</code> 方法拥有相同的 security 和 classloader rules，没有什么特别的限制，只要是 <code>main</code> 方法中能做的，<code>premain</code> 方法都可以做。</p><p>如果无法获取 agent（包括 agent class 无法加载、agent class 没有 <code>premain</code> 方法）或者 <code>premain</code> 方法抛出了异常，JVM 都会停止运行。</p><h3 id="动态加载"><a class="header-anchor" href="#动态加载">¶</a>动态加载</h3><p>在 JVM 程序运行之后（<code>main</code> 方法已经运行），通过 <a href="https://docs.oracle.com/javase/7/docs/jdk/api/attach/spec/com/sun/tools/attach/package-summary.html" target="_blank" rel="noopener">Java Attach API</a> 为正在运行的 JVM 进程加载 agent（Arthas）。</p><ol><li><p>将写好的 agent 类打包在一个 JAR，并在 manifest 中添加一项 <code>Agent-Class</code> ，类似 <code>Premain-Class</code>，值为 agent 类的全限定名。</p></li><li><p>agent 类必须实现以下之一的钩子方法：</p><pre class="line-numbers language-language-java"><code class="language-language-java">public static void agentmain(String agentArgs, Instrumentation inst);public static void agentmain(String agentArgs);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>同 <code>premain</code> 方法，JVM 会先尝试调用前者然后再尝试调用后者。<code>agentmain</code> 方法的类加载器和 <code>premain</code> 一致，security 和 classloader rules 也一致。</p></li><li><blockquote><p>注意： agent class 中的 <code>agentmain</code> 方法只有在动态加载的方式中会被调用，而且一旦 JVM 已经启动将不会调用 <code>premain</code> 方法；而在通过命令行方式的静态加载 agent，<code>agentmain</code> 方法不会被调用。</p></blockquote></li><li><p>通过 <code>Java Attach API</code> 编写第三个程序代码，该程序会连接到需要被 agent 的 JVM 程序，然后通过类似以下代码使得该程序加载 agent：</p><pre class="line-numbers language-language-java"><code class="language-language-java">String agentFilePath = "/Users/zhonghongpeng/IdeaProjects/tech-learning/learingsamples/agent/target/test-agent-jar-with-dependencies.jar";            VirtualMachine jvm = VirtualMachine.attach(jvmPid);jvm.loadAgent(agentFile.getAbsolutePath());jvm.detach();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h3 id="agent-的-manifest-属性"><a class="header-anchor" href="#agent-的-manifest-属性">¶</a>agent 的 manifest 属性</h3><ul><li><p><strong><code>Premain-Class</code>：当 agent 在 JVM 启动的时候被指定，需要定义该属性为 agent class 的全限定名，也就是包含 <code>premain</code> 方法的类，如果该类没有该方法，JVM 会停止运行。</strong></p></li><li><p><strong><code>Agent-Class</code>：如果 JVM 的实现提供了在 VM 启动之后加载 agent 的机制，需要通过当前属性指定 agent 类的全限定名，该类包含了 <code>agentmain</code> 方法，否则 JVM 会停止运行。</strong></p></li><li><p>Boot-Class-Path：A list of paths to be searched by the bootstrap class loader. Paths represent directories or libraries (commonly referred to as JAR or zip libraries on many platforms). These paths are searched by the bootstrap class loader after the platform specific mechanisms of locating a class have failed. Paths are searched in the order listed. Paths in the list are separated by one or more spaces. A path takes the syntax of the path component of a hierarchical URI. The path is absolute if it begins with a slash character (‘/’), otherwise it is relative. A relative path is resolved against the absolute path of the agent JAR file. Malformed and non-existent paths are ignored. When an agent is started sometime after the VM has started then paths that do not represent a JAR file are ignored. This attribute is optional.</p></li><li><p><strong><code>Can-Redefine-Classes</code>：Boolean (<code>true</code> or <code>false</code>, case irrelevant). 是否需要为该 agent 开启 redefine class 的功能. 不是 <code>true</code> 的值都会被当成 <code>false</code>. 可选，默认是 <code>false</code>.</strong></p></li><li><p><strong><code>Can-Retransform-Classes</code>：Boolean (<code>true</code> or <code>false</code>, case irrelevant). 是否需要为该 agent 开启 rertransform class 的功能. 不是 <code>true</code> 的值都会被当成 <code>false</code>. 可选，默认是 <code>false</code>.</strong></p></li><li><p><code>Can-Set-Native-Method-Prefix</code>：Boolean (<code>true</code> or <code>false</code>, case irrelevant). Is the ability to set native method prefix needed by this agent. Values other than <code>true</code> are considered <code>false</code>. This attribute is optional, the default is <code>false</code>.</p></li></ul><h2 id="字节码框架选型指标"><a class="header-anchor" href="#字节码框架选型指标">¶</a>字节码框架选型指标</h2><p>high-level API or low-level API, community size, and the license</p><h1>遇到的问题和解决</h1><h2 id="Maven打包问题"><a class="header-anchor" href="#Maven打包问题">¶</a>Maven打包问题</h2><p>默认情况下，maven 仅对当前工程中的源文件编译出来的字节码打包到一个 jar 中，而不会对其依赖项进行打包。一旦我们直接执行打包出来的文件就会遇到 <code>ClassNotFound</code> 等错误。这里通过一个 maven 插件 <code>maven-assembly-plugin</code> 解决，它会对当前项目默认打出来的包进行重新打包（另外 springboot 也有类似的插件），包含了除了 system scope 之外的所有依赖：</p><pre class="line-numbers language-language-xml"><code class="language-language-xml">            <plugin>                <artifactId>maven-assembly-plugin</artifactId>                <configuration>                    <archive>                        <manifest>                            <addClasspath>true</addClasspath>                        </manifest>                        <manifestEntries>                            <Premain-Class>com.john.agent.MyInstrumentationAgent</Premain-Class>                            <Main-Class>com.john.application.Launcher</Main-Class>                            <Can-Retransform-Classes>true</Can-Retransform-Classes>                            <Can-Redefine-Classes>true</Can-Redefine-Classes>                        </manifestEntries>                    </archive>                    <descriptorRefs>                        <descriptorRef>jar-with-dependencies</descriptorRef>                    </descriptorRefs>                    <finalName>test-agent</finalName>                </configuration>            </plugin><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行以下命令即可：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">mvn assembly:assembly<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>使用以下命令可以查看需要的 class 是否已经被打在包中：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">jar -tf test-agent-jar-with-dependencies.jar | grep xxx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="找不到-VirtualMachine-类"><a class="header-anchor" href="#找不到-VirtualMachine-类">¶</a>找不到 VirtualMachine 类</h2><p>在 <code>AgentLoader</code> 类中我们引入了 <code>com.sun.tools.attach.VirtualMachine</code> 类，IDEA 编译是可以通过的，因为 IDEA 自动扫描的 classpath 包含了该类所属 jar 包 tools.jar 所在路径。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201229115949.png" alt="image-20201229115948942"></p><p>但是在进行 maven 打包的时候编译过不了：</p><h3 id="步骤1"><a class="header-anchor" href="#步骤1">¶</a>步骤1</h3><p>通过增加 system 依赖解决</p><pre class="line-numbers language-language-xml"><code class="language-language-xml">        <dependency>            <groupId>org.sun</groupId>            <artifactId>tools</artifactId>            <version>1.0</version>            <scope>system</scope>            <systemPath>${JAVA_HOME}/lib/tools.jar</systemPath>        </dependency><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上方式虽然使得 maven 打包的时候可以编译通过但是在运行 jar 文件的时候就找不到了，报了以下错误：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">十二月 29, 2020 10:07:37 上午 com.john.agent.MyInstrumentationAgent premain信息: [Agent] In premain methodclass com.john.application.MyAtmsun.misc.Launcher$AppClassLoader@18b4aac2Exception in thread "main" java.lang.reflect.InvocationTargetException        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:498)        at sun.instrument.InstrumentationImpl.loadClassAndStartAgent(InstrumentationImpl.java:386)        at sun.instrument.InstrumentationImpl.loadClassAndCallPremain(InstrumentationImpl.java:401)Caused by: java.lang.NoClassDefFoundError: javassist/NotFoundException        at com.john.agent.MyInstrumentationAgent.transform(MyInstrumentationAgent.java:50)        at com.john.agent.MyInstrumentationAgent.transformClass(MyInstrumentationAgent.java:31)        at com.john.agent.MyInstrumentationAgent.premain(MyInstrumentationAgent.java:14)        ... 6 moreCaused by: java.lang.ClassNotFoundException: javassist.NotFoundException        at java.net.URLClassLoader.findClass(URLClassLoader.java:381)        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)        ... 9 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>看到了一个 <code>java.lang.NoClassDefFoundError</code> 错误，所有的元信息 <code>Error</code> 都是因为在运行时和编译期的元信息（类、方法、属性等）发生了偏差被抛出。这里是因为在编译期 <code>VirtualMachine</code> 类就需要被检查（因为在 <code>AgentLoader</code> 的 <code>.java</code> 源文件中使用了 <code>import</code> 字面量进行导入，在 <code>javac</code> 编译阶段就需要进行检查；相对于那些不会在编译期做检查的元信息错误即抛出 <code>Exception</code>）是否存在，被引用的方法描述是否正确等，在编译期通过后但是在运行期发现通过所有类加载器都无法找到这个类，即抛出一个该 <code>Error</code>。</p><p>其根本原因是因为在运行时类加载器无法找到 <code>tools.jar</code> 这一个包，而这又是因为上面提到的 <code>assembly</code> maven 插件默认不会将 system scope 的 jar 打到包中，以下有三种方式可以解决：</p><ol><li>增加 <code>assembly.xml</code> 修改 assembly 默认配置：比较繁琐，要引入额外的配置，这里先不选择这种。</li><li>执行 java 程序的时候通过 <code>-cp</code> 指定 <code>tools.jar</code>：我们需要通过 <code>-jar</code> 来运行我们打出来的 full jar，同时一旦指定了 <code>-jar</code> 选项，<code>-cp</code> 就会被忽略，不选择。</li><li>使用 <code>maven-install</code> 插件将本地安装绑定到 clean 阶段，查看下面的步骤2</li></ol><h3 id="步骤2"><a class="header-anchor" href="#步骤2">¶</a>步骤2</h3><p>引入以下插件，在 <code>mvn clean</code> 阶段将  <code>tools.jar</code> 安装到本地：</p><pre class="line-numbers language-language-xml"><code class="language-language-xml">            <plugin>                <artifactId>maven-assembly-plugin</artifactId>                <configuration>                    <archive>                        <manifest>                            <addClasspath>true</addClasspath>                        </manifest>                        <manifestEntries>                            <Premain-Class>com.john.agent.MyInstrumentationAgent</Premain-Class>                            <Agent-Class>com.john.agent.MyInstrumentationAgent</Agent-Class>                            <Main-Class>com.john.application.Launcher</Main-Class>                            <Can-Retransform-Classes>true</Can-Retransform-Classes>                            <Can-Redefine-Classes>true</Can-Redefine-Classes>                        </manifestEntries>                    </archive>                    <descriptorRefs>                        <descriptorRef>jar-with-dependencies</descriptorRef>                    </descriptorRefs>                    <finalName>test-agent</finalName>                </configuration>            </plugin><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后修改依赖为：</p><pre class="line-numbers language-language-xml"><code class="language-language-xml">        <dependency>            <groupId>org.sun</groupId>            <artifactId>tools</artifactId>            <version>0.1</version>        </dependency><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在每一次执行以下命令之前先执行 <code>mvn clean</code> 即可：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">mvn assembly:assembly<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1>参考阅读</h1><p><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/jvmti/" target="_blank" rel="noopener">oracle JVM TI guide</a></p><p><a href="https://docs.oracle.com/javase/8/docs/platform/jvmti/jvmti.html" target="_blank" rel="noopener">JVM Tool Interface Reference</a></p><p><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/instrumentation/index.html" target="_blank" rel="noopener">oracle java.lang.instrument pacakge</a></p><p><a href="https://docs.oracle.com/javase/8/docs/api/java/lang/instrument/package-summary.html" target="_blank" rel="noopener">oracle java se 8 api document：Package java.lang.instrument</a></p><p><a href="https://www.jrebel.com/blog/how-write-javaagent" target="_blank" rel="noopener">Jrebel：How to write Java agent</a></p><p><a href="https://www.baeldung.com/java-instrumentation" target="_blank" rel="noopener">baeldung：Guide to Java Instrumentation</a></p><p><a href="https://github.com/eugenp/tutorials/tree/master/core-java-modules/core-java-jvm" target="_blank" rel="noopener">包含了静态加载和动态加载实现的代码示例</a></p><p><a href="https://dzone.com/articles/java-agent-1#:~:text=Java%20agents%20are%20a%20special,using%20the%20simple%20HelloWorld%20Example." target="_blank" rel="noopener">Understanding Java Agents</a></p><p><a href="https://www3.ntu.edu.sg/home/ehchua/programming/java/JavaNativeInterface.html" target="_blank" rel="noopener">Java Programming Tutoriial JNI</a></p><p><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/jni/index.html" target="_blank" rel="noopener">Oracle jdk8 JNI</a></p>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于 Redis 的分布式锁：RedLock</title>
      <link href="/2021/01/04/redis/redis-guan-fang-wen-dang/redlock/"/>
      <url>/2021/01/04/redis/redis-guan-fang-wen-dang/redlock/</url>
      
        <content type="html"><![CDATA[<p>对于存在多个进程必须互斥的访问共享资源的环境中，分布式锁是一个很有用的基础工具。</p><p>许多库和博客描述了怎么使用 redis 实现一个 DLM（分布式锁管理器），但是每一个库都有不同的实现方式，并且大多数都是可靠性较低的简单实现。</p><p>这里将尝试提供一个更加规范的基于 redis 实现的分布式锁的算法，称为 Redlock。该算法实现了一个比使用单实例构建分布式锁的更加安全的 DLM。</p><h1>实现</h1><p>以下是一些该算法的实现：</p><ul><li><a href="https://github.com/antirez/redlock-rb" target="_blank" rel="noopener">Redlock-rb</a> (Ruby implementation). There is also a <a href="https://github.com/leandromoreira/redlock-rb" target="_blank" rel="noopener">fork of Redlock-rb</a> that adds a gem for easy distribution and perhaps more.</li><li><a href="https://github.com/SPSCommerce/redlock-py" target="_blank" rel="noopener">Redlock-py</a> (Python implementation).</li><li><a href="https://github.com/brainix/pottery#redlock" target="_blank" rel="noopener">Pottery</a> (Python implementation).</li><li><a href="https://github.com/joanvila/aioredlock" target="_blank" rel="noopener">Aioredlock</a> (Asyncio Python implementation).</li><li><a href="https://github.com/ronnylt/redlock-php" target="_blank" rel="noopener">Redlock-php</a> (PHP implementation).</li><li><a href="https://github.com/malkusch/lock#phpredismutex" target="_blank" rel="noopener">PHPRedisMutex</a> (further PHP implementation)</li><li><a href="https://github.com/cheprasov/php-redis-lock" target="_blank" rel="noopener">cheprasov/php-redis-lock</a> (PHP library for locks)</li><li><a href="https://github.com/rtckit/reactphp-redlock" target="_blank" rel="noopener">rtckit/react-redlock</a> (Async PHP implementation)</li><li><a href="https://github.com/go-redsync/redsync" target="_blank" rel="noopener">Redsync</a> (Go implementation).</li><li><a href="https://github.com/mrniko/redisson" target="_blank" rel="noopener">Redisson</a> (Java implementation).</li><li><a href="https://github.com/sbertrang/redis-distlock" target="_blank" rel="noopener">Redis::DistLock</a> (Perl implementation).</li><li><a href="https://github.com/jacket-code/redlock-cpp" target="_blank" rel="noopener">Redlock-cpp</a> (C++ implementation).</li><li><a href="https://github.com/kidfashion/redlock-cs" target="_blank" rel="noopener">Redlock-cs</a> (C#/.NET implementation).</li><li><a href="https://github.com/samcook/RedLock.net" target="_blank" rel="noopener">RedLock.net</a> (C#/.NET implementation). Includes async and lock extension support.</li><li><a href="https://github.com/psibernetic/scarletlock" target="_blank" rel="noopener">ScarletLock</a> (C# .NET implementation with configurable datastore)</li><li><a href="https://github.com/LiZhenNet/Redlock4Net" target="_blank" rel="noopener">Redlock4Net</a> (C# .NET implementation)</li><li><a href="https://github.com/mike-marcacci/node-redlock" target="_blank" rel="noopener">node-redlock</a> (NodeJS implementation). Includes support for lock extension.</li></ul><h1>安全性和可用性保证</h1><p>以下是将要描述的分布式锁的最小保证，拥有三个属性：</p><ol><li>安全性（Safety property）：锁的互斥。在任意时刻，只会有一个客户端持有锁。</li><li>可用性 A（Liveness property A）: 死锁自动释放。当出现类似某个客户端在申请了一个锁之后崩溃了或者和 DLM 出现了网络分区，这个锁最终是可以被其它客户端申请得到，而不是永远不可用.</li><li>可用性 B（Liveness property B）: 容灾. 只要<strong>大多数</strong>的 Redis 节点都是正常的，客户端就可以获取和释放锁.</li></ol><h1>基于故障转移的实现方案的问题</h1><p>为了明白这个 redlock 优化了什么问题，让我们来分析一下现有的大多数基于 redis 实现的分布式锁库。</p><p>使用 redis 来锁住某个资源的最简单方式就是创建一个有 ttl 的 key，使用 redis 的过期键特性，这个锁最终都可以释放。当客户端需要释放这个资源的时候，删除该 key 即可。</p><p>表面上看是可行的，但是这里有一个问题：该 key 存储在 redis 的一个单点实例中，如果这个实例挂了就会出问题。很容易想到的是增加一个从节点，当主节点挂掉之后就使用这个从节点即可。很不幸这是不可行的，如果这样做我们将不能实现属性1–锁的互斥，因为 redis 主从复制是异步的。</p><p>下面是一个基于该模型的并发竞争的例子：</p><ol><li>客户端 A 在 master 中获得了锁</li><li>master 在将 key 传递到 slave 之前挂掉了</li><li>slave 被提升为主节点</li><li>客户端 B 申请到了客户端 A 已经持有的用来锁住某资源的锁。安全性被破坏。</li></ol><p>在某些情况下这种方式是可行的，例如业务允许在故障期间存在多个客户端同时持有相同的锁。如果是这种情况，可以使用基于主从复制实现的方案，否则建议使用 redlock。</p><h1>单实例分布式锁的正确实现方式</h1><p>在尝试解决上述提到的单点分布式锁方案的一些问题之前，先来看看如何正确地使用单点 redis 来正确地实现分布式锁，因为单点分布式锁对于不时的并发竞争还是可以接受的，而使用一个 redis key 作为一个锁是一个基础，redlock 分布式算法也会使用到这个基础。</p><p>我们将使用以下方式来获取锁：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">    SET resource_name my_random_value NX PX 30000<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个命令只有在该 key 不存在的时候才会设置该 key（<code>NX</code> 选项），同时会将该 key 的过期时间设置为 30000 毫秒（<code>PX</code> 选项）。这个 key 的值被设置为 “myrandomvalue”。这个值必须在所有客户端以及所有取锁请求中是唯一的。这个随机值是安全解锁的基础，它会被这样一个脚本用来和 redis 交互：当且仅当这个 key 存在并且其值和当前请求的随机值完全一致，则删除该 key。以下是 lua 脚本的实现：</p><pre class="line-numbers language-language-lua"><code class="language-language-lua">if redis.call("get",KEYS[1]) == ARGV[1] then    return redis.call("del",KEYS[1])else    return 0end<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这对于避免释放掉其它客户端持有的锁来说是很重要的。举个例子：</p><ul><li>一个客户端 A 获取了锁，然后被一些操作阻塞直至时间大于锁的有效时间（key 过期时间），然后锁因为过期被移除了</li><li>此时另外一个客户端 B 获得了锁</li><li>此时客户端 A 操作完成会进行锁释放</li></ul><p>如果客户端 A 直接使用 <code>DEL</code> 删除该锁将会移除掉 B 的锁。使用上述 lua 脚本将会使得每个锁都被使用一个随机值签名了，所以删除锁的客户端只能是获取该锁的那一个。</p><p>可以使用 <code>/dev/urandom</code> 获取 20 字节的伪随机数，也可以根据自己的情况使用其它更简易的方式获取一个对于自己来说足够唯一的值。例如一个安全的选择是基于 <code>/dev/urandom</code> 使用 <code>RC4</code> 再进行加密。一个更简单的解决方案是使用 unix 微秒时间戳拼接客户端 ID，可能没有完全安全，但是对于大多数情况可以满足。</p><p>key 的 ttl 被称为 “锁的有效时间”。它是锁的自动释放时间，也是取到锁的客户端必须要完成自己的业务操作的时间，否则其它客户端就会取到锁，从而违背了锁互斥的安全保证。</p><p>以上的分布式的获取和释放方式对于一个非分布式的、单点的、永远可用的系统（redis）来说来说安全的。下面将对一些概念进行扩展进而讨论如何实现高可用的分布式锁。</p><h1>Redlock 算法</h1><p>在分布式版本的算法中假设有 N 个 redis master。这些节点是互相独立的，所以我们不使用从节点或者其它潜在的协调系统。在上面已经讨论了如何在一个实例下安全地取锁和释放锁。在以下例子中将有 5 个 master 节点，这是一个合理的数值，这 5 个 redis master 运行在不同的物理机或者虚拟机上，保证它们任何一个节点（环境）的不可用会影响到其它节点。</p><p>客户端通过以下步骤获取锁：</p><ol><li>获取当前的毫秒时间戳。</li><li>使用相同的 key 和唯一值 value 对 N 个实例<strong>按顺序</strong>取锁。在此期间，客户端应该使用一个较小于锁自动释放时间的一个时间作为获取锁的动作的超时时。例如如果自动释放锁的时间是 10 秒，则取锁超时时间可以在 5 到 50 毫秒之间。这是为了防止客户端长时间阻塞在一个可能已经挂掉的 redis 节点上：如果一个实例已经不可达，则已经尽快地尝试下一个节点。</li><li>客户端从当前时间戳减去步骤 1 的时间戳，计算出取锁花费的总时间。当且仅当客户端在大多数实例（至少 3 个）中获取到了锁，并且总消耗时间少于锁的有效时间，则认为该客户端取到了锁。</li><li>如果一个锁被申请到了，它的有效时间就是初始有效时间减去取锁总消耗时间，就像步骤 3 的计算一样。</li><li>如果客户端因为某些原因没有获取到锁（无法锁住 N/2+1 个实例或者算得有效时间是负数），它需要对所有实例进行解锁（尽管是它认为它没有锁住的实例）。</li></ol><h2 id="该算法是否异步的"><a class="header-anchor" href="#该算法是否异步的">¶</a>该算法是否异步的</h2><p>这个算法的前提是假设各进程之间没有时钟同步（互不影响，非同步），每个进程的时间都以近似相同的速率流逝，允许存在相较于自动释放锁时间要小的偏差。这个假设接近于真实的计算机：所有计算机拥有本地时钟，我们通常依赖于不同的计算机之间拥有一个较小的时钟偏移。</p><p>考虑到这一点，已经更严谨地定义 redlock 的互斥性：只要客户端在锁的有效时间（步骤3计算出来的）减去一些时间（为了补偿不同进程间的时钟偏移的几毫秒）之内完成它的业务就可以保证互斥性。</p><h2 id="失败重试"><a class="header-anchor" href="#失败重试">¶</a>失败重试</h2><p>当一个客户端无法申请到锁的时候，它应该在一个<strong>随机的</strong>延迟之后进行重试，这是为了将多个客户端在同一时间对一个资源获取锁的动作错开（这是因为如果不错开可能会导致脑裂/因为当某个客户端在当前 redis master 无法获取锁的时候它会尽快从下一个实例获取，如果一直有多个客户端同时在获取同一个 redlock，将可能导致一直没有客户端获取到 N/2+1 个锁）。另外，<strong>只要一个客户端在大多数 Redis 实例中获取到锁的时间越短，发生脑裂的窗口也就越小</strong>（这也是失败重试所需要的），所以理想情况下客户端应该使用多路复用器（如 linux epoll）在同一时间向 N 个 Redis 实例发送 <code>SET</code> 命令。</p><p>客户端需要在不能完全取锁时主动尽快地那些已经锁住的实例，基于此在重新获取该锁的时候就无需等待 key 过期才能获取。（但是如果出现了网络分区然后该客户端无法再与相应的 Redis 实例通信，就需要等待 key 过期）</p><h2 id="释放锁"><a class="header-anchor" href="#释放锁">¶</a>释放锁</h2><p>释放锁很简单，需要在所有的实例上释放锁，无论客户端是否认为它可以成功锁住某个实例。</p><h2 id="安全性讨论"><a class="header-anchor" href="#安全性讨论">¶</a>安全性讨论</h2><p>假设一个客户端锁住了大多数 redis 实例。所有实例都拥有一个具有相同 ttl 的 key。但是，这个key 是在不同时间被设置的，所以这些 key 会在不同时间过期。假设第一个 key 在时间 T1 （在设置第一个 redis 之前记录的时间戳）被设置，最后一个 key 在时间 T2 （取锁成功最后一个 redis 返回的时间）被设置，所以第一个 key 的最小有效时间 <code>MIN_VALIDITY = TTL - (T2 - T1) - CLOCK_DRIFFT</code> 。所有的其它 keys 都会在之后过期，所以可以确认的是，所有 keys 至少在这一时间到达之前都是被该客户端设置了的。</p><p>在大多数（N/2+1） keys 被设置期间，其它客户端就不能设置 <code>N/2+1</code> 个 keys。所以如果一个锁被申请了，就不可能被重复申请（破坏三要素的互斥性）。</p><p>下面要确认的是同时尝试获取锁的多个客户端不会同时成功。</p><p>如果一个客户端使用了接近于或者大于锁的最大有效时间（我们设置给 key 的 TTL），它将会认为这个锁是无效的然后释放锁，所以我们仅需考虑客户端取锁（N/2+1）时间小于该最大有效时间的情况。 In this case for the argument already expressed above, for <code>MIN_VALIDITY</code> no client should be able to re-acquire the lock. So multiple clients will be able to lock N/2+1 instances at the same time (with “time” being the end of Step 2) only when the time to lock the majority was greater than the TTL time, making the lock invalid.</p><h2 id="可用性讨论"><a class="header-anchor" href="#可用性讨论">¶</a>可用性讨论</h2><p>系统可用性基于三个主要的特性：</p><ol><li>锁的自动释放（基于 keys 的过期）：所有 keys 最终都可以被重新锁住。</li><li>客户端会在没有完全获取到锁或者获取到锁但是完成了业务的时候主动释放锁，而无需完全等待锁过期之后才能重新获取该锁。</li><li>当一个客户端重试取锁的时候，将会等待一个类似大于取锁所需时间的时间，降低锁竞争期间脑裂的可能性。</li></ol><p>另外上面提到如果一个客户端获取锁之后出现了网络分区，其它客户端就需要等待这个 key 的 TTL 之后才能申请到锁。</p><h2 id="性能、崩溃恢复和-fsync"><a class="header-anchor" href="#性能、崩溃恢复和-fsync">¶</a>性能、崩溃恢复和 fsync</h2><p>许多用户使用 Redis 作为一个高性能锁服务器，包括获取/释放锁需要的延迟、获取/释放锁的操作（可能需要一秒）数量。为了满足这一需求，肯定要使用多路复用器（或者&quot;低配版&quot;多路复用器，设置为实例创建的 socket 为非阻塞模式，然后一次性向所有 socket 发送所有命令，稍后再一起读取所有命令/假设客户端和每个实例之间的 RTT 近似的）来和 N 个 Redis 实例进行通信以减少延迟。</p><p>但是这里有另外一个需要考虑的点，如果我们想实现一个支持崩溃后恢复的系统，需要做持久化。假设 Redis 配置不做持久化。一个客户端在 5 个实例中的 3 个获取到了锁，然后其中一个锁住的实例发生了重启，此时对于这个锁又有了 3 个实例可以给其它客户端锁住了，破坏了锁互斥的安全性。</p><p>如果我们启用 AOF 持久化，将会稍微有所改进。例如在我们需要升级 Redis 的时候对其发送 <code>SHUTDOWN</code> 来重启它。因为 Redis 的过期是严格实现的，所以即使是 Redis 没有启动的时候过期时间也是在虚拟的流逝的（其实就是所有设置过期的方式都转换为给 key 设置一个死亡时间，每次读取 key 的时候都会比较该时间），此时是可以满足需求的。但是仅当 redis 的停止是&quot;干净&quot;的才会满足（redis 启动 AOF 之后会在 shutdown 的时候自动备份），如果是发生停电的情况下就不能满足了，默认情况下，redis 被配置为每秒 fsync 到磁盘，此时发生重启丢失 key 是有可能的。在理论上，如果我们需要在各种原因导致的 crash 下保证锁的安全性，需要启用 <code>fsync=always</code> 。这将会使得性能降低为和 CP 系统（安全的分布式锁的经典实现）一样。</p><p>不过这里还有另外一种方案。只要一个 crash 后重启的实例不再参与任何<strong>当前活跃的锁</strong>的获取就可以保持该算法的安全性，所以当一个实例发生重启后，当前所有活跃的锁都只能通过锁定除了重新加入集群的该实例之外的其它实例来获得。</p><p>为了实现上面提到的方案，我们仅需要使得一个 crash 的实例至少在大于所有锁的 key 中最大 TTL 的时间内不可达，这段时间需要用来等待所有在该实例 crash 的时候已经存在的锁的相关 keys 变成无效的并自动释放。</p><p>使用 <em>delayed restarts</em> 基本上就可以实现，无需配置 Redis 的任何持久化方案，但是需要注意的是这可能会付出一些可用性的代价。例如如果大多数的实例 crash 了，整个系统都会在 TTL 之内全局不可用（在这段时间内没有资源可以申请锁）</p><h2 id="使算法更可靠：延长锁时间"><a class="header-anchor" href="#使算法更可靠：延长锁时间">¶</a>使算法更可靠：延长锁时间</h2><p>如果客户端需要执行的工作由一些小的步骤组成，则默认情况下可以使用更小的时间作为锁的有效时间，然后扩展该算法以实现延长锁的有效时间的机制。当客户端在计算过程中发现锁的有效时间接近于一个很低的值的时候，可以通过发送一个 lua 脚本到所有的实例上延长 keys 的 TTL 来延长锁的时间，前提是锁依然存在并且它的值依然是该客户端之前申请该锁时设置的值。</p><p>客户端只有在它可以在大多数实例中都延长了锁的时间、并且在有效时间内的情况下才可以认为该锁被它继续占有（基本上这个算法和正常申请锁的算法很类似）。</p><p>However this does not technically change the algorithm, so the maximum number of lock reacquisition attempts should be limited, otherwise one of the liveness properties is violated.</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elastalert聚合告警</title>
      <link href="/2020/12/23/elastalert/elastalert-ju-he-gao-jing/"/>
      <url>/2020/12/23/elastalert/elastalert-ju-he-gao-jing/</url>
      
        <content type="html"><![CDATA[<h1>拉取代码及准备工作</h1><h2 id="代码拉取"><a class="header-anchor" href="#代码拉取">¶</a>代码拉取</h2><p>克隆代码到本地</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">git clone https://github.com/Yelp/elastalert.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>以下是代码目录：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">zhonghongpeng@bogon elastalert % tree ./ -L 1./├── Dockerfile-test├── LICENSE├── Makefile├── README.md├── build├── changelog.md├── config.yaml.example├── dist├── docker-compose.yml├── docs├── elastalert├── elastalert.egg-info├── example_rules├── mytest├── pytest.ini├── requirements-dev.txt├── requirements.txt├── setup.cfg├── setup.py├── supervisord.conf.example├── tests├── tox.ini└── venv<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="pycharm开发环境准备"><a class="header-anchor" href="#pycharm开发环境准备">¶</a>pycharm开发环境准备</h2><p>使用 pycharm 打开项目根目录：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201223153727.png" alt="image-20201223153727704"></p><h3 id="配置测试环境和venv"><a class="header-anchor" href="#配置测试环境和venv">¶</a>配置测试环境和venv</h3><h4 id="venv"><a class="header-anchor" href="#venv">¶</a>venv</h4><p>venv 可以用来在当前目录创建一个隔离的 python 运行环境，在使用 pycharm 导入项目的时候一般会弹出是否在根目录创建 venv，设置是即可. 来到以下 <code>Preferences</code> 界面确认路径是否正确（venv的基础Python版本以及venv环境路径）：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201223154238.png" alt="image-20201223154238353"></p><h4 id="测试框架选择"><a class="header-anchor" href="#测试框架选择">¶</a>测试框架选择</h4><p>还是 <code>Preferences</code> 窗口，配置 <code>requirements.txt</code> 和测试框架为 <code>pytest</code>（<code>requirements.txt</code>不是必要，下面将使用 <code>setup.py</code> 安装依赖）：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201223154047.png" alt="image-20201223154047862"></p><h4 id="安装依赖"><a class="header-anchor" href="#安装依赖">¶</a>安装依赖</h4><p>在根目录下 <code>setup.py</code> 文件的依赖数组最后增加 <code>pytest</code></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201223155006.png" alt="image-20201223155006145"></p><p>然后右击该文件：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201223190839.png" alt="image-20201223190839038"></p><p>添加 <code>install</code> 参数后运行安装即可：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201223190908.png" alt="image-20201223190908119"></p><p>安装完成后可以看到在 venv 中导入了以下脚本：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">zhonghongpeng@bogon elastalert % tree venv -L 4venv├── bin│   ├── __pycache__│   │   └── jp.cpython-37.pyc│   ├── activate│   ├── activate.csh│   ├── activate.fish│   ├── chardetect│   ├── easy_install│   ├── easy_install-3.7│   ├── easy_install-3.9│   ├── elastalert│   ├── elastalert-create-index│   ├── elastalert-rule-from-kibana│   ├── elastalert-test-rule│   ├── jirashell│   ├── jp.py│   ├── jsonschema│   ├── natsort│   ├── pbr│   ├── pip│   ├── pip3│   ├── pip3.7│   ├── py.test│   ├── pytest│   ├── python -> python3.7│   ├── python3 -> python3.7│   ├── python3.7 -> /usr/local/bin/python3.7│   └── stomp├── include├── lib│   └── python3.7│       └── site-packages│... ...│           ├── elastalert-0.2.4-py3.7.egg│... ...└── pyvenv.cfg119 directories, 44 files<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1>查看 metric_aggregation 代码结构</h1><h1>一些问题</h1><h2 id="Python-Import-问题"><a class="header-anchor" href="#Python-Import-问题">¶</a>Python Import 问题</h2><pre class="line-numbers language-language-shell"><code class="language-language-shell">Traceback (most recent call last):  File "/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py", line 1477, in _exec    pydev_imports.execfile(file, globals, locals)  # execute the script  File "/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile    exec(compile(contents+"\n", file, 'exec'), glob, loc)  File "/Users/zhonghongpeng/PycharmProjects/elastalert/elastalert/elastalert.py", line 29, in <module>    from . import kibanaImportError: cannot import name 'kibana' from '__main__' (/Users/zhonghongpeng/PycharmProjects/elastalert/elastalert/elastalert.py)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这是因为使用 python3 以及</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201223191220.png" alt="image-20201223191219999"></p><h2 id="ES-Python-库问题"><a class="header-anchor" href="#ES-Python-库问题">¶</a>ES Python 库问题</h2><pre class="line-numbers language-language-shell"><code class="language-language-shell">INFO:elastalert:Background alerts thread 0 pending alerts sent at 2020-12-23 18:32 CSTERROR:root:Traceback (most recent call last):  File "/Users/zhonghongpeng/PycharmProjects/elastalert/elastalert/elastalert.py", line 1271, in handle_rule_execution    num_matches = self.run_rule(rule, endtime, rule.get('initial_starttime'))  File "/Users/zhonghongpeng/PycharmProjects/elastalert/elastalert/elastalert.py", line 898, in run_rule    if not self.run_query(rule, tmp_endtime, endtime):  File "/Users/zhonghongpeng/PycharmProjects/elastalert/elastalert/elastalert.py", line 632, in run_query    data = self.get_hits_aggregation(rule, datetime.datetime.fromtimestamp(1236472051807 / 1000.0, tz=datetime.timezone.utc), end, index, rule.get('query_key', None))  File "/Users/zhonghongpeng/PycharmProjects/elastalert/elastalert/elastalert.py", line 566, in get_hits_aggregation    body=query, size=0, ignore_unavailable=True)  File "/Users/zhonghongpeng/PycharmProjects/elastalert/venv/lib/python3.7/site-packages/elasticsearch/client/utils.py", line 152, in _wrapped    return func(*args, params=params, headers=headers, **kwargs)TypeError: deprecated_search() got an unexpected keyword argument 'headers'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>具体抛出错误的代码是在 <code>elastalert/__init__.py</code> 的 566 行：</p><pre class="line-numbers language-language-python"><code class="language-language-python">                res = self.thread_data.current_es.deprecated_search(index=index, doc_type=rule.get('doc_type'),                                                                    body=query, size=0, ignore_unavailable=True)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>查看调用报错的方法 <code>deprecated_search</code>，上面用了一个装饰器 <code>@query_params</code>：</p><pre class="line-numbers language-language-python"><code class="language-language-python">    @query_params(        "_source",        "_source_exclude",        "_source_excludes",        "_source_include",        "_source_includes",        "allow_no_indices",        "allow_partial_search_results",        "analyze_wildcard",        "analyzer",        "batched_reduce_size",        "default_operator",        "df",        "docvalue_fields",        "expand_wildcards",        "explain",        "from_",        "ignore_unavailable",        "lenient",        "max_concurrent_shard_requests",        "pre_filter_shard_size",        "preference",        "q",        "rest_total_hits_as_int",        "request_cache",        "routing",        "scroll",        "search_type",        "seq_no_primary_term",        "size",        "sort",        "stats",        "stored_fields",        "suggest_field",        "suggest_mode",        "suggest_size",        "suggest_text",        "terminate_after",        "timeout",        "track_scores",        "track_total_hits",        "typed_keys",        "version",    )    def deprecated_search(self, index=None, doc_type=None, body=None, params=None):        if "from_" in params:            params["from"] = params.pop("from_")        if not index:            index = "_all"        res = self.transport.perform_request(            "GET", _make_path(index, doc_type, "_search"), params=params, body=body        )        if type(res) == list or type(res) == tuple:            return res[1]        return res<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>@query_params</code> 是 ES 提供的 Python 客户端库中提供的，主要功能是将传入参数构建成一个 URL query 参数，实现 <code>GET</code> 查询请求，而不使用 <code>POST</code>，当前报错的代码如下，可以看到 <code>_wrapped</code> 的 <code>return</code> 处的入参中传入了一个命名参数 <code>headers</code>，但是回顾上面被包装的 <code>deprecated_search</code> 中不存在 <code>headers</code> 命名参数</p><pre class="line-numbers language-language-python"><code class="language-language-python">def query_params(*es_query_params):    """    Decorator that pops all accepted parameters from method's kwargs and puts    them in the params argument.    """    def _wrapper(func):        @wraps(func)        def _wrapped(*args, **kwargs):            params = (kwargs.pop("params", None) or {}).copy()            headers = {                k.lower(): v                for k, v in (kwargs.pop("headers", None) or {}).copy().items()            }            if "opaque_id" in kwargs:                headers["x-opaque-id"] = kwargs.pop("opaque_id")            for p in es_query_params + GLOBAL_PARAMS:                if p in kwargs:                    v = kwargs.pop(p)                    if v is not None:                        params[p] = _escape(v)            # don't treat ignore, request_timeout, and opaque_id as other params to avoid escaping            for p in ("ignore", "request_timeout"):                if p in kwargs:                    params[p] = kwargs.pop(p)            return func(*args, params=params, headers=headers, **kwargs)        return _wrapped    return _wrapper<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>所以猜测应该是 ES Python 库的版本问题，查看 venv 中确实存在多个版本的 ES Python 库：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201223184233.png" alt="image-20201223184233434"></p><p>查看 7.0 版本的代码发现确实没有传入 <code>headers</code> 命名参数：</p><pre class="line-numbers language-language-python"><code class="language-language-python">def query_params(*es_query_params):    """    Decorator that pops all accepted parameters from method's kwargs and puts    them in the params argument.    """    def _wrapper(func):        @wraps(func)        def _wrapped(*args, **kwargs):            params = {}            if "params" in kwargs:                params = kwargs.pop("params").copy()            for p in es_query_params + GLOBAL_PARAMS:                if p in kwargs:                    v = kwargs.pop(p)                    if v is not None:                        params[p] = _escape(v)            # don't treat ignore and request_timeout as other params to avoid escaping            for p in ("ignore", "request_timeout"):                if p in kwargs:                    params[p] = kwargs.pop(p)            return func(*args, params=params, **kwargs)        return _wrapped    return _wrapper<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>直接将上面没有标明版本号的库从环境删除，即可正常运行。</p>]]></content>
      
      
      <categories>
          
          <category> elastalert </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ELK告警 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>02_规则类型和配置选项</title>
      <link href="/2020/12/22/elastalert/02-gui-ze-lei-xing-he-pei-zhi-xuan-xiang/"/>
      <url>/2020/12/22/elastalert/02-gui-ze-lei-xing-he-pei-zhi-xuan-xiang/</url>
      
        <content type="html"><![CDATA[<p>在源码目录下的 <code>example_rules</code> 文件夹中有几个不同类型的 <code>规则</code> 配置可以参考。</p><blockquote><p>注意：</p><p>所有的时间选项的格式都是 <code>&lt;单位&gt;:X</code> , 其中单位可以是 weeks, days, hours, minutes 或者 seconds. 例如 <code>minutes: 15</code> 或者 <code>hours: 1</code> .</p></blockquote><h2 id="规则配置列表"><a class="header-anchor" href="#规则配置列表">¶</a>规则配置列表</h2><h3 id="所有规则通用"><a class="header-anchor" href="#所有规则通用">¶</a>所有规则通用</h3><h4 id="必须"><a class="header-anchor" href="#必须">¶</a>必须</h4><h5 id="es-host-string-no-default"><a class="header-anchor" href="#es-host-string-no-default">¶</a><code>es_host</code>(string, no default)</h5><p><code>规则</code> 要轮询(监控)的 ES 集群 hostname</p><h5 id="es-port-number-no-default"><a class="header-anchor" href="#es-port-number-no-default">¶</a><code>es_port</code> (number, no default)</h5><p>ES 集群端口</p><h5 id="index-string-no-default"><a class="header-anchor" href="#index-string-no-default">¶</a><code>index</code> (string, no default)</h5><p>要查询的索引. 可以使用通配符, 例如: <code>index: my-index-*</code>. 还可以使用包含 <code>%Y</code>表示年、<code>%m</code>表示月、<code>%d</code>表示天的格式化字符串. 如果要使用这种格式化字符串, 需要将 <code>use_strftime_index</code> 设置为 true</p><h5 id="type-string-no-default"><a class="header-anchor" href="#type-string-no-default">¶</a><code>type</code> (string, no default)</h5><p>要使用的<code>规则类型</code>：<code>RuleType</code>（包含内置和自定义并导入的）. 对于导入模块的类型应该被声明为 <code>module.file.RuleName</code>.</p><h5 id="alert-string-or-list-no-defult"><a class="header-anchor" href="#alert-string-or-list-no-defult">¶</a><code>alert</code> (string or list, no defult)</h5><p>要使用的<code>告警器</code>：<code>Alerter</code>.同 <code>规则类型</code> 包含内置和自定义导入的. 导入的<code>告警器</code>应该被声明为 <code>module.file.AlertName</code>.</p><h5 id="filter-ES-filter-DSL-no-default"><a class="header-anchor" href="#filter-ES-filter-DSL-no-default">¶</a><code>filter</code> (ES filter DSL, no default)</h5><p>一个 ES 查询 DSL 的 filters 列表. ElastAlert 将会使用 <code>{'filter': {'bool': {'must': [config.filter]}}}</code> 的格式（and 操作）以及一个额外的 timestamp range filter 来查询 ES. 这些 filters 的查询出来的所有结果都会被传递到 <code>RuleType</code> 进行分析. 对于更多关于如何书写 filters, 后续有介绍, 或者参考<a href="https://elastalert.readthedocs.io/en/latest/recipes/writing_filters.html#writingfilters" target="_blank" rel="noopener">官网</a>.</p><h4 id="非必须"><a class="header-anchor" href="#非必须">¶</a>非必须</h4><h5 id="buffer-time-time-default-from-config-yaml"><a class="header-anchor" href="#buffer-time-time-default-from-config-yaml">¶</a><code>buffer_time</code> (time, default from config.yaml)</h5><p>在当前 <code>规则</code> 中覆盖全局 <code>config.yaml</code> 的值. 如果 <code>use_count_qeury</code>或者<code>use_terms_query</code> 为true, 该值会被忽略.</p><h5 id="realert-time-default-1-min"><a class="header-anchor" href="#realert-time-default-1-min">¶</a><code>realert</code> (time, default: 1 min)</h5><p>这个选项允许你在一段时间内忽略重复告警. 如果<code>规则</code>设置了<code>query_key</code>字段, 这个选项将会基于每一个 key 起作用.</p><ul><li>对于给定 <code>规则</code> 的所有<code>匹配</code>、或者说在<code>query_key</code>上拥有同一个值的<code>匹配</code>将会在给定时间段被忽略.</li><li>所有 <code>query_key</code> 字段没有值的<code>匹配</code>都会被分到一个值设为<code>_missing</code> 的组.</li></ul><p>忽略时间是从一个<code>告警</code>发出的时间点开始算的, 而不是触发事件的时间.</p><p>默认值是 1 分钟, 这意味着 ElastAlert 如果运行了很长一段时间且触发了很多<code>规则</code>，只有第一个<code>告警</code>会被发出. 如果想每一条都发出, 需要设置 <code>realert</code> 为 0.</p><h5 id="exponential-realert-optional-time-no-default"><a class="header-anchor" href="#exponential-realert-optional-time-no-default">¶</a><code>exponential_realert</code> (optional, time, no default)</h5><p>使得 <code>alert</code> 成指数级增长直到 <code>exponential_realert</code> : 如果触发<code>匹配</code> 的时间距离上一次触发小于当前 <code>alert</code> 的两倍, 那么 <code>alert</code> 会翻倍.</p><h6 id="示例"><a class="header-anchor" href="#示例">¶</a>示例</h6><p>举个例子</p><ul><li><code>realert</code> 设置为 <code>minutes: 10</code>, <code>exponential_realert</code> 设置为 <code>hours: 1</code></li><li>一个<code>告警</code>在 1:00 的时候触发, 另一个在 1:15, 则下一个<code>告警</code>至少要是 1:35 之后才能触发.</li><li>如果在 1:35 到 2:15 之间触发了一个 <code>告警</code>, <code>realert</code> 将增长到 1 个小时（最大值）.</li><li>之后如果超过 2 个小时也没有触发 <code>告警</code>, <code>realert</code> 就会恢复.</li></ul><blockquote><p>注意那些被忽略的<code>告警</code>不会对<code>realert</code>产生影响（例如在 1:05 的时候）</p></blockquote><h5 id="name-string-defaults-to-the-filename"><a class="header-anchor" href="#name-string-defaults-to-the-filename">¶</a><code>name</code> (string, defaults to the filename)</h5><h5 id="use-strftime-index-boolean-default-False"><a class="header-anchor" href="#use-strftime-index-boolean-default-False">¶</a><code>use_strftime_index</code> (boolean, default False)</h5><p>如果设置为 true, ElastAlert 将会在每一次对于 ES 的查询中使用 <code>datetime.strftime</code> 来对索引进行格式化. 参考 <a href="https://docs.python.org/2/library/datetime.html#strftime-strptime-behavior" target="_blank" rel="noopener">strftime</a> 获取更多信息. 如果一个查询贯穿了好几天, 格式化之后的索引将会被用逗号拼接(其实就是使用 python 提供的字符串格式化 api 用一个格式匹配我们的想要的日期). 这对于缩小查询索引的范围是很有用的, 相对于通配符索引, 应该会有显著的提速.</p><h5 id="owner-string-default-empty-string"><a class="header-anchor" href="#owner-string-default-empty-string">¶</a><code>owner</code> (string, default empty string)</h5><p>这个值可以被用来标识<code>告警</code>的持有者. 可选的, 这个字段可以被包含在任何<code>告警</code>类型中</p><h5 id="priority-int-default-2"><a class="header-anchor" href="#priority-int-default-2">¶</a><code>priority</code> (int, default 2)</h5><p>该值被用来标识<code>告警</code>的相关优先级/重要程度. 可选的, 这个字段可以被包含在任意 <code>告警 </code>类型中（例如使用在 email 的主题或者正文文本中）.</p><p><code>category</code> (string, default empty string)</p><p>该值被用来标识<code>告警</code>的分组. 可选的, 这个字段可以被包含在任意 <code>告警 </code>类型中（例如使用在 email 的主题或者正文文本中）.</p><h5 id="query-delay-time-default-0-min"><a class="header-anchor" href="#query-delay-time-default-0-min">¶</a><code>query_delay</code> (time, default 0 min)</h5><p>这个选项将会使得 ElastAlert 减掉一个时间量, 让<code>规则</code>延迟运行. 这对于那些 ES 不是实时索引的数据是有用的.</p><h5 id="use-ssl-boolean-default-False"><a class="header-anchor" href="#use-ssl-boolean-default-False">¶</a><code>use_ssl</code> (boolean, default False)</h5><p>是否使用 TLS 连接 ES. 环境变量 <code>ES_USE_SSL</code> 会覆盖这个字段</p><h5 id="verify-certs-boolean-default-True"><a class="header-anchor" href="#verify-certs-boolean-default-True">¶</a><code>verify_certs</code> (boolean, default True)</h5><p>是否进行 TLS 证书验证 ES 连接</p><h5 id="client-cert-string-no-default"><a class="header-anchor" href="#client-cert-string-no-default">¶</a><code>client_cert</code>(string, no default)</h5><p>客户端 PEM 证书</p><h5 id="client-key-string-no-default"><a class="header-anchor" href="#client-key-string-no-default">¶</a><code>client_key</code>(string, no default)</h5><p>客户端私钥文件</p><h5 id="es-username-string-no-default"><a class="header-anchor" href="#es-username-string-no-default">¶</a><code>es_username</code> (string, no default)</h5><p>ES 登录用户名. 环境变量 <code>ES_USERNAME</code> 会覆盖这个字段</p><h5 id="es-password-string-no-default"><a class="header-anchor" href="#es-password-string-no-default">¶</a><code>es_password</code> (string, no default)</h5><p>ES 登录用户密码. 环境变量 <code>ES_PASSWORD</code> 会覆盖这个字段</p><h5 id="es-url-prefix-string-no-default"><a class="header-anchor" href="#es-url-prefix-string-no-default">¶</a><code>es_url_prefix</code> (string, no default)</h5><p>ES 端点的 URL 前缀</p><h5 id="es-send-get-body-as-string-default-“GET”"><a class="header-anchor" href="#es-send-get-body-as-string-default-“GET”">¶</a><code>es_send_get_body_as</code> (string, default “GET”)</h5><p>查询 ES 时使用的 HTTP 方法</p><h5 id="aggregation-time-no-default"><a class="header-anchor" href="#aggregation-time-no-default">¶</a><code>aggregation</code> (time, no default)</h5><p>这个选项允许你将多个<code>匹配</code>聚合到一个<code>告警</code>中. 每当一个<code>匹配</code>发生, ElastAlert就会等待一个 <code>aggregation</code> 的周期, 然后在周期时间到达后, 发送所有在该周期内出现的的 <code>匹配</code>  到<code>告警器</code>.</p><h6 id="示例-v2"><a class="header-anchor" href="#示例-v2">¶</a>示例</h6><pre class="line-numbers language-language-yaml"><code class="language-language-yaml">aggregation:  hours: 2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>12点整有一个告警, 13点整又有一个, 第三个是在14点半, 一个告警将会在14点发出, 因为12点整出现了第一个 <code>匹配</code>, 需要等待2个小时, 将这2个小时之内的所有<code>匹配</code>在14点整聚合成一个<code>告警</code>发出. 因为14点整之后的第一个<code>匹配</code>是在14点半, 所以又要等2个小时, 在16点半的时候将这两个小时内的所有<code>匹配</code>整合成一个<code>告警</code>发出.</p><h6 id="固定告警时间"><a class="header-anchor" href="#固定告警时间">¶</a>固定告警时间</h6><p>如果你希望在一个递推的时间间隔中聚合所有<code>告警</code>再发送, 你可以使用<code>schedule</code> 字段. 举个例子, 如果你希望在每个周一和周五接收<code>告警</code>:</p><pre class="line-numbers language-language-yaml"><code class="language-language-yaml">aggregation:  schedule: '2 4 * * mon,fri'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这里使用了 <a href="http://www.nncron.ru/help/EN/working/cron-format.htm" target="_blank" rel="noopener">Cron</a> 语法. 注意不可以同时设置 <code>schedule</code> 和标准时间字段(<code>hours</code>、<code>minutes</code>、<code>days</code>), 只能选择其一.</p><h6 id="对匹配进行分组"><a class="header-anchor" href="#对匹配进行分组">¶</a>对<code>匹配</code>进行分组</h6><p>默认情况下, 所有在一个聚合窗口中的事件(<code>匹配</code>)会分在一组内. 不过, 如果你的规则定义了 <code>aggregation_key</code> 字段, 然后所有该字段拥有同一个值的事件都会被分为一组. 每当在该 key 上遇到一个新值的时候就会创建一个隔离的聚合窗口.</p><p>举个例子, 如果你希望接收以触发<code>匹配</code>事件的用户为分组的<code>告警</code>, 你可以这样设置:</p><pre class="line-numbers language-language-yaml"><code class="language-language-yaml">aggregation_key: 'my_data.username'<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>假设有一个 10 分钟的聚合窗口, 如果接收到以下数据:</p><pre class="line-numbers language-language-json"><code class="language-language-json">{'my_data': {'username': 'alice', 'event_type': 'login'}, '@timestamp': '2016-09-20T00:00:00'}{'my_data': {'username': 'bob', 'event_type': 'something'}, '@timestamp': '2016-09-20T00:05:00'}{'my_data': {'username': 'alice', 'event_type': 'something else'}, '@timestamp': '2016-09-20T00:06:00'}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>这将会生成 2 个<code>告警</code>: 一个包含 alice 的两个 <code>匹配</code> 事件, 在 <code>2016-09-20T00:10:00</code> 发送; 另一个包含 bob 的一个事件, 将会在 <code>2016-09-20T00:16:00</code> 发送.</p><h6 id="概要信息"><a class="header-anchor" href="#概要信息">¶</a>概要信息</h6><p>对于聚合告警来说, 有时候会在那些展示媒介（email, jira ticket等）上出现较大数量的文档(例如某个分组下出现了很多500错误). 如果你设置了 <code>summary_table_fields</code> 字段, ElastAlert 会从所有查询到的文档中针对该字段提供一个概要信息.</p><p>举个例子, 如果你希望对那些 <code>匹配</code> 了 <code>规则</code> 的文档的 <code>username</code> 和 <code>event_type</code> 做一个概述以便你可以很方便地得到最有相关/有价值的字段的信息, 你可以如下设置:</p><pre class="line-numbers language-language-yaml"><code class="language-language-yaml">summary_table_fields:    - my_data.username    - my_data.event_type<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>基于上面的 alice 和 bob 的数据, ElastAlert 会在告警媒介中提供如下概要表格:</p><pre class="line-numbers language-language-asciiarmor"><code class="language-language-asciiarmor">+------------------+--------------------+| my_data.username | my_data.event_type |+------------------+--------------------+|      alice       |       login        ||       bob        |     something      ||      alice       |   something else   |+------------------+--------------------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h6 id="注意"><a class="header-anchor" href="#注意">¶</a>注意</h6><p>默认的聚合时间是基于当前的系统时间, 而不是<code>匹配</code>的时间（例如第一条<code>匹配</code>出现后, 取当前系统时间戳作为时间窗口的起始值, 而不是取查询中的时间戳）. This means that running elastalert over past events will result in different alerts than if elastalert had been running while those events occured. This behavior can be changed by setting <code>aggregate_by_match_time</code>.</p><h5 id="aggregate-by-match-time"><a class="header-anchor" href="#aggregate-by-match-time">¶</a><code>aggregate_by_match_time</code></h5><p>Setting this to true will cause aggregations to be created relative to the timestamp of the first event, rather than the current time. This is useful for querying over historic data or if using a very large buffer_time and you want multiple aggregations to occur from a single query.</p><h5 id="max-query-size-int-default-global-max-query-size"><a class="header-anchor" href="#max-query-size-int-default-global-max-query-size">¶</a><code>max_query_size</code> (int, default global max_query_size)</h5><p>和全局 <code>max_query_size</code> 意义一样, 会覆盖全局的.</p><h5 id="include-list-of-string-default-“-”-all-fields"><a class="header-anchor" href="#include-list-of-string-default-“-”-all-fields">¶</a><code>include</code> (list of string, default [“*”] / all fields)</h5><p>查询结果应该返回的字段. 设置之后, 只有设置的字段以及 <a href="mailto:'%40timestamp" target="_blank" rel="noopener">‘@timestamp</a>’, <code>query_key</code>, <code>compare_key</code>, and <code>top_count_keys</code> 会返回.</p><h5 id="description-string-default-empty-string"><a class="header-anchor" href="#description-string-default-empty-string">¶</a><code>description</code> (string, default empty string)</h5><p>对于 <code>规则</code> 的描述. 可以在自定义<code>告警器</code>中引用到这个值, 提供一个 <code>规则</code> 触发原因的上下文.</p><h5 id="generate-kibana-link-boolean-default-False"><a class="header-anchor" href="#generate-kibana-link-boolean-default-False">¶</a><code>generate_kibana_link</code> (boolean, default False)</h5><p>这个选项只对 Kibana3 有效. 如果设置为 true, ElastAlert 将会在 <code>告警</code> 中生成一个临时的 Kibana 面板以及一个链接. 这个面板由一个基于时间变化的事件图标以及一个包含了 <code>include</code> 中字段的表格. 如果当前 <code>规则</code> 设置了 <code>query_key</code>, 这个面板也会包含一个关于该<code>告警</code>的该 <code>query_key</code> 的 filter. 该面板 schema 将会被上传到 kibana-int 的索引作为一个临时面板.</p><h5 id="kibana-url-string-default-from-http-es-host-es-port-plugin-kibana"><a class="header-anchor" href="#kibana-url-string-default-from-http-es-host-es-port-plugin-kibana">¶</a><code>kibana_url</code> (string, default from <code>http://&lt;es_host&gt;:&lt;es_port&gt;/_plugin/kibana/</code>)</h5><p>访问 Kibana 的 url. 这在 <code>generate_kibana_link</code> 或者 <code>use_kibana_dashboard</code> 为 true 的时候使用. 如果没有定义, 将会使用 <code>es_host</code> 以及 <code>es_port</code> 拼接成一个 URL.</p><h5 id="use-kibana-dashboard-string-no-default"><a class="header-anchor" href="#use-kibana-dashboard-string-no-default">¶</a><code>use_kibana_dashboard</code> (string, no default)</h5><p>Kibana3 面板的名称. 不像 <code>generate_kibana_link</code> 那样从一个模板生成一个面板, ElastAlert 可以复用一个已存在的面板. 它会在面板上根据<code>匹配</code> 的时间将该时间范围设置到面板, 将其上传为一个临时面板, 并添加一个 filter 到 <code>告警</code> 的 <code>query_key</code> 字段上（如果有的话）, 然后将 url 放到 <code>告警</code>里面.</p><h5 id="use-kibana4-dashboard-string-no-default"><a class="header-anchor" href="#use-kibana4-dashboard-string-no-default">¶</a><code>use_kibana4_dashboard</code> (string, no default)</h5><p>一个 Kibana4 面板的链接. 例如, “<a href="https://kibana.example.com/#/dashboard/My-Dashboard%E2%80%9D" target="_blank" rel="noopener">https://kibana.example.com/#/dashboard/My-Dashboard”</a>. This will set the time setting on the dashboard from the match time minus the timeframe, to 10 minutes after the match time. Note that this does not support filtering by <code>query_key</code> like Kibana 3. This value can use $VAR and ${VAR} references to expand environment variables.</p><h5 id="kibana4-start-timedelta-time-default-10-min"><a class="header-anchor" href="#kibana4-start-timedelta-time-default-10-min">¶</a><code>kibana4_start_timedelta</code> (time, default: 10 min)</h5><h5 id="kibana4-end-timedelta-time-default-10-min"><a class="header-anchor" href="#kibana4-end-timedelta-time-default-10-min">¶</a><code>kibana4_end_timedelta</code> (time, default: 10 min)</h5><h5 id="use-local-time-boolean-default-True"><a class="header-anchor" href="#use-local-time-boolean-default-True">¶</a><code>use_local_time</code> (boolean, default True)</h5><h5 id="match-enhancements-list-of-strs-no-default"><a class="header-anchor" href="#match-enhancements-list-of-strs-no-default">¶</a><code>match_enhancements</code> (list of strs, no default)</h5><h5 id="top-count-keys-list-of-strings"><a class="header-anchor" href="#top-count-keys-list-of-strings">¶</a><code>top_count_keys</code> (list of strings)</h5><p>一个包含多个字段的集合. ElastAlert 会在这些字段上使用 term query 查询 X 个最常见的值, X 默认值是 5, 或者 <code>top_count_number</code>（如果该选项被存在）. For example, if <code>num_events</code> is 100, and <code>top_count_keys</code> is <code>- &quot;username&quot;</code>, the alert will say how many of the 100 events have each username, for the top 5 usernames. When this is computed, the time range used is from <code>timeframe</code> before the most recent event to 10 minutes past the most recent event. Because ElastAlert uses an aggregation query to compute this, it will attempt to use the field name plus “.raw” to count unanalyzed terms. To turn this off, set <code>raw_count_keys</code> to false.</p><h5 id="top-count-number-int-default-5"><a class="header-anchor" href="#top-count-number-int-default-5">¶</a><code>top_count_number</code> (int, default 5)</h5><p>如果 <code>top_count_keys</code> 设置, 该选项为 term query 中每个 terms 的数量.</p><h5 id="raw-count-keys-boolean-default-True"><a class="header-anchor" href="#raw-count-keys-boolean-default-True">¶</a><code>raw_count_keys</code> (boolean, default True)</h5><p>如果设置为 true, 所有在 <code>top_count_keys</code> 中定义的字段都会拼接一个 <code>.raw</code> 后缀.（一个 keyword 类型的子字段, 高版本的 ES 后缀为 <code>.keyword</code>）</p><h5 id="scan-entire-timeframe-bool-default-False"><a class="header-anchor" href="#scan-entire-timeframe-bool-default-False">¶</a><code>scan_entire_timeframe</code> (bool, default False)</h5><h5 id="import-string-no-default-IGNORED-IF-use-count-query-or-use-terms-query-is-true"><a class="header-anchor" href="#import-string-no-default-IGNORED-IF-use-count-query-or-use-terms-query-is-true">¶</a><code>import</code> (string no default) IGNORED IF <code>use_count_query</code> or <code>use_terms_query</code> is true</h5><p>将所有设置导入到当前 yaml 文件中. 这允许通用配置选项被共享. 注意导入的文件如果不包含完整的<code>规则</code>配置就应该以<code>.yml</code>或者<code>.yaml</code>为后缀, 这样 ElastAlert 才不会加载它们并报错. 在被导入的文件中的 Filters 将会在当前<code>规则</code>中被合并成一个 <code>Any Filters</code> . 在一个<code>规则</code>配置文件中只能有一个 <code>import</code>, 不过被 import 的文件又可以 import 其它的文件. 导入的文件名称可以是绝对路径和相对于<code>规则路径</code>.</p><h5 id="timestamp-type-string-default-iso"><a class="header-anchor" href="#timestamp-type-string-default-iso">¶</a><code>timestamp_type</code> (string, default iso)</h5><h5 id="timestamp-format-string-default-“-Y-m-dT-H-M-SZ”"><a class="header-anchor" href="#timestamp-format-string-default-“-Y-m-dT-H-M-SZ”">¶</a><code>timestamp_format</code> (string, default “%Y-%m-%dT%H:%M:%SZ”)</h5><h5 id="timestamp-format-expr-string-no-default"><a class="header-anchor" href="#timestamp-format-expr-string-no-default">¶</a><code>timestamp_format_expr</code> (string, no default )</h5><h5 id="source-enabled-boolean-default-True"><a class="header-anchor" href="#source-enabled-boolean-default-True">¶</a><code>_source_enabled</code> (boolean, default True)</h5><h5 id="alert-text-args-array-of-strs"><a class="header-anchor" href="#alert-text-args-array-of-strs">¶</a><code>alert_text_args</code> (array of strs)</h5><h5 id="alert-text-kw-object"><a class="header-anchor" href="#alert-text-kw-object">¶</a><code>alert_text_kw</code> (object)</h5><h5 id="alert-missing-value-string-default-“-MISSING-VALUE-”"><a class="header-anchor" href="#alert-missing-value-string-default-“-MISSING-VALUE-”">¶</a><code>alert_missing_value</code> (string, default “<missing value>”)</missing></h5><h5 id="is-enabled-boolean-default-True"><a class="header-anchor" href="#is-enabled-boolean-default-True">¶</a><code>is_enabled</code> (boolean, default True)</h5><h5 id="search-extra-index-boolean-default-False"><a class="header-anchor" href="#search-extra-index-boolean-default-False">¶</a><code>search_extra_index</code> (boolean, default False)</h5><p>If this is true, ElastAlert will add an extra index on the early side onto each search. For example, if it’s querying completely within 2018-06-28, it will actually use 2018-06-27,2018-06-28. This can be useful if your timestamp_field is not what’s being used to generate the index names. If that’s the case, sometimes a query would not have been using the right index.</p><table><thead><tr><th>RULE TYPE</th><th>Any</th><th>Blacklist</th><th>Whitelist</th><th>Change</th><th>Frequency</th><th>Spike</th><th>Flatline</th><th>New_term</th><th>Cardinality</th></tr></thead><tbody><tr><td><code>compare_key</code> (list of strs, no default)</td><td></td><td>Req</td><td>Req</td><td>Req</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><code>blacklist</code> (list of strs, no default)</td><td></td><td>Req</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><code>whitelist</code> (list of strs, no default)</td><td></td><td></td><td>Req</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><code>ignore_null</code> (boolean, no default)</td><td></td><td></td><td>Req</td><td>Req</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><code>query_key</code> (string, no default)</td><td>Opt</td><td></td><td></td><td>Req</td><td>Opt</td><td>Opt</td><td>Opt</td><td>Req</td><td>Opt</td></tr><tr><td><code>aggregation_key</code> (string, no default)</td><td>Opt</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><code>summary_table_fields</code> (list, no default)</td><td>Opt</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><code>timeframe</code> (time, no default)</td><td></td><td></td><td></td><td>Opt</td><td>Req</td><td>Req</td><td>Req</td><td></td><td>Req</td></tr><tr><td><code>num_events</code> (int, no default)</td><td></td><td></td><td></td><td></td><td>Req</td><td></td><td></td><td></td><td></td></tr><tr><td><code>attach_related</code> (boolean, no default)</td><td></td><td></td><td></td><td></td><td>Opt</td><td></td><td></td><td></td><td></td></tr><tr><td><code>use_count_query</code> (boolean, no default)<code>doc_type</code> (string, no default)</td><td></td><td></td><td></td><td></td><td>Opt</td><td>Opt</td><td>Opt</td><td></td><td></td></tr><tr><td><code>use_terms_query</code> (boolean, no default)<br><code>doc_type</code> (string, no default)<br><code>query_key</code> (string, no default)<br><code>terms_size</code> (int, default 50)</td><td></td><td></td><td></td><td></td><td>Opt</td><td>Opt</td><td></td><td>Opt</td><td></td></tr><tr><td><code>spike_height</code> (int, no default)</td><td></td><td></td><td></td><td></td><td></td><td>Req</td><td></td><td></td><td></td></tr><tr><td><code>spike_type</code> ([up|down|both], no default)</td><td></td><td></td><td></td><td></td><td></td><td>Req</td><td></td><td></td><td></td></tr><tr><td><code>alert_on_new_data</code> (boolean, default False)</td><td></td><td></td><td></td><td></td><td></td><td>Opt</td><td></td><td></td><td></td></tr><tr><td><code>threshold_ref</code> (int, no default)</td><td></td><td></td><td></td><td></td><td></td><td>Opt</td><td></td><td></td><td></td></tr><tr><td><code>threshold_cur</code> (int, no default)</td><td></td><td></td><td></td><td></td><td></td><td>Opt</td><td></td><td></td><td></td></tr><tr><td><code>threshold</code> (int, no default)</td><td></td><td></td><td></td><td></td><td></td><td></td><td>Req</td><td></td><td></td></tr><tr><td><code>fields</code> (string or list, no default)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Req</td><td></td></tr><tr><td><code>terms_window_size</code> (time, default 30 days)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Opt</td><td></td></tr><tr><td><code>window_step_size</code> (time, default 1 day)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Opt</td><td></td></tr><tr><td><code>alert_on_missing_fields</code> (boolean, default False)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Opt</td><td></td></tr><tr><td><code>cardinality_field</code> (string, no default)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Req</td></tr><tr><td><code>max_cardinality</code> (boolean, no default)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Opt</td></tr><tr><td><code>min_cardinality</code> (boolean, no default)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Opt</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> elastalert </category>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
            <tag> ELK告警 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>01_首次运行elastalert</title>
      <link href="/2020/12/22/elastalert/01-shou-ci-yun-xing-elastalert/"/>
      <url>/2020/12/22/elastalert/01-shou-ci-yun-xing-elastalert/</url>
      
        <content type="html"><![CDATA[<h2 id="依赖"><a class="header-anchor" href="#依赖">¶</a>依赖</h2><ul><li>Elasticsearch</li><li>ISO8601 or Unix timestamped data</li><li>Python 3.6</li><li>pip, see requirements.txt</li><li>Packages on Ubuntu 14.x: python-pip python-dev libffi-dev libssl-dev</li></ul><blockquote><ul><li><p>ElastAlert 在 0.2.0 相较于 0.1.x 版本升级到了 Python3，且 requirements.txt 文件中强制依赖 elasticsearch 7 。</p></li><li><p>在 <a href="https://github.com/Yelp/elastalert/blob/master/changelog.md" target="_blank" rel="noopener">changlog</a> 中截止到当前最新的 0.2.4 版本没有增加很多特性。不过经测试即使本地安装的 elasticsearch python 客户端模块不是 7.x 也是可以兼容查询的。</p></li><li><p>需要注意的是无论任何版本 ElastAlert 不支持 <code>doc_type</code> 字段查询</p></li></ul></blockquote><h2 id="下载与配置"><a class="header-anchor" href="#下载与配置">¶</a>下载与配置</h2><h3 id="pip安装"><a class="header-anchor" href="#pip安装">¶</a>pip安装</h3><p>你可以通过 pip 安装最新的 released 版本的 ElastAlert :</p><pre><code>$ pip3 install elastalert</code></pre><h3 id="源代码安装"><a class="header-anchor" href="#源代码安装">¶</a>源代码安装</h3><p>这里安装官方文档的源代码安装进行实操</p><blockquote><p>请注意你的环境是否携带了多版本的 Python 环境，<code>pip</code> 指向的是不是正确版本的 python，例如要运行的 ElastAlert 是0.2.x 版本的，需要 Python 是 3.x 及其对应的 <code>pip</code> 包管理器</p></blockquote><p>或者从仓库克隆当前的最新代码:</p><pre><code>$ git clone https://github.com/Yelp/elastalert.git</code></pre><p>然后通过 setuptools 工具运行官方提供的 <code>setup.py</code> 进行安装:</p><pre><code>$ pip3 install &quot;setuptools&gt;=11.3&quot;$ python3 setup.py install</code></pre><p>取决于 Elasticsearch 的版本, 你可能需要手安装正确版本的 elasticsearch-py (ES 官方提供的 Python 客户端)(虽然 requirements.txt 里面写死了版本是 7).</p><p>Elasticsearch 5.0+:</p><pre><code>$ pip3 install &quot;elasticsearch&gt;=5.0.0&quot;</code></pre><p>Elasticsearch 2.X:</p><pre><code>$ pip3 install &quot;elasticsearch&lt;3.0.0&quot;</code></pre><h3 id="配置"><a class="header-anchor" href="#配置">¶</a>配置</h3><p>下一步，打开 <code>config.yaml</code> 示例文件。你会在文件中看到几个配置选项。</p><pre class="line-numbers language-language-yaml"><code class="language-language-yaml"># ElastAlert 加载规则文件的路径，如果里面没有任何有效规则配置文件，ElastAlert 将不能启动，同时 ElastAlert# 会监视这个路径进行热重载，这里使用 example_rules 相对路径文件夹名称rules_folder: example_rules# ElastAlert 轮询 ES 间隔，覆盖全局 config.yaml 配置文件# 单位从 weeks 到 secondsrun_every:  minutes: 1# 对 ES 的查询窗口，覆盖全局 config.yaml 配置文件，use_count_query和use_terms_query被设置的时候无效buffer_time:  minutes: 15# ES 集群地址，会写入一些轮询、告警、错误元信息es_host: elasticsearch.example.com# ES 集群端口es_port: 9200# 上面提到的 ElastAlert 写入信息的索引名称，使用 elastalert-create-index 创建 mappingwriteback_index: elastalert_status# 告警失败后的重试窗口alert_time_limit:  days: 2# 其它非必要参数已删除<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="配置-ES"><a class="header-anchor" href="#配置-ES">¶</a>配置 ES</h2><p>ElastAlert 会将它的 ES 查询和告警的信息和元数据回写到 ES 中。这对于审计、调试是很有用的，同时它允许 ElastAlert 在重启后准确地恢复到停止之前的状态。这对于 ElastAlert 的运行来说不是必要的，不过是强烈建议的。</p><p>第一步，我们需要通过运行 <code>elastalert-create-index</code> 命令来为 ElastAlert 创建索引：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z elastalert]# elastalert-create-indexElastic Version: 7.1.0Reading Elastic 6 index mappings:Reading index mapping 'es_mappings/6/silence.json'Reading index mapping 'es_mappings/6/elastalert_status.json'Reading index mapping 'es_mappings/6/elastalert.json'Reading index mapping 'es_mappings/6/past_elastalert.json'Reading index mapping 'es_mappings/6/elastalert_error.json'New index elastalert_status createdDone!<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>创建了以下索引</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222121751.png" alt="image-20201222121751045"></p><h2 id="创建一个规则"><a class="header-anchor" href="#创建一个规则">¶</a>创建一个规则</h2><p>每个 <code>规则</code> 配置文件中定义了一个要执行的查询, 触发<code>匹配</code>的参数, 以及一个当<code>匹配</code>发生的时候会被激活的<code>告警器</code>列表. 下面使用 <code>example_rules/example_frequency.yaml</code> 作为一个模板:</p><pre class="line-numbers language-language-yaml"><code class="language-language-yaml"># From example_rules/example_frequency.yaml# 要轮询的 es 地址和端口es_host: elasticsearch.example.comes_port: 9200# 唯一的规则名称，如果发生重名 ElastAlert 将无法启动name: Example rule# 每个规则都会有一个类型，不同的类型会有不同的参数设置# frequence 类型表示在 timeframe 之内超过 num_events 数量的时候进行告警type: frequency# 查询的 ES 索引(ES 查询天然支持通配符)。如果你使用 Logstash，可以使用如下配置index: logstash-*num_events: 50timeframe:    hours: 4# filter 是一个 ES filter 查询集合。如果没有想要设置的 filter，应该被设置为一个空 list，如 filter: []filter:- term:    some_field: "some_value"# alert 是一个告警器列表。email alert 需要一个 SMTP 服务器来发送邮件。默认它会尝试连接 localhost，使用 smtp_host 进行修改# 暂时没有看到修改 smtp 服务端口的选项，qq 端口是 465alert:- "email"# email 是一个告警器发送告警邮件的地址列表email:- "707845008@qq.com"smtp_host: smtp.qq.com# 修改查询时间格式为 unix 毫秒时间戳。一定要注意看你的 ES 里面的时间戳字段是什么类型的，否则将无法匹配# 这里考虑到是测试和可读性，使用默认的 ISO8601 时间戳# timestamp_type: unix_ms<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>重要：</p><ul><li><p>**所有日志文档必须拥有一个 timestamp 字段(一直提到的轮询窗口就是基于这个字段做的 range query). ElastAlert 默认使用 <code>@timestamp</code> , 可以通过 <code>timestamp_field</code> 选项改变. **</p></li><li><p><strong>默认情况下 ElastAlert 使用 ISO8601 时间戳,  unix 时间戳可以通过 <code>timestamp_type</code> 修改(当然也可以修改为其它，具体的参考配置列表章节).</strong></p></li></ul></blockquote><p>最终这个<code>规则</code>表示 “当在 4 小时内出现 50 个文档的 some_field 字段值为 some_value 的时候发送一个邮件到 <a href="mailto:707845008@qq.com" target="_blank" rel="noopener">707845008@qq.com</a>&quot;.</p><h2 id="检测你的规则配置"><a class="header-anchor" href="#检测你的规则配置">¶</a>检测你的规则配置</h2><p>运行 <code>elastalert-test-rule</code> 工具将会检测你的配置文件是否可以成功加载:</p><pre><code>$ elastalert-test-rule example_rules/example_frequency.yaml</code></pre><p>如果你想定义一个要使用的配置文件，可以使用 config 选项:</p><pre><code>$ elastalert-test-rule --config &lt;path-to-config-file&gt; example_rules/example_frequency.yaml</code></pre><p>配置选项加载顺序如下：</p><ol><li>在规则 yaml 文件中加载</li><li>在 config 文件中加载(如果指定)</li><li>使用内省设置</li></ol><h2 id="运行-ElastAlert"><a class="header-anchor" href="#运行-ElastAlert">¶</a>运行 ElastAlert</h2><p>有两种方式可以运行 ElastAlert. 通过 Supervisor (<a href="http://supervisord.org/" target="_blank" rel="noopener">http://supervisord.org/</a>) 作为一个守护进程, 或者直接由 Python 运行. 在这里为了调试建议, 直接使用 python 直接:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ python -m elastalert.elastalert --verbose --rule example_frequency.yaml  # or use the entry point: elastalert --verbose --rule ...No handlers could be found for logger "Elasticsearch"INFO:root:Queried rule Example rule from 1-15 14:22 PST to 1-15 15:07 PST: 5 hitsINFO:Elasticsearch:POST http://elasticsearch.example.com:14900/elastalert_status/elastalert_status?op_type=create [status:201 request:0.025s]INFO:root:Ran Example rule from 1-15 14:22 PST to 1-15 15:07 PST: 5 query hits (0 already seen), 0 matches, 0 alerts sentINFO:root:Sleeping for 297 seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ElastAlert 使用了 python 的日志系统, <code>--verbose</code> 设置显示 INFO 级别信息. <code>--rule example_frequency.yaml</code> 指定要执行的日志, 否则 ElastAlert 将会加载在 example_rules 文件夹中的其它<code>规则</code>文件.</p><p>让我们分解一下响应信息看看发生了什么.</p><pre><code>Queried rule Example rule from 1-15 14:22 PST to 1-15 15:07 PST: 5 hits</code></pre><p>ElastAlert 定期查询最近 <code>buffer_time</code> (default 45 minutes) 时间窗内的匹配 filters 的数据. 可以看到命中了 5 条.</p><pre><code>POST http://elasticsearch.example.com:14900/elastalert_status/elastalert_status?op_type=create [status:201 request:0.025s]</code></pre><p>上面这行显示了 ElastAlert 上传了一个关于刚刚发出的查询的信息文档到 elastalert_status 索引.</p><pre><code>Ran Example rule from 1-15 14:22 PST to 1-15 15:07 PST: 5 query hits (0 already seen), 0 matches, 0 alerts sent</code></pre><p>上面这行意味着 ElastAlert 已经完成了<code>规则</code> 处理. 对于一个大时间区间, 有时会执行多个查询，但是它们的数据将会被一起处理. <code>query_hits</code> 是从 ES 查询到的文档数量, <code>already seen</code> 指的是那些在前面的一个查询中已经被查询出来（buffer_time &gt; run_every 导致查询时间窗口重叠）, 这些将会被忽略. <code>matches</code> 指的是匹配了 <code>规则类型</code> 之后的输出文档数量, <code>alerts sent</code> 指的是实际发出的 <code>告警</code> 数(可能配了多个<code>告警器</code>). 这可能会因为 <code>realert</code> 、<code>aggregation</code> 选项或者一个错误导致 <code>matches</code> 有差异.</p><pre><code>Sleeping for 297 seconds</code></pre><p>默认 <code>run_every</code> 是 5 分钟, 意味着 ElastAlert 将会陷入 sleep 直到上个周期的运行过了 5 分钟才会执行一次从当前时间到 5 分钟之前的范围查询.</p><p>假设, 在接下来的 297 秒内, ES 中又增加了 45 个<code>匹配</code>的文档:</p><pre><code>INFO:root:Queried rule Example rule from 1-15 14:27 PST to 1-15 15:12 PST: 51 hits...INFO:root:Sent email to ['elastalert@example.com']...INFO:root:Ran Example rule from 1-15 14:27 PST to 1-15 15:12 PST: 51 query hits, 1 matches, 1 alerts sent</code></pre><p>邮件正文将会包含如下内容:</p><pre><code>Example ruleAt least 50 events occurred between 1-15 11:12 PST and 1-15 15:12 PST@timestamp: 2015-01-15T15:12:00-08:00</code></pre><p>如果出现了一个错误, 例如 SMTP 服务不可达, 你将会看到:</p><pre><code>ERROR:root:Error while running alert email: Error connecting to SMTP host: [Errno 61] Connection refused</code></pre><p>请注意如果你停止 ElastAlert 然后过一会再启动它, 它将会查询 <code>elastalert_status</code> 然后从上一次查询的结束时间开始查询. 这是为了防止当 ElastAlert 重启的时候发生重复告警或者遗漏告警.</p><p>使用 <code>--debug</code> 而不是 <code>--verbose</code>, 邮件不会发出, 取而代之的是打印日志. 另外, 查询 ES 的动作不会被保存到保存到 <code>elastalert_status</code>.</p>]]></content>
      
      
      <categories>
          
          <category> elastalert </category>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
            <tag> ELK告警 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elastalert疑问记录</title>
      <link href="/2020/12/22/elastalert/elastalert-yi-wen-ji-lu/"/>
      <url>/2020/12/22/elastalert/elastalert-yi-wen-ji-lu/</url>
      
        <content type="html"><![CDATA[<ol><li><p>config.yaml 文件中的<code>max_aggregation</code>配置项不太理解</p></li><li><p>config.yaml 文件中的<code>old_query_limit</code>配置项提到EA会在启动后从上次运行的时间开始查询，也就是说即使EA或者ES不可用的时候，日志监控也不会断层？待确认</p></li><li><p>EA 在运行过期中貌似会监控规则文件夹下的磁盘状态，一旦文件发生变化会自动发生热重载。参考 config.yaml 中的<code>disable_rules_on_error</code></p></li><li><p>config.yaml 中的 <code>skip_invalid</code> 选项的跳过无效文件指的是配置文件？</p></li><li><p>config.yaml 中的 <code>--end &lt;timestamp&gt;</code> 选项在官网有两个描述</p></li><li><p>buffer_time 选项要好好看看到底是什么意思，除了简单的查询窗口之外，还有没有其它用意以及功能：ElastAlert will buffer results from the most recent period of time, in case some log sources are not in real time</p></li><li><p>run_every 是执行时间间隔窗口，单run_every 小于buffer_time 的时候的处理逻辑是怎样的。初步看来 EA 会过滤那些在叠加的查询窗口内重复查询出来的内容，看看它是怎样实现的</p></li><li><p>大时间区间(timeframe)会有多个查询(run_every/buffer_time)发生</p></li><li><p>导入模块的规则和告警名称为 <code>module.file.RuleName</code>和 <code>module.file.AlertName</code>，有点奇怪</p></li><li><p>了解规则配置中的<code>use_strftime_index</code>格式化字符串索引名称的原理、<code>search_extra_index</code>参数不理解、aggregation和aggregate_by_match_time不理解、exponential_realert在文档中给出的例子算法貌似有点问题、query_delay 要看一下算法、<code>top_count_keys</code>不理解</p></li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> elastalert </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ELK告警 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>volatile 和 synchronized</title>
      <link href="/2020/12/22/bing-fa-bian-cheng/volatile-and-synchronized/"/>
      <url>/2020/12/22/bing-fa-bian-cheng/volatile-and-synchronized/</url>
      
        <content type="html"><![CDATA[<p>[toc]</p><h1>1、概述</h1><p>Java代码在编译后会变成Java字节码，字节码被类加载器加载到JVM里，JVM执行字节 码，最终需要转化为汇编指令在CPU上执行，Java中所使用的并发机制依赖于JVM的实现和 CPU的指令。</p><h1>2、volatile</h1><p>在多线程并发编程中synchronized和volatile都扮演着重要的角色，volatile是轻量级的 synchronized，它在多处理器开发中保证了共享变量的“可见性”。可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。如果volatile变量修饰符使用恰当的话，它比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。</p><h3 id="1、计算机的重排序和可见性"><a class="header-anchor" href="#1、计算机的重排序和可见性">¶</a>1、计算机的重排序和可见性</h3><h4 id="1）CPU流水线"><a class="header-anchor" href="#1）CPU流水线">¶</a>1）CPU流水线</h4><p>CPU 中一个指令周期分为多个阶段，每个阶段可以对应一个电路单元，每一个时钟周期每一个电路逻辑单元得到前一个电路逻辑单元的输出状态（从寄存器获取）并基于现有状态计算出新状态并输出到寄存器。</p><p>CPU 分为5个阶段：</p><ul><li><p>F保存程序计数器的预测值,稍后讨论。</p></li><li><p>D位于取指和译码阶段之间。它保存关于最新取出的指令的信息,即将由译码阶段进行处理。</p></li><li><p>E位于译码和执行阶段之间。它保存关于最新译码的指令和从寄存器文件读出的值的信息,即将由执行阶段进行处理。</p></li><li><p>M位于执行和访存阶段之间。它保存最新执行的指令的结果,即将由访存阶段进行处理。它还保存关于用于处理条件转移的分支条件和分支目标的信息</p></li><li><p>W位于访存阶段和反馈路径之间,反馈路径将计算出来的值提供给寄存器文件写, 而当完成ret指令时,它还要向PC选择逻辑提供返回地址</p></li></ul><p>以下是一个 CPU 逻辑组合电路示意图的例子：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202103.png" alt="image-20200421214256554"></p><p>一条指令的完整流程就是 FDEMW，下面是CPU三条指令的执行示意图：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202122.png" alt="image-20200421214723065"></p><p>可以看到这时未流水线化的处理器，三条指令串行执行，在第一条指令完成 W 之前，第二条指令的 F 都不能开始，则显然有问题，在第一条指令完成 F 之后，紧着的下一个时钟周期 F 逻辑单元其实就可以接着执行下一条指令的预取指令动作了，而不是白白消耗4个时钟周期！</p><p>看下面流水线化之后的示意图，效率明显提高：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202129.png" alt="image-20200421215232300"></p><h4 id="2）流水线冒险"><a class="header-anchor" href="#2）流水线冒险">¶</a>2）流水线冒险</h4><p>流水线有这样一种情况,在下一个时钟周期中下一条指令不能执行。这种情况称为冒险(hazard)。我们将介绍三种流水线冒险。</p><h5 id="1-结构冒险"><a class="header-anchor" href="#1-结构冒险">¶</a>1&gt; 结构冒险</h5><p>结构冒险第一种冒险叫作结构冒险( structural hazard)。即硬件不支持多条指令在同一时钟周期执行。例如看上图，假设该流水线结构只有一个存储器，第2个时钟周期正在访问存储器，而第5个时钟周期正在预取指令，存储器只能满足一个操作，这就是结构冒险。如果发生上述情况,那我们精心构筑起来的流水线就会受到破坏。</p><blockquote><p>结构冒险:因缺乏硬件支持而导致指令不能在预定的时钟周期内执行的情况。</p></blockquote><h5 id="2-数据冒险与指令重排"><a class="header-anchor" href="#2-数据冒险与指令重排">¶</a>2&gt; <strong>数据冒险与指令重排</strong></h5><p>数据冒险( data hazard)发生在由于一条指令必须等待另一条指令的完成而造成流水线暂停的情况下。假设你在折叠衣服时发现有一只短袜找不到与之配对的另一只。你可能做的是下楼到你的房间,在衣橱中找,看是否能找到另一只。很明显,当你在找的时候,已经烘干且正需要折叠的衣服以及已经洗完且正需要烘干的衣服不得不搁置一边</p><blockquote><p>数据冒险:也称为流水线数据冒险( pipeline data hazard),即因无法提供指令执行所需数据而导致指令不能在预定的时钟周期内执行的情况。</p></blockquote><p>在计算机流水线中,数据冒险是由于一条指令依赖于更早的一条还在流水线中的指令造成的(这是一种在洗衣店例子中不存在的情况)。</p><p>例如,假设有一条加法指令,它之后紧跟着一条减法指令,而减法指令要使用加法指令的和($s0):</p><pre><code>add $s0, $to, $tl sub $t2, $s0, $t3 </code></pre><p>在不做任何干涉的情况下,这一数据冒险会严重地阻碍流水线。加法指令直到第五步才能写回它的结果,这就意味着在流水线中浪费了3个时钟周期。<br>虽然可以试图通过编译器来避免这种数据冒险的发生,但实际上这种努力很难令人满意。<br>因为这种冒险的发生过于频繁而且导致的延迟太长,因此不可能指望编译器把我们从这种困境当中解脱出去。<br>一种最基本的解决方法是基于以下发现:在解决数据冒险问题之前不需要等待指令的执行结束。对于上述的代码序列,一且ALU生成了加法运算的结果,就可以将它用作减法运算的个输人项。从内部资源中直接提前得到缺少的运算项的过程称为前推( forwarding)或者旁路( bypassing)。</p><blockquote><p>前推:也称为旁路。一种解决数据冒险的方法,具体做法是从内部寄存器而非程序员可见的寄存器或存储器中提前取出数据。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202145.png" alt="image-20200421220725413"></p><p>上图表示了把add指令执行后的<code>$s0</code>中的值作为sub指令执行的输人的旁路连接。只有当目标步骤在时间上晚于源步骤时旁路的路径才有效。例如,从前一条指令存储器访问的输出至下一条指令执行的输人就不能实现旁路,因为那样的话将意味着时间的倒流。<br>旁路可以工作得很好。然而它并不能够避免所有流水线阻塞的发生。例如,假设第一条指令不是add而是装载<code>$s0</code>寄存器的内容, 正如上图所描述的那样,由于数据间的依赖,所需要的数据只有在前一条指令流水线的第四级完成之后才能生效,这对于sub指令的第三级输入来说就太迟了。因此,如下图所示, 即使采用了旁路机制, 在遇到 <strong>取数一使用型数据冒险(load- use data hazard)</strong> 时,流水线不得不阻塞一个步骤。<br>图中显示了一个重要的流水线概念,正式的叫法是<strong>流水线阻塞( pipeline stal)</strong>,但是它经常被呢称为<strong>气泡( bubble)</strong>（其实就是插入一个空指令，本次时钟周期什么也不做，发生了一次空转）。我们经常会在流水线中看到阻塞的发生。</p><blockquote><ul><li>取数一使用型数据冒险。一类特殊的数据冒险，指当装载指令要取的数还没取回来时其他指令就需要使用的情况。</li><li>流水线阻塞:也称为气泡。为了解决冒险而实施的一种阻塞。</li></ul></blockquote><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202235.png" alt="image-20200421220841398"></p><p>上面举了一个流水线阻塞的例子，下面则是一个流水线指令重排的例子。注意，指令重排就是通过旁路实现的，下面的指令重排在可以使用 WH 到 IF 的一个旁路实现。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202315.png" alt="image-20200421221824346"></p><h5 id="3-控制冒险"><a class="header-anchor" href="#3-控制冒险">¶</a>3&gt; 控制冒险</h5><p>第三种冒险叫作控制冒险( control hazard)。这种冒险会在下面的情况下出现:决策依赖于一条指令的结果,而其他指令正在执行中。</p><blockquote><p>控制冒险:也称为分支冒险( branch hazard)。因为取到的指令并不是所需要的(或者说指令地址的变化并不是流水线所预期的)而导致指令不能在预定的时钟周期内执行。</p></blockquote><h4 id="3）指令重排"><a class="header-anchor" href="#3）指令重排">¶</a>3）指令重排</h4><p>上面通过举例说明了现代处理器是会出现指令重排的情况，大多数现代微处理器都会采用将指令乱序执行（out-of-order execution，简称OoOE或OOE）的方法，在条件允许的情况下，直接运行当前有能力立即执行的后续指令，避开获取下一条指令所需数据时造成的等待3。通过乱序执行的技术，处理器可以大大提高执行效率。</p><p>除了处理器，常见的Java运行时环境的JIT编译器也会做指令重排序操作，即生成的机器指令与字节码指令顺序不一致。</p><p>以下是一个测试例子，指令重排可能会导致输出 x=0, y=0。 理论上是不可能出现这种情况的，要么是(1,0)，(0,1)，(1,1)中的一种，但是可能其中一个线程发生了指令重排。例如：one 线程<code>x=b</code>行排到<code>a=1</code>上面了，此时执行<code>x=b</code>得到 <code>x=0</code>，然后线程中断，执行 other 线程，执行到<code>y=a</code>即 <code>y=0</code>，然后输出结果得到(0,0)。</p><pre class="line-numbers language-language-java"><code class="language-language-java">public class Test {    private static int x = 0, y = 0;    private static int a = 0, b =0;    public static void main(String[] args) throws InterruptedException {        int i = 0;        for(;;) {            i++;            x = 0; y = 0;            a = 0; b = 0;            Thread one = new Thread(new Runnable() {                public void run() {                    //由于线程one先启动，下面这句话让它等一等线程two. 读着可根据自己电脑的实际性能适当调整等待时间.                    shortWait(100000);                    a = 1;                    x = b;                }            });            Thread other = new Thread(new Runnable() {                public void run() {                    b = 1;                    y = a;                }            });            one.start();other.start();            one.joilin();other.join();            String result = "第" + i + "次 (" + x + "," + y + "）";            if(x == 0 && y == 0) {                System.err.println(result);                break;            } else {                System.out.println(result);            }        }    }    public static void shortWait(long interval){        long start = System.nanoTime();        long end;        do{            end = System.nanoTime();        }while(start + interval >= end);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="4）as-if-serial-语义"><a class="header-anchor" href="#4）as-if-serial-语义">¶</a>4）as-if-serial 语义</h4><p>As-if-serial语义的意思是，所有的动作(Action)都可以为了优化而被重排序，但是必须保证它们重排序后的结果和程序代码本身的应有结果是一致的。Java编译器、运行时和处理器都会保证<strong>单线程下</strong>的as-if-serial语义。</p><pre class="line-numbers language-language-java"><code class="language-language-java">int a = 1;int b = 2;int c = a + b;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>将上面的代码编译成Java字节码或生成机器指令，可视为展开成了以下几步动作（实际可能会省略或添加某些步骤）。</p><ol><li>对a赋值1</li><li>对b赋值2</li><li>取a的值</li><li>取b的值</li><li>将取到两个值相加后存入c</li></ol><p>在上面5个动作中，动作1可能会和动作2、4重排序，动作2可能会和动作1、3重排序，动作3可能会和动作2、4重排序，动作4可能会和1、3重排序。但动作1和动作3、5不能重排序。动作2和动作4、5不能重排序。因为它们之间存在数据依赖关系，一旦重排，as-if-serial语义便无法保证。</p><p>为保证as-if-serial语义，Java异常处理机制也会为重排序做一些特殊处理。例如在下面的代码中，y = 0 / 0可能会被重排序在x = 2之前执行，为了保证最终不致于输出x = 1的错误结果，JIT在重排序时会在catch语句中插入错误代偿代码，将x赋值为2，将程序恢复到发生异常时应有的状态。这种做法的确将异常捕捉的逻辑变得复杂了，但是JIT的优化的原则是，尽力优化正常运行下的代码逻辑，哪怕以catch块逻辑变得复杂为代价，毕竟，进入catch块内是一种“异常”情况的表现。</p><pre class="line-numbers language-language-java"><code class="language-language-java">public class Reordering {    public static void main(String[] args) {        int x, y;        x = 1;        try {            x = 2;            y = 0 / 0;            } catch (Exception e) {        } finally {            System.out.println("x = " + x);        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="5）内存可见性"><a class="header-anchor" href="#5）内存可见性">¶</a>5）内存可见性</h4><p>计算机系统中，为了尽可能地避免处理器访问主内存的时间开销，处理器大多会利用缓存(cache)以提高性能。在这种模型下会存在一个现象，即缓存中的数据与主内存的数据并不是实时同步的，各CPU（或CPU核心）间缓存的数据也不是实时同步的。这导致在同一个时间点，各CPU所看到同一内存地址的数据的值可能是不一致的。从程序的视角来看，就是在同一个时间点，各个线程所看到的共享变量的值可能是不一致的。<br>有的观点会将这种现象也视为重排序的一种，命名为“内存系统重排序”。因为这种内存可见性问题造成的结果就好像是内存访问指令发生了重排序一样。<br>这种内存可见性问题也会导致上面示例代码即便在没有发生指令重排序的情况下的执行结果也还是(0, 0)。</p><h4 id="6）内存访问重排序与Java内存模型"><a class="header-anchor" href="#6）内存访问重排序与Java内存模型">¶</a>6）内存访问重排序与Java内存模型</h4><p>Java的目标是成为一门平台无关性的语言，即Write once, run anywhere. 但是不同硬件环境下指令重排序的规则不尽相同。例如，x86下运行正常的Java程序在IA64下就可能得到非预期的运行结果。为此，JSR-1337制定了Java内存模型(Java Memory Model, JMM)，旨在提供一个统一的可参考的规范，屏蔽平台差异性。从Java 5开始，Java内存模型成为Java语言规范的一部分。<br>根据Java内存模型中的规定，可以总结出以下几条happens-before规则。Happens-before的前后两个操作不会被重排序且后者对前者的内存可见。</p><ul><li>**程序次序法则：**线程中的每个动作A都happens-before于该线程中的每一个动作B，其中，在程序中，所有的动作B都能出现在A之后。</li><li>**监视器锁法则：**对一个监视器锁的解锁 happens-before于每一个后续对同一监视器锁的加锁。</li><li>**volatile变量法则：**对volatile域的写入操作happens-before于每一个后续对同一个域的读写操作。</li><li>**线程启动法则：**在一个线程里，对Thread.start的调用会happens-before于每个启动线程的动作。</li><li>**线程终结法则：**线程中的任何动作都happens-before于其他线程检测到这个线程已经终结、或者从Thread.join调用中成功返回，或Thread.isAlive返回false。</li><li>**中断法则：**一个线程调用另一个线程的interrupt happens-before于被中断的线程发现中断。</li><li>**终结法则：**一个对象的构造函数的结束happens-before于这个对象finalizer的开始。</li><li>**传递性：**如果A happens-before于B，且B happens-before于C，则A happens-before于C</li></ul><blockquote><p>两个操作之间具有happens-before关系,并不意味着前一个操作必须要在后一个操作之前执行!happens-before仅仅要求前一个操作(执行的结果)对后一个操作可见</p></blockquote><p>Happens-before关系只是对Java内存模型的一种近似性的描述，它并不够严谨，但便于日常程序开发参考使用，关于更严谨的Java内存模型的定义和描述，请阅读JSR-133原文或Java语言规范章节17.4。</p><p>除此之外，Java内存模型对volatile和final的语义做了扩展。对volatile语义的扩展保证了volatile变量在一些情况下不会重排序，volatile的64位变量double和long的读取和赋值操作都是原子的。对final语义的扩展保证一个对象的构建方法结束前，所有final成员变量都必须完成初始化（的前提是没有this引用溢出）。</p><p>为了保证final的新增语义。JSR-133对于final变量的重排序也做了限制。</p><ul><li><p>构建方法内部的final成员变量的存储，并且，假如final成员变量本身是一个引用的话，这个final成员变量可以引用到的一切存储操作，都不能与构建方法外的将当期构建对象赋值于多线程共享变量的存储操作重排序。例如对于如下语句<br>x.finalField = v; … ;构建方法边界sharedRef = x;<br>v.afield = 1; x.finalField = v; … ; 构建方法边界sharedRef = x;<br>这两条语句中，构建方法边界前后的指令都不能重排序。</p></li><li><p>初始读取共享对象与初始读取该共享对象的final成员变量之间不能重排序。例如对于如下语句<br>x = sharedRef; … ; i = x.finalField;<br>前后两句语句之间不会发生重排序。由于这两句语句有数据依赖关系，编译器本身就不会对它们重排序，但确实有一些处理器会对这种情况重排序，因此特别制定了这一规则。</p></li></ul><h4 id="7）内存屏障"><a class="header-anchor" href="#7）内存屏障">¶</a>7）内存屏障</h4><p>内存屏障（Memory Barrier，或有时叫做内存栅栏，Memory Fence）是一种CPU原子指令，用于<strong>控制特定条件下的重排序和内存可见性问题</strong>。Java编译器也会根据内存屏障的规则禁止重排序。<br>内存屏障可以被分为以下几种类型</p><ul><li>**LoadLoad屏障：**对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。</li><li>**StoreStore屏障：**对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。</li><li>**LoadStore屏障：**对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。</li><li>**StoreLoad屏障：**对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它一个“全能型”的屏障,它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障(其他类型的屏障不一定被所有处理器支持)。执行该屏障开销会很昂贵,因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中(Buffer Fully Flush)。<ul><li>控制重排序：在取指之后如果指令中包含了内存屏障标识，会根据情况禁止当前指令之后的指令放到当前指令之前执行，也会禁止将当前指令放置到需要后置执行的指令之后执行。</li><li>内存可见性：包含内存屏障标识的指令中所操作的数据在写回主存的时候会通过缓存一致性将其他处理器中缓存了该数据的缓存行全部置失效。</li></ul></li></ul><p>内存屏障是一种标准，不同的处理器厂商和操作系统可能会采用不同的实现。以X86 的内存屏障指令为例：包括读屏障、写屏障、全屏障。</p><table><thead><tr><th>屏障类型</th><th>示例</th><th>说明</th></tr></thead><tbody><tr><td>读屏障</td><td>Read1; 读屏障; Read2;</td><td>确保读操作Read1，先于 Read2及其后所有读操作。 对于屏障前后的写操作并无影响。</td></tr><tr><td>写屏障</td><td>Store1; 写屏障; Store2;Read;</td><td>确保写操作Store1刷新数据到内存(使数据对其他处理器可见)的操 作，先于写屏障后的Store2及其后所有Read指令的执行。</td></tr><tr><td>全 屏障</td><td>Read1;Store1; 全屏障; Read2;Store2;</td><td>确保屏障之前的所有内存访问操作(包括Store和Read)完成之后，才 执行屏障之后的内存访问操作。 全能型屏障，会屏蔽屏障前后所有指令的重排。</td></tr></tbody></table><p>那Java开发时，我们如何进行内存屏障呢?Java作为一种一次编写，多处运行的语言，开发者是不需 要考虑平台相关性的，同样这个问题也不需要也不应该由程序员来关心。在需要确保代码执行顺序时， JVM会在适当位置插入一个内存屏障命令，用来禁止特定类型的重排序。所以，Java虚拟机封装了底层内存屏障的实现，提供了四种内存屏障指令(在后面有说明)，编译器会根据底层的计算机架构，将内存屏障替换为相应的CPU指令。有的处理器的重排序规则较严，无需内存屏障也能很好的工作，Java编译器会在这种情况下不放置内存屏障。</p><h4 id="8-Intel-64-IA-32架构下的内存访问重排序"><a class="header-anchor" href="#8-Intel-64-IA-32架构下的内存访问重排序">¶</a>8) Intel 64/IA-32架构下的内存访问重排序</h4><p>Intel 64和IA-32是我们较常用的硬件环境，相对于其它处理器而言，它们拥有一种较严格的重排序规则。Pentium 4以后的Intel 64或IA-32处理的重排序规则如下。</p><p>在单CPU系统中</p><ul><li>读操作不与其它读操作重排序。</li><li>写操作不与其之前的写操作重排序。</li><li>写内存操作不与其它写操作重排序，但有以下几种例外</li><li>CLFLUSH的写操作</li><li>带有non-temporal move指令(MOVNTI, MOVNTQ, MOVNTDQ, MOVNTPS, and MOVNTPD)的streaming写入。</li><li>字符串操作</li><li>读操作可能会与其之前的写不同位置的写操作重排序，但不与其之前的写相同位置的写操作重排序。</li><li>读和写操作不与I/O指令，带锁的指令或序列化指令重排序。</li><li>读操作不能重排序到LFENCE和MFENCE之前。</li><li>写操作不能重排序到LFENCE、SFENCE和MFENCE之前。</li><li>LFENCE不能重排序到读操作之前。</li><li>SFENCE不能重排序到写之前。</li><li>MFENCE不能重排序到读或写操作之前。</li></ul><p>在多处理器系统中</p><ul><li>各自处理器内部遵循单处理器的重排序规则。</li><li>单处理器的写操作对所有处理器可见是同时的。</li><li>各自处理器的写操作不会重排序。</li><li>内存重排序遵守因果性(causality)（内存重排序遵守传递可见性）。</li><li>任何写操作对于执行这些写操作的处理器之外的处理器来看都是一致的。</li><li>带锁指令是顺序执行的。</li></ul><p>值得注意的是，对于Java编译器而言，Intel 64/IA-32架构下处理器不需要LoadLoad、LoadStore、StoreStore屏障，因为不会发生需要这三种屏障的重排序。</p><h3 id="2、volatile定义"><a class="header-anchor" href="#2、volatile定义">¶</a>2、volatile定义</h3><p>Java语言规范第3版中对volatile的定义如下:Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。Java语言 提供了volatile，在某些情况下比锁要更加方便。如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。也就是上面提到的**volatile变量法则：**对volatile域的写入操作happens-before于每一个后续对同一个域的读写操作。</p><h3 id="3、volatile-解决指令有序性和内存可见性"><a class="header-anchor" href="#3、volatile-解决指令有序性和内存可见性">¶</a>3、volatile 解决指令有序性和内存可见性</h3><h5 id="问题"><a class="header-anchor" href="#问题">¶</a>问题</h5><p>前面提到，重排序只会保证单线程内的访问语义，但是多线程下，重排序有可能会造成不可预知的问题，那有没有什么办法来禁止重排序呢?</p><ol><li>首先在 JVM 层面对于字节码指令的重排序由 JVM 自己可以进行控制，即识别到 volatile 关键字的时候，JVM 禁用字节码指令重排序。</li><li>JVM 自己本身的代码又会经过编译器的编译称为机器指令，这个过程可能会重排序。</li><li>编译之后的机器指令在 CPU 执行的时候也会可能发生重排序。</li><li>另外，由于本地高速缓存的引入也会导致多线程环境下多个核心缓存的主存数据不一致问题。</li></ol><p>可以看到，第一点是由 JVM 自身保证的，而问题3和4可以利用我们上面提到的内存屏障解决，后三者则需要依赖底层技术的实现。而在 Java 中，提供了 volatile 关键字来解决这些问题。</p><h5 id="volatile-实现原理"><a class="header-anchor" href="#volatile-实现原理">¶</a>volatile 实现原理</h5><ol><li><p>下载源码</p><p>OpenJDK的源码是托管在 Mercurial代码版本管理平台上的，可以使用Mercurial的代码管理工具直接 从远程仓库(Repository)中下载获取源码。</p><p>我们选用的项目是OpenJDK 8u，代码远程仓库地址:<a href="https://hg.openjdk.java.net/jdk8u/jdk8u/%E3%80%82" target="_blank" rel="noopener">https://hg.openjdk.java.net/jdk8u/jdk8u/。</a></p><p>因为下载源码过程中需要执行脚本文件get_source.sh，所以需要在Linux平台下下载。 大家可以在安装了Linux环境的机器上下载，或者在自己的机器上安装Linux虚拟机后进行下载。 获取源代码过程如下:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">#需先安装代码版本管理工具 yum -y install mercurial#安装成功后，可以用以下命令查看hg 版本信息 hg --version#从远程仓库下载源码hg clone https://hg.openjdk.java.net/jdk8u/jdk8u/#赋予get_source.sh文件可执行权限 chmod 755 get_source.sh#执行文件获取源码 ./get_source.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>OpenJDK 目录结构</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202330.png" alt="image-20200422073943486"></p></li><li><p>Hsdis工具查看机器指令</p><p>使用hsdis可以查看 Java 编译后的机器指令，使用方法:把编译好的 hsdis-amd64.dll放在 $JAVA_HOME/jre/bin/server 目录下。就可以使用如下命令，查看程序的机器指令。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">java-XX:+UnlockDiagnosticVMOptions-XX:+PrintAssembly,类名<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在类VolatileFieldTest中属性volatileField为volatile变量。</p><pre class="line-numbers language-language-java"><code class="language-language-java">public class VolatileFieldTest {    private  volatile int volatileField;    public int getVolatileField() {        return volatileField;}    public void setVolatileField(int volatileField) {        this.volatileField = volatileField;    }    public static void main(String[] args) {        VolatileFieldTest volatileFieldTest=new VolatileFieldTest();        volatileFieldTest.setVolatileField(2);    } }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 Linux中执行</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">java-XX:+UnlockDiagnosticVMOptions-XX:+PrintAssembly,VolatileFieldTest<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于 volatile 修饰的变量进行写操作，在生成汇编代码中，会有如下的指令:</p><pre class="line-numbers language-language-assembly"><code class="language-language-assembly">// 内存屏障lockaddl$0×0,(%esp); <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>上面的操作就相当于一个内存屏障。</p><ul><li><p>lock指令:会使紧跟在其后的指令变成原子操作，lock指令是一个汇编层面的指令，作为前缀加在其他汇编指令之前，可以保证其后汇编操作的原子性。在多CPU环境中， LOCK指令可以确保一个处理器能独占使用共享内存。</p><p>在计算机中每个CPU拥有自己的寄存器，缓冲区和高速缓存，所有CPU共享主内存。如果是单 核CPU环境，所有线程都会运行相同CPU上，使用的是相同存储空间不存在一致性问题，就不需要内存屏障;如果是多核 CPU环境中，线程可能运行在不同的CPU内核上， 共享主内存，就需用内存屏障保障一致性。</p></li><li><p>addl指令:加法操作指令。<code>addl $0,0(%%esp)</code>表示将数值0加到rsp寄存器中。esp寄存器指向栈顶的内存单元，加上一个0，esp寄存器的数值依然不变。<code>addl $0,0(%%esp)</code>使用此汇编指令再配合lock指令，实现了CPU的内存屏障。</p></li></ul><p>通过查IA-32架构软件开发者手册可知，Lock前缀的指令在多核处理器下会引发了两件事情：</p><ol><li><p>将当前处理器缓存行的数据写回到系统内存。Lock前缀指令导致在执行指令期间，声言处理器的LOCK#信号。在多处理器环境中，<strong>LOCK#信号确保在声言该信号期间，处理器可以独占任何共享内存</strong>。但是，在最近的处理器里，LOCK#信号一般不锁总线，而是锁缓存，毕竟锁总线开销的比较大。在8.1.4节有详细说明锁定操作对处理器缓存的影响，对于Intel486和 Pentium处理器，在锁操作时，总是在总线上声言LOCK#信号。但在P6和目前的处理器中，如果访问的内存区域已经缓存在处理器内部，则不会声言LOCK#信号。相反，<strong>它会锁定这块内存区域的缓存并回写到内存，并使用缓存一致性机制来确保修改的原子性，此操作被称为“缓存锁定”</strong>，缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据。</p></li><li><p>这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。<strong>IA-32处理器和Intel 64处理器使用MESI(修改、独占、共享、无效)控制协议去维护内部缓存和其他处理器缓存的一致性</strong>。在多核处理器系统中进行操作的时候，IA-32和Intel 64处理器能嗅探其他处理器访问系统 内存和它们的内部缓存。处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的 缓存的数据在总线上保持一致。例如，在Pentium和P6 family处理器中，如果通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理 器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充。</p><p>MESI 协议：</p></li></ol><table><thead><tr><th>状态</th><th>说明</th><th>描述</th></tr></thead><tbody><tr><td>M</td><td>Modify，修改</td><td>Cache line 数据有效，但数据被修改了，和主存中不一致，数据只存在本 cache 内。</td></tr><tr><td>E</td><td>Exclusive，独占</td><td>Cache line 数据有效，数据和主存中一致，数据只存在于本 cache 内</td></tr><tr><td>S</td><td>Share，共享</td><td>Cache line 数据有效，数据和主内存中一致，数据存在于2个以上 Cache 内</td></tr><tr><td>I</td><td>Invalid，无效</td><td>Cache line 数据无效</td></tr></tbody></table></li></ol><h5 id="volatile-源码"><a class="header-anchor" href="#volatile-源码">¶</a>volatile 源码</h5><p>下面我们通过OpenJDK源码，来看看JVM是怎么实现volatile赋值的。</p><ol><li><p>查看volatile 字段的字节码</p><p>通过javap命令(javap -v -p VolatileFieldClass.class)可以看到volatile的属性的字节码flags标识中有个关键字ACC_VOLATILE。</p><pre class="line-numbers language-language-java"><code class="language-language-java">private volatile int commonField;   descriptor: I   flags: ACC_PRIVATE, ACC_VOLATILE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>is_volatile方法：判断一个变量是否 volatile 类型</p><p>在不同的计算机架构(操作系统和CPU架构)下，内存屏障的实现也会不同，所以对应的JVM的 volatile底层实现在不同的平台上也是不同的。下面我们以linux_x86为例，来一层层解开volatile 的面纱。</p><p>通过全局搜索关键字ACC_VOLATILE，我们可以定位到JVM源文件vm\utilities\accessFlags.hpp文件，代码如下（看中文注释代码）:</p><pre class="line-numbers language-language-c++"><code class="language-language-c++">class AccessFlags VALUE_OBJ_CLASS_SPEC {  friend class VMStructs; private:  jint _flags; public:  AccessFlags() : _flags(0) {}  explicit AccessFlags(jint flags) : _flags(flags) {}  // Java access flags  bool is_public      () const         { return (_flags & JVM_ACC_PUBLIC      ) != 0; }  bool is_private     () const         { return (_flags & JVM_ACC_PRIVATE     ) != 0; }  bool is_protected   () const         { return (_flags & JVM_ACC_PROTECTED   ) != 0; }  bool is_static      () const         { return (_flags & JVM_ACC_STATIC      ) != 0; }  bool is_final       () const         { return (_flags & JVM_ACC_FINAL       ) != 0; }  bool is_synchronized() const         { return (_flags & JVM_ACC_SYNCHRONIZED) != 0; }  bool is_super       () const         { return (_flags & JVM_ACC_SUPER       ) != 0; }  //可以看到is_volatile函数，这个函数是判断变量字节码中是否有 ACC_VOLATILE这个flag。  bool is_volatile    () const         { return (_flags & JVM_ACC_VOLATILE    ) != 0; }  bool is_transient   () const         { return (_flags & JVM_ACC_TRANSIENT   ) != 0; }  bool is_native      () const         { return (_flags & JVM_ACC_NATIVE      ) != 0; }  bool is_interface   () const         { return (_flags & JVM_ACC_INTERFACE   ) != 0; }  bool is_abstract    () const         { return (_flags & JVM_ACC_ABSTRACT    ) != 0; }  bool is_strict      () const         { return (_flags & JVM_ACC_STRICT      ) != 0; }  ... ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>Java 中 volatile 变量赋值，C++实现</p><p>Java字节码是通过bytecodeInterpreter解释器来执行，我们在bytecodeInterpreter.cpp文件 根据关键字is_volatile搜索，可以看到如下代码:</p><pre class="line-numbers language-language-c++"><code class="language-language-c++">//// 变量修改后，存储变量值//int field_offset = cache->f2_as_index();  if (cache->is_volatile()) {//判断变量是否是volatile变量    if (tos_type == itos) {//变量类型为int      obj->release_int_field_put(field_offset, STACK_INT(-1));    } else if (tos_type == atos) {      VERIFY_OOP(STACK_OBJECT(-1));      obj->release_obj_field_put(field_offset, STACK_OBJECT(-1));    } else if (tos_type == btos) {      obj->release_byte_field_put(field_offset, STACK_INT(-1));    } else if (tos_type == ztos) {      int bool_field = STACK_INT(-1);  // only store LSB      obj->release_byte_field_put(field_offset, (bool_field & 1));    } else if (tos_type == ltos) {      obj->release_long_field_put(field_offset, STACK_LONG(-1));    } else if (tos_type == ctos) {      obj->release_char_field_put(field_offset, STACK_INT(-1));    } else if (tos_type == stos) {      obj->release_short_field_put(field_offset, STACK_INT(-1));    } else if (tos_type == ftos) {      obj->release_float_field_put(field_offset, STACK_FLOAT(-1));    } else {      obj->release_double_field_put(field_offset, STACK_DOUBLE(-1));    }    OrderAccess::storeload();  } else {<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这段代码中，cache-&gt;is_volatile()这段代码，cache代表变量在常量池缓存中的实例(本例中为volatileField)，这段代码的作用是判断变量是否被 volatile修饰。接着，根据当前变量的类型来赋值，会先判断volatile变量类型(tos_type变量)，后面有不同的基础类型的调用，比如int 类型就调用release_int_field_put。</p><p>release_int_field_put这个方法的实现在文件oop.inline.hpp中</p><pre class="line-numbers language-language-c++"><code class="language-language-c++">inlinevoidoopDesc::release_int_field_put(intoffset,jintcontents) { OrderAccess::release_store(int_field_addr(offset), contents); }<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>赋值动作int_field_addr外面包装执行了OrderAccess::release_store方法。<br>我们看看 OrderAccess::release_store做了什么，它的定义在 vm\runtime\orderAccess.hpp中</p><pre class="line-numbers language-language-c++"><code class="language-language-c++">staticvoidrelease_store();<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>linux_x86中实现在os_cpu\linux_x86\vm\orderAccess_linux_x86.inline.hpp</p><pre class="line-numbers language-language-c++"><code class="language-language-c++">inline void OrderAccess::release_store(volatile jint* p, jint v) { *p = v; }<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可以看到volatile操作，第一步是实现了C++的volatile变量的原生赋值实现。</p><p>C/C++中的volatile关键字，用来修饰变量，表明变量可能会通过某种方式发生改变，被 volatile声明的变量，会告诉编译器与该变量有关的运算，不要进行编译优化;且变量的值都必须直接写入内存地址或从内存地址读取。（<strong>可以看到这里解决了第2个问题</strong>）</p></li><li><p>volatile 使用内存屏障</p><p>赋值操作完成以后，我们可以看到最后一行执行的语句是</p><pre class="line-numbers language-language-c++"><code class="language-language-c++">OrderAccess::storeload();<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这是JVM的storeload一个内存屏障。<br>在 JMM 中，也把内存屏障指令分为了四类，可以在vm\runtime\orderAccess.hpp找到对应的实现方法:</p><pre class="line-numbers language-language-c++"><code class="language-language-c++">static void loadload();//读读 static void storestore();//写写static void loadstore();//读写static void storeload();//全屏障<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>内存屏障的解释也可以在orderAccess.hpp该文件中看到:</p><table><thead><tr><th>屏障类型</th><th>示例</th><th>说明</th></tr></thead><tbody><tr><td>LoadLoad Fence</td><td>Load1;LoadLoad;Load2</td><td>确保装载动作Load1，先于 Load2及其后所有 Load操作。 对于屏障前后的Store操作并无影响。</td></tr><tr><td>StoreStore Fence</td><td>Store1;StoreStore;Store2</td><td>确保Store1刷新数据到内存(使数据对其他处 理器可见)的操作，先于Store2及其后所有 Store指令的执行。 对于屏障前后的Load操作并无影响。</td></tr><tr><td>LoadStore Fence</td><td>Load1;LoadStore;Store2</td><td>确保屏障指令之前的所有Load操作，先于屏障之后所有Store操作(刷新数据到主存)。</td></tr><tr><td>StoreLoad Fence</td><td>Store1;StoreLoad;Load2</td><td>确保屏障之前的所有内存访问操作(包括Store 和Load)完成之后，才执行屏障之后的内存访 问操作。 全能型屏障，会屏蔽屏障前后所有指令的重排。</td></tr></tbody></table><p>其中StoreLoad Barriers 是一个“全能型”的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障，执行该屏障开销会很昂贵。</p><p>以linux_x86为例，我们可以在os_cpu\linux_x86\vm\orderAccess_linux_x86.inline.hpp 看到它们的实现:</p><pre class="line-numbers language-language-c++"><code class="language-language-c++">inline void OrderAccess::loadload()   { acquire(); }inline void OrderAccess::storestore() { release(); }inline void OrderAccess::loadstore()  { acquire(); }inline void OrderAccess::storeload()  { fence(); }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>当调用storeload屏障时，会调用fence()方法</p><pre class="line-numbers language-language-C++"><code class="language-language-C++">inline void OrderAccess::fence() {if (os::is_MP()) {//判断系统是否是多核CPU，在多核CPU才需要使用内存屏障。    // always use locked addl since mfence is sometimes expensive#ifdef AMD64    __asm__ volatile ("lock; addl $0,0(%%rsp)" : : : "cc", "memory");#else    __asm__ volatile ("lock; addl $0,0(%%esp)" : : : "cc", "memory");#endif} }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上面的代码中，我们看到了熟悉的汇编指令 <code>lock; addl $0,0(%%esp) </code>，<strong>该指令可以解决第3个问题，至此 volatile 保证了对于共享变量访问的指令的有序性以及该共享变量的可见性。</strong></p><ul><li>os::is_MP()，会判断当前环境是否是多核。单核不存在一致性问题，多核CPU才需要使用内存屏 障。 cc代表的是寄存器,memory代表是内存。</li><li>用”cc”和”memory”,会通知编译器和处理器 volatile变量在内存或者寄存器内的值已经发生了修改,要重新加载，需要直接从主内存中读取。</li></ul><p>到此，我们就彻底的揭开了volatile 的面纱，现在我们知道 volatile 保证有序性和可见性的原理了。</p></li></ol><h5 id="一些术语"><a class="header-anchor" href="#一些术语">¶</a>一些术语</h5><table><thead><tr><th>术语</th><th>英文单词</th><th>术语描述</th></tr></thead><tbody><tr><td>内存屏障</td><td>memory barries</td><td>一组处理器的指令，用于实现对内存操作的顺序限制</td></tr><tr><td>缓冲行</td><td>cache line</td><td>缓存中可以分配的最小存储单位。处理器填写缓存线时会加载整个缓存线，需要使用多个主内存读指令周期</td></tr><tr><td>原子操作</td><td>atomic operations</td><td>不可中断的一个或一系列操作</td></tr><tr><td>缓存行填充</td><td>cache line fill</td><td>当处理器识别到从内存中读取操作数是可缓存的，处理器读取整个缓存行到适当的缓存(L1、L2、L3的或所有)</td></tr><tr><td>缓存命中</td><td>cache hit</td><td>处理器按照寻址公式获取到的地址在缓存中有效，则处理器直接从缓存取指令而不是主存</td></tr><tr><td>写命中</td><td>write hit</td><td>当处理器将操作数写回到一个内存缓存的区域时，它首先会检查这个缓存的内存地址是否在缓存行中，如果存在一个有效的缓存行，则处理器将这个操作数写回到缓存，而不是写回内存，这个操作被称为写命中</td></tr><tr><td>写缺失</td><td>write misses the cache</td><td>一个有效的缓存行被写入到不存在的内区区域</td></tr></tbody></table><h3 id="3、volatile注意点"><a class="header-anchor" href="#3、volatile注意点">¶</a>3、volatile注意点</h3><h4 id="有序性"><a class="header-anchor" href="#有序性">¶</a>有序性</h4><p>所谓 volatile 保证了有序性仅仅是保证操作了其声明的变量的指令不会先于其前面的指令执行，其后面的指令不会重排到在其之前执行，而其前面的这些指令或者后面的指令集合自己的顺序它是不管的，也管不了。</p><h4 id="可见性"><a class="header-anchor" href="#可见性">¶</a>可见性</h4><p>可见性即保证声明变量在当前处理器的缓存中进行了修改写入主存的时候其他处理器缓存的可见性，很好理解。</p><h4 id="原子性"><a class="header-anchor" href="#原子性">¶</a>原子性</h4><p><strong>volatile 声明的指令本身是原子指令</strong>。</p><p>像下面这种经典操作其实包含了多条指令，其中有包含取出和写入 volatile 变量 a 到主存的动作，这些指令是原子的。但是 a = a+1 这条指令不是原子的：</p><pre class="line-numbers language-language-java"><code class="language-language-java">volatile int a = 1;a++;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol><li>线程 A 从内存中取出变量 a=1存储到缓存并加载到寄存器中，然后计算 a=a+1得到2并存到处理器的寄存器中，并更新了自己的缓存， 然后线程 A 在将数据写入到主存之前被中断了。</li><li>线程 B 开始执行，同样从内存中取出变量 a=1存储到缓存并加载到寄存器中，然后计算 a=a+1得到2并存到处理器的寄存器中，并更新了自己的缓存，然后将 a 写回到主存，触发缓存一致性将 A 中缓存置失效。线程完成。</li><li>线程 A 重新执行，继续将寄存器中的变量 a 写入主存。此时 a=2。实际上应该是3。</li></ol><p>以上问题是因为在从内存取出 a 之前就应该是临界区起始点，应该对线程进行同步，但是并没有。</p><h3 id="4、volatile使用场景举例"><a class="header-anchor" href="#4、volatile使用场景举例">¶</a>4、volatile使用场景举例</h3><h5 id="经典场景：DCL（Double-Check-Lock）"><a class="header-anchor" href="#经典场景：DCL（Double-Check-Lock）">¶</a>经典场景：DCL（Double Check Lock）</h5><h6 id="原始问题：懒汉单例模式"><a class="header-anchor" href="#原始问题：懒汉单例模式">¶</a>原始问题：懒汉单例模式</h6><pre class="line-numbers language-language-java"><code class="language-language-java">public class Singleton {  static Singleton instance;  static Singleton getInstance(){    if (instance == null) {          instance = new Singleton();    }    return instance;  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上是一个懒汉（懒加载）单例模式的写法，但是存在线程安全问题，当第一个进入第4行的线程被切换就会出现问题。</p><h6 id="优化：解决线程安全"><a class="header-anchor" href="#优化：解决线程安全">¶</a>优化：解决线程安全</h6><pre class="line-numbers language-language-java"><code class="language-language-java">public class Singleton {  static Singleton instance;  static synchronized Singleton getInstance(){    if (instance == null) {          instance = new Singleton();    }    return instance;  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上代码直接在原方法基础上使用<code>synchronized</code>关键字进行加锁，这样确实解决了线程安全问题，但是引入的却是性能的问题，所有尝试获取该单例的线程都会被要求先获得这把锁，如果锁的竞争激烈，<code>synchronized</code>会升级会重量级锁（具体看下面章节）。对性能的影响非常大！</p><h6 id="优化：性能问题"><a class="header-anchor" href="#优化：性能问题">¶</a>优化：性能问题</h6><pre class="line-numbers language-language-java"><code class="language-language-java">public class Singleton {  static Singleton instance;  static Singleton getInstance(){    if (instance == null) {      synchronized(Singleton.class) {        if (instance == null)          instance = new Singleton();        }    }    return instance;  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为了解决性能上的问题，我们将获取锁的位置后移，在获取单例之前先判断单例是否已经被初始化：</p><ul><li><p>如果有则直接返回，不走取锁流程；</p></li><li><p>否则竞争锁。竞争到锁之后我们不能立即实例化单例对象，因为虽然我们进入取锁流程的大前提是因为当前线程发现单例未实例化，但是前面判断单例是否实例化是非线程安全的，即可能会出现当前线程判断单例未实例化之后准备争锁前的一瞬间被切换了，另外一个线程开始执行并发现单例未实例，并开始取锁，对象实例化，释放锁等一系列动作且成功了，然后切换回当前线程，此时当前线程接着进行对象实例化，单例失败。</p><p>所以我们需要进入同步块之后还需要对单例对象进行是否实例化的判断。</p></li></ul><p>以上代码解决了性能上的问题，并不是所有获取单例的线程一旦调用该方法都需要先获取锁，而是先进行纳秒级的一个判断，再获取锁，虽然可能会出现已经获得锁准备进行实例化的线程被中断了导致当前线程会阻塞在锁之外的情况，但是这种情况的概率很少，其性能影响可以忽略。</p><p>虽然以上代码解决了性能上的问题，但是其实又引入了一个新的问题，就是我们前面提到的内存可见性的问题。这个问题可能由两个原因诱导：</p><ol><li><p>本地缓存引发的问题</p><p>线程 A 进入方法调用，从主存加载<code>Singleton</code> 的Class对象的静态成员变量<code>instance</code>的地址及其内容进入处理器，并缓存到高级缓存，然后送入寄存器并进行算术逻辑单元的计算，发现并未实例化，然后准备进入下面的运算，即获取锁然后继续后续流程，但是 CPU 时间片刚好用完了，线程切换。</p><p>此时线程 B 进入方法调用，重复线程 A的动作且未被切换然后获取锁，然后再判断单例是否确实没有被实例化还是在实例化中，发现确实没有被实例化，然后实例化单例，然后将单例对象指针引用回写到主存中<code>Singleton</code>  对象的<code>instance</code>变量，释放锁，线程完成，释放CPU资源。</p><p>切换回线程 A ，继续后续流程，判断单例是否实例化，注意此时是从本地缓存获取单例的内容，还是之前写入缓存的 null，所以后续动作将和线程 B 一模一样。单例失败！</p><p>以上问题就是前面提到的本地缓存和主存数据不一致的问题。</p></li><li><p>指令重排引发的问题</p><p>线程 A 进入方法调用，发现单例未实例化，竞争锁判断还是未实例化，此时开始实例化对象，以下是正常的实例化流程：</p><ul><li><p>分配一块内存 M；</p></li><li><p>在内存 M 上初始化 Singleton 对象；</p></li><li><p>然后 M 的地址赋值给 instance 变量。</p></li><li><p>释放锁</p></li></ul><p>但是实际上却可以是</p><ul><li><p>分配一块内存 M；</p></li><li><p>将 M 的地址赋值给 instance 变量。</p></li><li><p>最后在内存 M 上初始化 Singleton 对象；</p></li><li><p>释放锁</p></li></ul><p>这将导致线程 A 在完成对象实例化之前，线程 B进入方法，发现当前 Class的静态成员变量已经有值了，就是上面第二步所赋值的指针，便直接返回该指针。然后获取到该&quot;单例&quot;的业务正常使用该单例，结果在使用的时候 JVM 发现该单例内容未实例化，直接空指针。</p><blockquote><p>注意，以上不会出现在线程 A 释放锁之后第三步实例化对象的动作还未完成的情况，因为我们前面提到的 JMM 内存模型的关于锁的 happen-before 原则保证了锁释放之前需要完成所有临界区内的动作。</p></blockquote></li></ol><h6 id="解决：单例对象可见性"><a class="header-anchor" href="#解决：单例对象可见性">¶</a>解决：单例对象可见性</h6><pre class="line-numbers language-language-java"><code class="language-language-java">public class Singleton {  static volatile Singleton instance;  static Singleton getInstance(){    if (instance == null) {      synchronized(Singleton.class) {        if (instance == null)          instance = new Singleton();        }    }    return instance;  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，我们声明了<code>Singleton</code>类对象的静态成员变量<code>instance</code>为一个<code>volatile</code>变量，这就保证其在多缓存下的可见性，以及对于该变量的内存写入的动作的前后有序性（在将单例对象的指针写入到该<code>Singleton</code>类对象的静态成员变量<code>instance</code>变量之前必须保证该单例对象的实例动作都完成了）。</p><blockquote><p>另外，我们可以对该变量定义为final，final 关键字也有其相关的 happen-before原则，也是为了保证其声明的变量的可见性，但是声明了该关键字的话就不是懒汉式了，因为需要立即填充该变量的内容且之后都不能改变。</p></blockquote><h6 id="由DCL-问题引发的思考"><a class="header-anchor" href="#由DCL-问题引发的思考">¶</a>由DCL 问题引发的思考</h6><p>以上 DCL 的场景我们可以看到一个现象：在临界区之内的共享变量的访问并不一定是安全的。</p><p>那么我们是不是需要对所有可能被并发访问的变量即使是可以通过<code>synchronied</code>保证了变量被访问是同步的情况下也要加上<code>volatile</code>呢？其实不是的，之所以上面会出现这样的情况，是因为我们在进入临界区之前就先从主存加载了这个变量数据，导致本地对其进行缓存，如果我们的加载动作是在临界区内进行，那就没有问题了，所有线程的写入及获取动作都是同步的。</p><p>考虑到悲观锁的性能问题，我们需要结合其带来的代价是不是我们的业务不能承受的（例如上面的单例构建方法如果被调用的不多，完全可以到第二步优化线程安全问题就可以了）。如果悲观锁的代价实在太大，可以考虑乐观锁的实现。</p><p>另外，对于我们的业务来说，某些共享数据的&quot;短暂&quot;不可见是否是正常的？需要根据实际业务进行考虑。</p><h3 id="5、volatile的使用优化"><a class="header-anchor" href="#5、volatile的使用优化">¶</a>5、volatile的使用优化</h3><p>著名的Java并发编程大师Doug lea在JDK 7的并发包里新增一个队列集合类Linked- TransferQueue，它在使用volatile变量时，用一种追加字节的方式来优化队列出队和入队的性 能。LinkedTransferQueue的代码如下。<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202343.png" alt="3729c7403eb7298c0f4b2e7c118d5980"></p><p>让我们先来看看LinkedTransferQueue这个类，它使用一个内部类类型来定义队列的 头节点(head)和尾节点(tail)，而这个内部类PaddedAtomicReference相对于父类 AtomicReference只做了一件事情，就是将共享变量追加到64字节。我们可以来计算下，一个对 象的引用占4个字节，它追加了15个变量(共占60个字节)，再加上父类的value变量，一共64个 字节。</p><p>为什么追加64字节能够提高并发编程的效率呢?因为对于英特尔酷睿i7、酷睿、Atom和 NetBurst，以及Core Solo和Pentium M处理器的L1、L2或L3缓存的高速缓存行是64个字节宽，不支持部分填充缓存行，这意味着，如果队列的头节点和尾节点都不足64字节的话，处理器可能会将它们都读到同一个高速缓存行中，在多处理器下每个处理器都会缓存同样的头、尾节点，当一个处理器试图修改头节点时，会将整个缓存行锁定，那么在缓存一致性机制的作用下，会导致 其他处理器不能访问自己高速缓存中的尾节点，而队列的入队和出队操作则需要不停修改头节点和尾节点，所以在多处理器的情况下将会严重影响到队列的入队和出队效率。Doug lea使 用追加到64字节的方式来填满高速缓冲区的缓存行，避免头节点和尾节点加载到同一个缓存 行，使头、尾节点在修改时不会互相锁定。</p><p>那么是不是在使用volatile变量时都应该追加到64字节呢?不是的。在两种场景下不应该使用这种方式。</p><ul><li>缓存行非64字节宽的处理器。如P6系列和奔腾处理器，它们的L1和L2高速缓存行是32个 字节宽。</li><li>共享变量不会被频繁地写。因为使用追加字节的方式需要处理器读取更多的字节到高速缓冲区，这本身就会带来一定的性能消耗，如果共享变量不被频繁写的话，锁的几率也非常小，就没必要通过追加字节的方式来避免相互锁定。</li></ul><p>不过这种追加字节的方式在Java7下可能不生效，因为Java 7变得更加智慧，它会淘汰或 重新排列无用字段，需要使用其他追加字节的方式。</p><h1>3、synchronized</h1><p>在多线程并发编程中synchronized一直是元老级角色，很多人都会称呼它为重量级锁。但是，随着 <strong>Java SE 1.6</strong> 对synchronized进行了各种优化之后，有些情况下它就并不那么重了。 下面详细介绍Java SE 1.6中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁，以及锁的存储结构和升级过程。</p><h2 id="1-使用-synchronized-同步的方式"><a class="header-anchor" href="#1-使用-synchronized-同步的方式">¶</a>1. 使用 synchronized 同步的方式</h2><p>先来看下利用synchronized实现同步的基础，Java中的每一个对象都可以作为锁。具体表现为以下3种形式：</p><ul><li>对于普通同步方法，锁是当前实例对象。</li><li>对于静态同步方法，锁是当前类的Class对象。</li><li>对于同步方法块，锁是Synchonized括号里配置的对象。</li></ul><p>当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。</p><p>从JVM规范中可以看到Synchonized在JVM里的实现原理，JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter 和monitorexit指令实现的，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明。但是，方法的同步同样可以使用这两个指令来实现。<br>monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对，即<strong>Java在语言层面已经帮助我们对锁进行维护</strong>。<strong>任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态</strong>。线程执行到monitorenter 指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。</p><h2 id="2-synchronized-的锁"><a class="header-anchor" href="#2-synchronized-的锁">¶</a>2. synchronized 的锁</h2><p>由上面可以知道 Java 中所有对象都可以作为 synchronized 的锁（标志位），而synchronized用的锁是存在 <strong>Java对象头（不是对象体，仅仅对象头）</strong> 里的。如果对象是数组类型，则虚拟机用3个字宽 (Word)(12个字节、96bit)存储对象头，如果对象是非数组类型，则用2字宽(8个字节、64bit)存储对象头。在32位虚拟机中，1字宽 等于4字节，即32bit。<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202352.png" alt="f4b3b5226491637dd876157c9065a151"><br>以上是 Java 对象头结构组成。以32bit 虚拟机为例，可以看到锁相关的信息有：</p><ol><li>23bit 的线程 id</li><li>2bit 的锁标识位</li><li>1bit 的是否偏向锁标识位</li></ol><p>一个对象初始化之后默认状态后三位为001，表示偏向锁无锁状态。</p><h2 id="3、锁的升级和比较"><a class="header-anchor" href="#3、锁的升级和比较">¶</a>3、锁的升级和比较</h2><p>Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，在 Java SE 1.6中，锁一共有4种状态，级别从低到高依次是:无锁状态、偏向锁状态、轻量级锁状 态和重量级锁状态。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202359.png" alt="image-20200421151815413"></p><p>这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率.</p><h3 id="1-偏向锁"><a class="header-anchor" href="#1-偏向锁">¶</a>1. 偏向锁</h3><p>在 Java6和 Java7中偏向锁是默认启用的，而到了 Java8之后是关闭的（默认是轻量级锁），我们可以通过手动设置参数<code>-XX:-UseBiasedLocking=false</code>来关闭或者启用偏向锁。默认情况下，偏向锁是在程序启动几秒之后才激活，如有必要可以使用参数<code>XX:BiasedLockingStartupDelay=0</code>来关闭延迟。</p><h4 id="偏向锁获取"><a class="header-anchor" href="#偏向锁获取">¶</a>偏向锁获取</h4><p>HotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并 获取锁时，会在<strong>对象头和栈帧中的锁记录里</strong>存储锁偏向的线程ID，<strong>以后该线程在进入和退出 同步块时不需要进行CAS操作来加锁和解锁</strong>。<br>在线程尝试获取锁的时候，首先检查对象头中 Mark Word 的后三位是否为101，即检查是否是偏向锁：</p><ul><li>是：检查对象头 MarkWord 的线程 id 标识位是否为当前线程 id：如果是，将直接执行同步代码块</li><li>否：根据当前拥有该偏向锁的线程的状态是否活跃而<strong>升级为轻量级锁</strong>或者进行偏向锁撤销然后重新偏向当前线程。</li></ul><blockquote><p>可以看到，如果已经拥有偏向锁的线程尝试获取偏向锁，是不用再进行较重量的 CAS 操作的，仅进行了一些标志位的判断，纳秒级的区别。</p></blockquote><h4 id="偏向锁撤销"><a class="header-anchor" href="#偏向锁撤销">¶</a>偏向锁撤销</h4><p>另外，在一个拥有偏向锁的<strong>线程A</strong>完成或者异常结束之后，它是不会释放偏向锁的，即回填对象头 markword 中的信息，而是等待下一次其他线程来获取该偏向锁的时候进行撤销。 假设此时一个<strong>线程B</strong>在<strong>线程 A</strong>获得偏向锁之后最早来获取同一个锁对象( 此时锁对象头 markword 中的后三位为101，偏向锁1bit+锁标识2bit)，然后判断获取锁的<strong>线程A</strong>是否还活跃：</p><ul><li>如果还是活跃状态，则需要等到全局安全点，然后暂停该<strong>线程A</strong>，然后在栈帧中创建一个锁记录空间，并将对象头中的 mark word 复制到锁记录空间中，然后使用 CAS 设置锁记录指针到markword，并将锁标识位设置为00（完成轻量级锁升级），然后恢复该线程。当前<strong>线程B</strong>以及晚于线程B进入同步代码块的其他线程都进入轻量级锁的获取流程。</li><li>如果非活跃状态，<strong>线程 B</strong>则会使用 CAS 将对象头中 markword 的线程 id设置为当前线程 id 以及偏向锁标识位为1，完成重新偏向。如果 CAS 设置失败，存在锁竞争，触发上面的流程。</li></ul><h3 id="2-轻量级锁-自旋锁"><a class="header-anchor" href="#2-轻量级锁-自旋锁">¶</a>2. 轻量级锁(自旋锁)</h3><h4 id="轻量级锁获取"><a class="header-anchor" href="#轻量级锁获取">¶</a>轻量级锁获取</h4><p>当前线程(所有进入临界代码区的线程)检查到锁状态为00的时候，进入自旋检查锁状态是否为01**（可以为自旋次数设置一个阈值作为锁膨胀升级为重量级锁的条件，<code>-XX:PreBlockSpink</code>可以进行设置）**，直到拥有轻量级锁的线程执行完成或者异常结束后更新锁状态为01，所有在自旋获取锁的线程通过复制 markword 到锁记录空间然后 CAS 设置markword 指向自己的锁记录空间并设置锁状态为00来获得锁。</p><p>而当自旋线程CAS 失败的时候，说明存在其他线程同时在自旋获取锁**（可以为自旋线程的个数设置一个阈值作为锁膨胀升级为重量级锁的条件）**。此时向 OS 申请互斥量资源，并使用 CAS 设置互斥量资源指针到对象头 markword 并设置锁标识位为10，锁升级为重量级锁。当前线程以及所有其他线程进入重量级锁的获取流程。</p><h4 id="轻量级锁释放"><a class="header-anchor" href="#轻量级锁释放">¶</a>轻量级锁释放</h4><p>在拥有轻量级锁的线程执行完成或者异常结束之后会扫描当前栈帧中的锁记录，从锁记录中取出 markword 的内容 CAS 设置回对象头以及锁标识为01，锁释放成功。</p><blockquote><p>线程的过度自旋会使得 CPU 的过度空转而效率下降，过度自旋可能是拥有锁的线程执行时间过长，也可能是因为过多线程出现竞争锁等。</p></blockquote><h4 id="自适应旋锁"><a class="header-anchor" href="#自适应旋锁">¶</a>自适应旋锁</h4><p>所谓自适应自旋锁就是线程空循环等待的自旋次数并非是固定的，而是会动态着根据实际情况来改变自旋等待的次数。其大概原理是这样的：</p><p>假如一个线程1刚刚成功获得一个锁，当它把锁释放了之后，线程2获得该锁，并且线程2在运行的过程中，此时线程1又想来获得该锁了，但线程2还没有释放该锁，所以线程1只能自旋等待，但是虚拟机认为，<strong>由于线程1刚刚获得过该锁，那么虚拟机觉得线程1这次自旋也是很有可能能够再次成功获得该锁的，所以会延长线程1自旋的次数</strong>。</p><p>另外，如果对于某一个锁，一个线程自旋之后，很少成功获得该锁，那么以后这个线程要获取该锁时，是有可能直接忽略掉自旋过程，直接升级为重量级锁的，以免空循环等待浪费资源。</p><h3 id="3-重量级锁"><a class="header-anchor" href="#3-重量级锁">¶</a>3. 重量级锁</h3><h4 id="重量级锁获取"><a class="header-anchor" href="#重量级锁获取">¶</a>重量级锁获取</h4><p>当前线程(所有进入临界代码区的线程)复制对象头 marword 到当前栈帧，检查到锁状态位：如果是10，直接获取对象头中的互斥量指针向 OS 申请挂起到该互斥量上，陷入内核等待 OS 的唤醒；如果是01，则使用 CAS 设置锁标识位为01来获取锁，获取失败则同样向 OS 申请阻塞到互斥量上。</p><h4 id="重量级锁释放"><a class="header-anchor" href="#重量级锁释放">¶</a>重量级锁释放</h4><p>拥有重量级锁的线程在执行完毕或者异常结束之后，CAS 设置锁状态为01，并向 OS 申请唤醒所有在该互斥量上的所有线程。</p><blockquote><p>可以看到竞争重量级失败的锁需要全部陷入内核阻塞，等待操作系统调度，涉及到用户态和内核态之间的转换，这是比较消耗时间的，所以称之为重量级锁。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202413.png" alt="bc3fae9b2644ebc03b2d4d1d824f01e0"></p><blockquote><p>以上内容可以参考以下 HotSpot 源码：对象头源码markOop.hpp、偏向锁源码 biasedLocking.cpp，以及其他源码ObjectMonitor.cpp和BasicLock.cpp、CAS 操作源码 bytecodeInterpreter.cpp</p></blockquote><h3 id="4-三种锁的对比"><a class="header-anchor" href="#4-三种锁的对比">¶</a>4. 三种锁的对比</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202421.png" alt="image-20200421154117222"></p><h2 id="4-可重入"><a class="header-anchor" href="#4-可重入">¶</a>4. 可重入</h2><p>synchronized 拥有强制原子性的内部锁机制，是一把可重入锁。因此，在一个线程使用 synchronized 方法时调用该对象另一个 synchronized 方法，即一个线程得到一个对象锁后再次请求该对象锁，是永远可以拿到锁的。在 Java 中线程获得对象锁的操作是以线程为单位的，而不是以调用为单位的。 synchronized 锁的对象头的 markwork 中会记录该锁的线程持有者和计数器，当一个线程请求成功后， JVM 会记下持有锁的线程，并将计数器计为1。此时其他线程请求该锁，则必须等待。而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增。当线程退出一个 synchronized 方法/块时，计数器会递减，如果计数器为 0 则释放该锁锁。</p><h2 id="5-悲观锁-互斥锁、排他锁"><a class="header-anchor" href="#5-悲观锁-互斥锁、排他锁">¶</a>5.悲观锁(互斥锁、排他锁)</h2><p>synchronized 是一把悲观锁(独占锁)，所有线程在执行同步块之前必须先获得锁，如果获取不到必须在临界区之外等待，直到抢占到锁为止。</p><p>有一些文章提到上面的轻量级锁是乐观锁，感觉有问题，不应该是乐观锁。如果是乐观锁，那么操作就应该是当前无论是什么级别的锁，都先简单的 test 一下当前锁是否没有被占用，是的话就直接进入临界区，执行同步块，然后再通过 CAS获取乐观锁（而不是每次都直接 CAS，CAS 可以认为就是一个实际上的加锁动作），如果获取失败就需要回滚临界区中执行的逻辑，获取成功就什么也不做。所以这里的回滚动作需要保存进入临界区之前的状态或者保存临界区的一系列操作进行一步步回退，即多版本控制，参考数据库的 MVCC即为一个经典的&quot;乐观锁&quot;。</p><p>如果非要说它是一个乐观锁的话，只能这么解释，每一次都乐观地认为只有一个线程会去获得锁，所以先设置偏向锁或者轻量级锁，如果遇到多个线程竞争锁，再进行升级。（但是这并不是&quot;乐观锁&quot;的定义）。</p><p>另外，CAS 本身并不是一个&quot;乐观锁&quot;，只是乐观锁的组成部分：</p><ol><li>全局定义一个标识位0表示无锁，1表示有锁，初始化为0</li><li>业务操作</li><li>CAS 传入0和1，处理器（硬件）会原子地将标识位现有地值是否和旧值比较：如果相等则设置为传入地新值并返回成功；否则返回失败。<ul><li>如果 CAS 返回成功，说明无锁，并且拿到了锁，写入业务操作修改地共享变量。然后修改标识位为0。</li><li>如果 CAS 返回失败，说明已经有别的线程拿到了锁，回到步骤1重新进行业务操作（基于新地共享变量），直到成功或者超出重试次数。</li></ul></li></ol><p>以上对于 CAS 的应用存在 ABA问题，即当前线程认为标识位是0，即初始版本是0，但是实际上有另一个线程在当前线程访问共享变量之前修改了共享变量，然后在当前线程 CAS 之前先通过 CAS 获得了锁并成功刷新共享变量到主存并释放锁，这对于当前线程是无感知的，它还是傻乎乎地将基于老版本的共享变量地业务操作结果在获得锁之后刷新到主存。</p><p>解决方法就是对锁增加版本，方法如下</p><ol><li>全局定义一个标识位0xx表示无锁，1xx表示有锁，xx 表示版本号，初始化为00</li><li>获取标识位，是否0开头：是，截取当前版本号+1拼接成新标识值；否，循环当前代码直到变为1（或者阻塞）</li><li>业务操作</li><li>CAS 传入旧地标识位和新的拼接地标识位，处理器（硬件）会原子地将标识位现有地值是否和旧值比较：如果相等则设置为传入地新值并返回成功；否则返回失败。<ul><li>如果 CAS 返回成功，说明无锁且无人修改新版本，并且拿到了锁，写入业务操作修改地共享变量。然后修改标识位第一位为0。</li><li>如果 CAS 返回失败，说明已经有别的线程拿到了锁或者当前线程依赖地版本失效了，回到步骤2重新进行业务操作（基于新地共享变量），直到成功或者超出重试次数。</li></ul></li></ol><h1>4、原子操作的实现</h1><p>前面提到，多线程并发编程旨在提高程序效率，但是却带来了访问共享变量引起的冲突，而我们的解决方案有两大方向：</p><ul><li><p>对业务数据进行 hash，不同的线程处理不同数据，即避免访问共享变量。</p></li><li><p>对共享访问或者操作的时候进行加&quot;锁&quot;。</p></li></ul><p>前者实现逻辑较为简单，较为具象。我们主要看后者。</p><h2 id="1-原子操作"><a class="header-anchor" href="#1-原子操作">¶</a>1. 原子操作</h2><p>并发环境下，由于不同线程可能会共享变量，而在一组事务（原子操作）没有完成之前当前线程被打断且共享变量被其他线程进行修改，便可能导致两个线程之间的数据错乱。所以我们需要保证一个临界区之内的只能有一个线程在执行，即在线程到达临界点之后进行线程同步，而在临界区之内的代码即为同步块，同步块中的共享变量为临界资源。</p><p>高级语言的所有线程同步都可以抽象为以上描述。而我们对于临界区的线程同步动作可以放在临界区域起始点，也可以放到临界区域结束位置。</p><ul><li>对于前者，每个线程进入临界区域之前必须通过竞争获取到临界区的进入条件，然后才可以进入临界区执行代码块并访问临界资源，在到达临界区结尾的时候，释放临界区的进入条件。</li><li>对于后者，每个线程直接进入临界区域，但是在访问临界资源的时候复制一个副本进行操作，然后到达临界区域结尾的时候，通过竞争得到临界资源的写入的条件：<ul><li>如果获取得到，先检查当前临界区域中的这些共享变量的值是否发生了变化：如果没有，直接写入临界资源，然后释放该写入条件；如果发生了变化，释放该条件，然后走竞争失败逻辑。</li><li>如果竞争失败，则视具体业务做后续工作：可以放弃这些修改，重新回到临界区域起始点获取临界资源重新执行同步代码；也可以继续竞争写入。</li></ul></li></ul><p>可以看到，前者其实就是悲观锁，后者就是乐观锁。它们的区别是，悲观锁锁定的是同步块中的业务操作；乐观锁锁定的是临界资源刷入内存的动作。所以如果业务操作时间消耗远远大于临界资源刷入内存的动作，如果是悲观锁，临界区锁定时间变长，则总线程等待时间变长；如果使用乐观锁，则总线程等待时间变短；另外如果锁竞争激烈，可能会使用乐观锁维护多版本的代价剧烈上升。</p><p>所以，在业务操作时间过长，且锁竞争相对没有那么激烈的情况，使用乐观锁的收益是较高的。</p><p>可以看到无论是悲观锁还是乐观锁，都要进行&quot;加锁&quot;，所谓加锁，即拥有那么一个标识位，同一时刻只有一个线程可以修改这个标识位，而修改成功则表示这个线程为&quot;锁&quot;的拥有者，其可以对临界区进行访问。所以归根结底，我们需要的是一个原子操作可以原子的修改某个标识位。</p><p>&quot;原子(atomic)本意是“不能被进一步分割的最小粒子”，而原子操作(atomic operation)意为“不可被中断的一个或一系列操作”。在高级语言层面所以具象化的同步操作都是依赖的是操作系统提供的一系列原语（原子指令）来实现。操作系统提供的原语包括有信号量、test_and_set（CAS）、锁、消息传递、栅栏（内存屏障）等操作。而操作系统这些原语的构建又依赖于硬件（门电路逻辑）已有的一些原子操作，包括中断的禁止和启用(关闭线程中断)、内存的加载和写入、test &amp; set(CAS) 等。</p><p>当然，硬件提供这些原子操作不是因为它们预见到研究操作系统的人将来有这个需要，而是硬件设计师需要这些原子操作来对其涉及进行各种测试，操作系统对其利用只不过是一个副产品而已。</p><h2 id="2、处理器实现原子操作的一些例子"><a class="header-anchor" href="#2、处理器实现原子操作的一些例子">¶</a>2、处理器实现原子操作的一些例子</h2><p>32位IA-32处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操 作。首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存中读取或者写 入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节 的内存地址。Pentium 6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位 的操作是原子的，但是复杂的内存操作处理器是不能自动保证其原子性的，比如跨总线宽度、跨多个缓存行和跨页表的访问。但是，处理器提供总线锁定和缓存锁定两个机制来保证复杂 内存操作的原子性。</p><h3 id="锁总线"><a class="header-anchor" href="#锁总线">¶</a>锁总线</h3><p>当多个处理器对多个共享变量进行访问的时候，可能会出现交叉访问的情况，导致数据错误，此时处理器可以使用总线锁来解决这个问题。所谓总线锁就是使用处理器提供的一个 LOCK#信号，LOCK 指令是一个汇编层面的指令，在一些特殊的场景下，作为前缀加在以下汇编指令之前，保证操作的原子性，这种指令被称为 “LOCK前缀指令”。</p><pre><code>ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG,DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, and XCHG.</code></pre><p>LOCK前缀导致处理器在执行指令时会置上LOCK#信号，于是该指令就被作为一个原子指令（atomic instruction）执行。在多处理器环境下，置上LOCK#信号可以确保任何一个处理器能独占使用任何共享内存。这种方式代价太大。</p><h3 id="锁缓存"><a class="header-anchor" href="#锁缓存">¶</a>锁缓存</h3><p>在Pentium4、Inter Xeon和P6系列以及之后的处理器中，LOCK＃信号一般不锁总线，而是锁缓存，毕竟锁总线开销的比较大。</p><p>在所有的 X86 CPU 上都具有锁定一个特定内存地址的能力，当这个特定内存地址被锁定后，它就可以阻止其它的系统总线读取或修改这个内存地址。这种能力是通过 LOCK 指令前缀再加上具体操作（如ADD）的汇编指令来实现的。当使用 LOCK 指令前缀时，它会使 CPU 宣告一个 LOCK# 信号，处理器不在总线上声 言LOCK#信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子 性，因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据。</p><p>处理器使用<strong>嗅探技术</strong>保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致。<strong>例如CPU A嗅探到CPU B打算写内存地址，且这个地址处于共享状态</strong>，那么正在嗅探的处理器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充。</p><h2 id="3、Java-实现原子操作的一个例子"><a class="header-anchor" href="#3、Java-实现原子操作的一个例子">¶</a>3、Java 实现原子操作的一个例子</h2><p>在Java中可以通过锁和循环CAS的方式来实现原子操作。</p><h3 id="1-使用循环-CAS-实现直接对共享变量的原子操作"><a class="header-anchor" href="#1-使用循环-CAS-实现直接对共享变量的原子操作">¶</a>(1)使用循环 CAS 实现直接对共享变量的原子操作</h3><p>JVM中的CAS操作正是利用了处理器提供的CMPXCHG指令实现的。自旋CAS实现的基本 思路就是循环进行CAS操作直到成功为止，参考juc 包下的<code>AtomicInteger</code>类，很多方法都调用了<code>sun.misc.Unsafe#compareAndSwapInt</code>，例如：</p><pre class="line-numbers language-language-java"><code class="language-language-java">public final int updateAndGet(IntUnaryOperator updateFunction) {        int prev, next;        do {            prev = get();            next = updateFunction.applyAsInt(prev);        //调用本地方法        } while (!compareAndSet(prev, next));        return next;}public final boolean compareAndSet(int expect, int update) {  //该本地方法直接调用sun.misc.Unsafe#compareAndSwapInt        return unsafe.compareAndSwapInt(this, valueOffset, expect, update);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>而这个方法是一个 native 方法，底层就是依赖的处理器提供的 CMPXCHG 实现的。</p><h3 id="2-CAS-直接实现原子操作变量地三大问题"><a class="header-anchor" href="#2-CAS-直接实现原子操作变量地三大问题">¶</a>(2)CAS 直接实现原子操作变量地三大问题</h3><p>Java juc 包下基本都是循环 CAS。</p><h4 id="1-ABA-问题"><a class="header-anchor" href="#1-ABA-问题">¶</a>&lt;1&gt;ABA 问题</h4><p>参考3.5中悲观锁地描述。<code>AtomicStampedReference</code>是 Jdk1.5提供地解决 ABA 问题地。</p><h4 id="2-循环时间长CPU开销大"><a class="header-anchor" href="#2-循环时间长CPU开销大">¶</a>&lt;2&gt;循环时间长CPU开销大</h4><p>略。</p><h4 id="3-只能保证一个共享变量地原子操作"><a class="header-anchor" href="#3-只能保证一个共享变量地原子操作">¶</a>&lt;3&gt;只能保证一个共享变量地原子操作</h4><p>用锁；或者合并多个变量到一个变量进行操作，操作完之后再拆解；<code>AtomicReference</code>是 Jdk1.5提供地一个可以对引用类型对象进行 CAS 地一个类，可以实现该操作。</p><h3 id="3-使用悲观锁机制实现原子操作"><a class="header-anchor" href="#3-使用悲观锁机制实现原子操作">¶</a>(3)使用悲观锁机制实现原子操作</h3><p>悲观锁机制保证了只有获得锁的线程才能够操作锁定的内存区域。JVM内部实现了很多种锁机制，有偏向锁、轻量级锁和互斥锁。有意思的是除了偏向锁，JVM实现锁的方式都用了循环 CAS，即当一个线程想进入同步块的时候使用循环CAS的方式来获取锁，当它退出同步块的时候使用循环CAS释放锁。</p>]]></content>
      
      
      <categories>
          
          <category> Java并发编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java并发编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 并发编程艺术读书草稿</title>
      <link href="/2020/12/22/bing-fa-bian-cheng/java-bing-fa-bian-cheng-yi-zhu-du-shu-cao-gao/"/>
      <url>/2020/12/22/bing-fa-bian-cheng/java-bing-fa-bian-cheng-yi-zhu-du-shu-cao-gao/</url>
      
        <content type="html"><![CDATA[<p>在并发编程中,需要处理两个关键问题:线程之间如何通信及线程之间如何同步。通信是指线程之间以何种机制来交换信息。在命令式编程中,线程之间的通信机制有两种:<strong>共享内存和消息传递</strong><sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>。</p><ul><li><p>在共享内存的并发模型里,线程之间共享程序的公共状态,通过写-读内存中的公共状态进行隐式通信。</p></li><li><p>在消息传递的并发模型里,线程之间没有公共状态,线程之间必须通过发送消息来显式进行通信<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>。</p></li></ul><p>同步是指程序中用于控制不同线程间操作发生相对顺序的机制。在共享内存并发模型里,同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里,由于消息的发送必须在消息的接收之前,因此同步是隐式进行的<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>。</p><p>Java的并发采用的是共享内存模型。</p><h1>Java内存模型的抽象结构</h1><p>在Java中,所有实例域、静态域和数组元素(统称共享变量)都存储在堆内存中,堆内存在线程之间共享。局部变量(Local Variables),方法定义参数(Java语言规范称之为Formal Method Parameters)和异常处理器参数(Exception Handler Parameters)不会在线程之间共享,它们不会有内存可见性问题,也不受内存模型的影响。</p><p>Java内存模型(JMM)旨在定义一个线程如何对共享变量进行访问以及共享变量对于各线程的可见性。JMM在抽象的角度定义了共享变量存储在主内存(Main Memory)中，每一个线程都有一个本地内存(Local Memory)，线程每次对主存中共享变量的访问、操作都必须加载一份副本到本地内存中进行。<strong>所以不同线程之间的通信必须基于某一个主存中的共享变量进行</strong>。本地内存是JMM的一个抽象概念,并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。</p><h3 id="指令重排序"><a class="header-anchor" href="#指令重排序">¶</a>指令重排序</h3><p>在执行程序时,为了提高性能,编译器和处理器常常会对指令做重排序。重排序分3种类型。</p><ol><li>编译器优化的重排序(可以理解为各种编译器: javac、JIT、C++)。编译器在不改变单线程程序语义的前提下,可以重新安排语句的执行顺序。</li><li>指令级并行的重排序。现代处理器采用了指令级并行技术(Instruction-Level Parallelism,ILP)来将多条指令重叠执行。如果不存在数据依赖性,处理器可以改变语句对应机器指令的执行顺序。</li><li>内存系统的重排序。由于处理器使用缓存和读/写缓冲区,这使得加载和存储操作看上去可能是在乱序执行。<br>从Java源代码到最终实际执行的指令序列,会分别经历下面3种重排序,</li></ol><p>从Java源代码到最终实际执行的指令序列,会分别经历下面3种重排序</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202613.png" alt="image-20200924195705355"></p><p>上述的1属于编译器重排序,2和3属于处理器重排序。这些重排序可能会导致多线程程序出现内存可见性问题。</p><ul><li><p>对于编译器,JMM的<strong>编译器重排序规则</strong>会禁止特定类型的编译器重排序(不是所有的编译器重排序都要禁止)。</p></li><li><p>对于处理器重排序,JMM的处理器重排序规则会要求Java编译器在生成指令序列时,插入特定类型的内存屏障(Memory Barriers,Intel称之为Memory Fence)指令,通过内存屏障指令来禁止特定类型的处理器重排序。</p></li></ul><p>JMM属于语言级的内存模型,它确保在不同的编译器和不同的处理器平台之上,通过禁止特定类型的编译器重排序和处理器重排序,为程序员提供一致的内存可见性保证。</p><p>现代的处理器使用写缓冲区临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行,它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时,通过以批处理的方式刷新写缓冲区,以及合并写缓冲区中对同一内存地址的多次写,减少对内存总线的占用。虽然写缓冲区有这么多好处,但每个处理器上的写缓冲区,仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响:处理器对内存的读/写操作的执行顺序,不一定与内存实际发生的读/写操作顺序一致!</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202619.png" alt="image-20200924200533742"></p><p>从正常逻辑看来，无论哪个处理器先执行到第二步赋值，其对应的第一步赋值肯定发生了，所以不可能最终结果x和y都是0。但是如果发生了指令重排：</p><ol><li>A写入a=1到写缓冲区</li><li>然后就从主存加载b的值到工作内存，此时B未对b进行操作，得到值为0，然后将x=b=0写入到写缓冲区</li><li>此时B开始写b=2到写缓冲区，然后直接从主存加载a的值，此时A的写缓冲区还没刷，所以得到是0，直接将y=a=0写入到写缓冲区</li><li>此时A和B才开始刷写缓冲区，最终主存中的值：a=1、b=2、x=y=0</li></ol><p>需要注意，这里的操作对于处理器A、B的视角来说都是没问题的，但是对于主存来说、或者对于我们程序员来说，明显数据错乱了，在直观上发生了指令的重排序，即原本<code>a=1</code>、<code>b=2</code>要先于<code>x=b</code>、<code>y=a</code>执行的，虽然开始顺序是这样的，但是实际顺序却反过来了。另外这种重排序还和处理器使用旁路实现的重排序还不一样，对于使用旁路实现的重排序即使遇到控制条件的时候也是可以进行的，此时处理器会做出分支预测，先根据经验预测出哪个条件会成立然后先执行该条件分支指令，然后把计算结果临时保存到一个名为重排序缓冲(Reorder Buffer,ROB)的硬件缓存中，如果等待控制条件真正计算出来之后进行比较，如果预测正确则将之前计算的结果取出来正常往下走，如果预测错误了，需要进行回退重新执行<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>。</p><p>由于现代的处理器都会使用写缓冲区,因此现代的处理器都会允许对写-读操作进行重排序。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202626.png" alt="image-20200924201714088"></p><p>常见的处理器都允许Store-Load重排序;常见的处理器都不允许对存在数据依赖的操作做重排序。sparc-TSO和X86拥有相对较强的处理器内存模型,它们仅允许对写-读操作做重排序(因为它们都使用了写缓冲区)。</p><h4 id="as-if-serial语义和数据依赖"><a class="header-anchor" href="#as-if-serial语义和数据依赖">¶</a>as-if-serial语义和数据依赖</h4><p>as-if-serial语义的意思是:不管怎么重排序(编译器和处理器为了提高并行度),(单线程) 程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。</p><p>为了遵守as-if-serial语义,编译器和处理器不会对在单个处理器中执行的指令序列和单个线程中存在数据依赖关系的操作做重排序,因为这种重排序会改变执行结果。但是,如果操作之间不存在数据依赖关系或者是不同处理器之间和不同线程之间的数据依赖操作, 就可能被编译器和处理器重排序。</p><p>如果两个操作访问同一个变量,且这两个操作中有一个为写操作,此时这两个操作之间就存在数据依赖性。数据依赖分为下列3种类型</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202632.png" alt="image-20200924203424014"></p><p>上面3种情况,只要重排序两个操作的执行顺序,程序的执行结果就会被改变。编译器和处理器在重排序时,会遵守数据依赖性,编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。</p><h4 id="happen-before和内存屏障"><a class="header-anchor" href="#happen-before和内存屏障">¶</a>happen-before和内存屏障</h4><p>在JMM中,如果一个操作执行的结果需要对另一个操作可见,那么这两个操作之间必须要存在happens-before关系：参考<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup></p><p>为了保证内存可见性,Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM把内存屏障指令分为4类：参考<sup class="footnote-ref"><a href="#fn5" id="fnref5:1">[5:1]</a></sup></p><h4 id="顺序一致性内存模型"><a class="header-anchor" href="#顺序一致性内存模型">¶</a>顺序一致性内存模型</h4><p>顺序一致性内存模型是一个理论参考模型,在设计的时候,处理器的内存模型和编程语言的内存模型都会以顺序一致性内存模型作为参照。</p><p>JMM会在退出临界区和进入临界区这两个关键时间点做一些特别处理,使得线程在这两个时间点具有与顺序一致性模型相同的内存视图(具体细节后文会说明)。虽然线程A在临界区内做了重排序,但由于监视器互斥执行的特性,这里的线程B根本无法“观察”到线程A在临界区内的重排序。这种重排序既提高了执行效率,又没有改变程序的执行结果。</p><h4 id="volatile"><a class="header-anchor" href="#volatile">¶</a>volatile</h4><ul><li>可见性。对一个volatile变量的读,总是能看到(任意线程)对这个volatile变量最后的写入(例如64位操作数)。</li><li>原子性:对任意单个volatile变量的读/写具有原子性,但类似于volatile++这种复合操作不具有原子性。</li></ul><h5 id="volatile内存语义"><a class="header-anchor" href="#volatile内存语义">¶</a>volatile内存语义</h5><p>volatile写的内存语义如下：当写一个volatile变量时,JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。</p><p>volatile读的内存语义如下：当读一个volatile变量时,JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。</p><p>如果我们把volatile写和volatile读两个步骤综合起来看的话：在绝对时间上来说，在读线程B读一个volatile变量发生之前，如果写线程A对这个volatile变量发生了写操作，那么线程A中该操作及之前(在代码定义上的顺序)所有可见的共享变量的值都在将读线程B读取volatile变量之后立即变得对读线程B可见。</p><pre class="line-numbers language-language-java"><code class="language-language-java">volatile int a = 0;int b = 1;public void compute() {}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="volatile内存语义的实现"><a class="header-anchor" href="#volatile内存语义的实现">¶</a>volatile内存语义的实现</h5><p>重排序分为编译器重排序和处理器重排序。为了实现volatile内存语义,JMM 会分别限制这两种类型的重排序类型。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202638.png" alt="image-20200925090341636"></p><ol><li><p>当第二个操作是volatile写时,不管第一个操作是什么,都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。</p><ol><li>对于写操作的限制很明显，任何线程对于一个volatile的写都会导致它的写缓冲区原子地刷新到主存，无论写缓冲区是否由于CPU的乱序执行导致写入顺序和代码不一致，但是对于单线程来说，CPU的乱序执行的前提是不会破坏as-if-serial语义，所以保证了进行volatile写操作的线程之前的所有写操作对于其它线程都变得可见</li><li>对于读操作的限制是</li></ol></li><li><p>当第一个操作是volatile读时,不管第二个操作是什么,都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。</p></li><li><p>当第一个操作是volatile写,第二个操作是volatile读时,不能重排序。</p></li></ol><p>为了实现volatile的内存语义,编译器在生成字节码时,会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说,发现一个最优布置来最小化插入屏障的总数几乎不可能。为此,JMM采取保守策略。下面是基于<strong>保守</strong>策略的JMM内存屏障插入策略。</p><ul><li>在每个volatile写操作的前面插入一个StoreStore屏障。</li><li>在每个volatile写操作的后面插入一个StoreLoad屏障。</li><li>在每个volatile读操作的后面插入一个LoadLoad屏障。</li><li>在每个volatile读操作的后面插入一个LoadStore屏障。</li></ul><p>上述内存屏障插入策略非常保守,但它可以保证在任意处理器平台,任意的程序中都能得到正确的volatile内存语义。</p><p>下面是保守策略下,volatile写插入内存屏障后生成的指令序列示意图</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202644.png" alt="image-20200925090951619"></p><p>StoreStore屏障可以保证在volatile写之前,其前面的所有普通写操作已经对任意处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。</p><p>这里比较有意思的是,volatile写后面的StoreLoad屏障。此屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序。因为编译器常常无法准确判断在一个volatile写的后面是否需要插入一个StoreLoad屏障(比如,一个volatile写之后方法立即return)。为了保证能正确实现volatile的内存语义,JMM在采取了保守策略:在每个volatile写的后面,或者在每个volatile 读的前面插入一个StoreLoad屏障。从整体执行效率的角度考虑,JMM最终选择了在每个volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是:一个写线程写volatile变量,多个读线程读同一个volatile变量。当读线程的数量大大超过写线程时, 选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里可以看到JMM 在实现上的一个特点:首先确保正确性,然后再去追求执行效率。</p><p>下面是在保守策略下,volatile读插入内存屏障后生成的指令序列示意图</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202650.png" alt="image-20200925091029135"></p><p>LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。<br>LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。<br>上述volatile写和volatile读的内存屏障插入策略非常保守。在实际执行时,只要不改变volatile写-读的内存语义,编译器可以根据具体情况省略不必要的屏障。下面通过具体的示例代码进行说明。</p><pre class="line-numbers language-language-java"><code class="language-language-java">class VolatileBarrierExample {    int a;    volatile int v1 = 1;    volatile int v2 = 2;    void readAndWrite() {        int i = v1;      // 第一个volatile读        int j = v2;       // 第二个volatile读        a = i + j;         // 普通写        v1 = i + 1;       // 第一个volatile写        v2 = j * 2;       // 第二个 volatile写    }    //…               // 其他方法}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202657.png" alt="image-20200925091729146"></p><p>注意,最后的StoreLoad屏障不能省略。因为第二个volatile写之后,方法立即return。此时编译器可能无法准确断定后面是否会有volatile读或写,为了安全起见,编译器通常会在这里插入一个StoreLoad屏障。<br>上面的优化针对任意处理器平台,由于不同的处理器有不同“松紧度”的处理器内存模型,内存屏障的插入还可以根据具体的处理器内存模型继续优化。以X86处理器为例,图3-21 中除最后的StoreLoad屏障外,其他的屏障都会被省略。<br>前面保守策略下的volatile读和写,在X86处理器平台可以优化成如图3-22所示。<br>前文提到过,X86处理器仅会对写-读操作做重排序。X86不会对读-读、读-写和写-写操作做重排序,因此在X86处理器中会省略掉这3种操作类型对应的内存屏障。在X86中,JMM仅需在volatile写后面插入一个StoreLoad屏障即可正确实现volatile写-读的内存语义。这意味着在X86处理器中,volatile写的开销比volatile读的开销会大很多(因为执行StoreLoad屏障开销会比较大)。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202704.png" alt="image-20200925091926612"></p><h4 id="JSR-133为什么要增强volatile的内存语义"><a class="header-anchor" href="#JSR-133为什么要增强volatile的内存语义">¶</a>JSR-133为什么要增强volatile的内存语义</h4><p>在JSR-133之前的旧Java内存模型中,虽然不允许volatile变量之间重排序,但旧的Java内存模型允许volatile变量与普通变量重排序。在旧的内存模型中,VolatileExample示例程序可能被重排序成下列时序来执行,如图3-23所示。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221202709.png" alt="image-20200925092200374"></p><p>在旧的内存模型中,当1和2之间没有数据依赖关系时,1和2之间就可能被重排序(3和4类似)。其结果就是:读线程B执行4时,不一定能看到写线程A在执行1时对共享变量的修改。</p><p>因此,在旧的内存模型中,volatile的写-读没有锁的释放-获所具有的内存语义。为了提供一种比锁更轻量级的线程之间通信的机制,JSR-133专家组决定增强volatile的内存语义:严格限制编译器和处理器对volatile变量与普通变量的重排序,确保volatile的写-读和锁的释放-获取具有相同的内存语义。从编译器重排序规则和处理器内存屏障插入策略来看,只要volatile 变量与普通变量之间的重排序可能会破坏volatile的内存语义,这种重排序就会被编译器重排序规则和处理器内存屏障插入策略禁止。</p><p>由于volatile仅仅保证对单个volatile变量的读/写具有原子性,而锁的互斥执行的特性可以确保对整个临界区代码的执行具有原子性。在功能上,锁比volatile更强大;在可伸缩性和执行性能上,volatile更有优势。如果读者想在程序中用volatile代替锁,请一定谨慎</p><h1>疑问集合</h1><p><a href="https://zhuanlan.zhihu.com/p/43526907" target="_blank" rel="noopener">知乎：volatile与内存屏障总结</a></p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>消息传递是怎么做？不应该是进程通信吗？何来线程通信，同一进程之内的线程本身就是共享进程资源，仅是其线程域内资源独享，跨进程线程通信不就是进程通信么？ <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>需要复习下进程间通信知识 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>不懂什么意思 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>复习指令级并行下对指令重排序的部分知识 <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>file:///Users/zhonghongpeng/笔记/并发编程/艺术.md <a href="#fnref5" class="footnote-backref">↩︎</a> <a href="#fnref5:1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
      
      
      <categories>
          
          <category> Java并发编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java并发编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目笔记草稿</title>
      <link href="/2020/12/22/shi-zhan-xiang-mu-bi-ji/untitled/"/>
      <url>/2020/12/22/shi-zhan-xiang-mu-bi-ji/untitled/</url>
      
        <content type="html"><![CDATA[<ol><li><p>数据库外键去除</p><ol><li>外键检查降低性能</li><li>耦合性太高，有时候两个关系表不一定在同一个库</li></ol></li><li><p>SpringBoot自动装配：</p><ol><li>@SpringBootApplication<ol><li>@SpringBootConfiguration</li><li>@ComponentScan：排除一些bean</li><li>@EnableAutoConfiguration<ol><li>@AutoConfigurationPacakge</li><li>@Import(AutoConfigurationImportSelector.class)<ol><li>META-INF/spring.factories<ol><li>AutoConfig<ol><li>@EnableConfigurationProperties</li><li>@ConditionalOnXxx</li><li>@AutoConfigureAfterXxx</li><li>…</li></ol></li></ol></li></ol></li></ol></li></ol></li></ol></li><li><p>Spring事务传播</p><ul><li><p>REQUIRED</p></li><li><p>REQUIRES_NEW：调用方(上层)发生异常不会影响被调用方</p></li><li><p>MANDATORY</p></li><li><p>SUPPORTS</p></li><li><p>NEVER</p></li><li><p>NOT_SUPPORTED</p></li><li><p>NESTED</p><ul><li>如果当前已有事务，则挂起当前事务，然后开启一个子事务(SAVEPOINT)<ul><li>调用者(父事务)提交，所有子事务(savepoint)提交</li><li>调用者(父事务)回滚，所有子事务(savepoint)回滚</li><li>子事务(savepoint)提交和回滚，不影响父事务(其它子事务)的提交和回滚</li><li>只有父事务发生提交和回滚后，子事务才会被其它事务可见</li></ul></li><li>如果当前没事务，同 REQUIRED</li></ul></li></ul></li><li><p>SpringBoot 默认提供的 spring.factories 里面包含了事务配置(TransactionAutoConfiguration)，无需 @EnableTransactionManager</p></li><li><p>AOP 实现每个调用记录调用时间与日志打印</p></li><li><p>分类连接查询的一对多关系使用 MyBatis 的 ResultMap 直接实现</p></li><li><p>用延时队列替换springboot scheduler 实现订单超时关闭</p></li><li><p>nginx</p><ol><li><p>模型：master-workers-connections</p></li><li><p>信号通信</p></li><li><p>IO多路复用、非阻塞</p></li><li><p>配置文件</p><pre><code>                     nginx.conf 配置结构+----------------------------------------------------------------------+| main全局配置                                                          || +-----------------------------------------------------------------+  || |event 配置工作模式以及连接数                                         |  || +-----------------------------------------------------------------+  ||                                                                      || +-----------------------------------------------------------------+  || |http http模块相关配置                                              |  || |                                                                 |  || |                                                                 |  || | +-------------------------------------------------------------+ |  || | |server 虚拟主机配置，可以有多个                                  | |  || | |                                                             | |  || | | +---------------------------------------------------------+ | |  || | | |location 路由规则，表达式                                   | | |  || | | |                                                         | | |  || | | +---------------------------------------------------------+ | |  || | |                                                             | |  || | | +---------------------------------------------------------+ | |  || | | |upstream 集群，内网服务器                                   | | |  || | | |                                                         | | |  || | | +---------------------------------------------------------+ | |  || | +-------------------------------------------------------------+ |  || +-----------------------------------------------------------------+  |+----------------------------------------------------------------------+</code></pre><ul><li>location：静态资源</li></ul></li><li><p>nginx -s stop 暴力停止</p></li><li><p>nginx -s quit 优雅停止</p></li><li><p>nginx -t 检查配置文件格式</p></li><li><p>nginx -c <code>file-path</code> 设置配置文件</p></li><li><p>利用linux定时任务定时切割日志</p></li><li><p>指令</p><ul><li>include：将指定文件内容拷贝到当前配置文件中替换当前include</li></ul></li></ol></li><li><p>redis</p><ul><li>无磁盘主从赋值，直接写socket，不写RDB文件</li><li>max memory 选项设置最大内存</li><li>MAXMEMORY POLICY 设置淘汰策略<ul><li>valatile-lru：在设置了超时时间的key里进行lru删除</li><li>allkeys-lru：在所有key里进行lru</li><li>valatile-lfu</li><li>allkeys-lfu</li><li>valatile-random</li><li>allkeys-random</li><li>valatile-ttl：将快要过期的删除</li><li>noeviction：不删除</li></ul></li><li>缓存穿透：布隆过滤器缺点，一旦某个hash添加之后就无法删除，因为可能有多个数据hash到同一个槽，无法确定该槽是否有多个数据；另外还需要额外维护一层</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 随记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>00_前言</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/00-qian-yan/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/00-qian-yan/</url>
      
        <content type="html"><![CDATA[<p>[toc]</p><h1>JDK、JRE、JVM</h1><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232754.png" alt="JDK_JRE_JVM"></p><h1>JVM整体结构</h1><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232801.png" alt="image-20200910105340576"></p><ul><li>整个结构分为上、中、下层。</li><li>第一层类装载器子系统负责将class文件从文件系统加载到内存中成为一个JVM的class对象结构，分为加载、链接、初始化。</li><li>方法区、堆所有线程共享；虚拟机栈(Java栈)、本地方法栈、程序计数器线程私有。</li><li>生成Class文件的过程是前端编译，执行引擎中涉及的翻译字节码解释执行和JIT中的即使编译执行为后端编译</li></ul><h1>Java代码执行流程</h1><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232808.png" alt="image-20200910111130207"></p><h1>JVM的架构模型</h1><p>Java编译器输入的指令流基本上是一种基于栈的指令集架构，另外一种指令集架构则是基于寄存器的指令架构。</p><p>具体来说，这两种架构之间的区别：</p><ul><li>基于栈式架构的特点：<ul><li>设计和实现更简单，适用于资源受限的系统</li><li>避开了寄存器的分配难题：使用零地址指令方式分配</li><li>指令流中的指令大部分是零地址指令，其执行过程依赖于操作栈。指令集更小，编译器容易实现。</li><li>不需要硬件支持，可移植性好，更好实现跨平台</li></ul></li><li>基于寄存器架构的特点<ul><li>典型的应用是x86的二进制指令集：比如传统的PC以及Android的Davlik虚拟机。</li><li>指令集架构则完全依赖硬件，可移植性差</li><li>性能优秀和执行更高效</li><li>花费更少的指令去完成一项操作</li><li>在大部分情况下，基于寄存器架构的指令集往往都以一地址指令、二地址指令和三地址指令为主，而基于栈式架构的指令集却是以零地址指令为主。</li></ul></li></ul><blockquote><p>栈式架构即函数(方法)的实现是将函数中每一行代码要操作的所有变量不断压栈或者弹栈，使得待操作的变量永远存在栈顶，而操作指令则永远操作栈顶即可，所以无需在指令中包含操作数的地址，而是仅仅包含操作指令即可。</p><p>而寄存器架构则是将方法中的变量按照语言自己设计的一套规则分配到不同的寄存器中，这样函数中访问变量的代码也要按照这套规则去获取具体变量的寄存器地址进行访问。</p><p>很明显，前者确实更通用(不依赖具体硬件下可能不同的寄存器组)、容易实现(无需额外设计一套寄存器分配规则)。但是因为要将变量压栈入栈使得待操作数永远存在栈顶也使得增添了一些额外操作使得效率没有后者高。</p></blockquote><ul><li>栈式架构的指令集中指令为8位指令；寄存器架构的指令集中指令大多为16位指令。</li></ul><h3 id="Java字节码指令架构和x86指令架构区别示例"><a class="header-anchor" href="#Java字节码指令架构和x86指令架构区别示例">¶</a>Java字节码指令架构和x86指令架构区别示例</h3><h4 id="示例一"><a class="header-anchor" href="#示例一">¶</a>示例一</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232814.png" alt="image-20200910112820981"></p><h4 id="示例二"><a class="header-anchor" href="#示例二">¶</a>示例二</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232825.png" alt="image-20200910113850389"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232830.png" alt="image-20200910113925569"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232837.png" alt="image-20200910113941979"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232842.png" alt="image-20200910113957240"></p><h3 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h3><p>由于跨平台性的设计，Java的指令都是根据栈来设计的。不同平台CPU架构不同，所以不能设计为基于寄存器的。优点是跨平台，指令集小，编译器容易实现，缺点是性能下降，实现同样的功能需要更多的指令。</p><h1>JVM生命周期</h1><h3 id="虚拟机的启动"><a class="header-anchor" href="#虚拟机的启动">¶</a>虚拟机的启动</h3><p>Java虚拟机的启动是通过引导类加载器(bootstrap class loader)创建一个初始类(initial class)来完成的，这个类是由虚拟机的具体实现指定的。</p><h3 id="虚拟机的执行"><a class="header-anchor" href="#虚拟机的执行">¶</a>虚拟机的执行</h3><ul><li>一个运行中的Java虚拟机有着一个清晰的任务：执行Java程序。</li><li>程序开始执行时他才运行，程序结束时他就停止。</li><li>执行一个所谓的Java程序的时候，真真正正在执行的是一个叫做Java虚拟机的进程。</li></ul><h3 id="虚拟机的退出"><a class="header-anchor" href="#虚拟机的退出">¶</a>虚拟机的退出</h3><ul><li>程序正常执行结束</li><li>程序在执行过程中遇到了异常或错误而异常终止</li><li>由于操作系统出现错误而导致Java虚拟机进程终止</li><li>某线程调用Runtime类或System类的exit方法，或Runtime类的halt方法，并且Java安全管理器也允许这次exit或halt操作</li><li>除此之外，JNI(Java Native Interface)规范描述了用JNI Invocation API来加载或卸载Java虚拟机时，Java虚拟机的退出情况。</li></ul><h1>JVM发展历程</h1><h3 id="Sun-Classic-VM"><a class="header-anchor" href="#Sun-Classic-VM">¶</a>Sun Classic VM</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232850.png" alt="image-20200910115805813"></p><h3 id="Exact-VM"><a class="header-anchor" href="#Exact-VM">¶</a>Exact VM</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232930.png" alt="image-20201221232930708"></p><h3 id="Hotspot-VM"><a class="header-anchor" href="#Hotspot-VM">¶</a>Hotspot VM</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232942.png" alt="image-20200910120152236"></p><h3 id="JRockit"><a class="header-anchor" href="#JRockit">¶</a>JRockit</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233052.png" alt="image-20201221233027415"></p><p>被Oracle收购，合并到Hotspot中。</p><h3 id="J9"><a class="header-anchor" href="#J9">¶</a>J9</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233123.png" alt="image-20201221233123222"></p><h3 id="KVM、CDC-CLDC-Hotspot"><a class="header-anchor" href="#KVM、CDC-CLDC-Hotspot">¶</a>KVM、CDC/CLDC Hotspot</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233146.png" alt="image-20201221233146559"></p><h3 id="Azul-VM"><a class="header-anchor" href="#Azul-VM">¶</a>Azul VM</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233210.png" alt="image-20201221233209968"></p><h3 id="Liquid-VM"><a class="header-anchor" href="#Liquid-VM">¶</a>Liquid VM</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233233.png" alt="image-20201221233233601"></p><h3 id="Apache-Harmony"><a class="header-anchor" href="#Apache-Harmony">¶</a>Apache Harmony</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233244.png" alt="image-20200910150654952"></p><h3 id="Microsoft-JVM"><a class="header-anchor" href="#Microsoft-JVM">¶</a>Microsoft JVM</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233303.png" alt="image-20201221233303518"></p><h3 id="TaobaoJVM"><a class="header-anchor" href="#TaobaoJVM">¶</a>TaobaoJVM</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233321.png" alt="image-20201221233321106"></p><h3 id="DalvikVM"><a class="header-anchor" href="#DalvikVM">¶</a>DalvikVM</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233328.png" alt="image-20200910151317561"></p><h3 id="其他JVM"><a class="header-anchor" href="#其他JVM">¶</a>其他JVM</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233336.png" alt="image-20200910151532648"></p><h3 id="Graal-VM"><a class="header-anchor" href="#Graal-VM">¶</a>Graal VM</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233342.png" alt="image-20200910151904547"></p><h1><a href="https://docs.oracle.com/javase/specs/index.html" target="_blank" rel="noopener">JVM规范</a>主要内容</h1><ol><li>字节码指令集（相当于中央处理器CPU）</li><li>Class文件的格式</li><li>数据类型和值(范围、实现方式)</li><li>运行时数据区</li><li>栈帧</li><li>特殊方法的实现<ol><li><p><code>&lt;init&gt;</code>：这个不是我们定义的构造方法，是虚拟机内置的一个创建实例的方法，如果我们有给一个类定义实例成员变量并且赋值，那么这些实例成员变量将会在这个方法里面进行真正的赋值。通过JVM的<code>invokespecial</code>指令来调用。</p><p>虚拟机会在我们写的构造方法中将对<code>&lt;init&gt;</code>方法的调用代码以及构造代码块中的代码合并到构造方法的最前面，<code>&lt;init&gt;</code>作为这个特殊方法的符号引用存在。所以new一个对象的过程为：</p><ol><li>为对象分配内存</li><li>调用<code>&lt;init&gt;</code>方法初始化我们赋值的成员变量</li><li>执行构造代码块中代码</li><li>执行构造函数中代码</li></ol></li><li><p><code>&lt;clinit&gt;</code>：类或者接口的初始化方法，不包含参数，返回void，不是我们写的静态代码块，虚拟机会根据我们是否定义了静态代码块或者对静态变量进行了赋值而构造一个该方法进行执行。</p></li></ol></li><li>需要支持一些类库<ol><li>反射</li><li>加载和创建类或接口，如ClassLoader</li><li>连接和初始化类和接口的类</li><li>安全，如security</li><li>多线程</li><li>弱引用</li></ol></li><li>异常处理</li><li>虚拟机的启动、加载、链接和初始化，包括字节码的执行引擎</li></ol>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>05_堆</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/05-dui/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/05-dui/</url>
      
        <content type="html"><![CDATA[<h1>堆的核心概述</h1><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234342.png" alt="image-20200916075349717"></p><ul><li>一个JVM实例只存在一个堆内存，堆也是Java内存管理的核心区域</li><li>Java堆区在JVM启动的时候即被创建，其空间大小也就确定了。是JVM管理的最大一块内存空间。<ul><li>堆内存的大小是可以调节的</li></ul></li><li>《Java虚拟机规范》规定，堆可以处于物理上不连续的内存空间中，但在逻辑上它应该被视为连续的。所有的线程共享Java堆，<strong>在这里还可以划分线程私有的缓冲区</strong>（Thread Local Allocation Buffer，TLAB）</li><li>《Java虚拟机规范》中对Java堆的描述是：所有的对象实例以及数组都应该在运行时分配在堆上。<ul><li>实际上，是&quot;几乎&quot;所有的对象实例都在这里分配内存</li></ul></li><li>数组和对象可能永远不会存储在栈上，因为栈帧中保存引用，这个引用指向对象或者数组在堆中的位置。</li><li>在方法结束后，堆中的对象不会马上被移除，仅仅在垃圾收集的时候才会被移除</li><li>堆，是GC（Garbage Collection，垃圾收集器）执行垃圾回收的重点区域。</li></ul><h2 id="内存细分"><a class="header-anchor" href="#内存细分">¶</a>内存细分</h2><p>现代垃圾收集器大部分都基于分代收集理论设计：</p><p>堆和方法区是一组从功能上定义的内存区域名称；分代命名是从垃圾回收的角度进行内存区域划分和命名，方便垃圾收集器对不同分代区域进行特定的针对性内存分配及回收逻辑。</p><ul><li><p>Java 7及之前堆内存逻辑上分为两部分：新生代、老年代</p><ul><li>Young(New) Generation Space<ul><li>Eden、Survivor(from、to)</li></ul></li><li>Tenure(Old) generation space</li></ul></li><li><p>方法区被划为永久代（在Java虚拟机规范中没有定义方法区的实际位置，在7及之前它和堆共用一块内存，它所占用的内存空间称为非堆内存）：Permanent Space</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234348.png" alt="image-20200916082710521"></p></li><li><p>Java8及之后堆内存逻辑上分为三部分：新生代、老年代</p><ul><li>Young(New) Generation Space<ul><li>Eden、Survivor</li></ul></li><li>Tenure(Old) generation space</li></ul></li><li><p>永久代移除，使用元空间替代(在8之后出现，不占用堆内存，使用直接内存/又叫堆外内存，很蹩脚的命名)：Meta Spoce</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234355.png" alt="image-20200916082818919"></p></li></ul><h1>设置堆内存大小与OOM</h1><p>Java堆区用于存储Java对象实例，那么堆的大小在JVM启动时就已经设定好了，可以通过选项<code>-Xmx</code>和<code>-Xms</code>来进行设置</p><ul><li><code>-Xms</code>用于表示堆区的起始内存，等价于<code>-XX:InitialHeapSize</code></li><li><code>-Xmx</code>则用于表示堆区的最大内存，等价于<code>-XX:MaxHeapSize</code></li></ul><p>一旦堆区中的内存大小超过<code>-Xmx</code>所指定的最大内存时，将会抛出<code>OutOfMemoryError</code>异常</p><p>通常会将<code>-Xms</code>和<code>-Xmx</code>两个参数配置相同的值，其目的是为了能够在Java垃圾回收机制清理完堆区后不需要重新分配计算堆区的大小，从而提高性能。</p><p>默认情况下：</p><ul><li>初始内存大小：物理电脑内存大小/64</li><li>最大内存大小：物理电脑内存大小/4</li></ul><p>查看堆内存情况：</p><ul><li><code>jps</code>查看Java进程，<code>jstat -gc 进程id</code>查看内存使用情况和GC次数等</li><li><code>-XX:+PrintGCDetails</code></li></ul><h3 id="OOM"><a class="header-anchor" href="#OOM">¶</a>OOM</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234403.png" alt="image-20200916085807115"></p><h1>年轻代与老年代</h1><p>存储在JVM中的Java对象可以被划分为两类：</p><ul><li>一类是生命周期较短的瞬时对象，这类对象的创建和消亡都非常迅速</li><li>另外一类对象的生命周期却非常长，在某些极端的情况下还能够与JVM的生命周期保持一致</li></ul><p>Java堆区进一步细分的话，可以划分为年轻代（YoungGen）和老年代（OldGen）</p><p>其中年轻代又可以划分为Eden空间、Survivor0空间和Survivor1空间（有时也叫做form区、to区）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234410.png" alt="image-20200916090311825"></p><h3 id="相关参数设置"><a class="header-anchor" href="#相关参数设置">¶</a>相关参数设置</h3><ul><li><p>配置新生代与老年代在堆结构的占比</p><ul><li>默认<code>-XX:NewRatio=2</code>，表示新生代占1，老年代占2，新生代占整个堆的1/3</li><li>可以根据需要进行修改，一般开发中不会修改</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234416.png" alt="image-20200916090614423"></p></li><li><p>在Hotspot中，Eden空间和另外两个Survivor空间空间缺省所占的比例是8:1:1。可以通过以下参数进行设置：</p><ul><li>设置新生代中Eden区与Survivor区的比例：<code>-XX:SurvivorRatio=8</code>。默认是8（from和to平分Survivor区域）</li></ul></li><li><p><code>-XX:-UseAdaptiveSizePolicy</code>：关闭自适应的内存分配策略（否则新生代中分区可能和SurvivorRatio参数是不匹配的）</p></li></ul><p>几乎所有的Java对象都是在Eden区被new出来的。绝大部分的Java对象的销毁都在新生代进行了（IBM公司的专门研究表明，新生代中的80%的对象都是朝生夕死的）。</p><ul><li>可以使用选项<code>-Xmn</code>设置新生代最大内存大小，这个参数一般使用默认值即可。</li></ul><h1>图解对象分配过程</h1><h2 id="对象分配过程：概述"><a class="header-anchor" href="#对象分配过程：概述">¶</a>对象分配过程：概述</h2><p>为新对象分配内存是一件非常严谨和复杂的任务，JVM的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法与内存回收算法密切相关，所以还需要考虑GC执行完内存回收后是否会在内存空间中产生碎片。</p><ol><li>new的对象先放在Eden区。此区有大小限制</li><li>当伊甸园的空间填满时，程序又需要创建对象，JVM的垃圾回收器将对Eden区和from区进行垃圾回收（Minor GC/YGC），将Eden区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到Eden区</li><li>然后将Eden中的剩余对象移动到幸存者to区域（默认是0区），然后切换from和to</li><li>如果再次触发垃圾回收，同样对Eden和from区域进行回收，此时from区域为0区，to区域切换为1区，本次垃圾回收的幸存者将会移动到幸存者0区的</li><li>就这样经历不断的垃圾回收，幸存者一直在新生代的from区和to区之间移动。如果经过<code>-XX:MaxTenuringThreshold=&lt;N&gt;</code>设置的次数之后(默认15)，该对象还没有被回收，该对象将被移到tenure老年代。</li><li>另外如果MinorGC后新建对象还是过大或者GC清理对象过少，剩余对象过多，to区无法承载新建对象，则该对象直接进入老年区（如果老年区够大）。</li><li>在老年代，相当悠闲。当老年代内存不足时，再次触发GC：Major GC，进行老年代的内存清理。</li><li>若老年代执行了Major GC之后发现依然无法进行对象的保存，就会产生OOM异常：<code>java.lang.OutOfMemoryError: Java heap space</code></li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234422.png" alt="image-20200916093717986"></p><h2 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h2><ul><li>针对幸存者s0和s1区，复制之后有交换，谁空谁是to</li><li>关于垃圾回收：频繁在新生区收集，很少在老年区收集，几乎不在永久区/元空间收集</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234428.png" alt="image-20200916094118286"></p><h2 id="常用调优工具"><a class="header-anchor" href="#常用调优工具">¶</a>常用调优工具</h2><ul><li>JDK命令行：jstat、jinfo、jmap、jps、jstack等</li><li>Eclipse：Memory Analyzer Tool</li><li>Jconsole</li><li>VisualVM</li><li>Jprofiler</li><li>Java Flight Recorder（在JMC里面）</li><li>GCViewer</li><li>GC Easy</li></ul><h1>Minor GC、Major GC、Full GC</h1><p>JVM在进行GC时，并非每次都对三个内存区域(新生代、老年代、方法区)一起回收的，大部分时候回收的都是指新生代。</p><p>针对HotSpot VM的实现，它的垃圾收集按照回收区域又分为两大种类：一种是部分收集（Partial GC），另一种是整堆收集（Full GC）</p><ul><li>部分收集：不是完整收集整个Java堆的垃圾收集。其中又分为：<ul><li>新生代收集（Minor GC/Young GC）：只是新生代的垃圾收集</li><li>老年代收集（Major GC/Old GC）：只是老年代的垃圾收集<ul><li>目前，只有CMS收集器会有单独收集老年代的行为</li><li>注意，很多时候Major GC和Full GC混淆使用，需要具体分辨是老年代回收还是整堆回收（根据使用的垃圾收集器区分）</li></ul></li><li>混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集。<ul><li>目前，只有G1收集器会有这种行为</li></ul></li></ul></li><li>整堆收集（Full GC）：收集整个Java堆和方法区的垃圾收集。</li></ul><h2 id="最简单的分代式GC策略的触发条件"><a class="header-anchor" href="#最简单的分代式GC策略的触发条件">¶</a>最简单的分代式GC策略的触发条件</h2><ul><li><p>年轻代GC（Minor GC）触发机制：</p><ul><li>当年轻代空间不足时，就会触发Minor GC，这里的年轻代指的是Eden+from。</li><li>因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。这一定义既清晰又易于理解。</li><li>Minor GC会引发STW，暂停其它用户的线程，等垃圾回收结束，用户线程才恢复运行</li></ul></li><li><p>老年代GC（Major GC/Full GC）触发机制：</p><ul><li>指发生在老年代的GC，对象从老年代消失时，我们说&quot;Major GC&quot;或者&quot;Full GC&quot;发生了。</li><li>出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。<ul><li>也就是在老年代空间不足时，会先尝试触发Minor GC。如果之后空间还不足，会触发Major GC</li></ul></li><li>Major GC的速度一般会比Minor GC慢10倍以上，STW的时间更长。</li><li>如果Major GC后，内存还不足，就报OOM了。</li></ul></li><li><p>Full GC触发机制：</p><p>触发Full GC执行的情况有如下五种：</p><ol><li>调用<code>System.gc()</code>时，系统建议执行Full GC，但是不必然执行</li><li>老年代空间不足</li><li>方法区空间不足</li><li>通过Minor GC后进入老年代的平均大小大于老年代的可用内存</li><li>由Eden区、suvivor space0（From Sapce）区向survivor space1（To Space）区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小</li></ol></li></ul><ol start="6"><li>CMS 因为资源不足无法进行多线程回收发生 Concurrent mode failed</li></ol><p>说明：Full GC是开发或调优中尽量要避免的。这样暂停时间会短一些。</p><h1>堆空间分代思想</h1><p>为什么需要把Java堆分代？不分代就不能正常工作了吗？经研究，不同对象的生命周期不同。70%-99%的对象是临时对象。</p><ul><li>新生代：有Eden、两块大小相同的Survivor（又称为from/to、s0/s1）构成，to总为空。</li><li>老年代：存放新生代中经历多次GC仍然存活的对象。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234437.png" alt="image-20200916105218715"></p><p>分代的最大作用就是优化GC性能，对对象进行提前打标，在垃圾收集的时候就可以针对不同标识进行相关收集动作，防止在收集阶段才进行全对象的打标，会导致GC时间过长。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234442.png" alt="image-20200916105519846"></p><h1>内存分配策略</h1><p>如果对象在Eden出生并经过第一次MinorGC后依然存货，并且能被Survivor容纳的话，将被移动到Survivor空间中，并将对象年龄设为1.对象在Survivor区中每熬过一次MinorGC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁，其实每个JVM、每个GC都有所不同）时，就会被晋升到老年代中。</p><p>对象晋升老年代的年龄阈值，可以通过选项<code>-XX:MaxTenuringThresold</code>来设置。</p><p>针对不同年龄段的对象分配原则如下所示：</p><ul><li><p>优先分配到Eden</p></li><li><p>大于<code>-XX:PretenureSizeThreshold</code>的大对象直接分配到老年代</p><ul><li>尽量避免程序中出现过多的大对象，尤其是小于该阈值的大对象，因为它会先放在新生代，新生代的空间较小，很容易引发GC</li></ul></li><li><p>长期存活的对象分配到老年代</p><ul><li>每在年轻代经过一次Minor GC，对象年龄+1，年龄超过<code>-XX: MaxTenuringThreshold</code>的对象为长期存活</li></ul></li><li><p>动态对象年龄判断</p><ul><li>如果Survivor区中<strong>相同年龄的所有对象大小的总和</strong>大于<strong>Survivor空间的一半</strong>，<strong>年龄大于或等于该年龄的对象</strong>可以直接进入老年代，无须等到<code>MaxTenuringThreshold</code>中要求的年龄</li></ul></li><li><p>空间分配担保：<code>-XX:HandlePromotionFailure</code></p><p>在发生Minor GC之前，虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。</p><ul><li>如果大于，则此次Minor GC是安全的。（所有新生代对象都不能被收集且年龄满足晋升到老年代的极端情况下）</li><li>如果小于，则虚拟机会查看<code>-XX:HandlePromotionFailure</code>设置值是否允许担保小范围GC带来的风险（例如MinorGC之后可能老年代内存还是不足以存放新生代幸存下来且要晋升到老年代的对象，此时还是要进行FullGC。所以此时相较于一开始就进行FullGC多了一次MinorGC）。<ul><li>如果该值为true，那么会继续检查老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小<ul><li>如果大于，则尝试进行一次Minor GC，但这次Minor GC依然是有风险的，因为参考的是一个平均值</li><li>如果小于，则改为进行一次Full GC</li></ul></li><li>如果该值为false，则改为进行一次Full GC</li></ul></li></ul><p>在JDK6 Update24之后，<code>HandlePromotionFailure</code>参数不会再影响到虚拟机的空间分配担保策略，虽然源码中还定义了该参数，但是代码中已经不会再使用它了。JDK6 Update24之后的规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小就会进行Minor GC，否则将会进行Full GC。</p></li></ul><h1>为对象分配内存：TLAB</h1><p>为什么有TLAB（Thread Local Allocation Buffer）？</p><ul><li>堆区是线程共享区域，任何线程都可以访问到堆区中的共享数据</li><li>由于对象实例的创建在JVM中非常频繁，因此在并发环境下从堆区中划分内存空间是线程不安全的</li><li>为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度</li></ul><p>什么是TLAB？</p><ul><li><p>TLAB全称<code>ThreadLocalAllocBuffer</code>，是线程的一块私有内存，如果设置了虚拟机参数 <code>-XX:UseTLAB</code>，<strong>在线程初始化时</strong>，同时也会申请一块指定大小的内存，只给当前线程使用，这样每个线程都单独拥有一个Buffer，如果需要分配内存，就在自己的Buffer上分配，这样就不存在竞争的情况，可以大大提升分配效率，当Buffer容量不够的时候，再重新从Eden区域申请一块继续使用，这个申请动作还是需要原子操作的。</p><p>TLAB的目的是在为新对象分配内存空间时，让每个Java应用线程能在使用自己专属的分配指针来分配空间，均摊对GC堆（eden区）里共享的分配指针做更新而带来的同步开销，提升内存分配的吞吐量，因此可以将这种内存分配方式称之为快速分配策略。</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234449.png" alt="image-20200916113105504"></p><p>在TLAB中分配内存直接通过指针碰撞方式（移动指针）进行分配。</p><p>TLAB的再说明：</p><ul><li>尽管不是所有的对象实例都能够在TLAB中成功分配内存，但JVM确实是将TLAB作为内存分配的首选。</li><li>在程序中，开发人员可以通过选项<code>-XX:UseTLAB</code>设置是否开启TLAB空间</li><li>默认情况下，TLAB空间的内存非常小（所以线程创建的时候Eden中的TLAB空间如果用完了，就不会给这个线程初始化TLAB），仅占有整个Eden空间的1%，当然我们可以通过选项<code>-XX:TLABWasteTargetPercent</code>设置TLAB空间所占用Eden空间的百分比大小。</li><li>一旦对象在TLAB空间分配内存失败时，JVM就会尝试着通过使用加锁机制确保数据操作的原子性到Eden空间中再申请内存。</li></ul><h1>小结堆空间的参数设置</h1><pre><code>打印所有的参数默认初始值-XX:+PrintFlagsInitial打印所有的参数的实际值-XX:+PrintFlagsFinal# 在JVM运行期间查看设置参数步骤：# 1. jps：查看当前运行中的进程id# 2. jinfo -flag SurvivorRatio 进程id：查看具体JVM进程的指定参数值初始化堆空间内存（默认为物理内存的1/64）-Xms128m最大堆空间内存（默认为物理内存的1/4）-Xmx128m设置新生代大小（初始值及最大值）-Xmn128m配置新生代与老年代在堆结构的占比-XX:NewRatio=3设置新生代中Eden和S0/S1空间的比例-XX:SurvivorRatio=4设置新生代垃圾的最大年龄-XX:MaxTenuringThreshold=15输出详细的GC处理日志-XX:+PrintGCDetails打印GC简要信息-XX:+PrintGC、-verbose:gc设置是否空间分配担保-XX:HandlePromotionFailure</code></pre>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>04_本地方法接口及本地方法栈</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/04-ben-di-fang-fa-jie-kou-ji-ben-di-fang-fa-zhan/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/04-ben-di-fang-fa-jie-kou-ji-ben-di-fang-fa-zhan/</url>
      
        <content type="html"><![CDATA[<h1>什么是本地方法</h1><p>简单地讲，一个Native Method就是一个Java调用非Java代码的接口。一个Native Method是这样一个Java方法：该方法的实现由非Java语言实现，比如C。这个特征并非Java所特有，很多其它的编程语言都有这一机制，比如在C<ins>中，你可以用extern &quot;C&quot;告诉C</ins>编译器去调用一个C的函数。</p><p>在定义一个native method时，并不提供实现体（有些像定义一个Java interface），因为其实现体是由非Java语言在外面实现的。</p><p>本地接口的作用是融合不同的编程语言为Java所用，它的初衷是融合C/C++程序。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234326.png" alt="image-20200915220446930"></p><p>标识符native可以与所有其它的java标识符连用，但是abstract除外。</p><h1>为什么要使用Native Method</h1><p>Java使用起来非常方便，然而有些层次的任务用Java实现起来不容易，或者我们对程序的效率很在意时，问题就来了。</p><ul><li><p>与Java环境外交互</p><p>有时Java应用需要与Java外面的环境交互，这是本地方法存在的主要原因。你可以想象Java需要与一些底层系统，如操作系统或某些硬件交换信息时的情况。本地方法正是这样一种交流机制：它为我们提供了一个非常简洁的接口，而且我们无需去了解Java应用之外的繁琐的细节。</p></li><li><p>与操作系统的交互</p><p>JVM支持着Java语言本身和运行时库，它是Java程序赖以生存的平台，它由一个解释器（解释字节码）和一些连接到本地代码的库组成。然而不管怎样，它毕竟不是一个完整的系统，它经常依赖于一些底层系统的支持。这些底层系统常常是强大的操作系统。通过使用这些本地方法，我们得以用Java实现了jre的与底层系统的交互，甚至JVM的一些部分就是用C写的。还有，如果我们要使用一些Java语言本身没有提供封装的操作系统的特性时，我们也需要使用本地方法。</p></li><li><p>Sun’s Java</p><p>Sun的解释器是用C实现的，这使得它能像一些普通的C一样与外部交互。jre大部分是用Java实现的，它也通过一些本地方法与外界交互。例如：类<code>Java.lang.Thread</code>的<code>setPriority()</code>方法是用Java实现的，但是它实现调用的是该类里的本地方法<code>setPriority0()</code>。这个本地方法是用C实现的，并被植入JVM内部，在Windows 95的平台上，这个本地方法最终将调用Win32 SetPriority() API。这是一个本地方法的具体实现由JVM直接提供，更多的情况是本地方法由外部的动态链接库（external dynamic link library）提供，然后被JVM调用。</p><h1>现状</h1></li></ul><p>目前该方法使用得越来越少了，除非是与硬件有关的应用，比如通过Java程序驱动打印机或者Java系统管理生产设备，在企业级应用中已经比较少见。因为现在的异构领域间的通信发达，比如可以使用Socket通信，也可以使用Web Service等等。</p><h1>本地方法栈（Native Method Stack）</h1><ul><li>Java虚拟机栈用于管理Java方法的调用，而本地方法栈用于管理本地方法的调用。</li><li>本地方法栈，也是线程私有的。</li><li>允许被实现成固定或者是可动态扩展的内存大小。（在内存溢出方面是相同的）<ul><li>如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java虚拟机将会抛出一个StackOverflowError异常</li><li>如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么Java虚拟机将会抛出一个OutOfMemoryError异常。</li></ul></li><li>本地方法是使用C语言实现的。</li><li>它的具体做法是Native Method Stack中登记native方法，在Execution Engine执行时加载本地方法库。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234333.png" alt="image-20200915224410094"></p><p>当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。</p><ul><li>本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区</li><li>它甚至可以直接使用本地处理器中的寄存器</li><li>直接从本地内存的堆中分配任意数量的内存</li></ul><p>并不是所有的JVM都支持本地方法。因为Java虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。如果JVM产品不打算native方法，也可以无需实现本地方法栈。</p><p>在Hotspot JVM中，直接将本地方法栈和虚拟机栈合二为一。</p>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11_Class文件</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/11-class-wen-jian/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/11-class-wen-jian/</url>
      
        <content type="html"><![CDATA[<p>[toc]</p><h1>介绍</h1><p>Class文件是JVM的输入，Java虚拟机规范中定义了Class文件的结构。Class文件是JVM实现平台无关、技术无关的基础。</p><ol><li>Class文件是一组以8字节为单位的字节流，各个数据项目按顺序紧凑排列(无特殊分隔符，如空格)</li><li>对于占用空间大于8字节的数据项，按照高位在前(Big-edian)的方式分割成多个8字节进行存储</li><li>Class文件格式里面只有两种类型：无符号数、表<ol><li>无符号数属于基本的数据类型,以u1、u2、u4、u8来分别代表1个字节、2个字节、4个字节和8个字节的无符号数,无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串值。</li><li>表：由多个无符号数和其它表构成的复合数据类型，通常以&quot;_info&quot;结尾。表用于描述有层次关系的复合结构的数据,整个Class文件本质上也可以视作是一张表</li></ol></li></ol><h2 id="Class文件图表示意"><a class="header-anchor" href="#Class文件图表示意">¶</a>Class文件图表示意</h2><table><thead><tr><th>类型</th><th>名称</th><th>数量</th><th>抽象类型</th></tr></thead><tbody><tr><td>u4</td><td>magic</td><td>1</td><td>无符号数</td></tr><tr><td>u2</td><td>minor_version</td><td>1</td><td>无符号数</td></tr><tr><td>u2</td><td>major_verslon</td><td>1</td><td>无符号数</td></tr><tr><td>u2</td><td>constant_pool_count</td><td>1</td><td>无符号数</td></tr><tr><td>cp_info</td><td>constant_pool</td><td>constant_pool_count</td><td>表</td></tr><tr><td>u2</td><td>access_flags</td><td>1</td><td>无符号数</td></tr><tr><td>u2</td><td>this_class</td><td>1</td><td>无符号数</td></tr><tr><td>u2</td><td>super_class</td><td>1</td><td>无符号数</td></tr><tr><td>u2</td><td>interfaces_count</td><td>1</td><td>无符号数</td></tr><tr><td>u2</td><td>interfaces</td><td>interfaces_count</td><td>无符号数</td></tr><tr><td>u2</td><td>fields_count</td><td>1</td><td>无符号数</td></tr><tr><td>field_info</td><td>fields</td><td>fields_count</td><td>表</td></tr><tr><td>u2</td><td>methods_count</td><td>1</td><td>无符号数</td></tr><tr><td>method_info</td><td>methods</td><td>methods_count</td><td>表</td></tr><tr><td>u2</td><td>attributes_count</td><td>1</td><td>无符号数</td></tr><tr><td>attribute_info</td><td>attributes</td><td>attributes_count</td><td>表</td></tr></tbody></table><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235326.png" alt="class"></p><h1>魔数与Class文件的版本</h1><p>每个Class文件的头4个字节被称为魔数(Magic Number),它的唯一作用是确定这个文件是否为一个能被虚拟机接受的Class文件,其值为&quot;0xCAFEBABE&quot;。</p><p>紧接着魔数的4个字节存储的是Class文件的版本号:第5和第6个字节是次版本号(Minor Version),第7和第8个字节是主版本号(Major Version)。</p><h1>常量池</h1><p>常量池描述分为两部分：</p><ul><li><p>constant_pool_count：常量池数量，固定占两个字节</p><blockquote><p>注意：</p><p>常量池项(cp_info)从索引0开始，最后一个常量池项(cp_info)的素引值为constant_pool_count-1，所以真正常量池数量应该为constant_pool_count-1。例如constant_ pool_ count=22,则后面的常量池项(cp_info)的个数就为21。</p><p>原因是在指定 class 文件规范的时候,将第0项常量空出来是有特殊考虑的,这样做是为了满足某些指向常量池的素引值的数据在特定的情况下表达“不引用任何一个常量池项”的意思,这种情况下可以将素引值设置成0来表示)</p><p>class文件结构中只有常量池的容量计数是从1开始,对于其他集合类型,包括接口索引集合、字段表集合、方法表集合等的容量计数都与一般习惯相同,是从0开始。</p></blockquote></li><li><p>cp_info：常量池项，长度由常量池数量以及本身的常量类型决定</p></li></ul><h2 id="常量池内容"><a class="header-anchor" href="#常量池内容">¶</a>常量池内容</h2><p>常量池中主要存放两大类常量:字面量(Literal)和符号引用(Symbolic References)。</p><ul><li>字面量比较接近于Java语言层面的常量概念, 如文本字符串、被声明为final的常量值等。</li><li>而符号引用则属于编译原理方面的概念,主要包括下面几类常量:<ul><li>被模块导出或者开放的包(Package)</li><li>类和接口的全限定名(Fully Qualified Name)</li><li>字段的名称和描述符(Descriptor)</li><li>方法的名称和描述符</li><li>方法句柄和方法类型(Method Handle、Method Type、Invoke Dynamic)</li><li>动态调用点和动态常量(Dynamically-Computed CallSite、Dynamically-Computed Constant)</li></ul></li></ul><h2 id="常量池项-cp-info-结构"><a class="header-anchor" href="#常量池项-cp-info-结构">¶</a>常量池项(cp_info)结构</h2><p>常量池中每一项常量都是一个表,现在常量表中共有17种结构各不相同的表结构数据，这17类表都有一个共同的特点,表结构起始的第一位是个u1类型的标志位(tag),代表着当前常量属于哪种常量类型。</p><pre class="line-numbers language-language-c"><code class="language-language-c">cp_info {u1 tag;u1 info[];}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="tag值"><a class="header-anchor" href="#tag值">¶</a>tag值</h3><p>每个常量池项(cp_info)都会对应记录着Class文件中的某种类型的字面量。VM虚拟机根据tag的值来确定是某个常量池项(cp_info)表示什么类型的字面量。</p><table><thead><tr><th>Tag值</th><th>表示的宇面量</th><th>更细化的结构</th></tr></thead><tbody><tr><td>1</td><td>以UTF-8编码的字符串，通常用于被其他表结构引用</td><td>CONSTANT_Utf8_info</td></tr><tr><td>3</td><td>表示4字节(int)的数值字面量</td><td>CONSTANT_Integer_info</td></tr><tr><td>4</td><td>表示4字节( Float)的数值字面量</td><td>CONSTANT_Float_info</td></tr><tr><td>5</td><td>表示8字节(Long)的数值字面量</td><td>CONSTANT_Long_info</td></tr><tr><td>6</td><td>表示8字节( double)的数值字面量</td><td>CONSTANT_Double_info</td></tr><tr><td>7</td><td>表示类成接口的符号引用</td><td>CONSTANT_Class_info</td></tr><tr><td>8</td><td>字符串类型字面量</td><td>CONSTANT_String_info</td></tr><tr><td>9</td><td>字段的<strong>符号引用</strong></td><td>CONSTANT_Fieldref_info</td></tr><tr><td>10</td><td>类中方法的<strong>符号引用</strong></td><td>CONSTANT_Methodref_info</td></tr><tr><td>11</td><td>接口中方法的<strong>符号引用</strong></td><td>CONSTANT_InterfaceMethodref_info</td></tr><tr><td>12</td><td>字段或者方法的部分<strong>符号引用</strong></td><td>CONSTANT_NameAndType_info</td></tr><tr><td>15</td><td>表示方法句柄</td><td>CONSTANT_MethodHandle_info</td></tr><tr><td>16</td><td>表示方法类型</td><td>CONSTANT_MethodType_info</td></tr><tr><td>17</td><td>表示一个动态计算常量</td><td>CONSTANT_Dynamic_info</td></tr><tr><td>18</td><td>表示动态方法调用点</td><td>CONSTANT_InvokeDynamic_info</td></tr><tr><td>19</td><td>表示一个模块</td><td>CONSTANT_Module_info</td></tr><tr><td>20</td><td>表示一个模块中开放或者导出的包</td><td>CONSTANT_Package_info</td></tr></tbody></table><h3 id="示例"><a class="header-anchor" href="#示例">¶</a>示例</h3><p>使用<code>javap -v</code>查看字节码文件。</p><pre class="line-numbers language-language-c"><code class="language-language-c">//固定占用5字节，1字节指定tag类型为3，4字节为int二进制描述CONSTANT_Integer_info{u1 tag=3;u4 bytes;}//固定占用5字节，1字节指定tag类型为4，4字节为float二进制描述CONSTANT_Float_info{u1 tag=4;u4 bytes;}//固定占用9字节，1字节指定tag类型为5，后面4字节为long的高4位，再接着是long的低4位CONSTANT_Long_info{  u1 tag=5;  u4 high_bytes;  u4 low_bytes;}//固定占用9字节，1字节指定tag类型为6，后面4字节为double的高4位，再接着是double的低4位CONSTANT_Double_info{  u1 tag=6;  u4 high_bytes;  u4 low_bytes;}//JVM规定源文件中的所有字面量都以UTF-8编码格式存储到在class字节码文件中(包含方法名、""括起来的字符串、类名等等)CONSTANT_Utf8_info{  u1 tag=1;//一个字节指定tag类型为1  u2 length;//两个字节指定长度，所以源文件的字面量都是有长度限制的  u1 bytes[length];//接下来的length个长度字节承载UTF-8编码的二进制文本数据}//用双引号""括起来的字符串字面量，固定3个字节CONSTANT_String_info{  u1 tag=8;//一个字节指定tag类型为8  u2 string_index;//两个字节指向常量池中某个 CONSTANT_Utf8_info 项的索引}//类名字面量，同样固定3个字节CONSTANT_Class_info{u1 tag=7;//一个字节指定tag类型为7  u2 name_index;//两个字节指向常量池中某个 CONSTANT_Utf8_info 项的索引}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>对于类名字面量需要注意的：</p><ol><li><p>对于某个类而言,其class文件中至少要有两个CONSTANT_Class_info常量池项,用来表示自己的类信息和其父类信息。(除了<code>java.lang.Object</code>类除外,其他的任何类都会默认继承自<code>java.lang.Object</code>)如果类声明实现了某些接口,那么接口的信息也会生成对应的CONSTANT_Class_info常量池项。</p><p>所以对于某个类或接口而言,其自身、父类和继承或实现的接口的信息会被直接组装成CONSTANT_Class_info常量池项放置到常量池中</p></li><li><p>类中或接口中使用到了其他的类,只有在类中实际使用到了该类时,该类的信息才会在常量池中有对应的CONSTANT_Class_info常量池项; 否则Javac编译器只会将生成CONSTANT_Utf8_info而不会生成CONSTANT_Class_info</p></li></ol></blockquote><h3 id="各表结构示意"><a class="header-anchor" href="#各表结构示意">¶</a>各表结构示意</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235334.png" alt="image-20200921114044036"><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235340.png" alt="image-20200921114112717"><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235348.png" alt="image-20200921114153809"></p><h1>访问标识</h1><p>常量池结束之后,紧接着的2个字节(16个标志位)代表访问标志(access_flags),这个标志用于识别类或者接口层次的一些访问信息,包括:<strong>这个Class</strong>是类还是接口;是否定义为public类型;是否定义为abstract 类型;如果是类的话,是否被声明为final;等等。</p><p>access_flags中一共有16个标志位可以使用,当前只定义了其中<strong>9个</strong>,没有使用到的标志位要求一律为零：</p><table><thead><tr><th>标志名称</th><th>标志值</th><th>含义</th></tr></thead><tbody><tr><td>ACC_PUBLIC</td><td>0x0001</td><td>是否为 public类型</td></tr><tr><td>ACC_FINAL</td><td>0x0010</td><td>是否被声明为 final,只有类可设置</td></tr><tr><td>ACC_SUPER</td><td>0x0020</td><td>是否允许使用 invokespecial字节码指令的新语义, invokespecial指令的语义在JDK1.0.2发生过改变,为了区别这条指令使用哪种语义,JDK 1.0.2之后编译出来的类的这个标志都必须为真</td></tr><tr><td>ACC_INTERFACE</td><td>0x0200</td><td>标识这是一个接口</td></tr><tr><td>ACC_ABSTRACT</td><td>0X0400</td><td>是否为 abstract类型,对于接口或者抽象类来说,此标志值为真,其他类型值为假</td></tr><tr><td>ACC_SYNTHETIC</td><td>0x1000</td><td>标识这个类并非由用户代码产生的</td></tr><tr><td>ACC_ANNOTATION</td><td>0x2000</td><td>标识这是一个注解</td></tr><tr><td>ACC_ENUM</td><td>0X4000</td><td>标识这是一个枚举</td></tr><tr><td>ACC_MODULE</td><td>0X8000</td><td>标识这是一个模块</td></tr></tbody></table><h1>类索引、父类索引与接口索引集合</h1><p>类索引(this_class)和父类索引(super_class)<strong>都是一个u2类型的数据</strong>,而接口索引集合(interfaces)<strong>是一组u2类型的数据的集合</strong>,Class文件中由这三项数据来确定该类型的继承关系。</p><ol><li><strong>类索引用于确定这个类(当前Class字节码&quot;文件&quot;)的全限定名</strong></li><li>**父类索引用于确定这个类(当前Class字节码&quot;文件&quot;)的父类的全限定名。**由于Java语言不允许多重继承,所以父类索引只有一个,除了<code>java.lang.Object</code>之外,所有的Java类都有父类,因此除了<code>java.lang.Object</code>外,所有Java类的父类索引都不为0。</li><li>接口索引集合就用来描述这个类实现了哪些接口,这些被实现的接口将按implements关键字(如果这个Class文件表示的是一个接口,则应当是extends关键字)后的接口顺序从左到右排列在接口索引集合中。</li></ol><p>类索引、父类索引和接口索引集合都按顺序排列在访问标志之后</p><ol><li><p>类索引和父类索引用两个u2类型的索引值表示**,它们各自指向一个类型为CONSTANT_Class_info的类描述符常量,通过CONSTANT_Class_info类型的常量中的索引值可以找到定义在CONSTANT_Utf8_info类型的常量中的全限定名字符串**。</p></li><li><p>对于接口索引集合,<strong>入口的第一项u2类型的数据为接口计数器</strong>(interfaces_count),表示索引表的容量：</p><ul><li>如果该类没有实现任何接口,则该计数器值为0, 后面接口的索引表不再占用任何字节</li><li>如果该类实现了2各接口，则该计数器值为2，后面再跟两个u2类型数据存储<strong>CONSTANT_Class_info的索引</strong>。</li></ul></li></ol><h1>字段表</h1><p>字段表(field_info)用于描述接口或者类中声明的变量。Java语言中的“字段”(Field)包括类级变量以及实例级变量,但不包括在方法内部声明的局部变量。</p><p>字段可以包括的修饰符有：</p><ol><li>字段的作用域(public、private、protected修饰符)</li><li>是实例变量还是类变量(static修饰符)</li><li>可变性(final)</li><li>并发可见性(volatile修饰符,是否强制从主内存读写)</li><li>可否被序列化(transient修饰符)</li><li>字段数据类型(基本类型、对象、数组)</li><li>字段名称</li></ol><h2 id="字段表结构"><a class="header-anchor" href="#字段表结构">¶</a>字段表结构</h2><p>字段表集合中不会列出从父类或者父接口中继承而来的字段,但有可能出现原本Java代码之中不存在的字段,譬如在内部类中为了保持对外部类的访问性,编译器就会自动添加指向外部类实例的字段。另外,在Java语言中字段是无法重载的,两个字段的数据类型、修饰符不管是否相同,都必须使用不一样的名称,但是对于Class文件格式来讲,只要两个字段的描述符不是完全相同,那字段重名就是合法的。</p><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>access_flags</td><td>1</td></tr><tr><td>u2</td><td>name_index</td><td>1</td></tr><tr><td>u2</td><td>descriptor_index</td><td>1</td></tr><tr><td>u2</td><td>attributes_count</td><td>1</td></tr><tr><td>attribute_info</td><td>attributes</td><td>attributes_count</td></tr></tbody></table><h2 id="access-flags"><a class="header-anchor" href="#access-flags">¶</a>access_flags</h2><table><thead><tr><th>标志名称</th><th>标志值</th><th>含义</th></tr></thead><tbody><tr><td>ACC_PUBLIC</td><td>0x0001</td><td>字段是否public</td></tr><tr><td>ACC_PRIVATE</td><td>0x0002</td><td>字段是否private</td></tr><tr><td>ACC_PROTECTED</td><td>0x0004</td><td>字段是否protected</td></tr><tr><td>ACC_STATIC</td><td>0x0008</td><td>字段是否static</td></tr><tr><td>ACC_FINAL</td><td>0x0010</td><td>字段是否final</td></tr><tr><td>ACC_VOLATILE</td><td>0x0040</td><td>字段是否volatile</td></tr><tr><td>ACC_TRANSIENT</td><td>0x0080</td><td>字段是否transient</td></tr><tr><td>ACC_SYNTHETIC</td><td>0x1000</td><td>字段是否由编译器自动产生</td></tr><tr><td>ACC_ENUM</td><td>0x4000</td><td>字段是否enum</td></tr></tbody></table><h2 id="name-index和descriptor-index"><a class="header-anchor" href="#name-index和descriptor-index">¶</a>name_index和descriptor_index</h2><p>跟随access_flags标志的是两项索引值:name_index和descriptor_index。它们<strong>存储的都是常量池中某常量池项的索引值表示对其引用</strong>,分别代表着字段的简单名称以及字段和方法的描述符，概念对比：</p><ol><li>全限定名：“java/lang/Object;”，包名+类名以斜杠分隔并以分号结尾。</li><li>简单名称<ul><li>没有类型和参数修饰的方法名称</li><li>字段名称</li></ul></li><li>描述符<ul><li><p>单独作为一个&quot;CONSTANT_Utf8_info&quot;项描述字段的数据类型</p></li><li><p>组合<strong>多个有序</strong>的描述符以及<code>()</code>为一个&quot;CONSTANT_Utf8_info&quot;来描述方法的参数列表（包括数量、类型以及顺序）和返回值类型，如：<code>()Ljava/lang/String;</code>即可描述方法为无参、返回值为<code>String</code></p><blockquote><p>方法参数的类型描述符按顺序排列，完了之后才是返回值类型描述符</p></blockquote></li></ul></li></ol><h3 id="描述符"><a class="header-anchor" href="#描述符">¶</a>描述符</h3><table><thead><tr><th>标识字符</th><th>含义</th></tr></thead><tbody><tr><td><code>B</code></td><td>基本类型byte</td></tr><tr><td><code>C</code></td><td>基本类型char</td></tr><tr><td><code>D</code></td><td>基本类型double</td></tr><tr><td><code>F</code></td><td>基本类型float</td></tr><tr><td><code>I</code></td><td>基本类型int</td></tr><tr><td><code>J</code></td><td>基本类型long</td></tr><tr><td><code>S</code></td><td>基本类型short</td></tr><tr><td><code>Z</code></td><td>基本类型boolean</td></tr><tr><td><code>V</code></td><td>特殊类型void</td></tr><tr><td><code>L</code></td><td>后面跟一个全限定名，表示对象类型，如：Ljava/lang/Object;</td></tr><tr><td><code>[</code></td><td>数组类型,每一维度将使用一个前置的<code>[</code>字符来描述,如一个定义为<code>java.lang.String[][]</code>类型的二维数组将被记录成<code>[[Ljava/lang/String;</code>,一个整型数组<code>int[]</code>将被记录成<code>[I</code>。</td></tr></tbody></table><h2 id="属性表集合"><a class="header-anchor" href="#属性表集合">¶</a>属性表集合</h2><p>由attributes_count指定attributes项的个数，每个attributes项中包含一个CONSTANT_Utf8_info常量池项的索引，该Utf8常量表示属性的名称，另外attributes结构(属性表结构)还有其他的一些字段构成，具体参考下面的属性表介绍。</p><h1>方法表集合</h1><p>与字段表集合相对应地,如果父类方法在子类中没有被重写(Override),方法表集合中就不会出现来自父类的方法信息。但同样地,有可能会出现由编译器自动添加的方法,最常见的便是类构造器<code>&lt;clinit&gt;()</code>方法和实例构造器<code>&lt;init&gt;()</code>方法。</p><h2 id="方法表结构"><a class="header-anchor" href="#方法表结构">¶</a>方法表结构</h2><p>方法表的结构和字段表非常相似：</p><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>access_flags</td><td>1</td></tr><tr><td>u2</td><td>name_index</td><td>1</td></tr><tr><td>u2</td><td>descriptor_index</td><td>1</td></tr><tr><td>u2</td><td>attributes_count</td><td>1</td></tr><tr><td>attribute_info</td><td>attributes</td><td>attributes_count</td></tr></tbody></table><h2 id="Access-flags"><a class="header-anchor" href="#Access-flags">¶</a>Access_flags</h2><table><thead><tr><th>标志名称</th><th>标志值</th><th>含义</th></tr></thead><tbody><tr><td>ACC_PUBLIC</td><td>0x0001</td><td>方法是否public</td></tr><tr><td>ACC_PRIVATE</td><td>0x0002</td><td>方法是否private</td></tr><tr><td>ACC_PROTECTED</td><td>0x0004</td><td>方法是否protected</td></tr><tr><td>ACC_STATIC</td><td>0x0008</td><td>方法是否static</td></tr><tr><td>ACC_FINAL</td><td>0x0010</td><td>方法是否final</td></tr><tr><td>ACC_SYNCHRONIZED</td><td>0x0020</td><td>字段是否synchronized</td></tr><tr><td>ACC_BRIDGE</td><td>0x0040</td><td>方法是不是由编译器产生的桥接方法</td></tr><tr><td>ACC_VARARGS</td><td>0x0080</td><td>方法是否接受不定参数</td></tr><tr><td>ACC_NATIVE</td><td>0x0100</td><td>方法是否为native</td></tr><tr><td>ACC_ABSTRACT</td><td>0x0400</td><td>方法是否abstract</td></tr><tr><td>ACC_STRICT</td><td>0X0800</td><td>方法是否为strictfp</td></tr><tr><td>ACC_SYNTHETIC</td><td>0x1000</td><td>字段是否由编译器自动产生</td></tr></tbody></table><h2 id="属性表集合-v2"><a class="header-anchor" href="#属性表集合-v2">¶</a>属性表集合</h2><p>同字段表。</p><h1>属性表集合</h1><p>与Class文件中其他的数据项目要求严格的顺序、长度和内容不同,属性表集合的限制稍微宽松一些,不再要求各个属性表具有严格顺序,并且《Java虚拟机规范》允许只要不与已有属性名重复,任何人实现的编译器都可以向属性表中写入自己定义的属性信息,Java虚拟机运行时会忽略掉它不认识的属性。为了能正确解析Class文件,《Java虚拟机规范》最初只预定义了9项所有Java虚拟机实现都应当能识别的属性,而在最新的《Java虚拟机规范》的Java SE 12版本中,预定义属性已经增加到29项。</p><p>Class文件、字段表、方法表都可以携带自己的属性表集合。</p><h2 id="常用、关键的预定义属性"><a class="header-anchor" href="#常用、关键的预定义属性">¶</a>常用、关键的预定义属性</h2><table><thead><tr><th>属性名称</th><th>使用位置</th><th>含义</th></tr></thead><tbody><tr><td>Code</td><td>方法表</td><td>Java代码编译成的字节码指令</td></tr><tr><td>Constantvalue</td><td>字段表</td><td>由 final关键字定义的常量值</td></tr><tr><td>Deprecated</td><td>类、方法表、字段表</td><td>被声明为 deprecated的方法和字段</td></tr><tr><td>Exceptions</td><td>方法表</td><td>方法抛出的异常列表</td></tr><tr><td>EnclosingMethod</td><td>类文件</td><td>仅当一个类为局部类或者匿名类时才能拥有这个属性,这个属性用于标示这个类所在的外围方法</td></tr><tr><td>Innerclasses</td><td>类文件</td><td>内部类列表</td></tr><tr><td>LinenumberTable</td><td>Code属性</td><td>Java源码的行号与字节码指令的对应关系</td></tr><tr><td>LocalvariableTableCode</td><td>Code属性</td><td>方法的局部变量描述</td></tr><tr><td>StackMapTable</td><td>Code属性</td><td>JDK6中新增的属性,供新的类型检查验证器( Type Checker)检查和处理目标方法的局部变量和操作数所需要的类型是否匹配</td></tr><tr><td>Signature</td><td>类、方法表、字段表</td><td>JDK5中新增的属性,用于支持范型情况下的方法签名。在Java语言中,任何类、接口、初始化方法或成员的泛型签名如果包含了类型变量(TypeVariables)或参数化类型( Parameterized Types则Signature属性会为它记录泛型签名信息。由于Java 的范型采用擦除法实现,为了避免类型信息被擦除后导致签名混乱,需要这个属性记录范型中的相关信息</td></tr><tr><td>SourceFile</td><td>类文件</td><td>记录源文件名称</td></tr><tr><td>SourceDebugExtension</td><td>类文件</td><td>JDK5中新增的属性,用于存储额外的调试信息譬如在进行JSP文件调试时,无法通过Java堆栈来定位到JSP文件的行号,JSR45提案为这些非Java 语言编写,却需要编译成字节码并运行在Java虚拟机中的程序提供了一个进行调试的标准机制,使用该属性就可以用于存储这个标准所新加入的调试信息</td></tr><tr><td>Synthetic</td><td>类、方法表、字段表</td><td>标识方法或字段为编译器自动生成的</td></tr><tr><td>LocalVariableTypeTable</td><td>类</td><td>JDK5中新增的属性,它使用特征签名代替描述符,是为了引入泛型语法之后能描述泛型参数化类型而添加</td></tr><tr><td>RuntimeVisibleAnnotations</td><td>类、方法表、字段表</td><td>JDK5中新增的属性,为动态注解提供支持。该属性用于指明哪些注解是运行时(实际上运行时就是进行反射调用)可见的</td></tr><tr><td>RuntimelnvisibleAnnotations</td><td>类、方法表、字段表</td><td>JDK5中新增的属性,与 RuntimeVisibleAnnotations 属性作用刚好相反,用于指明哪些注解是运行时不可见的</td></tr><tr><td>RuntimeVisibleParameterAnnotations</td><td>方法表</td><td>JDK5中新增的属性,作用与 RuntimeVisibleAnotations 属性类似,只不过作用对象为方法参数</td></tr><tr><td>RuntimelnvisibleParameterAnnotations</td><td>方法表</td><td>JDK5中新增的属性,作用与 RuntimelnvisibleAnnotations 属性类似,只不过作用对象为方法参数</td></tr><tr><td>AnnotationDefault</td><td>方法表</td><td>JDK5中新增的属性,用于记录注解类元素的默认值</td></tr><tr><td>BootstrapMethods</td><td>类文件</td><td>JDK7中新增的属性,用于保存 invokedynamic指令引用的引导方法限定符</td></tr><tr><td>RuntimeVisibleTypeAnnotations</td><td>类、方法表、字段表、Code属性</td><td>JDK8中新增的属性,为实现JSR308中新增的类型注解提供的支持,用于指明哪些类注解是运行时(实际上运行时就是进行反射调用)可见的</td></tr><tr><td>RuntimelnvisibleTypeAnnotations</td><td>类、方法表、字段表、Code属性</td><td>JDK8中新增的属性,为实现JSR308中新增的类型注解提供的支持,与 RuntimeVisibleTypeAnntations 属性作用刚好相反,用于指明哪些注解是运行时不可见的</td></tr><tr><td>MethodParameters</td><td>方法表</td><td>JDK8中新增的属性,用于支持(编译时加上 -parameters参数)将方法名称编译进 Class文件中, 并可运行时获取。此前要获取方法名称(典型的如IDE的代码提示)只能通过 Javadoc中得到</td></tr><tr><td>Module</td><td>类</td><td>JDK9中新增的属性,用于记录一个 的名Module 称以及相关信息( requires、 exports, opens、uses provides)</td></tr><tr><td>ModulePackages</td><td>类</td><td>JDK9中新增的属性,用于记录一个模块中所有被 exports I或者 opens的包</td></tr><tr><td>ModuleMainClass</td><td>类</td><td>JDK9中新增的属性,用于指定一个模块的主类</td></tr><tr><td>NestHost</td><td>类</td><td>JDK11中新增的属性,用于支持嵌套类(Java中的内部类)的反射和访问控制的API,一个内部类通过该属性得知自己的宿主类</td></tr><tr><td>NestMembers</td><td>类</td><td>JDK11中新增的属性,用于支持嵌套类(Java中 的内部类)的反射和访问控制的API,一个宿主类通过该属性得知自己有哪些内部类</td></tr></tbody></table><h2 id="属性表结构"><a class="header-anchor" href="#属性表结构">¶</a>属性表结构</h2><p>对于每一个属性项,它的名称都要从常量池中引用一个CONSTANT_Utf8_info类型的常量来表示, 而<strong>属性值的结构则是完全自定义的</strong>,根据具体的属性信息有不一样的结构,只需要通过一个u4的长度属性去说明属性值所占用的位数即可。</p><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>具体的属性类型</td><td>attribute_info</td><td>attribute_length</td></tr></tbody></table><p>attribute_length表示attribute_info的长度，所以：<code>attribute_length值=整个属性表的长度 - 6</code>。</p><h3 id="Code属性"><a class="header-anchor" href="#Code属性">¶</a>Code属性</h3><p>Java程序方法体里面的代码经过Javac编译器处理之后,最终变为字节码指令存储在Code属性内。Code属性出现在方法表的属性集合之中,但并非所有的方法表都必须存在这个属性,譬如接口或者抽象类中的方法就不存在Code属性。</p><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>max_stack</td><td>1</td></tr><tr><td>u2</td><td>max_locaIs</td><td>1</td></tr><tr><td>u4</td><td>code_length</td><td>1</td></tr><tr><td>u1</td><td>code</td><td>code_length</td></tr><tr><td>u2</td><td>exception_table_length</td><td>1</td></tr><tr><td>exception_info</td><td>exception_table</td><td>exception_table_length</td></tr><tr><td>u2</td><td>attributes_count</td><td>1</td></tr><tr><td>attribute_info</td><td>attributes</td><td>attributes_count</td></tr></tbody></table><ul><li><p>attribute_name_index是一项指向CONSTANT_Utf8_info型常量的索引,此常量值固定为“Code”</p></li><li><p>attribute_length指示了属性值的长度</p></li><li><p>max_stack代表了操作数栈(Operand Stack)深度的最大值</p></li><li><p>max_locals代表了局部变量表所需的存储空间。在这里,max_locals的单位是变量槽(Slot),变量槽是虚拟机为局部变量分配内存所使用的最小单位。对于byte、char、float、int、short、boolean和returnAddress等长度不超过32位的数据类型,每个局部变量占用一个变量槽,而double和long这两种64 位的数据类型则需要两个变量槽来存放。方法参数(<strong>包括实例方法中的隐藏参数“this”</strong>)、显式异常处理程序的参数(Exception Handler Parameter,就是try-catch语句中catch块中所定义的异常)、方法体中定义的局部变量都需要依赖局部变量表来存放。注意,并不是在方法中用了多少个局部变量,就把这些局部变量所占变量槽数量之和作为max_locals的值,操作数栈和局部变量表直接决定一个该方法的栈帧所耗费的内存,不必要的操作数栈深度和变量槽数量会造成内存的浪费。Java虚拟机的做法是将局部变量表中的变量槽进行重用,当代码执行超出一个局部变量的作用域时,这个局部变量所占的变量槽可以被其他局部变量所使用,Javac编译器会根据变量的作用域来分配变量槽给各个变量使用,根据同时生存的最大局部变量数量和类型计算出max_locals的大小。</p></li><li><p>code_length和code用来存储Java源程序编译后生成的字节码指令。code_length代表字节码长度, code是用于存储字节码指令的一系列字节流。<strong>既然叫字节码指令,那顾名思义每个指令就是一个u1类型的单字节</strong>,当虚拟机读取到code中的一个字节码时,就可以对应找出这个字节码代表的是什么指令,并且可以知道这条指令后面是否需要跟随参数,以及后续的参数应当如何解析。我们知道一个u1 数据类型的取值范围为0x00<sub>0xFF,对应十进制的0</sub>255,也就是一共可以表达256条指令。目前, 《Java虚拟机规范》已经定义了其中约200条编码值对应的指令含义。</p><p>关于code_length,有一件值得注意的事情,虽然它是一个u4类型的长度值,理论上最大值可以达到2的32次幂,但是《Java虚拟机规范》中明确限制了一个方法不允许超过65535条字节码指令</p></li><li><p>exception_table_length和exception_table用来存储异常表，非必须，异常表结构如下：</p><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>start_pc</td><td>1</td></tr><tr><td>u2</td><td>end_pc</td><td>1</td></tr><tr><td>u2</td><td>handler_pc</td><td>1</td></tr><tr><td>u2</td><td>catch_type</td><td>1</td></tr></tbody></table><p>如果当字节码从第start_pc行到第end_pc行之间(不含第end_pc行)出现了类型为catch_type或者其子类的异常(catch_type为指向一个CONSTANT_Class_info型常量的索引),则转到第handler_pc行继续处理。当catch_type的值为0时,代表任意异常情况都需要转到handler_pc处进行处理。</p><p>异常表实际上是Java代码的一部分,尽管字节码中有最初为处理异常而设计的跳转指令,但《Java 虚拟机规范》中明确要求Java语言的编译器应当选择使用异常表而不是通过跳转指令来实现Java异常及<strong>finally处理机制</strong>。</p><p>例如：</p><pre class="line-numbers language-language-java"><code class="language-language-java">public int inc() {int x;try {x = 1;return x;} catch (Exception e) {x = 2;return x;} finally {x = 3;}}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上代码会生成三个异常表：</p><ul><li>如果try语句块中出现属于Exception或其子类的异常,转到catch语句块处理;</li><li>如果try语句块中出现不属于Exception或其子类的异常,转到finally语句块处理;</li><li>如果catch语句块中出现任何异常,转到finally语句块处理</li></ul></li></ul><h3 id="Exceptions属性"><a class="header-anchor" href="#Exceptions属性">¶</a>Exceptions属性</h3><p>这里的Exceptions属性是在方法表中与Code属性平级的一项属性,不要与前面刚刚讲解完的异常表产生混淆。Exceptions属性的作用是列举出方法中可能抛出的受查异常(Checked Excepitons),也就是方法描述时在throws关键字后面列举的异常。</p><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>number_of_exceptions</td><td>1</td></tr><tr><td>u2</td><td>exception_index_table</td><td>number_of_exception</td></tr></tbody></table><p>此属性中的number_of_exceptions项表示方法可能抛出number_of_exceptions种受查异常,每一种受查异常使用一个exception_index_table项表示;exception_index_table是一个指向常量池中CONSTANT_Class_info型常量的索引,代表了该受查异常的类型。</p><h3 id="LineNumberTable属性"><a class="header-anchor" href="#LineNumberTable属性">¶</a>LineNumberTable属性</h3><p>LineNumberTable属性用于描述Java源码行号与字节码行号(字节码的偏移量)之间的对应关系。</p><p>它并不是运行时必需的属性,但默认会生成到Class文件之中,可以在Javac中使用-g:none或-g:lines 选项来取消或要求生成这项信息。如果选择不生成LineNumberTable属性,对程序运行产生的最主要影响就是当抛出异常时,堆栈中将不会显示出错的行号,并且在调试程序的时候,也无法按照源码行来设置断点。</p><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>line_number_table_length</td><td>1</td></tr><tr><td>line_number_info</td><td>line_number_table</td><td>line_number_table_length</td></tr></tbody></table><p>line_number_table是一个数量为line_number_table_length、类型为line_number_info的集合, line_number_info表包含start_pc和line_number两个u2类型的数据项,前者是字节码行号,后者是Java源码行号。</p><h3 id="LocalVariableTable及LocalVariableTypeTable属性"><a class="header-anchor" href="#LocalVariableTable及LocalVariableTypeTable属性">¶</a>LocalVariableTable及LocalVariableTypeTable属性</h3><p>它是Code属性的子属性。LocalVariableTable属性用于描述栈帧中局部变量表的变量与Java源码中定义的变量之间的关系,它也不是运行时必需的属性,但默认会生成到Class文件之中,可以在Javac中使用-g:none或-g:vars选项来取消或要求生成这项信息。如果没有生成这项属性,最大的影响就是当其他人引用这个方法时,所有的参数名称都将会丢失,譬如IDE将会使用诸如arg0、arg1之类的占位符代替原有的参数名,这对程序运行没有影响,但是会对代码编写带来较大不便,而且在调试期间无法根据参数名称从上下文中获得参数值。</p><h4 id="LocalVariableTable结构"><a class="header-anchor" href="#LocalVariableTable结构">¶</a>LocalVariableTable结构</h4><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>local_variable_table_length</td><td>1</td></tr><tr><td>local_variable_info</td><td>local_variable_table</td><td>local_variable_table_length</td></tr></tbody></table><h4 id="local-variable-info结构"><a class="header-anchor" href="#local-variable-info结构">¶</a>local_variable_info结构</h4><p>其中local_variable_info项目代表了一个栈帧与源码中的局部变量的关联</p><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>start_pc</td><td>1</td></tr><tr><td>u2</td><td>length</td><td>1</td></tr><tr><td>u2</td><td>name_index</td><td>1</td></tr><tr><td>u2</td><td>descriptor_index</td><td>1</td></tr><tr><td>u2</td><td>index</td><td>1</td></tr></tbody></table><ul><li>start_pc和length属性分别代表了这个局部变量的生命周期开始的字节码偏移量及其作用范围覆盖的长度,两者结合起来就是这个局部变量在字节码之中的作用域范围。</li><li>name_index和descriptor_index都是指向常量池中CONSTANT_Utf8_info型常量的索引,分别代表了局部变量的名称以及这个局部变量的描述符。</li><li>index是这个局部变量在栈帧的局部变量表中变量槽的位置。当这个变量数据类型是64位类型时(double和long),它占用的变量槽为index和index+1两个。</li></ul><h4 id="LocalVariableTypeTable"><a class="header-anchor" href="#LocalVariableTypeTable">¶</a>LocalVariableTypeTable</h4><p>在JDK 5引入泛型之后,LocalVariableTable属性增加了一个“姐妹属性”——LocalVariableTypeTable。这个新增的属性结构与LocalV ariableTable非常相似,仅仅是把记录的字段描述符的descriptor_index替换成了字段的特征签名(Signature)。对于非泛型类型来说,描述符和特征签名能描述的信息是能吻合一致的,但是泛型引入之后,由于描述符中泛型的参数化类型被擦除掉,描述符就不能准确描述泛型类型了。因此出现了LocalV ariableTypeTable属性,使用字段的特征签名来完成泛型的描述。</p><h3 id="SourceFile及SourceDebugExtension属性"><a class="header-anchor" href="#SourceFile及SourceDebugExtension属性">¶</a>SourceFile及SourceDebugExtension属性</h3><p>SourceFile属性用于记录生成这个Class文件的源码文件名称。这个属性也是可选的,可以使用Javac 的-g:none或-g:source选项来关闭或要求生成这项信息。在Java中,对于大多数的类来说,类名和文件名是一致的,但是有一些特殊情况(如内部类)例外。如果不生成这项属性,当抛出异常时,堆栈中将不会显示出错代码所属的文件名。这个属性是一个定长的属性</p><h4 id="SourceFile属性结构"><a class="header-anchor" href="#SourceFile属性结构">¶</a>SourceFile属性结构</h4><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>sourcefile_index</td><td>1</td></tr></tbody></table><p>sourcefile_index数据项是指向常量池中CONSTANT_Utf8_info型常量的索引,常量值是源码文件的文件名。</p><h4 id="SourceDebugExtension"><a class="header-anchor" href="#SourceDebugExtension">¶</a>SourceDebugExtension</h4><p>为了方便在编译器和动态生成的Class中加入供程序员使用的自定义内容,在JDK 5时,新增了SourceDebugExtension属性用于存储额外的代码调试信息。典型的场景是在进行JSP文件调试时,无法通过Java堆栈来定位到JSP文件的行号。JSR 45提案为这些非Java语言编写,却需要编译成字节码并运行在Java虚拟机中的程序提供了一个进行调试的标准机制,使用SourceDebugExtension属性就可以用于存储这个标准所新加入的调试信息,譬如让程序员能够快速从异常堆栈中定位出原始JSP中出现问题的行号。</p><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u1</td><td>debug_extension[attribute_length]</td><td>1</td></tr></tbody></table><p>其中debug_extension存储的就是额外的调试信息,是一组通过变长UTF-8格式来表示的字符串。一个类中最多只允许存在一个SourceDebugExtension属性。</p><h3 id="ConstantValue属性"><a class="header-anchor" href="#ConstantValue属性">¶</a>ConstantValue属性</h3><p>ConstantValue属性的作用是通知虚拟机自动为静态变量赋值。只有被static关键字修饰的变量(类变量)才可以使用这项属性。</p><p>类似“int x=123”和“static int x=123”这样的变量定义在Java程序里面是非常常见的事情,但虚拟机对这两种变量赋值的方式和时刻都有所不同。</p><ul><li>对非static类型的变量(也就是实例变量)的赋值是在<code>&lt;init&gt;()</code>方法中进行的;</li><li>而对于类变量,则有两种方式可以选择:<ul><li>在<code>&lt;clinit&gt;()</code>方法中或者使用ConstantValue属性。目前Oracle公司实现的Javac编译器的选择是,如果同时使用final和static来修饰一个变量(按照习惯,这里称“常量”更贴切),并且这个变量的数据类型是基本类型或者<code>java.lang.String</code>的话,就将会生成ConstantValue属性来进行初始化;</li><li>如果这个变量没有被final修饰,或者并非基本类型及字符串,则将会选择在<code>&lt;clinit&gt;()</code>方法中进行初始化。</li></ul></li></ul><p>虽然有final关键字才更符合“ConstantValue”的语义,但《Java虚拟机规范》中并没有强制要求字段必须设置ACC_FINAL标志,只要求有ConstantValue属性的字段必须设置ACC_STATIC标志而已,<strong>对final关键字的要求是Javac编译器自己加入的限制</strong>。</p><p>而对ConstantValue的属性值只能限于基本类型和String这点,其实并不能算是什么限制,这是理所当然的结果。因为此属性的属性值只是一个常量池的索引号,由于Class文件格式的常量类型中只有与基本属性和字符串相对应的字面量,所以就算ConstantValue属性想支持别的类型也无能为力。</p><h4 id="属性结构"><a class="header-anchor" href="#属性结构">¶</a>属性结构</h4><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>constantvalue_index</td><td>1</td></tr></tbody></table><p>从数据结构中可以看出ConstantValue属性是一个定长属性,它的attribute_length数据项值必须固定为2。constantvalue_index数据项代表了常量池中一个字面量常量的引用,根据字段类型的不同,字面量可以是CONSTANT_Long_info、CONSTANT_Float_info、CONSTANT_Double_info、CONSTANT_Integer_info和CONSTANT_String_info常量中的一种。</p><h3 id="InnerClasses属性"><a class="header-anchor" href="#InnerClasses属性">¶</a>InnerClasses属性</h3><p>InnerClasses属性用于记录内部类与宿主类之间的关联。如果一个类中定义了内部类,那编译器将会为它以及它所包含的内部类生成InnerClasses属性。</p><h4 id="InnerClasses属性结构"><a class="header-anchor" href="#InnerClasses属性结构">¶</a>InnerClasses属性结构</h4><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>number_of_class</td><td>1</td></tr><tr><td>inner_class_info</td><td>inner_classes</td><td>number_of_class</td></tr></tbody></table><p>数据项number_of_classes代表需要记录多少个内部类信息,每一个内部类的信息都由一个inner_classes_info表进行描述。</p><h4 id="inner-classes-info结构"><a class="header-anchor" href="#inner-classes-info结构">¶</a>inner_classes_info结构</h4><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>inner_class_info_index</td><td>1</td></tr><tr><td>u2</td><td>outer_class_info_index</td><td>1</td></tr><tr><td>u2</td><td>inner_name_index</td><td>1</td></tr><tr><td>u2</td><td>inner_class_access_flags</td><td>1</td></tr></tbody></table><ul><li>inner_class_info_index和outer_class_info_index都是指向常量池中CONSTANT_Class_info型常量的索引,分别代表了内部类和宿主类的符号引用。</li><li>inner_name_index是指向常量池中CONSTANT_Utf8_info型常量的索引,代表这个内部类的名称, 如果是匿名内部类,这项值为0。</li><li>inner_class_access_flags是内部类的访问标志,类似于类的access_flags,它的取值范围如下<br>| 标志名称       | 标志值 | 含义                           |<br>| -------------- | ------ | ------------------------------ |<br>| ACC_PUBLIC     | 0x0001 | 内部类是否为public             |<br>| ACC_PRIVATE    | 0x0002 | 内部类是否为private            |<br>| ACC_PROTECTED  | 0x0004 | 内部类是否为protected          |<br>| ACC_STATIC     | 0x0008 | 内部类是否为static             |<br>| ACC_FINAL      | 0x0010 | 内部类是否为final              |<br>| ACC_INTERFACE  | 0x0020 | 内部类是否为接口               |<br>| ACC_ABSTRACT   | 0x0400 | 内部类是否为abstract           |<br>| ACC_SYNTHETIC  | 0x1000 | 内部类是否并非由用户代码产生的 |<br>| ACC_ANNOTATION | 0x2000 | 内部类是不是一个注解           |<br>| ACC_ENUM       | 0x4000 | 内部类是不是一个枚举           |</li></ul><h3 id="Deprecated及Synthetic属性"><a class="header-anchor" href="#Deprecated及Synthetic属性">¶</a>Deprecated及Synthetic属性</h3><p>Deprecated和Synthetic两个属性都属于标志类型的布尔属性,只存在有和没有的区别,没有属性值的概念。<br>Deprecated属性用于表示某个类、字段或者方法,已经被程序作者定为不再推荐使用,它可以通过代码中使用“@deprecated”注解进行设置。<br>Synthetic属性代表此字段或者方法并不是由Java源码直接产生的,而是由编译器自行添加的,在JDK 5之后,标识一个类、字段或者方法是编译器自动产生的,也可以设置它们访问标志中的ACC_SYNTHETIC标志位。编译器通过生成一些在源代码中不存在的Synthetic方法、字段甚至是整个类的方式,实现了越权访问(越过private修饰器)或其他绕开了语言限制的功能,这可以算是一种早期优化的技巧,其中最典型的例子就是枚举类中自动生成的枚举元素数组和嵌套类的桥接方法(Bridge Method)。所有由不属于用户代码产生的类、方法及字段都应当至少设置Synthetic属性或者ACC_SYNTHETIC标志位中的一项,唯一的例外是<code>&lt;init&gt;()</code>方法和类构造器<code>&lt;clinit&gt;()</code>方法。</p><h4 id="Deprecated和Synthetic属性的结构"><a class="header-anchor" href="#Deprecated和Synthetic属性的结构">¶</a>Deprecated和Synthetic属性的结构</h4><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr></tbody></table><p>其中attribute_length数据项的值必须为0x00000000,因为没有任何属性值需要设置。</p><h3 id="StackMapTable属性"><a class="header-anchor" href="#StackMapTable属性">¶</a>StackMapTable属性</h3><p>StackMapTable属性在JDK 6增加到Class文件规范之中,它是一个相当复杂的变长属性,位于Code 属性的属性表中。这个属性会在虚拟机类加载的字节码验证阶段被新类型检查验证器(Type Checker)使用,目的在于代替以前比较消耗性能的基于数据流分析的类型推导验证器。</p><h4 id="StackMapTable属性结构"><a class="header-anchor" href="#StackMapTable属性结构">¶</a>StackMapTable属性结构</h4><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>number_of_entries</td><td>1</td></tr><tr><td>stack_map_frame</td><td>stack_map_frame_entries</td><td>number_of_entries</td></tr></tbody></table><p>StackMapTable属性中包含零至多个栈映射帧(Stack Map Frame),每个栈映射帧都显式或隐式地代表了一个字节码偏移量,用于表示执行到该字节码时局部变量表和操作数栈的验证类型。类型检查验证器会通过检查目标方法的局部变量和操作数栈所需要的类型来确定一段字节码指令是否符合逻辑约束。</p><h3 id="Signature属性"><a class="header-anchor" href="#Signature属性">¶</a>Signature属性</h3><p>Signature属性在JDK 5增加到Class文件规范之中,它是一个可选的定长属性,可以出现于类、字段表和方法表结构的属性表中。在JDK 5里面大幅增强了Java语言的语法,在此之后,任何类、接口、初始化方法或成员的泛型签名如果包含了类型变量(Type Variable)或参数化类型(Parameterized Type),则Signature属性会为它记录泛型签名信息。之所以要专门使用这样一个属性去记录泛型类型,是因为Java语言的泛型采用的是擦除法实现的伪泛型,字节码(Code属性)中所有的泛型信息编译(类型变量、参数化类型)在编译之后都通通被擦除掉。使用擦除法的好处是实现简单(主要修改Javac编译器,虚拟机内部只做了很少的改动)、非常容易实现Backport,运行期也能够节省一些类型所占的内存空间。但坏处是运行期就无法像C#等有真泛型支持的语言那样,将泛型类型与用户定义的普通类型同等对待,例如运行期做反射时无法获得泛型信息。Signature属性就是为了弥补这个缺陷而增设的,现在Java的反射API能够获取的泛型类型,最终的数据来源也是这个属性。</p><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>singnature_index</td><td>1</td></tr></tbody></table><p>其中signature_index项的值必须是一个对常量池的有效索引。常量池在该索引处的项必须是CONSTANT_Utf8_info结构,表示类签名或方法类型签名或字段类型签名。如果当前的Signature属性是类文件的属性,则这个结构表示类签名,如果当前的Signature属性是方法表的属性,则这个结构表示方法类型签名,如果当前Signature属性是字段表的属性,则这个结构表示字段类型签名。</p><h3 id="BootstrapMethods属性"><a class="header-anchor" href="#BootstrapMethods属性">¶</a>BootstrapMethods属性</h3><p>BootstrapMethods属性在JDK 7时增加到Class文件规范之中,它是一个复杂的变长属性,位于类文件的属性表中。这个属性用于保存invokedynamic指令引用的引导方法限定符。<br>根据《Java虚拟机规范》(从Java SE 7版起)的规定,如果某个类文件结构的常量池中曾经出现过CONSTANT_InvokeDynamic_info类型的常量,那么这个类文件的属性表中必须存在一个明确的BootstrapMethods属性,另外,即使CONSTANT_InvokeDynamic_info类型的常量在常量池中出现过多次,类文件的属性表中最多也只能有一个BootstrapMethods属性。BootstrapMethods属性和JSR-292中的InvokeDynamic指令和java.lang.Invoke包关系非常密切,要介绍这个属性的作用,必须先讲清楚InovkeDynamic指令的运作原理。</p><p>虽然JDK 7中已经提供了InovkeDynamic指令,但这个版本的Javac编译器还暂时无法支持InvokeDynamic指令和生成BootstrapMethods属性,必须通过一些非常规的手段才能使用它们。直到JDK 8中Lambda表达式和接口默认方法的出现,InvokeDynamic指令才算在Java语言生成的Class文件中有了用武之地。</p><h4 id="BootstrapMethods属性结构"><a class="header-anchor" href="#BootstrapMethods属性结构">¶</a>BootstrapMethods属性结构</h4><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>num_bootstrap_methods</td><td>1</td></tr><tr><td>bootstrap_method</td><td>bootstrap_methods</td><td>num_bootstrap_methods</td></tr></tbody></table><h4 id="boostrap-method结构"><a class="header-anchor" href="#boostrap-method结构">¶</a>boostrap_method结构</h4><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>bootstrap_method_ref</td><td>1</td></tr><tr><td>u2</td><td>num_bootstrap_arguments</td><td>1</td></tr><tr><td>u2</td><td>bootstrap_arguments</td><td>num_boostrap_arguments</td></tr></tbody></table><p>BootstrapMethods属性里,num_bootstrap_methods项的值给出了bootstrap_methods[]数组中的引导方法限定符的数量。而bootstrap_methods[]数组的每个成员包含了一个指向常量池CONSTANT_MethodHandle结构的索引值,它代表了一个引导方法。还包含了这个引导方法静态参数的序列(可能为空)。bootstrap_methods[]数组的每个成员必须包含以下三项内容:</p><ul><li>bootstrap_method_ref:bootstrap_method_ref项的值必须是一个对常量池的有效索引。常量池在该索引处的值必须是一个CONSTANT_MethodHandle_info结构。</li><li>num_bootstrap_arguments:num_bootstrap_arguments项的值给出了bootstrap_argu-ments[]数组成员的数量。</li><li>bootstrap_arguments[]:bootstrap_arguments[]数组的每个成员必须是一个对常量池的有效索引。</li></ul><p>常量池在该索引处必须是下列结构之一：</p><ul><li>CONSTANT_String_info</li><li>CONSTANT_Class_info</li><li>CONSTANT_Integer_info</li><li>CONSTANT_Long_info</li><li>CONSTANT_Float_info</li><li>CONSTANT_Double_info</li><li>CONSTANT_MethodHandle_info</li><li>CONSTANT_MethodType_info</li></ul><h3 id="MethodParameters属性"><a class="header-anchor" href="#MethodParameters属性">¶</a>MethodParameters属性</h3><p>MethodParameters是在JDK 8时新加入到Class文件格式中的,它是一个用在方法表中的变长属性。</p><p>MethodParameters的作用是记录方法的各个形参名称和信息。</p><p>最初,基于存储空间的考虑,Class文件默认是不储存方法参数名称的,因为给参数起什么名字对计算机执行程序来说是没有任何区别的,所以只要在源码中妥当命名就可以了。随着Java的流行,这点确实为程序的传播和二次复用带来了诸多不便,由于Class文件中没有参数的名称,如果只有单独的程序包而不附加上JavaDoc的话,在IDE中编辑使用包里面的方法时是无法获得方法调用的智能提示的,这就阻碍了JAR包的传播。后来,“-g:var”就成为了Javac以及许多IDE编译Class时采用的默认值,这样会将方法参数的名称生成到LocalV ariableTable属性之中。不过此时问题仍然没有全部解决, LocalVariableTable属性是Code属性的子属性——没有方法体存在,自然就不会有局部变量表,但是对于其他情况,譬如抽象方法和接口方法,是理所当然地可以不存在方法体的,对于方法签名来说,还是没有找到一个统一完整的保留方法参数名称的地方。所以JDK 8中新增的这个属性,使得编译器可以(编译时加上-parameters参数)将方法名称也写进Class文件中,而且MethodParameters是方法表的属性,与Code属性平级的,可以运行时通过反射API获取。</p><h4 id="属性结构-v2"><a class="header-anchor" href="#属性结构-v2">¶</a>属性结构</h4><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u1</td><td>parameters_count</td><td>1</td></tr><tr><td>parameter</td><td>parameters</td><td>parameters_count</td></tr></tbody></table><h4 id="parameter结构"><a class="header-anchor" href="#parameter结构">¶</a>parameter结构</h4><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>name_index</td><td>1</td></tr><tr><td>u2</td><td>access_flags</td><td>1</td></tr></tbody></table><p>其中,name_index是一个指向常量池CONSTANT_Utf8_info常量的索引值,代表了该参数的名称。而access_flags是参数的状态指示器,它可以包含以下三种状态中的一种或多种:</p><ul><li>0x0010(ACC_FINAL):表示该参数被final修饰。</li><li>0x1000(ACC_SYNTHETIC):表示该参数并未出现在源文件中,是编译器自动生成的。</li><li>0x8000(ACC_MANDATED):表示该参数是在源文件中隐式定义的。Java语言中的典型场景是this关键字。</li></ul><h3 id="模块化相关属性"><a class="header-anchor" href="#模块化相关属性">¶</a>模块化相关属性</h3><p>JDK 9的一个重量级功能是Java的模块化功能,因为模块描述文件(module-info.java)最终是要编译成一个独立的Class文件来存储的,所以,Class文件格式也扩展了Module、ModulePackages和ModuleMainClass三个属性用于支持Java模块化相关功能。</p><h4 id="Module属性"><a class="header-anchor" href="#Module属性">¶</a>Module属性</h4><p>Module属性是一个非常复杂的变长属性,除了表示该模块的名称、版本、标志信息以外,还存储了这个模块requires、exports、opens、uses和provides定义的全部内容。</p><h5 id="属性结构-v3"><a class="header-anchor" href="#属性结构-v3">¶</a>属性结构</h5><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>module_name_index</td><td>1</td></tr><tr><td>u2</td><td>module_flags</td><td>1</td></tr><tr><td>u2</td><td>module_version_index</td><td>1</td></tr><tr><td>u2</td><td>requires_count</td><td>1</td></tr><tr><td>require</td><td>requires</td><td>requires_count</td></tr><tr><td>u2</td><td>exports_count</td><td>1</td></tr><tr><td>export</td><td>exports</td><td>exports_count</td></tr><tr><td>u2</td><td>opens_count</td><td>1</td></tr><tr><td>open</td><td>opens</td><td>opens_count</td></tr><tr><td>u2</td><td>uses_count</td><td>1</td></tr><tr><td>use</td><td>uses_index</td><td>uses_count</td></tr><tr><td>u2</td><td>provides_count</td><td>1</td></tr><tr><td>provide</td><td>provides</td><td>provides_count</td></tr></tbody></table><ul><li><p>其中,module_name_index是一个指向常量池CONSTANT_Utf8_info常量的索引值,代表了该模块的名称。而module_flags是模块的状态指示器,它可以包含以下三种状态中的一种或多种:</p><ul><li>0x0020(ACC_OPEN):表示该模块是开放的。</li><li>0x1000(ACC_SYNTHETIC):表示该模块并未出现在源文件中,是编译器自动生成的。</li><li>0x8000(ACC_MANDATED):表示该模块是在源文件中隐式定义的。</li></ul></li><li><p>module_version_index是一个指向常量池CONSTANT_Utf8_info常量的索引值,代表了该模块的版本号。</p></li><li><p>后续的几个属性分别记录了模块的requires、exports、opens、uses和provides定义。它们的结构是基本相似的</p></li></ul><h6 id="示例：export属性结构"><a class="header-anchor" href="#示例：export属性结构">¶</a>示例：export属性结构</h6><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>exports_index</td><td>1</td></tr><tr><td>u2</td><td>exports_flags</td><td>1</td></tr><tr><td>u2</td><td>exports_to_count</td><td>1</td></tr><tr><td>export</td><td>exports_to_index</td><td>exports_to_count</td></tr></tbody></table><p>exports属性的每一元素都代表一个被模块所导出的包</p><ul><li>exports_index是一个指向常量池CONSTANT_Package_info常量的索引值,代表了被该模块导出的包</li><li>exports_flags是该导出包的状态指示器,它可以包含以下两种状态中的一种或多种:<ul><li>0x1000(ACC_SYNTHETIC):表示该导出包并未出现在源文件中,是编译器自动生成的。</li><li>0x8000(ACC_MANDATED):表示该导出包是在源文件中隐式定义的。</li></ul></li><li>exports_to_count是该导出包的限定计数器,如果这个计数器为零,这说明该导出包是无限定的(Unqualified),即完全开放的,任何其他模块都可以访问该包中所有内容。如果该计数器不为零, 则后面的exports_to_index是以计数器值为长度的数组,每个数组元素都是一个指向常量池中CONSTANT_Module_info常量的索引值,代表着只有在这个数组范围内的模块才被允许访问该导出包的内容。</li></ul><h4 id="ModulePackages属性"><a class="header-anchor" href="#ModulePackages属性">¶</a>ModulePackages属性</h4><p>一个用于支持Java模块化的变长属性,它用于描述该模块中所有的包,不论是不是被export或者open的。</p><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>package_count</td><td>1</td></tr><tr><td>u2</td><td>package_index</td><td>package_count</td></tr></tbody></table><p>package_count是package_index数组的计数器,package_index中每个元素都是指向常量池CONSTANT_Package_info常量的索引值,代表了当前模块中的一个包。</p><h4 id="ModuleMainClass属性结构"><a class="header-anchor" href="#ModuleMainClass属性结构">¶</a>ModuleMainClass属性结构</h4><p>一个定长属性,用于确定该模块的主类(Main Class)</p><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>main_class_index</td><td>1</td></tr></tbody></table><p>其中,main_class_index是一个指向常量池CONSTANT_Class_info常量的索引值,代表了该模块的主类。</p><h3 id="运行时注解相关属性"><a class="header-anchor" href="#运行时注解相关属性">¶</a>运行时注解相关属性</h3><p>早在JDK 5时期,Java语言的语法进行了多项增强,其中之一是提供了对注解(Annotation)的支持。为了存储源码中注解信息,Class文件同步增加了：</p><ul><li>RuntimeVisibleAnnotations</li><li>RuntimeInvisibleAnnotations</li><li>RuntimeVisibleParameterAnnotations</li><li>RuntimeInvisibleParameterAnnotations</li></ul><p>四个属性。到了JDK 8时期,进一步加强了Java语言的注解使用范围,又新增类型注解(JSR 308),所以Class文件中也同步增加了：</p><ul><li>RuntimeVisibleTypeAnnotations</li><li>RuntimeInvisibleTypeAnnotations</li></ul><p>两个属性。由于这六个属性不论结构还是功能都比较雷同,因此把它们合并到一起,以RuntimeVisibleAnnotations为代表进行介绍。</p><p>RuntimeVisibleAnnotations是一个变长属性,它记录了类、字段或方法的声明上记录运行时可见注解,当我们使用反射API来获取类、字段或方法上的注解时,返回值就是通过这个属性来取到的。</p><h4 id="RuntimeVisibleAnnotations属性结构"><a class="header-anchor" href="#RuntimeVisibleAnnotations属性结构">¶</a>RuntimeVisibleAnnotations属性结构</h4><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>attribute_name_index</td><td>1</td></tr><tr><td>u4</td><td>attribute_length</td><td>1</td></tr><tr><td>u2</td><td>num_annotations</td><td>1</td></tr><tr><td>annotation</td><td>annotations</td><td>num_annotations</td></tr></tbody></table><p>num_annotations是annotations数组的计数器,annotations中每个元素都代表了一个运行时可见的注解,注解在Class文件中以annotation结构来存储</p><h4 id="annotation结构"><a class="header-anchor" href="#annotation结构">¶</a>annotation结构</h4><table><thead><tr><th>类型</th><th>名称</th><th>数量</th></tr></thead><tbody><tr><td>u2</td><td>type_index</td><td>1</td></tr><tr><td>u2</td><td>num_element_value_paires</td><td>1</td></tr><tr><td>element_value_pair</td><td>element_value_paires</td><td>num_element_value_paires</td></tr></tbody></table><p>type_index是一个指向常量池CONSTANT_Utf8_info常量的索引值,该常量应以字段描述符的形式表示一个注解。num_element_value_pairs是element_value_pairs数组的计数器,element_value_pairs中每个元素都是一个键值对,代表该注解的参数和值。</p><h1>Class文件结构解析及示例</h1><pre class="line-numbers language-language-java"><code class="language-language-java">package john.classloader;/** * @author: honphan.john * @date: 2020/9/10 17:14 * @description: */public class ClassLoaderTest1 {    public static void main(String[] args) {        ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader();        System.out.println(systemClassLoader); //sun.misc.Launcher$AppClassLoader@18b4aac2        ClassLoader parent = systemClassLoader.getParent();        System.out.println(parent); //sun.misc.Launcher$ExtClassLoader@4dc63996        ClassLoader boostrap = parent.getParent();        System.out.println(boostrap); //null        ClassLoader classLoader = ClassLoaderTest1.class.getClassLoader();        System.out.println(classLoader); //sun.misc.Launcher$AppClassLoader@18b4aac2        ClassLoader strClassLoader = String.class.getClassLoader();        System.out.println(strClassLoader); //null    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>javap工具生成非正式的&quot;虚拟机汇编语言&quot;(方法中的代码转成jvm指令集中指令的&quot;Java的汇编形式&quot;)，格式如下：<code>&lt;index&gt;&lt;opcode&gt;[&lt;operand1&gt;[&lt;operand2&gt;...]][&lt;comment&gt;]</code></p><ol><li><code>&lt;index&gt;</code>是指令操作码在数组中的下标，该数组以字节形式来存储当前方法的Java虚拟机代码；也可以是相对于方法起始处的字节偏移量</li><li><code>&lt;opcode&gt;</code>是指令的助记码，<code>&lt;operand&gt;</code>是操作数、<code>&lt;comment&gt;</code>是行尾的注释</li></ol><pre class="line-numbers language-language-shell"><code class="language-language-shell">zhonghongpeng@bogon classloader % javap -v ./ClassLoaderTest1.class <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-language-java"><code class="language-language-java">Classfile /Users/zhonghongpeng/IdeaProjects/tech-learning/jvm/target/classes/john/classloader/ClassLoaderTest1.class  Last modified 2020-9-10; size 988 bytes  MD5 checksum 2a924364f2c3f7e3670c6bba0d4fb145  Compiled from "ClassLoaderTest1.java"public class john.classloader.ClassLoaderTest1  minor version: 0  major version: 52  flags: ACC_PUBLIC, ACC_SUPERConstant pool:   #1 = Methodref          #9.#29         // java/lang/Object."<init>":()V   #2 = Methodref          #30.#31        // java/lang/ClassLoader.getSystemClassLoader:()Ljava/lang/ClassLoader;   #3 = Fieldref           #32.#33        // java/lang/System.out:Ljava/io/PrintStream;   #4 = Methodref          #34.#35        // java/io/PrintStream.println:(Ljava/lang/Object;)V   #5 = Methodref          #30.#36        // java/lang/ClassLoader.getParent:()Ljava/lang/ClassLoader;   #6 = Class              #37            // john/classloader/ClassLoaderTest1   #7 = Methodref          #38.#39        // java/lang/Class.getClassLoader:()Ljava/lang/ClassLoader;   #8 = Class              #40            // java/lang/String   #9 = Class              #41            // java/lang/Object  #10 = Utf8               <init>  #11 = Utf8               ()V  #12 = Utf8               Code  #13 = Utf8               LineNumberTable  #14 = Utf8               LocalVariableTable  #15 = Utf8               this  #16 = Utf8               Ljohn/classloader/ClassLoaderTest1;  #17 = Utf8               main  #18 = Utf8               ([Ljava/lang/String;)V  #19 = Utf8               args  #20 = Utf8               [Ljava/lang/String;  #21 = Utf8               systemClassLoader  #22 = Utf8               Ljava/lang/ClassLoader;  #23 = Utf8               parent  #24 = Utf8               boostrap  #25 = Utf8               classLoader  #26 = Utf8               strClassLoader  #27 = Utf8               SourceFile  #28 = Utf8               ClassLoaderTest1.java  #29 = NameAndType        #10:#11        // "<init>":()V  #30 = Class              #42            // java/lang/ClassLoader  #31 = NameAndType        #43:#44        // getSystemClassLoader:()Ljava/lang/ClassLoader;  #32 = Class              #45            // java/lang/System  #33 = NameAndType        #46:#47        // out:Ljava/io/PrintStream;  #34 = Class              #48            // java/io/PrintStream  #35 = NameAndType        #49:#50        // println:(Ljava/lang/Object;)V  #36 = NameAndType        #51:#44        // getParent:()Ljava/lang/ClassLoader;  #37 = Utf8               john/classloader/ClassLoaderTest1  #38 = Class              #52            // java/lang/Class  #39 = NameAndType        #53:#44        // getClassLoader:()Ljava/lang/ClassLoader;  #40 = Utf8               java/lang/String  #41 = Utf8               java/lang/Object  #42 = Utf8               java/lang/ClassLoader  #43 = Utf8               getSystemClassLoader  #44 = Utf8               ()Ljava/lang/ClassLoader;  #45 = Utf8               java/lang/System  #46 = Utf8               out  #47 = Utf8               Ljava/io/PrintStream;  #48 = Utf8               java/io/PrintStream  #49 = Utf8               println  #50 = Utf8               (Ljava/lang/Object;)V  #51 = Utf8               getParent  #52 = Utf8               java/lang/Class  #53 = Utf8               getClassLoader{  public john.classloader.ClassLoaderTest1();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=1, locals=1, args_size=1         0: aload_0         1: invokespecial #1                  // Method java/lang/Object."<init>":()V         4: return      LineNumberTable:        line 8: 0      LocalVariableTable:        Start  Length  Slot  Name   Signature            0       5     0  this   Ljohn/classloader/ClassLoaderTest1;  public static void main(java.lang.String[]);    descriptor: ([Ljava/lang/String;)V    flags: ACC_PUBLIC, ACC_STATIC    Code:      stack=2, locals=6, args_size=1         0: invokestatic  #2                  // Method java/lang/ClassLoader.getSystemClassLoader:()Ljava/lang/ClassLoader;         3: astore_1         4: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;         7: aload_1         8: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/Object;)V        11: aload_1        12: invokevirtual #5                  // Method java/lang/ClassLoader.getParent:()Ljava/lang/ClassLoader;        15: astore_2        16: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;        19: aload_2        20: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/Object;)V        23: aload_2        24: invokevirtual #5                  // Method java/lang/ClassLoader.getParent:()Ljava/lang/ClassLoader;        27: astore_3        28: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;        31: aload_3        32: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/Object;)V        35: ldc           #6                  // class john/classloader/ClassLoaderTest1        37: invokevirtual #7                  // Method java/lang/Class.getClassLoader:()Ljava/lang/ClassLoader;        40: astore        4        42: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;        45: aload         4        47: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/Object;)V        50: ldc           #8                  // class java/lang/String        52: invokevirtual #7                  // Method java/lang/Class.getClassLoader:()Ljava/lang/ClassLoader;        55: astore        5        57: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;        60: aload         5        62: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/Object;)V        65: return      LineNumberTable:        line 10: 0        line 11: 4        line 13: 11        line 14: 16        line 16: 23        line 17: 28        line 19: 35        line 20: 42        line 22: 50        line 23: 57        line 24: 65      LocalVariableTable:        Start  Length  Slot  Name   Signature            0      66     0  args   [Ljava/lang/String;            4      62     1 systemClassLoader   Ljava/lang/ClassLoader;           16      50     2 parent   Ljava/lang/ClassLoader;           28      38     3 boostrap   Ljava/lang/ClassLoader;           42      24     4 classLoader   Ljava/lang/ClassLoader;           57       9     5 strClassLoader   Ljava/lang/ClassLoader;}SourceFile: "ClassLoaderTest1.java"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>06_方法区</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/06-fang-fa-qu/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/06-fang-fa-qu/</url>
      
        <content type="html"><![CDATA[<h1>栈、堆、方法区的交互关系</h1><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234504.png" alt="image-20200916164449831"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234511.png" alt="image-20200916164505074"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234517.png" alt="image-20200916164613255"></p><h1>方法区的理解</h1><ul><li>方法区看作是一块独立于Java堆的内存空间，在HotSpotJVM中它有一个别名叫做Non-Heap（非堆），目的就是要和堆分开。</li><li>方法区（Method Area）与Java堆一样，是各个线程共享的内存区域。</li><li>方法区在JVM启动的时候被创建，并且它的实际的物理内存空间中和Java堆区一样都可以是不连续的。</li><li>方法区的大小，跟堆空间一样，可以选择固定大小或者可扩展。</li><li>方法区的大小决定了系统可以保存多少个类，如果系统定义了太多的类，导致方法区溢出，虚拟机同样会抛出内存溢出错误：<code>java.lang.OutOfMeoryError: PermGen space</code>或者<code>java.lang.OutOfMemoryError: Metaspace</code></li><li>关闭JVM就会释放这个区域的内存</li></ul><h1>方法区的内部结构</h1><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234527.png" alt="image-20200916173238733"></p><h2 id="存储内容"><a class="header-anchor" href="#存储内容">¶</a>存储内容</h2><p>它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234538.png" alt="image-20200916173331932"></p><h3 id="类型信息"><a class="header-anchor" href="#类型信息">¶</a>类型信息</h3><p>对每个加载的类型（类class、接口interface、枚举enum、注解annotation），JVM必须在方法区中存储以下类型信息：</p><ol><li>这个类型的完整有效名称</li><li>这个类型直接父类的完整有效名（对于interface或者是<code>java.lang.Object</code>都没有父类）</li><li>这个类型的修饰符（public、abstrace、final的某个子集）</li><li>这个类型直接接口的一个有序列表</li></ol><h3 id="域（Field）信息"><a class="header-anchor" href="#域（Field）信息">¶</a>域（Field）信息</h3><ul><li>JVM必须在方法区中保存类型的所有域的相关信息以及域的声明顺序。</li><li>域的相关信息包含：域名称、域类型、域修饰符（public、private、protected、static、final、volatile、transient的某个子集）</li></ul><h3 id="方法（Method）信息"><a class="header-anchor" href="#方法（Method）信息">¶</a>方法（Method）信息</h3><p>JVM必须保存所有方法的以下信息，同域信息一样包括声明顺序：</p><ul><li>方法名称</li><li>方法的返回类型（或void）</li><li>方法参数的数量和类型（按顺序）</li><li>方法的修饰符（public、private、protected、static、final、synchronized、native、abstract的一个子集）</li><li>方法的字节码（bytecodes）、操作数栈和局部变量表的大小（abstract和native方法除外）</li><li>异常表（abstract和native方法除外）<ul><li>每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的引用</li></ul></li></ul><h3 id="运行时常量池VS常量池"><a class="header-anchor" href="#运行时常量池VS常量池">¶</a>运行时常量池VS常量池</h3><p>方法区中的运行时常量池和字节码文件中的常量池是不同的。</p><h4 id="字节码文件的常量池"><a class="header-anchor" href="#字节码文件的常量池">¶</a>字节码文件的常量池</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234545.png" alt="image-20200916180016967"></p><p>一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述信息外，还包含一项信息那就是常量池表（Constant Pool Table），包含各种字面量(右值)和对类型、域和方法的<strong>符号</strong>(左值)引用。</p><h5 id="字节码文件中为什么需要常量池"><a class="header-anchor" href="#字节码文件中为什么需要常量池">¶</a>字节码文件中为什么需要常量池</h5><ol><li>配合构建字节码文件的自描述能力</li><li>压缩字节码文件大小（符号引用不会替换成其指向的字节码内容、使用二进制位进行描述）</li></ol><h4 id="运行时常量池"><a class="header-anchor" href="#运行时常量池">¶</a>运行时常量池</h4><ul><li>运行时常量池(Runtime Constant Pool)是方法区的一部分。</li><li>常量池表（Constant Pool Table）是Class文件的一部分，用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。</li><li>运行时常量池在加载类和接口到虚拟机后，就会创建。</li><li>JVM为每个已加载的类型（类或接口）都维护一个常量池。池中的数据项像数组一样，是通过索引访问的。</li><li>运行时常量池中包含多种不同的常量，包含编译期就已经明确的数值字面量，也包括到运行期解析后才能够获得的方法或者字段引用。此时不再是常量池中的符号引用了，已经替换为真实的直接引用。</li><li>当创建类或接口的运行时常量池时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大值，则JVM就会抛出OutOfMemoryError</li></ul><h5 id="运行时常量池中的-常量"><a class="header-anchor" href="#运行时常量池中的-常量">¶</a>运行时常量池中的&quot;常量&quot;</h5><p>运行时常量池之中主要存放的两大类常量：字面量和符号引用。</p><p>字面量比较接近Java语言层次的常量概念，如文本字符串、被声明为final的常量值等；而符号引用则属于编译原理方面的概念，包含下面三类常量：</p><ol><li>类和接口的全限定名</li><li>字段的名称和描述符</li><li>方法的名称和描述符</li></ol><h5 id="补充：non-final的类变量和final修饰的类变量"><a class="header-anchor" href="#补充：non-final的类变量和final修饰的类变量">¶</a>补充：non-final的类变量和final修饰的类变量</h5><ul><li>非final静态变量和类关联在一起，随着类的加载而加载，它们成为类数据在逻辑上的一部分。类变量被类的所有实例共享，即使没有类实例时你也可以访问它</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234554.png" alt="image-20200916174431865"></p><ul><li>被声明为final的类变量和非final类变量初始化时机不同。。</li></ul><h1>方法区的演进细节</h1><h2 id="占用内存位置调整"><a class="header-anchor" href="#占用内存位置调整">¶</a>占用内存位置调整</h2><p>在JDK7及之前，习惯上把方法区，称为永久代。JDK8开始，使用元空间取代了永久代。</p><p>本质上，方法区和永久代并不等价，仅是因为Hotspot JVM中垃圾收集器将方法区定义为永久代。《Java虚拟机规范》对如何实现方法区，不做统一要求。例如：BEA JRockit/IBM J9中不存在永久代的概念。</p><p>现在看来，当年使用永久代，不是好的idea。导致Java程序更容易OOM（超过<code>-XX:MaxpermSize</code>上限）。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234603.png" alt="image-20200916170345428"></p><p>而到了JDK8，终于完全废弃了永久代的概念，该用与JRockit、J9一样在本地内存中实现的元空间（Metaspace）来代替</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234609.png" alt="image-20200916170454628"></p><p>元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代最大的区别在于：元空间不在虚拟机控制的内存中，而是使用本地内存。</p><p>永久代、元空间二者并不只是名字变了，内存结构也调整了。</p><p>根据《Java虚拟机规范》的规定，如果方法区无法满足新的内存分配需求时，将抛出OOM异常</p><h2 id="存储内容变化"><a class="header-anchor" href="#存储内容变化">¶</a>存储内容变化</h2><ol><li><p>首先明确，只有HotSpot才有永久代。BEA JRockit、IBM J9等不存在永久代的概念。</p></li><li><p>Hotspot中方法区的变化：</p><table><thead><tr><th>版本</th><th>说明</th></tr></thead><tbody><tr><td>JDK1.6及之前</td><td>有永久代（permanent generation），静态(类)变量放在永久代上</td></tr><tr><td>JDK1.7</td><td>有永久代，但已经逐步&quot;去永久代&quot;，字符串常量池、静态(类)变量移到在堆中，永久代其它信息不变</td></tr><tr><td>JDK1.8及之后</td><td>无永久代，类型信息、字段、方法、常量(JDK1.6运行时常量池中除字符串常量之外的其它常量)保存在本地内存的元空间，但字符串常量池、静态(类)变量仍在堆</td></tr></tbody></table></li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234615.png" alt="image-20200916183025199"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234622.png" alt="image-20200916183040354"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234627.png" alt="image-20200916183124256"></p><h2 id="关于静态-类-变量需要注意的点"><a class="header-anchor" href="#关于静态-类-变量需要注意的点">¶</a>关于静态(类)变量需要注意的点</h2><p>上面提到静态变量在JDK1.6及之前都是在永久代，在7及之后才移到堆(老年代)中。以下特别说明一个情况：</p><p>加上<code>-XX:+PrintGCDetails</code>分别在JDK6、JDK7、JDK8运行下面这段代码，在程序退出之后会打印退出的时候各分代信息，发现无论是6、7还是8，始终是老年代的内存占用102400K的字节，说明这个字节数组无论是在6，7还是8都落在了堆的老年代中（应该是size太大，直接进入老年代）。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234634.png" alt="image-20200916205847835"></p><p>JDK7和8都将静态变量移到了堆，这个可以理解，但是为什么在JDK6中静态变量也是这样呢？因为目前为止无论是任何版本，对象的创建都是保存在堆中（栈上分配也没有实现对象分配，而是标量替换后进行分配），我们讲的静态常量指的是它保存的一个引用，即该数组对象的地址在JDK6中保存在永久代的，而无论在任何版本，该数组对象本身的数据内容都是存放在堆中。而7及之后则是将该静态变量放到了<code>java.lang.Class</code>对象中进行保存，该对象也是在堆中。所以现在的结构就是：</p><p>方法区类元信息-------引用--------&gt;<code>java.lang.class</code>-------包含--------&gt;静态变量-------引用--------&gt;数组对象</p><p>而6及之前的结构应该是：</p><p>方法区类元信息(包含静态变量)-------引用--------&gt;<code>java.lang.class</code></p><p>​|-------引用--------&gt;数组对象</p><p>除了方法区元信息之后，其它数据都在堆区，其中方法区类元信息也是GC Root。</p><p>下面例子再次进行说明：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234641.png" alt="image-20200916203914505"></p><p>可以使用JHSDB工具分析上面带面执行过程<code>staticObj</code>、<code>instanceObj</code>、<code>localObj</code>三个静态、实例、方法局部变量涉及的内存分布。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234648.png" alt="image-20200916203843641"></p><p><code>staticObj</code>随着Test的类型信息存放在方法区，<code>instanceObj</code>随着Test的对象实例存放在Java堆，<code>localObj</code>则是存放在<code>foo()</code>方法栈帧的局部变量表中。经过工具分析得到以下结果：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234656.png" alt="image-20200916204326241"></p><p>三个对象的数据都落在Eden区范围内（且是递增的），（所以结论：只要是对象实例必然会在Java堆中分配。）接着，找到了一个引用该<code>staticObj</code>对象的地方，是在一个<code>java.lang.Class</code>的实例里，并且<code>java.lang.Class</code>类型的对象实例，里面有一个名为<code>staticObj</code>的实例字段：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234701.png" alt="image-20200916204746680"></p><p>从《Java虚拟机规范》所定义的概念模型来看，所有Class相关的信息都应该存放在方法区之中，但方法区该如何实现，《Java虚拟机规范》并未做出规定，这就成了一件允许不同虚拟机自己灵活把握的事情。<strong>JDK7及其以后版本的HotSpot虚拟机选择把静态变量与描述类型的Java语言Class对象</strong>放在一起，存储于Java堆中。</p><h2 id="永久代为什么要被元空间替代"><a class="header-anchor" href="#永久代为什么要被元空间替代">¶</a>永久代为什么要被元空间替代</h2><ul><li><p>随着Java8的到来，HotSpot VM中再也见不到永久代了。但是这并不意味着类的元数据信息也消息了。这些数据被移到了一个与堆不相连的本地内存区域，这个区域叫做元空间（Metaspace）。</p></li><li><p>由于类的元数据分配在本地内存中，元空间的最大可分配空间就是系统可用内存空间。</p></li><li><p>这项改动是很有必要的，原因有：</p><ol><li><p>为永久代设置空间大小是很难确定的</p><p>在某些场景下，如果动态加载类过多，容易产生Perm区的OOM。比如某个实际Web工程中，因为功能点比较多，在运行过程中，要不断动态加载很多类，经常出现致命错误。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234709.png" alt="image-20200916183640560"></p><p>而元空间和永久代之间最大区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。</p></li><li><p>对永久代进行调优是很困难的</p></li></ol></li></ul><h1>设置方法区大小与OOm</h1><ul><li><p>方法区的大小不必是固定的，JVM可以根据应用的需要动态调整。</p></li><li><p>JDK7及之前：</p><ul><li><p>通过<code>-XX:PermSize=&lt;N&gt;</code>来设置永久代初始分配空间。默认值是20.75M。</p></li><li><p><code>-XX:MaxPermSize</code>来设定永久代最大可分配空间。32位及其默认是64M，64位及其默认是82M。</p></li><li><p>当JVM加载的类信息容量超过了这个值，会报异常OutOfMemoryError：PermGem space</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234714.png" alt="image-20200916171545341"></p></li></ul></li><li><p>JDK8及之后：</p><ul><li>元数据区大小可以使用参数<code>-XX:MetaspaceSize</code>和<code>-XX:MaxMetaspaceSize</code>指定，替代上述原有的两个参数。</li><li>默认指依赖于平台。Windows下，<code>-XX:MetaspaceSize</code>是21M，<code>-XX:MaxMetaspaceSize</code>的值是-1，即没有限制。</li><li>与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据区发生溢出，虚拟机一样会抛出异常OutOfMemoryError: Mataspace</li><li><code>-XX:MetaspaceSize:&lt;N&gt;</code>设置初始的元空间大小。对于一个64位的服务端JVM来说，其默认值位21MB。这就是初始的高水位线，一旦触及这个水位线，Full GC将会触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置。新的高水位线的值取决于GC后释放了多少元空间。如果释放的空间不足，那么在不超过<code>MaxMetaspaceSize</code>时，适当提高该值。如果释放空间过多，则适当降低该值。</li><li>如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次。通过垃圾回收器的日志可以观察到Full GC多次调用。为了避免频繁的GC，建议将<code>-XX:MetaspaceSize</code>设置为一个相对较高的值。</li></ul></li></ul><h2 id="OOM例子"><a class="header-anchor" href="#OOM例子">¶</a>OOM例子</h2><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234721.png" alt="image-20200916172507704"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234727.png" alt="image-20200916172530703"></p><h2 id="如何解决这些OOM"><a class="header-anchor" href="#如何解决这些OOM">¶</a>如何解决这些OOM</h2><ol><li>要解决OOM异常，一般的手段是首先通过内存映象分析工具对dump出来的堆转存快照进行分析，终点是确认内存中的对象是否是必要的，也就是先分清楚是不是内存泄露（Memory Leak）导致的内存溢出（Memory Overflow）。</li><li>如果是内存泄露，可进一步通过工具查看泄露对象到GC Roots的引用链。于是就能找到泄露对象是通过怎样的路径与GC Roots相关联并导致垃圾收集器无法自动回收它们的。掌握了泄露对象的类型信息，以及GC Roots引用链信息，就可以比较准确地定位出泄露代码的位置。</li><li>如果不存在内存泄露，换句话说就是内存中的对象确实都还必须存活着，那就应当检查虚拟机的堆参数（<code>-Xmx</code>与<code>-Xms</code>），与机器物理内存对比看是否还可以调大，从代码上检查是否存在某些对象生命周期过长、持有状态时间过长的情况，尝试减少程序运行期的内存消耗。</li></ol><h1>方法区的垃圾回收</h1><p>《Java虚拟机规范》对方法区的约束非常宽松，提到过可以不要求虚拟机在方法区中实现垃圾收集。事实上也确实有未实现或未能完整实现方法区类型卸载的收集器存在（如JDK11时期的ZGC收集器就不支持类卸载）</p><p>一般来说这个区域的回收效果比较难令人满意，尤其是类型的卸载，条件相当苛刻。但是这部分区域的回收有时又确实是必要的。以前Sun公司的Bug列表中，曾出现过的若干个严重的Bug就是由于低版本的HotSpot虚拟机对此区域未完全回收而导致内存泄露。</p><p>方法区的垃圾收集主要回收两部分内容：常量池中废弃的常量和不再使用的类型。HotSpot虚拟机对常量池的回收策略是很明确的，只要常量池中的常量没有被任何地方引用，就可以被回收。回收废弃常量与回收Java堆中的对象非常类似。</p><p>判定一个常量是否&quot;废弃&quot;还是相对简单，而要判定一个类型是否属于&quot;不再被使用的类&quot;的条件就比较苛刻了。需要同时满足下面三个条件：</p><ul><li>该类所有的实例都已经被回收,也就是Java堆中不存在该类及其任何派生子类的实例。</li><li>加载该类的类加载器已经被回收,这个条件除非是经过精心设计的可替换类加载器的场景,如OSGi、JSP的重加载等,否则通常是很难达成的。</li><li>该类对应的<code>java.lang.Class</code>对象(在堆中)没有在任何地方被引用,无法在任何地方通过反射访问该类的方法</li></ul><p>Java虚拟机被允许对满足上述三个条件的无用类进行回收,这里说的仅仅是“被允许”,而并不是和对象一样,没有引用了就必然会回收。关于是否要对类型进行回收,HotSpot虚拟机提供了<code>- Xnoclassgc</code>参数进行控制,还可以使用<code>-verbose:class</code>以及-<code>XX:+TraceClassLoading</code>、<code>-XX: +TraceClassUnLoading</code>查看类加载和卸载信息,其中-verbose:class和<code>-XX:+TraceClassLoading</code>可以在Product版的虚拟机中使用,<code>-XX:+TraceClassUnLoading</code>参数需要FastDebug版的虚拟机支持。<br>在大量使用反射、动态代理、CGLib等字节码框架,动态生成JSP以及OSGi这类频繁自定义类加载器的场景中,通常都需要Java虚拟机具备类型卸载的能力,以保证不会对方法区造成过大的内存压力。</p><h1>StringTable为什么要调整</h1><p>JDK7中将StringTable(字符串常量池)放到了堆空间中，因为永久代的回收效率很低，所以只有在Full GC的时候才会触发。而Full GC是老年代的空间不足、永久代不足时才会触发。这就导致StringTable回收频率不高。而我们开发中会有大量的字符串被创建，将其移到堆中划分老年代是为了提高回收频率。</p>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>01_运行时数据区</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/01-yun-xing-shi-shu-ju-qu/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/01-yun-xing-shi-shu-ju-qu/</url>
      
        <content type="html"><![CDATA[<h1>概述</h1><p>内存是非常重要的资源，是硬盘和CPU的中间仓库及桥梁，承载着操作系统和应用程序的实时运行。JVM内存布局规定了Java在运行过程中内存申请、分配、管理的策略，保证了JVM的高效稳定运行。不同的JVM对于内存的划分方式和管理机制存在着部分差异。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233351.png" alt="image-20200911073849034"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233357.png" alt="image-20200911074007528"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233403.png" alt="image-20200911074230149"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233411.png" alt="image-20200916211334192"></p><h1>运行时数据区分类</h1><p>Java虚拟机定义了若干种程序运行期间会使用到的运行时数据区，其中有一些会随着虚拟机启动而创建，随着虚拟机退出而销毁。另外一些则是与线程一一对应的，这些与线性对应的数据区会随着线程开始和结束而创建和销毁。</p><ul><li>每个线程：独立包括程序计数器、栈、本地方法栈</li><li>线程间共享：堆、堆外内存（永久代或元空间、代码缓存）</li></ul><h1>Runtime实例</h1><p>每个JVM只有一个<code>Runtime</code>实例。即内存结构中的运行时环境。可以通过<code>Runtime#getRuntime()</code>方法获取。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233432.png" alt="image-20200911074617973"></p><h1>堆、栈</h1><p>下面是一些个人经过一些书籍和资料查询总结对于堆栈的理解。首先在数据结构上堆是一棵结点具有权重的树，栈是一个先进后出的线性表，而我们这里讨论的是计算机内存管理中的栈区和堆区，栈区和堆区在物理上没有实质的区别，主要是管理上的区别。计算机的硬件(CPU)提供了栈区的实现基础，包括直接提供了一些相关的寄存器和操作指令的支持，栈空间(每一个线程)的分配和销毁都由操作系统来完成；而堆是由库函数按照一定的规则进行动态分配的。对于用户程序来说，栈空间的使用效率会更高。</p><p>计算机硬件对栈的支持（相关寄存器和操作指令）源于计算机硬件要实现的业务中一些业务逻辑符合先进后出的线性结构。如函数调用：调用函数调用被调用函数的时候，需要保存调用方法的寄存器信息，这时候就会用到堆栈将这些信息进行压栈，被调用方法执行完成之后返回的时候进行弹栈还原函数的寄存器。(线程切换应该也可以用到)</p><p>如果用户的程序业务逻辑有符合栈结构，可以考虑直接使用系统直接提供的栈空间。</p><blockquote><p>疑问：用户可以使用栈空间吗？如果可以，是否需要在方法返回前进行弹栈操作，还原状态为和调用本方法入口时的压栈状态一致？</p></blockquote><h2 id="一、转载：堆与栈"><a class="header-anchor" href="#一、转载：堆与栈">¶</a>一、转载：堆与栈</h2><p>“栈”一般是由硬件（CPU）实现的，CPU用栈来保存调用子程序（函数）时的返回地址，高级语言有时也用它作为局部变量的存储空间。</p><p>“堆”是个实实在在的软件概念，使用与否完全由编程者“显示地（explicitly）”决定，如malloc。</p><p>程序经过编译连接生成执行程序后，堆和栈的起始地址就已经确定了（具体说，是通过“连接程序”），在一个具有反向增长的栈的CPU上，数据空间可表示如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233444.png" alt="栈增长"></p><p>注意：</p><blockquote><p>进程地址空间的分布取决于操作系统，栈向什么方向增长取决于操作系统与CPU的组合。</p><p>不要把别的操作系统的实现方式套用到Windows上。</p><p>栈的增长方向与栈帧布局这个上下文里说的“栈”是函数调用栈，是以“栈帧”（stack frame）为单位的。每一次函数调用会在栈上分配一个新的栈帧，在这次函数调用结束时释放其空间。被调用函数（callee）的栈帧相对调用函数（caller）的栈帧的位置反映了栈的增长方向：如果被调用函数的栈帧比调用函数的在更低的地址，那么栈就是向下增长；反之则是向上增长。而在一个栈帧内，局部变量是如何分布到栈帧里的（所谓栈帧布局，stack frame layout），这完全是编译器的自由。至于数组元素与栈的增长方向：C与C++语言规范都规定了数组元素是分布在连续递增的地址上的。</p><p>堆没有方向之说，每个堆都是散落的</p><p>堆和栈之间没有谁地址高之说，看操作系统实现</p><p>数组取下标偏移总是往上涨的，和在堆还是栈没啥关系</p></blockquote><h3 id="C-内存区域"><a class="header-anchor" href="#C-内存区域">¶</a>C++内存区域</h3><p>C<ins>作为一款C语言的升级版本，具有非常强大的功能。它不但能够支持各种程序设计风格，而且还具有C语言的所有功能。我们在这里为大家介绍的是其中一个比较重要的内容，C</ins>内存区域的基本介绍。</p><p>C++内存区域分为5个区域。分别是堆，栈，自由存储区，全局/静态存储区和常量存储区。</p><p>栈：</p><blockquote><p>由编译器在需要的时候分配，在不需要的时候自动清除的变量存储区。里面通常是局部变量，函数参数等。</p></blockquote><p>堆：</p><blockquote><p>由new分配的内存块，他们的释放编译器不去管，由我们的应用程序去控制，一般一个new对应一个delete。如果程序员没有释放掉，那么在程序结束后，操作系统会自动回收。</p></blockquote><p>自由存储区：</p><blockquote><p>由malloc等分配的内存块，和堆十分相似，不过它使用free来结束自己的生命。</p></blockquote><p>全局/静态存储区：</p><blockquote><p>全局变量和静态变量被分配到同一块内存中，在以前的c语言中。全局变量又分为初始化的和未初始化的，在c++里面没有这个区分了，他们共同占用同一块内存。</p></blockquote><p>常量存储区：</p><blockquote><p>这是一块比较特殊的存储区，里面存放的是常量，不允许修改。</p></blockquote><h3 id="C-内存区域中堆和栈的区别"><a class="header-anchor" href="#C-内存区域中堆和栈的区别">¶</a>C++内存区域中堆和栈的区别</h3><p>管理方式不同：</p><blockquote><p>栈是由编译器自动管理，无需我们手工控制；对于堆来说，释放由程序员完成，容易产生内存泄漏。</p></blockquote><p>空间大小不同：</p><blockquote><p>一般来讲，在32位系统下面，堆内存可达到4G的空间，从这个角度来看堆内存几乎是没有什么限制的。但是对于栈来讲，一般都是有一定空间大小的，例如，在vc6下面，默认的栈大小好像是1M。当然，也可以自己修改：打开工程。 project–&gt;setting–&gt;link，在category中选中output，然后再reserve中设定堆栈的最大值和 commit。</p></blockquote><p>能否产生碎片：</p><blockquote><p>对于堆来讲，频繁的new/delete势必会造成内存空间的不连续，从而造成大量的碎片，使程序效率降低。对于栈来讲，则不会存在这个问题。</p></blockquote><p>生长方向不同：</p><blockquote><p>对于堆来讲，生长方向是向上的，也就是向着内存地址增加的方向；对于栈来讲，它的生长方式是向下的，是向着内存地址减小的方向增长。<br>注意：进程地址空间的分布取决于操作系统，栈向什么方向增长取决于操作系统与CPU的组合。不要把别的操作系统的实现方式套用到Windows上。</p></blockquote><p>x86硬件直接支持的栈确实是“向下增长”的</p><p>分配方式不同：</p><blockquote><p>堆都是动态分配的；栈有静态和动态两种分配方式。静态分配由编译器完成，比如局部变量的分配。动态分配由malloca函数进行、但栈的动态分配和堆是不同的，它的动态分配由编译器进行释放，无需我们手工实现。</p></blockquote><p>分配效率不同：</p><blockquote><p>栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。堆则是c/c++库函数提供的，机制很复杂。库函数会按照一定的算法进行分配。显然，堆的效率比栈要低得多。</p></blockquote><h3 id="为什么要把堆和栈分开？"><a class="header-anchor" href="#为什么要把堆和栈分开？">¶</a>为什么要把堆和栈分开？</h3><p>为什么要把堆和栈区分出来呢？栈中不是也可以存储数据吗？</p><p>从软件设计的角度看，栈代表了处理逻辑，而堆代表了数据。这样分开，使得处理逻辑更为清晰。分而治之的思想。这种隔离、模块化的思想在软件设计的方方面面都有体现。</p><p>堆与栈的分离，使得堆中的内容可以被多个栈共享（也可以理解为多个线程访问同一个对象）。这种共享的收益是很多的。一方面这种共享提供了一种有效的数据交互方式(如：共享内存)，另一方面，堆中的共享常量和缓存可以被所有栈访问，节省了空间。</p><p>栈因为运行时的需要，比如保存系统运行的上下文，需要进行地址段的划分。由于栈的反向增长，因此就会限制住栈存储内容的能力。而堆不同，堆中的对象是可以根据需要动态增长的，因此栈和堆的拆分，使得动态增长成为可能，相应栈中只需记录堆中的一个地址即可。</p><p>面向对象就是堆和栈的完美结合。其实，面向对象方式的程序与以前结构化的程序在执行上没有任何区别。但是，面向对象的引入，使得对待问题的思考方式发生了改变，而更接近于自然方式的思考。当我们把对象拆开，你会发现，对象的属性其实就是数据，存放在堆中；而对象的行为（方法），就是运行逻辑，放在栈中。我们在编写对象的时候，其实即编写了数据结构，也编写的处理数据的逻辑。不得不承认，面向对象的设计，确实很美。</p><h3 id="堆和栈它们在哪儿？"><a class="header-anchor" href="#堆和栈它们在哪儿？">¶</a>堆和栈它们在哪儿？</h3><p>栈是为执行线程留出的内存空间。当函数被调用的时候，栈顶为局部变量和一些 bookkeeping 数据预留块。当函数执行完毕，块就没有用了，可能在下次的函数调用的时候再被使用。栈通常用后进先出（LIFO）的方式预留空间；因此最近的保留块（reserved block）通常最先被释放。这么做可以使跟踪堆栈变的简单；从栈中释放块（free block）只不过是指针的偏移而已。</p><p>堆（heap）是为动态分配预留的内存空间。和栈不一样，从堆上分配和重新分配块没有固定模式；你可以在任何时候分配和释放它。这样使得跟踪哪部分堆已经被分配和被释放变的异常复杂；有许多定制的堆分配策略用来为不同的使用模式下调整堆的性能。</p><p>每一个线程都有一个栈，但是每一个应用程序通常都只有一个堆（尽管为不同类型分配内存使用多个堆的情况也是有的）。</p><p>当线程创建的时候，操作系统（OS）为每一个系统级（system-level）的线程分配栈。通常情况下，操作系统通过调用语言的运行时（runtime）去为应用程序分配堆。</p><p>栈附属于线程，因此当线程结束时栈被回收。堆通常通过运行时在应用程序启动时被分配，当应用程序（进程）退出时被回收。</p><p>当线程被创建的时候，设置栈的大小。在应用程序启动的时候，设置堆的大小，但是可以在需要的时候扩展（分配器向操作系统申请更多的内存）。</p><p><strong>栈比堆要快，因为它存取模式使它可以轻松的分配和重新分配内存（指针/整型只是进行简单的递增或者递减运算）</strong>，然而堆在分配和释放的时候有更多的复杂的 bookkeeping 参与。另外，在栈上的每个字节频繁的被复用也就意味着它可能映射到处理器缓存中，所以很快（译者注：局部性原理）。</p><p>堆和栈是两种内存分配的两个统称。可能有很多种不同的实现方式，但是实现要符合几个基本的概念:</p><blockquote><p>对栈而言，栈中的新加数据项放在其他数据的顶部，移除时你也只能移除最顶部的数据（不能越位获取）。</p><p>对堆而言，数据项位置没有固定的顺序。你可以以任何顺序插入和删除，因为他们没有“顶部”数据这一概念。</p><p>如前所述，堆和栈是一个统称，可以有很多的实现方式。计算机程序通常有一个栈叫做调用栈，用来存储当前函数调用相关的信息（比如：主调函数的地址，局部变量），因为函数调用之后需要返回给主调函数。栈通过扩展和收缩来承载信息。实际上，程序不是由运行时来控制的，它由编程语言、操作系统甚至是系统架构来决定。</p><p>堆是在任何内存中动态和随机分配的（内存的）统称；也就是无序的。内存通常由操作系统分配，通过应用程序调用 API 接口去实现分配。在管理动态分配内存上会有一些额外的开销，不过这由操作系统来处理。</p></blockquote><p>堆：</p><blockquote><p>堆包含一个链表来维护已用和空闲的内存块。在堆上新分配（用 new 或者 malloc）内存是从空闲的内存块中找到一些满足要求的合适块。这个操作会更新堆中的块链表。这些元信息也存储在堆上，经常在每个块的头部一个很小区域。</p><p>堆的增加新快通常从地地址向高地址扩展。因此你可以认为堆随着内存分配而不断的增加大小。如果申请的内存大小很小的话，通常从底层操作系统中得到比申请大小要多的内存。</p><p>申请和释放许多小的块可能会产生如下状态：在已用块之间存在很多小的空闲块。进而申请大块内存失败，虽然空闲块的总和足够，但是空闲的小块是零散的，不能满足申请的大小，。这叫做“堆碎片”。</p><p>当旁边有空闲块的已用块被释放时，新的空闲块可能会与相邻的空闲块合并为一个大的空闲块，这样可以有效的减少“堆碎片”的产生。</p></blockquote><p>栈：</p><blockquote><p>栈经常与 sp 寄存器（译者注：“stack pointer”，了解汇编的朋友应该都知道）一起工作，最初 sp 指向栈顶（栈的高地址）。</p><p>CPU 用 push 指令来将数据压栈，用 pop 指令来弹栈。当用 push 压栈时，sp 值减少（向低地址扩展）。当用 pop 弹栈时，sp 值增大。存储和获取数据都是 CPU 寄存器的值。</p><p>当函数被调用时，CPU使用特定的指令把当前的 IP （译者注：“instruction pointer”，是一个寄存器，用来记录 CPU 指令的位置）压栈。即执行代码的地址。CPU 接下来将调用函数地址赋给 IP ，进行调用。当函数返回时，旧的 IP 被弹栈，CPU 继续去函数调用之前的代码。</p><p>当进入函数时，sp 向下扩展，扩展到确保为函数的局部变量留足够大小的空间。如果函数中有一个 32-bit 的局部变量会在栈中留够四字节的空间。当函数返回时，sp 通过返回原来的位置来释放空间。</p><p>如果函数有参数的话，在函数调用之前，会将参数压栈。函数中的代码通过 sp 的当前位置来定位参数并访问它们。</p><p>函数嵌套调用和使用魔法一样，每一次新调用的函数都会分配函数参数，返回值地址、局部变量空间、嵌套调用的活动记录都要被压入栈中。函数返回时，按照正确方式的撤销。</p><p>栈要受到内存块的限制，不断的函数嵌套/为局部变量分配太多的空间，可能会导致栈溢出。当栈中的内存区域都已经被使用完之后继续向下写（低地址），会触发一个 CPU 异常。这个异常接下会通过语言的运行时转成各种类型的栈溢出异常。（译者注：“不同语言的异常提示不同，因此通过语言运行时来转换”我想他表达的是这个含义）</p></blockquote><h3 id="转载链接"><a class="header-anchor" href="#转载链接">¶</a>转载链接</h3><blockquote><p><a href="http://code4fs.xyz/article/41/" target="_blank" rel="noopener">http://code4fs.xyz/article/41/</a></p></blockquote><h2 id="二、转载：程序的内存分配之堆和栈的区别"><a class="header-anchor" href="#二、转载：程序的内存分配之堆和栈的区别">¶</a>二、转载：<a href="https://developer.aliyun.com/article/342485" target="_blank" rel="noopener">程序的内存分配之堆和栈的区别</a></h2><h2 id="三、方法调用中栈的使用"><a class="header-anchor" href="#三、方法调用中栈的使用">¶</a>三、方法调用中栈的使用</h2><h3 id="1-转载：x86-64下函数调用及栈帧原理"><a class="header-anchor" href="#1-转载：x86-64下函数调用及栈帧原理">¶</a>1&gt; 转载：x86-64下函数调用及栈帧原理</h3><h4 id="通用寄存器使用惯例"><a class="header-anchor" href="#通用寄存器使用惯例">¶</a>通用寄存器使用惯例</h4><p>函数调用时，在硬件层面我们需要关注的通常是cpu 的通用寄存器。在所有 cpu 体系架构中，每个寄存器通常都是有建议的使用方法的，而编译器也通常依照CPU架构的建议来使用这些寄存器，因而我们可以认为这些建议是强制性的。</p><p>对于 x86-64 架构，共有16个64位通用寄存器，各寄存器及用途如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233500.png" alt="x86-64寄存器"></p><p>从上图中，我们可以得到如下结论：</p><ul><li>每个寄存器的用途并不是单一的。</li><li>%rax 通常用于存储函数调用的返回结果，同时也用于乘法和除法指令中。在imul 指令中，两个64位的乘法最多会产生128位的结果，需要 %rax 与 %rdx 共同存储乘法结果，在div 指令中被除数是128 位的，同样需要%rax 与 %rdx 共同存储被除数。</li><li>%rsp 是堆栈指针寄存器，通常会指向栈顶位置，堆栈的 pop 和push 操作就是通过改变 %rsp 的值即移动堆栈指针的位置来实现的。</li><li>%rbp 是栈帧指针，用于标识当前栈帧的起始位置</li><li>%rdi, %rsi, %rdx, %rcx,%r8, %r9 六个寄存器用于存储函数调用时的6个参数（如果有6个或6个以上参数的话）。</li><li>被标识为 “miscellaneous registers” 的寄存器，属于通用性更为广泛的寄存器，编译器或汇编程序可以根据需要存储任何数据。</li></ul><p>这里还要区分一下 “Caller Save” 和 ”Callee Save” 寄存器，即寄存器的值是由”调用者保存“ 还是由 ”被调用者保存“。当产生函数调用时，子函数内通常也会使用到通用寄存器，那么这些寄存器中之前保存的调用者(父函数）的值就会被覆盖。为了避免数据覆盖而导致从子函数返回时寄存器中的数据不可恢复，CPU 体系结构中就规定了通用寄存器的保存方式。</p><p>如果一个寄存器被标识为”Caller Save”， 那么在进行子函数调用前，就需要由调用者提前保存好这些寄存器的值，保存方法通常是把寄存器的值压入堆栈中，调用者保存完成后，在被调用者（子函数）中就可以随意覆盖这些寄存器的值了。如果一个寄存被标识为“Callee Save”，那么在函数调用时，调用者就不必保存这些寄存器的值而直接进行子函数调用，进入子函数后，子函数在覆盖这些寄存器之前，需要先保存这些寄存器的值，即这些寄存器的值是由被调用者来保存和恢复的。</p><h4 id="函数的调用"><a class="header-anchor" href="#函数的调用">¶</a>函数的调用</h4><p>子函数调用时，调用者与被调用者的栈帧结构如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233510.png" alt="函数调用栈帧情况"></p><p>在子函数调用时，执行的操作有：父函数将调用参数从后向前压栈 -&gt; 将返回地址压栈保存 -&gt; 跳转到子函数起始地址执行 -&gt; 子函数将父函数栈帧起始地址（%rpb） 压栈 -&gt; 将 %rbp 的值设置为当前 %rsp 的值，即将 %rbp 指向子函数栈帧的起始地址。</p><p>上述过程中，保存返回地址和跳转到子函数处执行由 call 一条指令完成，在call 指令执行完成时，已经进入了子程序中，因而将上一栈帧%rbp 压栈的操作，需要由子程序来完成。函数调用时在汇编层面的指令序列如下：</p><pre class="line-numbers language-language-assembly"><code class="language-language-assembly">...   # 参数压栈call FUNC  # 将返回地址压栈，并跳转到子函数 FUNC 处执行...  # 函数调用的返回位置FUNC:  # 子函数入口pushq %rbp  # 保存旧的帧指针，相当于创建新的栈帧movq  %rsp, %rbp  # 让 %rbp 指向新栈帧的起始位置subq  $N, %rsp  # 在新栈帧中预留一些空位，供子程序使用，用 (%rsp+K) 或 (%rbp-K) 的形式引用空位<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>保存返回地址和保存上一栈帧的%rbp 都是为了函数返回时，恢复父函数的栈帧结构。在使用高级语言进行函数调用时，由编译器自动完成上述整个流程。对于”Caller Save” 和 “Callee Save” 寄存器的保存和恢复，也都是由编译器自动完成的。</p><p>需要注意的是，父函数中进行参数压栈时，顺序是从后向前进行的。但是，这一行为并不是固定的，是依赖于编译器的具体实现的，在gcc 中，使用的是从后向前的压栈方式，这种方式便于支持类似于 printf(“%d, %d”, i, j) 这样的使用变长参数的函数调用。</p><h4 id="函数的返回"><a class="header-anchor" href="#函数的返回">¶</a>函数的返回</h4><p>函数返回时，我们只需要得到函数的返回值（保存在 %rax 中），之后就需要将栈的结构恢复到函数调用之差的状态，并跳转到父函数的返回地址处继续执行。由于函数调用时已经保存了返回地址和父函数栈帧的起始地址，要恢复到子函数调用之前的父栈帧，我们只需要执行以下两条指令：</p><pre class="line-numbers language-language-assembly"><code class="language-language-assembly">movq %rbp, %rsp    # 使 %rsp 和 %rbp 指向同一位置，即子栈帧的起始处popq %rbp # 将栈中保存的父栈帧的 %rbp 的值赋值给 %rbp，并且 %rsp 上移一个位置指向父栈帧的结尾处<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>为了便于栈帧恢复，x86-64 架构中提供了 leave 指令来实现上述两条命令的功能。执行 leave 后，前面图中函数调用的栈帧结构如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233520.png" alt="函数调用返回后栈帧情况"></p><p>可以看出，调用 leave 后，%rsp 指向的正好是返回地址，x86-64 提供的 ret 指令，其作用就是从当前 %rsp 指向的位置（即栈顶）弹出数据，并跳转到此数据代表的地址处，在leave 执行后，%rsp 指向的正好是返回地址，因而 ret 的作用就是把 %rsp 上移一个位置，并跳转到返回地址执行。可以看出，leave 指令用于恢复父函数的栈帧，ret 用于跳转到返回地址处，leave 和ret 配合共同完成了子函数的返回。当执行完成 ret 后，%rsp 指向的是父栈帧的结尾处，父栈帧尾部存储的调用参数由编译器自动释放。</p><h4 id="函数调用示例"><a class="header-anchor" href="#函数调用示例">¶</a>函数调用示例</h4><p>为了更深入的了解函数调用原理，我们可以使用一个程序示例来观察函数的调用和返回。程序如下：</p><pre class="line-numbers language-language-c"><code class="language-language-c">int add(int a, int b, int c, int d, int e, int f, int g, int h) { // 8 个参数相加  int sum = a + b + c + d + e + f + g + h;  return sum;}int main(void) {  int i = 10;  int j = 20;  int k = i + j;  int sum = add(11, 22,33, 44, 55, 66, 77, 88);  int m = k; // 为了观察 %rax Caller Save 寄存器的恢复  return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在main 函数中，首先进行了一个 k=i+j 的加法，这是为了观察 Caller Save 效果。因为加法会用到 %rax，而下面 add 函数的返回值也会使用 %rax。由于 %rax 是 Caller Save 寄存器，在调用 add 子函数之前，程序应该先保存 %rax 的值。</p><p>add 函数使用了 8 个参数，这是为了观察当函数参数多于6个时程序的行为，前6个参数会保存到寄存器中，多于6个的参数会保存到堆栈中。但是，由于在子程序中可能会取参数的地址，而保存在寄存器中的前6个参数是没有内存地址的，因而我们可以猜测，保存在寄存器中的前6个参数，在子程序中也会被压入到堆栈中，这样才能取到这6个参数的内存地址。上面程序生成的和子函数调用相关的汇编程序如下：</p><pre class="line-numbers language-language-assembly"><code class="language-language-assembly">add:.LFB2:    pushq    %rbp.LCFI0:    movq    %rsp, %rbp.LCFI1:    movl    %edi, -20(%rbp)    movl    %esi, -24(%rbp)    movl    %edx, -28(%rbp)    movl    %ecx, -32(%rbp)    movl    %r8d, -36(%rbp)    movl    %r9d, -40(%rbp)    movl    -24(%rbp), %eax    addl    -20(%rbp), %eax    addl    -28(%rbp), %eax    addl    -32(%rbp), %eax    addl    -36(%rbp), %eax    addl    -40(%rbp), %eax    addl    16(%rbp), %eax    addl    24(%rbp), %eax    movl    %eax, -4(%rbp)    movl    -4(%rbp), %eax    leave    retmain:.LFB3:    pushq    %rbp.LCFI2:    movq    %rsp, %rbp.LCFI3:    subq    $48, %rsp.LCFI4:    movl    $10, -20(%rbp)    movl    $20, -16(%rbp)    movl    -16(%rbp), %eax    addl    -20(%rbp), %eax    movl    %eax, -12(%rbp)    movl    $88, 8(%rsp)    movl    $77, (%rsp)    movl    $66, %r9d    movl    $55, %r8d    movl    $44, %ecx    movl    $33, %edx    movl    $22, %esi    movl    $11, %edi    call    add    movl    %eax, -8(%rbp)    movl    -12(%rbp), %eax    movl    %eax, -4(%rbp)    movl    $0, %eax    leave    ret<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在汇编程序中，如果使用的是64位通用寄存器的低32位，则寄存器以 ”e“ 开头，比如 %eax，%ebx 等，对于 %r8-%r15，其低32 位是在64位寄存后加 “d” 来表示，比如 %r8d, %r15d。如果操作数是32 位的，则指令以 ”l“ 结尾，例如 movl $11, %esi，指令和寄存器都是32位的格式。如果操作数是64 位的，则指令以 q 结尾，例如 “movq %rsp, %rbp”。由于示例程序中的操作数全部在32位的表示范围内，因而上面的加法和移动指令全部是用的32位指令和操作数，只有在创建栈帧时为了地址对齐才使用的是64位指令及操作数。</p><p>首先看 main 函数的前三条汇编语句：</p><pre class="line-numbers language-language-assembly"><code class="language-language-assembly">.LFB3:    pushq    %rbp.LCFI2:    movq    %rsp, %rbp.LCFI3:    subq    $48, %rsp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这三条语句保存了父函数的栈帧（注意main函数也有父函数），之后创建了main 函数的栈帧并且在栈帧中分配了48Byte 的空位，这三条语句执行完成后，main 函数的栈帧如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233545.png" alt="函数调用示例栈帧情况"></p><p>之后，main 函数中就进行了 k=i+j 的加法和 add 参数的处理：</p><pre class="line-numbers language-language-assembly"><code class="language-language-assembly">    movl    $10, -20(%rbp)    movl    $20, -16(%rbp)    movl    -16(%rbp), %eax    addl    -20(%rbp), %eax    movl    %eax, -12(%rbp)  # 调用子函数前保存 %eax 的值到栈中，caller save    movl    $88, 8(%rsp)    movl    $77, (%rsp)    movl    $66, %r9d    movl    $55, %r8d    movl    $44, %ecx    movl    $33, %edx    movl    $22, %esi    movl    $11, %edi    call    add<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在进行 k=i+j 加法时，使用 main 栈空间的方式较为特别。并不是按照我们通常认为的每使用一个栈空间就会进行一次push 操作，而是使用之前预先分配的 48 个空位，并且用 -N(%rbp) 即从 %rbp 指向的位置向下计数的方式来使用空位的，本质上这和每次进行 push 操作是一样的，最后计算 i+j 得到的结果 k 保存在了 %eax 中。之后就需要准备调用 add 函数了。</p><p>我们知道，add 函数的返回值会保存在 %eax 中，即 %eax 一定会被子函数 add 覆盖，而现在 %eax 中保存的是 k 的值。在 C 程序中可以看到，在调用完成 add 后，我们又使用了 k 的值，因而在调用 add 中覆盖%eax 之前，需要保存 %eax 值，在add 使用完%eax 后，需要恢复 %eax 值（即k 的值），由于 %eax 是 Caller Save的，应该由父函数main来保存 %eax 的值，因而上面汇编中有一句 “movl %eax, -12(%rbp)” 就是在调用 add 函数之前来保存 %eax 的值的。</p><p>对于8个参数，可以看出，最后两个参数是从后向前压入了栈中，前6个参数全部保存到了对应的参数寄存器中，与本文开始描述的一致。</p><p>进入 add 之后的操作如下：</p><pre class="line-numbers language-language-assembly"><code class="language-language-assembly">add:.LFB2:    pushq    %rbp # 保存父栈帧指针.LCFI0:    movq    %rsp, %rbp  # 创建新栈帧.LCFI1:    movl    %edi, -20(%rbp)  # 在寄存器中的参数压栈    movl    %esi, -24(%rbp)    movl    %edx, -28(%rbp)    movl    %ecx, -32(%rbp)    movl    %r8d, -36(%rbp)    movl    %r9d, -40(%rbp)    movl    -24(%rbp), %eax    addl    -20(%rbp), %eax    addl    -28(%rbp), %eax    addl    -32(%rbp), %eax    addl    -36(%rbp), %eax    addl    -40(%rbp), %eax    addl    16(%rbp), %eax    addl    24(%rbp), %eax    movl    %eax, -4(%rbp)    movl    -4(%rbp), %eax    leave    ret<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>add 中最前面两条指令实现了新栈帧的创建。之后把在寄存器中的函数调用参数压入了栈中。在本文前面提到过，由于子程序中可能会用到参数的内存地址，这些参数放在寄存器中是无法取地址的，这里把参数压栈，正好印证了我们之前的猜想。</p><p>在参数压栈时，我们看到并未使用 push 之类的指令，也没有调整 %esp 指针的值，而是使用了 -N(%rbp) 这样的指令来使用新的栈空间。这种使用”基地址+偏移量“ 来使用栈的方式和直接使用 %esp 指向栈顶的方式其实是一样的。</p><p>这里有两个和编译器具体实现相关的问题：一是上面程序中，-8(%rbp) 和 -12(%rbp) 地址并未被使用到，这两个地址之前的地址 -4(%rbp) 和之后的 -16(%rsp) 都被使用到了，这可能是由于编译器具体的实现方式来决定的。另外一个就是如下两条指令：</p><pre class="line-numbers language-language-assembly"><code class="language-language-assembly">    movl    %eax, -4(%rbp)    movl    -4(%rbp), %eax<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>先是把 %eax 的值赋值给的 -4(%rbp)，之后又逆向赋值了一次，猜测可能是编译器为了通用性才如此操作的。以上两个问题需要后续进一步研究。</p><p>当add函数返回后，返回结果会存储在%eax 中，%rbp 和 %rsp 会调整为指向 main 的栈帧，之后会执行main 函数中的如下指令：</p><pre class="line-numbers language-language-assembly"><code class="language-language-assembly">movl    %eax, -8(%rbp)  # 保存 add 函数返回值到栈中，对应 C 语句 int sum = add(...)movl   -12(%rbp), %eax  # 恢复 call save 寄存器 %eax 的值，与调用add前保存 %eax 相对应 movl    %eax, -4(%rbp) # 对应 C 语句 m = k，%eax 中的值就是 k。movl    $0, %eax  # main 函数返回值leave   # main 函数返回ret<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看出，当 add 函数返回时，把返回值保存到了 %eax 中，使用完返回值后，会恢复 caller save 寄存器 %eax的值，这时main 栈帧与调用 add 之前完全一样。</p><p>需要注意的是，在调用 add 之前，main 中执行了一条 subq 48, %rsp 这样的指令，原因就在于调用 add 之后，main 中并未调用其他函数，而是执行了两条赋值语句后就直接从main返回了。 main 结尾处的 leave、ret 两条指令会直接覆盖 %rsp 的值从而回到 main 的父栈帧中。如果先调整 main 栈帧的 %rsp 值，之后 leave 再覆盖 %rsp 的值，相当于调整是多余的。因而省略main 中 add返回之后的 %rsp 的调整，而使用 leave 直接覆盖%rsp更为合理。</p><h4 id="转载链接-v2"><a class="header-anchor" href="#转载链接-v2">¶</a>转载链接</h4><blockquote><p><a href="https://zhuanlan.zhihu.com/p/27339191" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/27339191</a></p><p><a href="https://blog.csdn.net/Hanoi_ahoj/article/details/105115117" target="_blank" rel="noopener">线程的栈是如何分配的</a></p></blockquote><h3 id="2-英特尔8080芯片示例"><a class="header-anchor" href="#2-英特尔8080芯片示例">¶</a>2&gt; 英特尔8080芯片示例</h3><p>下面是英特尔8080处理器中一个子程序调用的示例。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233556.png" alt="image-20200911095457835"></p><h1>JVM主要内存占用以及溢出问题</h1><ul><li>直接内存:可通过<code>-XX:MaxDirectMemorySize</code>调整大小,内存不足时抛出<code>OutOfMemoryError:null</code>或者<code>OutOfMemoryError:Direct buffer memory</code>。</li><li>线程堆栈:可通过<code>-Xss</code>调整大小,内存不足时抛出StackOverflowError(如果线程请求的栈深度大于虚拟机所允许的深度)或者OutOfMemoryError(如果Java虚拟机栈容量可以动态扩展,当栈扩展时无法申请到足够的内存)。</li><li>Socket缓存区:每个Socket连接都Receive和Send两个缓存区,分别占大约37KB和25KB内存,连接多的话这块内存占用也比较可观如果无法分配,可能会抛出<code>IOException:Too many open files</code>异常。</li><li>JNI代码:如果代码中使用了JNI调用本地库,那本地库使用的内存也不在堆中,而是占用Java虚拟机的本地方法栈和本地内存的。</li><li>虚拟机和垃圾收集器:虚拟机、垃圾收集器的工作也是要消耗一定数量的内存的。</li></ul>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>12_类加载子系统</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/12-lei-jia-zai-zi-xi-tong/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/12-lei-jia-zai-zi-xi-tong/</url>
      
        <content type="html"><![CDATA[<h1>JVM类加载的特性</h1><p>那些在编译时需要进行连接的语言不同,在Java语言里面,类型的加载、连接和初始化过程都是在程序运行期间完成的,这种策略让Java语言进行提前编译会面临额外的困难,也会让类加载时稍微增加一些性能开销, 但是却为Java应用提供了极高的扩展性和灵活性,Java天生可以动态扩展的语言特性就是依赖运行期动态加载和动态连接这个特点实现的。</p><p>例如,编写一个面向接口的应用程序,可以等到运行时再指定其实际的实现类,用户可以通过Java预置的或自定义类加载器,让某个本地的应用程序在运行时从网络或其他地方上加载一个二进制流作为其程序代码的一部分。这种动态组装应用的方式目前已广泛应用于Java程序之中,从最基础的Applet、JSP到相对复杂的OSGi技术,都依赖着Java语言运行期类加载才得以诞生。</p><h1>类加载子系统图示</h1><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235411.png" alt="image-20200910152333208"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235420.png" alt="image-20200910152446215"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235426.png" alt="image-20200910152532755"></p><h1>类加载器与类的加载过程</h1><h3 id="作用"><a class="header-anchor" href="#作用">¶</a>作用</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235432.png" alt="image-20200910153524052"></p><h3 id="类加载器ClassLoader角色"><a class="header-anchor" href="#类加载器ClassLoader角色">¶</a>类加载器ClassLoader角色</h3><p>可以认为不同的类加载器的作用拥有<strong>从不同数据源</strong>找到class文件并从该数据源获取class文件为数据流的作用。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235438.png" alt="image-20200910153734911"></p><h3 id="类型的生命周期"><a class="header-anchor" href="#类型的生命周期">¶</a>类型的生命周期</h3><p>一个类型从被加载到虚拟机内存中开始,到卸载出内存为止,它的整个生命周期将会经历加载(Loading)、验证(Verification)、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)和卸载(Unloading)七个阶段,其中验证、准备、解析三个部分统称为连接(Linking)。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235444.png" alt="image-20200921164724467"></p><p><strong>加载、验证、准备、初始化和卸载</strong>这五个阶段的顺序是确定的,类型的加载过程必须按照这种顺序按部就班地开始,而<strong>解析阶段则不一定</strong>:它在某些情况下可以在初始化阶段之后再开始, 这是为了支持Java语言的<strong>运行时绑定特性</strong>(也称为<strong>动态绑定或晚期绑定</strong>)。请注意,这里的按部就班地“开始”,而不是按部就班地“进行”或按部就班地“完成”,强调这点是因为这些阶段通常都是互相交叉地混合进行的,会在一个阶段执行的过程中调用、激活另一个阶段。</p><h3 id="类加载时机"><a class="header-anchor" href="#类加载时机">¶</a>类加载时机</h3><p>关于在什么情况下需要开始类加载过程的第一个阶段“加载”,《Java虚拟机规范》中并没有进行强制约束,这点可以交给虚拟机的具体实现来自由把握。</p><h4 id="JVM规范严格定义的类初始化时机：主动引用"><a class="header-anchor" href="#JVM规范严格定义的类初始化时机：主动引用">¶</a>JVM规范严格定义的<strong>类初始化时机</strong>：主动引用</h4><p>但是对于<strong>初始化阶段</strong>,《Java虚拟机规范》则是严格规定了有且只有六种情况必须立即对类进行“初始化”(<strong>而加载、验证、准备自然需要在此之前开始</strong>):</p><ol><li>遇到new、getstatic、putstatic或invokestatic这四条字节码指令时,如果类型没有进行过初始化,则需要先触发其初始化阶段。能够生成这四条指令的典型Java代码场景有:<ul><li>使用new关键字实例化对象的时候。</li><li>读取或设置一个类型的静态字段(<strong>被final修饰、已在编译期把结果放入常量池的静态字段除外</strong>) 的时候。</li><li>调用一个类型的静态方法的时候。</li></ul></li><li>使用java.lang.reflect包的方法对类型进行反射调用的时候,如果类型没有进行过初始化,则需要先触发其初始化。</li><li>当初始化类的时候,如果发现其父类还没有进行过初始化,则需要先触发其父类的初始化。</li><li>当虚拟机启动时,用户需要指定一个要执行的主类(包含main()方法的那个类),虚拟机会先初始化这个主类。</li><li>当使用JDK 7新加入的动态语言支持时,如果一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_getStatic、REF_putStatic、REF_invokeStatic、REF_newInvokeSpecial四种类型的方法句柄,并且这个方法句柄对应的类没有进行过初始化,则需要先触发其初始化。</li><li>当一个接口中定义了JDK 8新加入的默认方法(被default关键字修饰的接口方法)时,如果有这个接口的实现类发生了初始化,那该接口要在其之前被初始化。</li></ol><p>对于这六种会触发类型进行初始化的场景,《Java虚拟机规范》中使用了一个非常强烈的限定语——“有且只有”,这六种场景中的行为称为对一个类型进行<strong>主动引用</strong>。</p><blockquote><p>在类加载器中有一个<code>loadClass()</code>方法进行类加载，这是一个重载方法，其中一个重载参数是boolean类型，表示是否需要对类进行链接，注意，这是也仅仅是链接，所以<code>loadClass()</code>中是不会对类进行初始化的，之后真正发生主动引用的地方才会发生初始化（包括类成员初始化、静态方法调用等）。</p></blockquote><h4 id="被动引用"><a class="header-anchor" href="#被动引用">¶</a>被动引用</h4><p>除此以上之外,所有引用类型的方式都不会触发初始化,称为<strong>被动引用</strong>。</p><ol><li><p>通过子类调用父类的静态字段,不会导致子类初始化</p><p>JVM没有规定是否需要对子类进行<strong>加载</strong>，通过<code>-XX: +TraceClassLoading</code>参数观察到此操作是会导致<strong>HotSpot</strong>对子类进行加载的。</p><pre class="line-numbers language-language-java"><code class="language-language-java">/** * 被动使用类字段演示一:  通过子类访问父类的静态字段,不会导致子类初始化 */public class SuperClass {    static {        System.out.println("SuperClass init!");    }    public static int value = 123;}class SubClass extends SuperClass {    static {        System.out.println("SubClass init!");    }}/** * 非主动使用类字段演示：SubClass的静态方法没有调用 **/class NotInitialization {    public static void main(String[] args) {        System.out.println(SubClass.value);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>通过数组定义来引用类,不会触发此类的初始化</p><p>这段代码里面触发了另一个名为<code>[john.classloader.SuperClass</code>的类的初始化阶段,对于用户代码来说,这并不是一个合法的类型名称,它是一个由虚拟机自动生成的、直接继承于java.lang.Object的子类,创建动作由字节码指令newarray触发。</p><pre class="line-numbers language-language-java"><code class="language-language-java">/** * 被动使用类字段演示一:  通过子类访问父类的静态字段,不会导致子类初始化 */public class SuperClass {    static {        System.out.println("SuperClass init!");    }    public static int value = 123;}class SubClass extends SuperClass {    static {        System.out.println("SubClass init!");    }}/** * 非主动使用类字段演示：SuperClass的静态方法没有调用 **/class NotInitialization {    public static void main(String[] args) {        SuperClass[] sca = new SuperClass[10];    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>常量在编译阶段会存入调用类的常量池中</strong>,本质上没有直接引用到定义常量的类,因此不会触发定义常量的类的初始化</p><pre class="line-numbers language-language-java"><code class="language-language-java">/** * 被动使用类字段演示一:  通过子类访问父类的静态字段,不会导致子类初始化 */public class SuperClass {    static {        System.out.println("SuperClass init!");    }    public final static int value = 123;}class SubClass extends SuperClass {    static {        System.out.println("SubClass init!");    }}/** * 非主动使用类字段演示：SuperClass的静态方法没有调用 **/class NotInitialization {    public static void main(String[] args) {        System.out.println(SubClass.value);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h3 id="接口的加载过程"><a class="header-anchor" href="#接口的加载过程">¶</a>接口的加载过程</h3><p>接口的加载过程与类加载过程稍有不同,针对接口需要做一些特殊说明:接口也有初始化过程, 这点与类是一致的,接口中不能定义静态代码块，但是虚拟机仍然会为其生成<code>&lt;clinit&gt;</code>类构造器，用于初始化接口中所定义的成员变量。接口与类真正有所区别的是前面讲述的六种“有且仅有”需要触发初始化场景中的第三种: 当一个类在初始化时,要求其父类全部都已经初始化过了,但是<strong>一个接口在初始化时,并不要求其父接口全部都完成了初始化,只有在真正使用到父接口的时候</strong>(如引用接口中定义的常量)才会初始化。</p><h3 id="类的加载过程"><a class="header-anchor" href="#类的加载过程">¶</a>类的加载过程</h3><h4 id="1、加载"><a class="header-anchor" href="#1、加载">¶</a>1、加载</h4><ol><li>通过一个类的全限定名来获取定义此类的二进制字节流。<ul><li>开发人员通过定义自己的类加载器去控制字节流的获取方式(重写一个类加载器的<code>findClass()</code>或<code>loadClass()</code>方法),实现根据自己的想法来赋予应用程序获取运行代码的动态性。</li></ul></li><li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。</li><li>在内存中生成一个代表这个类的<code>java.lang.Class</code>对象,作为方法区这个类的各种数据的访问入口</li></ol><p>加载.class文件的方式：</p><ul><li>从本地系统中直接加载</li><li>通过网络获取，典型场景：Web Applet</li><li>从zip压缩包中读取，成为日后jar、war格式的基础</li><li>运行时计算生成，使用最多的是：动态代理技术</li><li>由其他文件生成，典型场景：JSP应用</li><li>从专有数据库中提取.class文件，比较少见</li><li>从加密文件中获取，典型的防Class文件被反编译的保护措施</li></ul><h5 id="数组的加载"><a class="header-anchor" href="#数组的加载">¶</a>数组的加载</h5><p>对于数组类而言,情况就有所不同,数组类本身不通过类加载器创建,它是由Java虚拟机直接在内存中动态构造出来的。但数组类与类加载器仍然有很密切的关系,因为数组类的元素类型(Element Type,指的是数组去掉所有维度的类型)最终还是要靠类加载器来完成加载,一个数组类(下面简称为C)创建过程遵循以下规则:</p><ul><li>如果数组的组件类型(Component Type,指的是数组去掉一个维度的类型,注意和前面的元素类型区分开来)是引用类型,那就递归采用本节中定义的加载过程去加载这个组件类型,数组C将被<strong>标识在加载该组件类型的类加载器的类名称空间上</strong>(一个类型必须与类加载器一起确定唯一性)。</li><li>如果数组的组件类型不是引用类型(例如<code>int[]</code>数组的组件类型为<code>int</code>),Java虚拟机将会把数组C 标记为与引导类加载器关联。</li><li>数组类的可访问性与它的组件类型的可访问性一致,如果组件类型不是引用类型,它的数组类的可访问性将默认为<code>public</code>,可被所有的类和接口访问到。</li><li>加载阶段结束后,Java虚拟机外部的二进制字节流就按照虚拟机所设定的格式存储在方法区之中了,方法区中的数据存储格式完全由虚拟机实现自行定义,《Java虚拟机规范》未规定此区域的具体数据结构。类型数据妥善安置在方法区之后,会在Java堆内存中实例化一个<code>java.lang.Class</code>类的对象, 这个对象将作为程序访问方法区中的类型数据的外部接口。</li></ul><h5 id="加载与链接的顺序"><a class="header-anchor" href="#加载与链接的顺序">¶</a>加载与链接的顺序</h5><p>加载阶段与连接阶段的部分动作(如一部分字节码文件格式验证动作)是交叉进行的,加载阶段尚未完成,连接阶段可能已经开始,但这些夹在加载阶段之中进行的动作,仍然属于连接阶段的一部分,这两个阶段的开始时间仍然保持着固定的先后顺序。</p><h4 id="2、链接"><a class="header-anchor" href="#2、链接">¶</a>2、链接</h4><h5 id="验证"><a class="header-anchor" href="#验证">¶</a>验证</h5><p>验证是连接阶段的第一步,这一阶段的目的是确保Class文件的字节流中包含的信息符合《Java虚拟机规范》的全部约束要求,保证这些信息被当作代码运行后不会危害虚拟机自身的安全。</p><p>验证阶段大致上会完成下面四个阶段的检验动作:文件格式验证、元数据验证、字节码验证和符号引用验证。</p><h6 id="文件格式验证"><a class="header-anchor" href="#文件格式验证">¶</a>文件格式验证</h6><p>第一阶段要验证字节流是否符合Class文件格式的规范,并且能被当前版本的虚拟机处理。这一阶段可能包括下面这些验证点:</p><ul><li>是否以魔数0xCAFEBABE开头。</li><li>主、次版本号是否在当前Java虚拟机接受范围之内。</li><li>常量池的常量中是否有不被支持的常量类型(检查常量tag标志)。</li><li>指向常量的各种索引值中是否有指向不存在的常量或不符合类型的常量。</li><li>CONSTANT_Utf8_info型的常量中是否有不符合UTF-8编码的数据。</li><li>Class文件中各个部分及文件本身是否有被删除的或附加的其他信息。</li><li>… …</li></ul><p>该验证阶段的主要目的是保证输入的字节流能正确地解析并存储于方法区之内,格式上符合描述一个Java类型信息的要求。<strong>这阶段的验证主要是对class二进制流的格式进行验证</strong>,只有通过了这个阶段的验证之后,这段字节流才被允许进入Java虚拟机内存的方法区中进行存储,所以<strong>后面的三个验证阶段全部是基于方法区的存储结构上进行的,不会再直接读取、操作字节流了。</strong></p><h6 id="元数据验证"><a class="header-anchor" href="#元数据验证">¶</a>元数据验证</h6><p>第二阶段是对字节码描述的信息进行语义分析,以保证其描述的信息符合《Java语言规范》的要求,这个阶段可能包括的验证点如下:</p><ul><li>这个类是否有父类(除了java.lang.Object之外,所有的类都应当有父类)。</li><li>这个类的父类是否继承了不允许被继承的类(被final修饰的类)。</li><li>如果这个类不是抽象类,是否实现了其父类或接口之中要求实现的所有方法。</li><li>类中的字段、方法是否与父类产生矛盾(例如覆盖了父类的final字段,或者出现不符合规则的方法重载,例如方法参数都一致,但返回值类型却不同等)。</li><li>… …</li></ul><p>第二阶段的<strong>主要目的是对类的元数据信息进行语义校验,保证不存在与《Java语言规范》定义相悖的元数据信息。</strong></p><h6 id="字节码验证"><a class="header-anchor" href="#字节码验证">¶</a>字节码验证</h6><p>第三阶段是整个验证过程中最复杂的一个阶段,<strong>主要目的是通过数据流分析和控制流分析,确定程序语义是合法的、符合逻辑的</strong>。在第二阶段对元数据信息中的数据类型校验完毕以后,这阶段就要对类的方法体(Class文件中的Code属性)进行校验分析,保证被校验类的方法在运行时不会做出危害虚拟机安全的行为,例如:</p><ul><li>保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作,例如不会出现类似于“在操作栈放置了一个int类型的数据,使用时却按long类型来加载入本地变量表中”这样的情况。</li><li>保证任何跳转指令都不会跳转到方法体以外的字节码指令上。</li><li>保证方法体中的类型转换总是有效的,例如可以把一个子类对象赋值给父类数据类型,这是安全的,但是把父类对象赋值给子类数据类型,甚至把对象赋值给与它毫无继承关系、完全不相干的一个数据类型,则是危险和不合法的。</li><li>……</li></ul><p>由于数据流分析和控制流分析的高度复杂性,Java虚拟机的设计团队为了避免过多的执行时间消耗在字节码验证阶段中,在JDK 6之后的Javac编译器和Java虚拟机里进行了一项联合优化,把尽可能多的校验辅助措施挪到Javac编译器里进行。具体做法是给方法体Code属性的属性表中新增加了一项名为“StackMapTable”的新属性,这项属性描述了方法体所有的基本块(Basic Block,指按照控制流拆分的代码块)开始时本地变量表和操作栈应有的状态,在字节码验证期间,Java虚拟机就不需要根据程序推导这些状态的合法性,只需要检查StackMapTable属性中的记录是否合法即可。这样就将字节码验证的类型推导转变为类型检查,从而节省了大量校验时间。理论上StackMapTable属性也存在错误或被篡改的可能,所以是否有可能在恶意篡改了Code属性的同时,也生成相应的StackMapTable属性来骗过虚拟机的类型校验,则是虚拟机设计者们需要仔细思考的问题。</p><h6 id="符号引用验证"><a class="header-anchor" href="#符号引用验证">¶</a>符号引用验证</h6><p>最后一个阶段的校验行为<strong>发生在虚拟机将符号引用转化为直接引用的时候,这个转化动作将在连接的第三阶段——解析阶段中发生</strong>。符号引用验证可以看作是对类自身以外(常量池中的各种符号引用)的各类信息进行匹配性校验,通俗来说就是,该类是否缺少或者被禁止访问它依赖的某些外部类、方法、字段等资源。本阶段通常需要校验下列内容:</p><ul><li>符号引用中通过字符串描述的全限定名是否能找到对应的类。</li><li>在指定类中是否存在符合方法的字段描述符及简单名称所描述的方法和字段。</li><li>符号引用中的类、字段、方法的可访问性(private、protected、public、package)是否可被当前类访问。</li><li>……</li></ul><p>符号引用验证的主要目的是确保解析行为能正常执行,如果无法通过符号引用验证,Java虚拟机将会抛出一个<code>java.lang.IncompatibleClassChangeError</code>的子类异常,典型的如: <code>java.lang.IllegalAccessError</code>、<code>java.lang.NoSuchFieldError</code>、<code>java.lang.NoSuchMethodError</code>等。</p><p>验证阶段对于虚拟机的类加载机制来说,是一个非常重要的、但却不是必须要执行的阶段,因为验证阶段只有通过或者不通过的差别,只要通过了验证,其后就对程序运行期没有任何影响了。如果程序运行的全部代码(包括自己编写的、第三方包中的、从外部加载的、动态生成的等所有代码)都已经被反复使用和验证过,在生产环境的实施阶段就可以考虑使用<code>-Xverify:none</code>参数来关闭大部分的类验证措施,以缩短虚拟机类加载的时间。</p><h5 id="准备"><a class="header-anchor" href="#准备">¶</a>准备</h5><h6 id="调用类构造器-clinit-方法对类变量赋-零值"><a class="header-anchor" href="#调用类构造器-clinit-方法对类变量赋-零值">¶</a>调用类构造器<code>&lt;clinit&gt;()</code>方法对类变量赋&quot;零值&quot;</h6><p>准备阶段是正式为类中定义的变量(即静态变量,被static修饰的变量)分配内存并设置类变量初始值的阶段,从概念上讲,这些变量所使用的内存都在方法区中(逻辑概念，JDK7及之前在堆、JDK8及之后在直接内存)进行分配。</p><table><thead><tr><th>数据类型</th><th>零值</th></tr></thead><tbody><tr><td>int</td><td>0</td></tr><tr><td>long</td><td>0L</td></tr><tr><td>short</td><td>(short)0</td></tr><tr><td>char</td><td>‘\u0000’</td></tr><tr><td>byte</td><td>(byte)0</td></tr><tr><td>boolean</td><td>flase</td></tr><tr><td>float</td><td>0.0f</td></tr><tr><td>double</td><td>0.0d</td></tr><tr><td>reference</td><td>null</td></tr></tbody></table><h6 id="根据ConstantValue对常量初始化"><a class="header-anchor" href="#根据ConstantValue对常量初始化">¶</a>根据ConstantValue对常量初始化</h6><p>Javac编译时会为所有被<code>final</code>、<code>static</code>修饰的字段生成ConstantValue属性, 准备阶段如果类字段的字段属性表中存在ConstantValue属性, 那就会将字段值初始化为ConstantValue属性所指定的初始值.例如：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">public static final int value = 123; //value会被在当前阶段初始化为123<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="解析"><a class="header-anchor" href="#解析">¶</a>解析</h5><p>解析阶段是Java虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符这7 类符号引用进行,分别对应于常量池中：</p><ul><li>CONSTANT_Class_info</li><li>CONSTANT_Fieldref_info</li><li>CONSTANT_Methodref_info</li><li>CONSTANT_InterfaceMethodref_info</li><li>CONSTANT_MethodType_info</li><li>CONSTANT_MethodHandle_info</li><li>CONSTANT_Dynamic_info</li><li>CONSTANT_InvokeDynamic_info</li></ul><p>8种常量类型。</p><ul><li>符号引用(Symbolic References):符号引用以一组符号来描述所引用的目标,符号可以是任何形式的字面量,只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关,引用的目标并不一定是已经加载到虚拟机内存当中的内容。各种虚拟机实现的内存布局可以各不相同, 但是它们能接受的符号引用必须都是一致的,因为符号引用的字面量形式明确定义在《Java虚拟机规范》的Class文件格式中。</li><li>直接引用(Direct References):直接引用是可以直接指向目标的指针、相对偏移量或者是一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局直接相关的,同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用,那引用的目标必定已经在虚拟机的内存中存在。</li></ul><h6 id="触发解析的时机"><a class="header-anchor" href="#触发解析的时机">¶</a>触发解析的时机</h6><p>《Java虚拟机规范》之中并未规定解析阶段发生的具体时间,只要求了在执行ane-warray、checkcast、getfield、getstatic、instanceof、invokedynamic、invokeinterface、invoke-special、invokestatic、invokevirtual、ldc、ldc_w、ldc2_w、multianewarray、new、putfield和putstatic这17个用于操作符号引用的字节码指令之前,先对它们所使用的符号引用进行解析。所以虚拟机实现可以根据需要来自行判断,到底是在类被加载器加载时就对常量池中的符号引用进行解析,还是等到一个符号引用将要被使用前才去解析它。</p><blockquote><p>对于invokedynamic指令，它本来就是用于动态语言支持,它对应的引用称为“动态调用点限定符(Dynamically-Computed Call Site Specifier)”,这里“动态”的含义是指必须等到程序实际运行到这条指令时,解析动作才能进行。相对地,其余可触发解析的指令都是“静态”的,可以在刚刚完成加载阶段,还没有开始执行代码时就提前进行解析。</p></blockquote><h6 id="1-类或接口的解析"><a class="header-anchor" href="#1-类或接口的解析">¶</a>1&gt;类或接口的解析</h6><p>假设当前代码所处的类为D,如果要把一个从未解析过的符号引用N解析为一个类或接口C的直接引用,那虚拟机完成整个解析的过程需要包括以下3个步骤:</p><ol><li>如果C不是一个数组类型,那虚拟机将会把代表N的全限定名传递给D的类加载器去加载这个类C。在加载过程中,由于元数据验证、字节码验证的需要,又可能触发其他相关类的加载动作,例如加载这个类的父类或实现的接口。一旦这个加载过程出现了任何异常,解析过程就将宣告失败。</li><li>如果C是一个数组类型,并且数组的元素类型为对象,也就是N的描述符会是类似<code>[Ljava/lang/Integer</code>的形式,那将会按照第一点的规则加载数组元素类型。如果N的描述符如前面所假设的形式,需要加载的元素类型就是<code>java.lang.Integer</code>,接着由虚拟机生成一个代表该数组维度和元素的数组对象。</li><li>如果上面两步没有出现任何异常,那么C在虚拟机中实际上已经成为一个有效的类或接口了, 但在解析完成前还要进行符号引用验证,确认D是否具备对C的访问权限(public、protected、private… …)。如果发现不具备访问权限, 将抛出<code>java.lang.IllegalAccessError</code>异常。</li></ol><h6 id="2-字段解析"><a class="header-anchor" href="#2-字段解析">¶</a>2&gt;字段解析</h6><p>要解析一个未被解析过的字段符号引用，首先将会对对应的CONSTANT_Fieldref_info内class_index项中索引的CONSTANT_Class_info符号引用进行解析,也就是字段所属的类或接口的符号引用</p><ul><li>如果在解析这个类或接口符号引用的过程中出现了任何异常,都会导致字段符号引用解析的失败。</li><li>如果解析成功完成,那把这个字段所属的类或接口用C表示,《Java虚拟机规范》要求按照如下步骤对C进行后续字段的搜索:<ol><li>如果C本身就包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束。</li><li>否则,如果在C中实现了接口,将会按照继承关系从下往上递归搜索各个接口和它的父接口, 如果接口中包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束。</li><li>否则,如果C不是<code>java.lang.Object</code>的话,将会按照继承关系从下往上递归搜索其父类,如果在父类中包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束。</li><li>否则,查找失败,抛出<code>java.lang.NoSuchFieldError</code>异常。</li><li>如果查找过程成功返回了引用,将会对这个字段进行权限验证,如果发现不具备对字段的访问权限,将抛出<code>java.lang.IllegalAccessError</code>异常。</li></ol></li></ul><p>以上解析规则能够确保Java虚拟机获得字段唯一的解析结果,但在实际情况中,Javac编译器往往会采取比上述规范更加严格一些的约束,譬如有一个同名字段同时出现在某个类的接口和父类当中, 或者同时在自己或父类的多个接口中出现,按照解析规则仍是可以确定唯一的访问字段,但Javac编译器就<strong>可能</strong>直接拒绝其编译为Class文件。</p><pre class="line-numbers language-language-java"><code class="language-language-java">package john.classloader;public class FieldResolution {    interface Interface0 {        int A = 0;    }    interface Interface1 extends Interface0 {        int A = 1;    }    interface Interface2 {        int A = 2;    }    static class Parent implements Interface1 {        public static int A = 3;    }    static class Sub extends Parent implements Interface2 {        public static int A = 4;//如果注释这行代码，接口与父类同时存在字段A,那Oracle公司实现的Javac编译器将提示“The field Sub.A is ambiguous”,并且会拒绝编译这段代码。    }    public static void main(String[] args) {        System.out.println(Sub.A);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h6 id="3-方法解析"><a class="header-anchor" href="#3-方法解析">¶</a>3&gt;方法解析</h6><p>方法解析的第一个步骤与字段解析一样,也是需要先解析出对应的CONSTANT_Methodref_info的class_index项中索引的方法所属的类或接口的符号引用。如果解析成功,那么我们依然用C表示这个类,接下来虚拟机将会按照如下步骤进行后续的方法搜索:</p><ol><li>由于Class文件格式中类的方法和接口的方法符号引用的常量类型定义是分开的,如果在类的方法表中发现class_index中索引的C是个接口的话,那就直接抛出<code>java.lang.IncompatibleClassChangeError</code> 异常。</li><li>如果通过了第一步,在类C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束。</li><li>否则,在类C的父类中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束。</li><li>否则,在类C实现的接口列表及它们的父接口之中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果存在匹配的方法,说明类C是一个抽象类,这时候查找结束,抛出<code>java.lang.AbstractMethodError</code>异常。</li><li>否则,宣告方法查找失败,抛出<code>java.lang.NoSuchMethodError</code>。</li><li>最后,如果查找过程成功返回了直接引用,将会对这个方法进行权限验证,如果发现不具备对此方法的访问权限,将抛出<code>java.lang.IllegalAccessError</code>异常。</li></ol><h6 id="4-接口方法解析"><a class="header-anchor" href="#4-接口方法解析">¶</a>4&gt;接口方法解析</h6><p>接口方法也是需要先解析出对应的CONSTANT_InterfaceMethodref_info的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然用C表示这个接口,接下来虚拟机将会按照如下步骤进行后续的接口方法搜索:</p><ol><li>与类的方法解析相反,如果在接口方法表中发现class_index中的索引C是个类而不是接口,那么就直接抛出<code>java.lang.IncompatibleClassChangeError</code>异常。</li><li>否则,在接口C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束。</li><li>否则,在接口C的父接口中递归查找,直到java.lang.Object类(接口方法的查找范围也会包括Object类中的方法)为止,看是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束。</li><li>对于规则3,由于Java的接口允许多重继承,如果C的不同父接口中存有多个简单名称和描述符都与目标相匹配的方法,那将会从这多个方法中返回其中一个并结束查找,《Java虚拟机规范》中并没有进一步规则约束应该返回哪一个接口方法。但与之前字段查找类似地,不同发行商实现的Javac编译器有可能会按照更严格的约束拒绝编译这种代码来避免不确定性。</li><li>否则,宣告方法查找失败,抛出<code>java.lang.NoSuchMethodError</code>异常。</li></ol><h4 id="3、初始化"><a class="header-anchor" href="#3、初始化">¶</a>3、初始化</h4><p>类的初始化阶段是类加载过程的最后一个步骤。初始化阶段就是执行类构造器<code>&lt;clinit&gt;()</code>方法的过程。<code>&lt;clinit&gt;()</code>并不是程序员在Java代码中直接编写的方法,它是Javac编译器的自动生成物，<code>&lt;clinit&gt;()</code>方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块(static{}块)中的语句合并产生的：</p><ul><li>编译器收集的顺序是<strong>由语句在源文件中出现的顺序决定的(包括类字段赋值及静态代码块的顺序)</strong></li><li>静态语句块中只能访问到定义在静态语句块之前的变量,定义在它之后的变量,在前面的静态语句块可以赋值,但是不能访问。</li></ul><pre class="line-numbers language-language-java"><code class="language-language-java">    static {        i = 0;  //  给变量复制可以正常编译通过        System.out.print(i);  // 这句编译器会提示“非法向前引用”。    }    static int i = 1;//看了往上的一些答案，说是为了解决循环引用，例如下面的例子。所以只允许将出现在后面的静态变量作为左值不能作为右值，但是感觉有点怪怪的，变量不是都在链接的准备阶段赋零值了吗。    static int a = b; //这种写法也会提示“非法向前引用”    static int b = a;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><code>&lt;clinit&gt;()</code>方法与类的构造函数(即在虚拟机视角中的实例构造器<code>&lt;init&gt;()</code>方法)不同,它不需要显式地调用父类构造器,Java虚拟机会保证在子类的<code>&lt;clinit&gt;()</code>方法执行前(加载子类之前保证父类已经加载),父类的<code>&lt;clinit&gt;()</code>方法已经执行完毕。因此在Java虚拟机中第一个被执行的<code>&lt;clinit&gt;()</code>方法的类型肯定是<code>java.lang.Object</code>。</li><li><code>&lt;clinit&gt;()</code>方法对于类或接口来说并不是必需的,<strong>如果一个类中没有静态语句块,也没有对变量的赋值操作,那么编译器可以不为这个类生成<code>&lt;clinit&gt;()</code>方法</strong>。</li><li>接口中不能使用静态语句块,但仍然有变量初始化的赋值操作,因此接口与类一样都会生成<code>&lt;clinit&gt;()</code>方法。但接口与类不同的是,执行接口的<code>&lt;clinit&gt;()</code>方法不需要先执行父接口的<code>&lt;clinit&gt;()</code>方法, 因为只有当父接口中定义的变量被使用时,父接口才会被初始化。<strong>此外,接口的实现类在初始化时也一样不会执行接口的<code>&lt;clinit&gt;()</code>方法。</strong></li><li>Java虚拟机必须保证一个类的<code>&lt;clinit&gt;()</code>方法在多线程环境中被正确地加锁同步,如果多个线程同时去初始化一个类,那么只会有其中一个线程去执行这个类的<code>&lt;clinit&gt;()</code>方法,其他线程都需要阻塞等待,直到活动线程执行完毕<code>&lt;clinit&gt;()</code>方法。如果在一个类的<code>&lt;clinit&gt;()</code>方法中有耗时很长的操作,那就可能造成多个进程阻塞[2],在实际应用中这种阻塞往往是很隐蔽的。</li></ul><h1>类加载器分类</h1><p>JVM支持两种类型的类加载器，分别为引导类加载器(Bootstrap ClassLoader)和自定义类加载器(User-Defined ClassLoader)。从概念上讲，自定义类加载器一般指的是程序中由开发人员自定义的一类类加载器，但是Java虚拟机规范却没有这么定义，而是将所有<strong>派生于抽象类ClassLoader的类加载器</strong>都划分为自定义类加载器。</p><p>无论类加载器的类型如何划分，在程序中我们最常见的类加载器始终只有3个，如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235457.png" alt="image-20200910170353512"></p><p>类加载器之间的父子关系一般不是以继承(Inheritance)的关系来实现的,而是通常使用组合(Composition)关系来复用父加载器的代码。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235504.png" alt="image-20200910170517036"></p><h3 id="类加载器包含关系-双亲委派关系"><a class="header-anchor" href="#类加载器包含关系-双亲委派关系">¶</a>类加载器包含关系(双亲委派关系)</h3><p>包含关系指的是包含加载器加载的类包含但不限于被包含加载器加载的类(包含加载器是被包含加载器的parent，被包含加载器在加载类的时候尝试交由包含加载器加载，当包含加载器无法加载的时候，再由被包含加载器加载)。</p><h3 id="类加载代码演示"><a class="header-anchor" href="#类加载代码演示">¶</a>类加载代码演示</h3><pre class="line-numbers language-language-java"><code class="language-language-java">        ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader();        System.out.println(systemClassLoader); //sun.misc.Launcher$AppClassLoader@18b4aac2        ClassLoader parent = systemClassLoader.getParent();        System.out.println(parent); //sun.misc.Launcher$ExtClassLoader@4dc63996        ClassLoader boostrap = parent.getParent();        System.out.println(boostrap); //null        ClassLoader classLoader = ClassLoaderTest1.class.getClassLoader();        System.out.println(classLoader); //sun.misc.Launcher$AppClassLoader@18b4aac2        ClassLoader strClassLoader = String.class.getClassLoader();        System.out.println(strClassLoader); //null<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>用户代码默认是&quot;System ClassLoader&quot;来加载，而&quot;System ClassLoader&quot;默认就是&quot;AppClassLoader&quot;应用程序类加载器，而应用程序类加载器的父亲就是拓展类加载器，拓展类加载器的父亲是引导类加载器，使用<code>getParent</code>方法得到的是null，因为该加载器使用的是C/C++实现。</p><h3 id="虚拟机自带的加载器"><a class="header-anchor" href="#虚拟机自带的加载器">¶</a>虚拟机自带的加载器</h3><ul><li>启动类加载器(引导类加载器，Boostrap ClassLoader)<ul><li>这个类加载使用C/C++语言实现的，嵌套在JVM内部</li><li>它用来加载<code>JAVA_HOME/jre/lib/rt.jar</code>、resources.jar或sun.boot.class.path路径、<code>-Xbootclasspath</code>参数所指定的路径下的，而且是Java虚拟机能够识别的(按照文件名识别,如rt.jar、tools.jar,名字不符合的类库即使放在lib目录中也不会被加载)Java的核心类库</li><li>并不继承<code>java.lang.ClassLoader</code>，没有父加载器</li><li>加载拓展类和应用程序类加载器，并指定为他们的父类加载器</li><li>出于安全考虑，Boostrap启动类加载器只加载包名为java、javax、sun等开头的类</li></ul></li><li>扩展类加载器(Extension ClassLoader)<ul><li>Java语言编写，由<code>sun.misc.Launcher$ExtClassLoader</code>实现。</li><li>派生于<code>ClassLoader</code>类</li><li>父类加载器为启动类加载器</li><li>从<code>java.ext.dirs</code>系统属性所指定的目录中加载类库，或从JDK的安装目录的<code>&lt;JAVA_HOME&gt;\lib\ext</code>子目录（扩展目录）下加载类库。如果用于创建的JAR放在此目录下，也会自动由扩展类加载器加载。</li></ul></li><li>应用程序类加载器(系统类加载器，AppClassLoader)<ul><li>java语言编写，由<code>sun.misc.Launcher$AppClassLoader</code>实现。</li><li>派生于<code>ClassLoader</code>类</li><li>父类加载器为扩展类加载器</li><li>它负责加载环境变量classpath或系统属性<code>java.class.path</code>指定路径下的类库</li><li>该类加载是程序中默认的类加载器，一般来说，Java应用的类都是由它来完成加载</li><li>通过<code>ClassLoader#getSystemClassLoader()</code>方法可以获取到该类加载器</li></ul></li></ul><h2 id="用户自定义类加载器"><a class="header-anchor" href="#用户自定义类加载器">¶</a>用户自定义类加载器</h2><ul><li>在Java的日常应用程序开发中，类的加载几乎是由上述3种类加载器相互配合执行的，在必要时，我们还可以自定义类加载器，来定制类的加载方式。</li><li>为什么要自定义类加载器？<ul><li>隔离加载类。在动态环境中，例如依赖了多个中间件的应用程序，可能会遇到不同依赖下的类名冲突，为了避免默认类加载器的不确定性，此时中间件一般会自定义类加载器实现自己的类的加载逻辑在反射的时候使用该类加载器加载自己的类(在JVM中类加载器+类本身唯一确定一个类，即类全限定名重复，但是类加载器不同，是可以同时存在的)。</li><li>修改类加载的方式。例如懒加载或者缓存等。</li><li>扩展加载源。实现可以从网络、数据库等不同的数据源中动态获取class文件流。</li><li>防止源码泄露。在编译源文件之后对class文件加密，然后在执行的时候通过自定义类加载器进行解密。</li></ul></li></ul><h4 id="用户自定义类加载器实现步骤："><a class="header-anchor" href="#用户自定义类加载器实现步骤：">¶</a>用户自定义类加载器实现步骤：</h4><ol><li>开发人员可以通过继承抽象类<code>java.lang.ClassLoader</code>类的方式，实现自己的类加载器，以满足一些特殊的需求</li><li>在JDK1.2之前，在自定义类加载器时，总会去继承<code>ClassLoader</code>类并重写<code>loadClass()</code>方法，从而实现自定义的加载类，但是在JDK1.2之后已不再建议用户去覆盖<code>loadClass()</code>方法，而是建议把自定义的类加载逻辑写在<code>findClass()</code>方法中</li><li>在编写自定义类加载器时，如果没有太过于复杂的需求，可以直接继承<code>URLClassLoader</code>类，这样就可以避免自己去编写<code>findClass()</code>方法及其获取字节码流的方式，使自定义类加载器编写更加简洁。</li></ol><h2 id="ClassLoader类的常用方法"><a class="header-anchor" href="#ClassLoader类的常用方法">¶</a>ClassLoader类的常用方法</h2><p>ClassLoader类是一个抽象类，除了引导类加载都需要继承自ClassLoader。</p><table><thead><tr><th>方法名称</th><th>描述</th></tr></thead><tbody><tr><td><code>getParent()</code></td><td>返回该类加载器的超类加载器</td></tr><tr><td><code>loadClass(String name)</code></td><td>加载名称为name的类，返回结果为<code>java.lang.Class</code>类的实例，如果类已经加载，将直接返回已经加载的类；如果还没加载，就会调用<code>findClass</code>去获取，自定义加载类一般不要重写这个方法</td></tr><tr><td><code>findClass(String name)</code></td><td>查找名称为name的类，返回结果为<code>java.lang.Class</code>类的实例，自定义加载类一般将查找类逻辑重写在这个方法里面</td></tr><tr><td><code>findLoadedClass(String name)</code></td><td>查找名称为name的已经被加载过的类，返回结果为<code>java.lang.Class</code>类的实例</td></tr><tr><td><code>defineClass(String name, byte[] b, int off, int len)</code></td><td>把字节数组b中的内容转换为一个Java类，返回结果为<code>java.lang.Class</code>类的实例</td></tr><tr><td><code>resolveClass(Class&lt;?&gt; c)</code></td><td>连接指定的一个Java类</td></tr></tbody></table><h2 id="获取ClassLoader的几种方式"><a class="header-anchor" href="#获取ClassLoader的几种方式">¶</a>获取ClassLoader的几种方式</h2><p>一般是根据指定方式来获取对应的类加载器来加载自己本身无法加载的类，例如在破坏双亲委派模型的情况下，父类通过约定的方式获取对应的类加载器加载其无法加载的类：</p><pre class="line-numbers language-language-java"><code class="language-language-java">//方式一：获取当前类的ClassLoaderclazz.getClassLoader()//方式二：获取当前线程上下文的ClassLoaderThread.currentThread().getContextClassLoader()//方式三：获取系统的ClassLoaderClassLoader.getSystemClassLoader()//方式四：获取调用者的ClassLoaderDriverManager.getCallerClassLoader()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="双亲委派机制"><a class="header-anchor" href="#双亲委派机制">¶</a>双亲委派机制</h2><p>Java虚拟机对class文件采用的是按需加载的方式，也就是說当需要使用该类时才会将它的class文件加载到内存生成class对象。而且加载某个类的class文件时，Java虚拟机采用的是双亲委派模式，即把请求交由父类处理，它是一种任务委派模式。</p><p>工作原理：</p><ol><li>如果一个类加载器收到了JVM对它发起的类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行</li><li>如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的引导类加载器</li><li>如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235513.png" alt="image-20200910182810609"></p><p>作用：</p><ol><li><p>避免核心库中的类被用户自定义的完全一样的全限定名的类覆盖(即使用户定义了<code>java.lang.CustomerClass</code>这样的自定义类，但是包名是核心库下的包，最终委派到引导类加载器的时候会抛出异常，这也称为&quot;<strong>沙箱安全机制</strong>&quot;)</p><p>即使自定义了自己的类加载器,强行用defineClass()方法去加载一个自定义的以“java.lang”开头的类也不会成功。如果读者尝试这样做的话,将会收到一个由Java虚拟机内部抛出的“java.lang.SecurityException: Prohibited package name:java.lang”异常。</p></li><li><p>避免类的重复加载</p></li><li><p>在遇到类名完全一样的情况下，如果加载器不同也不会有问题，由加载器-全限定类名唯一确定一个类</p></li></ol><h3 id="破坏双亲委派机制-反向委派"><a class="header-anchor" href="#破坏双亲委派机制-反向委派">¶</a>破坏双亲委派机制(反向委派)</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235519.png" alt="image-20200910201806151"></p><p>类似JDBC，接口类是由引导类加载器加载的，但是后续的<code>Class.forName(&quot;具体的服务实现类全限定名&quot;)</code>中指定的具体服务实现类引导类加载器却无法加载，此时需要委派到子类加载器进行加载。</p><h2 id="JDK9后的类加载器"><a class="header-anchor" href="#JDK9后的类加载器">¶</a>JDK9后的类加载器</h2><p>在JDK 9中引入的Java模块化系统(Java Platform Module System,JPMS)是对Java技术的一次重要升级,为了能够实现模块化的关键目标——可配置的封装隔离机制,Java虚拟机对类加载架构也做出了相应的变动调整,才使模块化系统得以顺利地运作。JDK 9的模块不仅仅像之前的JAR包那样只是简单地充当代码的容器,除了代码外,Java的模块定义还包含以下内容:</p><ul><li>依赖其他模块的列表。</li><li>导出的包列表,即其他模块可以使用的列表。</li><li>开放的包列表,即其他模块可反射访问模块的列表。</li><li>使用的服务列表。</li><li>提供服务的实现列表。</li></ul><p>配置的封装隔离机制首先要解决JDK 9之前基于类路径(ClassPath)来查找依赖的可靠性问题。此前,如果类路径中缺失了运行时依赖的类型,那就只能等程序运行到发生该类型的加载、链接时才会报出运行的异常。而在JDK 9以后,如果启用了模块化进行封装,模块就可以声明对其他模块的显式依赖,这样Java虚拟机就能够在启动时验证应用程序开发阶段设定好的依赖关系在运行期是否完备,如有缺失那就直接启动失败,从而避免了<strong>很大一部分</strong>由于类型依赖而引发的运行时异常。</p><p>可配置的封装隔离机制还解决了原来类路径上跨JAR文件的public类型的可访问性问题。JDK 9中的public类型不再意味着程序的所有地方的代码都可以随意访问到它们,模块提供了更精细的可访问性控制,必须明确声明其中哪一些public的类型可以被其他哪一些模块访问,这种访问控制也主要是在类加载过程中完成的（链接-验证的符号引用验证部分）。</p><h3 id="加入模块化系统之后向前兼容JAR包访"><a class="header-anchor" href="#加入模块化系统之后向前兼容JAR包访">¶</a>加入模块化系统之后向前兼容JAR包访</h3><p>为了使可配置的封装隔离机制能够兼容传统的类路径查找机制,JDK 9提出了与“类路径”(ClassPath)相对应的“模块路径”(ModulePath)的概念。简单来说,就是某个类库到底是模块还是传统的JAR包,只取决于它存放在哪种路径上。只要是放在类路径上的JAR文件,无论其中是否包含模块化信息(是否包含了module-info.class文件),它都会被当作传统的JAR包来对待;相应地,只要放在模块路径上的JAR文件,即使没有使用JMOD后缀,甚至说其中并不包含module-info.class文件,它也仍然会被当作一个模块来对待。</p><p>模块化系统将按照以下规则来保证使用传统类路径依赖的Java程序可以不经修改地直接运行在JDK 9及以后的Java版本上,即使这些版本的JDK已经使用模块来封装了Java SE的标准类库,模块化系统的这套规则也仍然保证了传统程序可以访问到所有标准类库模块中导出的包。</p><ul><li>JAR文件在类路径的访问规则:所有类路径下的JAR文件及其他资源文件,都被视为自动打包在一个匿名模块(Unnamed Module)里,这个匿名模块几乎是没有任何隔离的,它可以看到和使用类路径上所有的包、JDK系统模块中所有的导出包,以及模块路径上所有模块中导出的包。</li><li>模块在模块路径的访问规则:模块路径下的具名模块(Named Module)只能访问到它依赖定义中列明依赖的模块和包,匿名模块里所有的内容对具名模块来说都是不可见的,即具名模块看不见传统JAR包的内容。</li><li>JAR文件在模块路径的访问规则:如果把一个传统的、不包含模块定义的JAR文件放置到模块路径中,它就会变成一个自动模块(Automatic Module)。尽管不包含module-info.class,但自动模块将默认依赖于整个模块路径中的所有模块,因此可以访问到所有模块导出的包,自动模块也默认导出自己所有的包。</li></ul><p>以上3条规则保证了即使Java应用依然使用传统的类路径,升级到JDK 9对应用来说几乎(类加载器上的变动还是可能会导致少许可见的影响,将在下节介绍)不会有任何感觉,项目也不需要专门为了升级JDK版本而去把传统JAR包升级成模块。</p><h3 id="模块化下的类加载器"><a class="header-anchor" href="#模块化下的类加载器">¶</a>模块化下的类加载器</h3><ul><li><p>首先,是扩展类加载器(Extension Class Loader)被平台类加载器(Platform Class Loader)取代。这其实是一个很顺理成章的变动,既然整个JDK都基于模块化进行构建(原来的<code>rt.jar</code>和<code>tools.jar</code>被拆分成数十个JMOD文件),其中的Java类库就已天然地满足了可扩展的需求,那自然无须再保留<jav a_home>\lib\ext目录</jav></p></li><li><p>其次,平台类加载器和应用程序类加载器都不再派生自<code>java.net.URLClassLoader</code>,如果有程序直接依赖了这种继承关系,或者依赖了<code>URLClassLoader</code>类的特定方法,那代码很可能会在JDK 9及更高版本的JDK中崩溃。现在启动类加载器、平台类加载器、应用程序类加载器全都继承于<code>jdk.internal.loader.BuiltinClassLoader</code></p></li><li><p>启动类加载器现在是在Java虚拟机内部和Java类库共同协作实现的类加载器,尽管有了<code>BootClassLoader</code>这样的Java类,但为了与之前的代码保持兼容,所有在获取启动类加载器的场景(譬如<code>Object.class.getClassLoader()</code>)中仍然会返回null来代替,而不会得到<code>BootClassLoader</code>的实例。</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235527.png" alt="image-20200921211450487"></p><p>JDK 9中虽然仍然维持着三层类加载器和双亲委派的架构,但类加载的委派关系也发生了变动。当平台及应用程序类加载器收到类加载请求,在委派给父加载器加载前,要先判断该类是否能够归属到某一个系统模块中,如果可以找到这样的归属关系,就要优先委派给负责那个模块的加载器完成加载,也许这可以算是对双亲委派的又一次破坏。</p><p>在Java模块化系统明确规定了三个类加载器负责各自加载的模块,即前面所说的归属关系,如下所示：</p><h4 id="启动类加载器负责加载的模块"><a class="header-anchor" href="#启动类加载器负责加载的模块">¶</a>启动类加载器负责加载的模块</h4><pre class="line-numbers language-language-java"><code class="language-language-java">java.basejava.security.sasl java.datatransferjava.xml java.desktopjdk.httpserver java.instrument                  jdk.internal.vm.cijava.loggingjdk.management java.management                  jdk.management.agent java.management.rmi              jdk.naming.rmi java.namingjdk.netjava.prefsjdk.sctpjava.rmijdk.unsupported<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="平台类加载器负责加载的模块"><a class="header-anchor" href="#平台类加载器负责加载的模块">¶</a>平台类加载器负责加载的模块</h4><pre class="line-numbers language-language-java"><code class="language-language-java">java.activation*jdk.accessibility java.compiler*jdk.charsets java.corba*jdk.crypto.cryptoki java.scriptingjdk.crypto.ecjava.sejdk.dynalinkjava.se.eejdk.incubator.httpclient java.security.jgssjdk.internal.vm.compiler*java.smartcardio                jdk.jsobjectjava.sqljdk.localedata java.sql.rowsetjdk.naming.dns java.transaction*jdk.scripting.nashorn java.xml.bind*jdk.security.authjava.xml.cryptojdk.security.jgss java.xml.ws*jdk.xml.dom java.xml.ws.annotation*jdk.zipfs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="应用程序类加载器负责加载的模块"><a class="header-anchor" href="#应用程序类加载器负责加载的模块">¶</a>应用程序类加载器负责加载的模块</h4><pre class="line-numbers language-language-java"><code class="language-language-java">jdk.aotjdk.jdeps jdk.attach                      jdk.jdi jdk.compiler           jdk.jdwp.agent jdk.editpad   jdk.jlink jdk.hotspot.agent  jdk.jshelljdk.internal.ed     jdk.jstatd jdk.internal.jvmstat       jdk.pack jdk.internal.le  jdk.policytool jdk.internal.opt  jdk.rmic jdk.jartool  jdk.scripting.nashorn.shelljdk.javadoc         jdk.xml.bind* jdk.jcmd        jdk.xml.ws* jdk.jconsole<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1>其他</h1><ul><li><p>在JVM中表示通过以下方式唯一确定一个Class对象：</p><ol><li><p>类的完整类名必须一致，包括包名。</p></li><li><p>加载这个类的ClassLoader（指ClassLoader实例对象）必须是同一个</p><p>换句话说，在JVM中，即使这两个类对象(class对象)来源同一个Class文件，被同一个虚拟机所加载，但只要加载它们的ClassLoader实例对象不同，那么这两个类对象也是不相等的。这里所指的“相等”,包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance() 方法的返回结果,也包括了使用instanceof关键字做对象所属关系判定等各种情况。</p></li></ol></li><li><p>JVM必须知道一个类型是由启动加载器加载的还是由用户类加载器加载的。如果一个类型是由用户类加载器加载的，那么JVM会将这个类加载器的一个引用作为类型信息的一部分保存在方法区中(<code>clzz.getClassLoader()</code>)。当解析一个类型到另一个类型的引用的时候，JVM需要保证这两个类型的类加载器是相同的。</p></li></ul><h1>类加载器案例</h1><h2 id="TOMCAT"><a class="header-anchor" href="#TOMCAT">¶</a>TOMCAT</h2><p>主流的Java Web服务器,如Tomcat、Jetty、WebLogic、WebSphere或其他笔者没有列举的服务器, 都实现了自己定义的类加载器,而且一般还都不止一个。因为一个功能健全的Web服务器,都要解决如下的这些问题:</p><ul><li><p>部署在同一个服务器上的两个Web应用程序所使用的Java类库可以实现相互隔离。这是最基本的需求,两个不同的应用程序可能会依赖同一个第三方类库的不同版本,不能要求每个类库在一个服务器中只能有一份,服务器应当能够保证两个独立应用程序的类库可以互相独立使用。</p></li><li><p>部署在同一个服务器上的两个Web应用程序所使用的Java类库可以互相共享。这个需求与前面一点正好相反,但是也很常见,例如用户可能有10个使用Spring组织的应用程序部署在同一台服务器上,如果把10份Spring分别存放在各个应用程序的隔离目录中,将会是很大的资源浪费——这主要倒不是浪费磁盘空间的问题,而是指类库在使用时都要被加载到服务器内存,如果类库不能共享,虚拟机的方法区就会很容易出现过度膨胀的风险。</p></li><li><p>服务器需要尽可能地保证自身的安全不受部署的Web应用程序影响。目前,有许多主流的Java Web服务器自身也是使用Java语言来实现的。因此服务器本身也有类库依赖的问题,一般来说,基于安全考虑,服务器所使用的类库应该与应用程序的类库互相独立。</p></li><li><p>支持JSP应用的Web服务器,十有八九都需要支持HotSwap功能。我们知道JSP文件最终要被编译成Java的Class文件才能被虚拟机执行,但JSP文件由于其纯文本存储的特性,被运行时修改的概率远大于第三方类库或程序自己的Class文件。而且ASP、PHP和JSP这些网页应用也把修改后无须重启作为一个很大的“优势”来看待,因此“主流”的Web服务器都会支持JSP生成类的热替换,当然也有“非主流”的,如运行在生产模式(Production Mode)下的WebLogic服务器默认就不会处理JSP文件的变化。</p></li></ul><p>由于存在上述问题,在部署Web应用时,单独的一个ClassPath就不能满足需求了,所以各种Web服务器都不约而同地提供了好几个有着不同含义的ClassPath路径供用户存放第三方类库,这些路径一般会以“lib”或“classes”命名。被放置到不同路径中的类库,具备不同的访问范围和服务对象,通常每一个目录都会有一个相应的自定义类加载器去加载放置在里面的Java类库。</p><p>在Tomcat目录结构中,可以设置3组目录(<code>/common/*</code>、<code>/server/*</code>和<code>/shared/*</code>,但默认不一定是开放的,可能只有<code>/lib/*</code>目录存在)用于存放Java类库,另外还应该加上Web应用程序自身的<code>/WEB- INF/*</code>目录,一共4组。把Java类库放置在这4组目录中,每一组都有独立的含义,分别是:</p><ul><li>放置在/common目录中。类库可被Tomcat和所有的Web应用程序共同使用。</li><li>放置在/server目录中。类库可被Tomcat使用,对所有的Web应用程序都不可见。</li><li>放置在/shared目录中。类库可被所有的Web应用程序共同使用,但对Tomcat自己不可见。</li><li>放置在/WebApp/WEB-INF目录中。类库仅仅可以被该Web应用程序使用,对Tomcat和其他Web应用程序都不可见。</li></ul><p>为了支持这套目录结构,并对目录里面的类库进行加载和隔离,Tomcat自定义了多个类加载器, 这些类加载器按照经典的双亲委派模型来实现</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235535.png" alt="image-20200922151032313"></p><p>灰色背景的3个类加载器是JDK(以JDK 9之前经典的三层类加载器为例)默认提供的类加载器。下面则是Tomcat自己定义的类加载器</p><ul><li>Common类加载器：加载<code>/common/*</code>中的Java类库</li><li>Catalina类加载器(也称为Server类加载器)：加载<code>/server/*</code>中的Java类库</li><li>Shared类加载器：加载<code>/shared/*</code>中的Java类库</li><li>Webapp类加载器：加载<code>/WebApp/WEB-INF/*</code>中的Java类库<ul><li>存在多个实例：每一个Web应用程序对应一个WebApp类加载器</li></ul></li><li>JSP类加载器：加载JSP文件<ul><li>存在多个实例：每一个JSP文件对应一个JasperLoader类加载器</li></ul></li></ul><p>Common类加载器能加载的类都可以被Catalina类加载器和Shared 类加载器使用,而Catalina类加载器和Shared类加载器自己能加载的类则与对方相互隔离。WebApp类加载器可以使用Shared类加载器加载到的类,但各个WebApp类加载器实例之间相互隔离。而JasperLoader的加载范围仅仅是这个JSP文件所编译出来的那一个Class文件,它存在的目的就是为了被丢弃:当服务器检测到JSP文件被修改时,会替换掉目前的JasperLoader的实例,并通过再建立一个新的JSP类加载器来实现JSP文件的HotSwap功能。</p><p>本例中的类加载结构在Tomcat 6以前是它默认的类加载器结构,在Tomcat 6及之后的版本简化了默认的目录结构,只有指定了<code>tomcat/conf/catalina.properties</code>配置文件的<code>server.loader</code>和<code>share.loader</code>项后才会真正建立Catalina类加载器和Shared类加载器的实例,否则会用到这两个类加载器的地方都会用Common类加载器的实例代替,而默认的配置文件中并没有设置这两个loader项,所以Tomcat 6之后也顺理成章地把<code>/common</code>、<code>/server</code>和<code>/shared</code>这3个目录默认合并到一起变成1个<code>/lib</code>目录,这个目录里的类库相当于以前<code>/common</code>目录中类库的作用,是Tomcat的开发团队为了简化大多数的部署场景所做的一项易用性改进。如果默认设置不能满足需要,用户可以通过修改配置文件指定<code>server.loader</code>和<code>share.loader</code> 的方式重新启用原来完整的加载器架构。</p><h3 id="思考"><a class="header-anchor" href="#思考">¶</a>思考</h3><p>被Common类加载器或Shared类加载器加载的Spring如何访问并不在其加载范围内的用户程序呢？其实就是类似破坏双亲委派模型，通过调用子类加载器(委派)将对应的<code>Class</code>对象加载出来。</p><p>例子：以下代码中通过将<code>john.classloader.TestClassLoader.java</code>编译后得到的<code>TestClassLoader.class</code>文件在标准库目录和指定目录之间移动将得到不同的效果。当移动到指定目录之后，<code>TestCall</code>由应用程序类加载器加载，它通过指定的类加载器<code>Loader</code>在指定目录对类进行加载之后即可进行访问：</p><pre class="line-numbers language-language-java"><code class="language-language-java">package john.classloader;import java.lang.reflect.InvocationTargetException;import java.net.MalformedURLException;import java.net.URL;import java.net.URLClassLoader;import java.net.URLStreamHandlerFactory;/** * @author: honphan.john * @date: 2020/9/10 17:14 * @description: */public class ClassLoaderTest2 {    public static void main(String[] args) throws MalformedURLException, ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException {        TestCall testCall = new TestCall();        testCall.testWithClassLoader();        testCall.testWithSymbol();    }    static class Loader extends URLClassLoader {        public Loader() throws MalformedURLException {          //自定义类路径，非标准路径            super(new URL[]{new URL( "file:///Users/zhonghongpeng/IdeaProjects/tech-learning/jvm/src/main/java/")});        }        public Loader(URL[] urls, ClassLoader parent) {            super(urls, parent);        }        public Loader(URL[] urls, ClassLoader parent, URLStreamHandlerFactory factory) {            super(urls, parent, factory);        }    }    static class TestCall {        public void testWithClassLoader() {            try {                final String methodName = "test";                Class<?> aClass = new Loader().loadClass("john.classloader.TestClassLoader");                aClass.getMethod(methodName).invoke(aClass.getConstructors()[0].newInstance());            } catch (Exception ignored) {}            //当 TestClassLoader.class移动到了指定目录。输出："hello! 我的类加载器是john.classloader.ClassLoaderTest2$Loader@d716361"            //当 TestClassLoader.class移动到了指定目录 存在标准目录。输出："hello! 我的类加载器是sun.misc.Launcher$AppClassLoader@18b4aac2"        }        TestClassLoader test; //如果在标准类路径中不存在 TestClassLoader.class，这里会在编译期报错，无法通过编译，该符号引用无效。此时只能通过指定类加载器进行加载        public void testWithSymbol() {            test.test();        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-language-java"><code class="language-language-java">package john.classloader;/** * @author: honphan.john * @date: 2020/9/22 14:59 * @description: */public class TestClassLoader {    public void test() {        System.out.println("hello! 我的类加载器是" + this.getClass().getClassLoader());    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="OSGI"><a class="header-anchor" href="#OSGI">¶</a>OSGI</h2><p>OSGi[1](Open Service Gateway Initiative)是OSGi联盟(OSGi Alliance)制订的一个基于Java语言的动态模块化规范(在JDK 9引入的JPMS是静态的模块系统)。</p><p>OSGi中的每个模块(称为Bundle)与普通的Java类库区别并不太大,两者一般都以JAR格式进行封装,并且内部存储的都是Java的Package和Class。但是一个Bundle可以声明它所依赖的Package(通过Import-Package描述),也可以声明它允许导出发布的Package(通过Export-Package描述)。在OSGi 里面,Bundle之间的依赖关系从传统的上层模块依赖底层模块转变为平级模块之间的依赖,而且类库的可见性能得到非常精确的控制,一个模块里只有被Export过的Package才可能被外界访问,其他的Package和Class将会被隐藏起来。</p><p>OSGi现在着重向动态模块化系统的方向发展。在今天,通常引入OSGi的主要理由是基于OSGi架构的程序很可能(只是很可能,并不是一定会,需要考虑热插拔后的内存管理、上下文状态维护问题等复杂因素)会实现模块级的热插拔功能,当程序升级更新或调试除错时,可以只停用、重新安装然后启用程序的其中一部分,这对大型软件、企业级程序开发来说是一个非常有诱惑力的特性,譬如Eclipse中安装、卸载、更新插件而不需要重启动,就使用到了这种特性。</p><p>OSGi之所以能有上述诱人的特点,必须要归功于它灵活的类加载器架构。OSGi的Bundle类加载器之间只有规则,没有固定的委派关系。例如,某个Bundle声明了一个它依赖的Package,如果有其他Bundle声明了发布这个Package后,那么所有对这个Package的类加载动作都会委派给发布它的Bundle类加载器去完成。不涉及某个具体的Package时,各个Bundle加载器都是平级的关系,只有具体使用到某个Package和Class的时候,才会根据Package导入导出定义来构造Bundle间的委派和依赖。</p><p>另外,一个Bundle类加载器为其他Bundle提供服务时,会根据Export-Package列表严格控制访问范围。如果一个类存在于Bundle的类库中但是没有被Export,那么这个Bundle的类加载器能找到这个类, 但不会提供给其他Bundle使用,而且OSGi框架也不会把其他Bundle的类加载请求分配给这个Bundle来处理。</p><p>我们可以举一个更具体些的简单例子来解释上面的规则,假设存在Bundle A、Bundle B、Bundle C3个模块,并且这3个Bundle定义的依赖关系如下所示。</p><ul><li>Bundle A:声明发布了packageA,依赖了<code>java.*</code>的包;</li><li>Bundle B:声明依赖了packageA和packageC,同时也依赖了<code>java.*</code>的包;</li><li>Bundle C:声明发布了packageC,依赖了packageA。</li></ul><p>那么,这3个Bundle之间的类加载器及父类加载器之间的关系如</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235544.png" alt="image-20200922155054517"></p><p>在OSGi中,加载器之间的关系不再是双亲委派模型的树形结构,而是已经进一步发展成一种更为复杂的、运行时才能确定的网状结构。这种网状的类加载器架构在带来更优秀的灵活性的同时,也可能会产生许多新的隐患。例如死锁。</p><h2 id="字节码生成技术与动态代理的实现"><a class="header-anchor" href="#字节码生成技术与动态代理的实现">¶</a>字节码生成技术与动态代理的实现</h2><p>动态代理中所说的“动态”,是相对<strong>使用Java代码实际编写了代理类</strong>的“静态”代理而言的,它的优势不在于省去了编写代理类那一点编码工作量,而是实现了可以在原始类和接口还未知的时候,就确定代理类的代理行为,当代理类与原始类脱离直接联系后,就可以很灵活地重用于不同的应用场景之中。</p><pre class="line-numbers language-language-java"><code class="language-language-java">package john.classloader;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;/** * @author: honphan.john * @date: 2020/9/22 15:57 * @description: */public class DynamicProxyTest {    interface IHello {        void sayHello();    }    static class Hello implements IHello {        @Override        public void sayHello() {            System.out.println("hello world");        }    }    static class DynamicProxy implements InvocationHandler {        Object originalObj;        Object bind(Object originalObj) {            this.originalObj = originalObj;            return Proxy.newProxyInstance(originalObj.getClass().getClassLoader(), originalObj.getClass().getInterfaces(), this);        }        @Override        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {            System.out.println("welcome");            return method.invoke(originalObj, args);        }    }    public static void main(String[] args) {        IHello hello = (IHello) new DynamicProxy().bind(new Hello());        hello.sayHello();    }}//输出//welcome//hello world<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Proxy::newProxyInstance()方法返回一个实现了<code>IHello</code>的接口,并且代理了<code>new Hello()</code>实例行为的对象。跟踪这个方法的源码,可以看到程序进行过验证、优化、缓存、同步、生成字节码、显式类加载等操作,前面的步骤并不是我们关注的重点,这里只分析它最后调用<code>sun.misc.ProxyGenerator::generateProxyClass()</code>方法来完成生成字节码的动作,这个方法会在运行时产生一个描述代理类的字节码byte[]数组。如果想看一看这个在运行时产生的代理类中写了些什么,可以在main()方法中加入下面这句:</p><pre class="line-numbers language-language-java"><code class="language-language-java">System.getProperties().put("sun.misc.ProxyGenerator.saveGeneratedFiles", "true");<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>磁盘中将会产生一个名为“$Proxy0.class”的代理类Class文件,反编译后可以看见：</p><pre class="line-numbers language-language-java"><code class="language-language-java">//// Source code recreated from a .class file by IntelliJ IDEA// (powered by FernFlower decompiler)//package john.classloader;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;import john.classloader.DynamicProxyTest.IHello;final class $Proxy0 extends Proxy implements IHello {    private static Method m1;    private static Method m3;    private static Method m2;    private static Method m0;    public $Proxy0(InvocationHandler var1) throws  {        super(var1);    }    public final boolean equals(Object var1) throws  {        try {            return (Boolean)super.h.invoke(this, m1, new Object[]{var1});        } catch (RuntimeException | Error var3) {            throw var3;        } catch (Throwable var4) {            throw new UndeclaredThrowableException(var4);        }    }    public final void sayHello() throws  {        try {            super.h.invoke(this, m3, (Object[])null);        } catch (RuntimeException | Error var2) {            throw var2;        } catch (Throwable var3) {            throw new UndeclaredThrowableException(var3);        }    }    public final String toString() throws  {        try {            return (String)super.h.invoke(this, m2, (Object[])null);        } catch (RuntimeException | Error var2) {            throw var2;        } catch (Throwable var3) {            throw new UndeclaredThrowableException(var3);        }    }    public final int hashCode() throws  {        try {            return (Integer)super.h.invoke(this, m0, (Object[])null);        } catch (RuntimeException | Error var2) {            throw var2;        } catch (Throwable var3) {            throw new UndeclaredThrowableException(var3);        }    }    static {        try {            m1 = Class.forName("java.lang.Object").getMethod("equals", Class.forName("java.lang.Object"));            m3 = Class.forName("john.classloader.DynamicProxyTest$IHello").getMethod("sayHello");            m2 = Class.forName("java.lang.Object").getMethod("toString");            m0 = Class.forName("java.lang.Object").getMethod("hashCode");        } catch (NoSuchMethodException var2) {            throw new NoSuchMethodError(var2.getMessage());        } catch (ClassNotFoundException var3) {            throw new NoClassDefFoundError(var3.getMessage());        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个代理类的实现代码也很简单,它为传入接口中的每一个方法,以及从java.lang.Object中继承来的equals()、hashCode()、toString()方法都生成了对应的实现,并且统一调用了InvocationHandler对象的invoke()方法(代码中的“this.h”就是父类Proxy中保存的InvocationHandler实例变量)来实现这些方法的内容,各个方法的区别不过是传入的参数和Method对象有所不同而已,所以无论调用动态代理的哪一个方法,实际上都是在执行InvocationHandler::invoke()中的代理逻辑。</p>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>07_直接内存</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/07-zhi-jie-nei-cun/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/07-zhi-jie-nei-cun/</url>
      
        <content type="html"><![CDATA[<h1>直接内存概述</h1><p>不是虚拟机运行时数据区的一部分，也不是《Java虚拟机规范》中定义的内存区域。直接内存是在Java堆外的、直接向系统申请的内存空间。它来源于NIO，通过存在堆中的DirectByteBuffer操作Native内存(底层都是调用unsafe包的api)。</p><p>通常，访问直接内存的速度会优于Java堆。即读写性能高。</p><ul><li><p>因此出于性能考虑，读写频繁的场合可能会考虑使用直接内存。</p></li><li><p>Java的NIO库允许Java程序使用直接内存，用于数据缓冲区。</p><pre class="line-numbers language-language-Java"><code class="language-language-Java">ByteBuffer buffer = ByteBuffer.allocateDirect(1024);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>另外这里申请的直接内存也会被GC</p><pre class="line-numbers language-language-java"><code class="language-language-java">System.gc();<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul><h2 id="在读写文件中直接内存的好处"><a class="header-anchor" href="#在读写文件中直接内存的好处">¶</a>在读写文件中直接内存的好处</h2><p>在普通IO的情况下，使用的是JVM进程的内存，这是用户态的内存空间。读写文件，需要与磁盘交互，涉及用户态和内核态之间的切换。如果不是使用直接内存，则会发生内核态与用户态直接的内存拷贝（读一次，写一次）。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234739.png" alt="image-20200917094412411"></p><p>但是，如果使用直接内存，JVM则可以利用操作系统的<a href="https://mp.weixin.qq.com/s/8J3Hnr7PX7YBX4hbK8oAQQ" target="_blank" rel="noopener">零拷贝</a>特性减少内存复制带来的消耗。</p><h1>直接内存异常</h1><p>直接内存也可能导致<code>OutOfMemoryError:Direct Memory Buffer</code>或者<code>OutOfMemoryError:null</code>异常。由于直接内存在Java堆外，因此它的大小不会直接受限于<code>-Xmx</code>指定的最大堆大小，但是系统内存是有限的，Java堆和直接内存的总和依然受限于操作系统能给出的最大内存。</p><p>缺点：</p><ul><li><p>分配回收成本较高</p></li><li><p>垃圾收集进行时,虚拟机虽然会对直接内存进行回收,但是直接内存却不能像新生代、老年代那样,发现空间不足了就主动通知收集器进行垃圾回收,它只能等待老年代满后Full GC出现后,“顺便”帮它清理掉内存的废弃对象。</p><p>所以如果JVM&quot;本身申请管理的内存&quot;没有很大消耗，反而直接内存消耗很大的时候，将直接抛出OOM。除非手动调用<code>System.gc()</code>进行Full GC，但是该方法可以通过<code>-XX:+DisableExplicitGC</code>禁用。</p></li></ul><p>直接内存大小可以通过<code>MaxDirectMemorySize</code>设置，如果不指定，默认与堆的最大值<code>-Xmx</code>一致。（注意，元空间占用的内存不在这里讲的直接内存中）</p><h1>内存分布图示</h1><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234752.png" alt="image-20200917100817936"></p>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>16_高效并发</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/16-gao-xiao-bing-fa/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/16-gao-xiao-bing-fa/</url>
      
        <content type="html"><![CDATA[<h1>Java内存模型与线程</h1><h2 id="硬件的效率与一致性"><a class="header-anchor" href="#硬件的效率与一致性">¶</a>硬件的效率与一致性</h2><p>“让计算机并发执行若干个运算任务”与“更充分地利用计算机处理器的效能”之间的因果关系,看起来理所当然,实际上它们之间的关系并没有想象中那么简单,其中一个重要的复杂性的来源是绝大多数的运算任务都不可能只靠处理器“计算”就能完成。处理器至少要与内存交互,如读取运算数据、存储运算结果等,这个I/O操作就是很难消除的(无法仅靠寄存器来完成所有运算任务)。由于计算机的存储设备与处理器的运算速度有着几个数量级的差距,所以现代计算机系统都不得不加入一层或多层读写速度尽可能接近处理器运算速度的高速缓存(Cache)来作为内存与处理器之间的缓冲:将运算需要使用的数据复制到缓存中,让运算能快速进行,当运算结束后再从缓存同步回内存之中,这样处理器就无须等待缓慢的内存读写了。</p><p>基于高速缓存的存储交互很好地解决了处理器与内存速度之间的矛盾,但是也为计算机系统带来更高的复杂度,它引入了一个新的问题:缓存一致性(Cache Coherence)。在多路处理器系统中,每个处理器都有自己的高速缓存,而它们又共享同一主内存(Main Memory),这种系统称为共享内存多核系统(Shared Memory Multiprocessors System),如图12-1所示。当多个处理器的运算任务都涉及同一块主内存区域时,将可能导致各自的缓存数据不一致。如果真的发生这种情况,那同步回到主内存时该以谁的缓存数据为准呢?为了解决一致性的问题,需要各个处理器访问缓存时都遵循一些协议,在读写时要根据协议来进行操作,这类协议有MSI、MESI(Illinois Protocol)、MOSI、Synapse、Firefly及Dragon Protocol等。“内存模型”可以理解为在特定的操作协议下,对特定的内存或高速缓存进行读写访问的过程抽象。不同架构的物理机器可以拥有不一样的内存模型,而Java虚拟机也有自己的内存模型,并且与这里介绍的内存访问操作及硬件的缓存访问操作具有高度的可类比性。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000528.png" alt="image-20200923160311060"></p><p>除了增加高速缓存之外,为了使处理器内部的运算单元能尽量被充分利用,<strong>处理器可能会对输入代码进行乱序执行</strong>(Out-Of-Order Execution)优化,处理器会在计算之后将乱序执行的结果重组,保证该结果与顺序执行的结果是一致的,但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致,因此如果存在一个计算任务依赖另外一个计算任务的中间结果,那么其顺序性并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类似,<strong>Java虚拟机的即时编译器中也有指令重排序(Instruction Reorder)优化</strong>。</p><h2 id="Java内存模型"><a class="header-anchor" href="#Java内存模型">¶</a>Java内存模型</h2><p>《Java虚拟机规范》<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>中曾试图定义一种“Java内存模型”<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> (Java Memory Model,JMM)来屏蔽各种硬件和操作系统的内存访问差异,以实现让Java程序在各种平台下都能达到一致的内存访问效果。在此之前,主流程序语言(如C和C++等)直接使用物理硬件和操作系统的内存模型。因此,由于不同平台上内存模型的差异,有可能导致程序在一套平台上并发完全正常,而在另外一套平台上并发访问却经常出错,所以在某些场景下必须针对不同的平台来编写程序。</p><p>定义Java内存模型并非一件容易的事情,这个模型必须定义得足够严谨,才能让Java的并发内存访问操作不会产生歧义;但是也必须定义得足够宽松,使得虚拟机的实现能有足够的自由空间去利用硬件的各种特性(寄存器、高速缓存和指令集中某些特有的指令)来获取更好的执行速度。经过长时间的验证和修补,直至JDK 5(实现了JSR-133<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>)发布后,Java内存模型才终于成熟、完善起来了</p><h3 id="主内存与工作内存"><a class="header-anchor" href="#主内存与工作内存">¶</a>主内存与工作内存</h3><p><strong>Java内存模型的主要目的是定义程序中各种变量的访问规则,即关注在虚拟机中把变量值存储到内存和从内存中取出变量值这样的底层细节</strong>。此处的变量(Variables)与Java编程中所说的变量有所区别,它包括了实例字段、静态字段和构成数组对象的元素,但是不包括局部变量与方法参数,因为后者是线程私有的<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>,不会被共享,自然就不会存在竞争问题。为了获得更好的执行效能,Java内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互,也没有限制即时编译器是否要进行调整代码执行顺序这类优化措施。</p><p>Java内存模型规定了所有的变量都存储在主内存(Main Memory)中(此处的主内存与介绍物理硬件时提到的主内存名字一样,两者也可以类比,但物理上它仅是虚拟机内存的一部分)。<strong>每条线程还有自己的工作内存</strong>(Working Memory,可与前面讲的处理器高速缓存类比),线程的工作内存中保存了被该线程使用的变量的主内存副本<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>,线程对变量的所有操作(<strong>读取、赋值</strong>等)都必须在工作内存中进行,而不能直接读写主内存中的数据<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>。<strong>不同的线程之间也无法直接访问对方工作内存中的变量,线程间变量值的传递均需要通过主内存来完成</strong>,线程、主内存、工作内存三者的交互关系如图</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000534.png" alt="image-20200923192052109"></p><p><strong>这里所讲的主内存、工作内存与Java内存区域中的Java堆、栈、方法区等并不是同一个层次的对内存的划分</strong>,这两者基本上是没有任何关系的。如果两者一定要勉强对应起来,那么从变量、主内存、工作内存的定义来看,主内存主要对应于Java堆中的对象实例数据部分<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>,而工作内存则对应于<strong>虚拟机栈中的部分区域</strong>。<strong>从更基础的层次上说,主内存直接对应于物理硬件的内存,而为了获取更好的运行速度,虚拟机(或者是硬件、操作系统本身的优化措施)可能会让工作内存优先存储于寄存器和高速缓存中,因为程序运行时主要访问的是工作内存</strong>。</p><h3 id="内存间交互操作"><a class="header-anchor" href="#内存间交互操作">¶</a>内存间交互操作</h3><p>关于主内存与工作内存之间具体的交互协议,即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存这一类的实现细节,Java内存模型中定义了以下8种操作来完成。Java虚拟机实现时必须保证下面提及的<strong>每一种操作都是原子的、不可再分的</strong>(对于double和long类型的变量来说, load、store、read和write操作在某些平台上允许有例外)<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>。</p><ul><li>lock(锁定):作用于主内存的变量,它把一个变量标识为一条线程独占的状态。</li><li>unlock(解锁):作用于主内存的变量,它把一个处于锁定状态的变量释放出来,<strong>释放后的变量才可以被其他线程锁定</strong>。</li><li>read(读取):作用于主内存的变量,它把一个变量的值从主内存传输到线程的工作内存中,以便随后的load动作使用(<strong>从主存到工作内存中的读buffer</strong>)。</li><li>load(载入):作用于工作内存的变量,它把read操作从主内存中得到的变量值放入工作内存的变量副本中(<strong>从工作内存中的读buffer到工作内存中的缓存</strong>)。</li><li>use(使用):作用于工作内存的变量,它把工作内存中一个变量的值传递给执行引擎,每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作(<strong>从工作内存到ALU寄存器</strong>)。</li><li>assign(赋值):作用于工作内存的变量,它把一个从执行引擎接收的值赋给工作内存的变量, 每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作(<strong>从ALU寄存器到工作内存</strong>)。</li><li>store(存储):作用于工作内存的变量,它把工作内存中一个变量的值传送到主内存中,以便随后的write操作使用(<strong>从工作内存中的缓存到工作内存中的写buffer</strong>)。</li><li>write(写入):作用于主内存的变量,它把store操作从工作内存中得到的变量的值放入主内存的变量中(<strong>从工作内存中的写buffer到主存</strong>)。</li></ul><p>如果要把一个变量从主内存拷贝到工作内存,那就要按顺序执行read和load操作,如果要把变量从工作内存同步回主内存,就要按顺序执行store和write操作。**注意,Java内存模型只要求上述两个操作必须按顺序执行,但不要求是连续执行。**也就是说read与load之间、store与write之间是可插入其他指令的,如对主内存中的变量a、b进行访问时,一种可能出现的顺序是read a、read b、load b、load a。除此之外,Java内存模型还规定了在执行上述8种基本操作时必须满足如下规则:</p><ul><li>不允许read和load、store和write操作之一单独出现,即不允许一个变量从主内存读取了但工作内存不接受,或者工作内存发起回写了但主内存不接受的情况出现。</li><li>不允许一个线程丢弃它最近的assign操作,即变量<strong>在工作内存中改变了之后必须把该变化同步回主内存</strong>(在工作内存中发生了变化必须同步回主存，无论何时同步)。</li><li>不允许一个线程无原因地(没有发生过任何assign操作)把数据从线程的工作内存同步回主内存中(没有发生变化不能同步)。</li><li>一个新的变量只能在主内存中“诞生”,不允许在工作内存中直接使用一个未被初始化(load或assign)的变量,换句话说就是对一个变量实施use、store操作之前,必须先执行assign和load操作？</li><li>一个变量在同一个时刻只允许一条线程对其进行lock操作,但lock操作可以被同一条线程重复执行多次,多次执行lock后,只有执行相同次数的unlock操作,变量才会被解锁。</li><li><strong>如果对一个变量执行lock操作,那将会清空工作内存中此变量的值</strong>,在执行引擎使用这个变量前,需要重新执行load或assign操作以初始化变量的值。</li><li>如果一个变量事先没有被lock操作锁定,那就不允许对它执行unlock操作,也不允许去unlock一个被其他线程锁定的变量。</li><li>对一个变量执行unlock操作之前,必须先把此变量同步回主内存中(执行store、write操作)。</li></ul><p>这8种内存访问操作以及上述规则限定,再加上稍后会介绍的专门针对volatile的一些特殊规定,就已经能准确地描述出Java程序中哪些内存访问操作在并发下才是安全的。这种定义相当严谨,但也是极为烦琐,实践起来更是无比麻烦。可能部分读者阅读到这里已经对多线程开发产生恐惧感了,后来Java设计团队大概也意识到了这个问题,将Java内存模型的操作简化为read、write、lock和unlock四种,但这只是语言描述上的等价化简,Java内存模型的基础设计并未改变,即使是这四种操作,对于普通用户来说阅读使用起来仍然并不方便。不过除了进行虚拟机开发的团队外,大概没有其他开发人员会以这种方式来思考并发问题,我们只需要理解Java内存模型的定义即可。后面将介绍这种定义的一个等效判断原则——先行发生原则,用来确定一个操作在并发环境下是否安全的。</p><h3 id="对于volatile型变量的特殊规则"><a class="header-anchor" href="#对于volatile型变量的特殊规则">¶</a>对于volatile型变量的特殊规则</h3><p>关键字<code>volatile</code>可以说是Java虚拟机提供的最轻量级的同步机制，它和<code>synchronized</code>具有不同的语义。</p><p>Java内存模型为<code>volatile</code>专门定义了一些特殊的访问规则,在介绍这些比较拗口的规则定义之前, 先用一些不那么正式,但通俗易懂的语言来介绍一下这个关键字的作用。<br>当一个变量被定义成<code>volatile</code>之后,它将具备两项特性:</p><h4 id="可见性"><a class="header-anchor" href="#可见性">¶</a>可见性</h4><p>第一项是保证此变量对所有线程的可见性,这里的“可见性”是指当一条线程修改了这个变量的值,新值对于其他线程来说是可以立即得知的。而普通变量并不能做到这一点,普通变量的值在线程间传递时均需要通过主内存来完成。比如, 线程A修改一个普通变量的值,然后向主内存进行回写,另外一条线程B在线程A回写完成了之后再对主内存进行读取操作,新变量值才会对线程B可见(也就是说线程B如果在线程A回写完成之前读取变量那么得到的还是旧值)。</p><p>关于<code>volatile</code>变量的可见性,经常会被开发人员误解,他们会误以为下面的描述是正确的:“volatile 变量对所有线程是立即可见的,对volatile变量所有的写操作都能立刻反映到其他线程之中。换句话说,volatile变量在各个线程中是一致的,所以基于volatile变量的运算在并发下是线程安全的”。这句话的论据部分并没有错,但是由其论据并不能得出“基于volatile变量的运算在并发下是线程安全的”这样的结论</p><p><strong>volatile变量在各个线程的工作内存中是不存在一致性问题的</strong>(<em><strong>从物理存储的角度看,各个线程的工作内存中volatile变量也可以存在不一致的情况,但由于每次使用之前都要先刷新,执行引擎看不到不一致的情况,因此可以认为不存在一致性问题</strong></em>),但是Java里面的运算操作符并非原子操作, 这导致<code>volatile</code>变量的运算在并发下一样是不安全的,最经典的就是<code>var++</code>的例子，即使在源代码上是一行代码，但是经过编译到底层后就是很多行指令了：</p><ul><li>主存中存在变量<code>var</code>被<code>volatile</code>修饰</li><li>线程A读取变量<code>var</code>，必须从主存中获取最新值，此时经过<code>read</code>、<code>load</code>获取到值为1然后加载到工作内存，执行引擎<code>use</code>开始+1计算</li><li>此时切换到了线程B，同样从主存加载<code>var</code>值到工作内存，此时还是1</li><li>此时切换回线程A，计算完毕，<code>assign</code>计算结果2到工作内存，经过<code>store</code>、<code>write</code>从工作内存回写到主存</li><li>此时再切换回线程B，同样计算完毕，执行同样操作，此时线程A计算结果被覆盖</li></ul><p>由于<code>volatile</code>变量只能保证可见性,在<strong>不符合以下两条规则的运算场景中</strong>,我们仍然要通过加锁(使用<code>synchronized</code>、<code>java.util.concurrent</code>中的锁或原子类)来保证原子性:</p><ul><li>运算结果并不依赖变量的当前值,或者能够确保只有单一的线程修改变量的值。</li><li>变量不需要与其他的状态变量共同参与不变约束。</li></ul><p>而在像以下代码所示的这类场景中就很适合使用<code>volatile</code>变量来控制并发,当<code>shutdown()</code>方法被调用时,能保证所有线程中执行的<code>doWork()</code>方法都立即停下来。</p><pre class="line-numbers language-language-java"><code class="language-language-java">volatile boolean shutdownRequested; public void shutdown() {  shutdownRequested = true; }public void doWork() {  while (!shutdownRequested) {    // 代码的业务逻辑      } }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="有序性"><a class="header-anchor" href="#有序性">¶</a>有序性</h4><p>使用<code>volatile</code>变量的第二个语义是禁止指令重排序优化,普通的变量仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果,而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。因为在同一个线程的方法执行过程中无法感知到这点,这就是Java内存模型中描述的所谓“线程内表现为串行的语义”(Within-Thread As-If-Serial Semantics)。</p><p>一个例子说明指令重排序带来的影响：</p><pre class="line-numbers language-language-java"><code class="language-language-java">Map configOptions; char[] configText; // 此变量必须定义为volatile volatile boolean initialized = false; // 假设以下代码在线程A中执行// 模拟读取配置信息,当读取完成后// 将initialized设置为true,通知其他线程配置可用configOptions = new HashMap(); configText = readConfigFile(fileName); processConfigOptions(configText, configOptions); initialized = true; // 假设以下代码在线程B中执行// 等待initialized为true,代表线程A已经把配置信息初始化完成while (!initialized) {sleep(); } // 使用线程A中初始化好的配置信息doSomethingWithConfig();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果定义<code>initialized</code>变量时没有使用<code>volatile</code>修饰,就可能会由于指令重排序的优化,导致位于线程A中最后一条代码<code>initialized=true</code>被提前执行(这里虽然使用Java作为伪代码,但所指的重排序优化是机器级的优化操作,提前执行是指这条语句对应的汇编代码被提前执行),这样在线程B中使用配置信息的代码就可能出现错误,而<code>volatile</code>关键字则可以避免此类情况的发生。</p><h4 id="可见性和有序性的实现"><a class="header-anchor" href="#可见性和有序性的实现">¶</a>可见性和有序性的实现</h4><p>下面是一个DCL实现的单例代码：</p><pre class="line-numbers language-language-java"><code class="language-language-java">public class Singleton {    private volatile static Singleton instance;    public static Singleton getInstance() {        if (instance == null) {            synchronized (Singleton.class) {                if (instance == null) {                    instance = new Singleton();                }            }        }        return instance;    }    public static void main(String[] args) {        Singleton.getInstance();    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>反汇编后对<code>instance</code>赋值如下(<code>instance</code>是工作内存里面的变量，仅仅存储的是一个引用或者<code>null</code>)：</p><pre class="line-numbers language-language-assembly"><code class="language-language-assembly">0x01a3de0f: mov    $0x3375cdb0,%esi     ;...beb0cd75 33                                         ;   {oop('Singleton')} 0x01a3de14: mov    %eax,0x150(%esi)     ;...89865001 0000 0x01a3de1a: shr    $0x9,%esi            ;...c1ee09 0x01a3de1d: movb   $0x0,0x1104800(%esi) ;...c6860048 100100 0x01a3de24: lock addl $0x0,(%esp)       ;...f0830424 00                                         ;*putstatic instance                                         ; - Singleton::getInstance@24<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过对比发现,关键变化在于有volatile修饰的变量,赋值后(前面<code>mov %eax,0x150(%esi)</code>这句便是赋值操作)多执行了一个<code>lock addl $0x0,(%esp)</code>操作,这个操作的作用相当于一个内存屏障(Memory Barrier或Memory Fence,<strong>指重排序时不能把后面的指令重排序到内存屏障之前的位置</strong>),只有一个处理器访问内存时,并不需要内存屏障;但如果有两个或更多处理器访问同一块内存,且其中有一个在观测另一个,就需要内存屏障来保证一致性了。</p><p>这句指令中的<code>addl $0x0,(%esp)</code>(把ESP寄存器的值加0)显然是一个空操作,之所以用这个空操作而不是空操作专用指令<code>nop</code>,是因为IA32手册规定<code>lock</code>前缀不允许配合<code>nop</code>指令使用。这里的关键在于<code>lock</code>前缀,查询IA32手册可知,它的作用是将本处理器的缓存写入了内存,该写入动作也会引起别的处理器或者别的内核无效化(<code>Invalidate</code>)其缓存,这种操作相当于对缓存中的变量做了一次前面介绍Java内存模式中所说的<code>store</code>和<code>write</code>操作<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>。所以通过这样一个空操作,可让前面<code>volatile</code>变量的修改对其他处理器立即可见。</p><p>那为何说它禁止指令重排序呢?从硬件架构上讲,指令重排序是指处理器采用了允许将多条指令不按程序规定的顺序分开发送给各个相应的电路单元进行处理。但并不是说指令任意重排,处理器必须能正确处理指令依赖情况保障程序能得出正确的执行结果。譬如指令1把地址A中的值加10,指令2 把地址A中的值乘以2,指令3把地址B中的值减去3,这时指令1和指令2是有依赖的,它们之间的顺序不能重排——(A+10)<em>2与A</em>2+10显然不相等,但指令3可以重排到指令1、2之前或者中间,只要保证处理器执行后面依赖到A、B值的操作时能获取正确的A和B值即可。所以在同一个处理器中,重排序过的代码看起来依然是有序的。因此,<code>lock addl$0x0,(%esp)</code>指令把修改同步到内存时,意味着所有之前的操作都已经执行完成(即使前面的操作是乱序执行的，但是处理器会保证在单线程中它们计算得到的结果是一致的),这样便形成了“指令重排序无法越过内存屏障”的效果(<strong>这里的有序指的是在对<code>volatile</code>变量赋值之前的指令永远只会在它前面，在它后面的也永远只会在它后面</strong>)。</p><p>解决了<code>volatile</code>的语义问题,再来看看在众多保障并发安全的工具中选用<code>volatile</code>的意义——它能让我们的代码比使用其他的同步工具更快吗?在某些情况下,<code>volatile</code>的同步机制的性能确实要优于锁(使用<code>synchronized</code>关键字或<code>java.util.concurrent</code>包里面的锁),但是由于虚拟机对锁实行的许多消除和优化,使得我们很难确切地说<code>volatile</code>就会比<code>synchronized</code>快上多少。如果让<code>volatile</code>自己与自己比较,那可以确定一个原则:<code>volatile</code>变量读操作的性能消耗与普通变量几乎没有什么差别,但是写操作则可能会慢上一些,因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。不过即便如此,大多数场景下<code>volatile</code>的总开销仍然要比锁来得更低。我们在<code>volatile</code>与锁中选择的唯一判断依据仅仅是<code>volatile</code>的语义能否满足使用场景的需求。</p><p>现在回头来看看Java内存模型中对<code>volatile</code>变量定义的特殊规则的定义。假定<code>T</code>表示一个线程,<code>V</code>和<code>W</code>分别表示两个<code>volatile</code>型变量,那么在进行<code>read</code>、<code>load</code>、<code>use</code>、<code>assign</code>、<code>store</code>和<code>write</code>操作时需要满足如下规则:</p><ul><li><p>只有当线程<code>T</code>对变量<code>V</code>执行的前一个动作是<code>load</code>的时候,线程<code>T</code>才能对变量<code>V</code>执行<code>use</code>动作(<strong>变量加载到了工作内存就要立即使用</strong>)；</p><p>并且, 只有当线程<code>T</code>对变量<code>V</code>执行的后一个动作是<code>use</code>的时候,线程<code>T</code>才能对变量<code>V</code>执行<code>load</code>动作。线程<code>T</code>对变量<code>V</code>的<code>use</code>动作。可以认为是和线程<code>T</code>对变量<code>V</code>的<code>load</code>、<code>read</code>动作相关联的,必须连续且一起出现(<strong>只有在真正使用变量的前一刻才能从主存读取变量，并且是原子性地读取</strong>)。</p><p>这条规则要求在工作内存中,每次使用<code>V</code>前都必须先从主内存刷新最新的值,用于保证能看见其他线程对变量<code>V</code>所做的修改。</p></li><li><p>只有当线程<code>T</code>对变量<code>V</code>执行的前一个动作是<code>assign</code>的时候,线程<code>T</code>才能对变量<code>V</code>执行<code>store</code>动作(<strong>如果没有修改过变量的值，不能进行值同步，防止无缘由覆盖别的线程地覆盖其他线程的修改</strong>)；</p><p>并且,只有当线程<code>T</code>对变量<code>V</code>执行的后一个动作是<code>store</code>的时候,线程<code>T</code>才能对变量<code>V</code>执行<code>assign</code>动作。线程<code>T</code>对变量<code>V</code>的<code>assign</code>动作可以认为是和线程<code>T</code>对变量<code>V</code>的<code>store</code>、<code>write</code>动作相关联的,必须连续且一起出现(<strong>只要修改了变量的值，就要立即原子性地将其同步到主存</strong>)。</p><p>这条规则要求在工作内存中,每次修改<code>V</code>后都必须立刻同步回主内存中,用于保证其他线程可以看到自己对变量<code>V</code>所做的修改。</p></li><li><p>假定动作<code>A</code>是线程<code>T</code>对变量<code>V</code>实施的<code>use</code>或<code>assign</code>动作,假定动作<code>F</code>是和动作<code>A</code>相关联的<code>load</code>或<code>store</code>动作,假定动作<code>P</code>是和动作<code>F</code>相应的对变量<code>V</code>的<code>read</code>或<code>write</code>动作；</p><p>与此类似,假定动作<code>B</code>是线程<code>T</code>对变量<code>W</code> 实施的<code>use</code>或<code>assign</code>动作,假定动作<code>G</code>是和动作<code>B</code>相关联的<code>load</code>或<code>store</code>动作,假定动作<code>Q</code>是和动作<code>G</code>相应的对变量<code>W</code>的<code>read</code>或<code>write</code>动作。如果<code>A</code>先于<code>B</code>,那么<code>P</code>先于<code>Q</code>。</p><p>这条规则要求<code>volatile</code>修饰的变量不会被<strong>指令重排序</strong>优化,从而保证代码的执行顺序与程序的顺序相同。</p></li></ul><h3 id="针对long和double型变量的特殊规则"><a class="header-anchor" href="#针对long和double型变量的特殊规则">¶</a>针对long和double型变量的特殊规则</h3><p>Java内存模型要求<code>lock</code>、<code>unlock</code>、<code>read</code>、<code>load</code>、<code>assign</code>、<code>use</code>、<code>store</code>、<code>write</code>这八种操作都具有原子性, 但是对于64位的数据类型(<code>long</code>和<code>double</code>),在模型中特别定义了一条宽松的规定:<strong>允许虚拟机将没有被<code>volatile</code>修饰的64位数据的读写操作划分为两次32位的操作来进行</strong>,即允许虚拟机实现自行选择是否要保证64位数据类型的<code>load</code>、<code>store</code>、<code>read</code>和<code>write</code>这四个操作的原子性,这就是所谓的“<code>long</code>和<code>double</code>的非原子性协定”(Non-Atomic Treatment of double and long Variables)。</p><p><strong>如果有多个线程共享一个并未声明为<code>volatile</code>的<code>long</code>或<code>double</code>类型的变量</strong>,并且同时对它们进行读取和修改操作,那么某些线程可能会读取到一个既不是原值,也不是其他线程修改值的代表了“半个变量”的数值。不过这种读取到“半个变量”的情况是非常罕见的,经过实际测试[1],在目前主流平台下商用的64位Java虚拟机中并不会出现非原子性访问行为,但是对于32位的Java虚拟机,譬如比较常用的32 位x86平台下的HotSpot虚拟机,对long类型的数据确实存在非原子性访问的风险。从JDK 9起, HotSpot增加了一个实验性的参数<code>-XX:+AlwaysAtomicAccesses</code>(这是JEP 188对Java内存模型更新的一部分内容)来约束虚拟机对所有数据类型进行原子性的访问。而针对double类型,由于现代中央处理器中一般都包含专门用于处理浮点数据的浮点运算器(Floating Point Unit,FPU),用来专门处理单、双精度的浮点数据,所以哪怕是32位虚拟机中通常也不会出现非原子性访问的问题,实际测试也证实了这一点。笔者的看法是,在实际开发中,除非该数据有明确可知的线程竞争,否则我们在编写代码时一般不需要因为这个原因刻意把用到的long和double变量专门声明为volatile。</p><h3 id="原子性、可见性与有序性"><a class="header-anchor" href="#原子性、可见性与有序性">¶</a>原子性、可见性与有序性</h3><p>介绍完Java内存模型的相关操作和规则后,我们再整体回顾一下这个模型的特征。Java内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性这三个特征来建立的,我们逐个来看一下哪些操作实现了这三个特性。</p><h4 id="原子性-Atomicity"><a class="header-anchor" href="#原子性-Atomicity">¶</a>原子性(Atomicity)</h4><p>由Java内存模型来直接保证的原子性变量操作包括<code>read</code>、<code>load</code>、<code>assign</code>、<code>use</code>、<code>store</code>和<code>write</code>这六个, 我们大致可以认为,基本数据类型的访问、读写都是具备原子性的(例外就是<code>long</code>和<code>double</code>的非原子性协定,只要知道这件事情就可以了,无须太过在意这些几乎不会发生的例外情况)。</p><p>如果应用场景需要一个更大范围的原子性保证(经常会遇到),Java内存模型还提供了<code>lock</code>和<code>unlock</code>操作来满足这种需求,尽管虚拟机未把<code>lock</code>和<code>unlock</code>操作直接开放给用户使用,但是却提供了更高层次的字节码指令<code>monitorenter</code>和<code>monitorexit</code>来隐式地使用这两个操作。这两个字节码指令反映到Java 代码中就是同步块——<code>synchronized</code>关键字,因此在<code>synchronized</code>块之间的操作也具备原子性。</p><h4 id="可见性-Visibility"><a class="header-anchor" href="#可见性-Visibility">¶</a>可见性(Visibility)</h4><p>可见性就是指当一个线程修改了共享变量的值时,其他线程能够立即得知这个修改。上文在讲解<code>volatile</code>变量的时候已详细讨论过这一点。Java内存模型是通过在变量修改后将新值同步回主内存,在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的,无论是普通变量还是<code>volatile</code>变量都是如此。普通变量与<code>volatile</code>变量的区别是,<code>volatile</code>的特殊规则保证了新值能<strong>立即</strong>同步到主内存,以及每次使用前<strong>立即</strong>从主内存刷新。因此我们可以说<code>volatile</code>保证了<strong>多线程操作时变量的可见性</strong>,而普通变量则不能保证这一点。</p><p>除了<code>volatile</code>之外,Java还有两个关键字能实现可见性,它们是<code>synchronized</code>和<code>final</code>。</p><ul><li><p>同步块的可见性是由“对一个变量执行<code>unlock</code>操作之前,必须先把此变量同步回主内存中(执行<code>store</code>、<code>write</code>操作)”这条规则获得的。</p></li><li><p>而<code>final</code>关键字的可见性是指:被<code>final</code>修饰的字段在构造器中一旦被初始化完成,并且构造器没有把<code>this</code>的引用传递出去(<code>this</code>引用逃逸是一件很危险的事情,其他线程有可能通过这个引用访问到“初始化了一半”的对象),那么在其他线程中就能看见<code>final</code>字段的值。如下所示,变量<code>i</code>与<code>j</code>都具备可见性,它们无须同步就能被其他线程正确访问。</p><pre class="line-numbers language-language-java"><code class="language-language-java">    public static final int i;    public final int j;    static {        i=0;             // 省略后续动作    }    {            // 也可以选择在构造函数中初始化            j=0;             // 省略后续动作    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h4 id="有序性-Ordering"><a class="header-anchor" href="#有序性-Ordering">¶</a>有序性(Ordering)</h4><p>Java内存模型的有序性在前面讲解<code>volatile</code>时也比较详细地讨论过了,Java程序中天然的有序性可以总结为一句话:如果在本线程内观察,所有的操作都是有序的;如果在一个线程中观察另一个线程, 所有的操作都是无序的。前半句是指“线程内似表现为串行的语义”(Within-Thread As-If-Serial Semantics),后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。</p><p>Java语言提供了<code>volatile</code>和<code>synchronized</code>两个关键字来保证线程之间操作的有序性,<code>volatile</code>关键字本身就包含了禁止指令重排序的语义,而<code>synchronized</code>则是由“一个变量在同一个时刻只允许一条线程对其进行<code>lock</code>操作”这条规则获得的,这个规则决定了持有同一个锁的两个同步块只能串行地进入。</p><h3 id="先行发生原则"><a class="header-anchor" href="#先行发生原则">¶</a>先行发生原则</h3><p>如果Java内存模型中所有的有序性都仅靠<code>volatile</code>和<code>synchronized</code>来完成,那么有很多操作都将会变得非常啰嗦,但是我们在编写Java并发代码的时候并没有察觉到这一点,这是因为Java语言中有一个“先行发生”(Happens-Before)的原则。这个原则非常重要,它是判断数据是否存在竞争,线程是否安全的非常有用的手段。依赖这个原则,我们可以通过几条简单规则一揽子解决并发环境下两个操作之间是否可能存在冲突的所有问题,而不需要陷入Java内存模型苦涩难懂的定义之中。</p><p>现在就来看看“先行发生”原则指的是什么。先行发生是Java内存模型中定义的两项操作之间的偏序关系,比如说操作A先行发生于操作B,其实就是说在发生操作B之前,操作A产生的影响能被操作B 观察到,“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。这句话不难理解,但它意味着什么呢?我们可以举个例子来说明一下。如代码清单12-8所示的这三条伪代码。</p><pre class="line-numbers language-language-java"><code class="language-language-java">// 以下操作在线程A中执行i = 1; // 以下操作在线程B中执行j = i; // 以下操作在线程C中执行i = 2;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>假设线程A中的操作<code>i=1</code>先行发生于线程B的操作<code>j=i</code>,那我们就可以确定在线程B的操作执行后,变量<code>j</code>的值一定是等于1,得出这个结论的依据有两个:</p><ul><li>一是根据先行发生原则,<code>i=1</code>的结果可以被观察到;</li><li>二是线程C还没登场,线程A操作结束之后没有其他线程会修改变量i的值。</li></ul><p>现在再来考虑线程C,我们依然保持线程A和B之间的先行发生关系,而C出现在线程A和B的操作之间,但是C与B没有先行发生关系,那<code>j</code>的值会是多少呢?答案是不确定!1和2都有可能,因为线程C对变量<code>i</code>的影响可能会被线程B观察到,也可能不会,这时候线程B就存在读取到过期数据的风险,不具备多线程安全性。</p><p>下面是Java内存模型下一些“天然的”先行发生关系,这些先行发生关系无须任何同步器协助就已经存在,可以在编码中直接使用。如果两个操作之间的关系不在此列,并且无法从下列规则推导出来,则它们就没有顺序性保障,虚拟机可以对它们随意地进行重排序。</p><ul><li>程序次序规则(Program Order Rule):<strong>在一个线程内</strong>,<strong>按照控制流顺序</strong>,书写在前面的操作先行发生于书写在后面的操作。注意,这里说的是控制流顺序而不是程序代码顺序,因为要考虑分支、循环等结构。</li><li>管程锁定规则(Monitor Lock Rule):一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是“同一个锁”,而“后面”是指时间上的先后。</li><li><code>volatile</code>变量规则(Volatile Variable Rule):对一个<code>volatile</code>变量的写操作先行发生于后面对这个变量的读操作,这里的“后面”同样是指时间上的先后。</li><li>线程启动规则(Thread Start Rule):<code>Thread</code>对象的<code>start()</code>方法先行发生于此线程的每一个动作。</li><li>线程终止规则(Thread Termination Rule):线程中的所有操作都先行发生于对此线程的终止检测,我们可以通过<code>Thread::join()</code>方法是否结束、<code>Thread::isAlive()</code>的返回值等手段检测线程是否已经终止执行。</li><li>线程中断规则(Thread Interruption Rule):对线程<code>interrupt()</code>方法的调用先行发生于被中断线程的代码检测到中断事件的发生,可以通过<code>Thread::interrupted()</code>方法检测到是否有中断发生。</li><li>对象终结规则(Finalizer Rule):一个对象的初始化完成(构造函数执行结束)先行发生于它的<code>finalize()</code>方法的开始。</li><li>传递性(Transitivity):如果操作A先行发生于操作B,操作B先行发生于操作C,那就可以得出操作A先行发生于操作C的结论。</li></ul><p>Java语言无须任何同步手段保障就能成立的先行发生规则有且只有上面这些,下面演示一下如何使用这些规则去判定操作间是否具备顺序性,对于读写共享变量的操作来说,就是线程是否安全。还可以从下面这个例子中感受一下“时间上的先后顺序”与“先<strong>行</strong>发生”之间有什么不同。</p><pre class="line-numbers language-language-java"><code class="language-language-java">    private int value = 0;    public void setValue(int value) {        this.value = value;    }    public int getValue() {        return value;    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>显示的是一组再普通不过的getter/setter方法,假设存在线程A和B,线程A先(时间上的先后)调用了<code>setValue(1)</code>,然后线程B调用了同一个对象的<code>getValue()</code>,那么线程B收到的返回值是什么? 我们依次分析一下先行发生原则中的各项规则。由于两个方法分别由线程A和B调用,不在一个线程中,所以程序次序规则在这里不适用;由于没有同步块,自然就不会发生lock和unlock操作,所以管程锁定规则不适用;由于<code>value</code>变量没有被<code>volatile</code>关键字修饰,所以<code>volatile</code>变量规则不适用;后面的线程启动、终止、中断规则和对象终结规则也和这里完全没有关系。因为没有一个适用的先行发生规则,所以最后一条传递性也无从谈起,因此我们可以判定,尽管线程A在操作时间上先于线程B,但是无法确定线程B中<code>getValue()</code>方法的返回结果,换句话说,这里面的操作不是线程安全的。</p><p>那怎么修复这个问题呢?我们至少有两种比较简单的方案可以选择:要么把getter/setter方法都定义为<code>synchronized</code>方法,这样就可以套用管程锁定规则;要么把value定义为<code>volatile</code>变量,由于setter方法对value的修改不依赖<code>value</code>的原值,满足<code>volatile</code>关键字使用场景,这样就可以套用<code>volatile</code>变量规则来实现先行发生关系。</p><p>通过上面的例子,我们可以得出结论:一个操作“时间上的先发生”不代表这个操作会是“先<strong>行</strong>发生”。那如果一个操作“先行发生”,是否就能推导出这个操作必定是“时间上的先发生”呢?很遗憾,这个推论也是不成立的。一个典型的例子就是多次提到的“指令重排序”：</p><pre class="line-numbers language-language-java"><code class="language-language-java">// 以下操作在同一个线程中执行int i = 1; int j = 2;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>如上所示的两条赋值语句在同一个线程之中,根据程序次序规则,<code>int i=1</code>的操作先行发生于<code>int j=2</code>,但是<code>int j=2</code>的代码完全可能先被处理器执行,这并不影响先行发生原则的正确性, <strong>因为我们在这条线程之中没有办法感知到这一点</strong>。</p><p>上面两个例子综合起来证明了一个结论:<strong>时间先后顺序与先行发生原则之间基本没有因果关系</strong>, 所以我们衡量并发安全问题的时候不要受时间顺序的干扰,<strong>一切必须以先行发生原则为准</strong>。</p><h2 id="Java与线程"><a class="header-anchor" href="#Java与线程">¶</a>Java与线程</h2><p>并发不一定要依赖多线程(如PHP中很常见的多进程并发),但是在Java里面谈论并发,基本上都与线程脱不开关系。</p><h3 id="线程的实现"><a class="header-anchor" href="#线程的实现">¶</a>线程的实现</h3><p>我们知道,线程是比进程更轻量级的调度执行单位,线程的引入,可以把一个进程的资源分配和执行调度分开,各个线程既可以共享进程资源(内存地址、文件I/O等),又可以独立调度。目前线程是Java里面进行处理器资源调度的最基本单位,不过如果日后Loom项目能成功为Java引入纤程(Fiber)的话,可能就会改变这一点。</p><p>主流的操作系统都提供了线程实现,Java语言则提供了在不同硬件和操作系统平台下对线程操作的统一处理,每个已经调用过<code>start()</code>方法且还未结束的<code>java.lang.Thread</code>类的实例就代表着一个线程。我们注意到<code>Thread</code>类与大部分的Java类库API有着显著差别,它的所有关键方法都被声明为<code>Native</code>。在Java类库API中,一个<code>Native</code>方法往往就意味着这个方法没有使用或无法使用平台无关的手段来实现(当然也可能是为了执行效率而使用<code>Native</code>方法,不过通常最高效率的手段也就是平台相关的手段)。正因为这个原因,本节的标题被定为“线程的实现”而不是“Java线程的实现”,在稍后介绍的实现方式中,我们也先把Java的技术背景放下,以一个通用的应用程序的角度来看看线程是如何实现的。</p><p>实现线程主要有三种方式:使用内核线程实现(1:1实现),使用用户线程实现(1:N实现), 使用用户线程加轻量级进程混合实现(N:M实现)。</p><h4 id="1-内核线程实现"><a class="header-anchor" href="#1-内核线程实现">¶</a>1.内核线程实现</h4><p>使用内核线程实现的方式也被称为1:1实现。内核线程(Kernel-Level Thread,KLT)就是直接由操作系统内核(Kernel,下称内核)支持的线程,这种线程由内核来完成线程切换,内核通过操纵调度器(Scheduler)对线程进行调度,并负责将线程的任务映射到各个处理器上。每个内核线程可以视为内核的一个分身,这样操作系统就有能力同时处理多件事情,支持多线程的内核就称为多线程内核(Multi-Threads Kernel)。<br>程序一般不会直接使用内核线程,而是使用内核线程的一种高级接口——<strong>轻量级进程</strong>(Light Weight Process,LWP),轻量级进程就是我们通常意义上所讲的线程,由于每个轻量级进程都由一个内核线程支持,因此只有先支持内核线程,才能有轻量级进程。这种轻量级进程与内核线程之间1:1 的关系称为一对一的线程模型</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000546.png" alt="image-20200923212114160"></p><p>由于内核线程的支持,每个轻量级进程都成为一个独立的调度单元,即使其中某一个轻量级进程在系统调用中被阻塞了,也不会影响整个进程继续工作。轻量级进程也具有它的局限性:</p><ul><li>首先,由于是基于内核线程实现的,所以各种线程操作,如创建、析构及同步,都需要进行系统调用。而系统调用的代价相对较高,需要在用户态(User Mode)和内核态(Kernel Mode)中来回切换。</li><li>其次,每个轻量级进程都需要有一个内核线程的支持,因此轻量级进程要消耗一定的内核资源(如内核线程的栈空间),因此一个系统支持轻量级进程的数量是有限的。</li></ul><blockquote><p>所谓轻量级进程指的应该就是内核线程的用户态线程实现(该轻量级进程的所有的资源还是由操作系统创建出来的，但是用户态下用户是可以拥有这些资源的绝大多数权限)，一个线程的具体体现就是它所占据的资源，如栈空间以及占用的CPU时间片。内核线程和用户态线程(轻量级进程)虽然是一对一的，通常对于上层业务来说它们是无区别的，但是对底层系统来说它们却是有区别的，它们分别占用了一定的内存空间作为它们的栈、并且是需要占用一定CPU时间的、涉及到线程切换也增加了CPU时间消耗</p></blockquote><h4 id="2-用户线程实现"><a class="header-anchor" href="#2-用户线程实现">¶</a>2.用户线程实现</h4><p>使用用户线程实现的方式被称为1:N实现。广义上来讲,一个线程只要不是内核线程,都可以认为是用户线程(User Thread,UT)的一种,因此从这个定义上看,轻量级进程也属于用户线程,但轻量级进程的实现始终是建立在内核之上的,许多操作都要进行系统调用,因此效率会受到限制,并不具备通常意义上的用户线程的优点。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000552.png" alt="image-20200923211921391"></p><p>而狭义上的用户线程指的是完全建立在用户空间的线程库上,<strong>系统内核不能感知到用户线程的存在及如何实现的</strong>。用户线程的建立、同步、销毁和调度完全在用户态中完成,不需要内核的帮助。如果程序实现得当,这种线程不需要切换到内核态,因此操作可以是非常快速且低消耗的,也能够支持规模更大的线程数量,部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间1:N的关系称为一对多的线程模型。</p><p>用户线程的优势在于不需要系统内核支援,<strong>劣势也在于没有系统内核的支援</strong>,所有的线程操作都需要由用户程序自己去处理。线程的创建、销毁、切换和调度都是用户必须考虑的问题,而且由于操作系统只把处理器资源分配到进程,那诸如“阻塞如何处理”“多处理器系统中如何将线程映射到其他处理器上”这类问题解决起来将会异常困难,甚至有些是不可能实现的。因为使用用户线程实现的程序通常都比较复杂<sup class="footnote-ref"><a href="#fn3" id="fnref3:1">[3:1]</a></sup>,除了有明确的需求外(譬如以前在不支持多线程的操作系统中的多线程程序、需要支持大规模线程数量的应用),一般的应用程序都不倾向使用用户线程。Java、Ruby等语言都曾经使用过用户线程,最终又都放弃了使用它。但是近年来许多新的、以高并发为卖点的编程语言又普遍支持了用户线程,譬如Golang、Erlang等,使得用户线程的使用率有所回升。</p><h4 id="3-混合实现"><a class="header-anchor" href="#3-混合实现">¶</a>3.混合实现</h4><p>线程除了依赖内核线程实现和完全由用户程序自己实现之外,还有一种将内核线程与用户线程一起使用的实现方式,被称为N:M实现。在这种混合实现下,既存在用户线程,也存在轻量级进程。</p><p>用户线程还是完全建立在用户空间中,因此用户线程的创建、切换、析构等操作依然廉价,并且可以支持大规模的用户线程并发。而操作系统支持的轻量级进程则作为用户线程和内核线程之间的桥梁, 这样可以使用内核提供的线程调度功能及处理器映射,并且用户线程的系统调用要通过轻量级进程来完成,这大大降低了整个进程被完全阻塞的风险。在这种混合模式中,用户线程与轻量级进程的数量比是不定的,是N:M的关系</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000559.png" alt="image-20200923212501118"></p><p>许多UNIX系列的操作系统,如Solaris、HP-UX等都提供了M:N的线程模型实现。在这些操作系统上的应用也相对更容易应用M:N的线程模型。</p><h4 id="4-Java线程的实现"><a class="header-anchor" href="#4-Java线程的实现">¶</a>4.Java线程的实现</h4><p>Java线程如何实现并不受Java虚拟机规范的约束,这是一个与具体虚拟机相关的话题。Java线程在早期的Classic虚拟机上(JDK 1.2以前),是基于一种被称为“绿色线程”(Green Threads)的用户线程实现的,但从JDK 1.3起,“主流”平台上的“主流”商用Java虚拟机的线程模型普遍都被替换为基于操作系统原生线程模型来实现,即采用1:1的线程模型。</p><p>以HotSpot为例,它的每一个Java线程都是直接映射到一个操作系统原生线程来实现的,而且中间没有额外的间接结构,所以HotSpot自己是不会去干涉线程调度的(可以设置线程优先级给操作系统提供调度建议),全权交给底下的操作系统去处理,所以何时冻结或唤醒线程、该给线程分配多少处理器执行时间、该把线程安排给哪个处理器核心去执行等,都是由操作系统完成的,也都是由操作系统全权决定的。</p><p>前面强调是两个“主流”,那就说明肯定还有例外的情况,这里举两个比较著名的例子,一个是用于Java ME的CLDC HotSpot Implementation。它同时支持两种线程模型,默认使用1:N由用户线程实现的线程模型,所有Java线程都映射到一个内核线程上;不过它也可以使用另一种特殊的混合模型,Java线程仍然全部映射到一个内核线程上,但当Java线程要执行一个阻塞调用时,CLDC-HI会为该调用单独开一个内核线程,并且调度执行其他Java线程,等到那个阻塞调用完成之后再重新调度之前的Java线程继续执行。</p><p>另外一个例子是在Solaris平台的HotSpot虚拟机,由于操作系统的线程特性本来就可以同时支持1:1(通过Bound Threads或Alternate Libthread实现)及N:M(通过LWP/Thread Based Synchronization 实现)的线程模型,因此Solaris版的HotSpot也对应提供了两个平台专有的虚拟机参数,即<code>-XX: +UseLWPSynchronization</code>(默认值)和<code>-XX:+UseBoundThreads</code>来明确指定虚拟机使用哪种线程模型。</p><p>操作系统支持怎样的线程模型,在很大程度上会影响上面的Java虚拟机的线程是怎样映射的,这一点在不同的平台上很难达成一致,因此《Java虚拟机规范》中才不去限定Java线程需要使用哪种线程模型来实现。线程模型只对线程的并发规模和操作成本产生影响,对Java程序的编码和运行过程来说,这些差异都是完全透明的。</p><h3 id="Java线程调度"><a class="header-anchor" href="#Java线程调度">¶</a>Java线程调度</h3><p>线程调度是指系统为线程分配处理器使用权的过程,调度主要方式有两种,分别是协同式(Cooperative Threads-Scheduling)线程调度和抢占式(Preemptive Threads-Scheduling)线程调度。</p><ul><li><p>如果使用协同式调度的多线程系统,线程的执行时间由线程本身来控制,线程把自己的工作执行完了之后,要主动通知系统切换到另外一个线程上去。协同式多线程的最大好处是实现简单,而且由于线程要把自己的事情干完后才会进行线程切换,切换操作对线程自己是可知的,所以一般没有什么线程同步的问题。Lua语言中的“协同例程”就是这类实现。它的坏处也很明显:线程执行时间不可控制,甚至如果一个线程的代码编写有问题,一直不告知系统进行线程切换,那么程序就会一直阻塞在那里。很久以前的Windows 3.x系统就是使用协同式来实现多进程多任务的,那是相当不稳定的,只要有一个进程坚持不让出处理器执行时间,就可能会导致整个系统崩溃。</p></li><li><p>如果使用抢占式调度的多线程系统,那么每个线程将由系统来分配执行时间,线程的切换不由线程本身来决定。譬如在Java中,有<code>Thread::yield()</code>方法可以主动让出执行时间,但是如果想要主动获取执行时间,线程本身是没有什么办法的。在这种实现线程调度的方式下,线程的执行时间是系统可控的,也不会有一个线程导致整个进程甚至整个系统阻塞的问题。Java使用的线程调度方式就是抢占式调度。与前面所说的Windows 3.x的例子相对,在Windows 9x/NT内核中就是使用抢占式来实现多进程的,当一个进程出了问题,我们还可以使用任务管理器把这个进程杀掉,而不至于导致系统崩溃。</p></li></ul><p>虽然说Java线程调度是系统自动完成的,但是我们仍然可以“建议”操作系统给某些线程多分配一点执行时间,另外的一些线程则可以少分配一点——这项操作是通过设置线程优先级来完成的。<strong>Java 语言一共设置了10个级别的线程优先级</strong>(<code>Thread.MIN_PRIORITY</code>至<code>Thread.MAX_PRIORITY</code>)。在两个线程同时处于Ready状态时,优先级越高的线程越容易被系统选择执行。</p><p>不过,线程优先级并不是一项稳定的调节手段,很显然因为主流虚拟机上的Java线程是被映射到系统的原生线程上来实现的,所以线程调度最终还是由操作系统说了算。尽管现代的操作系统基本都提供线程优先级的概念,但是并不见得能与Java线程的优先级一一对应,如Solaris中线程有<code>2147483648(2的31次幂)</code>种优先级,但Windows中就只有七种优先级。如果操作系统的优先级比Java 线程优先级更多,那问题还比较好处理,中间留出一点空位就是了,但对于比Java线程优先级少的系统,就不得不出现几个线程优先级对应到同一个操作系统优先级的情况了。下面显示了Java线程优先级与Windows线程优先级之间的对应关系,Windows平台的虚拟机中使用了除<code>THREAD_PRIORITY_IDLE</code>之外的其余6种线程优先级,因此在Windows下设置线程优先级为1和2、3 和4、6和7、8和9的效果是完全相同的。</p><table><thead><tr><th>Java线程优先级</th><th>Windows线程优先级</th></tr></thead><tbody><tr><td>1 ( Thread.MIN_PRIORITY)</td><td>THREAD_PRORIY_LOWEST</td></tr><tr><td>2</td><td>THREAD_PRIORITY_LOWEST</td></tr><tr><td>3</td><td>THREAD_PRIORITY_BELOW_NORMAL</td></tr><tr><td>4</td><td>THREAD_PRIORITY_BELOW_NORMAL</td></tr><tr><td>5 (Thread.NORM_PRIORITY)</td><td>THREAD_PRIORITY_NORMAL</td></tr><tr><td>6</td><td>THREAD_PRIORITY_ABOVE_NORMAL</td></tr><tr><td>7</td><td>THREAD_PRIORITY_ABOVE_NORMAL</td></tr><tr><td>8</td><td>THREAD_PRORITY_HIGHEST</td></tr><tr><td>9</td><td>THREAD_PRORITY_HIGHEST</td></tr><tr><td>10</td><td>THREAD_PRIORITY_CRITICAL</td></tr></tbody></table><p>线程优先级并不是一项稳定的调节手段,这不仅仅体现在某些操作系统上不同的优先级实际会变得相同这一点上,还有其他情况让我们不能过于依赖线程优先级: 优先级可能会被系统自行改变,例如在Windows系统中存在一个叫“优先级推进器”的功能(Priority Boosting,当然它可以被关掉),大致作用是当系统发现一个线程被执行得特别频繁时,可能会越过线程优先级去为它分配执行时间,从而减少因为线程频繁切换而带来的性能损耗。因此,我们并不能在程序中通过优先级来完全准确判断一组状态都为Ready的线程将会先执行哪一个。</p><h3 id="状态转换"><a class="header-anchor" href="#状态转换">¶</a>状态转换</h3><p>Java语言定义了6种线程状态,在任意一个时间点中,一个线程只能有且只有其中的一种状态,并且可以通过特定的方法在不同状态之间转换。这6种状态分别是:</p><ul><li>新建(New):创建后尚未启动的线程处于这种状态。</li><li>运行(Runnable):包括操作系统线程状态中的Running和Ready,也就是处于此状态的线程有可能正在执行,也有可能正在等待着操作系统为它分配执行时间。</li><li>无限期等待(Waiting):处于这种状态的线程不会被分配处理器执行时间,它们要等待被其他线程显式唤醒。以下方法会让线程陷入无限期的等待状态:<ul><li>没有设置Timeout参数的<code>Object::wait()</code>方法;</li><li>没有设置Timeout参数的<code>Thread::join()</code>方法;</li><li><code>LockSupport::park()</code>方法。</li></ul></li><li>限期等待(Timed Waiting):处于这种状态的线程也不会被分配处理器执行时间,不过无须等待被其他线程显式唤醒,在一定时间之后它们会由系统自动唤醒。以下方法会让线程进入限期等待状态:<ul><li><code>Thread::sleep()</code>方法;</li><li>设置了Timeout参数的Object::wait()方法;</li><li>设置了Timeout参数的Thread::join()方法;</li><li>LockSupport::parkNanos()方法;</li><li>LockSupport::parkUntil()方法。</li></ul></li><li>阻塞(Blocked):线程被阻塞了,“阻塞状态”与“等待状态”的区别是“阻塞状态”在等待着获取到一个排它锁,这个事件将在另外一个线程放弃这个锁的时候发生;而“等待状态”则是在等待一段时间,或者唤醒动作的发生。在程序等待进入同步区域的时候,线程将进入这种状态。</li><li>结束(Terminated):已终止线程的线程状态,线程已经结束执行。</li></ul><p>上述6种状态在遇到特定事件发生的时候将会互相转换,它们的转换关系如下</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000606.png" alt="image-20200923213849273"></p><h3 id="JVM线程知识补充"><a class="header-anchor" href="#JVM线程知识补充">¶</a>JVM线程知识补充</h3><ul><li><p>线程是一个程序里的运行单元。JVM允许一个应用有多个线程并行的执行。</p></li><li><p>在Hotsport VM里，每个线程都与操作系统的本地线程直接映射。当一个Java线程准备好执行以后，此时一个操作系统的本地线程也同时创建。Java线程执行终止后，本地线程也会回收。</p></li><li><p>操作系统负责所有线程的安排调度到任何一个可用的CPU上。一旦本地线程初始化成功，它就会调用Java线程中的run()方法。</p></li><li><p>线程分为守护线程(参考下面的例子，主要作用是在某个抽象维度下维护程序的正常运行)和普通线程，所有普通线程终止后，程序退出(不会收到守护线程影响，而是会主动终止所有守护线程)。</p></li><li><p>如果你使用jconsole或者是任何一个调试工具，都能看到在后台有许多线程在运行。这些后台线程不包括调用main方法的main线程以及所有这个main线程自己创建的线程。这些主要的后台系统线程在Hotspot JVM里主要是以下几个：</p><ul><li>虚拟机线程：这种线程的操作是需要JVM达到安全点才会出现。这些操作必须在不同的线程中发生的原因是他们都需要JVM到达安全点，这样堆才不会变化。这种线程的执行类型包括&quot;Stop-The-World&quot;的垃圾收集，线程栈收集，线程挂起以及偏向锁撤销。</li><li>周期任务线程：这种线程是时间周期事件的出现（比如中断），他们一般用于周期性操作的调度执行。</li><li>GC线程：这种线程对在JVM里不同种类的垃圾收集行为提供了支持。</li><li>编译线程：这种线程在运行时会将字节码编译成本地代码。</li><li>信号调度线程：这种线程接收信号并发送给JVM，在它内部通过调用适当的方法进行处理。</li></ul></li></ul><h2 id="Java与协程"><a class="header-anchor" href="#Java与协程">¶</a>Java与协程</h2><p>在Java时代的早期,Java语言抽象出来隐藏了<strong>各种操作系统线程差异性的统一线程接口</strong>,这曾经是它区别于其他编程语言的一大优势。在此基础上,涌现过无数多线程的应用与框架,譬如在网页访问时,HTTP请求可以直接与Servlet API中的一条处理线程绑定在一起,以“一对一服务”的方式处理由浏览器发来的信息。语言与框架已经自动屏蔽了相当多同步和并发的复杂性,对于普通开发者而言,几乎不需要专门针对多线程进行学习训练就能完成一般的并发任务。时至今日,这种便捷的并发编程方式和同步的机制依然在有效地运作着,但是在某些场景下,却也已经显现出了疲态。</p><h3 id="内核线程的局限"><a class="header-anchor" href="#内核线程的局限">¶</a>内核线程的局限</h3><p>通过一个具体场景来解释目前Java线程面临的困境。今天对Web应用的服务要求,不论是在请求数量上还是在复杂度上,与十多年前相比已不可同日而语,这一方面是源于业务量的增长,另一方面来自于为了应对业务复杂化而不断进行的服务细分。现代B/S系统中一次对外部业务请求的响应,往往需要分布在不同机器上的大量服务共同协作来实现,这种服务细分的架构在减少单个服务复杂度、增加复用性的同时,也不可避免地增加了服务的数量,缩短了留给每个服务的响应时间。这要求每一个服务都必须在极短的时间内完成计算,这样组合多个服务的总耗时才不会太长;也要求每一个服务提供者都要能同时处理数量更庞大的请求,这样才不会出现请求由于某个服务被阻塞而出现等待。</p><p>Java目前的并发编程机制就与上述架构趋势产生了一些矛盾,1:1的内核线程模型是如今Java虚拟机线程实现的主流选择,但是这种映射到操作系统上的线程天然的缺陷是切换、调度成本高昂,系统能容纳的线程数量也很有限。以前处理一个请求可以允许花费很长时间在单体应用中,具有这种线程切换的成本也是无伤大雅的,但现在在每个请求本身的执行时间变得很短、数量变得很多的前提下, 用户线程切换的开销甚至可能会接近用于计算本身的开销,这就会造成严重的浪费。</p><p>传统的Java Web服务器的线程池的容量通常在几十个到两百之间,当程序员把数以百万计的请求往线程池里面灌时,系统即使能处理得过来,但其中的切换损耗也是相当可观的。现实的需求在迫使Java去研究新的解决方案,同大家又开始怀念以前绿色线程的种种好处,绿色线程已随着Classic虚拟机的消失而被尘封到历史之中,它还会有重现天日的一天吗?</p><h3 id="协程的复苏"><a class="header-anchor" href="#协程的复苏">¶</a>协程的复苏</h3><p>为什么内核线程调度切换起来成本就要更高? 内核线程的调度成本主要来自于用户态与核心态之间的状态转换,而这两种状态转换的开销主要来自于响应中断、保护和恢复执行现场的成本。请读者试想以下场景,假设发生了这样一次线程切换:</p><pre><code>线程A -&gt; 系统中断 -&gt; 线程B</code></pre><p>处理器要去执行线程A的程序代码时,并不是仅有代码程序就能跑得起来,程序是数据与代码的组合体,代码执行时还必须要有上下文数据的支撑。而这里说的“上下文”,以程序员的角度来看,是方法调用过程中的各种局部的变量与资源;以线程的角度来看,是方法的调用栈中存储的各类信息; 而以操作系统和硬件的角度来看,则是存储在内存、缓存和寄存器中的一个个具体数值。物理硬件的各种存储设备和寄存器是被操作系统内所有线程共享的资源,<strong>当中断发生,从线程A切换到线程B去执行之前,操作系统首先要把线程A的上下文数据妥善保管好,然后把寄存器、内存分页等恢复到线程B 挂起时候的状态,这样线程B被重新激活后才能仿佛从来没有被挂起过。这种保护和恢复现场的工作,免不了涉及一系列数据在各种寄存器、缓存中的来回拷贝,当然不可能是一种轻量级的操作</strong>。</p><p><strong>如果说内核线程的切换开销是来自于保护和恢复现场的成本,那如果改为采用用户线程,这部分开销就能够省略掉吗?答案是“不能”。但是,一旦把保护、恢复现场及调度的工作从操作系统交到程序员手上,那我们就可以打开脑洞,通过玩出很多新的花样来缩减这些开销。</strong><br>有一些古老的操作系统(譬如DOS)是单人单工作业形式的,天生就不支持多线程,自然也不会有多个调用栈这样的基础设施。而早在那样的蛮荒时代,就已经出现了今天被称为栈纠缠(Stack Twine)的、由用户自己模拟多线程、自己保护恢复现场的工作模式。其大致的原理是通过在内存里划出一片额外空间来模拟调用栈,只要其他“线程”中方法压栈、退栈时遵守规则,不破坏这片空间即可,这样多段代码执行时就会像相互缠绕着一样,非常形象。</p><p>到后来,操作系统开始提供多线程的支持,靠应用自己模拟多线程的做法自然是变少了许多,但也并没有完全消失,而是演化为用户线程继续存在。<strong>由于最初多数的用户线程是被设计成协同式调度(Cooperative Scheduling)的,所以它有了一个别名——“协程”(Coroutine)</strong>。<strong>又由于这时候的协程会完整地做调用栈的保护、恢复工作,所以今天也被称为“有栈协程”(Stackfull Coroutine)</strong>,<strong>起这样的名字是为了便于跟后来的“无栈协程”(Stackless Coroutine)区分开</strong>。无栈协程不是本节的主角,不过还是可以简单提一下它的典型应用,即各种语言中的<code>await</code>、<code>async</code>、<code>yield</code>这类关键字。<strong>无栈协程本质上是一种有限状态机,状态保存在闭包里,自然比有栈协程恢复调用栈要轻量得多,但功能也相对更有限</strong>。</p><p>协程的主要优势是轻量,无论是有栈协程还是无栈协程,都要比传统内核线程要轻量得多。如果进行量化的话,那么如果不显式设置<code>-Xss</code>或<code>-XX:ThreadStackSize</code>,则在64位Linux上HotSpot的线程栈容量默认是1MB,此外内核数据结构(Kernel Data Structures)还会额外消耗16KB内存。与之相对的,一个协程的栈通常在几百个字节到几KB之间,所以Java虚拟机里线程池容量达到两百就已经不算小了,而很多支持协程的应用中,同时并存的协程数量可数以十万计。</p><h3 id="缺点"><a class="header-anchor" href="#缺点">¶</a>缺点</h3><p>协程当然也有它的局限,需要在应用层面实现的内容(调用栈、调度器这些)特别多,这个缺点就不赘述了。除此之外,协程在最初,甚至在今天很多语言和框架中会被设计成协同式调度,这样在语言运行平台或者框架上的调度器就可以做得非常简单。不过有不少资料上显示,既然取了“协程”这样的名字,它们之间就一定以协同调度的方式工作。这种“规定”的出处没有经过查证,只能说这种提法在今天太过狭隘了,非协同式、可自定义调度的协程的例子并不少见。</p><p>具体到Java语言,还会有一些别的限制,譬如HotSpot这样的虚拟机,Java调用栈跟本地调用栈是做在一起的。如果在协程中调用了本地方法,还能否正常切换协程而不影响整个线程?另外,如果协程中遇传统的线程同步措施会怎样?譬如Kotlin提供的协程实现,一旦遭遇<code>synchronize</code>关键字,那挂起来的仍将是整个线程。</p><h3 id="Java的解决方案"><a class="header-anchor" href="#Java的解决方案">¶</a>Java的解决方案</h3><p>对于有栈协程,有一种特例实现名为纤程(Fiber),这个词最早是来自微软公司,后来微软还推出过系统层面的纤程包来方便应用做现场保存、恢复和纤程调度。OpenJDK在2018年创建了Loom项目,这是Java用来应对本节开篇所列场景的官方解决方案,根据目前公开的信息,如无意外,日后该项目为Java语言引入的、与现在线程模型平行的新并发编程机制中应该也会采用“纤程”这个名字,不过这显然跟微软是没有任何关系的。从Oracle官方对“什么是纤程”的解释里可以看出,它就是一种典型的有栈协程</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000614.png" alt="image-20200923215113676"></p><p>Loom项目背后的意图是重新提供对用户线程的支持,但与过去的绿色线程不同,这些新功能不是为了取代当前基于操作系统的线程实现,而是会有两个并发编程模型在Java虚拟机中并存,可以在程序中同时使用。新模型有意地保持了与目前线程模型相似的API设计,它们甚至可以拥有一个共同的基类,这样现有的代码就不需要为了使用纤程而进行过多改动,甚至不需要知道背后采用了哪个并发编程模型。Loom团队在JVMLS 2018大会上公布了他们对Jetty基于纤程改造后的测试结果,同样在5000QPS的压力下,以容量为400的线程池的传统模式和每个请求配以一个纤程的新并发处理模式进行对比,前者的请求响应延迟在10000至20000毫秒之间,而后者的延迟普遍在200毫秒以下,具体结果如图</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000620.png" alt="image-20200923215222185"></p><p>在新并发模型下,一段使用纤程并发的代码会被分为两部分——执行过程(Continuation)和调度器(Scheduler)。执行过程主要用于维护执行现场保护、恢复上下文状态,而调度器则负责编排所有要执行的代码的顺序。将调度程序与执行过程分离的好处是,用户可以选择自行控制其中的一个或者多个,而且Java中现有的调度器也可以被直接重用。事实上,Loom中默认的调度器就是原来已存在的用于任务分解的Fork/Join池(JDK 7中加入的<code>ForkJoinPool</code>)。</p><p>Loom项目目前仍然在进行当中,还没有明确的发布日期,上面提到的内容日后都有被改动的可能。如果现在就想尝试协程,那可以在项目中使用Quasar协程库,这是一个不依赖Java虚拟机的独立实现的协程库。不依赖虚拟机来实现协程是完全可能的,Kotlin语言的协程就已经证明了这一点。Quasar的实现原理是字节码注入,在字节码层面对当前被调用函数中的所有局部变量进行保存和恢复。这种不依赖Java虚拟机的现场保护虽然能够工作,但很影响性能,对即时编译器的干扰也非常大,而且必须要求用户手动标注每一个函数是否会在协程上下文被调用,这些都是未来Loom项目要解决的问题。</p><h1>线程安全与锁优化</h1><h2 id="线程安全"><a class="header-anchor" href="#线程安全">¶</a>线程安全</h2><p>《Java并发编程实战(Java Concurrency In Practice)》的作者Brian Goetz为“线程安全”做出了一个比较恰当的定义:“当多个线程同时访问一个对象时,如果不用考虑这些线程在运行时环境下的调度和交替执行,也不需要进行额外的同步,或者在调用方进行任何其他的协调操作,调用这个对象的行为都可以获得正确的结果,那就称这个对象是线程安全的。”</p><p>这个定义就很严谨而且有可操作性,它要求线程安全的代码都必须具备一个共同特征:<strong>代码本身封装了所有必要的正确性保障手段</strong>(如互斥同步等),令调用者无须关心多线程下的调用问题,更无须自己实现任何措施来保证多线程环境下的正确调用。这点听起来简单,但其实并不容易做到,在许多场景中,我们都会将这个定义弱化一些。如果把“调用这个对象的行为”限定为“单次调用”,这个定义的其他描述能够成立的话,那么就已经可以称它是线程安全了。</p><h3 id="Java语言中的线程安全"><a class="header-anchor" href="#Java语言中的线程安全">¶</a>Java语言中的线程安全</h3><p>我们已经有了线程安全的一个可操作的定义,那接下来就讨论一下:在Java语言中,线程安全具体是如何体现的?有哪些操作是线程安全的?我们这里讨论的线程安全,将以多个线程之间存在共享数据访问为前提。因为如果根本不存在多线程,又或者一段代码根本不会与其他线程共享数据,那么从线程安全的角度上看,程序是串行执行还是多线程执行对它来说是没有什么区别的。</p><p>为了更深入地理解线程安全,在这里我们可以不把线程安全当作一个非真即假的二元排他选项来看待,而是按照线程安全的“安全程度”由强至弱来排序,可以将Java语言中各种操作共享的数据分为以下五类:<strong>不可变、绝对线程安全、相对线程安全、线程兼容和线程对立</strong>。</p><h4 id="1-不可变"><a class="header-anchor" href="#1-不可变">¶</a>1.不可变</h4><p>在Java语言里面(特指JDK 5以后,即Java内存模型被修正之后的Java语言),不可变(Immutable)的对象一定是线程安全的,无论是对象的方法实现还是方法的调用者,都不需要再进行任何线程安全保障措施。“final关键字带来的可见性”:只要一个不可变的对象被正确地构建出来(即没有发生<code>this</code>引用逃逸的情况),那其外部的可见状态永远都不会改变,永远都不会看到它在多个线程之中处于不一致的状态。“不可变”带来的安全性是最直接、最纯粹的。</p><p>Java语言中,如果多线程共享的数据是一个基本数据类型,那么只要在定义时使用<code>final</code>关键字修饰它就可以保证它是不可变的。如果共享数据是一个对象,由于Java语言目前暂时还没有提供值类型的支持,那就需要对象自行保证其行为不会对其状态产生任何影响才行。类比<code>java.lang.String</code>类的对象实例,它是一个典型的不可变对象,用户调用它的<code>substring()</code>、<code>replace()</code>和<code>concat()</code>这些方法都不会影响它原来的值,只会返回一个新构造的字符串对象。</p><p>保证对象行为不影响自己状态的途径有很多种,最简单的一种就是把对象里面带有状态的变量都声明为<code>final</code>,这样在构造函数结束之后,它就是不可变的,如下所示的<code>java.lang.Integer</code> 构造函数,它通过将内部状态变量<code>value</code>定义为<code>final</code>来保障状态不变。</p><pre class="line-numbers language-language-java"><code class="language-language-java">    /**     * The value of the {@code Integer}.     *     * @serial     */    private final int value;    /**     * Constructs a newly allocated {@code Integer} object that     * represents the specified {@code int} value.     *     * @param   value   the value to be represented by the     *                  {@code Integer} object.     */    public Integer(int value) {        this.value = value;    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在Java类库API中符合不可变要求的类型,除了上面提到的<code>String</code>之外,常用的还有枚举类型及<code>java.lang.Number</code>的部分子类,如<code>Long</code>和<code>Double</code>等数值包装类型、<code>BigInteger</code>和<code>BigDecimal</code>等大数据类型。</p><p>但同为<code>Number</code>子类型的原子类<code>AtomicInteger</code>和<code>AtomicLong</code>则是可变的。</p><h4 id="2-绝对线程安全"><a class="header-anchor" href="#2-绝对线程安全">¶</a>2.绝对线程安全</h4><p>绝对的线程安全能够完全满足Brian Goetz给出的线程安全的定义,这个定义其实是很严格的,一个类要达到“不管运行时环境如何,调用者都不需要任何额外的同步措施”可能需要付出非常高昂的, 甚至不切实际的代价。在Java API中标注自己是线程安全的类,大多数都不是绝对的线程安全。我们可以通过Java API中一个不是“绝对线程安全”的“线程安全类型”来看看这个语境里的“绝对”究竟是什么意思。<br>如果说<code>java.util.Vector</code>是一个线程安全的容器,相信所有的Java程序员对此都不会有异议,因为它的<code>add()</code>、<code>get()</code>和<code>size()</code>等方法都是被<code>synchronized</code>修饰的,尽管这样效率不高,但保证了具备原子性、可见性和有序性。不过,即使它所有的方法都被修饰成<code>synchronized</code>,也不意味着调用它的时候就永远都不再需要同步手段了：</p><pre class="line-numbers language-language-java"><code class="language-language-java">package john;import java.util.Vector;public class TestVector {    private static Vector<Integer> vector = new Vector<Integer>();    public static void main(String[] args) {        while (true) {            for (int i = 0; i < 10; i++) {                vector.add(i);            }            Thread removeThread = new Thread(new Runnable() {                @Override                public void run() {                    for (int i = 0; i < vector.size(); i++) {                        vector.remove(i);                    }                }            });            Thread printThread = new Thread(new Runnable() {                @Override                public void run() {                    for (int i = 0; i < vector.size(); i++) {                        System.out.println((vector.get(i)));                    }                }            });            removeThread.start();            printThread.start();                     //不要同时产生过多的线程,否则会导致操作系统假死            while (Thread.activeCount() > 20) {                ;            }        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>会遇到以下输出</p><pre><code>Exception in thread &quot;Thread-81127&quot; java.lang.ArrayIndexOutOfBoundsException: Array index out of range: 15at java.util.Vector.get(Vector.java:751)at john.TestVector$2.run(TestVector.java:30)at java.lang.Thread.run(Thread.java:748)Exception in thread &quot;Thread-81375&quot; java.lang.ArrayIndexOutOfBoundsException: Array index out of range: 14</code></pre><p>很明显,尽管这里使用到的<code>Vector</code>的<code>get()</code>、<code>remove()</code>和<code>size()</code>方法都是同步的,但是在多线程的环境中,如果不在方法调用端做额外的同步措施,使用这段代码仍然是不安全的。因为如果另一个线程恰好在错误的时间里删除了一个元素,导致序号i已经不再可用,再用i访问数组就会抛出一个<code>ArrayIndexOutOfBoundsException</code>异常。如果要保证这段代码能正确执行下去,我们不得不把<code>removeThread</code>和<code>printThread</code>的定义进行修改</p><pre class="line-numbers language-language-java"><code class="language-language-java">            Thread removeThread = new Thread(new Runnable() {                @Override                public void run() {                    synchronized (vector) {                        for (int i = 0; i < vector.size(); i++) {                            vector.remove(i);                        }                    }                }            });            Thread printThread = new Thread(new Runnable() {                @Override                public void run() {                    synchronized (vector) {                        for (int i = 0; i < vector.size(); i++) {                            System.out.println((vector.get(i)));                        }                    }                }            });<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>假如<code>Vector</code>一定要做到绝对的线程安全,那就必须在它内部维护一组一致性的快照访问才行,每次对其中元素进行改动都要产生新的快照,这样要付出的时间和空间成本都是非常大的。</p><h4 id="3-相对线程安全"><a class="header-anchor" href="#3-相对线程安全">¶</a>3.相对线程安全</h4><p>相对线程安全就是我们通常意义上所讲的线程安全,它需要保证对这个对象单次的操作是线程安全的,我们在调用的时候不需要进行额外的保障措施,但是对于一些特定顺序的连续调用,就可能需要在调用端使用额外的同步手段来保证调用的正确性。上面的代码就是相对线程安全的案例。</p><p>在Java语言中,大部分声称线程安全的类都属于这种类型,例如<code>Vector</code>、<code>HashTable</code>、<code>Collections</code>的<code>synchronizedCollection()</code>方法包装的集合等。</p><h4 id="4-线程兼容"><a class="header-anchor" href="#4-线程兼容">¶</a>4.线程兼容</h4><p>**线程兼容是指对象本身并不是线程安全的,但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用。**我们平常说一个类不是线程安全的,通常就是指这种情况。Java类库API中大部分的类都是线程兼容的,如与前面的<code>Vector</code>和<code>HashTable</code>相对应的集合类<code>ArrayList</code>和<code>HashMap</code>等。</p><h4 id="5-线程对立"><a class="header-anchor" href="#5-线程对立">¶</a>5.线程对立</h4><p><strong>线程对立是指不管调用端是否采取了同步措施,都无法在多线程环境中并发使用代码</strong>。由于Java 语言天生就支持多线程的特性,线程对立这种排斥多线程的代码是很少出现的,而且通常都是有害的,应当尽量避免。</p><p>一个线程对立的例子是<code>Thread</code>类的<code>suspend()</code>和<code>resume()</code>方法。如果有两个线程同时持有一个线程对象,一个尝试去中断线程,一个尝试去恢复线程,在并发进行的情况下,无论调用时是否进行了同步,目标线程都存在死锁风险——假如<code>suspend()</code>中断的线程就是即将要执行<code>resume()</code>的那个线程,那就肯定要产生死锁了。也正是这个原因,<code>suspend()</code>和<code>resume()</code>方法都已经被声明废弃了。常见的线程对立的操作还有<code>System.setIn()</code>、<code>Sytem.setOut()</code>和<code>System.runFinalizersOnExit()</code>等。</p><h3 id="线程安全的实现方法"><a class="header-anchor" href="#线程安全的实现方法">¶</a>线程安全的实现方法</h3><h4 id="1-互斥同步"><a class="header-anchor" href="#1-互斥同步">¶</a>1.互斥同步</h4><p>互斥同步(Mutual Exclusion &amp; Synchronization)是一种最常见也是最主要的并发正确性保障手段。同步是指在多个线程并发访问共享数据时,保证共享数据在同一个时刻只被一条(或者是一些, 当使用信号量的时候)线程使用。而互斥是实现同步的一种手段,**临界区(Critical Section)、互斥量(Mutex)和信号量(Semaphore)**都是常见的互斥实现方式。因此在“互斥同步”这四个字里面,互斥是因,同步是果;互斥是方法,同步是目的。</p><p>在Java里面,最基本的互斥同步手段就是<code>synchronized</code>关键字,这是一种块结构(Block Structured)的同步语法。<code>synchronized</code>关键字经过Javac编译之后,会在同步块的前后分别形成<code>monitorenter</code>和<code>monitorexit</code>这两个字节码指令。这两个字节码指令都需要一个<code>reference</code>类型的参数来指明要锁定和解锁的对象。如果Java源码中的<code>synchronized</code>明确指定了对象参数,那就以这个对象的引用作为<code>reference</code>;如果没有明确指定,那将根据<code>synchronized</code>修饰的方法类型(如实例方法或类方法),来决定是取代码所在的对象实例还是取类型对应的Class对象来作为线程要持有的锁。</p><p>根据《Java虚拟机规范》的要求,在执行<code>monitorenter</code>指令时,首先要去尝试获取对象的锁。如果这个对象没被锁定,或者当前线程已经持有了那个对象的锁,就把锁的计数器的值增加一,而在执行<code>monitorexit</code>指令时会将锁计数器的值减一。一旦计数器的值为零,锁随即就被释放了。如果获取对象锁失败,那当前线程就应当被阻塞等待,直到请求锁定的对象被持有它的线程释放为止。</p><p>从功能上看,根据以上《Java虚拟机规范》对<code>monitorenter</code>和<code>monitorexit</code>的行为描述,我们可以得出两个关于<code>synchronized</code>的直接推论,这是使用它时需特别注意的:</p><ul><li>被<code>synchronized</code>修饰的同步块对同一条线程来说是可重入的。这意味着同一线程反复进入同步块也不会出现自己把自己锁死的情况。</li><li>被<code>synchronized</code>修饰的同步块在持有锁的线程执行完毕并释放锁之前,会无条件地阻塞后面其他线程的进入。这意味着无法像处理某些数据库中的锁那样,强制已获取锁的线程释放锁;也无法强制正在等待锁的线程中断等待或超时退出。</li></ul><p>从执行成本的角度看,持有锁是一个重量级(Heavy-Weight)的操作。Java的线程是映射到操作系统的原生内核线程之上的,如果要阻塞或唤醒一条线程,则需要操作系统来帮忙完成,这就不可避免地陷入用户态到核心态的转换中,进行这种状态转换需要耗费很多的处理器时间。尤其是对于代码特别简单的同步块(譬如被<code>synchronized</code>修饰的<code>getter()</code> 或<code>setter()</code>方法),状态转换消耗的时间甚至会比用户代码本身执行的时间还要长。因此才说,<code>synchronized</code>是Java语言中一个重量级的操作,有经验的程序员都只会在确实必要的情况下才使用这种操作。而虚拟机本身也会进行一些优化,<strong>譬如在通知操作系统阻塞线程之前加入一段自旋等待过程, 以避免频繁地切入核心态之中</strong>。</p><p>从上面的介绍中我们可以看到<code>synchronized</code>的局限性,除了<code>synchronized</code>关键字以外,自JDK 5起(实现了JSR 166<sup class="footnote-ref"><a href="#fn3" id="fnref3:2">[3:2]</a></sup>),Java类库中新提供了<code>java.util.concurrent</code>包(下文称J.U.C包),其中的<code>java.util.concurrent.locks.Lock</code>接口便成了Java的另一种全新的互斥同步手段。基于<code>Lock</code>接口,用户能够以非块结构(Non-Block Structured)来实现互斥同步,从而摆脱了语言特性的束缚,改为在类库层面去实现同步,这也为日后扩展出不同调度算法、不同特征、不同性能、不同语义的各种锁提供了广阔的空间。</p><p>重入锁(ReentrantLock)是<code>Lock</code>接口最常见的一种实现<sup class="footnote-ref"><a href="#fn4" id="fnref4:1">[4:1]</a></sup>,顾名思义,它与<code>synchronized</code>一样是可重入<sup class="footnote-ref"><a href="#fn5" id="fnref5:1">[5:1]</a></sup>的。在基本用法上,<code>ReentrantLock</code>也与<code>synchronized</code>很相似,只是代码写法上稍有区别而已。不过,<code>ReentrantLock</code>与<code>synchronized</code>相比增加了一些高级功能,主要有以下三项:<strong>等待可中断、可实现公平锁及锁可以绑定多个条件</strong>。</p><ul><li>等待可中断:是指当持有锁的线程长期不释放锁的时候,正在等待的线程可以选择放弃等待,改为处理其他事情。可中断特性对处理执行时间非常长的同步块很有帮助。</li><li><strong>公平锁:是指多个线程在等待同一个锁时,必须按照申请锁的时间顺序来依次获得锁;而非公平锁则不保证这一点,在锁被释放时,任何一个等待锁的线程都有机会获得锁。</strong><code>synchronized</code>中的锁是非公平的,<code>ReentrantLock</code>在默认情况下也是非公平的,但可以通过带布尔值的构造函数要求使用公平锁。不过一旦使用了公平锁,将会导致<code>ReentrantLock</code>的性能急剧下降,会明显影响吞吐量。</li><li>锁绑定多个条件:是指一个<code>ReentrantLock</code>对象可以同时绑定多个<code>Condition</code>对象。在<code>synchronized</code> 中,锁对象的<code>wait()</code>跟它的<code>notify()</code>或者<code>notifyAll()</code>方法配合可以实现一个隐含的条件,如果要和多于一个的条件关联的时候,就不得不额外添加一个锁;而<code>ReentrantLock</code>则无须这样做,多次调用<code>newCondition()</code>方法即可。</li></ul><p>如果需要使用上述功能,使用<code>ReentrantLock</code>是一个很好的选择,那如果是基于性能考虑呢? <code>synchronized</code>对性能的影响,尤其在JDK 5之前是很显著的,为此在JDK 6中还专门进行过针对性的优化。以<code>synchronized</code>和<code>ReentrantLock</code>的性能对比为例,Brian Goetz对这两种锁在<strong>JDK 5</strong>、单核处理器及双Xeon处理器环境下做了一组吞吐量对比的实验</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000632.png" alt="image-20200923222946804"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000638.png" alt="image-20200923223011124"></p><p>可以看出,多线程环境下<code>synchronized</code>的吞吐量下降得非常严重,而<code>ReentrantLock</code>则能基本保持在同一个相对稳定的水平上。但与其说<code>ReentrantLock</code>性能好,倒不如说当时的<code>synchronized</code>有非常大的优化余地,后续的技术发展也证明了这一点。当JDK 6中加入了大量针对<code>synchronized</code>锁的优化措施之后,相同的测试中就发现<code>synchronized</code>与<code>ReentrantLock</code>的性能基本上能够持平。相信现在所开发的程序应该都是使用JDK 6或以上版本来部署的,所以性能已经不再是选择<code>synchronized</code>或者<code>ReentrantLock</code>的决定因素。</p><p>根据上面的讨论,<code>ReentrantLock</code>在功能上是<code>synchronized</code>的超集,在性能上又至少不会弱于<code>synchronized</code>,那<code>synchronized</code>修饰符是否应该被直接抛弃,不再使用了呢?当然不是,基于以下理由,仍然推荐在<code>synchronized</code>与<code>ReentrantLock</code>都可满足需要时优先使用<code>synchronized</code>:</p><ul><li><code>synchronized</code>是在Java语法层面的同步,足够清晰,也足够简单。每个Java程序员都熟悉<code>synchronized</code>,但J.U.C中的<code>Lock</code>接口则并非如此。因此在只需要基础的同步功能时,更推荐<code>synchronized</code>。</li><li><code>Lock</code>应该确保在<code>finally</code>块中释放锁,否则一旦受同步保护的代码块中抛出异常,则有可能永远不会释放持有的锁。这一点必须由程序员自己来保证,而使用<code>synchronized</code>的话则可以由Java虚拟机来确保即使出现异常,锁也能被自动释放。</li><li>尽管在JDK 5时代<code>ReentrantLock</code>曾经在性能上领先过<code>synchronized</code>,但这已经是十多年之前的胜利了。从长远来看,Java虚拟机更容易针对<code>synchronized</code>来进行优化,因为Java虚拟机可以在<strong>线程和对象的元数据中记录</strong><code>synchronized</code>中锁的相关信息,而使用J.U.C中的Lock的话,Java虚拟机是很难得知具体哪些锁对象是由特定线程锁持有的。</li></ul><h4 id="2-非阻塞同步"><a class="header-anchor" href="#2-非阻塞同步">¶</a>2.非阻塞同步</h4><p>互斥同步面临的主要问题是进行线程阻塞和唤醒所带来的性能开销,因此这种同步也被称为阻塞同步(Blocking Synchronization)。从解决问题的方式上看,互斥同步属于一种悲观的并发策略,其总是认为只要不去做正确的同步措施(例如加锁),那就肯定会出现问题,无论共享的数据是否真的会出现竞争,它都会进行加锁(这里讨论的是概念模型,实际上虚拟机会优化掉很大一部分不必要的加锁),这将会导致用户态到核心态转换、维护锁计数器和检查是否有被阻塞的线程需要被唤醒等开销。随着硬件指令集的发展,我们已经有了另外一个选择:基于冲突检测的乐观并发策略,通俗地说就是不管风险,先进行操作,如果没有其他线程争用共享数据,那操作就直接成功了;如果共享的数据的确被争用,产生了冲突,那再进行其他的补偿措施,最常用的补偿措施是不断地重试,直到出现没有竞争的共享数据为止。这种乐观并发策略的实现不再需要把线程阻塞挂起,因此这种同步操作被称为非阻塞同步(Non-Blocking Synchronization),使用这种措施的代码也常被称为无锁(Lock-Free) 编程。</p><p>为什么说使用乐观并发策略需要“硬件指令集的发展”?因为我们必须要求操作和冲突检测这两个步骤具备原子性。靠什么来保证原子性?如果这里再使用互斥同步来保证就完全失去意义了,所以我们只能靠硬件来实现这件事情,硬件保证某些从语义上看起来需要多次操作的行为可以只通过一条处理器指令就能完成,这类指令常用的有:</p><ul><li>测试并设置(Test-and-Set);</li><li>获取并增加(Fetch-and-Increment);</li><li>交换(Swap);</li><li>比较并交换(Compare-and-Swap,下文称CAS);</li><li>加载链接/条件储存(Load-Linked/Store-Conditional,下文称LL/SC)。</li></ul><p>其中,前面的三条是20世纪就已经存在于大多数指令集之中的处理器指令,后面的两条是现代处理器新增的,而且这两条指令的目的和功能也是类似的。在IA64、x86指令集中有用<code>cmpxchg</code>指令完成的CAS功能,在SPARC-TSO中也有用casa指令实现的,而在ARM和PowerPC架构下,则需要使用一对<code>ldrex/strex</code>指令来完成LL/SC的功能。因为Java里最终暴露出来的是CAS操作,所以我们以CAS指令为例进行讲解。</p><p>CAS指令需要有三个操作数,分别是内存位置(在Java中可以简单地理解为变量的内存地址,用V 表示)、旧的预期值(用A表示)和准备设置的新值(用B表示)。CAS指令执行时,当且仅当V符合A时,处理器才会用B更新V的值,否则它就不执行更新。但是,不管是否更新了V的值,都会返回V的旧值,上述的处理过程是一个原子操作,执行期间不会被其他线程中断。</p><p>在JDK 5之后,Java类库中才开始使用CAS操作,该操作由<code>sun.misc.Unsafe</code>类里面的<code>compareAndSwapInt()</code>和<code>compareAndSwapLong()</code>等几个方法包装提供。HotSpot虚拟机在内部对这些方法做了特殊处理,即时编译出来的结果就是一条平台相关的处理器CAS指令,没有方法调用的过程, 或者可以认为是无条件内联进去了<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>。不过由于<code>Unsafe</code>类在设计上就不是提供给用户程序调用的类(<code>Unsafe::getUnsafe()</code>的代码中限制了只有启动类加载器(Bootstrap ClassLoader)加载的Class才能访问它),因此在JDK 9之前只有Java类库可以使用CAS,譬如J.U.C包里面的整数原子类,其中的<code>compareAndSet()</code>和<code>getAndIncrement()</code>等方法都使用了<code>Unsafe</code>类的CAS操作来实现。而如果用户程序也有使用CAS操作的需求,那要么就采用反射手段突破<code>Unsafe</code>的访问限制,要么就只能通过Java类库API来间接使用它。直到JDK 9之后,Java类库才在<code>VarHandle</code>类里开放了面向用户程序使用的CAS操作。</p><p><code>incrementAndGet()</code>方法的JDK源码</p><pre class="line-numbers language-language-java"><code class="language-language-java">    /**     * Atomically increment by one the current value.     *     * @return the updated value     */    public final int incrementAndGet() {        for (; ; ) {            int current = get();            int next = current + 1;            if (compareAndSet(current, next)) {                return next;            }        }    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>incrementAndGet()</code>方法在一个无限循环中,不断尝试将一个比当前值大一的新值赋值给自己。如果失败了,那说明在执行CAS操作的时候,旧值已经发生改变,于是再次循环进行下一次操作,直到设置成功为止。</p><p>尽管CAS看起来很美好,既简单又高效,但显然这种操作无法涵盖互斥同步的所有使用场景,并且CAS从语义上来说并不是真正完美的,它存在一个逻辑漏洞:如果一个变量V初次读取的时候是A 值,并且在准备赋值的时候检查到它仍然为A值,那就能说明它的值没有被其他线程改变过了吗?这是不能的,因为如果在这段期间它的值曾经被改成B,后来又被改回为A,那CAS操作就会误认为它从来没有被改变过。这个漏洞称为CAS操作的“ABA问题”。J.U.C包为了解决这个问题,提供了一个带有标记的原子引用类<code>AtomicStampedReference</code>,它可以通过控制变量值的版本来保证CAS的正确性。不过目前来说这个类处于相当鸡肋的位置,大部分情况下ABA问题不会影响程序并发的正确性,如果需要解决ABA问题,改用传统的互斥同步可能会比原子类更为高效。</p><h4 id="3-无同步方案"><a class="header-anchor" href="#3-无同步方案">¶</a>3.无同步方案</h4><p>要保证线程安全,也并非一定要进行阻塞或非阻塞同步,同步与线程安全两者没有必然的联系。</p><p>同步只是保障存在共享数据争用时正确性的手段,如果能让一个方法本来就不涉及共享数据,那它自然就不需要任何同步措施去保证其正确性,因此会有一些代码天生就是线程安全的,笔者简单介绍其中的两类。</p><p>可重入代码(Reentrant Code):这种代码又称纯代码(Pure Code),是指可以在代码执行的任何时刻中断它,转而去执行另外一段代码(包括递归调用它本身),而在控制权返回后,原来的程序不会出现任何错误,也不会对结果有所影响。在特指多线程的上下文语境里(不涉及信号量等因素),我们可以认为可重入代码是线程安全代码的一个真子集,这意味着相对线程安全来说,可重入性是更为基础的特性,它可以保证代码线程安全,即所有可重入的代码都是线程安全的,但并非所有的线程安全的代码都是可重入的。</p><p>可重入代码有一些共同的特征,例如,不依赖全局变量、存储在堆上的数据和公用的系统资源, 用到的状态量都由参数中传入,不调用非可重入的方法等。我们可以通过一个比较简单的原则来判断代码是否具备可重入性:如果一个方法的返回结果是可以预测的,只要输入了相同的数据,就都能返回相同的结果,那它就满足可重入性的要求,当然也就是线程安全的。</p><p>线程本地存储(Thread Local Storage):如果一段代码中所需要的数据必须与其他代码共享,那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证,我们就可以把共享数据的可见范围限制在同一个线程之内,这样,无须同步也能保证线程之间不出现数据争用的问题。</p><p>符合这种特点的应用并不少见,大部分使用消费队列的架构模式(如“生产者-消费者”模式)都会将产品的消费过程限制在一个线程中消费完,其中最重要的一种应用实例就是经典Web交互模型中的“一个请求对应一个服务器线程”(Thread-per-Request)的处理方式,这种处理方式的广泛应用使得很多Web服务端应用都可以使用线程本地存储来解决线程安全问题。</p><p>Java语言中,如果一个变量要被多线程访问,可以使用<code>volatile</code>关键字将它声明为“易变的”;如果一个变量只要被某个线程独享,Java中就没有类似C++中<code>__declspec(thread)</code>这样的关键字去修饰,不过我们还是可以通过<code>java.lang.ThreadLocal</code>类来实现线程本地存储的功能。每一个线程的Thread对象中都有一个<code>ThreadLocalMap</code>对象,这个对象存储了一组以<code>ThreadLocal.threadLocalHashCode</code>为键,以本地线程变量为值的K-V值对,<code>ThreadLocal</code>对象就是当前线程的<code>ThreadLocalMap</code>的访问入口,每一个<code>ThreadLocal</code>对象都包含了一个独一无二的<code>threadLocalHashCode</code>值,使用这个值就可以在线程K-V值对中找回对应的本地线程变量。</p><h2 id="锁优化"><a class="header-anchor" href="#锁优化">¶</a>锁优化</h2><p>高效并发是从JDK 5升级到JDK 6后一项重要的改进项,HotSpot虚拟机开发团队在这个版本上花费了大量的资源去实现各种锁优化技术,如适应性自旋(Adaptive Spinning)、锁消除(Lock Elimination)、锁膨胀(Lock Coarsening)、轻量级锁(Lightweight Locking)、偏向锁(Biased Locking)等,这些技术都是为了在线程之间更高效地共享数据及解决竞争问题,从而提高程序的执行效率。</p><h3 id="自旋锁与自适应锁"><a class="header-anchor" href="#自旋锁与自适应锁">¶</a>自旋锁与自适应锁</h3><p>互斥同步对性能最大的影响是阻塞的实现,挂起线程和恢复线程的操作都需要转入内核态中完成,这些操作给Java虚拟机的并发性能带来了很大的压力。同时,虚拟机的开发团队也注意到在许多应用上,共享数据的锁定状态只会持续很短的一段时间,为了这段时间去挂起和恢复线程并不值得。现在绝大多数的个人电脑和服务器都是多路(核)处理器系统,如果物理机器有一个以上的处理器或者处理器核心,能让两个或以上的线程同时并行执行,我们就可以让后面请求锁的那个线程“稍等一会”,但不放弃处理器的执行时间,看看持有锁的线程是否很快就会释放锁。为了让线程等待,我们只须让线程执行一个忙循环(自旋),这项技术就是所谓的自旋锁。</p><p>自旋锁在JDK 1.4.2中就已经引入,只不过默认是关闭的,可以使用<code>-XX:+UseSpinning</code>参数来开启,在JDK 6中就已经改为默认开启了。自旋等待不能代替阻塞,且先不说对处理器数量的要求,自旋等待本身虽然避免了线程切换的开销,但它是要占用处理器时间的,所以如果锁被占用的时间很短,自旋等待的效果就会非常好,反之如果锁被占用的时间很长,那么自旋的线程只会白白消耗处理器资源,而不会做任何有价值的工作,这就会带来性能的浪费。因此自旋等待的时间必须有一定的限度,如果自旋超过了限定的次数仍然没有成功获得锁,就应当使用传统的方式去挂起线程。自旋次数的默认值是十次,用户也可以使用参数<code>-XX:PreBlockSpin</code>来自行更改。</p><p>不过无论是默认值还是用户指定的自旋次数,对整个Java虚拟机中所有的锁来说都是相同的。在JDK 6中对自旋锁的优化,引入了自适应的自旋。<strong>自适应意味着自旋的时间不再是固定的了,而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的</strong>。如果在同一个锁对象上,自旋等待刚刚成功获得过锁,并且持有锁的线程正在运行中,那么虚拟机就会认为这次自旋也很有可能再次成功,进而允许自旋等待持续相对更长的时间,比如持续100次忙循环。另一方面,如果对于某个锁,自旋很少成功获得过锁,那在以后要获取这个锁时将有可能直接省略掉自旋过程,以避免浪费处理器资源。有了自适应自旋,随着程序运行时间的增长及性能监控信息的不断完善,虚拟机对程序锁的状况预测就会越来越精准,虚拟机就会变得越来越“聪明”了。</p><h3 id="锁消除"><a class="header-anchor" href="#锁消除">¶</a>锁消除</h3><p>锁消除是指虚拟机即时编译器在运行时,对一些代码要求同步,但是对被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持,如果判断到一段代码中,在堆上的所有数据都不会逃逸出去被其他线程访问到,那就可以把它们当作栈上数据对待,认为它们是线程私有的,同步加锁自然就无须再进行。</p><p>变量是否逃逸,对于虚拟机来说是需要使用复杂的过程间分析才能确定的, 但是程序员自己应该是很清楚的,怎么会在明知道不存在数据争用的情况下还要求同步呢?这个问题的答案是:有许多同步措施并不是程序员自己加入的,同步的代码在Java程序中出现的频率是很高的，如下例子所示：</p><p><code>String</code>是一个不可变的类,对字符串的连接操作总是通过生成新的<code>String</code>对象来进行的,因此Javac编译器会对<code>String</code>连接做自动优化。在JDK 5之前,字符串加法会转化为<code>StringBuffer</code> 对象的连续<code>append()</code>操作,在JDK 5及以后的版本中,会转化为<code>StringBuilder</code>对象的连续<code>append()</code>操作。</p><pre class="line-numbers language-language-java"><code class="language-language-java">public String concatString(String s1, String s2, String s3) {     return s1 + s2 + s3; }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-language-java"><code class="language-language-java">    public String concatString(String s1, String s2, String s3) {        StringBuffer sb = new StringBuffer();        sb.append(s1);        sb.append(s2);        sb.append(s3);        return sb.toString();    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>现在每个<code>StringBuffer.append()</code>方法中都有一个同步块,锁就是<code>sb</code>对象。虚拟机观察变量<code>sb</code>,经过逃逸分析后会发现它的动态作用域被限制在<code>concatString()</code>方法内部。也就是<code>sb</code>的所有引用都永远不会逃逸到<code>concatString()</code>方法之外,其他线程无法访问到它,所以这里虽然有锁,但是可以被安全地消除掉。在解释执行时这里仍然会加锁,但在经过服务端编译器的即时编译之后,这段代码就会忽略所有的同步措施而直接执行。</p><h3 id="锁粗化"><a class="header-anchor" href="#锁粗化">¶</a>锁粗化</h3><p>原则上,我们在编写代码的时候,总是推荐将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步,这样是为了使得需要同步的操作数量尽可能变少,即使存在锁竞争,等待锁的线程也能尽可能快地拿到锁。</p><p>大多数情况下,上面的原则都是正确的,但是如果一系列的连续操作都对同一个对象反复加锁和解锁,甚至加锁操作是出现在循环体之中的,那即使没有线程竞争,频繁地进行互斥同步操作也会导致不必要的性能损耗。</p><p>以上代码所示连续的<code>append()</code>方法就属于这类情况。如果虚拟机探测到有这样一串零碎(<strong>执行时间相对加锁时间短</strong>)的操作都对同一个对象加锁,将会把加锁同步的范围扩展(粗化)到整个操作序列的外部,上面代码为例,就是扩展到第一个<code>append()</code>操作之前直至最后一个<code>append()</code>操作之后,这样只需要加锁一次就可以了。</p><h3 id="轻量级锁"><a class="header-anchor" href="#轻量级锁">¶</a>轻量级锁</h3><p>轻量级锁是JDK 6时加入的新型锁机制,它名字中的“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的,因此传统的锁机制就被称为“重量级”锁。不过,需要强调一点,轻量级锁并不是用来代替重量级锁的,它设计的初衷是在没有多线程竞争的前提下,减少传统的重量级锁使用操作系统互斥量产生的性能消耗。</p><p>要理解轻量级锁,以及后面会讲到的偏向锁的原理和运作过程,必须要对HotSpot虚拟机对象的内存布局(尤其是对象头部分)有所了解。HotSpot虚拟机的对象头(Object Header)分为两部分,第一部分用于存储对象自身的运行时数据,如哈希码(HashCode)、GC分代年龄(Generational GC Age) 等。这部分数据的长度在32位和64位的Java虚拟机中分别会占用32个或64个比特,官方称它为“Mark Word”。这部分是实现轻量级锁和偏向锁的关键。另外一部分用于存储指向方法区对象类型数据的指针,如果是数组对象,还会有一个额外的部分用于存储数组长度。</p><p>由于对象头信息是与对象自身定义的数据无关的额外存储成本,考虑到Java虚拟机的空间使用效率,Mark Word被设计成一个非固定的动态数据结构,以便在极小的空间内存储尽量多的信息。它会根据对象的状态复用自己的存储空间。例如在32位的HotSpot虚拟机中,对象未被锁定的状态下, Mark Word的32个比特空间里的25个比特将用于存储对象哈希码,4个比特用于存储对象分代年龄,2 个比特用于存储锁标志位,还有1个比特固定为0(这表示未进入偏向模式)。对象除了未被锁定的正常状态外,还有轻量级锁定、重量级锁定、GC标记、可偏向等几种不同状态,这些状态下对象头的存储内容如下<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000646.png" alt="image-20200924075130335"></p><p>轻量级锁的工作过程:在代码即将进入同步块的时候,如果此同步对象没有被锁定(锁标志位为“01”状态),虚拟机首先将在当前线程的栈帧中建立一个名为锁记录(Lock Record)的空间,用于存储锁对象目前的Mark Word的拷贝(官方为这份拷贝加了一个Displaced前缀,即Displaced Mark Word),这时候线程堆栈与对象头的状态如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000650.png" alt="image-20200924075237466"></p><p>然后,虚拟机将使用CAS操作尝试把对象的Mark Word更新为指向Lock Record的指针。如果这个更新动作成功了,即代表该线程拥有了这个对象的锁,并且对象Mark Word的锁标志位(Mark Word的最后两个比特)将转变为“00”,表示此对象处于轻量级锁定状态。这时候线程堆栈与对象头的状态如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000655.png" alt="image-20200924075327306"></p><p>如果这个更新操作失败了,那就意味着至少存在一条线程与当前线程竞争获取该对象的锁。虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧,如果是,说明当前线程已经拥有了这个对象的锁,那直接进入同步块继续执行就可以了,否则就说明这个锁对象已经被其他线程抢占了。如果出现两条以上的线程争用同一个锁的情况,那轻量级锁就不再有效,必须要膨胀为重量级锁,锁标志的状态值变为“10”,此时Mark Word中存储的就是指向重量级锁(互斥量)的指针,后面等待锁的线程也必须进入阻塞状态。</p><p>上面描述的是轻量级锁的加锁过程,它的解锁过程也同样是通过CAS操作来进行的,如果对象的Mark Word仍然指向线程的锁记录,那就用CAS操作把对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来。假如能够成功替换,那整个同步过程就顺利完成了;如果替换失败,则说明有其他线程尝试过获取该锁,就要在释放锁的同时,唤醒被挂起的线程<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup>。</p><p><strong>轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁,在整个同步周期内都是不存在竞争的”这一经验法则。如果没有竞争,轻量级锁便通过CAS操作成功避免了使用互斥量的开销;但如果确实存在锁竞争,除了互斥量的本身开销外,还额外发生了CAS操作的开销。因此在有竞争的情况下, 轻量级锁反而会比传统的重量级锁更慢。</strong></p><h3 id="偏向锁"><a class="header-anchor" href="#偏向锁">¶</a>偏向锁</h3><p>偏向锁也是JDK 6中引入的一项锁优化措施,它的目的是消除数据在无竞争情况下的同步原语, 进一步提高程序的运行性能。如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量,那偏向锁就是在无竞争的情况下把整个同步都消除掉,连CAS操作都不去做了。</p><p>偏向锁中的“偏”,就是偏心的“偏”、偏袒的“偏”。它的意思是这个锁会偏向于第一个获得它的线程,如果在接下来的执行过程中,该锁一直没有被其他的线程获取,则持有偏向锁的线程将永远不需要再进行同步。</p><p>假设当前虚拟机启用了偏向锁(启用参数<code>-XX:+UseBiased Locking</code>,这是自JDK 6 起HotSpot虚拟机的默认值),那么当锁对象第一次被线程获取的时候,虚拟机将会把对象头中的标志位设置为“01”、把偏向模式设置为“1”,表示进入偏向模式。同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中。如果CAS操作成功,持有偏向锁的线程以后每次进入这个锁相关的同步块时,虚拟机都可以不再进行任何同步操作(例如加锁、解锁及对Mark Word的更新操作等)。</p><p>一旦出现另外一个线程去尝试获取这个锁的情况,偏向模式就马上宣告结束。根据锁对象目前是否处于被锁定的状态决定是否撤销偏向(偏向模式设置为“0”),撤销后标志位恢复到未锁定(标志位为“01”)或轻量级锁定(标志位为“00”)的状态,后续的同步操作就按照上面介绍的轻量级锁那样去执行。偏向锁、轻量级锁的状态转化及对象Mark Word的关系如下</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000705.png" alt="image-20200924080441295"></p><p>细心的读者看到这里可能会发现一个问题:当对象进入偏向状态的时候,Mark Word大部分的空间(23个比特)都用于存储持有锁的线程ID了,这部分空间占用了原有存储对象哈希码的位置,那原来对象的哈希码怎么办呢? 在Java语言里面一个对象如果计算过哈希码,就应该一直保持该值不变(强烈推荐但不强制,因为用户可以重载hashCode()方法按自己的意愿返回哈希码),否则很多依赖对象哈希码的API都可能存在出错风险。而作为绝大多数对象哈希码来源的<code>Object::hashCode()</code>方法,返回的是对象的一致性哈希码(Identity Hash Code),这个值是能强制保证不变的,它通过在对象头中存储计算结果来保证第一次计算之后,再次调用该方法取到的哈希码值永远不会再发生改变。<strong>因此,当一个对象已经计算过一致性哈希码后,它就再也无法进入偏向锁状态了;而当一个对象当前正处于偏向锁状态,又收到需要计算其一致性哈希码请求<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>时,它的偏向状态会被立即撤销,并且锁会膨胀为重量级锁。在重量级锁的实现中,对象头指向了重量级锁的位置,代表重量级锁的<code>ObjectMonitor</code>类里有字段可以记录非加锁状态(标志位为“01”)下的Mark Word,其中自然可以存储原来的哈希码。</strong></p><p>偏向锁可以提高带有同步但无竞争的程序性能,但它同样是一个带有效益权衡(Trade Off)性质的优化,也就是说它并非总是对程序运行有利。如果程序中大多数的锁都总是被多个不同的线程访问,那偏向模式就是多余的。在具体问题具体分析的前提下,有时候使用参数<code>-XX:- UseBiasedLocking</code>来禁止偏向锁优化反而可以提升性能。</p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>在《Java虚拟机规范》的第2版及之前,专门有一章“Threads and Locks”来描述内存模型,后来由于这部分内容难以把握宽紧限度,被反复修正更新,从第3版(Java SE 7版)开始索性就被移除出规范, 独立以JSR形式维护。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>在JDK 1.2之后建立起来并在JDK 5中完善过的内存模型，就是指前面笔记中的内存部分的结构 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>JSR 166:Concurrency Utilities。 <a href="#fnref3" class="footnote-backref">↩︎</a> <a href="#fnref3:1" class="footnote-backref">↩︎</a> <a href="#fnref3:2" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>还有另外一种常见的实现——重入读写锁(ReentrantReadWriteLock,尽管名字看起来很像,但它并不是ReentrantLock的子类) <a href="#fnref4" class="footnote-backref">↩︎</a> <a href="#fnref4:1" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>可重入性是指一条线程能够反复进入被它自己持有锁的同步块的特性,即锁关联的计数器,如果持有锁的线程再次获得它,则将计数器的值加一,每次释放锁时计数器的值减一,当计数器的值为零时,才能真正释放锁。 <a href="#fnref5" class="footnote-backref">↩︎</a> <a href="#fnref5:1" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>根据《Java虚拟机规范》的约定,volatile变量依然有工作内存的拷贝,但是由于它特殊的操作顺序性规定(后文会讲到),所以看起来如同直接在主内存中读写访问一般,因此这里的描述对于volatile 也并不存在例外。 <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>除了实例数据,Java堆还保存了对象的其他信息,对于HotSpot虚拟机来讲,有Mark Word(存储对象哈希码、GC标志、GC年龄、同步锁等信息)、Klass Point(指向存储类型元数据的指针)及一些用于字节对齐补白的填充数据(如果实例数据刚好满足8字节对齐,则可以不存在补白)。 <a href="#fnref7" class="footnote-backref">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>基于理解难度和严谨性考虑,最新的JSR-133文档中,已经放弃了采用这8种操作去定义Java内存模型的访问协议,缩减为4种(仅是描述方式改变了,Java内存模型并没有改变)。 <a href="#fnref8" class="footnote-backref">↩︎</a></p></li><li id="fn9" class="footnote-item"><p>Doug Lea列出了各种处理器架构下的内存屏障指令:<a href="http://gee.cs.oswego.edu/dl/jmm/cookbook.html" target="_blank" rel="noopener">http://gee.cs.oswego.edu/dl/jmm/cookbook.html</a> <a href="#fnref9" class="footnote-backref">↩︎</a></p></li><li id="fn10" class="footnote-item"><p>这种被虚拟机特殊处理的方法称为固有函数(Intrinsics)优化,类似的固有函数还有Math类的一系列算数计算函数、Object的构造函数等,目前已有数百个,具体的清单(以JDK 9为例)可以见: <a href="https://gist.github.com/apangin/8bc69f06879a86163e490a61931b37e8%E3%80%82" target="_blank" rel="noopener">https://gist.github.com/apangin/8bc69f06879a86163e490a61931b37e8。</a> <a href="#fnref10" class="footnote-backref">↩︎</a></p></li><li id="fn11" class="footnote-item"><p>替换失败是因为有其它线程将轻量级锁标识改成重量级锁了，当前线程还是拿旧值也就是轻量级锁标识记进行CAS，无论是CAS的一瞬间产生竞争还是轻量级锁标识被改了较长时间了都会导致失败，此时其他线程肯定都在重量级锁的互斥量上挂起了。此时当前线程需要获取对象头的新mark word进行CAS，然后根据此时mark word中的互斥量指针得到互斥量对在互斥量上挂起的线程进行唤醒 <a href="#fnref11" class="footnote-backref">↩︎</a></p></li><li id="fn12" class="footnote-item"><p>注意,这里说的计算请求应来自于对Object::hashCode()或者System::identityHashCode(Object)方法的调用,如果重写了对象的hashCode()方法,计算哈希码时并不会产生这里所说的请求。 <a href="#fnref12" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>03_虚拟机栈(方法栈)</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/03-xu-ni-ji-zhan-fang-fa-zhan/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/03-xu-ni-ji-zhan-fang-fa-zhan/</url>
      
        <content type="html"><![CDATA[<h1>虚拟机栈概述</h1><p>由于跨平台性的设计，Java的指令都是根据栈来设计的。不同平台CPU架构不同，所以不能设计为基于寄存器的。优点是跨平台，指令集小，编译器容易实现，缺点是性能下降，实现同样的功能需要更多的指令。</p><p>栈是运行时的单位(线程绑定、方法相关)，而堆是存储的单位。即，栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放、放在哪儿。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233944.png" alt="image-20200911114147108"></p><h3 id="基本内容"><a class="header-anchor" href="#基本内容">¶</a>基本内容</h3><ul><li><p>Java虚拟机栈(Java virtual Machine Stack)，早期也叫Java栈。每个线程在创建时都会创建一个虚拟机栈，其内部保存一个个的栈帧(Stack Frame)，对应着一次次的Java方法调用。是线程私有的。</p></li><li><p>生命周期和线程一致</p></li><li><p>主管Java程序的运行，它保存方法的局部变量(8种基本数据类型、对象的引用地址)、部分结果，并参与方法的调用和返回。</p></li></ul><blockquote><p>这里有个疑问，JVM的用户方法是否对应到native中是否是一对一的方法，如果不是，用户方法的栈帧就应该是JVM自己实现的一个数据结构？</p></blockquote><h3 id="栈的特点-优点"><a class="header-anchor" href="#栈的特点-优点">¶</a>栈的特点(优点)</h3><p>栈是一种快速有效的分配存储方式，访问速度仅次于程序计数器。JVM直接对Java栈的操作只有两个：</p><ul><li>每个方法执行，伴随着压栈</li><li>执行结束后的出栈工作</li></ul><p>对于栈来说不存在垃圾回收问题</p><h3 id="开发中遇到的异常有哪些？"><a class="header-anchor" href="#开发中遇到的异常有哪些？">¶</a>开发中遇到的异常有哪些？</h3><p>Java虚拟机规范允许Java栈的大小是动态的或者是固定不变的：</p><ul><li>如果采用固定大小的Java虚拟机栈，那每一个线程的Java虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过Java虚拟机栈允许的最大容量，Java虚拟机将抛出一个StackOverflowError异常。<ul><li>我们可以使用参数<code>-Xss</code>选项来设置线程的栈容量，栈的容量直接决定了函数调用的最大可达深度。</li></ul></li><li>如果Java虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程的时候没有足够的内存去创建对应的虚拟机栈，那Java虚拟机将会抛出一个OutofMemoryError异常。</li></ul><h1>栈的存储单位-栈帧</h1><ul><li>每个线程都有自己的栈，栈中的数据都是以栈帧(Stack Frame)的格式存在。</li><li>在这个线程上正在执行的每个方法都各自对应一个栈帧。</li><li>栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息。</li></ul><h3 id="栈执行原理"><a class="header-anchor" href="#栈执行原理">¶</a>栈执行原理</h3><ul><li><p>JVM直接对Java栈的操作只有两个，就是对栈帧的压栈和出栈，遵循&quot;先进后出&quot;/&quot;后进先出&quot;原则。</p></li><li><p>在一条活动线程中，一个时间点上，只会有一个活动的栈帧。即只有当前正在执行的方法的栈帧(栈顶栈帧)是有效的，这个栈帧被称为<strong>当前栈帧(Current Frame)</strong>，与当前栈帧相对应的方法就是<strong>当前方法（Current Method）</strong>，定义这个方法的类就是<strong>当前类（Current Class）。</strong></p></li><li><p>执行引擎运行的所有字节码指令只针对当前栈帧进行操作。</p></li><li><p>如果在该方法中调用了其它方法，对应的新的栈帧会被创建出来，放在栈的顶端，成为新的当前帧。</p></li><li><p>不同线程中所包含的栈帧是不允许存在相互引用的，即不可能在一个栈帧之中引用另外一个线程的栈帧。</p></li><li><p>如果当前方法调用了其它方法，方法返回之际，当前栈帧会传回此方法的执行结果给前一个栈帧，接着，虚拟机会丢弃当前栈帧，使得前一个栈帧重新成为当前栈帧。</p></li><li><p>Java方法会有两种返回函数的方式，一种是正常的函数返回，使用return指令；另一种是抛出异常。不管使用哪种方式，都会导致栈帧被弹出。</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233952.png" alt="image-20200911145920934"></p><h3 id="1、局部变量表-Local-Variables"><a class="header-anchor" href="#1、局部变量表-Local-Variables">¶</a>1、局部变量表(Local Variables)</h3><ul><li><p>局部变量表也被称之为局部变量数组或本地变量表。</p></li><li><p>定义为一个数字数组，主要用于存储方法参数和定义在方法体内的局部变量，这些数据类型在编译期即可确定，包括各类基本数据类型、对象引用(reference)，以及returnAddress类型。</p></li><li><p>由于局部变量表是建立在线程的栈上，是线程的私有数据，因此不存在数据安全问题</p></li><li><p>局部变量表<strong>所需的容量大小是在编译期确定下来的</strong>，并保存在方法的Code属性的maximum local variables数据项中。在方法运行期间是不会改变局部变量表的大小的。</p></li><li><p>参数值的存放总是在局部变量数组的index0开始，到数组长度-1的索引结束</p></li><li><p>局部变量表，最基本的存储单元是slot（变量槽）</p></li><li><p>在局部变量表里，32位以内的类型只占用一个slot（boolean、byte、char、short、int、float、reference和returnAddress），64位的类型(long和double)占用两个slot。</p><ul><li>byte、short、char在存储前被转换成int，boolean也被转换成int，0表示false，非0表示true</li></ul></li><li><p>long和double则占据两个slot</p><blockquote><ul><li><p>reference类型在不同虚拟机、不同机器上的长度可能不一样，有的32位有的64位</p></li><li><p>returnAddress类型目前已经很少见了,它是为字节码指令jsr、jsr_w和ret服务的,指向了一条字节码指令的地址,某些很古老的Java虚拟机曾经使用这几条指令来实现异常处理时的跳转,但现在也已经全部改为采用异常表来代替了</p></li></ul></blockquote></li><li><p>方法嵌套调用的次数由栈的大小决定。一般来说，栈越大，方法嵌套调用次数越多。对一个函数而言，它的参数和局部变量越多，使得局部变量表膨胀，它的栈帧就越大，以满足方法调用所需传递的信息增大的需求。进而函数调用就会占用更多的栈空间，导致其嵌套调用次数就会减少。</p></li><li><p>局部变量表中的变量只在当前方法调用中有效。在方法执行时，虚拟机通过使用局部变量表完成参数值到参数变量列表的传递过程。当方法调用结束后，随着方法栈帧的销毁，局部变量表也会随之销毁。</p></li><li><p>JVM会为局部变量表中的每一个Slot都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值。</p></li><li><p>当一个实例方法被调用的时候，它的方法参数和方法体内部定义的局部变量都会<strong>按照顺序被复制</strong>到局部变量表的每一个slot上。</p></li><li><p>如果需要访问局部变量表中一个64bit的局部变量值时，只需要使用前一个索引即可。（比如：访问long或double类型变量）</p></li><li><p>如果当前帧时由构造方法或者实例方法创建的（<strong>非静态方法</strong>），那么该对象引用this将会存放在index为0的slot处，其余的参数按照参数表顺序继续排列。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234000.png" alt="image-20200915152023282"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234006.png" alt="image-20200915153851804"></p></li><li><p>栈帧中的局部变量表中的槽位时可以重用的，如果一个局部变量过了其作用域，那么在其作用域之后申明的新的局部变量就很有可能会复用过期局部变量的槽位，从而达到节省资源的目的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234014.png" alt="image-20200915152856343"></p><p>但是可能在垃圾回收方面会带来一些问题，如果失效作用域内的变量槽没有再次被赋值，那这个槽位就会一直持有对应的数据对象的引用，无法被GC；除非经过了JIT编译器的优化，JIT编译器会对这种情况进行优化，如果发现该变量没有发生逃逸且所属作用域已经失效，即判为引用失效，可以进行回收。</p></li><li><p>参数表分配完毕之后，再根据方法体内定义的变量的顺序和作用域分配。</p></li><li><p>成员变量：在使用前，都经历过默认初始化赋值</p><ul><li>类变量：linking的prepare阶段给类变量默认赋值；在initial阶段将程序员定义的值进行赋值</li><li>局部变量表不存在系统初始化的过程，这意味着一旦定义了局部变量则必须人为的初始化，否则无法使用，编译错误</li></ul></li><li><p>在栈帧中，与性能调优关系最为密切的部分就是前面提到的局部变量表。在方法执行的时候，虚拟机使用局部变量表完成方法的传递。</p></li><li><p><strong>局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收。</strong></p></li></ul><h3 id="2、操作数栈-Operand-Stack"><a class="header-anchor" href="#2、操作数栈-Operand-Stack">¶</a>2、操作数栈(Operand Stack)</h3><ul><li><p>每一个独立的栈帧中除了包含局部变量表以外，还包含一个后进先出(Last-In-First-Out)的操作数栈，也可以称之为表达式栈(Expression Stack)。</p></li><li><p>操作数栈，在方法执行过程中，根据字节码指令，往栈中写入数据或提取数据，即入栈(push)/出栈(pop)。</p><ul><li>某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈。</li><li>比如：执行复制、交换、求和等操作。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234021.png" alt="image-20200915155210392"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234027.png" alt="image-20200915155315502"></p></li><li><p>操作数栈，主要用于保存计算过程的中间结果，同时作为计算过程中变量(本地变量表中的变量)临时的存储空间。</p></li><li><p>操作数栈就是JVM执行引擎的一个工作区(从本地变量表加载数据到操作数栈、对栈顶数据进行计算、把计算结果写回本地变量表并弹栈)，当一个方法刚开始执行的时候，一个新的栈帧也会随之被创建出来，这个方法的操作数栈是空的。</p></li><li><p>每一个操作数栈都会拥有一个明确的栈深度用于存储数值，其所需的最大深度在编译期就定义好了，保存在方法的Code属性中，为max_stack的值</p></li><li><p>栈中的任何一个元素都是可以任意的Java数据类型（8种基本数据类型和引用类型）</p><ul><li>32bit的类型占用一个栈单位深度</li><li>64bit的类型占用两个栈单位深度</li></ul></li><li><p>操作数栈并非采用访问索引的方式来进行数据访问的，而是只能通过标准的入栈和出栈操作来完成一次数据访问</p></li><li><p>如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中，并更新PC寄存器中下一条需要执行的字节码指令。</p></li><li><p>操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，这由编译器在编译期间进行验证，同时在类加载过程中的类检验阶段的数据流分析阶段要再次验证。</p></li><li><p>另外，我们说Java虚拟机的解释引擎时基于栈的执行引擎，其中的栈指的就是操作数栈。</p></li></ul><h4 id="代码追踪"><a class="header-anchor" href="#代码追踪">¶</a>代码追踪</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234035.png" alt="image-20200915160522240"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234051.png" alt="image-20200915160613692"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234057.png" alt="image-20200915160713714"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234105.png" alt="image-20200915160758187"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234112.png" alt="image-20200915160836515"></p><h4 id="栈顶缓存技术-ToS，Top-of-Stack-Caching"><a class="header-anchor" href="#栈顶缓存技术-ToS，Top-of-Stack-Caching">¶</a>栈顶缓存技术(ToS，Top-of-Stack Caching)</h4><p>前面提过，基于栈式架构的虚拟机所使用的零地址指令更加紧凑，但完成一项操作的时候必然需要使用更多的入栈和出栈指令，这同时也就意味着将需要更多的指令分派(instruction dispatch)次数和内存读/写次数。</p><p>由于操作数时存储在内存中的，因此频繁地执行内存读/写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM的设计者们**提出了（仅是提出?）**栈顶缓存(ToS，Top-of-Stack Caching)计数，将栈顶元素全部缓存在物理CPU的寄存器中，以此降低对内存的读/写次数，提升执行引擎的执行效率。</p><h3 id="3、动态链接-Dynamic-Linking"><a class="header-anchor" href="#3、动态链接-Dynamic-Linking">¶</a>3、动态链接(Dynamic Linking)</h3><p>指向运行时常量池的方法引用。</p><ul><li>每一个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用。持有这个引用是为了支持方法调用过程中的动态连接(Dynamic Linking)。<strong>Class文件</strong>的常量池中存有大量的符号引用,字节码中的方法调用指令就以常量池里指向方法的符号引用作为参数。<ul><li>这些符号引用一部分会在类加载阶段或者第一次使用的时候就被转化为直接引用,这种转化被称为静态解析。</li><li>另外一部分将在每一次运行期间都转化为直接引用,这部分就称为动态连接。</li></ul></li><li>在Java源文件被编译到字节码文件中时，所有的变量和方法引用都作为符号引用(Symbolic Reference)保存在class文件的常量池区中，在后续编译阶段会进行内存分配将符号引用替换为真实的直接引用，保存在运行时常量池，而在C/C++中，方法也是可以作为一个对象进行取址从而进行动态地传递和调用的，所以所有的方法符号引用也会被转换为直接内存引用保存在常量池中，此后在进行相关方法调用的时候，会根据编译期得到的信息判断它调用了哪些方法，从而将相关方法的直接引用也保存到其栈帧中。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234120.png" alt="image-20200915163545120"></p><h3 id="4、方法返回地址-Return-Address"><a class="header-anchor" href="#4、方法返回地址-Return-Address">¶</a>4、方法返回地址(Return Address)</h3><ul><li><p>一个方法的结束，有两种方式：</p><ul><li>正常执行完成</li><li>出现未处理的异常，非正常退出</li></ul></li><li><p>无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。</p><ul><li>方法正常退出时，调用者的pc计数器的值都作为返回地址，即调用该方法的指令的下一条指令的地址。所以这里的意思是发生方法调用的时候，调用方的PC计数器的值由被调用方进行保存，保存的位置就是当前被调用方栈帧中的&quot;方法返回地址&quot;内存区域，在弹出栈帧的时候重新取出该值调整后设置到PC计数器。（同时如果方法有返回值就压入到调用方的操作数栈中）</li><li>而通过异常退出的，返回地址是要通过异常表来确定，栈帧中一般不会保存这部分信息。</li></ul></li><li><p>当一个方法开始执行后，只有两种方式可以退出这个方法：</p><ol><li><p>执行引擎遇到任意一个方法返回的字节码指令(return)，会有返回值传递给上层的方法调用者，简称正常完成出口。</p><ul><li>一个方法在正常调用完成之后究竟需要使用哪一个返回指令还需要根据方法返回值的实际数据类型而定。</li><li>在字节码指令中，返回指令包含ireturn（当返回值是boolean、byte、char、short、int类型时使用）、lreturn、freturn、dreturn以及areturn，另外还有一个return指令供声明为void的方法、实例初始化方法、类和接口的初始化方法使用。</li></ul></li><li><p>在方法执行的过程中遇到了异常，并且这个异常没有在方法内进行处理，也就是只要在本方法的异常表(根据try catch代码块构建)中没有搜索到匹配的异常处理器，就会导致方法退出。简称异常完成出口。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234127.png" alt="image-20200915182531902"></p><p>上述描述了一个异常表(通过classlib或者javap都可以查看)，表示在4到16、19到21直接的字节码指令遇到任何(any)类型的异常都跳转到(goto)19字节码指令。</p></li></ol></li></ul><p>本质上，方法退出就是当前栈帧出栈的过程。此时，需要恢复上层方法的局部变量表、操作数栈、将返回值压入调用者栈帧的操作数栈、设置PC寄存器值等，让调用者方法继续执行下去。</p><p>正常完成出口和异常完成出口的区别在于：通过异常完成出口退出的不会给它的上层调用者产生任何的返回值。</p><h3 id="5、一些附加信息"><a class="header-anchor" href="#5、一些附加信息">¶</a>5、一些附加信息</h3><p>栈帧中还允许携带与Java虚拟机实现相关的一些附加信息。例如，对程序调试提供支持的信息。</p><p>栈的相关面试题</p><h1>虚方法与非虚方法</h1><ul><li><p>如果方法在编译期就确定了具体的调用版本，这个版本在运行时时不可变的。这样的方法称为非虚方法。</p><p>静态方法、私有方法、final方法、实例构造器、父类方法都是非虚方法。</p></li><li><p>其它方法称为虚方法。</p></li></ul><p>虚拟机中提供了以下几条方法调用指令：</p><ul><li>普通调用指令：<ol><li>invokestatic:：调用静态方法，解析阶段确定唯一方法版本</li><li>invokespecial：调用<code>&lt;init&gt;</code>方法、私有方法、父类方法，解析阶段确定唯一方法版本</li><li>invokevirtual：调用所有虚方法</li><li>invokeinterface：调用接口方法，在运行时再确定一个实现该接口的对象</li></ol></li><li>动态调用指令：<ol><li>invokedynamic：动态解析出需要调用的方法，然后执行</li></ol></li></ul><p>前面4 条调用指令,分派逻辑都固化在Java虚拟机内部,而invokedynamic指令的分派逻辑是由用户设定的引导方法来决定的。</p><p>只要能被invokestatic和invokespecial指令调用的方法,都可以在解析阶段中确定唯一的调用版本, Java语言里符合这个条件的方法共有静态方法、私有方法、实例构造器、父类方法4种,<strong>再加上被final 修饰的方法</strong>(尽管它使用invokevirtual指令调用),这5种方法调用会在类加载的时候就可以把符号引用解析为该方法的直接引用。**这些方法统称为“非虚方法”(Non-Virtual Method),**与之相反,其他方法就被称为“虚方法”(Virtual Method)。</p><h1>方法的调用：链接与绑定维度</h1><p>在JVM中，将符号引用转换为调用方法的直接引用与方法的绑定机制相关。</p><ul><li>静态链接：当一个字节码文件被装载进JVM内部时，如果被调用的目标方法在编译期可知，且运行期保持不变时。这种情况下将调用方法的符号引用转换为直接引用的过程称之为&quot;静态链接&quot;。</li><li>动态链接：如果被调用的方法在编译期无法被确定下来，也就是说，只能够在程序运行期将调用方法的符号引用转换为直接引用，由于这种引用转换过程具备动态性，因此也就被称之为&quot;动态链接&quot;</li></ul><p>对应的方法的绑定机制为：早期绑定（Early Binding）和晚期绑定（Late Binding）。绑定是一个字段、方法或者类在符号引用被替换为直接引用的过程，这仅仅发生一次。</p><ul><li>早期绑定：早期绑定就是被调用的目标方法如果在编译期可知，且运行期保持不变时，即可将这个方法与所属的类型进行绑定，这样一来，由于明确了被调用的目标方法究竟是属于哪个class，因此也就可以使用静态链接的方式将符号引用直接转换为符号引用。<ul><li>例如在某个方法中对某个class的构造函数的调用，这个就是可以在编译期可以确定它指的就是某个具体class的某个构造函数，此时在编译该方法所属class的时候可以直接在其内存区域保存该构造函数转换后的直接引用即可。</li><li>另外<code>this.method()</code>和<code>super.method</code>的调用都是可以明确确定具体要调用的方法的。</li><li><code>final</code>方法表示不可被重写，也是可以在早期绑定的。</li><li>其它参考下面虚方法与非虚方法介绍</li></ul></li><li>晚期绑定：如果被调用的方法在编译期无法被确定下来，只能够在程序运行期根据实际的类型(class)绑定相关的方法，这种绑定方式也就被称之为晚期绑定(例如方法中调用的其它非final普通方法的引用绑定)。<ul><li>对于其它方法的调用都是动态绑定，因为Java是面向对象的，具有多态性，即使在调用某个方法的时候，该方法的所属(declared)类是没有子类的，但是Java的字节码是可以动态注入的，所以体现了final关键字的作用。故不能在调用普通方法的class的编译期就将该方法的符号引用替换为具体的直接引用，而是在运行期(创建栈帧)的时候根据传入的实际类型(该普通方法的所属class对象地址)获取到对应的方法引用进行绑定。</li></ul></li></ul><p>随着高级语言的横空出世，类似于Java一样的基于面向对象的编程语言如今越来越多，尽管这类编程语言在语法风格上存在一定的差别，但是它们彼此之间始终保持着一个共性，那就是都支持封装、继承和多态等面向对象特性，既然这一类的编程语言具备多态特性，那么自然也就具备早期绑定和晚期绑定两种绑定方式。</p><p>Java中任何一个普通的方法其实都具备虚函数的特征，它们相当于C<ins>语言中的虚函数(C</ins>中则需要使用关键字virtual来显式定义)。如果在Java程序中不希望某个方法拥有虚函数的特征时，则可以使用关键字final来标记这个方法。</p><h1>方法的调用：解析与分派维度</h1><h2 id="解析"><a class="header-anchor" href="#解析">¶</a>解析</h2><p>所有方法调用的目标方法在Class文件里面都是一个常量池中的符号引用,在类加载的解析阶段,会将其中的一部分符号引用转化为直接引用,这种解析能够成立的前提是:<strong>方法在程序真正运行之前就有一个可确定的调用版本,并且这个方法的调用版本在运行期是不可改变的</strong>。换句话说,调用目标在程序代码写好、编译器进行编译那一刻就已经确定下来。这类方法的调用被称为解析(Resolution)。</p><p><strong>所有非虚方法都会在类加载的时候直接解析。</strong></p><p>解析调用一定是个静态的过程,在编译期间就完全确定,在类加载的解析阶段就会把涉及的符号引用全部转变为明确的直接引用,不必延迟到运行期再去完成。而另一种主要的方法调用形式:分派(Dispatch)调用则要复杂许多,它可能是静态的也可能是动态的,按照分派依据的宗量数可分为单分派和多分派。这两类分派方式两两组合就构成了静态单分派、静态多分派、动态单分派、动态多分派4种分派组合情况。</p><h2 id="分派"><a class="header-anchor" href="#分派">¶</a>分派</h2><h3 id="静态分派与重载"><a class="header-anchor" href="#静态分派与重载">¶</a>静态分派与重载</h3><p>所有<strong>依赖静态类型来决定方法执行版本</strong>的分派动作,都称为静态分派。静态分派的最典型应用表现就是方法重载。静态分派发生在编译阶段,因此确定静态分派的动作实际上不是由虚拟机来执行的。</p><pre class="line-numbers language-language-java"><code class="language-language-java">package demo;/** * 方法静态分派演示 */public class StaticDispatch {    static abstract class Human {    }    static class Man extends Human {    }    static class Woman extends Human {    }    public void sayHello(Human guy) {        System.out.println("hello,guy!");    }    public void sayHello(Man guy) {        System.out.println("hello,gentleman!");    }    public void sayHello(Woman guy) {        System.out.println("hello,lady!");    }    public static void main(String[] args) {        Human man = new Man();        Human woman = new Woman();        StaticDispatch sr = new StaticDispatch();        sr.sayHello(man);        sr.sayHello(woman);    }}//运行结果：//hello,guy!//hello,guy!<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>代码中的“Human”称为变量的“静态类型”(Static Type),或者叫“外观类型”(Apparent Type),后面的“Man”则被称为变量的“实际类型”(Actual Type)或者叫“运行时类型”(Runtime Type)。静态类型和实际类型在程序中都可能会发生变化,区别是：</p><ul><li><p>静态类型的变化仅仅在使用时发生,变量本身的静态类型不会被改变,并且最终的静态类型是在编译期可知的;</p><pre class="line-numbers language-language-java"><code class="language-language-java">// 强制转换使静态类型变化，但是依旧是编译期可知sr.sayHello((Man) human) sr.sayHello((Woman) human)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>而实际类型变化的结果在运行期才可确定,编译器在编译程序的时候并不知道一个对象的实际类型是什么。</p><pre class="line-numbers language-language-java"><code class="language-language-java">// 实际类型变化Human human = (new Random()).nextBoolean() ? new Man() : new Woman();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><h4 id="重载方法匹配优先级"><a class="header-anchor" href="#重载方法匹配优先级">¶</a>重载方法匹配优先级</h4><p>字面量就没有显式的静态类型,它的静态类型只能通过语言、语法的规则去理解和推断。例如下面代码中的’a’。</p><pre class="line-numbers language-language-java"><code class="language-language-java">package demo;import java.io.Serializable;/** * @author: honphan.john * @date: 2020/9/22 09:10 * @description: */public class Overload {    public static void sayHello(Object arg) {        System.out.println("hello Object");    }    public static void sayHello(int arg) {        System.out.println("hello int");    }    public static void sayHello(long arg) {        System.out.println("hello long");    }    public static void sayHello(Character arg) {        System.out.println("hello Character");    }    public static void sayHello(char arg) {        System.out.println("hello char");    }    public static void sayHello(char... arg) {        System.out.println("hello char ...");    }    public static void sayHello(Serializable arg) {        System.out.println("hello Serializable");    }    public static void main(String[] args) {        sayHello('a');    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面的’a’会按照以下顺序通过本身的类型或者安全地转型之后得到一个静态类型结果进行匹配。但不会匹配到byte和short类型的重载,因为char到byte或short的转型是不安全的。(可以通过一行行地注释代码得到验证)</p><ul><li><p>char：首先对自身的类型作为静态类型进行匹配，如果没有匹配到就往下走</p></li><li><p>int&gt;long&gt;float&gt;double：按照从左到右地优先级进行安全的宽化转型之后进行匹配，如果没有匹配到就往下走</p></li><li><p>Character：寻找装箱类型，如果还是没有就往下走</p></li><li><p>Serializable：寻找装箱类型实现的接口（Character还实现了一个Comparable接口，如果同时出现这两个重载方法，javac编译期将无法确定是哪一个，将无法编译通过，此时必须进行手动强转入参’a’为其中的一个接口类型）</p></li><li><p>Object：所有接口到找不到就寻找父类，按照继承关系从下到上一层层找，直到Object</p></li><li><p>char …：最后匹配多参类型</p></li></ul><blockquote><p>注：赋值为null的时候，只有装箱、接口、父类重载可以匹配。</p></blockquote><h3 id="动态分派与重写"><a class="header-anchor" href="#动态分派与重写">¶</a>动态分派与重写</h3><pre class="line-numbers language-language-java"><code class="language-language-java">package demo;/** * 方法动态分派演示 */public class DynamicDispatch {    static abstract class Human {        protected abstract void sayHello();    }    static class Man extends Human {        @Override        protected void sayHello() {            System.out.println("man say hello");        }    }    static class Woman extends Human {        @Override        protected void sayHello() {            System.out.println("woman say hello");        }    }    public static void main(String[] args) {        Human man = new Man();        Human woman = new Woman();        man.sayHello();        woman.sayHello();        man = new Woman();        man.sayHello();    }}//运行结果//man say hello//woman say hello//woman say hello<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面是字节码指令，0到15步分别new了Man和Woman对象并存储到了本地变量表的1和2位置，16到21分别加载对应的对象引用到操作数栈顶，然后调用invokevirtual指令取操作数栈顶引用进行虚方法调用：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234139.png" alt="image-20200922092619242"></p><p>invokevirtual指令的运行时解析过程大致分为以下几步:</p><ol><li><p>找到操作数栈顶的第一个元素所指向的对象的实际类型,记作C。</p></li><li><p>如果在类型C中找到与常量中的描述符和简单名称都相符的方法,则进行访问权限校验,如果通过则返回这个方法的直接引用,查找过程结束;不通过则返回<code>java.lang.IllegalAccessError</code>异常。</p></li><li><p>否则,按照继承关系从下往上依次对C的各个父类进行第二步的搜索和验证过程。</p></li><li><p>如果始终没有找到合适的方法,则抛出<code>java.lang.AbstractMethodError</code>异常。</p><blockquote><p>优化：由于在面向对象的编程中，会很频繁的使用到动态分派，如果在每次动态分派的过程中都要重新在类的方法元数据中搜索合适的目标的话就可能印象到执行效率。因此，为了提高性能，JVM采用在class对象的内存区域中建立一个<strong>虚方法表(virtual method table)</strong>(非虚方法不会出现在表中)来实现，使用索引表来代替查找，借助数组利用到CPU的缓存已经减少寻址次数。</p><p>该虚方法表中存放着<strong>当前class的所有方法引用</strong>，如果有重写了父类的方法，则保存的是重写的方法引用；如果有未重写父类的方法，则保存的是父方法的引用。</p><p>虚方法表会在类加载的链接(第三阶段-解析)阶段被创建并开始初始化，类的变量初始值准备完成之后，JVM会把该类的方法表也初始化完毕。</p></blockquote></li></ol><p><strong>正是因为invokevirtual指令执行的第一步就是在运行期确定接收者的实际类型</strong>,所以两次调用中的invokevirtual指令并不是把常量池中方法的符号引用解析到直接引用上就结束了,还会根据方法接收者的实际类型来选择方法版本,这个过程就是Java语言中方法重写的本质。我们把这种在运行期根据实际类型确定方法执行版本的分派过程称为动态分派。</p><h4 id="方法动态分派以及继承体系下同名字段的问题"><a class="header-anchor" href="#方法动态分派以及继承体系下同名字段的问题">¶</a>方法动态分派以及继承体系下同名字段的问题</h4><pre class="line-numbers language-language-java"><code class="language-language-java">package demo;/** * 字段不参与多态 */public class FieldHasNoPolymorphic {    static class Father {        public int money = 1;        public Father() {            money = 2;            showMeTheMoney();        }        public void showMeTheMoney() {            System.out.println("I am Father, i have $" + money);        }    }    static class Son extends Father {        public int money = 3;        public Son() {            money = 4;            showMeTheMoney();        }        @Override        public void showMeTheMoney() {            System.out.println("I am Son,  i have $" + money);        }    }    public static void main(String[] args) {        Father gay = new Son();        System.out.println("This gay has $" + gay.money);    }}//输出//I am Son,  i have $0//I am Son,  i have $4//This gay has $2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面两句输出&quot;I am Son&quot;，说明<code>showMeTheMoney()</code>方法都是调用到了Son的方法，此时方法栈中本地变量表第一个槽位压入的就是Son对象的引用，而第一句接着输出&quot;i have $0&quot;说明在<code>Father()</code>构造函数中money的赋值动作是赋值到了Father对象，因为此时<code>Son#showMeTheMoney()</code>中<code>money</code>(即<code>this.money</code>)得到的值是0，因为<code>Son#money</code>还没有初始化。</p><p>这就奇怪了，对于<code>showMeTheMoney()</code>方法能调用到子类的方法这个还好理解，只能说在子类构造函数中对父类构造函数调用时，父类构造函数中栈帧的本地变量表压入的this是子类对象引用。但是为什么对于<code>money</code>的访问(即对字段的访问)又是访问到父类的呢？下面是父类<code>&lt;init&gt;</code>方法的字节码，可以看到在<code>putfield</code>和<code>invokevirtual</code>之前都有一个<code>aload_0</code>指令加载this到操作数栈的，难道<code>putfield</code>之类对于字段访问的指令的相关<code>aload_0</code>都是无意义的？关于这个有待后面研究了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234146.png" alt="image-20200922093825364"></p><h3 id="单分派和多分派"><a class="header-anchor" href="#单分派和多分派">¶</a>单分派和多分派</h3><p><strong>方法的接收者(invokevirtual或者invokeinterface之前通过aload_0加载到的对象引用)<strong>与</strong>方法的参数</strong>统称为方法的宗量,这个定义最早应该来源于著名的《Java与模式》一书。根据分派基于多少种宗量,可以将分派划分为单分派和多分派两种。单分派是根据一个宗量对目标方法进行选择,多分派则是根据多于一个宗量对目标方法进行选择。</p><p>Java的<strong>静态分派是在编译阶段，根据方法所属的类的静态类型以及方法参数列表中的静态类型进行方法分派</strong>，涉及两个宗量，所以属于多分派。</p><p>在运行阶段中的动态分派过程，执行到<code>invokevirtual</code>指令的时候，<strong>此时虚拟机只关心方法所属的类的实际类型</strong>，所以只有一个宗量作为选择依据，所以属于单分派。</p><p>综上，称目前Java语言是一门静态多分派、动态单分派语言。</p><h3 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h3><p><strong>可以认为解析调用和分派调用是对立的，一个方法只能是其中的一种调用方式。</strong></p><p><strong>静态分派和动态分派是合作关系，它们是分派调用的两个阶段，来共同确定最终要调用的方法是哪一个。</strong></p><h1>动态类型语言支持</h1><h2 id="动态语言"><a class="header-anchor" href="#动态语言">¶</a>动态语言</h2><p>何谓动态类型语言<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>?动态类型语言的关键特征是它的类型检查的主体过程是在运行期而不是编译期进行的,满足这个特征的语言有很多,常用的包括:APL、Clojure、Erlang、Groovy、JavaScript、Lisp、Lua、PHP、Prolog、Python、Ruby、Smalltalk、Tcl,等等。那相对地,在编译期就进行类型检查过程的语言,譬如C++和Java等就是最常用的静态类型语言。</p><p>对于Java 来说，下面的代码合法性很明显。对于代码片段2正是说明了Java语言会在编译期做类型检查，导致该段代码编译不通过</p><pre class="line-numbers language-language-java"><code class="language-language-java">//片段1：不合法PrintStream obj = new Object();obj.println("hello world");//片段2：合法PrintStream obj = System.out;obj.println("hello world");<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但是在ECMAScript(JavaScript)中情况则不一样,无论obj具体是何种类型,无论其继承关系如何,只要这种类型的方法定义中确实包含有println(String)方法,能够找到相同签名的方法,调用便可成功。</p><pre class="line-numbers language-language-javascript"><code class="language-language-javascript">//片段2：合法var obj = System.out;obj.println("hello world");<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>产生这种差别产生的根本原因是Java语言在编译期间却已将println(String)方法完整的符号引用(本例中为一项CONSTANT_InterfaceMethodref_info常量)生成出来,并作为方法调用指令的参数存储到Class文件中,例如下面这个样子:</p><pre class="line-numbers language-language-java"><code class="language-language-java">invokevirtual #4; //Method java/io/PrintStream.println:(Ljava/lang/String;)V<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>#4</code>表示字节码常量池中的第4项常量，这个常量必定是一个&quot;CONSTANT_InterfaceMethodref_info&quot;方法符号引用，这个符号引用包含了该方法定义在哪个具体类型之中、方法的名字以及参数顺序、参数类型和方法返回值等信息,通过这个符号引用,Java虚拟机就可以翻译出该方法的直接引用。</p><p>而ECMAScript等动态类型语言与Java有一个核心的差异就是变量obj本身并没有类型,变量obj的值才具有类型,所以编译器在编译时最多只能确定方法名称、参数、返回值这些信息,而不会去确定方法所在的具体类型(即方法接收者不固定)。“变量无类型而变量值才有类型”这个特点也是动态类型语言的一个核心特征。</p><p>它们都有自己的优点,选择哪种语言是需要权衡的事情。静态类型语言能够在编译期确定变量类型,最显著的好处是编译器可以提供全面严谨的类型检查,这样与数据类型相关的潜在问题就能在编码时被及时发现,利于稳定性及让项目容易达到更大的规模。而动态类型语言在运行期才确定类型,这可以为开发人员提供极大的灵活性,某些在静态类型语言中要花大量臃肿代码来实现的功能,由动态类型语言去做可能会很清晰简洁,清晰简洁通常也就意味着开发效率的提升。</p><h2 id="Java与动态类型"><a class="header-anchor" href="#Java与动态类型">¶</a>Java与动态类型</h2><p>Java虚拟机层面对动态类型语言的支持一直都还有所欠缺,主要表现在方法调用方面:JDK 7以前的字节码指令集中,4条方法调用指令(invokevirtual、invokespecial、invokestatic、invokeinterface)的第一个参数都是<strong>被调用的方法的符号引用</strong>(CONSTANT_Methodref_info或者CONSTANT_InterfaceMethodref_info常量), <strong>方法的符号引用在编译时产生</strong>, <strong>而动态类型语言是在运行期才确定的</strong>。</p><h2 id="java-lang-invoke包"><a class="header-anchor" href="#java-lang-invoke包">¶</a>java.lang.invoke包</h2><p>JDK 7时新加入的java.lang.invoke包是JSR 292的一个重要组成部分,这个包的主要目的是在之前单纯依靠符号引用来确定调用的目标方法这条路之外,提供一种新的动态确定目标方法的机制,称为“方法句柄”(Method Handle)。与C/C++中的函数指针(Function Pointer),或者C#里面的委派(Delegate)，如：</p><pre class="line-numbers language-language-c++"><code class="language-language-c++">void sort(int list[], const int size, int (*compare)(int, int))<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>但在Java语言中做不到这一点,没有办法单独把一个函数作为参数进行传递。普遍的做法是设计一个带有compare()方法的Comparator接口,以实现这个接口的对象作为参数,例如Java类库中的<code>Collections::sort()</code>方法就是这样定义的:</p><pre class="line-numbers language-language-java"><code class="language-language-java">void sort(List list, Comparator c)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>不过,在拥有方法句柄之后,Java语言也可以拥有类似于函数指针或者委托的方法别名这样的工具了：</p><pre class="line-numbers language-language-java"><code class="language-language-java">package demo;import java.lang.invoke.MethodHandle;import java.lang.invoke.MethodHandles;import java.lang.invoke.MethodType;/** * JSR 292 MethodHandle基础用法演示 * @author zzm */public class MethodHandleTest {    static class ClassA {        public void println(String s) {            System.out.println(s);        }    }    public static void main(String[] args) throws Throwable {        Object obj = System.currentTimeMillis() % 2 == 0 ? System.out : new ClassA();        // 无论obj最终是哪个实现类,下面这句都能正确调用到println方法。        getPrintlnMH(obj).invokeExact("icyfenix");    }    private static MethodHandle getPrintlnMH(Object reveiver) throws Throwable {        // MethodType:代表“方法类型”,包含了方法的返回值(methodType()的第一个参数)和 具体参数(methodType()第二个及以后的参数)。        MethodType mt = MethodType.methodType(void.class, String.class);        // lookup()方法来自于MethodHandles.lookup,这句的作用是在指定类中查找符合给定的方法名称、方法类型,并且符合调用权限的方法句柄。        // 因为这里调用的是一个虚方法,按照Java语言的规则,方法第一个参数是隐式的,代表该方法的接收者,也即this指向的对象,这个参数以前是放在参数列表中进行传递,现在提供了bindTo()方法来完成这件事情。        return MethodHandles.lookup().findVirtual(reveiver.getClass(), "println", mt).bindTo(reveiver);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上代码中无论obj是何种类型(临时定义的ClassA抑或是实现PrintStream接口的实现类System.out),都可以正确调用到println()方法。</p><p>仅站在Java语言的角度看,MethodHandle在使用方法和效果上与Reflection有众多相似之处。不过,它们也有以下这些区别:</p><ul><li><p>Reflection和MethodHandle机制本质上都是在模拟方法调用,但是Reflection是在模拟Java代码层次的方法调用,而MethodHandle是在模拟字节码层次的方法调用。</p><ul><li><p>在MethodHandles.Lookup上的3个方法findStatic()、findVirtual()、findSpecial()正是为了对应于invokestatic、invokevirtual(以及invokeinterface)和invokespecial这几条字节码指令的执行权限校验行为(即将原本编译期就能确定的符号引用延迟到运行期由用户代码来确定)</p></li><li><p>而这些动作对于Reflection API来说是一个JVM的底层动作，先对于它来说是抽象的，它是不需要关心的。</p></li></ul></li><li><p>Reflection中的java.lang.reflect.Method对象远比MethodHandle机制中的java.lang.invoke.MethodHandle对象所包含的信息来得多。前者是方法在Java端的全面映像,包含了方法的签名、描述符以及方法属性表中各种属性的Java端表示方式,还包含执行权限等的运行期信息。而后者仅包含执行该方法的相关信息。用开发人员通俗的话来讲,Reflection是重量级,而MethodHandle 是轻量级。</p></li><li><p>由于MethodHandle是对字节码的方法指令调用的模拟,那理论上虚拟机在这方面做的各种优化(如方法内联),在MethodHandle上也应当可以采用类似思路去支持(但目前实现还在继续完善中),而通过反射去调用方法则几乎不可能直接去实施各类调用点优化措施。</p></li></ul><p>MethodHandle与Reflection除了上面列举的区别外,最关键的一点还在于去掉前面讨论施加的前提“仅站在Java语言的角度看”之后:Reflection API的设计目标是只为Java语言服务的,而MethodHandle 则设计为可服务于所有Java虚拟机之上的语言,其中也包括了Java语言而已,而且Java在这里并不是主角。</p><h2 id="invokedynamic指令"><a class="header-anchor" href="#invokedynamic指令">¶</a>invokedynamic指令</h2><p>JDK 7为了更好地支持动态类型语言引入了第五条方法调用的字节码指令invokedynamic, 将MethodHandle的示例代码反编译后并没有找到invokedynamic的身影,invokedynamic到底有什么应用呢? 某种意义上可以说invokedynamic指令与MethodHandle机制的作用是一样的,都是为了解决原有4 条“invoke*”指令方法分派规则完全固化在虚拟机之中的问题：<strong>把如何查找目标方法的决定权从虚拟机转嫁到具体用户代码之中,让用户(广义的用户,包含其他程序语言的设计者)有更高的自由度。<strong>而且,它们两者的思路也是可类比的,都是为了达成同一个目的,只是</strong>一个用上层代码和API来实现</strong>, <strong>另一个用字节码和Class中其他属性、常量来完成</strong>。</p><p>每一处含有invokedynamic指令的位置都被称作“动态调用点(Dynamically-Computed Call Site)”, 这条指令的第一个参数不再是代表方法符号引用的CONSTANT_Methodref_info常量,而是变为JDK 7 时新加入的<strong>CONSTANT_InvokeDynamic_info</strong>常量,从这个新常量中可以得到3项信息:</p><ol><li><p>引导方法(Bootstrap Method,该方法存放在新增的BootstrapMethods属性中)</p><p>引导方法是有固定的参数,并且返回值规定是<code>java.lang.invoke.CallSite</code>对象,这个对象代表了真正要执行的目标方法调用</p></li><li><p>方法类型(MethodType)</p></li><li><p>方法名称。</p></li></ol><p>根据<strong>CONSTANT_InvokeDynamic_info</strong>常量中提供的信息,虚拟机可以找到并且执行引导方法,从而获得一个CallSite对象,最终调用到要执行的目标方法上（其实目前引导方法里面的实现还是最终会调到invoke包里面的api进行方法查找，然后将得到<code>MethodHandle</code>对象包装称一个<code>CallSite</code>）。下面例子说明<code>invokedynamic</code>指令的工作过程：</p><h3 id="例1：自定义字节码查找方法逻辑"><a class="header-anchor" href="#例1：自定义字节码查找方法逻辑">¶</a>例1：自定义字节码查找方法逻辑</h3><p>利用JDK源码中的一个字节码转换工具将特定格式的源文件的字节码生成一个包含<code>invokedynamic</code>指令的新的字节码。</p><p>以下是特定的源文件，先对它进行javac编译得到一个class文件</p><pre class="line-numbers language-language-java"><code class="language-language-java">package demo.dynamic;import java.lang.invoke.*;public class InvokeDynamicTest {    public static void main(String[] args) throws Throwable {        INDY_BootstrapMethod().invokeExact("icyfenix");    }    //真正要执行的方法    public static void testMethod(String s) {        System.out.println("hello String:" + s);    }    //Boostrap方法，由Boostrap属性表中的属性指定    public static CallSite BootstrapMethod(MethodHandles.Lookup lookup, String name, MethodType mt) throws Throwable {        return new ConstantCallSite(lookup.findStatic(InvokeDynamicTest.class, name, mt));    }    //获取方法描述符    private static MethodType MT_BootstrapMethod() {        return MethodType.fromMethodDescriptorString("(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;", null);    }    //获取引导方法的句柄    private static MethodHandle MH_BootstrapMethod() throws Throwable {        return MethodHandles.lookup().findStatic(InvokeDynamicTest.class, "BootstrapMethod", MT_BootstrapMethod());    }    //先获取引导方法的句柄，然后通过引导方法获取真正要执行方法的句柄，这个就是自定义寻找方法的实现，只不过这里放在了字节码层面来做，也就是说寻找逻辑可能在字节码层面就确定了，将无法在编译成字节码之前的源文件中定义逻辑，该逻辑一般由一门JVM语言来实现    private static MethodHandle INDY_BootstrapMethod() throws Throwable {        CallSite cs = (CallSite) MH_BootstrapMethod().invokeWithArguments(MethodHandles.lookup(), "testMethod", MethodType.fromMethodDescriptorString("(Ljava/lang/String;)V", null));        return cs.dynamicInvoker();    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后在OpenJDK源码的<code>${SOURCE_CODE_HOME}/jdk/test/java/lang/invoke/indify/Indify.java</code>下面找到<code>Indify</code>工具类，然后复制出来，编写以下代码主动调用该工具类的<code>main</code>方法或者<code>java</code>执行也可以，在参数中分别指定要转换的class文件的路径(即上面编译得到的文件)以及转换的class文件的存放路径</p><pre class="line-numbers language-language-java"><code class="language-language-java">package demo.dynamic;import java.io.IOException;/** * @author: honphan.john * @date: 2020/9/22 12:28 * @description: */public class Test {    public static void main(String[] args) throws IOException {        System.out.println("main");        Indify.main("--verify-specifier-count=1",                /*INDY工具将Example.class转换成等效的class文件存放路径*/                "--dest=/Users/zhonghongpeng/IdeaProjects/tech-learning/jvm/target/classes/indy",                "--verbose",                "--expand-properties", "--classpath", "${java.class.path}",                /*输入class文件Example.class的全路径,然后使用javap打开该文件*/                "/Users/zhonghongpeng/IdeaProjects/tech-learning/jvm/target/classes/demo/dynamic/InvokeDynamicTest.class");        //Example.main();    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行转换后，进入新的class文件所在目录，<code>java</code>执行新的class文件，可得到指定输出，<code>testMethod()</code>得到执行</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">zhonghongpeng@bogon dynamic % java -cp /Users/zhonghongpeng/IdeaProjects/tech-learning/jvm/target/classes/indy demo.dynamic.InvokeDynamicTesthello String:icyfenix<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>下面分析新转换后的字节码是如何通过<code>invokedynamic</code>指令工作的：</p><p>首先可以看到的是在main方法中存在了一条<code>invokedynamic</code>指令，该指令指向了索引为124的常量池项。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234203.png" alt="image-20200922130539186"></p><p>通过查看124项常量为<code>CONSTANT_InvokeDynamic_info</code>：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234210.png" alt="image-20200922130731119"></p><p>其结构为：</p><table><thead><tr><th>结构成员长度</th><th>结构成员类型</th><th>结构成员描述</th></tr></thead><tbody><tr><td>u1</td><td>tag</td><td>值为18</td></tr><tr><td>u2</td><td>bootstrap_method_attr_index</td><td>值必须是对当前class文件中引导方法表的bootstrap_method[]数组的有效索引</td></tr><tr><td>u2</td><td>name_and_type_index</td><td>值必须是对当前常量池的有效索引，常量池在该索引处的项必须是CONSTANT_NameAndType_info结构，表示方法名称和方法描述符</td></tr></tbody></table><p>查看该常量内容：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234217.png" alt="image-20200922131138608"></p><p><strong>可以看到name_and_type指向的CONSTANT_NameAndType_info结构描述的正是我们要动态寻找的方法<code>testMethod</code></strong>，然后进一步查看Class文件的bootstrap_method属性表中的第0项内容，发现该项属性值为<code>#120</code>，指向了常量池中的一项<code>CONSTANT_Methodhandle_info</code>常量：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234221.png" alt="image-20200922131414368"></p><p>查看该常量，它引用了<code>#119</code>项<code>CONSTATN_Methodref_info</code>常量：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234230.png" alt="image-20200922131742684"></p><p>该<code>CONSTATN_Methodref_info</code>常量为：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234238.png" alt="image-20200922131954731"></p><p>可以看到，它引用的就是测试代码中寻找方法<code>testMethod()</code>的句柄的方法<code>INDY_BootstrapMethod</code>。</p><p>综上可以直到<code>invokedynmaic</code>方法可以通过<code>CONSTANT_Invokedynamic_info</code>常量中包含的对&quot;被查找方法的符号引用常量&quot;以及&quot;查找方法逻辑的引导方法符号引用常量&quot;一起实现动态地查找方法。</p><h3 id="例2：lambda查找方法逻辑"><a class="header-anchor" href="#例2：lambda查找方法逻辑">¶</a>例2：lambda查找方法逻辑</h3><p>来看下以下代码的字节码是怎么使用<code>invokedynamic</code>的</p><pre class="line-numbers language-language-java"><code class="language-language-java">package demo.dynamic;/** * @author: honphan.john * @date: 2020/9/22 11:36 * @description: */public class LambdaTest {    interface PrintTool {        void println(String s);    }    public static void main(String[] args) {        PrintTool printTool = System.out::println;        printTool.println("icyfenix");    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>直接查看main方法字节码，看到了<code>invokedynamic</code>指令</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234248.png" alt="image-20200922132952160"></p><p>查看它引用的<code>#4</code>号<code>CONSTANT_Invokedynamic_info</code>常量项，可以看到此时内容和我们上面看到的不太一样了：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234253.png" alt="image-20200922133015064"></p><p>进一步查看<code>#35</code>号<code>CONSTANT_NameAndType_info</code>常量项，发现，此时该常量项指向了一个名为&quot;println&quot;、参数为<code>java.io.PrintStream</code>、返回值为<code>demo.dynamic.LambdaTest$PrintTool</code>的方法</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234302.png" alt="image-20200922133029845"></p><p>然后查看bootstrapmethod属性第0项，查找的是<code>java.io.PrintStream#println</code>方法</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234309.png" alt="image-20200922133134602"></p><p>另外我们看到最关键的<strong>Bootstrap Method为：<code>java.lang.invoke.LambdaMetafactory#metafactory</code></strong>，代码如下：</p><pre class="line-numbers language-language-java"><code class="language-language-java">    public static CallSite metafactory(MethodHandles.Lookup caller,                                       String invokedName,                                       MethodType invokedType,                                       MethodType samMethodType,                                       MethodHandle implMethod,                                       MethodType instantiatedMethodType)            throws LambdaConversionException {        AbstractValidatingLambdaMetafactory mf;        mf = new InnerClassLambdaMetafactory(caller, invokedType,                                             invokedName, samMethodType,                                             implMethod, instantiatedMethodType,                                             false, EMPTY_CLASS_ARRAY, EMPTY_MT_ARRAY);        mf.validateMetafactoryArgs();        return mf.buildCallSite();    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>也就是说，Java8的lambda是通过该方法来动态寻找方法句柄的。</p><h2 id="实战运行运用"><a class="header-anchor" href="#实战运行运用">¶</a>实战运行运用</h2><pre class="line-numbers language-language-java"><code class="language-language-java">package demo;import java.lang.invoke.MethodHandle;import java.lang.invoke.MethodHandles;import java.lang.invoke.MethodType;import java.lang.reflect.Field;/** * @author: honphan.john * @date: 2020/9/22 14:24 * @description: */public class DynamicPractise {    static class GrandFather {        void thinking() {            System.out.println("i am grandfather");        }    }    static class Father extends GrandFather {        @Override        void thinking() {            System.out.println("i am father");        }    }    static class Son extends Father {        /**         * 请读者在这里填入适当的代码(不能修改其他地方的代码)实现调用祖父类的thinking()方法,打印"i am grandfather"         */        @Override        void thinking() {            //JDK 7 Update 9之前            try {                MethodType mt = MethodType.methodType(void.class);                MethodHandle mh = MethodHandles.lookup().findSpecial(GrandFather.class, "thinking", mt, getClass());                mh.invoke(this);            } catch (Throwable e) {            }            /*            在JDK 7 Update 10之后            这个逻辑在JDK 7 Update 9之后被视作一个潜在的安全性缺陷修正了,原因是必须保证findSpecial()查找方法版本时受到的访问约束(譬如对访问控制的限制、对参数类型的限制)            应与使用invokespecial指令一样,两者必须保持精确对等,包括在上面的场景中它只能访问到其直接父类中的方法版本。            */            try {                MethodType mt = MethodType.methodType(void.class);                Field lookupImpl = MethodHandles.Lookup.class.getDeclaredField("IMPL_LOOKUP");                lookupImpl.setAccessible(true);                MethodHandle mh = ((MethodHandles.Lookup) lookupImpl.get(null)).findSpecial(GrandFather.class, "thinking", mt, GrandFather.class);                mh.invoke(this);            } catch (Throwable e) {            }        }    }    public static void main(String[] args) {        new Son().thinking();    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>注意,动态类型语言与动态语言、弱类型语言并不是一个概念,需要区别对待。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java-JVM-操作系统线程模型</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/xian-cheng-mo-xing/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/xian-cheng-mo-xing/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM 附录</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/fu-lu/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/fu-lu/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1>附录</h1><h2 id="JVM大图"><a class="header-anchor" href="#JVM大图">¶</a>JVM大图</h2><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232740.png" alt="Java-jvm"></p><h2 id="JVM参数"><a class="header-anchor" href="#JVM参数">¶</a>JVM参数</h2><p>在jvm中有很多的参数可以进行设置,这样可以让JVM在各种环境中都能够高效的运行。绝大部分的参数保持默认即可。</p><h3 id="参数类型"><a class="header-anchor" href="#参数类型">¶</a>参数类型</h3><p>JVM的参数类型分为三类,分别是:</p><ol><li><code>-</code>前缀标准参数，如<code>-help</code>、<code>-version</code></li><li><code>-X</code>前缀参数 (非标准参数)，如：<code> -Xint</code>、<code>-Xcomp</code></li><li><code>-XX:</code>前缀参数(使用率较高)，如：<code>-XX:newSize</code>、<code> -XX:+UseSerialGC</code></li></ol><h4 id="标准参数"><a class="header-anchor" href="#标准参数">¶</a>标准参数</h4><p>jvm的标准参数,一般都是很稳定的,在未来的JVM版本中不会改变,可以使用<code>java -help</code>检索出所有的标准参数。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">zhonghongpeng@bogon classes % java -help                             用法: java [-options] class [args...]           (执行类)   或  java [-options] -jar jarfile [args...]           (执行 jar 文件)其中选项包括:    -d32          使用 32 位数据模型 (如果可用)    -d64          使用 64 位数据模型 (如果可用)    -server       选择 "server" VM                  默认 VM 是 server,                  因为您是在服务器类计算机上运行。    -cp <目录和 zip/jar 文件的类搜索路径>    -classpath <目录和 zip/jar 文件的类搜索路径>                  用 : 分隔的目录, JAR 档案                  和 ZIP 档案列表, 用于搜索类文件。    -D<名称>=<值>                  设置系统属性    -verbose:[class|gc|jni]                  启用详细输出    -version      输出产品版本并退出    -version:<值>                  警告: 此功能已过时, 将在                  未来发行版中删除。                  需要指定的版本才能运行    -showversion  输出产品版本并继续    -jre-restrict-search | -no-jre-restrict-search                  警告: 此功能已过时, 将在                  未来发行版中删除。                  在版本搜索中包括/排除用户专用 JRE    -? -help      输出此帮助消息    -X            输出非标准选项的帮助    -ea[:<packagename>...|:<classname>]    -enableassertions[:<packagename>...|:<classname>]                  按指定的粒度启用断言    -da[:<packagename>...|:<classname>]    -disableassertions[:<packagename>...|:<classname>]                  禁用具有指定粒度的断言    -esa | -enablesystemassertions                  启用系统断言    -dsa | -disablesystemassertions                  禁用系统断言    -agentlib:<libname>[=<选项>]                  加载本机代理库 <libname>, 例如 -agentlib:hprof                  另请参阅 -agentlib:jdwp=help 和 -agentlib:hprof=help    -agentpath:<pathname>[=<选项>]                  按完整路径名加载本机代理库    -javaagent:<jarpath>[=<选项>]                  加载 Java 编程语言代理, 请参阅 java.lang.instrument    -splash:<imagepath>                  使用指定的图像显示启动屏幕有关详细信息, 请参阅 http://www.oracle.com/technetwork/java/javase/documentation/index.html。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="X参数"><a class="header-anchor" href="#X参数">¶</a>-X参数</h4><p>JVM的<code>-X</code>参数是非标准参数,在不同版本的JVM中,参数可能会有所不同,可以通过<code>java -X</code>查看非标准参数。</p><pre class="line-numbers language-language-java"><code class="language-language-java">zhonghongpeng@bogon classes % java -X                                    -Xmixed           混合模式执行 (默认)    -Xint             仅解释模式执行    -Xbootclasspath:<用 : 分隔的目录和 zip/jar 文件>                      设置搜索路径以引导类和资源    -Xbootclasspath/a:<用 : 分隔的目录和 zip/jar 文件>                      附加在引导类路径末尾    -Xbootclasspath/p:<用 : 分隔的目录和 zip/jar 文件>                      置于引导类路径之前    -Xdiag            显示附加诊断消息    -Xnoclassgc       禁用类垃圾收集    -Xincgc           启用增量垃圾收集    -Xloggc:<file>    将 GC 状态记录在文件中 (带时间戳)    -Xbatch           禁用后台编译    -Xms<size>        设置初始 Java 堆大小    -Xmx<size>        设置最大 Java 堆大小    -Xss<size>        设置 Java 线程堆栈大小    -Xprof            输出 cpu 配置文件数据    -Xfuture          启用最严格的检查, 预期将来的默认值    -Xrs              减少 Java/VM 对操作系统信号的使用 (请参阅文档)    -Xcheck:jni       对 JNI 函数执行其他检查    -Xshare:off       不尝试使用共享类数据    -Xshare:auto      在可能的情况下使用共享类数据 (默认)    -Xshare:on        要求使用共享类数据, 否则将失败。    -XshowSettings    显示所有设置并继续    -XshowSettings:all                      显示所有设置并继续    -XshowSettings:vm 显示所有与 vm 相关的设置并继续    -XshowSettings:properties                      显示所有属性设置并继续    -XshowSettings:locale                      显示所有与区域设置相关的设置并继续-X 选项是非标准选项, 如有更改, 恕不另行通知。以下选项为 Mac OS X 特定的选项:    -XstartOnFirstThread                      在第一个 (AppKit) 线程上运行 main() 方法    -Xdock:name=<应用程序名称>"                      覆盖停靠栏中显示的默认应用程序名称    -Xdock:icon=<图标文件的路径>                      覆盖停靠栏中显示的默认图标<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="XX参数"><a class="header-anchor" href="#XX参数">¶</a>-XX参数</h4><p><code>-XX</code>参数也是非标准参数,主要用于JVM的调优和debug操作。</p><p><code>-XX</code>参数的使用有2种方式,一种是boolean类型,一种是非boolean类型:</p><ul><li>boolean类型<ul><li>格式：<code>-XX:[+-]</code></li><li>如：<code>-XX:+DisableExplicitGC</code>表示禁用手动调用gc操作,也就是说调用<code>System.gc()</code>无效</li></ul></li><li>非boolean类型<ul><li>格式：<code>-XX:</code></li><li>如：<code>-XX:NewRatio=1</code> 表示新生代和老年代的比值</li></ul></li></ul><h3 id="常用参数参考附录"><a class="header-anchor" href="#常用参数参考附录">¶</a>常用参数参考附录</h3><pre class="line-numbers language-language-shell"><code class="language-language-shell">指定虚拟机以解释模式运行-Xint指定虚拟机以编译模式运行-Xcomp解释+编译模式运行，默认-Xmixed设置系统属性-D<名称>=<值>以服务器模式运行-server以客户端模式运行-client设置栈空间大小-Xss128k自旋锁升级前最大次数-XX:PreBlockSpin自旋锁开关-XX:-UseBiasedLocking=falsejvm 启动自旋锁立即激活-XX:BiasedLockingStartupDelay=0-XX:MaxMetaspaceSize:设置元空间最大值,默认是-1,即不限制,或者说只受限于本地内存大小。-XX:MetaspaceSize:指定元空间的初始空间大小,以字节为单位,达到该值就会触发垃圾收集进行类型卸载,同时收集器会对该值进行调整:如果释放了大量的空间,就适当降低该值;如果释放了很少的空间,那么在不超过-XX:MaxMetaspaceSize(如果设置了的话)的情况下,适当提高该值。-XX:MinMetaspaceFreeRatio:作用是在垃圾收集之后控制最小的元空间剩余容量的百分比,可减少因为元空间不足导致的垃圾收集的频率。类似的还有-XX:Max-MetaspaceFreeRatio,用于控制最大的元空间剩余容量的百分比。-Xnoclassgc参数进行控制是否允许对方法区内方法信息进行垃圾回收,还可以使用-verbose:class以及-XX:+TraceClass-Loading、-XX:+TraceClassUnLoading查看类加载和卸载信息,其中-verbose:class和-XX:+TraceClassLoading可以在Product版的虚拟机中使用,-XX:+TraceClassUnLoading参数需要FastDebug版的虚拟机支持。显式开启逃逸分析-XX:+DoEscapeAnalysis查看逃逸分析的筛选结果-XX:+PrintEscapeAnalysis是否开启栈上分配-XX:+/-UseTLAB开启同步省略-XX:+EliminateLocks开启标量替换-XX:+EliminateAllocations查看替换情况-XX:+PrintEliminateAllocations代码执行次数会被JIT优化编译-XX:CompileThreshold = 10000 计算因子-XX:OnStackReplacePercentage = 140-XX:InterpreterProfilePercentage = 33客户端下某段循环体中的代码循环次数会被JIT优化编译(回边计数器阈值) = CompileThreshold * OnStackReplacePercentage / 100服务端下某段循环体中的代码循环次数会被JIT优化编译(回边计数器阈值) = (CompileThreshold * (OnStackReplacePercentage - InterpreterProfilePercentage)) / 100 = 10700关闭JIT代码运行计数器热度衰减-XX:-UseCounterDecay参数设置半衰周期的时间(代码空闲多少秒进行半衰)，单位是秒-XX:CounterHalfLife=<N>禁止后台线程编译，执行线程阻塞等待编译结果，得到结果后再执行编译得到的本地代码-XX:-BackgroundCompilation打印所有的参数默认初始值-XX:+PrintFlagsInitial打印所有的参数的实际值，输出赋值操作符有=或:=,分别代表默认值和被修改的值。-XX:+PrintFlagsFinal# 在JVM运行期间查看设置参数步骤：# 1. jps：查看当前运行中的进程id# 2. jinfo -flag SurvivorRatio 进程id：查看具体JVM进程的指定参数值初始化堆空间内存（默认为物理内存的1/64）-Xms128m最大堆空间内存（默认为物理内存的1/4）-Xmx128m设置新生代大小（初始值及最大值）-Xmn128m配置新生代与老年代在堆结构的占比-XX:NewRatio=3设置新生代中Eden和S0/S1空间的比例-XX:SurvivorRatio=4设置新生代垃圾的最大年龄-XX:MaxTenuringThreshold=15设置多大的对象直接进入老年代，默认值为0，代表不管多大都是先在Eden中分配内存-XX:PretenureSizeThreshold=0输出详细的GC处理日志-XX:+PrintGCDetails打印GC简要信息-XX:+PrintGC、-verbose:gc设置是否空间分配担保-XX:HandlePromotionFailure在退出的时候打印StringTable的信息-XX:+PrintStringTableStatistics# 开启G1 string去重,默认是不开启的,需要手动开启。-XX:+/-UseStringDeduplication# 打印详细的去重统计信息-XX:+/-PrintStringDeduplicationStatistics# 达到这个年龄的 string对象被认为是去重的候选对象-XX:StringDeduplicationAgeThreshold=<N># 开启先检查记忆集卡表是否已经变脏然后再更新卡表-XX:+UseCondCardMark# 开启指针压缩。ZGC不可用-XX: +UseCompressedOops# 解锁诊断性质的VM参数、打印汇编代码-XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly # 出现 OOME 时生成堆 dump:-XX:+HeapDumpOnOutOfMemoryError# 生成堆文件地址: -XX:HeapDumpPath=/home/hadoop/dump/# 使用[Ctrl]+[Break]键让虚拟机生成堆转储快照文件-XX:+HeapDumpOnCtrlBreak# 查看安全点日志-XX:+PrintSafepointStatistics-XX:PrintSafepointStatisticsCount=1# 让虚拟机在等到线程进入安全点的时间超过2000毫秒时就认定为超时,这样就会输出迟迟无法进入安全点的线程名称-XX: +SafepointTimeout-XX:SafepointTimeoutDelay=2000# 关闭类加载的链接过程中的验证阶段，这个阶段占据大部分时间-Xverify:none# JDK6开启分层编译-XX:+TieredCompilation<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="JDK-9前后日志参数变化"><a class="header-anchor" href="#JDK-9前后日志参数变化">¶</a>JDK 9前后日志参数变化</h3><table><thead><tr><th>JDK9前日志参数</th><th>JDK9后配置形式</th></tr></thead><tbody><tr><td>G1PrintHeapRegions</td><td>Xlog: gc+region=trace</td></tr><tr><td>G1PrintRegionLiveness Info</td><td>Xlog: gc+liveness=trace</td></tr><tr><td>G1Summarize Concmark</td><td>Xlog: gc+marking=trace</td></tr><tr><td>G1SummarizeRSetStats</td><td>Xlog: gc+remset*=trace</td></tr><tr><td>GCLogFileSize, NumberOfGCLogFiles, UseGCLogFileRotation</td><td><code>Xlog: gc*:file&lt;file&gt;::filecount=&lt;count&gt;,filesize=file size in kb&gt;</code></td></tr><tr><td>PrintAdaptiveSizePolicy</td><td>Xlog: gc+ergo*=trace</td></tr><tr><td>PrintClassHistogramAfterFullGC</td><td>Xlog: classhisto*=trace</td></tr><tr><td>PrintClassHistogramBeforeFullGC</td><td>Xlog: classhisto*=trace</td></tr><tr><td>PrintGCApplicationConcurrentTime</td><td>Xlog: safepoint</td></tr><tr><td>PrintGCApplicationStoppedTime</td><td>Xlog: safepoint</td></tr><tr><td>PrintGCDateStamps</td><td>使用time修饰器</td></tr><tr><td>PrintGCTaskTimeStamps</td><td>Xlog: gc+task=trace</td></tr><tr><td>PrintGCtimeStamps</td><td>使用 uptime修饰器</td></tr><tr><td>PrintHeapAtGC</td><td>Xlog: gc+heap=debug</td></tr><tr><td>PrintHeapAtGCExtended</td><td>Xlog: gc+heap=trace</td></tr><tr><td>PrintJNIGCStalls</td><td>Xlog: gc+jni=debug</td></tr><tr><td>PrintOldPLAB</td><td>Xlog: gc+plab=trace</td></tr><tr><td>PrintParallelOldGCPhaseTimes</td><td>Xlog: gc+phases=trace</td></tr><tr><td>PrintPLAB</td><td>Xlog: gc+plab=trace</td></tr><tr><td>PrintPromotionFailure</td><td>Xlog: gc+promotion=debug</td></tr><tr><td>PrintReferenceGC</td><td>Xlog: gc+ref=debug</td></tr><tr><td>PrintStringDeduplicationStatistics</td><td>Xlog: gc+stringdedup</td></tr><tr><td>PrintTaskqueue</td><td>Xlog: gc+task+stats=trace</td></tr><tr><td>PrintTenuringDistribution</td><td>Xlog: gc+age=trace</td></tr><tr><td>PrintTerminationStats</td><td>Xlog: gc+task+stats=debug</td></tr><tr><td>PrintTLAB</td><td>Xlog: gc+tlab=trace</td></tr><tr><td>TraceAdaptiveGCBoundary</td><td>Xlog: heap+ergo=debug</td></tr><tr><td>TraceDynamicGCThreads</td><td>Xlog: gc+task=trace</td></tr><tr><td>TraceMetadataHumongousAllocation</td><td>Xlog: gc+metaspace+alloc=debug</td></tr><tr><td>G1TraceConcRefinement</td><td>Xlog: gc+refine=debug</td></tr><tr><td>G1TraceEagerReclaimHumongousObjects</td><td>Xlog: gc+humongous=debug</td></tr><tr><td>G1TraceStringSymbolTableScrubbing</td><td>Xlog: gc+stringtable=trace</td></tr><tr><td></td><td></td></tr></tbody></table><h3 id="垃圾收集器相关参数"><a class="header-anchor" href="#垃圾收集器相关参数">¶</a>垃圾收集器相关参数</h3><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>UseSerialGC</td><td>虚拟机运行在 Client模式下的默认值,打开此开关后.使用 Serial+ Serial Old的收集器组合进行内存回收</td></tr><tr><td>UseParNewGC</td><td>打开此开关后,使用 Pardew+ Serial Old的收集器组合进行内存回收,在JDK9后不再支持</td></tr><tr><td>UseConcMarkSweepGC</td><td>打开此开关后,使用 Pardew+CMS+ Serial Old的收集器组合进行内存 回收。Serial Old收集器将作为CMS收集器出现“Concurrent Mode Failure&quot; 失败后的后备收集器使用</td></tr><tr><td>UseParallelGC</td><td>JDK9之前虚拟机运行在 Server模式下的默认值,打开此开关后,使用Parallel Scavenge+ Serial Old( PS Marksweep)的收集器组合进行内存回收</td></tr><tr><td>UseParallelOldGC</td><td>打开此开关后,使用 Parallel Scavenge+ Parallel Old的收集器组合进行内存回收</td></tr><tr><td>SurvivorRatio</td><td>新生代中Eden区域与 Survivor区域的容量比值,.默认为8,代表Eden Survivor=8: 1</td></tr><tr><td>PretenureSizeThreshold</td><td>直接晋升到老年代的对象大小,设置这个参数后,大于这个参数的对象将直接在老年代分配</td></tr><tr><td>MaxTenuringThreshold</td><td>晋升到老年代的对象年龄。每个对象在坚持过一次 Minor GC之后,年龄就增加1,当超过这个参数值时就进入老年代</td></tr><tr><td>UseAdaptiveSizePolicy</td><td>动态调整Java堆中各个区域的大小以及进入老年代的年龄</td></tr><tr><td>HandlePromotionFailure</td><td>是否允许分配担保失败,即老年代的剩余空间不足以应付新生代的整个 Eden和 Survivor区的所有对象都存活的极端情况</td></tr><tr><td>ParallelGCThreads</td><td>设置并行GC时进行内存回收的线程数</td></tr><tr><td>GcTimeRatio</td><td>GC时间占总时间的比率,默认值为99,即允许1%的GC时间。仅在使用 Parallel Scavenge收集器时生效</td></tr><tr><td>MaxGCPauseMillis</td><td>设置GC的最大停顿时间。仅在使用 Parallel Scavenge收集器时生效设置</td></tr><tr><td>CMSInitiatingOccupancyFraction</td><td>设置CMS收集器在老年代空间被使用多少后触发垃圾收集。默认值为 68%,仅在使用CMS收集器时生效</td></tr><tr><td>UseCMSCompactAtFullCollection</td><td>设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片整理。仅在使用CMS收集器时生效,此参数从JDK9开始废弃</td></tr><tr><td>CMSFullGCsBeforeCompaction</td><td>设置CMS收集器在进行若干次垃圾收集后再启动一次内存碎片整理。仅在使用CMS收集器时生效,此参数从JDK9开始废弃</td></tr><tr><td>UseG1GC</td><td>使用G1收集器,这个是JDK9后的 Server模式默认值</td></tr><tr><td>G1heapRegionsize=N</td><td>设置 Region大小,并非最终值</td></tr><tr><td>MaxGCPauseMillis</td><td>设置G1收集过程目标时间,默认值是200ms,不是硬性条件</td></tr><tr><td>G1NewSizePereent</td><td>新生代最小值,默认值是5%</td></tr><tr><td>G1MaxNewSizePercent</td><td>新生代最大值,默认值是60%</td></tr><tr><td>ParallelGCThreads</td><td>用户线程冻结期间并行执行的收集器线程数</td></tr><tr><td>ConcGCthreads=N</td><td>并发标记、并发整理的执行线程数,对不同的收集器,根据其能够并发的阶段,有不同的含义</td></tr><tr><td>InitiatingHeapOccupancyPercent</td><td>设置触发标记周期的Java堆占用率國值。默认值是45%。这里的java堆占比指的是 non young capacity bytes,包括 old+humongous</td></tr><tr><td>UseShenandoahGC</td><td>使用 Shenandoah 收集器。这个选项在 Oraclejdk中不被支持,只能在 OPENJDK12或者某些支持 Shenandoah的 Backport发行版本使用。目前仍然要配合<code>-XX:+ UnlockExperimentalVMOptions</code></td></tr><tr><td>ShenandoahGCHeuristics</td><td>使用Shenandoah何时启动一次GC过程,其可选值有 adaptive、 static、 compact、 passive、 aggressive</td></tr><tr><td>UesZGC</td><td>使用ZGC收集器,目前仍然要配合<code>-XX:+ UnlockExperimentalVMOptions</code>使用</td></tr><tr><td>UseNUMA</td><td>启用NUMA内存分配支持,目前只有 Parallel和ZGC支持,以后G1收 集器可能也会支持该选项</td></tr></tbody></table><h3 id="官方网址"><a class="header-anchor" href="#官方网址">¶</a>官方网址</h3><blockquote><p><a href="https://docs.oracle.com/en/java/javase/11/tools/java.html#GUID-3B1CE181-CD30-4178-9602-230B800D4FAE" target="_blank" rel="noopener">https://docs.oracle.com/en/java/javase/11/tools/java.html#GUID-3B1CE181-CD30-4178-9602-230B800D4FAE</a></p><p><a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>08_执行引擎</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/08-zhi-xing-yin-qing/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/08-zhi-xing-yin-qing/</url>
      
        <content type="html"><![CDATA[<h1>一、编译原理</h1><p>如今,基于物理机、Java虚拟机,或者是非Java的其他高级语言虚拟机(HLLVM)的代码执行过程,大体上都会遵循这种符合现代经典编译原理的思路,在执行前先对程序源码进行词法分析和语法分析处理,把源码转化为抽象语法树(Abstract Syntax Tree,AST)。对于一门具体语言的实现来说, 词法、语法分析以至后面的优化器和目标代码生成器都可以选择独立于执行引擎,形成一个完整意义的编译器去实现,这类代表是C/C++语言。也可以选择把其中一部分步骤(如生成抽象语法树之前的步骤)实现为一个半独立的编译器,这类代表是Java语言。又或者把这些步骤和执行引擎全部集中封装在一个封闭的黑匣子之中,如大多数的JavaScript执行引擎。</p><p>在Java语言中,Javac编译器完成了程序代码经过词法分析、语法分析到抽象语法树,再遍历语法树生成线性的字节码指令流的过程。因为这一部分动作是在Java虚拟机之外进行的,而解释器在虚拟机的内部,所以Java程序的编译就是半独立的实现。</p><h1>二、执行引擎概述</h1><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234802.png" alt="image-20200917101306991"></p><p>虚拟机是一个相对于物理机的概念，这两种机器都有代码执行能力，其区别是物理机的执行引擎是直接建立在处理器、缓存、指令集和操作系统层面上的，而虚拟机的执行引擎则是由软件自行实现的，因此可以不受物理条件制约地定制指令集与执行引擎的结构体系，能够执行那些不被硬件直接支持的指令集格式。</p><p>JVM的主要任务是负责装载字节码到其内部，但字节码并不能够直接运行在操作系统之上，因为字节码指令并非等价于本地机器指令，它内部包含的仅仅只是一些能够被JVM所识别的字节码指令、符号表、以及其他辅助信息。</p><p>那么，如果想要让一个Java程序运行起来，执行引擎（Execution Engine）的任务就是将字节码指令解释/编译为对应平台上的本地机器指令才可以。简单来说，JVM中的执行引擎充当了将高级语言翻译为机器语言的译者。</p><h2 id="执行引擎工作"><a class="header-anchor" href="#执行引擎工作">¶</a>执行引擎工作</h2><ol><li>执行引擎在执行的过程中究竟需要执行什么样的字节码指令完全依赖于PC寄存器。</li><li>每当执行完一项指令操作后，PC寄存器就会更新下一条需要被执行的指令地址。</li><li>当然方法在执行的过程中，执行引擎有可能会通过存储在局部变量表中的对象引用准确定位到存储在Java堆区中的对象实例信息，以及通过对象头中的元数据指针定位到目标对象的类型信息。</li></ol><h1>三、Java代码编译和执行过程</h1><p>Java是半编译半解释型语言。JDK1.0时代，将Java语言定位为&quot;解释执行&quot;还是比较准确的。再后来，Java也发展出可以直接生成本地代码的编译器。现在JVM在执行Java代码的时候，通常都会将解释执行与编译执行二者结合起来进行。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234809.png" alt="image-20200917102446107"></p><p>大部分的程序代码转换成物理机的目标代码或虚拟机能执行的指令集之前，都需要经过以上步骤。</p><h2 id="前端编译"><a class="header-anchor" href="#前端编译">¶</a>前端编译</h2><p>Java代码编译由Java源码编译器(javac)来完成：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234815.png" alt="image-20200917102634953"></p><h2 id="后端编译"><a class="header-anchor" href="#后端编译">¶</a>后端编译</h2><p>Java字节码的执行是由JVM执行引擎来完成：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234822.png" alt="image-20200917102821293"></p><h1>四、机器码、指令、汇编语言</h1><h2 id="机器码"><a class="header-anchor" href="#机器码">¶</a>机器码</h2><p>各种用二进制编码方式表示的指令，叫做机器指令码。开始，人们就用它编写程序，这就是机器语言。机器语言虽然能够被计算机理解和接受，但和人们的语言差别太大，不易被人们理解和记忆，并且用它编程容易出错。用它编写的程序一经输入计算机，CPU直接读取运行，因此和其他语言编写的程序相比，执行速度最快。机器指令和CPU紧密相关，所以不同种类的CPU所对应的机器指令也就不同。</p><h3 id="指令"><a class="header-anchor" href="#指令">¶</a>指令</h3><p>表达不同的操作行为和操作数的一条原子机器码即为一条指令，另外不同硬件平台都定义了一些指令助记标准，方便描述和阅读。</p><h3 id="指令集"><a class="header-anchor" href="#指令集">¶</a>指令集</h3><p>不同的硬件平台，各自支持的指令是有差别的。因此每个平台所支持的指令，称之为对应平台的指令集。如常见的：</p><ul><li>x86指令集，对应的是x86架构的平台</li><li>ARM指令集，对应的是ARM架构的平台</li></ul><h3 id="汇编语言"><a class="header-anchor" href="#汇编语言">¶</a>汇编语言</h3><p>在汇编语言中，使用汇编助记符来替代机器指令的操作码，用地址符号(symbol)或标号(Label)代替指令或操作数的地址。相较于机器指令，汇编指令中的操作码都是字面量，操作数都是符号引用；而机器指令都是二进制位。</p><p>在不同的硬件平台，汇编语言对应着不同的机器语言指令集，通过汇编过程转换成机器指令。</p><ul><li>由于计算机只认识指令码，所以用汇编语言写的程序还必须翻译成机器指令码，计算机才能识别和执行。</li></ul><h3 id="高级语言"><a class="header-anchor" href="#高级语言">¶</a>高级语言</h3><p>高级语言比机器语言、汇编语言更接近人的语言。当计算机执行高级语言编写的程序时，仍然需要把程序解释和编译成机器的指令码。完成这个过程的程序就叫做解释程序或编译程序。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234830.png" alt="image-20200917105832983"></p><h3 id="C-C-源程序执行过程"><a class="header-anchor" href="#C-C-源程序执行过程">¶</a>C/C++源程序执行过程</h3><p>编译过程又可以分成两个阶段：编译和汇编</p><ul><li>编译过程：读取源程序（字符流），对之进行词法和语法的分析，将高级语言指令转换成功能等效的汇编代码。</li><li>汇编过程：实际上指把汇编语言代码翻译成目标机器指令的过程。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234836.png" alt="image-20200917110116047"></p><h3 id="字节码"><a class="header-anchor" href="#字节码">¶</a>字节码</h3><p>字节码是一种中间状态（中间码）的二进制代码（文件），它比机器码更抽象，需要直译器转译后才能称为机器码。字节码主要为了实现特定软件运行和软件环境有关、与硬件环境无关。</p><p>字节码的实现方式是通过编译器和虚拟机器。编译器将源码编译成字节码，特定平台上的虚拟机器将字节码转译为可以直接执行的指令。</p><ul><li>字节码的典型应用为Java bytecode</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234842.png" alt="image-20200917110450770"></p><h1>五、解释器</h1><p>当Java虚拟机启动时会根据预定义的规范对字节码采用逐行解释的方式执行，将每条字节码文件中的内容&quot;翻译&quot;为对应平台的本地机器指令执行。当一条字节码指令被解释执行完成后，接着再根据PC寄存器中记录的下一条需要被执行的字节码指令执行解释操作。</p><p>在Java的发展历史中，一共有两套解释执行器，即古老的字节码解释器、现在普遍使用的模板解释器。</p><ul><li>字节码解释器在执行时通过纯软件代码模拟字节码的执行，效率非常低下。</li><li>而模板解释器将每一条字节码和一个模板函数相关联，模板函数中直接产生这条字节码执行时的机器码，从而很大程度上提高了解释器的性能。<ul><li>在HotSpot VM中，解释器主要由Interpreter模块和Code模块构成。<ul><li>Interpreter模块：实现了解释器的核心功能。</li><li>Code模块：用于管理HotSpot VM在运行时生成的本地机器指令。</li></ul></li></ul></li></ul><h2 id="现状"><a class="header-anchor" href="#现状">¶</a>现状</h2><p>由于解释器在设计和实现上非常简单，因此除了Java语言之外，还有许多高级语言同样也是基于解释器执行的，比如Python、Perl、Ruby等。但是在今天，基于解释器执行已经沦落为低效的代名词，并且时常被一些C/C++程序员所调侃。</p><p>为了解决这个问题，JVM平台支持一种叫做即时编译的技术。即时编译的目的是避免函数被解释执行，而是将整个函数体编译称为机器码，每次函数执行时，只执行编译后的机器码即可，这种方式可以使执行效率大幅度提升。</p><p>不过无论如何，基于解释器的执行模式仍然为中间语言的发展做出了不可磨灭的贡献。</p><h1>六、编译器</h1><h2 id="6-1、Java中的编译"><a class="header-anchor" href="#6-1、Java中的编译">¶</a>6.1、Java中的编译</h2><p>Java语言的“编译期”其实是一段“不确定”的操作过程，因为它可能是指：</p><ul><li>一个前端编译器(其实叫“编译器的前端”更准确一些)把java文件转变成 class文件的过程</li><li>也可能是指虚拟机的后端运行期编译器(编译器， Just In Time Compiler)把字节码转变成机器码的过程</li><li>还可能是指使用静态提前编译器(AOT编译器, Ahead of Time Compiler)直接把.java文件编译成本地机器代码的过程</li></ul><blockquote><p>前端编译器：JDK的 Javac、 <a href="ttp://www.eclipse.org/jdt/" target="_blank" rel="noopener">Eclipse JDT</a>中的增量式编译器(ECJ)<br>JIT编译器:：HotSpot VM的C1、C2编译器、Graal编译器。<br>AOT编译器：GNU Compiler for the Java(<a href="http://gcc.gnu.org/java/" target="_blank" rel="noopener">GCJ</a>)、 <a href="https://en.wikipedia.org/wiki/Excelsior_JET" target="_blank" rel="noopener">Excelsior JET</a></p></blockquote><h3 id="Java中的JIT编译器"><a class="header-anchor" href="#Java中的JIT编译器">¶</a>Java中的JIT编译器</h3><p>HotSpot中内嵌有两个(或者三个)JIT编译器,分别为 Client Compiler 和 Server compiler ,但大多数情况下我们简称为C1编译器和C2编译器。第三个是在JDK 10时才出现的、长期目标是代替C2的Graal编译器。Graal编译器目前还处于实验状态。</p><p>开发人员可以通过如下命令显式指定Java虚拟机在运行时到底使用哪一种即时编译器,如下所示:</p><ul><li><code>-client</code>：指定Java虚拟机 client运行在模式下,并使用C1编译器;</li><li>Client VM初始化堆空间会小一些，使用串行垃圾回收器。<ul><li>C1编译器会对字节码进行简单和可靠的优化,耗时短。以达到更快的编译速度。</li></ul></li><li><code>-server</code>：指定Java虚拟机 Server运行在模式下，并使用C2编译器。</li><li>Server VM的初始化堆空间会大一些，默认使用的是并行垃圾回收器。<ul><li>C2进行耗时较长的优化,以及激进优化。但优化的代码执行效率更高。</li></ul></li></ul><blockquote><p>如果不指定参数，JVM在启动的时候会根据硬件和操作系统自动选择使用Server还是Client类型的JVM。</p><ol><li>32位操作系统<ul><li>如果是Windows系统,不论硬件配置如何,都默认使用Client类型的JVM。</li><li>如果是其他操作系统上,机器配置有2GB以上的内存同时有2个以上CPU的话默认使用server 模式,否则使用client模式</li></ul></li><li><strong>64位操作系统 只有Server类型,不支持Client类型。</strong></li></ol></blockquote><p>一般来讲，JIT编译出来的机器码性能比解释器高。C2编译器启动时长比C1编译器慢，系统稳定执行以后，C2编译器执行速度远远快于C1编译器。</p><h2 id="6-2、前端编译"><a class="header-anchor" href="#6-2、前端编译">¶</a>6.2、前端编译</h2><p>Java中即时编译器在运行期的优化过程,支撑了程序执行效率的不断提升;而前端编译器在编译期的优化过程（新生的Java语法特性,都是靠前端编译器的“语法糖”）,则是支撑着程序员的编码效率和语言使用者的幸福感的提高。</p><p>Javac编译器不像HotSpot虚拟机那样使用C++语言(包含少量C语言)实现,它本身就是一个由Java语言编写的程序。</p><p>从Javac代码的总体结构来看,编译过程大致可以分为1个准备过程和3个处理过程,它们分别如下所示。</p><p>《Java虚拟机规范》中严格定义了Class文件格式的各种细节,可是对如何把Java源码编译为Class 文件却描述得相当宽松。规范里尽管有专门的一章名为“Compiling for the Java Virtual Machine”,但这章也仅仅是以举例的形式来介绍怎样的Java代码应该被转换为怎样的字节码,并没有使用编译原理中常用的描述工具(如文法、生成式等)来对Java源码编译过程加以约束。这是给了Java前端编译器较大的实现灵活性,但也导致Class文件编译过程在某种程度上是与具体的JDK或编译器实现相关的,譬如在一些极端情况下,可能会出现某些代码在Javac编译器可以编译,但是ECJ编译器就不可以编译的问题(反过来也有可能,后文中将会给出一些这样的例子)</p><p>从Javac代码的总体结构来看,编译过程大致可以分为1个准备过程和3个处理过程,它们分别如下所示。</p><ol><li>准备过程:初始化插入式注解处理器。</li><li>解析与填充符号表过程,包括:<ul><li>词法、语法分析。将源代码的字符流转变为标记集合,构造出抽象语法树。</li><li>填充符号表。产生符号地址和符号信息。</li></ul></li><li>插入式注解处理器的注解处理过程:插入式注解处理器的执行阶段</li><li>分析与字节码生成过程,包括:<ol><li>标注检查。对语法的静态信息进行检查。</li><li>数据流及控制流分析。对程序动态运行过程进行检查。</li><li>解语法糖。将简化代码编写的语法糖还原为原有的形式。</li><li>字节码生成。将前面各个步骤所生成的信息转化成字节码。</li></ol></li></ol><p>上述前3个处理过程里,执行插入式注解时又可能会产生新的符号,如果有新的符号产生,就必须转回到之前的解析、填充符号表的过程中重新处理这些新符号,从总体来看,三者之间的关系与交互顺序如图</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234851.png" alt="image-20200922165158822"></p><p>上述处理过程对应到代码中,Javac编译动作的入口是<code>com.sun.tools.javac.main.JavaCompiler</code>类,上述3个过程的代码逻辑集中在这个类的<code>compile()</code>和<code>compile2()</code>方法里，其中主体代码如下图。下面步骤围绕这个图中方法展开描述</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234857.png" alt="image-20200922165505278"></p><h3 id="6-2-1、解析与填充符号表"><a class="header-anchor" href="#6-2-1、解析与填充符号表">¶</a>6.2.1、解析与填充符号表</h3><p>解析过程由parseFiles()方法来完成,解析过程包括了经典程序编译原理中的词法分析和语法分析两个步骤。</p><h4 id="1-词法、语法分析"><a class="header-anchor" href="#1-词法、语法分析">¶</a>1&gt;词法、语法分析</h4><p>法分析是将源代码的字符流转变为标记(Token)集合的过程,单个字符是程序编写时的最小元素,但标记才是编译时的最小元素。关键字、变量名、字面量、运算符都可以作为标记,如“int a=b+2”这句代码中就包含了6个标记,分别是int、a、=、b、+、2,虽然关键字int由3个字符构成,但是它只是一个独立的标记,不可以再拆分。在Javac的源码中,词法分析过程由com.sun.tools.javac.parser.Scanner类来实现。<br>语法分析是根据标记序列构造抽象语法树的过程,抽象语法树(Abstract Syntax Tree,AST)是一种用来描述程序代码语法结构的树形表示方式,抽象语法树的每一个节点都代表着程序代码中的一个语法结构(Syntax Construct),例如包、类型、修饰符、运算符、接口、返回值甚至连代码注释等都可以是一种特定的语法结构。</p><p>下面是Eclipse AST View插件分析出来的某段代码的抽象语法树视图,</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234906.png" alt="image-20200922170218225"></p><p>在Javac的源码中,语法分析过程由<code>com.sun.tools.javac.parser.Parser</code>类实现,这个阶段产出的抽象语法树是以<code>com.sun.tools.javac.tree.JCTree</code> 类表示的。</p><p>经过词法和语法分析生成语法树以后,编译器就不会再对源码字符流进行操作了,后续的操作都建立在抽象语法树之上。</p><h4 id="2-填充符号表"><a class="header-anchor" href="#2-填充符号表">¶</a>2&gt;填充符号表</h4><p>完成了语法分析和词法分析之后,下一个阶段是对符号表进行填充的过程,也就是<code>enterTrees()</code>方法要做的事情。符号表(Symbol Table)是由一组符号地址和符号信息构成的数据结构,读者可以把它类比想象成哈希表中键值对的存储形式(实际上符号表不一定是哈希表实现,可以是有序符号表、树状符号表、栈结构符号表等各种形式)。符号表中所登记的信息在编译的不同阶段都要被用到。譬如在语义分析的过程中,符号表所登记的内容将用于语义检查(如检查一个名字的使用和原先的声明是否一致)和产生中间代码,在目标代码生成阶段,当对符号名进行地址分配时,符号表是地址分配的直接依据。</p><p>在Javac源代码中,填充符号表的过程由<code>com.sun.tools.javac.comp.Enter</code>类实现,该过程的产出物是一个待处理列表,其中包含了每一个编译单元的抽象语法树的顶级节点,以及<code>package-info.java</code>(如果存在的话)的顶级节点。</p><h3 id="6-2-2、注解处理器"><a class="header-anchor" href="#6-2-2、注解处理器">¶</a>6.2.2、注解处理器</h3><p>JDK 5之后,Java语言提供了对注解(Annotations)的支持,注解在设计上原本是与普通的Java代码一样,都只会在程序运行期间发挥作用的。但在JDK 6中又提出并通过了JSR-269提案,该提案设计了一组被称为“插入式注解处理器”的标准API,可以提前至编译期对代码中的特定注解进行处理, 从而影响到前端编译器的工作过程。我们可以把插入式注解处理器看作是一组编译器的插件,当这些插件工作时,允许读取、修改、添加抽象语法树中的任意元素。如果这些插件在处理注解期间对语法树进行过修改,编译器将回到解析及填充符号表的过程重新处理,直到所有插入式注解处理器都没有再对语法树进行修改为止,每一次循环过程称为一个轮次(Round)。</p><p>有了编译器注解处理的标准API后,程序员的代码才有可能干涉编译器的行为,由于语法树中的任意元素,甚至包括代码注释都可以在插件中被访问到,所以通过插入式注解处理器实现的插件在功能上有很大的发挥空间。只要有足够的创意,程序员能使用插入式注解处理器来实现许多原本只能在编码中由人工完成的事情。譬如Java著名的编码效率工具Lombok,它可以通过注解来实现自动产生getter/setter方法、进行空置检查、生成受查异常表、产生equals()和hashCode()方法,等等。</p><p>Javac源码中,插入式注解处理器的初始化过程是在<code>initPorcessAnnotations()</code>方法中完成的,而它的执行过程则是在<code>processAnnotations()</code>方法中完成。这个方法会判断是否还有新的注解处理器需要执行,如果有的话,通过<code>com.sun.tools.javac.processing.JavacProcessing-Environment</code>类的<code>doProcessing()</code>方法来生成一个新的<code>JavaCompiler</code>对象,对编译的后续步骤进行处理。</p><h3 id="6-2-3、语义分析与字节码生成"><a class="header-anchor" href="#6-2-3、语义分析与字节码生成">¶</a>6.2.3、语义分析与字节码生成</h3><p>经过语法分析之后,编译器获得了程序代码的抽象语法树表示,抽象语法树能够表示一个结构正确的源程序,但无法保证源程序的语义是符合逻辑的。而语义分析的主要任务则是对结构上正确的源程序进行上下文相关性质的检查,譬如进行类型检查、控制流检查、数据流检查,等等。</p><h4 id="1-标注检查"><a class="header-anchor" href="#1-标注检查">¶</a>1&gt;标注检查</h4><p>Javac在编译过程中,语义分析过程可分为标注检查和数据及控制流分析两个步骤,分别由<code>attribute()</code>和<code>flow()</code>方法完成。</p><p>标注检查步骤要检查的内容包括诸如变量使用前是否已被声明、变量与赋值之间的数据类型是否能够匹配,等等。在标注检查中,还会顺便进行一个称为常量折叠(Constant Folding)的代码优化,这是Javac编译器会对源代码做的极少量优化措施之一(代码优化几乎都在即时编译器中进行)。如果我们在Java代码中写下如下所示的变量定义</p><pre class="line-numbers language-language-java"><code class="language-language-java">int a = 1 + 2;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>则在抽象语法树上仍然能看到字面量“1”“2”和操作符“+”号,但是在经过常量折叠优化之后,它们将会被折叠为字面量“3”,这插入式表达式(InfixExpression)的值已经在语法树上标注出来了(ConstantExpressionValue:3)。由于编译期间进行了常量折叠,所以在代码里面定义“a=1+2”比起直接定义“a=3”来,并不会增加程序运行期哪怕仅仅一个处理器时钟周期的处理工作量。<br>标注检查步骤在Javac源码中的实现类是<code>com.sun.tools.javac.comp.Attr</code>类和<code>com.sun.tools.javac.comp.Check</code>类。</p><h4 id="2-数据及控制流分析"><a class="header-anchor" href="#2-数据及控制流分析">¶</a>2&gt;数据及控制流分析</h4><p>数据流分析和控制流分析是对程序上下文逻辑更进一步的验证,它可以检查出诸如程序局部变量在使用前是否有赋值、方法的每条路径是否都有返回值、是否所有的受查异常都被正确处理了等问题。编译时期的数据及控制流分析与类加载时的数据及控制流分析的目的基本上可以看作是一致的, 但校验范围会有所区别,有一些校验项只有在编译期或运行期才能进行。下面举一个关于final修饰符的数据及控制流分析的例子</p><pre class="line-numbers language-language-java"><code class="language-language-java">// 方法一带有final修饰public void foo(final int arg) {final int var = 0;  // do something } // 方法二没有final修饰public void foo(int arg) {     int var = 0;  // do something }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这两个<code>foo()</code>方法中,一个方法的参数和局部变量定义使用了final修饰符,另外一个则没有,在代码编写时程序肯定会受到final修饰符的影响,不能再改变arg和var变量的值,但是如果观察这两段代码编译出来的字节码,会发现它们是没有任何一点区别的,每条指令,甚至每个字节都一模一样。局部变量与类的字段(实例变量、类变量)的存储是有显著差别的,局部变量在常量池中并没有CONSTANT_Fieldref_info的符号引用,自然就不可能存储有访问标志(access_flags)的信息,甚至可能连变量名称都不一定会被保留下来(这取决于编译时的编译器的参数选项),自然在Class文件中就不可能知道一个局部变量是不是被声明为final了。因此, 可以肯定地推断出把局部变量声明为final,对运行期是完全没有影响的,变量的不变性仅仅由Javac编译器在编译期间来保障,这就是一个只能在编译期而不能在运行期中检查的例子。在Javac的源码中, 数据及控制流分析的入口<code>flow()</code>方法,具体操作由<code>com.sun.tools.javac.comp.Flow</code>类来完成。</p><h4 id="3-解语法糖"><a class="header-anchor" href="#3-解语法糖">¶</a>3&gt;解语法糖</h4><p>语法糖(Syntactic Sugar),也称糖衣语法,是由英国计算机科学家Peter J.Landin发明的一种编程术语,指的是在计算机语言中添加的某种语法,这种语法对语言的编译结果和功能并没有实际影响, 但是却能更方便程序员使用该语言。通常来说使用语法糖能够减少代码量、增加程序的可读性,从而减少程序代码出错的机会。</p><p>Java在现代编程语言之中已经属于“低糖语言”(相对于C#及许多其他Java虚拟机语言来说),尤其是JDK 5之前的Java。“低糖”的语法让Java程序实现相同功能的代码量往往高于其他语言,通俗地说就是会显得比较“啰嗦”,这也是Java语言一直被质疑是否已经“落后”了的一个浮于表面的理由。</p><p>Java中最常见的语法糖包括了前面提到过的泛型(其他语言中泛型并不一定都是语法糖实现,如C#的泛型就是直接由CLR支持的)、变长参数、自动装箱拆箱,等等,Java虚拟机运行时并不直接支持这些语法,它们在编译阶段被还原回原始的基础语法结构,这个过程就称为解语法糖。在Javac的源码中,解语法糖的过程由<code>desugar()</code>方法触发,在<code>com.sun.tools.javac.comp.TransTypes</code>类和<code>com.sun.tools.javac.comp.Lower</code>类中完成。</p><h4 id="4-字节码生成"><a class="header-anchor" href="#4-字节码生成">¶</a>4&gt;字节码生成</h4><p>字节码生成是Javac编译过程的最后一个阶段,在Javac源码里面由<code>com.sun.tools.javac.jvm.Gen</code>类来完成。字节码生成阶段不仅仅是把前面各个步骤所生成的信息(语法树、符号表)转化成字节码指令写到磁盘中,编译器还进行了少量的代码添加和转换工作。</p><p>例如前文多次登场的实例构造器<code>&lt;init&gt;()</code>方法和类构造器<code>&lt;clinit&gt;()</code>方法就是在这个阶段被添加到语法树之中的。请注意这里的实例构造器并不等同于默认构造函数,如果用户代码中没有提供任何构造函数,那编译器将会添加一个没有参数的、可访问性(public、protected、private或<code>&lt;package&gt;</code>)与当前类型一致的默认构造函数,这个工作在填充符号表阶段中就已经完成。<code>&lt;init&gt;()</code>和<code>&lt;clinit&gt;()</code>这两个构造器的产生实际上是一种代码收敛的过程,编译器会把语句块(对于实例构造器而言是“{}”块,对于类构造器而言是“static{}”块)、变量初始化(实例变量和类变量)、调用父类的实例构造器(仅仅是实例构造器,<code>&lt;clinit&gt;()</code>方法中无须调用父类的<code>&lt;clinit&gt;()</code>方法,Java虚拟机会自动保证父类构造器的正确执行,但在<code>&lt;clinit&gt;()</code>方法中经常会生成调用<code>java.lang.Object</code>的<code>&lt;init&gt;()</code>方法的代码)等操作收敛到<code>&lt;init&gt;()</code>和<code>&lt;clinit&gt;()</code>方法之中,并且保证无论源码中出现的顺序如何,都一定是按先执行父类的实例构造器,然后初始化变量,最后执行语句块的顺序进行,上面所述的动作由<code>Gen::normalizeDefs()</code>方法来实现。除了生成构造器以外,还有其他的一些代码替换工作用于优化程序某些逻辑的实现方式,如把字符串的加操作替换为<code>StringBuffer</code>或<code>StringBuilder</code>(取决于目标代码的版本是否大于或等于JDK 5)的<code>append()</code>操作,等等。</p><p>完成了对语法树的遍历和调整之后,就会把填充了所有所需信息的符号表交到<code>com.sun.tools.javac.jvm.ClassWriter</code>类手上,由这个类的<code>writeClass()</code>方法输出字节码,生成最终的Class 文件,到此,整个编译过程宣告结束。</p><h3 id="6-2-4、Java语法糖的味道"><a class="header-anchor" href="#6-2-4、Java语法糖的味道">¶</a>6.2.4、Java语法糖的味道</h3><h4 id="1-泛型"><a class="header-anchor" href="#1-泛型">¶</a>1&gt;泛型</h4><p>泛型的本质是参数化类型(Parameterized Type)或者参数化多态(Parametric Polymorphism)的应用,即可以将操作的数据类型指定为方法签名中的一种特殊参数,这种参数类型能够用在类、接口和方法的创建中,分别构成泛型类、泛型接口和泛型方法。泛型让程序员能够针对泛化的数据类型编写相同的算法,这极大地增强了编程语言的类型系统及抽象能力。</p><h5 id="Java与C-的泛型"><a class="header-anchor" href="#Java与C-的泛型">¶</a>Java与C#的泛型</h5><p>Java选择的泛型实现方式叫作“类型擦除式泛型”(Type Erasure Generics),而C#选择的泛型实现方式是“具现化式泛型”(Reified Generics)。</p><ul><li>C#里面泛型无论在程序源码里面、编译后的中间语言表示(Intermediate Language,这时候泛型是一个占位符)里面,抑或是运行期的CLR里面都是切实存在的,<code>List&lt;int&gt;</code>与<code>List&lt;string&gt;</code>就是两个不同的类型,它们由系统在运行期生成,有着自己独立的虚方法表和类型数据。</li><li>而Java语言中的泛型则不同,它只在程序源码中存在,在编译后的字节码文件中,全部泛型都被替换为原来的裸类型(Raw Type)了,并且在相应的地方插入了强制转型代码,因此对于运行期的Java语言来说,<code>ArrayList&lt;int&gt;</code>与<code>ArrayList&lt;String&gt;</code>其实是同一个类型</li></ul><p>以下是C#支持而Java不支持的泛型用法</p><pre class="line-numbers language-language-java"><code class="language-language-java">public class TypeErasureGenerics<E> {       public void doSomething(Object item) {    if (item instanceof E) {   // 不合法,无法对泛型进行实例判断      ...    }    E newItem = new E();       // 不合法,无法使用泛型创建对象    E[] itemArray = new E[10]; // 不合法,无法使用泛型创建数组      } } <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面这些是Java泛型在编码阶段产生的不良影响,如果说这种使用层次上的差别还可以通过多写几行代码、方法中多加一两个类型参数来解决的话,性能上的差距则是难以用编码弥补的。C#2.0引入了泛型之后,带来的显著优势之一便是对比起Java在执行性能上的提高,因为在使用平台提供的容器类型(如<code>List&lt;T&gt;</code>,<code>Dictionary&lt;TKey,TV alue&gt;</code>)时,无须像Java里那样不厌其烦地拆箱和装箱,如果在Java中要避免这种损失,就必须构造一个与数据类型相关的容器类(譬如<code>IntFloatHashMap</code>这样的容器)。显然,这除了引入更多代码造成复杂度提高、复用性降低之外,更是丧失了泛型本身的存在价值。</p><p>Java的类型擦除式泛型无论在使用效果上还是运行效率上,几乎是全面落后于C#的具现化式泛型,而它的唯一优势是在于实现这种泛型的影响范围上:擦除式泛型的实现几乎只需要在Javac编译器上做出改进即可,不需要改动字节码、不需要改动Java虚拟机,也保证了以前没有使用泛型的库可以直接运行在Java 5.0之上。但这种听起来节省工作量甚至可以说是有偷工减料嫌疑的优势就显得非常短视,真的能在当年Java实现泛型的利弊权衡中胜出吗?答案的确是它胜出了,但我们必须在那时的泛型历史背景中去考虑不同实现方式带来的代价。</p><h5 id="泛型的历史背景"><a class="header-anchor" href="#泛型的历史背景">¶</a>泛型的历史背景</h5><p>为了保证这些编译出来的Class文件可以在Java 5.0引入泛型之后继续运行,设计者面前大体上有两条路可以选择:</p><ol><li>需要泛型化的类型(主要是容器类型),以前有的就保持不变,然后平行地加一套泛型化版本的新类型。</li><li>直接把已有的类型泛型化,即让所有需要泛型化的已有类型都原地泛型化,不添加任何平行于已有类型的泛型版。</li></ol><p>在这个分叉路口,C#走了第一条路,添加了一组<code>System.Collections.Generic</code>的新容器,以前的<code>System.Collections</code>以及<code>System.Collections.Specialized</code>容器类型继续存在。C#的开发人员很快就接受了新的容器,倒也没出现过什么不适应的问题,唯一的不适大概是许多.NET自身的标准库已经把老容器类型当作方法的返回值或者参数使用,这些方法至今还保持着原来的老样子。</p><p>但如果相同的选择出现在Java中就很可能不会是相同的结果了,要知道当时.NET才问世两年,而Java已经有快十年的历史了,再加上各自流行程度的不同,两者遗留代码的规模根本不在同一个数量级上。而且更大的问题是Java并不是没有做过第一条路那样的技术决策,在JDK 1.2时,遗留代码规模尚小,Java就引入过新的集合类,并且保留了旧集合类不动。这导致了直到现在标准类库中还有<code>Vector</code>(老)和<code>ArrayList</code>(新)、有<code>Hashtable</code>(老)和<code>HashMap</code>(新)等两套容器代码并存,如果当时再摆弄出像<code>Vector</code>(老)、<code>ArrayList</code>(新)、<code>Vector</code><t>(老但有泛型)、<code>ArrayList</code><t>(新且有泛型)这样的容器集合,可能叫骂声会比今天听到的更响更大。</t></t></p><p>所以Java只能选择第二条路了。但第二条路也并不意味着一定只能使用类型擦除来实现,如果当时有足够的时间好好设计和实现,是完全有可能做出更好的泛型系统的,否则也不会有今天的V alhalla项目来还以前泛型偷懒留下的技术债了。</p><h5 id="类型擦除"><a class="header-anchor" href="#类型擦除">¶</a>类型擦除</h5><p>由于Java选择了第二条路,直接把已有的类型泛型化。要让所有需要泛型化的已有类型,譬如ArrayList,原地泛型化后变成了<code>ArrayList&lt;T&gt;</code>,而且保证以前直接用<code>ArrayList</code>的代码在泛型新版本里必须还能继续用这同一个容器,这就必须让所有泛型化的实例类型,譬如<code>ArrayList&lt;Integer&gt;</code>、<code>ArrayList&lt;String&gt;</code>这些全部自动成为ArrayList的子类型才能可以,否则类型转换就是不安全的。由此就引出了“裸类型”(Raw Type)的概念,裸类型应被视为所有该类型泛型化实例的共同父类型(Super Type),只有这样,以下代码中的赋值才是被系统允许的从子类到父类的安全转型。</p><pre class="line-numbers language-language-java"><code class="language-language-java">ArrayList<Integer> ilist = new ArrayList<Integer>(); ArrayList<String> slist = new ArrayList<String>(); ArrayList list; // 裸类型list = ilist; list = slist<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>接下来的问题是该如何实现裸类型。这里又有了两种选择:</p><ul><li>一种是在运行期由Java虚拟机来自动地、真实地构造出<code>ArrayList&lt;Integer&gt;</code>这样的类型,并且自动实现从<code>ArrayList&lt;Integer&gt;</code>派生自<code>ArrayList</code> 的继承关系来满足裸类型的定义;</li><li>另外一种是索性简单粗暴地直接在编译时把<code>ArrayList&lt;Integer&gt;</code>还原回<code>ArrayList</code>,只在元素访问、修改时自动插入一些强制类型转换和检查指令</li></ul><p>Java选择了第二种：</p><pre class="line-numbers language-language-java"><code class="language-language-java">    public static void main(String[] args) {        Map<String, String> map = new HashMap<String, String>();        map.put("hello", "你好");        map.put("how are you?", "吃了没?");        System.out.println(map.get("hello"));        System.out.println(map.get("how are you?"));    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面代码反编译后：</p><pre class="line-numbers language-language-java"><code class="language-language-java">public static void main(String[] args) {        Map map = new HashMap();        map.put("hello", "你好");        map.put("how are you?", "吃了没?");        System.out.println((String) map.get("hello"));        System.out.println((String) map.get("how are you?"));    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>类型擦除的缺点：</p><ul><li><p>使用擦除法实现泛型直接导致了对原始类型(Primitive Types)数据的支持又成了新的麻烦</p><pre class="line-numbers language-language-java"><code class="language-language-java">ArrayList<int> ilist = new ArrayList<int>(); ArrayList<long> llist = new ArrayList<long>(); ArrayList list; list = ilist; list = llist;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这种情况下,一旦把泛型信息擦除后,到要插入强制转型代码的地方就没办法往下做了,因为不支持<code>int</code>、<code>long</code>与<code>Object</code>之间的强制转型。当时Java给出的解决方案一如既往的简单粗暴:既然没法转换那就索性别支持原生类型的泛型了吧,你们都用<code>ArrayList&lt;Integer&gt;</code>、<code>ArrayList&lt;Long&gt;</code>,反正都做了自动的强制类型转换,遇到原生类型时把装箱、拆箱也自动做了得了。这个决定后面导致了无数构造包装类和装箱、拆箱的开销,成为Java泛型慢的重要原因,也成为今天Valhalla项目要重点解决的问题之一。</p></li><li><p>运行期无法取到泛型类型信息,会让一些代码变得相当啰嗦, 需要写更多的代码通过其它方式获取, 有的地方甚至无法获取。如以下代码,我们去写一个泛型版本的从List到数组的转换方法,由于不能从List中取得参数化类型T,所以不得不从一个额外参数中再传入一个数组的组件类型进去,实属无奈。</p><pre class="line-numbers language-language-java"><code class="language-language-java">public static <T> T[] convert(List<T> list, Class<T> componentType) {     T[] array = (T[])Array.newInstance(componentType, list.size());       //...}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>最后,笔者认为通过擦除法来实现泛型,还丧失了一些面向对象思想应有的优雅,带来了一些模棱两可的模糊状况</p><pre class="line-numbers language-language-java"><code class="language-language-java">public class GenericTypes {        public static void method(List<String> list) {            System.out.println("invoke method(List<String> list)");        }        public static void method(List<Integer> list) {            System.out.println("invoke method(List<Integer> list)");        }    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这段代码是不能被编译的,因为参数<code>List&lt;Integer&gt;</code>和<code>List&lt;String&gt;</code>编译之后都被擦除了,变成了同一种的裸类型<code>List</code>, 类型擦除导致这两个方法的特征签名变得一模一样。</p><p>但是下面的例子在JDK 6的Javac编译器中又能通过并执行成功。</p><pre class="line-numbers language-language-java"><code class="language-language-java">public class GenericTypes {    public static String method(List<String> list) {        System.out.println("invoke method(List<String> list)");        return "";    }    public static int method(List<Integer> list) {        System.out.println("invoke method(List<Integer> list)");        return 1;    }    public static void main(String[] args) {        method(new ArrayList<String>());        method(new ArrayList<Integer>());    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>重载当然不是根据返回值来确定的,之所以这次能编译和执行成功,是因为两个<code>method()</code>方法加入了不同的返回值后才能共存在一个Class文件之中。在Class文件方法表(method_info)的数据结构中,<strong>方法重载</strong>要求方法具备不同的特征签名,返回值并不包含在方法的特征签名中,所以返回值不参与重载选择,这一点如果前端编译器不保证,即可编译通过。</p><p>而对于<strong>Class文件格式</strong>来说,只要描述符不是完全一致的两个方法就可以共存，所以编译通过后的代码也是可以执行的。</p></li></ul><p>由于Java泛型的引入,各种场景(虚拟机解析、反射等)下的方法调用都可能对原有的基础产生影响并带来新的需求,如在泛型类中如何获取传入的参数化类型等。所以JCP组织对《Java虚拟机规范》做出了相应的修改,引入了诸如Signature、LocalV ariableTypeTable等新的属性用于解决伴随泛型而来的参数类型的识别问题,Signature是其中最重要的一项属性,它的作用就是存储一个方法在字节码层面的特征签名,这个属性中保存的参数类型并不是原生类型,而是包括了参数化类型的信息。<a href="http://java.sun.com/docs/books/jvms/second_edition/jvms-clarify.html" target="_blank" rel="noopener">修改后的虚拟机规范</a>要求所有能识别49.0以上版本的Class文件的虚拟机都要能正确地识别Signature参数。</p><p>从上面的例子中可以看到擦除法对实际编码带来的不良影响,由于<code>List&lt;String&gt;</code>和<code>List&lt;Integer&gt;</code>擦除后是同一个类型,我们只能添加两个并不需要实际使用到的返回值才能完成重载,这是一种毫无优雅和美感可言的解决方案,并且存在一定语意上的混乱,譬如上面脚注中提到的,必须用JDK 6的Javac才能编译成功,其他版本或者是ECJ编译器都有可能拒绝编译。</p><p>另外,从Signature属性的出现我们还可以得出结论,擦除法所谓的擦除,仅仅是对方法的Code属性中的字节码进行擦除,实际上元数据中还是保留了泛型信息,这也是我们在编码时能通过反射手段取得参数化类型的根本依据。</p><h5 id="值类型与未来的泛型"><a class="header-anchor" href="#值类型与未来的泛型">¶</a>值类型与未来的泛型</h5><p>在2014年,刚好是Java泛型出现的十年之后,Oracle建立了一个名为Valhalla的语言改进项目[10], 希望改进Java语言留下的各种缺陷(解决泛型的缺陷就是项目主要目标其中之一)。</p><p>在V alhalla项目中规划了几种不同的新泛型实现方案,被称为Model 1到Model 3,在这些新的泛型设计中,泛型类型有可能被具现化,也有可能继续维持类型擦除以保持兼容(取决于采用哪种实现方案),即使是继续采用类型擦除的方案,泛型的参数化类型也可以选择不被完全地擦除掉,而是相对完整地记录在Class文件中,能够在运行期被使用,也可以指定编译器默认要擦除哪些类型。相对于使用不同方式实现泛型,<strong>目前比较明确的是未来的Java应该会提供“值类型”(Value Type)的语言层面的支持</strong>。</p><p>说起值类型,这点也是C#用户攻讦Java语言的常用武器之一,C#并没有Java意义上的原生数据类型,在C#中使用的int、bool、double关键字其实是对应了一系列在.NET框架中预定义好的结构体(Struct),如Int32、Boolean、Double等。在C#中开发人员也可以定义自己值类型,只要继承于ValueType类型即可,而ValueType也是统一基类Object的子类,所以并不会遇到Java那样int不自动装箱就无法转型为Object的尴尬。</p><p>值类型可以与引用类型一样,具有构造函数、方法或是属性字段,等等,而它与引用类型的区别在于它在赋值的时候通常是整体复制,而不是像引用类型那样传递引用的。更为关键的是,值类型的实例很容易实现分配在方法的调用栈上的,这意味着值类型会随着当前方法的退出而自动释放,不会给垃圾收集子系统带来任何压力。</p><p>在Valhalla项目中,Java的值类型方案被称为“内联类型”,计划通过一个新的关键字inline来定义, 字节码层面也有专门与原生类型对应的以Q开头的新的操作码(譬如iload对应qload)来支撑。</p><h4 id="2-自动装箱、拆箱与遍历循环"><a class="header-anchor" href="#2-自动装箱、拆箱与遍历循环">¶</a>2&gt;自动装箱、拆箱与遍历循环</h4><pre class="line-numbers language-language-java"><code class="language-language-java">    public static void main(String[] args) {        List<Integer> list = Arrays.asList(1, 2, 3, 4);        int sum = 0;        for (int i : list) {            sum += i;        }        System.out.println(sum);    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-language-java"><code class="language-language-java">    public static void main(String[] args) {        List list = Arrays.asList(new Integer[]{Integer.valueOf(1), Integer.valueOf(2), Integer.valueOf(3), Integer.valueOf(4)});        int sum = 0;        for (Iterator localIterator = list.iterator(); localIterator.hasNext(); ) {            int i = ((Integer) localIterator.next()).intValue();            sum += i;        }        System.out.println(sum);    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上代码一共包含了泛型、自动装箱、自动拆箱、遍历循环与变长参数5种语法糖,分别展示了它们在编译前后发生的变化。泛型就不必说了,自动装箱、拆箱在编译之后被转化成了对应的包装和还原方法,如<code>Integer.valueOf()</code>与<code>Integer.intValue()</code>方法,而遍历循环则是把代码还原成了迭代器的实现,这也是为何遍历循环需要被遍历的类实现<code>Iterable</code>接口的原因。最后再看看变长参数,它在调用的时候变成了一个数组类型的参数,在变长参数出现之前,程序员的确也就是使用数组来完成类似功能的。</p><p>以下是一些自动拆箱的不正确用法。</p><pre class="line-numbers language-language-java"><code class="language-language-java">        Integer a = 1;        Integer b = 2;        Integer c = 3;        Integer d = 3;        Integer e = 321;        Integer f = 321;        Long g = 3L;        System.out.println(c == d); //true：发现对象是同一个，貌似是因为数值较小，所以会共用一个对象(常量池？)        System.out.println(e == f); //false："=="没有遇到运算符不会自动拆箱，且数值较大，不会共用对象        System.out.println(c == (a + b));   //true："=="遇到运算符会自动拆箱        System.out.println(c.equals(a + b));    //true："=="遇到运算符会自动拆箱        System.out.println(g == (a + b));   //true："=="遇到运算符会自动拆箱        System.out.println(g.equals(a + b));    //false：equals会做类型判断且不会处理类型转换<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="3-条件编译"><a class="header-anchor" href="#3-条件编译">¶</a>3&gt;条件编译</h4><p>许多程序设计语言都提供了条件编译的途径,如C、C<ins>中使用预处理器指示符(#ifdef)来完成条件编译。C、C</ins>的预处理器最初的任务是解决编译时的代码依赖关系(如极为常用的#include预处理命令)。</p><ul><li><p>C/C++在预处理阶段通过对源文件中宏的判断条件进行预处理，对满足条件的一些宏定义进行展开。之后在编译阶段再对展开后的源文件进行整体编译。</p></li><li><p>而在Java语言之中并没有使用预处理器,因为Java语言天然的编译方式(编译器并非一个个地编译Java文件,而是将所有编译单元的语法树顶级节点输入到待处理列表后再进行编译,因此各个文件之间能够互相提供符号信息)就无须使用到预处理器。</p></li></ul><p>Java语言当然也可以进行条件编译,方法就是使用条件为常量的if语句。如下：</p><pre class="line-numbers language-language-java"><code class="language-language-java">public static void main(String[] args) {        if (true) {            System.out.println("block 1");        } else {            System.out.println("block 2");        }    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>反编译后得到</p><pre class="line-numbers language-language-java"><code class="language-language-java">public static void main(String[] args) {System.out.println("block 1"); }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>该代码中的if语句不同于其他Java代码,它在编译阶段就会被“运行”</strong>,生成的字节码之中只包括<code>System.out.println(&quot;block 1&quot;);</code>一条语句,并不会包含if语句及另外一个分子中的<code>System.out.println(&quot;block 2&quot;);</code>。</p><p>只能使用<strong>条件为常量的if语句</strong>才能达到上述效果,如果使用常量与其他带有条件判断能力的语句搭配,则可能在控制流分析中提示错误,被拒绝编译：</p><pre class="line-numbers language-language-java"><code class="language-language-java">  public static void main(String[] args) {             while (false) {            System.out.println(""); // 编译器将会提示“Unreachable code”         }    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-2-5、修改字节码的方式"><a class="header-anchor" href="#6-2-5、修改字节码的方式">¶</a>6.2.5、修改字节码的方式</h3><ol><li>手动编辑.class文件或者自己编写代码直接基于二进制流修改字节码</li><li>基于一些字节码框架如ASM</li><li>动态代理框架如JDK的动态代理、CGLIB</li><li>Javac提供的注解处理器机制</li></ol><h2 id="6-3、后端编译：JIT编译器"><a class="header-anchor" href="#6-3、后端编译：JIT编译器">¶</a>6.3、后端编译：JIT编译器</h2><p>JIT（Just In Time Compiler）编译器：就是虚拟机将字节码直接编译成和本地机器平台相关的机器语言。</p><p>HotSpot VM是目前市面上高性能虚拟机的代表作之一。它采用解释器与即时编译器并存的架构。在Java虚拟机运行时，解释器和即时编译器能够相互协作，各自取长补短，尽力去选择最合适的方式来权衡编译本地代码的时间和直接解释执行代码的时间。</p><p>在今天，Java程序的运行性能早已脱胎换骨，已经达到了可以和C/C++程序一较高下的地步。</p><h3 id="6-3-1、和解释器并存"><a class="header-anchor" href="#6-3-1、和解释器并存">¶</a>6.3.1、和解释器并存</h3><p>当程序启动后，解释器可以马上发挥作用，省去编译的时间，立即执行。编译器要想发挥作用，把代码编译成本地代码，需要一定的执行时间。但编译为本地代码后，执行效率高。</p><p>所以尽管JRocket VM程序因为不包含解释器，在启动过程将字节码完全编译后才开始运行带来了很高的性能，但这个编译过程可能花费了很长时间。对于服务端应用来说，启动时间并非是关注重点，但对于那些看重启动时间的应用场景而言，或许就需要采用解释器与即时编译器并存的架构来换取一个平衡点。在此模式下，当Java虚拟机启动时，解释器可以首先发挥作用，而不必等待即时编译器全部编译完成后再执行，这样可以省去许多不必要的编译时间。随着时间的推移，编译器发挥作用，把越来越多的代码编译成本地代码，获取更高的执行效率。</p><p>当程序运行环境中内存资源限制较大,可以使用解释执行节约内存(如部分嵌入式系统中和大部分的JavaCard应用中就只有解释器的存在),反之可以使用编译执行来提升效率。同时，解释执行在编译器进行激进优化不成立的时候，作为编译器的&quot;逃生门&quot;。</p><h4 id="案例"><a class="header-anchor" href="#案例">¶</a>案例</h4><p>注意解释执行与编译执行在线上环境微妙的辩证关系。机器在热机状态可以承受的负载要大于冷机状态。如果以热机状态时的流量进行切流,可能使处于冷机状态的服务器因无法承载流量而假死。在生产环境发布过程中,以分批的方式进行发布,根据机器数量划分成多个批次,每个批次的机器数至多占到整个集群的1/8。曾经有这样的故障案例:某程序员在发布平台进行分批发布,在输入发布总批数时,误填写成分为两批发布。如果是热机状态,在正常情况下一半的机器可以勉强承载流量,但由于刚启动的JVM均是解释执行,还没有进行热点代码统计和JIT动态编译,导致机器启动之后,当前1/2发布成功的服务器马上全部宕机,此故障说明了JIT的存在。—阿里团队</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234932.png" alt="image-20200917114330410"></p><h3 id="6-3-2、热点代码及探测方式触发编译及优化"><a class="header-anchor" href="#6-3-2、热点代码及探测方式触发编译及优化">¶</a>6.3.2、热点代码及探测方式触发编译及优化</h3><p>当然是否需要启动JIT编译器将字节码直接编译为对应平台的本地机器指令则需要根据代码被调用执行的频率而定。关于那些需要被编译为本地代码的字节码,也被称之为“热点代码”,JIT编译器在运行时会针对那些频繁被调用的“热点代码”做出深度优化,将其直接编译为对应平台的本地机器指令,以此提升Java程序的执行性能。</p><p><strong>一个被多次调用的方法或者是一个方法体内部循环次数较多的循环体</strong>都可以被称之为“热点代码”,因此都可以通过JIT编译器编译为本地机器指令, 对于这两种情况,<strong>编译的目标对象都是整个方法体,而不会是单独的循环体</strong>。</p><ol><li>第一种情况,由于是依靠方法调用触发的编译,那编译器理所当然地会以整个方法作为编译对象,这种编译也是虚拟机中标准的即时编译方式。</li><li>而对于后一种情况,尽管编译动作是由循环体所触发的,热点只是方法的一部分,<strong>但编译器依然必须以整个方法作为编译对象,只是执行入口(从方法第几条字节码指令开始执行)会稍有不同,编译时会传入执行入口点字节码序号(Byte Code Index,BCI)</strong>。这种编译方式因为编译发生在方法执行的过程中,因此被很形象地称为“栈上替换”(On Stack Replacement,OSR),即方法的栈帧还在栈上,方法就被替换了。</li></ol><p>一个方法究竟要被调用多少次,或者一个循环体究竟需要执行多少次循环才可以达到这个标准?必然需要一个明确的阈值JIT编译器才会将这些“热点代码”编译为本地机器指令执行。这里主要依靠热点探测功能。</p><h4 id="1-基于计数器探测"><a class="header-anchor" href="#1-基于计数器探测">¶</a>1&gt;基于计数器探测</h4><p>目前HotSpot VM所采用的热点探测方式是基于计数器的热点探测。HotSpot VM将会为每一个方法都建立2个不同类型的计数器,分别为方法调用计数器(Invocation Counter)和回边计数器(back Edge Counter).当虚拟机运行参数确定的前提下,这两个计数器都有一个明确的阈值,计数器阈值一旦溢出,就会触发即时编译。</p><p>这种统计方法实现起来要麻烦一些,需要为每个方法建立并维护计数器,而且不能直接获取到方法的调用关系。但是它的统计结果相对来说更加精确严谨。</p><ol><li><p>方法调用计数器用于统计方法的调用次数</p><ul><li><p>这个计数器就用于统计方法被调用的次数,它的默认阈值在 client模式下是1500次,在 Server模式下是10000次。超过这个阈值,就会触发JIT编译。这个阈值可以通过虚拟机参数<code>-xx: CompileThreshold</code>来人为设定。</p></li><li><p>当一个方法被调用时,会先检查该方法是否存在被JIT编译过的版本：</p><ul><li><p>如果存在,则优先使用编译后的本地代码来执行。</p></li><li><p>如果不存在已被编译过的版本,则将此方法的调用计数器值加1,然后判断方法调用计数器与回边计数器值之和是否超过方法调用计数器的阈值。如果已超过阈值,那么将会向即时编译器提交一个该方法的代码编译请求。</p><p>如果没有做过任何设置,执行引擎默认不会同步等待编译请求完成,而是继续进入解释器按照解释方式执行字节码,直到提交的请求被即时编译器编译完成。当编译工作完成后,这个方法的调用入口地址就会被系统自动改写成新值,下一次调用该方法时就会使用已编译的版本了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234938.png" alt="image-20200917141432235"></p></li></ul></li><li><p><strong>热度衰减</strong><br>如果不做任何设置,方法调用计数器统计的并不是方法被调用的绝对次数,而是一个相对的执行频率,即一段时间之内方法被调用的次数。当超过一定的时间限度,如果方法的调用次数仍然不足以让它提交给即时编译器编译,那这个方法的调用计数器就会被减少一半,这个过程称为方法调用计数器热度的衰减(Counter Decay),而这段时间就称为此方法统计的半衰周期(Counter Half Life Time)。<br>进行热度衰减的动作是在虚拟机进行垃圾收集时顺便进行的,可以使用虚拟机参数<code>-XX:-UseCounterDecay</code>来关闭热度衰减,让方法计数器统计方法调用的绝对次数,这样,只要系统运行时间足够长,绝大部分方法都会被编译成本地代码。<br>另外,可以使用<code>-XX:CounterHalfLife=&lt;N&gt;</code>参数设置半衰周期的时间,单位是秒。</p></li></ul></li><li><p>回边计数器则用于统计循环体执行的循环次数</p><p>它的作用是统计一个方法中循环体代码执行的次数<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>,在字节码中遇到控制流向后跳转的指令就称为“回边(Back Edge)”,很显然建立回边计数器统计的目的是为了触发栈上的替换编译。</p><p>关于回边计数器的阈值,虽然HotSpot虚拟机也提供了一个类似于方法调用计数器阈值<code>-XX: CompileThreshold</code>的参数<code>-XX:BackEdgeThreshold</code>供用户设置,但是当前的HotSpot虚拟机实际上并未使用此参数,我们必须设置另外一个参数<code>-XX:OnStackReplacePercentage</code>来间接调整回边计数器的阈值,其计算公式有如下两种。</p><ul><li>虚拟机运行在客户端模式下,回边计数器阈值计算公式为:方法调用计数器阈值(<code>-XX: CompileThreshold</code>)乘以OSR比率(<code>-XX:OnStackReplacePercentage</code>)除以100。其中<code>-XX: OnStackReplacePercentage</code>默认值为933,如果都取默认值,那客户端模式虚拟机的回边计数器的阈值为13995。</li><li>虚拟机运行在服务端模式下,回边计数器阈值的计算公式为:方法调用计数器阈值(<code>-XX: CompileThreshold</code>)乘以(OSR比率(<code>-XX:OnStackReplacePercentage</code>)减去解释器监控比率(<code>-XX: InterpreterProfilePercentage</code>)的差值)除以100。其中<code>-XX:OnStack ReplacePercentage</code>默认值为140,<code>-XX:InterpreterProfilePercentage</code>默认值为33,如果都取默认值,那服务端模式虚拟机回边计数器的阈值为10700。</li></ul><p>当解释器遇到一条回边指令时,会先查找将要执行的代码片段是否有已经编译好的版本,如果有的话,它将会优先执行已编译的代码,否则就把回边计数器的值加一,然后判断方法调用计数器与回边计数器值之和是否超过回边计数器的阈值。当超过阈值的时候,将会提交一个栈上替换编译请求, 并且把回边计数器的值稍微降低一些,以便继续在解释器中执行循环,等待编译器输出编译结果</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234945.png" alt="image-20200917142023229"></p><p><strong>与方法计数器不同,回边计数器没有计数热度衰减的过程,因此这个计数器统计的就是该方法循环执行的绝对次数。当计数器溢出的时候,它还会把方法计数器的值也调整到溢出状态,这样下次再进入该方法的时候就会执行标准编译过程。</strong></p></li></ol><h4 id="2-基于采样的热点探测"><a class="header-anchor" href="#2-基于采样的热点探测">¶</a>2&gt;基于采样的热点探测</h4><p>除了HotSpot采用的计数器探测法，另外还有一种方法是基于采样的热点探测(Sample Based Hot Spot Code Detection)。采用这种方法的虚拟机会周期性地检查各个线程的调用栈顶,如果发现某个(或某些)方法经常出现在栈顶,那这个方法就是“热点方法”。</p><p>基于采样的热点探测的好处是实现简单高效,还可以很容易地获取方法调用关系(将调用堆栈展开即可),缺点是很难精确地确认一个方法的热度,容易因为受到线程阻塞或别的外界因素的影响而扰乱热点探测。</p><h3 id="6-3-3、编译过程"><a class="header-anchor" href="#6-3-3、编译过程">¶</a>6.3.3、编译过程</h3><p>在默认条件下,无论是方法调用产生的标准编译请求,还是栈上替换编译请求,虚拟机在编译器还未完成编译之前,都仍然将按照解释方式继续执行代码,而编译动作则在后台的编译线程中进行。<br>用户可以通过参数<code>-XX:-BackgroundCompilation</code>来禁止后台编译,后台编译被禁止后,当达到触发即时编译的条件时,执行线程向虚拟机提交编译请求以后将会一直阻塞等待,直到编译过程完成再开始执行编译器输出的本地代码。</p><p>那在后台执行编译的过程中,编译器具体会做什么事情呢?服务端编译器和客户端编译器的编译过程是有所差别的。</p><h4 id="客户端编译期"><a class="header-anchor" href="#客户端编译期">¶</a>客户端编译期</h4><p>对于客户端编译器来说,它是一个相对简单快速的三段式编译器,主要的关注点在于局部性的优化,而放弃了许多耗时较长的全局优化手段。</p><ol><li>在第一个阶段,一个平台独立的前端将字节码构造成一种高级中间代码表示(High-Level Intermediate Representation,HIR,即与目标机器指令集无关的中间表示)。HIR使用静态单分配(Static Single Assignment,SSA)的形式来代表代码值,这可以使得一些在HIR的构造过程之中和之后进行的优化动作更容易实现。在此之前编译器已经会在字节码上完成一部分基础优化,如方法内联、常量传播等优化将会在字节码被构造成HIR之前完成。</li><li>在第二个阶段,一个平台相关的后端从HIR中产生低级中间代码表示(Low-Level Intermediate Representation,LIR,即与目标机器指令集相关的中间表示),而在此之前会在HIR上完成另外一些优化,如空值检查消除、范围检查消除等,以便让HIR达到更高效的代码表示形式。</li><li>最后的阶段是在平台相关的后端使用线性扫描算法(Linear Scan Register Allocation)在LIR上分配寄存器,并在LIR上做窥孔(Peephole)优化,然后产生机器代码。客户端编译器大致的执行过程如图</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221234952.png" alt="image-20200922211554031"></p><h4 id="服务端编译期"><a class="header-anchor" href="#服务端编译期">¶</a>服务端编译期</h4><p>而服务端编译器则是专门面向服务端的典型应用场景,并为服务端的性能配置针对性调整过的编译器,也是一个能容忍很高优化复杂度的高级编译器,几乎能达到GNU C++编译器使用-O2参数时的优化强度。它会执行大部分经典的优化动作,如:无用代码消除(Dead Code Elimination)、循环展开(Loop Unrolling)、循环表达式外提(Loop Expression Hoisting)、消除公共子表达式(Common Subexpression Elimination)、常量传播(Constant Propagation)、基本块重排序(Basic Block Reordering)等,还会实施一些与Java语言特性密切相关的优化技术,如范围检查消除(Range Check Elimination)、空值检查消除(Null Check Elimination,不过并非所有的空值检查消除都是依赖编译器优化的,有一些是代码运行过程中自动优化了)等。另外,还可能根据解释器或客户端编译器提供的性能监控信息,进行一些不稳定的预测性激进优化,如守护内联(Guarded Inlining)、分支频率预测(Branch Frequency Prediction)等。</p><p>服务端编译采用的寄存器分配器是一个全局图着色分配器,它可以充分利用某些处理器架构(如RISC)上的大寄存器集合。以即时编译的标准来看,服务端编译器无疑是比较缓慢的,但它的编译速度依然远远超过传统的静态优化编译器,而且它相对于客户端编译器编译输出的代码质量有很大提高,可以大幅减少本地代码的执行时间,从而抵消掉额外的编译时间开销,所以也有很多非服务端的应用选择使用服务端模式的HotSpot虚拟机来运行。</p><h3 id="6-3-4、如何查看JIT编译情况"><a class="header-anchor" href="#6-3-4、如何查看JIT编译情况">¶</a>6.3.4、如何查看JIT编译情况</h3><h4 id="使用JVM参数打印编译信息"><a class="header-anchor" href="#使用JVM参数打印编译信息">¶</a>使用JVM参数打印编译信息</h4><h5 id="查看方法编译情况和方法内联情况"><a class="header-anchor" href="#查看方法编译情况和方法内联情况">¶</a>查看方法编译情况和方法内联情况</h5><p>FastDebug或SlowDebug优化级别的HotSpot虚拟机, 需要自己编译将“–with-debug-level”参数设置为“fastdebug”或者“slowdebug”。</p><pre class="line-numbers language-language-java"><code class="language-language-java">    public static final int NUM = 15000;    public static int doubleValue(int i) {     // 这个空循环用于后面演示JIT代码优化过程        for (int j = 0; j < 100000; j++) {            ;        }        return i * 2;    }    public static long calcSum() {        long sum = 0;        for (int i = 1; i <= 100; i++) {            sum += doubleValue(i);        }        return sum;    }    public static void main(String[] args) {        for (int i = 0; i < NUM; i++) {            calcSum();        }    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>-XX:+PrintCompilation</code>要求虚拟机打印编译信息，其中带有“%”的输出说明是由回边计数器触发的栈上替换编译，输出的信息中可以确认,main()、calcSum()和doubleV alue()方法已经被编译</p><pre class="line-numbers language-language-java"><code class="language-language-java">310   1       java.lang.String::charAt (33 bytes)     329   2       org.fenixsoft.jit.Test::calcSum (26 bytes)     329   3       org.fenixsoft.jit.Test::doubleValue (4 bytes)     332   1%      org.fenixsoft.jit.Test::main @ 5 (20 bytes)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>加上<code>-XX:+PrintInlining</code>要求虚拟机打印方法内联信息，doubleV alue()方法已被内联编译到calcSum()方法中,而calcSum()方法又被内联编译到main()方法里面,所以虚拟机再次执行main()方法的时候(举例而已, main()方法当然不会运行两次),calcSum()和doubleV alue()方法是不会再被实际调用的,没有任何方法分派的开销,它们的代码逻辑都被直接内联到main()方法里面了。</p><pre class="line-numbers language-language-java"><code class="language-language-java">273   1       java.lang.String::charAt (33 bytes)     291   2       org.fenixsoft.jit.Test::calcSum (26 bytes)       @   9       org.fenixsoft.jit.Test::doubleValue  inline (hot)     294   3       org.fenixsoft.jit.Test::doubleValue (4 bytes)     295   1%      org.fenixsoft.jit.Test::main @ 5 (20 bytes)       @   5       org.fenixsoft.jit.Test::calcSum  inline (hot)       @   9       org.fenixsoft.jit.Test::doubleValue  inline (hot)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="查看反汇编代码"><a class="header-anchor" href="#查看反汇编代码">¶</a>查看反汇编代码</h5><p>自己编译或者在网上下载反汇编适配器HSDIS插件配合使用<code>-XX: +PrintAssembly</code>参数要求虚拟机打印编译方法的汇编代码。另外<code>FastDebug</code>或<code>SlowDebug</code>优化级别的HotSpot虚拟机才能直接支持,如果使用<code>Product</code>版的虚拟机,则需要在最前面加入参数<code>-XX: +UnlockDiagnosticVMOptions</code>打开虚拟机诊断模式。</p><p>如果没有HSDIS插件支持,也可以使用<code>-XX:+PrintOptoAssembly</code>(用于服务端模式的虚拟机) 或<code>-XX:+PrintLIR</code>(用于客户端模式的虚拟机)来输出比较接近最终结果的中间代码表示,上面代码被编译后部分反汇编(使用-XX:+PrintOptoAssembly)的输出结果如下所示。对于阅读来说,使用<code>-XX:+PrintOptoAssembly</code>参数输出的伪汇编结果包含了更多的信息(主要是注释),有利于人们阅读、理解虚拟机即时编译器的优化结果。</p><pre><code>…… ……000   B1: #       N1 &lt;- BLOCK HEAD IS JUNK   Freq: 1 000       pushq   rbp           subq    rsp, #16    # Create frame           nop     # nop for patch_verified_entry 006       movl    RAX, RDX    # spill 008       sall    RAX, #1 00a       addq    rsp, 16     # Destroy frame           popq    rbp           testl   rax, [rip + #offset_to_poll_page]    # Safepoint: poll for GC …… ……</code></pre><h5 id="查看本地代码具体生成过程"><a class="header-anchor" href="#查看本地代码具体生成过程">¶</a>查看本地代码具体生成过程</h5><p>如果除了本地代码的生成结果外,还想再进一步跟踪本地代码生成的具体过程,那可以使用参数<code>-XX:+PrintCFGToFile</code>(用于客户端编译器)或<code>-XX:PrintIdealGraphFile</code>(用于服务端编译器)要求Java虚拟机将编译过程中各个阶段的数据(譬如对客户端编译器来说包括字节码、HIR生成、LIR生成、寄存器分配过程、本地代码生成等数据)输出到文件中。然后使用<a href="http://ssw.jku.at/Research/Projects/JVM/CCVis.html" target="_blank" rel="noopener">Java HotSpot Client Compiler Visualizer</a>(用于分析客户端编译器)或<a href="http://ssw.jku.at/General/Staff/TW/igv.html" target="_blank" rel="noopener">Ideal Graph Visualizer</a>(用于分析服务端编译器)打开这些数据文件进行分析。</p><p>服务端编译器的中间代码表示是一种名为理想图(Ideal Graph)的程序依赖图(Program Dependence Graph,PDG),在运行Java程序的FastDebug或SlowDebug优化级别的虚拟机上的参数中加入<code>-XX:PrintIdealGraphLevel=2</code>、<code>-XX:PrintIdealGraphFile=ideal.xml</code>,即时编译后将会产生一个名为ideal.xml的文件,它包含了服务端编译器编译代码的全过程信息,可以使用Ideal Graph Visualizer对这些信息进行分析。</p><h6 id="编译Ideal-Graph-Visualizer及使用"><a class="header-anchor" href="#编译Ideal-Graph-Visualizer及使用">¶</a>编译Ideal Graph Visualizer及使用</h6><p>上面地址里面的是基于JDK7版本的，8及以上都不能用。打算自己基于open jdk9版本编译一份出来，记录下编译步骤：</p><ol><li><p>下载<a href="https://downloads.apache.org/ant/binaries/" target="_blank" rel="noopener">ant构建工具</a>并配置环境变量<code>ANT_HOME=${ANT路径}</code>、<code>PATH=$PATH:$ANT_HOME/bin</code></p></li><li><p>进入openjdk IdealGraphVisualizer路径：<code>${openjdk9 sourcecode 根路径}/hotspot/src/share/tools/IdealGraphVisualizer/</code></p></li><li><p>参考目录下的<code>README.md</code>进行编译，直接运行<code>ant build</code>，但是遇到以下问题：</p><ul><li><p>下载<code>tasks.jar</code>超时：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">download:     [echo] Downloading clusters ide|platform      [get] Getting: http://deadlock.netbeans.org/hudson/job/nbms-and-javadoc/lastSuccessfulBuild/artifact/nbbuild/netbeans/harness/tasks.jar      [get] To: /var/folders/82/yy1bqb7s141_3m40prm43xz40000gn/T/tasks.jar      [get] Error getting http://deadlock.netbeans.org/hudson/job/nbms-and-javadoc/lastSuccessfulBuild/artifact/nbbuild/netbeans/harness/tasks.jar to /var/folders/82/yy1bqb7s141_3m40prm43xz40000gn/T/tasks.jarBUILD FAILED/Users/zhonghongpeng/ClionProjects/jvm/openjdk/hotspot/src/share/tools/IdealGraphVisualizer/build.xml:7: The following error occurred while executing this line:/Users/zhonghongpeng/ClionProjects/jvm/openjdk/hotspot/src/share/tools/IdealGraphVisualizer/nbproject/build-impl.xml:41: The following error occurred while executing this line:/Users/zhonghongpeng/ClionProjects/jvm/openjdk/hotspot/src/share/tools/IdealGraphVisualizer/nbproject/platform.xml:27: java.net.ConnectException: Operation timed out (Connection timed out)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>解决：</p><p>参考了以下链接的描述将<code>./nbproject/platform.properties</code>中的<code>bootstrap.url</code>属性设置成<code>http://bits.netbeans.org/dev/nbms-and-javadoc/lastSuccessfulBuild/artifact/nbbuild/netbeans/harness/tasks.jar</code>。</p><blockquote><p><a href="https://bugs.openjdk.java.net/browse/JDK-8191868" target="_blank" rel="noopener">https://bugs.openjdk.java.net/browse/JDK-8191868</a></p><p><a href="http://hg.openjdk.java.net/jdk/hs/rev/f140bebf0348" target="_blank" rel="noopener">http://hg.openjdk.java.net/jdk/hs/rev/f140bebf0348</a></p></blockquote></li><li><p>下载的<code>catalog.xml.gz</code>文件有问题</p><pre class="line-numbers language-language-java"><code class="language-language-java">[autoupdate] Downloading http://updates.netbeans.org/netbeans/updates/7.4/uc/final/distribution/catalog.xml.gz[autoupdate] 九月 23, 2020 9:37:32 上午 org.netbeans.nbbuild.AutoUpdateCatalogParser getInputSource[autoupdate] 信息: The file at http://updates.netbeans.org/netbeans/updates/7.4/uc/final/distribution/catalog.xml.gz, corresponding to the catalog at http://updates.netbeans.org/netbeans/updates/7.4/uc/final/distribution/catalog.xml.gz, does not look like the gzip file, trying to parse it as the pure xml[autoupdate] java.io.EOFException[autoupdate] at java.util.zip.GZIPInputStream.readUByte(GZIPInputStream.java:268)[autoupdate] at java.util.zip.GZIPInputStream.readUShort(GZIPInputStream.java:258)[autoupdate] at java.util.zip.GZIPInputStream.readHeader(GZIPInputStream.java:164)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>解决：</p><p>参考<code>https://stackoverflow.com/questions/54326975/unable-to-connect-to-the-netbeans-distribution-because-of-zero-sized-file</code>将<code>./nbproject/platform.properties</code>中的<code>autoupdate.catalog.url</code>属性的&quot;http&quot;改成&quot;https&quot;。</p></li></ul></li><li><p>构建完成后授权执行即可：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">zhonghongpeng@bogon IdealGraphVisualizer % chmod 777 ./igv.sh                               zhonghongpeng@bogon IdealGraphVisualizer % ./igv.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>使用参数<code>-XX:PrintIdealGraphLevel=2 -XX:PrintIdealGraphFile=ideal.xml -Xbatch</code>运行上面的代码得到多份<code>ideal&lt;n&gt;.xml</code>(注意参考<code>README.md</code>，其中就说明了最后一个参数如果不加将会导致程序结束后dump的xml文件不完整，导入到Ideal Graph Visualizer会报错)</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235000.png" alt="image-20200923101300031"></p><p>在Ideal Graph Visualizer中全部打开即可进行查看</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235006.png" alt="image-20200923101334213"></p></li></ol><h4 id="利用一些监控工具查看编译情况"><a class="header-anchor" href="#利用一些监控工具查看编译情况">¶</a>利用一些监控工具查看编译情况</h4><h5 id="VisualVM查看编译次数和时间"><a class="header-anchor" href="#VisualVM查看编译次数和时间">¶</a>VisualVM查看编译次数和时间</h5><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235013.png" alt="image-20200917114807396"></p><h5 id="Jconsole查看"><a class="header-anchor" href="#Jconsole查看">¶</a>Jconsole查看</h5><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235019.png" alt="image-20200917114954541"></p><h3 id="6-3-5、分层优化"><a class="header-anchor" href="#6-3-5、分层优化">¶</a>6.3.5、分层优化</h3><p>由于即时编译器编译本地代码需要占用程序运行时间,通常要编译出优化程度越高的代码,所花费的时间便会越长;而且想要编译出优化程度更高的代码,解释器可能还要替编译器收集性能监控信息,这对解释执行阶段的速度也有所影响。为了在程序启动响应速度与运行效率之间达到最佳平衡, HotSpot虚拟机在编译子系统中加入了分层编译的功能<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>,分层编译的概念其实很早就已经提出,但直到JDK 6时期才被初步实现,后来一直处于改进阶段,最终在JDK 7的服务端模式虚拟机中作为默认编译策略被开启。分层编译根据编译器编译、优化的规模与耗时,划分出不同的编译层次,其中包括:</p><ul><li>第0层。程序纯解释执行,并且解释器不开启性能监控功能(Profiling)。</li><li>第1层。使用客户端编译器将字节码编译为本地代码来运行,进行简单可靠的稳定优化,不开启性能监控功能。</li><li>第2层。仍然使用客户端编译器执行,仅开启方法及回边次数统计等有限的性能监控功能。</li><li>第3层。仍然使用客户端编译器执行,开启全部性能监控,除了第2层的统计信息外,还会收集如分支跳转、虚方法调用版本等全部的统计信息。</li><li>第4层。使用服务端编译器将字节码编译为本地代码,相比起客户端编译器,服务端编译器会启用更多编译耗时更长的优化,还会根据性能监控信息进行一些不可靠的激进优化。</li></ul><p>实施分层编译后,解释器、客户端编译器和服务端编译器就会同时工作,热点代码都可能会被多次编译,用客户端编译器获取更高的编译速度,用服务端编译器来获取更好的编译质量,在解释执行的时候也无须额外承担收集性能监控信息的任务,而在服务端编译器采用高复杂度的优化算法时,客户端编译器可先采用简单优化来为它争取更多的编译时间。</p><h4 id="配置执行引擎运行方式"><a class="header-anchor" href="#配置执行引擎运行方式">¶</a>配置执行引擎运行方式</h4><p>缺省情况下 HotSpot VM是采用解释器与即时编译器并存的架构,当然开发人员可以根据具体的应用场景,通过命令显式地为Java虚拟机指定在运行时到底是完全采用解释器执行,还是完全采用即时编译器执行。如下所示:</p><p><code>-Xint</code>：完全采用解释器模式执行程序<br><code>-Xcomp</code>：完全采用即时编译器模式执行程序。如果即时编译出现问题,解释器会介入执行。<br><code>-Xmixed</code>：采用解释器+即时编译器的混合模式共同执行程序</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235029.png" alt="image-20200917142725766"></p><h3 id="6-3-6、编译器优化技术"><a class="header-anchor" href="#6-3-6、编译器优化技术">¶</a>6.3.6、编译器优化技术</h3><h4 id="优化技术概览"><a class="header-anchor" href="#优化技术概览">¶</a><a href="https://wiki.openjdk.java.net/display/HotSpot/PerformanceTacticIndex" target="_blank" rel="noopener">优化技术概览</a></h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235036.png" alt="image-20200923114911958"><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235043.png" alt="image-20200923114932612"></p><p>**即时编译器对这些代码优化变换是建立在源代码转换得的中间表示或者是机器码之上的,绝不是直接在Java源码上去做的。**下面仅仅基于Java源码作一个比喻：</p><h5 id="代码示例"><a class="header-anchor" href="#代码示例">¶</a>代码示例</h5><pre class="line-numbers language-language-java"><code class="language-language-java">static class B {    int value;    final int get() {        return value;    }}public void foo() {    y = b.get();         // ...do stuff...    z = b.get();    sum = y + z;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol><li>方法内联,它的主要目的有两个:一是去除方法调用的成本(如查找方法版本、建立栈帧等); 二是为其他优化建立良好的基础。方法内联膨胀之后可以便于在更大范围上进行后续的优化手段,可以获取更好的优化效果。因此各种编译器一般都会把内联优化放在优化序列最靠前的位置。内联后的代码：</li></ol><pre class="line-numbers language-language-java"><code class="language-language-java">    public void foo() {        y = b.value;             // ...do stuff...        z = b.value;        sum = y + z;    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>冗余访问消除(Redundant Loads Elimination),假设代码中间注释掉的<code>…do stuff…</code>所代表的操作不会改变<code>b.value</code>的值,那么就可以把<code>z=b.value</code>替换为<code>z=y</code>,因为上一句<code>y=b.value</code>已经保证了变量<code>y</code>与<code>b.value</code>是一致的,这样就可以不再去访问对象<code>b</code>的局部变量了。如果把<code>b.value</code>看作一个表达式,那么也可以把这项优化看作一种公共子表达式消除(Common Subexpression Elimination)</li></ol><pre class="line-numbers language-language-java"><code class="language-language-java">    public void foo() {        y = b.value;        // ...do stuff...        z = y;        sum = y + z;    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>复写传播(Copy Propagation),因为这段程序的逻辑之中没有必要使用一个额外的变量z,它与变量y是完全相等的,因此我们可以使用y来代替z。</li></ol><pre class="line-numbers language-language-java"><code class="language-language-java">    public void foo() {        y = b.value;             // ...do stuff...        y = y;        sum = y + y;    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>无用代码消除(Dead Code Elimination),无用代码可能是永远不会被执行的代码,也可能是完全没有意义的代码。因此它又被很形象地称为“Dead Code”, 如<code>y=y</code>是没有意义的</li></ol><pre class="line-numbers language-language-java"><code class="language-language-java">    public void foo() {        y = b.value;            // ...do stuff...        sum = y + y;    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最终优化出来得代码达到的效果是一致的,但是前者比后者省略了许多语句,体现在字节码和机器码指令上的差距会更大,执行效率的差距也会更高。</p><h4 id="最重要的优化技术之一-方法内联"><a class="header-anchor" href="#最重要的优化技术之一-方法内联">¶</a>最重要的优化技术之一:方法内联</h4><p>方法内联,说它是编译器最重要的优化手段,甚至都可以不加上“之一”。内联被业内戏称为优化之母,因为除了消除方法调用的成本之外,它更重要的意义是为其他优化手段建立良好的基础</p><pre class="line-numbers language-language-java"><code class="language-language-java">    public static void foo(Object obj) {        if (obj != null) {            System.out.println("do something");        }    }    public static void testInline(String[] args) {        Object obj = null;        foo(obj);    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上所示的简单例子就揭示了内联对其他优化手段的巨大价值:没有内联,多数其他优化都无法有效进行。例子里<code>testInline()</code>方法的内部全部是无用的代码,但如果不做内联,后续即使进行了无用代码消除的优化,也无法发现任何“Dead Code”的存在。如果分开来看,<code>foo()</code>和<code>testInline()</code>两个方法里面的操作都有可能是有意义的。</p><p>方法内联的优化行为理解起来是没有任何困难的,不过就是把目标方法的代码原封不动地“复制”到发起调用的方法之中,避免发生真实的方法调用而已。但实际上Java虚拟机中的内联过程却远没有想象中容易,甚至如果不是即时编译器做了一些特殊的努力,按照经典编译原理的优化理论,大多数的Java方法都无法进行内联。</p><p>无法内联的原因：只有使用<code>invokespecial</code>指令调用的私有方法、实例构造器、父类方法和使用<code>invokestatic</code>指令调用的静态方法才会在编译期进行解析。除了上述四种方法之外(最多再除去被<code>final</code>修饰的方法这种特殊情况,尽管它使用<code>invokevirtual</code>指令调用,但也是非虚方法,《Java语言规范》中明确说明了这点),其他的Java方法调用都必须在运行时进行方法接收者的多态选择,它们都有可能存在多于一个版本的方法接收者,简而言之,Java语言中默认的实例方法是虚方法。</p><p>对于一个虚方法,编译器<strong>静态地</strong>去做内联的时候很难确定应该使用哪个方法版本, 如果不依赖上下文,是无法确定b的实际类型是什么的。假如有<code>ParentB</code>和<code>SubB</code>是两个具有继承关系的父子类型,并且子类重写了父类的<code>get()</code>方法,那么此时对象<code>obj.get()</code>是执行父类的<code>get()</code>方法还是子类的<code>get()</code>方法,这应该是根据实际类型动态分派的,而实际类型必须在实际运行到这一行代码时才能确定,编译器很难在编译时得出绝对准确的结论。</p><p>更糟糕的情况是,由于Java提倡使用面向对象的方式进行编程,而Java对象的方法默认就是虚方法,可以说Java间接鼓励了程序员使用大量的虚方法来实现程序逻辑。根据上面的分析可知,<strong>内联与虚方法之间会产生“矛盾”</strong>,那是不是为了提高执行性能,就应该默认给每个方法都使用<strong>final关键字</strong>去修饰呢（<strong>即由程序员通过编译器约定的关键字来告诉编译器那些虚方法可以进行内联</strong>）?</p><ul><li>C和C++语言的确是这样做的,默认的方法是非虚方法,如果需要用到多态,就用<code>virtual</code>关键字来修饰</li><li>但Java选择了在虚拟机中解决这个问题。</li></ul><p>为了解决虚方法的内联问题,Java虚拟机首先引入了一种名为<strong>类型继承关系分析(Class Hierarchy Analysis,CHA)的技术</strong>,这是整个应用程序范围内的类型分析技术,<strong>用于确定在目前已加载的类中,某个接口是否有多于一种的实现、某个类是否存在子类、某个子类是否覆盖了父类的某个虚方法等信息</strong>。这样,编译器在进行内联时就会分不同情况采取不同的处理：</p><ul><li><p>如果是非虚方法,那么直接进行内联就可以了,这种的内联是有百分百安全保障的;</p></li><li><p>如果遇到虚方法,则会向CHA查询此方法在当前程序状态下是否真的有多个目标版本可供选择：</p><ul><li><p>如果查询到只有一个版本,那就可以<strong>假设</strong>“应用程序的全貌就是现在运行的这个样子”来进行内联,这种内联被称为守护内联(Guarded Inlining)。</p><p>不过由于Java程序是动态连接的,说不准什么时候就会加载到新的类型从而改变CHA结论,因此这种内联属于<strong>激进预测性优化</strong>,必须预留好“逃生门”,即当假设条件不成立时的“退路”(Slow Path)。假如在程序的后续执行过程中**,虚拟机一直没有加载到会令这个方法的接收者的继承关系发生变化的类**,那这个内联优化的代码就可以一直使用下去。如果加载了导致继承关系发生变化的新类,那么就必须抛弃已经编译的代码,退回到解释状态进行执行,或者重新进行编译。</p></li><li><p>假如向CHA查询出来的结果是该方法确实有多个版本的目标方法可供选择,那即时编译器还将进行最后一次努力,使用<strong>内联缓存</strong>(Inline Cache)的方式来缩减方法调用的开销。这种状态下<strong>方法调用是真正发生</strong>了的,但是比起直接查虚方法表还是要快一些。内联缓存是一个建立在目标方法正常入口之前的缓存,它的工作原理大致为:</p><p>在未发生方法调用之前,内联缓存状态为空,当第一次调用发生后,缓存记录下方法接收者的版本信息,并且每次进行方法调用时都比较接收者的版本。</p><ul><li>如果以后进来的每次调用的方法接收者版本都是一样的,那么这时它就是一种单态内联缓存(Monomorphic Inline Cache)。通过该缓存来调用,比用不内联的非虚方法调用,仅多了一次类型判断的开销而已。</li><li>但如果真的出现方法接收者不一致的情况,就说明程序用到了虚方法的多态特性,这时候会退化成超多态内联缓存(Megamorphic Inline Cache),其开销相当于真正查找虚方法表来进行方法分派。</li></ul></li></ul></li></ul><p>所以说,在多数情况下Java虚拟机进行的方法内联都是一种<strong>激进优化</strong>。事实上,激进优化的应用在高性能的Java虚拟机中比比皆是,极为常见。除了方法内联之外,对于出现概率很小(通过经验数据或解释器收集到的性能监控信息确定概率大小)的隐式异常、使用概率很小的分支等都可以被激进优化“移除”,如果真的出现了小概率事件,这时才会从“逃生门”回到解释状态重新执行。</p><h4 id="最前沿的优化技术之一-逃逸分析"><a class="header-anchor" href="#最前沿的优化技术之一-逃逸分析">¶</a>最前沿的优化技术之一:逃逸分析</h4><p>逃逸分析(Escape Analysis)是目前Java虚拟机中比较前沿的优化技术,它与类型继承关系分析一样,并不是直接优化代码的手段,而是为其他优化措施提供依据的分析技术。</p><p>逃逸分析的基本原理是分析对象动态作用域,当一个对象在方法里面被定义后,它可能被外部方法所引用：</p><ul><li>例如作为调用参数或者返回值传递到其他方法中、赋值到全局变量中,这种称为方法逃逸</li><li>甚至还有可能被外部线程访问到,譬如赋值给可以在其他线程中访问的实例变量,这种称为线程逃逸</li></ul><p>从<strong>不逃逸、方法逃逸到线程逃逸</strong>,称为对象由低到高的不同逃逸程度。</p><p>如果能证明一个对象不会逃逸到方法或线程之外(换句话说是别的方法或线程无法通过任何途径访问到这个对象),或者逃逸程度比较低(只逃逸出方法而不会逃逸出线程),则可能为这个对象实例采取不同程度的优化,如：</p><h5 id="1-栈上分配-Stack-Allocations"><a class="header-anchor" href="#1-栈上分配-Stack-Allocations">¶</a>1&gt;栈上分配(Stack Allocations)<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></h5><p>在Java虚拟机中,Java堆上分配创建对象的内存空间几乎是Java程序员都知道的常识,Java堆中的对象对于各个线程都是共享和可见的,只要持有这个对象的引用,就可以访问到堆中存储的对象数据。虚拟机的垃圾收集子系统会回收堆中不再使用的对象,但回收动作无论是标记筛选出可回收对象,还是回收和整理内存,都需要耗费大量资源。如果确定一个对象不会逃逸出线程之外,那让这个对象在栈上分配内存将会是一个很不错的主意,对象所占用的内存空间就可以随栈帧出栈而销毁。在一般应用中,完全不会逃逸的局部对象和不会逃逸出线程的对象所占的比例是很大的,如果能使用栈上分配,那大量的对象就会随着方法的结束而自动销毁了,垃圾收集子系统的压力将会下降很多。<strong>栈上分配可以支持方法逃逸,但不能支持线程逃逸</strong>。</p><h5 id="2-标量替换-Scalar-Replacement"><a class="header-anchor" href="#2-标量替换-Scalar-Replacement">¶</a>2&gt;标量替换(Scalar Replacement)</h5><p>若一个数据已经无法再分解成更小的数据来表示了,Java虚拟机中的原始数据类型(int、long等数值类型及reference类型等)都不能再进一步分解了,那么这些数据就可以被称为标量。相对的,如果一个数据可以继续分解,那它就被称为聚合量(Aggregate),Java 中的对象就是典型的聚合量。</p><blockquote><p>这里的标量和线性代数中的标量还不是一回事</p></blockquote><p>如果把一个Java对象拆散,根据程序访问的情况,将其用到的成员变量恢复为原始类型来访问,这个过程就称为标量替换。假如逃逸分析能够证明<strong>一个对象不会被方法外部访问</strong>,并且这个对象可以被拆散,那么程序真正执行的时候将可能不去创建这个对象,而改为直接创建它的若干个被这个方法使用的成员变量来代替。<strong>将对象拆分后,除了可以让对象的成员变量在栈上(栈上存储的数据,很大机会被虚拟机分配至物理机器的高速寄存器中存储)分配和读写之外,还可以为后续进一步的优化手段创建条件。标量替换可以视作栈上分配的一种特例,实现更简单(不用考虑整个对象完整结构的分配),但对逃逸程度的要求更高,它不允许对象逃逸出方法范围内</strong>。</p><h5 id="3-同步消除-Synchronization-Elimination"><a class="header-anchor" href="#3-同步消除-Synchronization-Elimination">¶</a>3&gt;同步消除(Synchronization Elimination)</h5><p>线程同步本身是一个相对耗时的过程,如果逃逸分析能够确定一个变量不会逃逸出线程,无法被其他线程访问,那么这个变量的读写肯定就不会有竞争, 对这个变量实施的同步措施也就可以安全地消除掉。</p><p>线程同步的代价是相当高的，同步的后果是降低并发性和性能。同步锁消除能大大提高并发性能。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235054.png" alt="image-20200916150511162"></p><p>以下方法锁对象未发生逃逸，在转换成字节码之后，可以看到还是有加锁字节码指令的，所以前端编译器完全没有参与到逃逸分析和同步锁消除得过程，它完全依赖后端(JIT)编译器。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235100.png" alt="image-20200916150716430"></p><h5 id="逃逸分析发展"><a class="header-anchor" href="#逃逸分析发展">¶</a>逃逸分析发展</h5><p>关于逃逸分析的研究论文早在1999年就已经发表,但直到JDK 6,HotSpot才开始支持初步的逃逸分析,而且到现在这项优化技术尚未足够成熟,仍有很大的改进余地。不成熟的原因主要是逃逸分析的计算成本非常高,甚至不能保证逃逸分析带来的性能收益会高于它的消耗。如果要百分之百准确地判断一个对象是否会逃逸,需要进行一系列复杂的数据流敏感的过程间分析,才能确定程序各个分支执行时对此对象的影响。前面介绍即时编译、提前编译优劣势时提到了过程间分析这种大压力的分析算法正是即时编译的弱项。可以试想一下,<strong>如果逃逸分析完毕后发现几乎找不到几个不逃逸的对象, 那这些运行期耗用的时间就白白浪费了,所以目前虚拟机只能采用不那么准确,但时间压力相对较小的算法来完成分析</strong>。</p><p>在实际的应用程序中,尤其是大型程序中反而发现实施逃逸分析可能出现效果不稳定的情况,或分析过程耗时但却无法有效判别出非逃逸对象而导致性能(即时编译的收益)下降,所以曾经在很长的一段时间里,即使是服务端编译器,也默认不开启逃逸分析<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>,甚至在某些版本(如JDK 6 Update 18)中还曾经完全禁止了这项优化,一直到<strong>JDK 7时这项优化才成为服务端编译器默认开启的选项</strong>。如果有需要,或者确认对程序运行有益,用户也可以使用参数<code>-XX:+DoEscapeAnalysis</code>来手动开启逃逸分析, 开启之后可以通过参数<code>-XX:+PrintEscapeAnalysis</code>来查看分析结果。有了逃逸分析支持之后,用户可以使用参数<code>-XX:+EliminateAllocations</code>来开启标量替换,使用<code>+XX:+EliminateLocks</code>来开启同步消除,使用参数<code>-XX:+PrintEliminateAllocations</code>查看标量的替换情况。</p><h5 id="逃逸分析优化示例"><a class="header-anchor" href="#逃逸分析优化示例">¶</a>逃逸分析优化示例</h5><p>C和C++语言里面原生就支持了栈上分配(不使用new操作符即可)。</p><p>而C#也支持值类型,可以很自然地做到标量替换(但并不会对引用类型做这种优化)。</p><p>在灵活运用栈内存方面,确实是Java的一个弱项。在现在仍处于实验阶段的Valhalla项目里,设计了新的inline关键字用于定义Java的内联类型, <strong>目的是实现与C#中值类型相对标的功能</strong>。有了这个标识与约束,以后逃逸分析做起来就会简单很多。</p><pre class="line-numbers language-language-java"><code class="language-language-java">    // 完全未优化的代码    public int test(int x) {        int xx = x + 2;        Point p = new Point(xx, 42);        return p.getX();    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-language-java"><code class="language-language-java">    // 步骤1:将Point的构造函数和getX()方法进行内联优化    public int test(int x) {        int xx = x + 2;        Point p = point_memory_alloc();   // 在堆中分配P对象的示意方法            p.x = xx;                         // Point构造函数被内联后的样子        p.y = 42         return p.x;                       // Point::getX()被内联后的样子    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-language-java"><code class="language-language-java">    // 步骤2:经过逃逸分析,发现在整个test()方法的范围内Point对象实例不会发生任何程度的逃逸, 这样可以对它进行标量替换优化,把其内部的x和y直接置换出来,分解为test()方法内的局部变量,从而避免Point对象实例被实际创建    public int test(int x) {        int xx = x + 2;        int px = xx;        int py = 42         return px;    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-language-java"><code class="language-language-java">    // 步骤3:通过数据流分析,发现py的值其实对方法不会造成任何影响,那就可以放心地去做无效代码消除得到最终优化结果    public int test(int x) {        return x + 2;    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h5 id="参考阅读"><a class="header-anchor" href="#参考阅读">¶</a>参考阅读</h5><p><a href="https://www.jianshu.com/p/20bd2e9b1f03" target="_blank" rel="noopener">浅谈Hotspot逃逸分析</a></p><h4 id="语言无关的经典优化技术之一-公共子表达式消除"><a class="header-anchor" href="#语言无关的经典优化技术之一-公共子表达式消除">¶</a>语言无关的经典优化技术之一:公共子表达式消除</h4><p>公共子表达式消除是一项非常经典的、普遍应用于各种编译器的优化技术,它的含义是:如果一个表达式E之前已经被计算过了,并且从先前的计算到现在E中所有变量的值都没有发生变化,那么E 的这次出现就称为公共子表达式。对于这种表达式,没有必要花时间再对它重新进行计算,只需要直接用前面计算过的表达式结果代替E。如果这种优化仅限于<strong>程序基本块内</strong>,便可称为局部公共子表达式消除(Local Common Subexpression Elimination),如果这种优化的范围涵盖了多个基本块,那就称为全局公共子表达式消除(Global Common Subexpression Elimination)。</p><blockquote><p>基本块可以通俗理解为一个没有嵌套的大括号范围，如：<code>if</code>语句块、<code>while</code>语句块等。</p></blockquote><pre><code>int d = (c * b) * 12 + a + (a + b * c);</code></pre><p>如果这段代码交给Javac编译器则不会进行任何优化,那生成的代码如下</p><pre><code>iload_2       // b imul          // 计算b*c bipush 12     // 推入12 imul          // 计算(c * b) * 12 iload_1       // a iadd          // 计算(c * b) * 12 + a iload_1       // a iload_2       // b iload_3       // c imul          // 计算b * c iadd          // 计算a + b * c iadd          // 计算(c * b) * 12 + a + a + b * c istore 4</code></pre><p>当这段代码进入虚拟机即时编译器后,它将进行如下优化:编译器检测到c<em>b与b</em>c是一样的表达式,而且在计算期间b与c的值是不变的。因此这条表达式就可能被视为:</p><pre><code>int d = E * 12 + a + (a + E);</code></pre><p>这时候,编译器还可能(取决于哪种虚拟机的编译器以及具体的上下文而定)进行另外一种优化——代数化简(Algebraic Simplification),在E本来就有乘法运算的前提下,把表达式变为:</p><pre><code>int d = E * 13 + a + a;</code></pre><h4 id="语言相关的经典优化技术之一-数组边界检查消除"><a class="header-anchor" href="#语言相关的经典优化技术之一-数组边界检查消除">¶</a>语言相关的经典优化技术之一:数组边界检查消除</h4><p>组边界检查消除(Array Bounds Checking Elimination)是即时编译器中的一项语言相关的经典优化技术。我们知道Java语言是一门动态安全的语言,对数组的读写访问也不像C、C++那样实质上就是裸指针操作。如果有一个数组<code>foo[]</code>,在Java语言中访问数组元素<code>foo[i]</code>的时候系统将会自动进行上下界的范围检查,即i必须满足<code>i&gt;=0&amp;&amp;i&lt;foo.length</code>的访问条件,否则将抛出一个运行时异常: <code>java.lang.ArrayIndexOutOfBoundsException</code>。这对软件开发者来说是一件很友好的事情,即使程序员没有专门编写防御代码,也能够避免大多数的溢出攻击。但是对于虚拟机的执行子系统来说,<strong>每次数组元素的读写都带有一次隐含的条件判定操作,对于拥有大量数组访问的程序代码,这必定是一种性能负担</strong>。</p><p>无论如何,为了安全,数组边界检查肯定是要做的,但数组边界检查是不是必须在运行期间一次不漏地进行则是可以“商量”的事情。例如：</p><ul><li><p>下面这个简单的情况:<strong>数组下标是一个常量</strong>,如<code>foo[3]</code>,<strong>只要在编译期根据数据流分析来确定<code>foo.length</code>的值</strong>,并判断下标<code>3</code>没有越界,就去掉检查的代码, 在执行的时候就没有了检查边界的那一步了。</p></li><li><p>更加常见的情况是,数组访问发生在循环之中,并且使用循环变量来进行数组的访问。如果编译器<strong>只要通过数据流分析就可以判定循环变量的取值范围永远在区间<code>[0,foo.length)</code>之内</strong>,那么在循环中就可以把整个数组的上下界检查消除掉,这可以节省很多次的条件判断操作。</p></li><li><p>把这个数组边界检查的例子放在更高的视角来看,大量的安全检查使编写Java程序比编写C和C<ins>程序容易了很多,比如:数组越界会得到<code>ArrayIndexOutOfBoundsException</code>异常;空指针访问会得到<code>NullPointException</code>异常;除数为零会得到<code>ArithmeticException</code>异常……在C和C</ins>程序中出现类似的问题,一个不小心就会出现<code>Segment Fault</code>信号或者Windows编程中常见的“XXX内存不能为Read/Write”之类的提示,处理不好程序就直接崩溃退出了。但这些安全检查也导致出现相同的程序, 从而使Java比C和C++要做更多的事情(各种检查判断),这些事情就会导致一些隐式开销,如果不处理好它们,就很可能成为一项“Java语言天生就比较慢”的原罪。</p><p>为了消除这些隐式开销,<strong>除了如数组边界检查优化这种尽可能把运行期检查提前到编译期完成的思路之外,还有一种避开的处理思路——隐式异常处理</strong>,Java中空指针检查和算术运算中除数为零的检查都采用了这种方案：</p><p>虚拟机会注册一个<code>Segment Fault</code>信号的异常处理器,此时不用进行任何检查,而代价就是发生空指针调用或者除0的时候,<strong>必须转到异常处理器中恢复中断并抛出<code>NullPointException</code>或者<code>ArithmeticException</code>异常</strong>。进入异常处理器的过程涉及进程从用户态转到内核态中处理的过程,结束后会再回到用户态,速度远比一次判空检查要慢得多。当这样的错误发生极少的时候,隐式异常优化是值得的,但假如发生很频繁,这样的优化反而会让程序更慢。幸好HotSpot虚拟机足够聪明,它会根据运行期收集到的性能监控信息自动选择最合适的方案。</p></li></ul><h2 id="6-4、提前编译器：AOT"><a class="header-anchor" href="#6-4、提前编译器：AOT">¶</a>6.4、提前编译器：AOT</h2><p>前编译在Java技术体系中并不是新事物。1996年JDK 1.0发布,Java有了正式的运行环境,第一个可以使用外挂即时编译器的Java版本是1996年7月发布的JDK 1.0.2,而Java提前编译器的诞生并没有比这晚多少。仅几个月后,IBM公司就推出了第一款用于Java语言的提前编译器(IBM High Performance Compiler for Java)。在1998年,GNU组织公布了著名的GCC家族(GNU Compiler Collection)的新成员GNU Compiler for Java(GCJ,2018年从GCC家族中除名),这也是一款Java的提前编译器[1],而且曾经被广泛应用。在OpenJDK流行起来之前,各种Linux发行版带的Java实现通常就是GCJ。</p><p>但是提前编译很快又在Java世界里沉寂了下来,因为当时Java的一个核心优势是平台中立性,其宣传口号是“一次编译,到处运行”,这与平台相关的提前编译在理念上就是直接冲突的。GCJ出现之后在长达15年的时间里,提前编译这条故事线上基本就再没有什么大的新闻和进展了。</p><p>现在提前编译产品和对其的研究有着两条明显的分支:</p><ul><li>一条分支是做与传统C、C++编译器类似的,在程序运行之前把程序代码编译成机器码的静态翻译工作，这是传统的提前编译应用形式：<ol><li>它在Java中存在的价值直指即时编译的最大弱点即时编译要占用程序运行时间和运算资源。即使现在先进的即时编译器已经足够快,但是,无论如何,即时编译消耗的时间都是原本可用于程序运行的时间,消耗的运算资源都是原本可用于程序运行的资源,这个约束从未减弱,更不会消失。在编译过程中最耗时的优化措施之一是通过“过程间分析”(Inter-Procedural Analysis,IPA,也经常被称为全程序分析,即Whole Program Analysis)来获得诸如某个程序点上某个变量的值是否一定为常量、某段代码块是否永远不可能被使用、在某个点调用的某个虚方法是否只能有单一版本等的分析结论。这些信息对生成高质量的优化代码有着极为巨大的价值,但是要精确(譬如对流敏感、对路径敏感、对上下文敏感、对字段敏感)得到这些信息, 必须在全程序范围内做大量极耗时的计算工作,目前所有常见的Java虚拟机对过程间分析的支持都相当有限,要么借助大规模的方法内联来打通方法间的隔阂,以过程内分析(Intra-Procedural Analysis, 只考虑过程内部语句,不考虑过程调用的分析)来模拟过程间分析的部分效果;要么借助可假设的激进优化,不求得到精确的结果,只求按照最可能的状况来优化,有问题再退回来解析执行。</li><li>但如果是在程序运行之前进行的静态编译,这些耗时的优化就可以放心大胆地进行了,譬如Graal VM中的Substrate VM,在创建本地镜像的时候,就会采取许多原本在HotSpot即时编译中并不会做的全程序优化措施以获得更好的运行时性能,反正做镜像阶段慢一点并没有什么大影响。</li></ol></li><li>另外一条分支是把原本即时编译器在运行时要做的编译工作提前做好并保存下来,下次运行到这些代码(譬如公共库代码在被同一台机器其他Java进程使用)时直接把它加载进来使用。本质是给即时编译器做缓存加速,去改善Java程序的启动时间,以及需要一段时间预热后才能到达最高性能的问题。这种提前编译被称为动态提前编译(Dynamic AOT)或者索性就大大方方地直接叫即时编译缓存(JIT Caching)。<ul><li>真正引起业界普遍关注的是OpenJDK/OracleJDK 9中所带的Jaotc提前编译器,这是一个基于Graal编译器实现的新工具,目的是让用户可以针对目标机器,为应用程序进行提前编译。HotSpot运行时可以直接加载这些编译的结果,实现加快程序启动速度,减少程序达到全速运行状态所需时间的目的。这里面确实有比较大的优化价值,试想一下,各种Java应用最起码会用到Java的标准类库,如java.base等模块,如果能够将这个类库提前编译好,并进行比较高质量的优化,显然能够节约不少应用运行时的编译成本。</li><li>这的确是很好的想法,但实际应用起来并不是那么容易,原因是这种提前编译方式不仅要和目标机器相关,甚至还必须与HotSpot虚拟机的运行时参数绑定。譬如虚拟机运行时采用了不同的垃圾收集器,这原本就需要即时编译子系统的配合(典型的如生成内存屏障代码,见第3章相关介绍)才能正确工作,要做提前编译的话,自然也要把这些配合的工作平移过去。至于前面提到过的提前编译破坏平台中立性、字节膨胀等缺点当然还存在,这里就不重复了。尽管还有许多困难,但提前编译无疑已经成为一种极限榨取性能(启动、响应速度)的手段,且被官方JDK关注,相信日后会更加灵活、更加容易使用</li></ul></li></ul><h3 id="和JIT编译对比"><a class="header-anchor" href="#和JIT编译对比">¶</a>和JIT编译对比</h3><h4 id="性能分析制导优化-Profile-Guided-Optimization-PGO"><a class="header-anchor" href="#性能分析制导优化-Profile-Guided-Optimization-PGO">¶</a>性能分析制导优化(Profile-Guided Optimization,PGO)</h4><p>在解释器或者客户端编译器运行过程中,会不断收集性能监控信息,譬如某个程序点抽象类通常会是什么实际类型、条件判断通常会走哪条分支、方法调用通常会选择哪个版本、循环通常会进行多少次等,这些数据一般在静态分析时是无法得到的,或者不可能存在确定且唯一的解, 最多只能依照一些启发性的条件去进行猜测。但在动态运行时却能看出它们具有非常明显的偏好性。</p><p>如果一个条件分支的某一条路径执行特别频繁,而其他路径鲜有问津,那就可以把热的代码集中放到一起,集中优化和分配更好的资源(分支预测、寄存器、缓存等)给它。</p><h4 id="激进预测性优化-Aggressive-Speculative-Optimization"><a class="header-anchor" href="#激进预测性优化-Aggressive-Speculative-Optimization">¶</a>激进预测性优化(Aggressive Speculative Optimization)</h4><p>这也已经成为很多即时编译优化措施的基础。静态优化无论如何都必须保证优化后所有的程序外部可见影响(不仅仅是执行结果) 与优化前是等效的,不然优化之后会导致程序报错或者结果不对,若出现这种情况,则速度再快也是没有价值的。然而,相对于提前编译来说,即时编译的策略就可以不必这样保守,如果性能监控信息能够支持它做出一些正确的可能性很大但无法保证绝对正确的预测判断,就已经可以大胆地按照高概率的假设进行优化,万一真的走到罕见分支上,大不了退回到低级编译器甚至解释器上去执行,并不会出现无法挽救的后果。只要出错概率足够低,这样的优化往往能够大幅度降低目标程序的复杂度, 输出运行速度非常高的代码。譬如在Java语言中,默认方法都是虚方法调用,部分C、C++程序员(甚至一些老旧教材)会说虚方法是不能内联的,但如果Java虚拟机真的遇到虚方法就去查虚表而不做内联的话,Java技术可能就已经因性能问题而被淘汰很多年了。实际上虚拟机会通过类继承关系分析等一系列激进的猜测去做去虚拟化(Devitalization),以保证绝大部分有内联价值的虚方法都可以顺利内联。内联是最基础的一项优化措施。(即编译期还有一个解释器逃生门)</p><h4 id="链接时优化-Link-Time-Optimization-LTO"><a class="header-anchor" href="#链接时优化-Link-Time-Optimization-LTO">¶</a>链接时优化(Link-Time Optimization,LTO)</h4><p>Java语言天生就是动态链接的,一个个Class文件在运行期被加载到虚拟机内存当中,然后在即时编译器里产生优化后的本地代码,这类事情在Java程序员眼里看起来毫无违和之处。但如果类似的场景出现在使用提前编译的语言和程序上,譬如C、C<ins>的程序要调用某个动态链接库的某个方法,就会出现很明显的边界隔阂,还难以优化。这是因为主程序与动态链接库的代码在它们编译时是完全独立的,两者各自编译、优化自己的代码。这些代码的作者、编译的时间,以及编译器甚至很可能都是不同的,当出现跨链接库边界的调用时,那些理论上应该要做的优化——譬如做对调用方法的内联,就会执行起来相当的困难。如果刚才说的虚方法内联让C、C</ins>程序员理解还算比较能够接受的话(其实C++编译器也可以通过一些技巧来做到虚方法内联),那这种跨越动态链接库的方法内联在他们眼里可能就近乎于离经叛道了(但实际上依然是可行的)。</p><h3 id="最大好处"><a class="header-anchor" href="#最大好处">¶</a>最大好处</h3><p>Java虚拟机加载已经预编译成二进制库,可以直接执行。不必等待即时编译器的预热,减少Java应用给人带来“第一次运行慢”的不良体验。</p><h3 id="缺点"><a class="header-anchor" href="#缺点">¶</a>缺点</h3><ul><li>破坏了java&quot;一次编译,到处运行”,必须为每个不同硬件、OS编译对应的发行包。</li><li>降低了Java链接过程的动态性,加载的代码在编译期就必须全部已知。</li><li>还需要继续优化中,最初只支持 Linux x64 java base</li></ul><h3 id="实战：Jaotc的提前编译"><a class="header-anchor" href="#实战：Jaotc的提前编译">¶</a>实战：Jaotc的提前编译</h3><p>JDK 9引入了用于支持对Class文件和模块进行提前编译的工具Jaotc,以减少程序的启动时间和到达全速性能的预热时间,但由于这项功能必须针对特定物理机器和目标虚拟机的运行参数来使用,加之限制太多,Java开发人员对此了解、使用普遍比较少</p><p>我们首先通过一段测试代码(什么代码都可以,最简单的HelloWorld都可以,内容笔者就不贴了)来演示Jaotc的基本使用过程,操作如下:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ javac HelloWorld.java$ java HelloWorld Hello World! $ jaotc --output libHelloWorld.so HelloWorld.class <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>通过以上命令,就生成了一个名为<code>libHelloWorld.so</code>的库,我们可以使用Linux的<code>ldd</code>命令来确认这是否是一个静态链接库,使用<code>mn</code>命令来确认其中是否包含了HelloWorld的构造函数和<code>main()</code>方法的入口信息,操作如下</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ ldd libHelloWorld.so statically linked $ nm libHelloWorld.so ……0000000000002a20 t HelloWorld.()V 0000000000002b20 t HelloWorld.main([Ljava/lang/String;)V ……<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>现在我们就可以使用这个静态链接库而不是Class文件来输出HelloWorld了:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"> java -XX:AOTLibrary=./libHelloWorld.so HelloWorld Hello World!<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>提前编译一个HelloWorld只具备演示价值,下一步我们来做更有实用意义的事情:把<code>java.base</code>模块编译成类似的静态链接库。<code>java.base</code>包含的代码数量庞大,虽然其中绝大部分内容现在都能被Jaotc的提前编译所支持了,但总还有那么几个“刺头”会导致编译异常。因此我们要建立一个编译命令文件来排除这些目前还不支持提前编译的方法,将此文件取名为<code>java.base-list.txt</code>,其具体内容如下:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># jaotc: java.lang.StackOverflowError exclude sun.util.resources.LocaleNames.getContents()[[Ljava/lang/Object; exclude sun.util.resources.TimeZoneNames.getContents()[[Ljava/lang/Object; exclude sun.util.resources.cldr.LocaleNames.getContents()[[Ljava/lang/Object; exclude sun.util.resources..*.LocaleNames_.*.getContents\(\)\[\[Ljava/lang/Object; exclude sun.util.resources..*.LocaleNames_.*_.*.getContents\(\)\[\[Ljava/lang/Object; exclude sun.util.resources..*.TimeZoneNames_.*.getContents\(\)\[\[Ljava/lang/Object; exclude sun.util.resources..*.TimeZoneNames_.*_.*.getContents\(\)\[\[Ljava/lang/Object; # java.lang.Error: Trampoline must not be defined by the bootstrap classloader exclude sun.reflect.misc.Trampoline.<clinit>()V exclude sun.reflect.misc.Trampoline.invoke(Ljava/lang/reflect/Method;Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object; # JVM asserts exclude com.sun.crypto.provider.AESWrapCipher.engineUnwrap([BLjava/lang/String;I)Ljava/security/Key; exclude sun.security.ssl.* exclude sun.net.RegisteredDomain.<clinit>()V # Huge methods exclude jdk.internal.module.SystemModules.descriptors()[Ljava/lang/module/ModuleDescriptor;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后我们就可以开始进行提前编译了,使用的命令如下所示:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">jaotc -J-XX:+UseCompressedOops -J-XX:+UseG1GC -J-Xmx4g --compile-for-tiered --info --compile-commands java.base-list.txt --output libjava.base-coop.so --module java.base<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上面Jaotc用了<code>-J</code>参数传递与目标虚拟机相关的运行时参数,这些运行时信息与编译的结果是直接相关的,编译后的静态链接库只能支持运行在相同参数的虚拟机之上,如果需要支持多种虚拟机运行参数(譬如采用不同垃圾收集器、是否开启压缩指针等)的话,可以花点时间为每一种可能用到的参数组合编译出对应的静态链接库。此外,由于Jaotc是基于Graal编译器开发的,所以现在ZGC和Shenandoah收集器还不支持Graal编译器,自然它们在Jaotc上也是无法使用的。事实上,目前Jaotc只支持G1和Parallel(PS+PS Old)两种垃圾收集器。使用Jaotc编译java.base模块的输出结果如下所示:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ jaotc -J-XX:+UseCompressedOops -J-XX:+UseG1GC -J-Xmx4g --compile-for-tiered --info --compile-commands java.base-list.txt --output libjava.base-coop.so --module java.base Compiling libjava.base-coop.so...6177 classes found (335 ms) 55845 methods total, 49575 methods to compile (1037 ms) Compiling with 4 threads ……49575 methods compiled, 0 methods failed (138821 ms) Parsing compiled code (906 ms) Processing metadata (10867 ms) Preparing stubs binary (0 ms) Preparing compiled binary (103 ms) Creating binary: libjava.base-coop.o (2719 ms) Creating shared library: libjava.base-coop.so (5812 ms) Total time: 163609 ms <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>编译完成后,我们就可以使用提前编译版本的<code>java.base</code>模块来运行Java程序了,方法与前面运行HelloWorld是一样的,用<code>-XX:AOTLibrary</code>来指定链接库位置即可,譬如:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">java -XX:AOTLibrary=java_base/libjava.base-coop.so,./libHelloWorld.so HelloWorld Hello World!<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>我们还可以使用<code>-XX:+PrintAOT</code>参数来确认哪些方法使用了提前编译的版本,从输出信息中可以看到,如果不使用提前编译版本的<code>java.base</code>模块,就只有HelloWord的构造函数和<code>main()</code>方法是提前编译版本的</p><pre class="line-numbers language-language-java"><code class="language-language-java">$ java -XX:+PrintAOT -XX:AOTLibrary=./libHelloWorld.so HelloWorld      11    1     loaded    ./libHelloWorld.so  aot library     105    1     aot[ 1]   HelloWorld.()V     105    2     aot[ 1]   HelloWorld.main([Ljava/lang/String;)V Hello World! <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但如果加入<code>libjava.base-coop.so</code>,那使用到的几乎所有的标准Java SE API都是被提前编译好的,输出如下:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">java -XX:AOTLibrary=java_base/libjava.base-coop.so,./libHelloWorld.so HelloWorld Hello World!13    1     loaded    java_base/libjava.base-coop.so  aot library     13    2     loaded    ./libHelloWorld.so  aot library [Found  [Z  in  java_base/libjava.base-coop.so] …… // 省略其他输出[Found  [J  in  java_base/libjava.base-coop.so]     31    1     aot[ 1]   java.lang.Object.()V     31    2     aot[ 1]   java.lang.Object.finalize()V …… // 省略其他输出<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>目前状态的Jaotc还有许多需要完善的地方,仍难以直接编译SpringBoot、MyBatis这些常见的第三方工具库,甚至在众多Java标准模块中,能比较顺利编译的也只有java.base模块而已。不过随着Graal编译器的逐渐成熟,相信Jaotc前途还是可期的。</p><p>此外除了Jaotc,同样有发展潜力的Substrate VM也不应被忽视。Jaotc做的提前编译属于本节开头所说的“第二条分支”,即做即时编译的缓存;而Substrate VM则是选择的“第一条分支”,做的是传统的静态提前编译。</p><h2 id="6-5、Graal"><a class="header-anchor" href="#6-5、Graal">¶</a>6.5、Graal</h2><p>自JDK10起, HotSpot又加入一个全新的编译器: Graal编译器，它是HotSpot即时编译器以及提前编译器共同的最新成果。编译效果短短几年时间就追评了C2编译器。未来可期。目前,带着“实验状态&quot;标签,需要使用开关参数<code>-xx:+UnlockExperimentalVMOptions</code>、<code>-xx:+UseJVMCICompiler</code>去激活,才可以使用。</p><h3 id="历史背景"><a class="header-anchor" href="#历史背景">¶</a>历史背景</h3><p>2012年,Graal编译器从Maxine虚拟机(也是一款Java虚拟机)项目中分离,成为一个独立发展的Java编译器项目,Oracle Labs希望它最终能够成为一款高编译效率、高输出质量、支持提前编译和即时编译,同时支持应用于包括HotSpot在内的不同虚拟机的编译器。<strong>由于这个编译器使用Java编写</strong>,代码清晰,又继承了许多来自HotSpot的服务端编译器的高质量优化技术,所以无论是科技企业还是高校研究院,都愿意在它上面研究和开发新编译技术。HotSpot服务端编译器的创造者Cliff Click自己就对Graal编译器十分推崇,并且公开表示再也不会用C、C++去编写虚拟机和编译器了。Twitter的Java虚拟机团队也曾公开说过C2目前犹如一潭死水, 亟待一个替代品,因为在它上面开发、改进实在太困难了。</p><p>Graal编译器在JDK 9时以Jaotc提前编译工具的形式首次加入到官方的JDK中,从JDK 10起,Graal 编译器可以替换服务端编译器,成为HotSpot分层编译中最顶层的即时编译器。这种可替换的即时编译器架构的实现,得益于HotSpot编译器接口的出现。</p><p>早期的Graal曾经同C1及C2一样,与HotSpot的协作是紧耦合的,这意味着每次编译Graal均需重新编译整个HotSpot。JDK 9时发布的JEP 243:Java虚拟机编译器接口(Java-Level JVM Compiler Interface,JVMCI)使得Graal可以从HotSpot的代码中分离出来。JVMCI主要提供如下三种功能:</p><ul><li><p>响应HotSpot的编译请求,并将该请求分发给Java实现的即时编译器。</p></li><li><p>允许编译器访问HotSpot中与即时编译相关的数据结构,包括类、字段、方法及其性能监控数据等,并提供了一组这些数据结构在Java语言层面的抽象表示。</p></li><li><p>提供HotSpot代码缓存(Code Cache)的Java端抽象表示,允许编译器部署编译完成的二进制机器码。</p></li></ul><p>综合利用上述三项功能,我们就可以把一个在HotSpot虚拟机外部的、用Java语言实现的即时编译器(不局限于Graal)集成到HotSpot中,响应HotSpot发出的最顶层的编译请求,并将编译后的二进制代码部署到HotSpot的代码缓存中。此外,单独使用上述第三项功能,又可以绕开HotSpot的即时编译系统,让该编译器直接为应用的类库编译出二进制机器码,将该编译器当作一个提前编译器去使用(如Jaotc)。</p><h3 id="构建编译调试环境"><a class="header-anchor" href="#构建编译调试环境">¶</a>构建编译调试环境</h3><p>由于Graal编译器要同时支持Graal VM下的各种子项目,如Truffle、Substrate VM、Sulong等,还要支持作为HotSpot和Maxine虚拟机的即时编译器,所以只用Maven或Gradle的话,配置管理过程会相当复杂。为了降低代码管理、依赖项管理、编译和测试等环节的复杂度,Graal团队专门用Python 2写了一个名为mx的小工具来自动化做好这些事情。我们要构建Graal的调试环境,第一步要先把构建工具mx 安装好,这非常简单,进行如下操作即可:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ git clone https://github.com/graalvm/mx.git $ export PATH=`pwd`/mx:$PATH<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然Graal编译器是以Java代码编写的,那第二步自然是要找一个合适的JDK来编译。考虑到Graal VM项目是基于OpenJDK 8开发的,而JVMCI接口又在JDK 9以后才会提供,所以Graal团队提供了一个**<a href="https://github.com/graalvm/graal-jvmci-8" target="_blank" rel="noopener">带有JVMCI功能的OpenJDK 8版本</a><strong>,我们可以选择这个版本的JDK 8来进行编译。如果只关注Graal 编译器在HotSpot上的应用而不想涉及Graal VM其他方面时,可直接采用</strong>JDK 9及之后的标准Open/OracleJDK**。选择好JDK版本后,设置JAV A_HOME环境变量即可,这是编译过程中唯一需要手工处理的依赖:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">export JAVA_HOME=/usr/lib/jvm/oraclejdk1.8.0_212-jvmci-20-b01<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>第三步是获取Graal编译器代码,编译器部分的代码是与整个Graal VM放在一块的,我们把Graal VM复制下来,大约有700MB,操作如下:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ git clone https://github.com/graalvm/graal.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其他目录中存放着Truffle、Substrate VM、Sulong等其他项目,这些在本次实战中不会涉及。进入compiler子目录,使用mx构建Graal编译器,操作如下:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ cd graal/compiler $ mx build<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>由于整个构建过程需要的依赖项都可以自动处理,需要手动处理的只有OpenJDK一个,所以编译一般不会出现什么问题,大概两三分钟编译即可完成。此时其实已经可以修改、调试Graal编译器了。mx工具能够支持Eclipse、Intellij IDEA和NetBeans三种主流的Java IDE项目的创建, Graal团队中使用Eclipse占多数,支持也最好,生成eclipse配置文件如下</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ cd graal/compiler $ mx eclipseinit<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>无论使用哪种IDE,都需要把IDE配置中使用的Java堆修改到2GB或以上,才能保证Graal在IDE中的编译构建能够顺利进行,譬如Eclipse默认配置(eclipse.ini文件)下的Java堆最大为1GB,这是不够的。设置完成后,在Eclipse中选择File-&gt;Open Projects from File System,再选择Graal项目的根目录,将会导入整个Graal VM</p><p>图</p><p>如果你采用的是JDK 8,那么要记得在Eclipse中也必须将那个带有JVMCI功能的特殊JDK 8用作Eclipse里面“Java SE-1.8”的环境配置(Windows-&gt;Preferences-&gt;Java-&gt;Install JREs-&gt;Execution Environments-&gt;Java SE-1.8),此外,还需要手工将以其他版本号结尾的工程关闭。这对于采用其他版本JDK来编译的读者也是一样的。到此为止,整个编译、调试环境就已经构建完毕。</p><h3 id="JVMCI编译器接口"><a class="header-anchor" href="#JVMCI编译器接口">¶</a>JVMCI编译器接口</h3><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>准确地说,应当是回边的次数而不是循环次数,因为并非所有的循环都是回边,如空循环实际上就可以视为自己跳转到自己的过程,因此并不算作控制流向后跳转,也不会被回边计数器统计。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>分层编译在JDK 6时期出现,到JDK 7之前都需要使用<code>-XX:+TieredCompilation</code>参数来手动开启, 如果不开启分层编译策略,而虚拟机又运行在服务端模式,服务端编译器需要性能监控信息提供编译依据,则是由解释器收集性能监控信息供服务端编译器使用。分层编译的相关资料可参见: <a href="http://weblogs.java.net/blog/forax/archive/2010/09/04/tiered-compilation%E3%80%82" target="_blank" rel="noopener">http://weblogs.java.net/blog/forax/archive/2010/09/04/tiered-compilation。</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>由于复杂度等原因,HotSpot中目前暂时还没有做这项优化,但一些其他的虚拟机(如Excelsior JET)使用了这项优化 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>从JDK 6 Update 23开始,服务端编译器中开始才默认开启逃逸分析。 <a href="#fnref4" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>14_GC关键概念补充</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/14-gc-guan-jian-gai-nian-bu-chong/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/14-gc-guan-jian-gai-nian-bu-chong/</url>
      
        <content type="html"><![CDATA[<h1><code>System.gc()</code>的理解</h1><p>在默认情况下,通过 <code>System.gc()</code>者 <code>Runtime.getRuntime().gc()</code>的调用,<strong>会显式触发Full GC</strong>,同时对老年代和新生代进行回收,尝试释放被丢弃对象占用的内存。然而<code>System.gc()</code>调用附带一个免责声明,无法保证对垃圾收集器的调用。</p><p>JVM实现者可以通过<code>System.gc()</code>调用来决定JVM的GC行为。而一般情况下,垃圾回收应该是自动进行的,无须手动触发,否则就太过于麻烦了。在一些特殊情况下,如我们正在编写一个性能基准,我们可以在运行之间调用<code>System.gc()</code>。</p><p><code>System.runFinalization()</code>方法会强制调用所有进入F-Queue的对象的<code>finalize()</code>方法(只有重写了该方法才会进入该Queue)。</p><h1>内存溢出与内存泄露</h1><h2 id="内存溢出-OOM"><a class="header-anchor" href="#内存溢出-OOM">¶</a>内存溢出(OOM)</h2><p>内存溢出相对于内存泄漏来说,尽管更容易被理解,但是同样的,内存溢出也是引发程序崩溃的罪魁祸首之一。由于GC一直在发展,所有一般情况下除非应用程序占用的内存增长速度非常快,造成垃圾回收已经跟不上内存消耗的速度,否则不太容易出现OOM的情况。</p><p>大多数情况下,GC会进行各种年龄段的垃圾回收,实在不行了就放大招,来一次独占式的Full GC操作,这时候会回收大量的内存,供应用程序继续使用。</p><p>javadoc中对OutOfMemoryError的解释是,没有空闲内存,并且垃圾收集器也无法提供更多内存。</p><h3 id="一般原因"><a class="header-anchor" href="#一般原因">¶</a>一般原因</h3><p>首先说没有空闲内存的情况:说明Java虚拟机的堆内存不够。原因有二:</p><ol><li><p>Java虚拟机的堆内存设置过小。</p><p>比如:可能存在内存泄漏问题;也很有可能就是堆的大小不合理,比如我们要处理比较可观的数据量,但是没有显式指定JVM堆大小或者指定数值偏小。我们可以通过参数<code>-Xms</code>、<code>-Xmx</code>来调整</p></li><li><p>代码中创建了大量大对象,并且长时间不能被垃圾收集器收集(存在被引用)</p><p>对于老版本的 Oracle JDK,因为永久代的大小是有限的,并且JVM对永久代垃圾回收(如,常量池回收、卸载不再需要的类型)非常不积极,所以当我们不断添加新类型的时候,永久代出现OutOfMemoryError也非常多见,尤其是在运行时存在大量动态类型生成的场合;类似 intern字符串缓存占用太多空间,也会导致OOM问题。对应的异常信息,会标记出来和永久代相关:<code>java.lang.OutofMemoryError: PermGen space</code>。</p><p>随着元数据区的引入,方法区内存已经不再那么窘迫,所以相应的OOM有所改观,出现OOM,异常信息则变成了:<code>java.lang.OutOfMemoryError: Metaspace</code>。直接内存不足,也会导致OOM。</p></li></ol><blockquote><p>这里面隐含着一层意思是,在抛出 OutOfMemoryError之前,通常垃圾收集器会被触发,尽其所能去清理出空间。</p><ul><li>例如:在引用机制分析中,涉及到JVM会去尝试回收软引用指向的对象等。</li><li>在<code>java.nio.Bits#reserveMemory()</code>方法中,我们能清楚的看到, <code>System.gc()</code>会被调用,以清理空间。</li></ul><p>自然,也不是在任何情况下垃圾收集器都会被触发的。</p><ul><li>比如,我们去分配一个超大对象,类似一个超大数组超过堆的最大值,JVM可以判断出垃圾收集并不能解决这个问题,所以直接抛出 OutOfMemoryError</li></ul></blockquote><h2 id="内存泄露-Memory-Leak"><a class="header-anchor" href="#内存泄露-Memory-Leak">¶</a>内存泄露(Memory Leak)</h2><p>也称作“存储渗漏”。严格来说,只有对象不会再被程序用到了,但是GC又不能回收他们的情况,才叫内存泄漏。</p><p>但实际情况很多时候一些不太好的实践(或疏忽)会导致对象的生命周期变得很长甚至导致OOM,也可以叫做宽泛意义上的“内存泄漏”。</p><p>尽管内存泄漏并不会立刻引起程序崩溃,但是一旦发生内存泄漏,程序中的可用内存就会被逐步蚕食,直至耗尽所有内存,最终出现 OutOfMemory，导致程序崩溃。</p><p>注意,这里的存储空间并不是指物理内存,而是指虚拟内存大小,这个虚拟内存大小取决于磁盘交换区设定的大小。</p><h3 id="举例"><a class="header-anchor" href="#举例">¶</a>举例:</h3><p>1、单例模式<br>单例的生命周期和应用程序是一样长的,所以单例程序中,如果持有对外部对象的引用的话,那么这个外部对象是不能被回收的,则会导致内存泄漏的产生。<br>2、一些 close提供的资源未关闭导致内存泄漏<br>数据库连接(<code>dataSourse#getConnection()</code>),网络连接(socket)和io连接必须手动close,否则是不能被回收的。</p><h1>Stop The World</h1><p>Stop-The-World,简称STW,指的是GC事件发生过程中,会产生应用程序的停顿。停顿产生时整个应用程序线程都会被暂停,没有任何响应,有点像卡死的感觉,这个停顿称为STW。</p><ul><li>可达性分析算法中枚举根节点(GC Roots)会导致所有Java执行线程停顿<ul><li>分析工作必须在一个能确保一致性的快照中进行</li><li>一致性指整个分析期间整个执行系统看起来像被冻结在某个时间点上</li><li>如果出现分析过程中对象引用关系还在不断变化,则分析结果的准确性无法保证</li></ul></li></ul><p>被STW中断的应用程序线程会在完成GC之后恢复,频繁中断会让用户感觉像是网速不快造成电影卡带一样,所以我们需要减少STW的发生。</p><p>目前为止，STW事件和采用哪款GC无关,所有的GC都有这个事件。哪怕是G1也不能完全避免Stop-The-World情况发生,只能说垃圾回收器越来越优秀,回收效率越来越高,尽可能地缩短了暂停时间。</p><p>STW是JVM在后台自动发起和自动完成的。在用户不可见的情况下,把用户正常的工作线程全部停掉。</p><p>开发中不要用 <code>System.gc();</code>会导致Stop-The-World的发生。</p><h1>垃圾回收的并行与并发</h1><h2 id="并发-Concurrent"><a class="header-anchor" href="#并发-Concurrent">¶</a>并发(Concurrent)</h2><p>在操作系统中,是指一个时间段中有几个程序都处于已启动运行到运行完毕之间,且这几个程序都是在同一个处理器上运行。并发不是真正意义上的“同时进行”,只是CPU把一个时间段划分成几个时间片段(时间区间),然后在这几个时间区间之间来回切换,由于CPU处理的速度非常快,只要时间间隔处理得当,即可让用户感觉是多个应用程序同时在进行。<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235819.png" alt="image-20200918084337086"></p><h2 id="并行-Parallel"><a class="header-anchor" href="#并行-Parallel">¶</a>并行(Parallel)</h2><p>当系统有一个以上CPU时,当一个CPU执行一个线程时,另一个CPU可以执行另一个线程,两个线程互不抢占CPU资源,可以同时进行,我们称之为并行(Parallel)。</p><p>其实决定并行的因素不是CPU的数量,而是CPU的核心数量,比如一个CPU多个核也可以并行。适合科学计算,后台处理等弱交互场景</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235824.png" alt="image-20200918084645787"></p><h2 id="垃圾回收的并发与并行"><a class="header-anchor" href="#垃圾回收的并发与并行">¶</a>垃圾回收的并发与并行</h2><p>并发和并行,在谈论垃圾收集器的上下文语境中,它们可以解释如下:</p><ul><li><p>并行(Parallel):指多条垃圾收集线程并行工作,但此时用户线程仍处于等待状态。</p><ul><li>如ParNew、 Parallel Scavenge、 Parallel Old;</li></ul></li><li><p>串行(Serial)</p><ul><li><p>相较于并行的概念,单线程执行。</p></li><li><p>如果内存不够,则程序暂停,启动JVM垃圾回收器进行垃圾回收。回收完,再启动程序的线程。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235829.png" alt="image-20200918084912731"></p></li></ul></li><li><p>并行(Concurrent):指用户线程与垃圾收集线程同时执行(但不一定是并行的,可能会交替执行),垃圾回收线程在执行时不会停顿用户程序的运行。</p><ul><li>用户程序在继续运行,而垃圾收集程序线程运行于另一个CPU上</li><li>如:CMS、G1</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235834.png" alt="image-20200918085237660"></p></li></ul><h1>安全点与安全区域</h1><h2 id="安全点"><a class="header-anchor" href="#安全点">¶</a>安全点</h2><p>程序执行时并非在所有地方都能停顿下来开始GC,只有在特定的位置才能停顿下来开始GC,这些位置称为“安全点(Safepoint)”。</p><p>Safe Point的选择很重要,如果太少可能导致GC等待的时间太长,如果太频繁可能导致运行时的性能问题。大部分指令的执行时间都非常短暂,通常会根据“是否具有让程序长时间执行的特征”为标准。比如:选择一些执行时间较长的指令作为 Safe Point,如方法调用、循环跳转和异常跳转等。因为：</p><ul><li>当需要发生GC的时候，通常是因为内存紧张了，这时候我们是希望可以尽快进入GC的</li><li>但是GC的时候有个关键点就是如何在GC的过程识别出哪些内存空间是一个对象</li><li>而Hotspot使用的是准确式GC，使用一个OopMap的结构记录引用对象的位置，在用户字节码的间隙插入记录OopMap的代码</li><li>所以我们在GC的时候需要保证所有用户线程中的对象的引用都被记录到OopMap中了才能进行，那么以尽快进入GC的理想条件当然是在每一次发生对象赋值的时候都插入一行记录OopMap的代码</li><li>但是这样对内存和CPU的额外消耗会很大，所以综合起来考虑在一些&quot;执行周期可能会很长的指令&quot;之前插入记录OopMap的代码就可以得到一个权衡。</li></ul><h3 id="循环跳转的安全点优化"><a class="header-anchor" href="#循环跳转的安全点优化">¶</a>循环跳转的安全点优化</h3><p>为了避免安全点过多带来过重的负担,对循环还有一项优化措施,认为循环次数较少的话,执行时间应该也不会太长,所以使用int类型或范围更小的数据类型作为索引值的循环默认是不会被放置安全点的。这种循环被称为可数循环(Counted Loop),相对应地,使用long或者范围更大的数据类型作为索引值的循环就被称为不可数循环(Uncounted Loop),将会被放置安全点。通常情况下这个优化措施是可行的,但循环执行的时间不单单是由其次数决定,如果循环体单次执行就特别慢,那即使是可数循环也可能会耗费很多的时间。</p><p>使用<code>-XX:+UseCountedLoopSafepoints</code>可以强制在可数循环跳转前放置安全点，但是JDK8中有bug。</p><h3 id="实现用户线程在安全点挂起"><a class="header-anchor" href="#实现用户线程在安全点挂起">¶</a>实现用户线程在安全点挂起</h3><p>如何在GC发生时,检查所有线程都跑到最近的安全点停顿下来呢?</p><ul><li><p>抢先式中断:(目前没有虚拟机采用了)</p><p>首先中断所有线程。如果还有线程不在安全点,就恢复线程,让线程跑到安全点。</p></li><li><p>主动式中断:<br>设置一个中断标志,各个线程运行到Safe Point的时候主动轮询这个标志,如果中断标志为真,就会产生一个自陷信号，当前线程会被操作系统中断然后在JVM为该信号预先注册的异常处理器中挂起</p></li></ul><h2 id="安全区域"><a class="header-anchor" href="#安全区域">¶</a>安全区域</h2><p>Safepoint机制保证了程序执行时,在不太长的时间内就会遇到可进入GC的 Safepoint。但是,程序“不执行”的时候呢?例如线程处于 Sleep状态或 Blocked状态,这时候线程无法响应JVM的中断请求,“走”到安全点去中断挂起,VM也不太可能等待线程被唤醒。对于这种情况,就需要安全区域(Safe Region)来解决。</p><p><strong>安全区域是指在一段代码片段中,对象的引用关系不会发生变化,在这个区域中的任何位置开始GC都是安全的</strong>。我们也可以把 Safe Region看做是被扩展了的 Safepoint。</p><h3 id="实际执行时"><a class="header-anchor" href="#实际执行时">¶</a>实际执行时:</h3><ol><li>当线程运行到 Safe Region的代码时,首先标识已经进入了 Safe Reion,如果这段时间内发生GC,JVM会忽略 Safe Region 标识为状态的线程;</li><li>当线程即将离开 Safe Region时,会检查JVM是否已经完成GC,如果完成了,则继续运行,否则线程必须等待直到收到可以安全离开 Safe Region的信号为止。</li></ol><h1>引用</h1><p>我们希望能描述这样一类对象：当内存空间还足够时，则能保留在内存中；如果内存空间在进行垃圾收集后还是很紧张，则可以抛弃这些对象。</p><p>在JDK1.2版之后,Java对引用的概念进行了扩充,将引用分为强引用(Strong Reference)、软引用(Soft Reference)、弱引用(Weak Reference)和虚引用(Phantom Reference)4种,这4种引用强度依次逐渐减弱。</p><p>除强引用外,其他3种引用均可以在<code>java.lang.ref</code>包中找到它们的身影。如下图,显示了这3种引用类型对应的类,开发人员可以在应用程序中直接使用它们:</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235841.png" alt="image-20200918090609957"></p><p><code>Reference</code>子类中只有终结器引用是包内可见的,其他3种引用类型均为 <code>public</code>,可以在应用程序中直接使用</p><ul><li>强引用(StrongReference):最传统的“引用”的定义,是指在程序代码之中普遍存在的引用赋值,即类似<code>Object obj= Object()</code>这种引用关系。无论任何情况下,只要强引用关系还存在,垃圾收集器就永远不会回收掉被引用的对象</li><li>软引用(SoftReference):在系统将要发生内存溢出之前,将会把这些对象列入回收范围之中进行第二次回收。如果这次回收后还没有足够的内存,才会抛出内存溢出异常。</li><li>弱引用(WeakReference):被弱引用关联的对象只能生存到下一次垃圾收集之前。当垃圾收集器工作时,无论内存空间是否足够,都会回收掉被弱引用关联的对象。</li><li>虚引用(PhantomReference):一个对象是否有虚引用的存在,完全不会对其生存时间构成影响,也无法通过虚引用来获得一个对象的实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。</li></ul><h2 id="强引用"><a class="header-anchor" href="#强引用">¶</a>强引用</h2><p>在Java程序中,最常见的引用类型是强引用(普通系统99%以上都是强引用),也就是我们最常见的普通对象引用,也是默认的引用类型。当在Java语言中使用new操作符创建一个新的对象,并将其赋值给一个变量的时候,这个变量就成为指向该对象的一个强引用。</p><p>强引用的对象是可触及的,垃圾收集器就永远不会回收掉被引用的对象。对于一个普通的对象,如果没有其他的引用关系,只要超过了引用的作用域或者显式地将相应(强)引用赋值为nu1,就是可以当做垃圾被收集了,当然具体回收时机还是要看垃圾收集策略。</p><p>相对的,软引用、弱引用和虚引用的对象是软可触及、弱可触及和虚可触及的,在一定条件下,都是可以被回收的。所以,强引用是造成Java内存泄漏的主要原因之一。</p><h3 id="强引用例子"><a class="header-anchor" href="#强引用例子">¶</a>强引用例子</h3><pre class="line-numbers language-language-java"><code class="language-language-java">StringBuffer str = new StringBuffer("Hello");<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>局部变量str指向 <code>StringBuffer</code>实例所在堆空间,通过str可以操作该实例,那么str就 <code>StringBuffer</code>是实例的强引用<br>对应内存结构:<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235847.png" alt="image-20200918091626405"></p><p>此时，如果再运行一个赋值语句：</p><pre class="line-numbers language-language-java"><code class="language-language-java">StringBuffer str1 = str;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对应内存结构：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235852.png" alt="image-20200918091712769"></p><p>本例中的两个引用,都是强引用,强引用具备以下特点:</p><ul><li>强引用可以直接访问目标对象。</li><li>强引用所指向的对象在任何时候都不会被系统回收虚拟机宁愿抛出OOM,也不会回收强引用所指向对象。</li><li>强引用可能导致内存泄漏。</li></ul><h2 id="软引用"><a class="header-anchor" href="#软引用">¶</a>软引用</h2><p>软引用是用来描述一些还有用,但非必需的对象。只被软引用关联着的对象<strong>在系统将要发生内存溢出异常前</strong>,会把这些对象列进回收范围之中进行第二次回收,如果这次回收还没有足够的内存,才会抛出内存溢出异常。</p><p>软引用通常用来实现内存敏感的缓存比如:高速缓存就有用到软引用。如果还有空闲内存,就可以暂时保留缓存,当内存不足时清理掉,这样就保证了使用缓存的同时,不会耗尽内存。</p><p>垃圾回收器在某个时刻决定回收软可达的对象的时候,会清理软引用,并可选地把引用存放到一个引用队列(Reference Queue)。</p><h3 id="例子"><a class="header-anchor" href="#例子">¶</a>例子</h3><p>在JDK1.2之后提供了<code>java.lang.ref.SoftReference</code>类来实现软引用：</p><pre class="line-numbers language-language-java"><code class="language-language-java">//第一种Object obj = new Object();//声明强引用SoftReference<Object> sf = new SoftReference<>(obj); //弱引用obj = null;//销毁强引用，此时该对象只剩一个弱引用//第二种：直接是软引用SoftReference<Object> sf = new SoftReference<>(new Object()); //弱引用<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="弱引用"><a class="header-anchor" href="#弱引用">¶</a>弱引用</h2><p>弱引用也是用来描述那些非必需对象,被弱引用关联的对象只能生存到下一次垃圾收集发生为止。<strong>在系统GC时,只要发现弱引用,不管系统堆空间使用是否充足</strong>,都会回收掉只被弱引用关联的对象。</p><p>但是,由于垃圾回收器的线程通常优先级很低,因此,并不一定能很快地发现持有弱引用的对象。在这种情况下,弱引用对象可以存在较长的时间。</p><p>弱引用和软引用一样,在构造弱引用时,也可以指定一个引用队列,当弱引用对象被回收时,就会加入指定的引用队列,通过这个队列可以跟踪对象的回收情况。</p><p>软引用、弱引用都非常适合来保存那些可有可无的缓存数据。如果这么做,当系统内存不足时,这些缓存数据会被回收,不会导致内存溢出。而当内存资源充足时,这些缓存数据又可以存在相当长的时间,从而起到加速系统的作用。</p><h3 id="例子-v2"><a class="header-anchor" href="#例子-v2">¶</a>例子</h3><p>在JDK 1.2版之后提供了<code>java.lang.ref.WeakReference</code>类来实现弱引用。</p><pre class="line-numbers language-language-java"><code class="language-language-java">//第一种Object obj = new Object();//声明强引用WeakReference<Object> sf = new WeakReference<>(obj); //软引用obj = null;//销毁强引用，此时该对象只剩一个软引用//第二种：直接是软引用WeakReference<Object> sf = new WeakReference<>(new Object()); //软引用<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>弱引用对象与软引用对象的最大不同就在于,当GC在进行回收时,需要通过算法检查是否回收软引用对象,而对于弱引用对象,GC总是进行回收。弱引用对象更容易、更快被GC回收。</p><h2 id="虚引用-对象回收跟踪"><a class="header-anchor" href="#虚引用-对象回收跟踪">¶</a>虚引用(对象回收跟踪)</h2><p>也称为“幽灵引用”或者“幻影引用”,是所有引用类型中最弱的一个。一个对象是否有虚引用的存在,完全不会决定对象的生命周期。如果一个对象仅持有虚引用,那么它和没有引用几乎是一样的,随时都可能被垃圾回收器回收。</p><p>它不能单独使用,也无法通过虚引用来获取被引用的对象。当试图通过虚引用的get()方法取得对象时,总是nu11。</p><p>为一个对象设置虚引用关联的唯一目的在于跟踪垃圾回收过程。比如:能在这个对象被收集器回收时收到一个系统通知。</p><h3 id="使用和例子"><a class="header-anchor" href="#使用和例子">¶</a>使用和例子</h3><p>虚引用必须和引用队列<code>java.lang.ref.ReferenceQueue</code>一起使用，<strong>虚引用在创建时必须提供一个引用队列作为参数</strong>(只有一个两参构造器)。当垃圾回收器准备回收一个对象时,如果发现它还有虚引用,<strong>就会在回收对象后,将这个虚引用加入引用队列</strong>,以通知应用程序对象的回收情况。</p><p>由于虚引用可以跟踪对象的回收时间,因此,也可以将一些资源释放操作放置在虚引用中执行和记录。</p><p>在JDK1.2版之后提供了 <code>PhantomReference</code>类来实现虚引用。</p><pre class="line-numbers language-language-java"><code class="language-language-java">Object obj= new object();ReferenceQueue phantomQueue =new ReferenceQueue();PhantomReference<object> pf = new PhantomReference<object>(obj, phantomQueue);obj = null;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>下面是一个详细例子：</p><pre class="line-numbers language-language-java"><code class="language-language-java">public class PhantomReferenceTest {    private static PhantomReferenceTest obj;    private static ReferenceQueue<PhantomReferenceTest> queue = new ReferenceQueue<>();    private static Runnable check = () -> {        while (true) {            PhantomReference<PhantomReferenceTest> phantomRef = null;            try {                phantomRef =(PhantomReference<PhantomReferenceTest>) queue.remove();            } catch (InterruptedException e) {                e.printStackTrace();            }            if (phantomRef != null) {                System.out.println("追踪垃圾回收过程：PhantomReferenceTest实例被GC了");            }        }    };    @Override    protected void finalize() throws Throwable {        super.finalize();        System.out.println("调用了finalize()");        obj = this;    }    public static void main(String[] args) throws InterruptedException {        Thread t = new Thread(check);        t.setDaemon(true);        t.start();        obj = new PhantomReferenceTest();        PhantomReference<PhantomReferenceTest> phantomRef = new PhantomReference<>(obj, queue);        System.out.println("无法获取虚引用中的对象：" + phantomRef.get());        //强引用去除        obj = null;        System.out.println("第一次GC");        System.gc();        Thread.sleep(1000);        if (obj == null) {            System.out.println("obj 是 null");        } else {            System.out.println("obj 可用");        }        System.out.println("第二次GC");        obj = null;        System.gc();        if (obj == null) {            System.out.println("obj 是 null");        } else {            System.out.println("obj 可用");        }        Thread.sleep(1000);    }}//输出：////无法获取虚引用中的对象：null//第一次GC//调用了finalize()//obj 可用//第二次GC//obj 是 null//追踪垃圾回收过程：PhantomReferenceTest实例被GC了<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="引用队列"><a class="header-anchor" href="#引用队列">¶</a>引用队列</h2><p>参考上面的虚引用中<code>ReferenceQueue</code>引用队列的使用，对于虚引用来说，必须指定一个引用队列，而弱引用和软引用则会有两个构造函数，一个是仅接收一个强引用、另一个是接收一个强引用和引用队列，所以引用队列对于所有非强引用都是可用的，只是虚引用被强制必须使用。</p><h2 id="终结器引用"><a class="header-anchor" href="#终结器引用">¶</a>终结器引用</h2><p>它用以实现对象的 <code>finalize()</code>方法,也可以称为终结器引用。无需手动编码,其内部配合引用队列使用**(使用权限为<code>default</code>，包外不可使用)**。在GC时,终结器引用入队。由 Finalizer线程通过终结器引用找到被引用对象并调用它的 <code>finalize()</code>方法,第二次GC时才能回收被引用对象。</p>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>13_GC概述及算法思想</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/13-gc-gai-shu-ji-suan-fa-si-xiang/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/13-gc-gai-shu-ji-suan-fa-si-xiang/</url>
      
        <content type="html"><![CDATA[<h1>概述</h1><p>垃圾收集,不是Java语言的伴生产物。早在1960年,第一门开始使用内存动态分配和垃圾收集技术的Lisp语言诞生。<br>关于垃圾收集有三个经典问题:</p><ul><li>哪些内存需要回收?</li><li>什么时候回收?</li><li>如何回收?</li></ul><p>垃圾收集机制是Java的招牌能力,极大地提高了开发效率。如今,垃圾收集几乎成为现代语言的标配,即使经过如此长时间的发展,Java的垃<br>圾收集机制仍然在不断的演进中,不同大小的设备、不同特征的应用场景,对垃圾收集提出了新的挑战。</p><h2 id="什么是垃圾"><a class="header-anchor" href="#什么是垃圾">¶</a>什么是垃圾</h2><p>什么是垃圾( Garbage)呢?</p><p>“垃圾是指在运行程序中没有任何指针指向的对象,这个对象就是需要被回收的垃圾”。如果不及时对内存中的垃圾进行清理,那么,这些垃圾对象所占的内存空间会一直保留到应用程序结束,被保留的空间无法被其他对象使用。甚至可能导致内存溢出。</p><p>对于高级语言来说,一个基本认知是如果不进行垃圾回收,内存迟早都会被消耗完因为不断地分配内存空间而不进行回收就好像不停地生产生活垃圾而从来不打扫一样。<br>除了释放没用的对象,垃圾回收也可以清除内存里的记录碎片。碎片整理将所占用的堆内存移到堆的一端,以便JVM将整理出的足够大的内存分配给新的对象。<br>随着应用程序所应付的业务越来越庞大、复杂,用户越来越多,没有GC就不能保证应用程序的正常进行。而经常造成STW的GC又跟不上实际的需求,所以才会不断地尝试对GC进行优化。</p><h2 id="早期垃圾回收"><a class="header-anchor" href="#早期垃圾回收">¶</a>早期垃圾回收</h2><p>在早期的C/C++时代,垃圾回收基本上是手工进行的。开发人员可以使用<code>new</code>关键字进行内存申请,并使用 <code>delete</code>关键字进行内存释放。比如以下代码:</p><pre class="line-numbers language-language-c++"><code class="language-language-c++">MibBridgepBridge= new cmBaseGroupBridge();//如果注册失败,使用Delete释放该对象所占内存区域if(pBridge->Register()!= NO ERROR)delete pBridge;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>这种方式可以灵活控制内存释放的时间,但是会给开发人员带来频繁申请和释放内存的管理负担。倘若有一处内存区间由于程序员编码的问题忘记被回收,那么就会产生内存泄漏,垃圾对象永远无法被清除,随着系统运行时间的不断增长,垃圾对象所耗内存可能持续上升,直到出现内存溢出并造成应用程序崩溃。</p><p>在有了垃圾回收机制后,上述代码块极有可能变成这样:</p><pre class="line-numbers language-language-c++"><code class="language-language-c++">MibBridgepBridge= new cmBaseGroupBridge();pBridge->Register(kDestroy);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>现在,除了Java以外 C#、 Python、Ruby等语言都使用了自动垃圾回收的思想,也是未来发展趋势。可以说这种自动化的内存分配和垃圾回收的方式己经成为现代开发语言必备的标准。</p><h2 id="Java垃圾回收"><a class="header-anchor" href="#Java垃圾回收">¶</a>Java垃圾回收</h2><p>自动内存管理,无需开发人员手动参与内存的分配与回收,这样降低内存泄漏和内存溢出的风险</p><ul><li>没有垃圾回收器,java也会和cpp一样,各种悬垂指针,野指针,泄露问题让你头疼不已。</li></ul><p>自动内存管理机制,将程序员从繁重的内存管理中释放出来,可以更专心地专注于业务开发。</p><blockquote><p>[oracle官网关于垃圾回收的介绍](<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/toc" target="_blank" rel="noopener">https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/toc</a>. html)</p></blockquote><p>对于Java开发人员而言,自动内存管理就像是一个黑匣子,如果过度依赖于“自动”,那么这将会是一场灾难,最严重的就会弱化ava开发人员在程序出现内存溢出时定位问题和解决问题的能力。</p><p>此时,了解JVM的自动内存分配和内存回收原理就显得非常重要,只有在真正了解JVM是如何管理内存后,我们才能够在遇见 OutofMemoryError时,快速地根据错误异常日志定位问题和解决问题。</p><p>当需要排查各种内存溢出、内存泄漏问题时,当垃圾收集成为系统达到更高并发量的瓶颈时,我们就必须对这些“自动化”的技术实施必要的监控和调节。</p><h3 id="GC作用区域"><a class="header-anchor" href="#GC作用区域">¶</a>GC作用区域</h3><p>下面漏了直接内存，直接内存也会GC。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235604.png" alt="image-20200917195635270"></p><p>垃圾回收器可以对年轻代回收,也可以对老年代回收,甚至是全堆和方法区的回收。</p><p>其中,Java堆是垃圾收集器的工作重点。<br>从次数上讲:</p><ul><li>频繁收集Young区</li><li>较少收集Old区</li><li>基本不动Perm区</li></ul><h1>垃圾回收相关算法</h1><h2 id="垃圾标记阶段-对象存活判断"><a class="header-anchor" href="#垃圾标记阶段-对象存活判断">¶</a>垃圾标记阶段:对象存活判断</h2><p>在堆里存放着几乎所有的Java对象实例,在GC执行垃圾回收之前,首先需要区分出内存中哪些是存活对象,哪些是已经死亡的对象。只有被标记为己经死亡的对象,GC才会在执行垃圾回收时,释放掉其所占用的内存空间,因此这个过程我们可以称为垃圾标记阶段。</p><p>那么在JVM中究竟是如何标记一个死亡对象呢?简单来说,当一个对象已经不再被任何的存活对象继续引用时,就可以宣判为已经死亡。</p><p>判断对象存活一般有两种方式:<strong>引用计数算法</strong>和<strong>可达性分析算法</strong>。</p><h3 id="标记阶段：引用记数算法"><a class="header-anchor" href="#标记阶段：引用记数算法">¶</a>标记阶段：引用记数算法</h3><p>引用计数算法(Reference Counting)比较简单,对每个对象保存一个整型的引用计数器属性。用于记录对象被引用的情况。对于一个对象A,只要有任何一个对象引用了A,则A的引用计数器就加1;当引用失效时,引用计数器就减1。只要对象A的引用计数器的值为0即表示对象A不可能再被使用,可进行回收。</p><ul><li><p>优点:实现简单,垃圾对象便于辨识;判定效率高,回收没有延迟性。</p></li><li><p>缺点:</p><ul><li><p>它需要单独的字段存储计数器,这样的做法增加了存储空间的开销。</p></li><li><p>每次赋值都需要更新计数器,伴随着加法和减法操作,这增加了时间开销。</p></li><li><p>引用计数器有一个严重的问题,即无法处理循环引用的情况。这是一条致命缺陷,导致在Java的垃圾回收器中没有使用这类算法。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235610.png" alt="image-20200917200717565"></p></li></ul></li></ul><p>引用计数算法,是很多语言的资源回收选择,例如因人工智能而更加火热的 Python,它更是同时支持引用计数和垃圾收集机制。</p><p>具体哪种最优是要看场景的,业界有大规模实践中仅保留引用计数机制,以提高吞吐量的尝试。</p><p>Java并没有选择引用计数,是因为其存在一个基本的难题,也就是很难处理循环引用关系。</p><p>Python如何解决循环引用?</p><ul><li>手动解除:很好理解,就是在合适的时机,解除引用关系。</li><li>使用弱引用weakref, weakref是Python提供的标准库,旨在解决循环引用。 编译器/解释器本身在对成员变量赋值引用类型数据之前检查是否发生循环引用，是的话将当前引用包装为弱引用，弱引用不会增加计数。</li></ul><h3 id="标记阶段：可达性分析算法"><a class="header-anchor" href="#标记阶段：可达性分析算法">¶</a>标记阶段：可达性分析算法</h3><p>可达性分析算法又称根搜索算法、追踪性垃圾收集。相对于引用计数算法而言,可达性分析算法不仅同样具备实现简单和执行高效等特点,更重要的是该算法可以有效地解决在引用计数算法中循环引用的问题,防止内存泄漏的发生。</p><p>相较于引用计数算法,这里的可达性分析就是Java、C#选择的。这种类型的垃圾收集通常也叫作追踪性垃圾收集(Tracing Garbage<br>Collection)。</p><p>所谓&quot;GC Roots&quot;根集合就是一组必须活跃的引用</p><p>基本思路:</p><ul><li>可达性分析算法是以根对象集合(GC Roots)为起始点,按照从上至下的方式搜索被根对象集合所连接的目标对象是否可达。</li><li>使用可达性分析算法后,内存中的存活对象都会被根对象集合直接或间接连接着,搜索所走过的路径称为引用链(Reference Chain)。<ul><li>如果目标对象没有任何引用链相连,则是不可达的,就意味着该对象己经死亡,可以标记为垃圾对象。</li><li>在可达性分析算法中,只有能够被根对象集合直接或者间接连接的对象才是存活对象。</li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235617.png" alt="image-20200917202219017"></p><h4 id="GC-Roots"><a class="header-anchor" href="#GC-Roots">¶</a>GC Roots</h4><p>在Java语言中, GC Roots包括几类元素:</p><ul><li>虚拟机栈中引用的对象<ul><li>比如:各个线程被调用的方法中使用到的参数、局部变量等。</li></ul></li><li>本地方法栈内JNI(通常说的本地方法)引用的对象</li><li>方法区中类静态属性引用的对象<ul><li>比如:Java类的引用类型静态变量</li></ul></li><li>方法区中常量引用的对象<ul><li>比如:字符串常量池(StringTable)里的引用</li></ul></li><li>所有被同步锁 synchronized持有的对象</li><li>Java虚拟机内部的引用。</li><li>基本数据类型对应的Class对象,一些常驻的异常对象(如: NullPointerException、 OutofMemoryError),系统类加载器。</li><li>反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。</li></ul><p>除了这些固定的 GC Roots集合以外,根据用户所选用的垃圾收集器以及当前回收的内存区域不同,还可以有其他对象“临时性”地加入,共同构成完整 GC Roots集合。比如:分代收集和局部回收(Partial GC)。如果只针对Java堆中的某一块区域进行垃圾回收(比如:典型的只针对新生代),必须考虑到内存区域是虚拟机自己的实现细节,更不是孤立封闭的,这个区域的对象完全有可能被其他区域的对象所引用,这时候就需要一并将关联的区域对象也加入 GC Roots集合中去考虑,才能保证可达性分析的准确性。</p><p>如果要使用可达性分析算法来判断内存是否可回收,那么分析工作必须在一个能保障一致性的快照中进行。这点不满足的话分析结果的准确性就无去保证。这点也是导致GC进行时必须Stop The World的一个重要原因。即使是号称(几乎)不会发生停顿的CMS收集器中,枚举根节点时也是必须要停顿的。</p><h4 id="MAT与JProfiler的GC-Roots溯源"><a class="header-anchor" href="#MAT与JProfiler的GC-Roots溯源">¶</a>MAT与JProfiler的GC Roots溯源</h4><p>MAT是 Memory Analyzer的简称,它是一款功能强大的Java堆内存分析器。用于查找内存泄漏以及查看内存消耗情况。<br>MAT是基 Eclipse于开发的,是一款免费的性能分析工具。可以在 <a href="http://www.eclipse.org/mat/" target="_blank" rel="noopener">http://www.eclipse.org/mat/</a> 下载并使用MAT。</p><h5 id="1-获取堆dump文件"><a class="header-anchor" href="#1-获取堆dump文件">¶</a>1&gt;获取堆dump文件</h5><h6 id="方式1：命令行使用jmap"><a class="header-anchor" href="#方式1：命令行使用jmap">¶</a>方式1：命令行使用jmap</h6><p>先用jps查看进程id，然后使用jmap dump出。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235624.png" alt="image-20200917210552170"></p><h6 id="方式2-使用JVisualVM导出"><a class="header-anchor" href="#方式2-使用JVisualVM导出">¶</a>方式2:使用JVisualVM导出</h6><p>捕获的 heap dump文件是一个临时文件,关闭 JVisualVM后自动删除,若要保留,需要将其另存为文件。可通过以下方法捕获 heap dump：</p><ul><li>在左侧“Application(应用程序)子窗口中右击相应的应用程序,选择Heap Dump(堆Dump)。</li><li>在Monitor(监视)子标签页中点击 Heap Dump(堆Dump)按钮。</li></ul><p>本地应用程序的Heap dumps作为应用程序标签页的一个子标签页打开。同时,heap dump在左侧的Application(应用程序)栏中对应一个含有时间戳的节点。右击这个节点选择 save as(另存为)即可将heap dump保存到本地（.hprof文件）。</p><h5 id="2-使用MAT打开dump文件"><a class="header-anchor" href="#2-使用MAT打开dump文件">¶</a>2&gt;使用MAT打开dump文件</h5><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235629.png" alt="image-20200917212350256"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235638.png" alt="image-20200917212505143"></p><h6 id="Eclipse-GC-Roots统计维度"><a class="header-anchor" href="#Eclipse-GC-Roots统计维度">¶</a><a href="https://help.eclipse.org/2020-03/index.jsp?topic=%2Forg.eclipse.mat.ui.help%2Fconcepts%2Fgcroots.html" target="_blank" rel="noopener">Eclipse GC Roots统计维度</a></h6><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235645.png" alt="image-20200917211456832"></p><h5 id="3-使用JProfiler监控或者分析dump文件"><a class="header-anchor" href="#3-使用JProfiler监控或者分析dump文件">¶</a>3&gt;使用<a href="https://www.ej-technologies.com/download/jprofiler/files" target="_blank" rel="noopener">JProfiler</a>监控或者分析dump文件</h5><p>下载JProfiler，并安装IDE插件，以JProfiler插件启动程序，如下即可查看当前程序中<code>GCRootsTest</code>类型对象的GC Root引用链。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235652.png" alt="image-20200917214342359"><br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235700.png" alt="image-20200917214540189"></p><h2 id="对象的finalization机制"><a class="header-anchor" href="#对象的finalization机制">¶</a>对象的finalization机制</h2><p>Java语言提供了对象终止(finalization)机制来允许开发人员提供对象被销毁之前的自定义处理逻辑。当垃圾回收器发现没有引用指向一个对象,即:垃圾回收此对象之前,总会先调用这个对象的 <code>finalize()</code>方法。<br><code>finalize()</code>方法允许在子类中被重写,用于在对象被回收时进行资源释放。通常在这个方法中进行一些资源释放和清理的工作,比如关闭文件、套接字和数据库连接等。</p><p>永远不要主动调用某个对象的 <code>finalize()</code>方法,应该交给垃圾回收机制调用。理由包括下面三点:</p><ul><li>在<code>finalize()</code>时可能会导致对象复活。</li><li><code>finalize()</code>方法的执行时间是没有保障的,它完全由GC线程决定极端情况下,若不发生GC,则 finalize()方法将没有执行机会？？？？？？？？？？？？？？</li><li>一个糟糕的<code>finalize()</code>会严重影响GC的性能。</li></ul><p>从功能上来说, <code>finalize()</code>方法与C<ins>中的析构函数比较相似,但是Java采用的是基于垃圾回收器的自动内存管理机制,所以 <code>finalize()</code>方法在本质上不同于C</ins>中的析构函数。<br>由于<code>finalize()</code>方法的存在,虚拟机中的对象一般处于三种可能的状态。</p><h3 id="对象的三种状态"><a class="header-anchor" href="#对象的三种状态">¶</a>对象的三种状态</h3><p>如果从所有的根节点都无法访问到某个对象,说明对象己经不再使用了。一般来说,此对象需要被回收。但事实上,也并非是“非死不可”的,这时候它们暂时处于“缓刑”阶段。一个无法触及的对象有可能在某一个条件下“复活”自己,如果这样,那么对它的回收就是不合理的,为此,定义虚拟机中的对象可能的三种状态。如下:</p><ul><li>可触及的:从根节点开始,可以到达这个对象。</li><li>可复活的:对象的所有引用都被释放,但是对象有可能在 <code>finalize()</code>中复活。</li><li>不可触及的:对象的 <code>finalize()</code>被调用,并且没有复活,那么就会进入不可触及状态。不可触及的对象不可能被复活,因为 <code>finalize()</code>只会被调用一次。</li></ul><p>以上3种状态中,是由于 <code>finalize()</code>方法的存在,进行的区分。只有在对象不可触及时才可以被回收。</p><h3 id="对象判断回收过程"><a class="header-anchor" href="#对象判断回收过程">¶</a>对象判断回收过程</h3><p>判定一个对象objA是否可回收,至少要经历两次标记过程（？？？？下面说的没有重写finalize不就只经过一次标记吗？？另外，标记不是说标记可达对象吗）:</p><ol><li>如果对象objA到 GC Roots没有引用链,则进行第一次标记。</li><li>进行筛选,判断此对象是否有必要执行<code>finalize()</code>方法<ol><li>如果对象objA没有 <code>finalize()</code>重写方法,或者<code>finalize()</code>方法已经被虚拟机调用过,则虚拟机视为“没有必要执行”,objA被判定为不可触及的。</li><li>如果对象objA重写 <code>finalize()</code>了方法,且还未执行过,那么objA会被插入到<code>F-Queue</code>队列中,由一个虚拟机自动创建的、低优先级的 Finalizer 线程触发其<code>finalize()</code>方法执行。</li><li><code>finalize()</code>方法是对象逃脱死亡的最后机会,稍后GC会对<code>F-Queue</code>队列中的对象进行第二次标记。如果obj在 <code>finalize()</code>方法中与引用链上的任何一个对象建立了联系,那么在第二次标记时,objA会被移出“即将回收”集合。之后,对象会再次出现没有引用存在的情况。在这个情况下, <code>finalize()</code>方法不会被再次调用,对象会直接变成不可触及的状态,也就是说,一个对象的<code>finalize()</code>方法只会被调用一次。</li></ol></li></ol><h2 id="清除阶段"><a class="header-anchor" href="#清除阶段">¶</a>清除阶段</h2><p>当成功区分出内存中存活对象和死亡对象后,GC接下来的任务就是执行垃圾回收,释放掉无用对象所占用的内存空间,以便有足够的可用内存空间为新对象分配内存。<br>目前在JVM中比较常见的三种垃圾收集算法是标记一清除算法(Mark-Sweep)、复制算法( Copying)、标记压缩算法(Mark-Compact)。</p><h3 id="清除阶段：标记-清除算法"><a class="header-anchor" href="#清除阶段：标记-清除算法">¶</a>清除阶段：标记-清除算法</h3><p>标记-清除算法(Mark- -Sweep)是一种非常基础和常见的垃圾收集算法,该算法被J.McCarthy等人在1960年提出并并应用于Lisp语言。</p><p>执行过程:<br>当堆中的有效内存空间(available memory)被耗尽的时候,就会停止整个程序(也被称为 stop the world),然后进行两项工作,第一项则是标记,第二项则是清除。</p><ul><li>标记: Collector从引用根节点开始遍历,标记所有被引用的对象。一般是在对象的 Header中记录为可达对象。</li><li>清除: Collector对堆内存从头到尾进行线性的遍历,如果发现某个对象在其 Header中<strong>没有标记</strong>为可达对象,则将其回收。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235710.png" alt="image-20200917215522806"></p><h4 id="缺点"><a class="header-anchor" href="#缺点">¶</a>缺点</h4><ul><li><p>效率不算高</p></li><li><p>在进行GC的时候,需要停止整个应用程序,导致用户体验差？？？这个应该也是看具体收集器实现吧</p></li><li><p>这种方式清理出来的空闲内存是不连续的,产生内存碎片。需要维护一个空闲列表</p><blockquote><p>注意:何为清除?<br>这里所谓的清除并不是真的置空,而是把需要清除的对象地址保存在空闲的地址列表里。下次有新对象需要加载时,判断垃圾的位置空间是否够,如果够,就存放。</p></blockquote></li></ul><h3 id="清除阶段：复制算法"><a class="header-anchor" href="#清除阶段：复制算法">¶</a>清除阶段：复制算法</h3><p>为了解决标记-清除算法在垃圾收集效率方面的缺陷，M.L.Minsky于1963年发表了著名的论文,《使用双存储区的Lisp语言垃圾收集器》(CA LISP Garbage Collector Algorithm Using Serial Secondary Storage)。M.L.Minsky在该论文中描述的算法被人们称为复制( Copying)算法,它被M.L.Minsky本人成功地引入到了Lisp语言的一个实现版本中。</p><h4 id="核心思想"><a class="header-anchor" href="#核心思想">¶</a>核心思想:</h4><p>将活着的内存空间分为两块,每次只使用其中一块,在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中,之后清除正在使用的内存块中的所有对象,交换两个内存的角色,最后完成垃圾回收。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235721.png" alt="image-20200917220440894"></p><h4 id="优点"><a class="header-anchor" href="#优点">¶</a>优点</h4><ul><li>没有标记和清除过程,实现简单,运行高效</li><li>复制过去以后保证空间的连续性,不会出现“碎片”问题</li></ul><h4 id="缺点-v2"><a class="header-anchor" href="#缺点-v2">¶</a>缺点</h4><ul><li>此算法的缺点也是很明显的,就是需要两倍的内存空间</li><li>对于G1这种分拆 region成为大量的C,复制而不是移动,意味着GC需要维护 region之间对象引用关系,不管是内存占用或者时间开销也不小</li></ul><h4 id="特别的"><a class="header-anchor" href="#特别的">¶</a>特别的</h4><ul><li>如果系统中的经历标记后剩余的垃圾对象还是很多，此时就需要复制很多对象，复制算法就不会太理想。因为复制算法需要复制的存活对象数量并不会太大，或者说非常低才行</li></ul><h4 id="应用场景"><a class="header-anchor" href="#应用场景">¶</a>应用场景</h4><p>在新生代，对常规应用的垃圾回收，一次通常可以回收70%-99%的内存空间。回收性价比很高。所以现在的商业虚拟机都是用这种收集算法回收新生代。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235731.png" alt="image-20200917221336302"></p><h3 id="清除阶段：标记-压缩算法"><a class="header-anchor" href="#清除阶段：标记-压缩算法">¶</a>清除阶段：标记-压缩算法</h3><p>又称标记-整理算法。</p><p>复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在新生代经常发生,但是在老年代,更常见的情况是大部分对象都是存活对象。如果依然使用复制算法,由于存活对象较多,复制的成本也将很高。因此,基于老年代垃圾回收的特性,需要使用其他的算法。<br>标记-清除算法的确可以应用在老年代中,但是该算法不仅执行效率低下,而且在执行完内存回收后还会产生内存碎片,所以JVM的设计者需要在此基础之上进行改进。标记压缩(Mark- Compact)算法由此诞生。<br>1970年前后, G.L.Steele、C.J.Chene和D.S.Wise等研究者发布标记-压缩算法。在许多现代的垃圾收集器中,人们都使用了标记-压缩算法或其改进版本。</p><h4 id="执行过程："><a class="header-anchor" href="#执行过程：">¶</a>执行过程：</h4><ul><li>第一阶段和标记-清除算法一样，从根节点开始标记所有被引用对象；</li><li>第二阶段将所有的存活对象压缩到内存的一段，按顺序排放；</li><li>之后，清理边界外所有的空间。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235738.png" alt="image-20200917222128968"></p><h4 id="和复制算法区别"><a class="header-anchor" href="#和复制算法区别">¶</a>和复制算法区别</h4><p>和复制算法的区别就是复制算法预留了一半&quot;待复制&quot;内存空间是不能使用的，在进行对象移动的时候，移动的目标是固定的，可预知的；而标记-整理算法则没有预留空间，它是在标记的过程中动态算出要移动的对象及对象要去的目标位置(而且要考虑性能)，所以相对更复杂。</p><h4 id="和标记-清除算法区别"><a class="header-anchor" href="#和标记-清除算法区别">¶</a>和标记-清除算法区别</h4><p>标记-压缩算法的最终效果等同于标记-清除算法执行完成后,再进行一次内存碎片整理,因此,也可以把它称为标记-清除-压缩(mark-Sweep-<br>Compact)算法。</p><p>二者的本质差异在于标记-清除算法是一种非移动式的回收算法,标记压缩是移动式的。是否移动回收后的存活对象是一项优缺点并存的风险决策。</p><p>可以看到,标记的存活对象将会被整理,按照内存地址依次排列,而未被标记的内存会被清理掉。如此一来,当我们需要给新对象分配内存时,JVM只需要持有一个内存的起始地址即可,这比维护一个空闲列表显然少了许多开销。</p><h4 id="优点-v2"><a class="header-anchor" href="#优点-v2">¶</a>优点:</h4><ul><li>消除了标记-清除算法当中,内存区域分散的缺点,我们需要给新对象分配内存时,JVM只需要持有一个内存的起始地址即可。</li><li>消除了复制算法当中,内存减半的高额代价。</li></ul><h4 id="缺点-v3"><a class="header-anchor" href="#缺点-v3">¶</a>缺点:</h4><ul><li>从效率上来说,标记-整理算法要低于复制算法。</li><li>移动对象的同时,如果对象被其他对象引用,则还需要调整引用的地址。</li><li>移动过程中,需要全程暂停用户应用程序。即:STW？？？？？？应该是看具体的垃圾收集器吧</li></ul><h3 id="三种算法对比"><a class="header-anchor" href="#三种算法对比">¶</a>三种算法对比</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235745.png" alt="image-20200917222914385"></p><p>效率上来说,复制算法是当之无愧的老大但是却浪费了太多内存???凭什么标记清除比复制慢，你还多一个复制的过程呢？</p><p>而为了尽量兼顾上面提到的三个指标,标记整理算法相对来说更平滑一些,但是效率上不尽如人意,它比复制算法多了一个标记的阶段,比标记-清除多了一个整理内存的阶段。</p><h2 id="分代收集算法"><a class="header-anchor" href="#分代收集算法">¶</a>分代收集算法</h2><p>前面所有这些算法中,并没有一种算法可以完全替代其他算法,它们都具有自己独特的优势和特点。分代收集算法应运而生。</p><p>分代收集算法,是基于这样一个事实不同的对象的生命周期是不一样的。因此,不同生命周期的对象可以采取不同的收集方式,以便提高回收效率。一般是把Java堆分为新生代和老年代,这样就可以根据各个年代的特点使用不同的回收算法,以提高垃圾回收的效率。</p><p>在Java程序运行的过程中,会产生大量的对象,其中有些对象是与业务信息相关,比如Http请求中的 , httpsession对象、线程、soocket连接,这类对象跟业务直接挂钩,因此生命周期比较长。但是还有一些对象,主要是程序运行过程中生成的临时变量,这些对象生命周期会比较短,比如: String对象,由于其不变类的特性,系统会产生大量的这些对象,有些对象甚至只用一次即可回收。</p><p>目前几乎所有的GC都是采用分代收集(Generational Collecting)算法执行垃圾回收的。在 HotSpot中,基于分代的概念,GC所使用的内存回收算法必须结合年轻代和老年代各自的特点。</p><ul><li><p>年轻代(Young Gen)</p><p>年轻代特点:区域相对老年代较小,对象生命周期短、存活率低,回收频繁。</p><p>这种情况复制算法的回收整理,速度是最快的。复制算法的效率只和当前存活对象大小有关,因此很适用于年轻代的回收。而复制算法内存利用率不高的问题,通过hotspot survivor中的两个的设计得到缓解</p></li><li><p>老年代(Tenured Gen)</p><p>老年代特点:区域较大,对象生命周期长、存活率高,回收不及年轻代频繁。</p><p>这种情况存在大量存活率高的对象,复制算法明显变得不合适。一般是由标记-清除或者是标记-清除与标记-整理的混合实现。</p><ul><li>Mark阶段的开销与存活对象的数量成正比</li><li>Sweep阶段的开销与所管理区域的大小成正相关。</li><li>Compact阶段的开销与存活对象的数据成正比。</li></ul></li></ul><p>以 HotSpot中的CMS回收器为例,CMS是基于Mark-Sweep实现的对于对象的回收效率很高。而对于碎片问题,CMS采用基于Mark-Compact算法的 Serial Old回收器作为补偿措施:当内存回收不佳(碎片导致的 Concurrent Mode Failure时),将采用 Serial Old执行Full GC以达到对老年代内存的整理。</p><p>分代的思想被现有的虚拟机广泛使用。几乎所有的垃圾回收器都区分新生代和老年代。</p><h2 id="增量收集算法"><a class="header-anchor" href="#增量收集算法">¶</a>增量收集算法</h2><p>上述现有的算法,在垃圾回收过程中,应用软件将处于一种 Stop The World的状态???在 Stop The World状态下应用程序所有的线程都会挂起,暂停一切正常的工作,等待垃圾回收的完成。如果垃圾回收时间过长,应用程序会被挂起很久,将严重影响用户体验或者系统的稳定性。为了解决这个问题,即对实时垃圾收集算法的研究直接导致了增量收集(Incremental Collecting)算法的诞生。</p><h3 id="基本思想"><a class="header-anchor" href="#基本思想">¶</a>基本思想</h3><p>如果一次性将所有的垃圾进行处理,需要造成系统长时间的停顿,那么就可以让垃圾收集线程和应用程序线程交替执行。每次,垃圾收集线程只收集一小片区域的内存空间,接着切换到应用程序线程。依次反复,直到垃圾收集完成。</p><p>总的来说,增量收集算法的基础仍是传统的标记-清除和复制算法。增量收集算法通过对线程间冲突的妥善处理,允许垃圾收集线程以分阶段的方式完成标记、清理或复制工作。</p><h3 id="缺点-v4"><a class="header-anchor" href="#缺点-v4">¶</a>缺点:</h3><p>使用这种方式,由于在垃圾回收过程中,间断性地还执行了应用程序代码, 所以能减少系统的停顿时间(低时延)。但是,因为线程切换和上下文转换的消耗,会使得垃圾回收的总体成本上升,造成系统吞吐量的下降。</p><h2 id="分区算法"><a class="header-anchor" href="#分区算法">¶</a>分区算法</h2><p>一般来说,在相同条件下,堆空间越大一次GC时所需要的时间就越长,有关GC产生的停顿也越长。为了更好地控制GC产生的停顿时间,将一块大的内存区域分割成多个小块,根据目标的停顿时间,每次合理地回收若干个小区间,而不是整个堆空间,从而减少一次GC所产生的停顿。</p><p>分代算法将按照对象的生命周期长短划分成两个部分,分区算法将整个堆空间划分成连续的不同小区间。每一个小区间都独立使用,独立回收。这种算法的好处是可以控制一次回收多少个小区间。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235753.png" alt="image-20200918080526405"></p>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>09_对象</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/09-dui-xiang/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/09-dui-xiang/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1>一、对象的实例化</h1><h2 id="思维导图-file-Users-zhonghongpeng-Library-Mobile-20Documents-iCloudcomtoketawareiosithoughts-Documents-jvm-E5-AF-B9-E8-B1-A1-E7-9A-84-E5-AE-9E-E4-BE-8B-E5-8C-96-itmz"><a class="header-anchor" href="#思维导图-file-Users-zhonghongpeng-Library-Mobile-20Documents-iCloudcomtoketawareiosithoughts-Documents-jvm-E5-AF-B9-E8-B1-A1-E7-9A-84-E5-AE-9E-E4-BE-8B-E5-8C-96-itmz">¶</a>[思维导图](file:///Users/zhonghongpeng/Library/Mobile%20Documents/iCloud<sub>com</sub>toketaware<sub>ios</sub>ithoughts/Documents/jvm/%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%AE%9E%E4%BE%8B%E5%8C%96.itmz)</h2><h2 id="字节码举例"><a class="header-anchor" href="#字节码举例">¶</a>字节码举例</h2><pre class="line-numbers language-language-java"><code class="language-language-java">Object obj = new Object();<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>以上代码对应下列字节码，可以看到我们定义的构造方法是在字节码<code>invokespecial</code>字节码进行执行(初始化)的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235134.png" alt="image-20200917081025938"></p><h1>二、对象的内存布局</h1><h2 id="思维导图-file-Users-zhonghongpeng-Library-Mobile-20Documents-iCloudcomtoketawareiosithoughts-Documents-jvm-E5-AF-B9-E8-B1-A1-E5-86-85-E5-AD-98-E5-B8-83-E5-B1-80-itmz"><a class="header-anchor" href="#思维导图-file-Users-zhonghongpeng-Library-Mobile-20Documents-iCloudcomtoketawareiosithoughts-Documents-jvm-E5-AF-B9-E8-B1-A1-E5-86-85-E5-AD-98-E5-B8-83-E5-B1-80-itmz">¶</a>[思维导图](file:///Users/zhonghongpeng/Library/Mobile%20Documents/iCloud<sub>com</sub>toketaware<sub>ios</sub>ithoughts/Documents/jvm/%E5%AF%B9%E8%B1%A1%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80.itmz)</h2><h1>三、对象的访问定位</h1><h2 id="思维导图-file-Users-zhonghongpeng-Library-Mobile-20Documents-iCloudcomtoketawareiosithoughts-Documents-jvm-E5-AF-B9-E8-B1-A1-E7-9A-84-E8-AE-BF-E9-97-AE-E5-AE-9A-E4-BD-8D-itmz"><a class="header-anchor" href="#思维导图-file-Users-zhonghongpeng-Library-Mobile-20Documents-iCloudcomtoketawareiosithoughts-Documents-jvm-E5-AF-B9-E8-B1-A1-E7-9A-84-E8-AE-BF-E9-97-AE-E5-AE-9A-E4-BD-8D-itmz">¶</a>[思维导图](file:///Users/zhonghongpeng/Library/Mobile%20Documents/iCloud<sub>com</sub>toketaware<sub>ios</sub>ithoughts/Documents/jvm/%E5%AF%B9%E8%B1%A1%E7%9A%84%E8%AE%BF%E9%97%AE%E5%AE%9A%E4%BD%8D.itmz)</h2>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>02_程序计数寄存器</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/02-cheng-xu-ji-shu-ji-cun-qi/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/02-cheng-xu-ji-shu-ji-cun-qi/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233902.png" alt="image-20200911110925570"></p><p>JVM中的程序计数寄存器(Program Counter Register)中，Register的命名源于CPU的寄存器，寄存器存储指令相关的现场信息。CPU只有把数据装载到寄存器才能够进行逻辑计算(ALU)。</p><p>这里，并非是广义上所指的物理寄存器，它仅仅是JVM中对于物理PC寄存器的一种抽象模拟。它是JVM定义的一个数据结构，用来存储指向JVM方法中下一条JVM指令的地址(索引)，也就是可以获取到即将要执行的指令代码，由执行引擎读取下一条指令。</p><p>它是一块独立的很小的内存空间，即不属于栈(虚拟机栈和本地方法栈)也不属于堆，几乎可以忽略不记，这块内存和线程绑定。也是运行速度最快的存储区域。</p><p>在JVM规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的声明周期保持一致。</p><p>任何时间一个线程都只有一个方法在执行，也就是所谓的<strong>当前方法</strong>。程序计数器会存储当前线程正在执行的Java方法的JVM指令地址；如果是在执行native方法，则是未指定值(undefined)。（所以个人猜测对于<strong>用户方法的实现</strong>就是在<strong>一个统一的通用的native方法</strong>中加载用户方法中所有jvm指令到一个列表，然后模拟CPU指令按指令进行实际的C/C++代码操作即可）</p><p>它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。</p><p>字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。</p><p>它是唯一一个在Java虚拟机规范中没有规定任何<code>OutofMemoryError</code>情况的区域。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233909.png" alt="image-20200911111453664"></p><h3 id="示例"><a class="header-anchor" href="#示例">¶</a>示例</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233915.png" alt="image-20200911113000991"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221233921.png" alt="image-20200911113116621"></p><h3 id="为什么要有PC寄存器"><a class="header-anchor" href="#为什么要有PC寄存器">¶</a>为什么要有PC寄存器</h3><p>因为CPU需要不停地切换各个线程，这时候切换回来以后，就得知道接着从哪开始继续执行。</p><p>JVM的字节码解释器就需要通过改变PC寄存器的值来明确下一条应该执行什么样的字节码指令。</p>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM 调优工具及辅助工具</title>
      <link href="/2020/12/22/jvm/diao-you/diao-you-gong-ju-ji-fu-zhu-gong-ju/"/>
      <url>/2020/12/22/jvm/diao-you/diao-you-gong-ju-ji-fu-zhu-gong-ju/</url>
      
        <content type="html"><![CDATA[<h1>命令工具</h1><h2 id="jps-JVM-Process-Status-Tool"><a class="header-anchor" href="#jps-JVM-Process-Status-Tool">¶</a>jps(JVM Process Status Tool)</h2><p>虚拟机进程状况工具。命令格式：</p><p><code>jps [ options ] [ hostid ]</code></p><p>jps还可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态,参数hostid为RMI注册表中注册的主机名。</p><h3 id="参数说明"><a class="header-anchor" href="#参数说明">¶</a>参数说明</h3><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 列出Java程序进程ID和Main函数名称jps# 只输出进程IDjps -q# 输出传递给Java进程(主函数)的参数 jps -m# 输出主函数的完整路径jps -l# 显示传递给Java虚拟的参数jps -v<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="jstat-JVM-Statistics-Monitoring-Tool"><a class="header-anchor" href="#jstat-JVM-Statistics-Monitoring-Tool">¶</a>jstat(JVM Statistics Monitoring Tool)</h2><p>jstat 是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>中的类加载、内存、垃圾收集、即时编译等运行时数据,在没有GUI图形界面、只提供了纯文本控制台环境的服务器上,它将是运行期定位虚拟机性能问题的常用工具。在实际生产环境中不一定可以使用图形界面,而且多数服务器管理员也都已经习惯了在文本控制台工作,直接在控制台中使用jstat命令依然是一种常用的监控方式。</p><p>jstat命令格式为：</p><p><code>jstat [ option vmid [interval[s|ms] [count]] ]</code></p><h3 id="参数说明-v2"><a class="header-anchor" href="#参数说明-v2">¶</a>参数说明</h3><p>对于命令格式中的VMID与LVMID需要特别说明一下:<strong>如果是本地虚拟机进程,VMID与LVMID 是一致的（为操作系统进程ID）</strong>;如果是远程虚拟机进程,那VMID的格式应当是:</p><p><code>[protocol:][//]lvmid[@hostname[:port]/servername]</code></p><p>参数interval和count代表查询间隔和次数,如果省略这2个参数,说明只查询一次。假设需要每250 毫秒查询一次进程2764垃圾收集状况,一共查询20次,那命令应当是:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">jstat -gc 2764 250 20<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>选项option代表用户希望查询的虚拟机信息,主要分为三类:类加载、垃圾收集、运行期编译状况。</p><table><thead><tr><th>选项</th><th>作用</th></tr></thead><tbody><tr><td>-class</td><td>监视类加载、卸载数量、总空间以及类装载所耗费的时间</td></tr><tr><td>-gc</td><td>监视Java堆状况,包括Eden区、2个 Survivor区、老年代、永久代等的容量已用空间,垃圾收集时间合计等信息</td></tr><tr><td>-gccapacity</td><td>监视内容与-gc基本相同,但输出主要关注Java堆各个区域使用到的最大、最小空间</td></tr><tr><td>-gcutil</td><td>监视内容与-gc基本相同,但输出主要关注已使用空间占总空间的百分比</td></tr><tr><td>-gccause</td><td>与-gcutil功能一样,但是会额外输出导致上一次垃圾收集产生的原因</td></tr><tr><td>-gcnew</td><td>监视新生代垃圾收集状况</td></tr><tr><td>-gcnewcapacity</td><td>监视内容与-gcnew基本相同,输出主要关注使用到的最大、最小空间</td></tr><tr><td>-gcold</td><td>监视老年代垃圾收集状况</td></tr><tr><td>-gcoldcapacity</td><td>监视内容与-gcold基本相同,输出主要关注使用到的最大、最小空间</td></tr><tr><td>-gcpermcapacity</td><td>输出永久代使用到的最大、最小空间</td></tr><tr><td>-compiler</td><td>输出即时编译器编译过的方法、耗时等信息</td></tr><tr><td>-printcompilation</td><td>输出已经被即时编译的方法</td></tr><tr><td>-t</td><td>在输出信息前加上一个Timestamp列，显示程序的运行时间</td></tr><tr><td>-h</td><td>可以在周期性数据输出后，输出多少行数据后，跟着一个表头信息</td></tr><tr><td>interval</td><td>用于指定输出统计数据的周期，单位为毫秒</td></tr><tr><td>count</td><td>用于指定一个输出多少次数据</td></tr></tbody></table><h3 id="示例"><a class="header-anchor" href="#示例">¶</a>示例</h3><h4 id="jstat-gc"><a class="header-anchor" href="#jstat-gc">¶</a>jstat -gc</h4><pre class="line-numbers language-language-shell"><code class="language-language-shell">zhonghongpeng@bogon ~ % jstat -gc 3230 250 4 S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT 0.0   4096.0  0.0   4096.0 64512.0  11264.0   455680.0   15242.4   30336.0 29368.5 3456.0 3226.7      3    0.010   0      0.000    0.010 0.0   4096.0  0.0   4096.0 64512.0  11264.0   455680.0   15242.4   30336.0 29368.5 3456.0 3226.7      3    0.010   0      0.000    0.010 0.0   4096.0  0.0   4096.0 64512.0  11264.0   455680.0   15242.4   30336.0 29368.5 3456.0 3226.7      3    0.010   0      0.000    0.010 0.0   4096.0  0.0   4096.0 64512.0  11264.0   455680.0   15242.4   30336.0 29368.5 3456.0 3226.7      3    0.010   0      0.000    0.010<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><table><thead><tr><th>输出列</th><th>说明</th></tr></thead><tbody><tr><td>S0C</td><td>年轻代中第一个survivor(幸存区)的容量 (字节)</td></tr><tr><td>S1C</td><td>年轻代中第二个survivor(幸存区)的容量 (字节)</td></tr><tr><td>S0U</td><td>年轻代中第一个survivor(幸存区)目前已使用空间 (字节)</td></tr><tr><td>S1U</td><td>年轻代中第二个survivor(幸存区)目前已使用空间 (字节)</td></tr><tr><td>EC</td><td>年轻代中Eden(伊甸园)的容量 (字节)</td></tr><tr><td>EU</td><td>年轻代中Eden(伊甸园)目前已使用空间 (字节)</td></tr><tr><td>OC</td><td>Old代的容量 (字节)</td></tr><tr><td>OU</td><td>Old代目前已使用空间 (字节)</td></tr><tr><td>MC</td><td>metaspace(元空间)的容量 (字节)</td></tr><tr><td>MU</td><td>metaspace(元空间)目前已使用空间 (字节)</td></tr><tr><td>CCSC</td><td>压缩类空间大小</td></tr><tr><td>CCSU</td><td>压缩类空间使用大小</td></tr><tr><td>YGC</td><td>从应用程序启动到采样时年轻代中gc次数</td></tr><tr><td>YGCT</td><td>从应用程序启动到采样时年轻代中gc所用时间(s)</td></tr><tr><td>FGC</td><td>从应用程序启动到采样时old代(全gc)gc次数</td></tr><tr><td>FGCT</td><td>从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT:从应用程序启动到采样时gc用的总时间(s)</td></tr><tr><td>GCT</td><td>从应用程序启动到采样时gc用的总时间(s)</td></tr></tbody></table><h4 id="jstat-class"><a class="header-anchor" href="#jstat-class">¶</a>jstat -class</h4><pre class="line-numbers language-language-shell"><code class="language-language-shell">zhonghongpeng@bogon ~ % jstat -class 3230Loaded  Bytes  Unloaded  Bytes     Time  4714  9787.2        0     0.0       1.28<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><table><thead><tr><th>输出列</th><th>说明</th></tr></thead><tbody><tr><td>Loaded</td><td>已经装载的类的数量</td></tr><tr><td>Bytes</td><td>装载类所占用的字节数</td></tr><tr><td>Unloaded</td><td>已经卸载类的数量</td></tr><tr><td>Bytes</td><td>卸载类的字节数</td></tr><tr><td>Time</td><td>装载和卸载类所花费的时间</td></tr></tbody></table><h2 id="jinfo-Configuration-Info-for-Java"><a class="header-anchor" href="#jinfo-Configuration-Info-for-Java">¶</a>jinfo(Configuration Info for Java)</h2><p>Java配置信息工具的作用是实时查看和调整虚拟机各项参数。使用jps命令的-v参数可以查看虚拟机启动时显式指定的参数列表,但如果想知道未被显式指定的参数的系统默认值,除了去找资料外,就只能使用jinfo的-flag选项进行查询了(如果只限于JDK 6或以上版本的话,使用<code>java- XX:+PrintFlagsFinal</code>查看参数默认值也是一个很好的选择)。</p><p>在JDK 6中,jinfo对于Windows平台功能仍然有较大限制,只提供了最基本的-flag选项。</p><p>格式：<code>jinfo [option] &lt;pid&gt;</code></p><h3 id="参数说明-v3"><a class="header-anchor" href="#参数说明-v3">¶</a>参数说明</h3><table><thead><tr><th>选项</th><th>说明</th></tr></thead><tbody><tr><td><code>-flag &lt;name&gt;</code></td><td>打印JVM参数<code>&lt;name&gt;</code>的值</td></tr><tr><td><code>-flag [+/-]&lt;name&gt;</code></td><td>在运行期修改部分参数值的</td></tr><tr><td><code>-flag &lt;name&gt;=&lt;value&gt;</code></td><td>在运行期修改部分参数值的</td></tr><tr><td>-sysprops</td><td>把虚拟机进程的<code>System.getProperties()</code>的内容打印出来</td></tr><tr><td><code>&lt;no option&gt;</code></td><td>打印以上所有</td></tr><tr><td>-h/-help</td><td>帮助信息</td></tr></tbody></table><h2 id="jmap-Memory-Map-for-Java"><a class="header-anchor" href="#jmap-Memory-Map-for-Java">¶</a>jmap(Memory Map for Java)</h2><p>jmap命令用于生成堆转储快照(一般称为heapdump或dump文件)。如果不使用jmap命令,要想获取Java堆转储快照也还有一些比较“暴力”的手段:</p><ul><li><code>-XX:+HeapDumpOnOutOfMemoryError</code>参数,可以让虚拟机在内存溢出异常出现之后自动生成堆转储快照文件</li><li>通过<code>-XX:+HeapDumpOnCtrlBreak</code>参数则可以使用[Ctrl]+[Break]键让虚拟机生成堆转储快照文件</li><li>又或者在Linux系统下通过Kill-3命令发送进程退出信号“恐吓”一下虚拟机,也能顺利拿到堆转储快照。</li><li>使用 jconsole 选项通过 HotSpotDiagnosticMXBean 从运行时获得堆转储。</li><li>使用 hprof 命令。</li></ul><p>jmap的作用并不仅仅是为了获取堆转储快照,它还可以查询finalize执行队列、Java堆和方法区的详细信息,如空间使用率、当前用的是哪种收集器等。和jinfo命令一样,jmap有部分功能在Windows平台下是受限的,除了生成堆转储快照的<code>-dump</code>选项和用于查看每个类的实例、空间占用统计的<code>-histo</code>选项在所有操作系统中都可以使用之外,其余选项都只能在Linux/Solaris中使用。</p><p>命令格式：</p><ul><li><code>jmap [option] &lt;pid&gt;</code></li><li><code>jmap [option] &lt;executable&gt; &lt;core&gt;</code></li><li><code>jmap [option] [server_id@]&lt;remote server IP or hostname&gt;</code></li></ul><h3 id="参数说明-v4"><a class="header-anchor" href="#参数说明-v4">¶</a>参数说明</h3><table><thead><tr><th>参数</th><th>作用</th></tr></thead><tbody><tr><td>pid</td><td>需要打印配置信息的进程ID。</td></tr><tr><td>executable</td><td>产生核心dump的Java可执行文件。</td></tr><tr><td>core</td><td>需要打印配置信息的核心文件。</td></tr><tr><td>server-id</td><td>可选的唯一id，如果相同的远程主机上运行了多台调试服务器，用此选项参数标识服务器。(VMID?)</td></tr><tr><td>remote server IP or hostname</td><td>远程调试服务器的IP地址或主机名。</td></tr></tbody></table><table><thead><tr><th>选项</th><th>说明</th></tr></thead><tbody><tr><td>no option</td><td>查看进程的内存映像信息,类似 Solaris pmap 命令。</td></tr><tr><td>-heap</td><td>显示Java堆详细信息,如使用哪种回收器、参数配置、分代状况等。只在 Linux/Solaris平台下有效</td></tr><tr><td>-dump</td><td>生成Java堆转储快照。格式为 <code>-dump:[live,]format=b,file= &lt;filename&gt;</code>, 其中live子参数说明是否只dump出存活的对象</td></tr><tr><td>-finalizerinfo</td><td>显示在F-Queue中等待 Finalizer线程执行 finalize方法的对象。只在 Linux/ Solaris平下有效</td></tr><tr><td>-histo[:live]</td><td>显示堆中对象统计信息,包括类、实例数量、合计容量</td></tr><tr><td>-F</td><td>当虚拟机进程对-dump选项没有响应时,可使用这个选项强制生成dump快照。只在Linux/ Solaris平台下有效</td></tr><tr><td>-permstat</td><td>以 Classloader为统计口径显示永久代内存状态。只在 Linux/ Solaris平台下有效</td></tr><tr><td>-clstats</td><td>打印类加载器相关统计信息</td></tr><tr><td><code>-J&lt;flag&gt;</code></td><td>to pass <code>&lt;flag&gt;</code> directly to the runtime system</td></tr></tbody></table><h2 id="jhat-JVM-Heap-Analysis-Tool"><a class="header-anchor" href="#jhat-JVM-Heap-Analysis-Tool">¶</a>jhat(JVM Heap Analysis Tool)</h2><p>JDK提供jhat(JVM Heap Analysis Tool)命令与jmap搭配使用,来分析jmap生成的堆转储快照。<br>jhat内置了一个微型的HTTP/Web服务器,生成堆转储快照的分析结果后,可以在浏览器中查看。不过实事求是地说,在实际工作中,除非手上真的没有别的工具可用,否则多数人是不会直接使用jhat命令来分析堆转储快照文件的,主要原因有两个方面：</p><ol><li>一般不会在部署应用程序的服务器上直接分析堆转储快照,即使可以这样做,也会尽量将堆转储快照文件复制到其他机器上进行分析,因为分析工作是一个耗时而且极为耗费硬件资源的过程,既然都要在其他机器上进行,就没有必要再受命令行工具的限制了</li><li>另外一个原因是jhat的分析功能相对来说比较简陋,如VisualVM以及专业用于分析堆转储快照文件的Eclipse Memory Analyzer、IBM HeapAnalyzer等工具,都能实现比jhat更强大专业的分析功能。</li></ol><p>命令格式：<code>jhat [ options ] heap-dump-file</code></p><h3 id="参数说明-v5"><a class="header-anchor" href="#参数说明-v5">¶</a>参数说明</h3><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>options</td><td>可选命令行参数</td></tr><tr><td>heap-dump-file</td><td>要查看的二进制Java堆转储文件(Java binary heap dump file)。 如果某个转储文件中包含了多份 heap dumps, 可在文件名之后加上 <code>#</code> 的方式指定解析哪一个 dump, 如: <code>myfile.hprof#3</code></td></tr></tbody></table><table><thead><tr><th>选项</th><th>说明</th></tr></thead><tbody><tr><td>-stack false/true</td><td>关闭对象分配调用栈跟踪(tracking object allocation call stack)。 如果分配位置信息在堆转储中不可用. 则必须将此标志设置为 false. 默认值为 true .</td></tr><tr><td>-refs false/true</td><td>关闭对象引用跟踪(tracking of references to objects)。 默认值为 true . 默认情况下, 返回的指针是指 向其他特定对象的对象,如反向链接或输入引用(referrers or incoming references), 会统计/计算堆中的 所有对象。</td></tr><tr><td>-port port-number</td><td>设置 jhat HTTP server 的端口号. 默认值 7000 .</td></tr><tr><td>-exclude exclude-file</td><td>指定对象查询时需要排除的数据成员列表文件(a file that lists data members that should be excluded from the reachable objects query)。 例如, 如果文件列列出了 java.lang.String.value , 那么当从某个特定对象 Object o 计算可达的对象列表时, 引用路径涉及 java.lang.String.value 的都会被排除。</td></tr><tr><td>-baseline exclude-file</td><td>指定一个基准堆转储(baseline heap dump)。 在两个 heap dumps 中有相同 object ID 的对象会被标记为不是新的(marked as not being new). 其他对象被标记为新的(new). 在比较两个不同的堆转储时很 有用.</td></tr><tr><td>-debug int</td><td>设置 debug 级别. 0 表示不输出调试信息。 值越大则表示输出更详细的 debug 信息.</td></tr><tr><td>-version</td><td>启动后只显示版本信息就退出</td></tr><tr><td>-help/-h</td><td>显示帮助信息并退出</td></tr><tr><td><code>-J&lt;flag&gt;</code></td><td>因为 jhat 命令实际上会启动一个JVM来执行, 通过 <code>-J</code> 可以在启动JVM时传入一些启动参数. 例如, <code>-JXmx512m</code> 则指定运行 jhat 的Java虚拟机使用的最大堆内存为 512 MB. 如果需要使用多个JVM启动参数, 则传入多个 <code>-Jxxxxxx</code>.</td></tr></tbody></table><h3 id="示例-v2"><a class="header-anchor" href="#示例-v2">¶</a>示例</h3><p>执行命令启动服务器</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">zhonghongpeng@bogon heapdump % jhat ./heapdump-1600348822631.hprof Reading from ./heapdump-1600348822631.hprof...Dump file created Thu Sep 17 21:20:22 CST 2020Snapshot read, resolving...Resolving 38612 objects...Chasing references, expect 7 dots.......Eliminating duplicate references.......Snapshot resolved.Started HTTP server on port 7000Server is ready.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>启动如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232437.png" alt="image-20200920093053766"></p><p>分析结果默认以包为单位进行分组显示,分析内存泄漏问题主要会使用到其中的“Heap Histogram”(与jmap-histo功能一样)与OQL页签的功能,前者可以找到内存中总容量最大的对象,后者是标准的对象查询语言,使用类似SQL的语法对内存中的对象进行查询统计。</p><p>jhat 启动后显示的 html ⻚面中包含有:</p><ul><li>All classes including platform:显示出堆中所包含的所有的类</li><li>Show all members of the rootset :从根集能引用到的对象</li><li>Show instance counts for all classes (including platform/excluding platform):显示平台包括的 所有类的实例数量</li><li>Show heap histogram:堆实例的分布表</li><li>Show finalizer summary:Finalizer 摘要</li><li>Execute Object Query Language (OQL) query:执行对象查询语句(OQL)</li></ul><h2 id="jstack-Stack-Trace-for-Java"><a class="header-anchor" href="#jstack-Stack-Trace-for-Java">¶</a>jstack(Stack Trace for Java)</h2><p>jstack命令用于生成虚拟机当前时刻的线程快照(一般称为threaddump或者javacore文件)。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合,生成线程快照的目的通常是定位线程出现长时间停顿的原因,如线程间死锁、死循环、请求外部资源导致的长时间挂起等,都是导致线程长时间停顿的常见原因。线程出现停顿时通过jstack来查看各个线程的调用堆栈, 就可以获知没有响应的线程到底在后台做些什么事情,或者等待着什么资源。</p><p>命令格式：</p><ul><li><p><code>jstack [ option ] pid</code>： 查看当前时间点，指定进程的dump堆栈信息。</p></li><li><p><code>jstack [ option ] pid &gt; 文件</code>： 将当前时间点的指定进程的dump堆栈信息，写入到指定文件中。</p><p>注:若该文件不存在，则会自动生成;若该文件存在，则会覆盖源文件。</p></li><li><p><code>jstack [ option ] executable core</code>： 查看当前时间点，core文件的dump堆栈信息。</p></li><li><p><code>jstack [ option ] [server_id@]&lt;remote server IP or hostname&gt;</code>： 查看当前时间点，远程 机器的dump堆栈信息。</p></li></ul><h3 id="参数说明-v6"><a class="header-anchor" href="#参数说明-v6">¶</a>参数说明</h3><table><thead><tr><th>选项</th><th>说明</th></tr></thead><tbody><tr><td>-F</td><td>当正常输出的请求不被响应时,强制输出线程堆栈</td></tr><tr><td>-l</td><td>除堆栈外,显示关于锁的附加信息。⻓列表. 打印关于锁的附加信息。例如属于java.util.concurrent的ownable synchronizers 列表，会使得JVM停顿得⻓久得多(可能会差很多倍，比如普通的jstack可能几毫秒和一次GC没区别，加了-l 就是近一秒的时间)，-l 建议不要用。一般情况不需要使用。</td></tr><tr><td>-m</td><td>如果调用到本地方法的话,可以显示C/C++的堆栈，一般应用排查不需要使用。</td></tr></tbody></table><h3 id="在thread-dump中要留意的状态"><a class="header-anchor" href="#在thread-dump中要留意的状态">¶</a>在thread dump中要留意的状态</h3><ul><li>死锁，Deadlock(重点关注)</li><li>等待资源，Waiting on condition(重点关注)</li><li>等待获取监视器，Waiting on monitor entry(重点关注)</li><li>阻塞，Blocked(重点关注)</li><li>执行中，Runnable</li><li>暂停，Suspended</li><li>对象等待中，Object.wait() 或 TIMED_WAITING</li><li>停止，Parked</li></ul><h3 id="自己实现"><a class="header-anchor" href="#自己实现">¶</a>自己实现</h3><p>从JDK5起,<code>java.lang.Thread</code>类新增了一个<code>getAllStackTraces()</code>方法用于获取虚拟机中所有线程的<code>StackTraceElement</code>对象。使用这个方法可以通过简单的几行代码完成jstack的大部分功能,在实际项目中不妨调用这个方法做个管理员页面,可以随时使用浏览器来查看线程堆栈：</p><pre class="line-numbers language-language-java"><code class="language-language-java">        for (Map.Entry<Thread, StackTraceElement[]> stackTrace : Thread.getAllStackTraces().entrySet()) {            Thread thread = (Thread) stackTrace.getKey();            StackTraceElement[] stack = (StackTraceElement[]) stackTrace.getValue();            if (thread.equals(Thread.currentThread())) {                continue;            }            System.out.print("\n线程:" + thread.getName() + "\n");            for (StackTraceElement element : stack) {                System.out.print("\t" + element + "\n");            }        }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="hprof-Heap-CPU-Profiling-Tool"><a class="header-anchor" href="#hprof-Heap-CPU-Profiling-Tool">¶</a>hprof(Heap/CPU Profiling Tool)</h2><p>J2SE中提供了一个简单的命令行工具来对java程序的cpu和heap进行 profiling，叫做HPROF。 HPROF实际上是JVM中的一个native的库，它会在JVM启动的时候通过命令行参数来动态加载，并成为 JVM进程的一部分。若要在java进程启动的时候使用HPROF，用户可以通过各种命令行参数类型来使用 HPROF对java进程的heap或者 (和)cpu进行profiling的功能。HPROF产生的profiling数据可以是二 进制的，也可以是文本格式的。这些日志可以用来跟踪和分析 java进程的性能问题和瓶颈，解决内存使用上不优的地方或者程序实现上的不优之处。二进制格式的日志还可以被JVM中的HAT工具来进行浏览 和分析，用 以观察java进程的heap中各种类型和数据的情况。在J2SE 5.0以后的版本中，HPROF已经被 并入到一个叫做Java Virtual Machine Tool Interface(JVM TI)中。</p><p>命令格式：</p><ul><li><code>java -agentlib:hprof[=options] ToBeProfiledClass</code></li><li><code>java -Xrunprof[:options] ToBeProfiledClass</code></li><li><code>javac -J-agentlib:hprof[=options] ToBeProfiledClass</code></li></ul><h3 id="参数说明-v7"><a class="header-anchor" href="#参数说明-v7">¶</a>参数说明</h3><table><thead><tr><th>选项</th><th>说明</th><th>默认</th></tr></thead><tbody><tr><td>heap=dump|site|sall</td><td>heap profiling</td><td>all</td></tr><tr><td>cpu=samples|times|old</td><td>CPU usage</td><td>off</td></tr><tr><td>monitor=y|n</td><td>monitor contention</td><td>n</td></tr><tr><td>format=a|b</td><td>text(txt) or binary output</td><td>a</td></tr><tr><td><code>file=&lt;file&gt;</code></td><td>write data to file</td><td>java.hprof[.txt]</td></tr><tr><td><code>net=&lt;host&gt;:&lt;port&gt;</code></td><td>send data over a socket</td><td>off</td></tr><tr><td><code>depth=&lt;size&gt;</code></td><td>stack trace depth</td><td>4</td></tr><tr><td><code>interval=&lt;ms&gt;</code></td><td>sample interval in ms</td><td>10</td></tr><tr><td><code>cutoff=&lt;value&gt;</code></td><td>output cutoff point</td><td>0.0001</td></tr><tr><td>lineno=y|n</td><td>line number in traces?</td><td>y</td></tr><tr><td>thread=y|n</td><td>thread in traces?</td><td>n</td></tr><tr><td>doe=y|n</td><td>dump on exit?</td><td>y</td></tr><tr><td>msa=y|n</td><td>Solaris micro state accounting</td><td>n</td></tr><tr><td>force=y|n</td><td><code>force output to &lt;file&gt;</code></td><td>y</td></tr><tr><td>verbose=y|n</td><td>print messages about dumps</td><td>y</td></tr></tbody></table><h3 id="示例-v3"><a class="header-anchor" href="#示例-v3">¶</a>示例</h3><p>命令示例：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 每隔20毫秒采样CPU消耗信息，堆栈深度为3，生成的profile文件名称 java.hprof.txt，在当前目录。java -agentlib:hprof=cpu=samples,interval=20,depth=3 Hello# CPU Usage Times Profiling(cpu=times)的例子，它相对于CPU Usage Sampling Profile能够获得更加细粒度的CPU消耗信息，能够细到每个方法调用的开始和结束，它的实现使用了字节码注入技术 (BCI):javac -J-agentlib:hprof=cpu=times Hello.java# Heap Allocation Profiling(heap=sites)的例子:javac -J-agentlib:hprof=heap=sites Hello.java# Heap Dump(heap=dump)的例子，它比上面的Heap Allocation Profiling能生成更详细的Heap Dump信息:javac -J-agentlib:hprof=heap=dump Hello.java<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>统计方法耗时：</p><pre class="line-numbers language-language-java"><code class="language-language-java">package demo;/** * @author: honphan.john * @date: 2020/9/20 10:03 * @description: */public class HprofTest {    // java -agentlib:hprof=cpu=times,interval=10 demo.HprofTest demo.HprofTest    public void slowMethod() {        try {            Thread.sleep(1000);        } catch (InterruptedException e) {            e.printStackTrace();        }    }    public void slowerMethod() {        try {            Thread.sleep(1000);        } catch (InterruptedException e) {            e.printStackTrace();        }    }    public void fastMethod() {        try {            Thread.yield();        } catch (Exception e) {            e.printStackTrace();        }    }    public static void main(String[] args) {        HprofTest test = new HprofTest();        test.fastMethod();        test.slowMethod();        test.slowerMethod();    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="注"><a class="header-anchor" href="#注">¶</a>注</h3><p>虽然在JVM启动参数中加入<code>-Xrunprof:heap=sites</code>参数可以生成CPU/Heap Profile文件，但对JVM性能影响非常大，不建议在线上服务器环境使用。</p><h2 id="命令工具参考"><a class="header-anchor" href="#命令工具参考">¶</a>命令工具参考</h2><h3 id="基础工具"><a class="header-anchor" href="#基础工具">¶</a>基础工具</h3><p>用于支持基本的程序创建和运行</p><table><thead><tr><th>名称</th><th>主要作用</th></tr></thead><tbody><tr><td>appletviewer</td><td>在不使用Web浏览器的情况下运行和调试 Applet,JDK11中被移除</td></tr><tr><td>extcheck</td><td>检査JAR冲突的工具,从JDK9中被移除</td></tr><tr><td>jar</td><td>创建和管理JAR文件</td></tr><tr><td>java</td><td>Java运行工具,用于运行 Class文件或JAR文件</td></tr><tr><td>javac</td><td>用于Java编程语言的编译器</td></tr><tr><td>javadoc</td><td>Java的API文档生成器</td></tr><tr><td>javah</td><td>C语言头文件和Stub函数生成器,用于编写JNI方法</td></tr><tr><td>javap</td><td>Java字节码分析工具</td></tr><tr><td>jlink</td><td>将Module和它的依赖打包成一个运行时镜像文件</td></tr><tr><td>jdb</td><td>基于JPDA协议的调试器,以类似于GDB的方式进行调试Java代码</td></tr><tr><td>jdeps</td><td>Java类依赖性分析器</td></tr><tr><td>ideprscan</td><td>用于搜索JAR包中使用了“ deprecated”的类,从JDK9开始提供</td></tr></tbody></table><h3 id="安全"><a class="header-anchor" href="#安全">¶</a>安全</h3><p>用于程序签名、设置安全测试</p><table><thead><tr><th>名称</th><th>主要作用</th></tr></thead><tbody><tr><td>keytool</td><td>管理密钥库和证书。主要用于获取或缓存 Kerberos协议的票据授权票据。允许用户査看本地凭据缓存和密钥表中的条目(用于 Kerberos协议)</td></tr><tr><td>jarsigner</td><td>生成并验证JAR签名</td></tr><tr><td>policytool</td><td>管理策略文件的GUI工具,用于管理用户策略文件(java. policy),在JDK10中被移除</td></tr></tbody></table><h3 id="国际化"><a class="header-anchor" href="#国际化">¶</a>国际化</h3><p>用于创建本地语言文件</p><table><thead><tr><th>名称</th><th>主要作用</th></tr></thead><tbody><tr><td>native2ascii</td><td>本地编码到ASCⅡ编码的转换器( Native-to-ASCII Converter),用于“任意受支持的字符编码和与之对应的“ASC编码和 Unicode转义”之间的相互转换</td></tr></tbody></table><h3 id="远程方法调用"><a class="header-anchor" href="#远程方法调用">¶</a>远程方法调用</h3><p>用于跨Web或网络的服务交互</p><table><thead><tr><th>名称</th><th>主要作用</th></tr></thead><tbody><tr><td>rmic</td><td>Java RMI编译器,为使用JRMP或IIOP协议的远程对象生成Stub、 Skeleton和Tie类,也用于生成 OMG IDL</td></tr><tr><td>rmiregistry</td><td>远程对象注册表服务,用于在当前主机的指定端口上创建并启动一个远程对象注册表</td></tr><tr><td>rmid</td><td>启动激活系统守护进程,允许在虚拟机中注册或激活对象</td></tr><tr><td>serialver</td><td>生成并返回指定类的序列化版本ID</td></tr></tbody></table><h3 id="Java-IDL与RMI-IOP"><a class="header-anchor" href="#Java-IDL与RMI-IOP">¶</a>Java IDL与RMI-IOP</h3><p>在JDK11中结束了十余年的 CORBA支持,这些工具不再提供</p><table><thead><tr><th>名称</th><th>主要作用</th></tr></thead><tbody><tr><td>tnameserv</td><td>提供对命名服务的访问IDL转Java编译器(IDL-to- -Java Compiler),生成映射 OMG IDL接口的Java源文件,并启用以Java编程语言编写的使用 CORBA功能的应用程序的Java源文件。IDL意即接口定义语言(Interface Definition Language)</td></tr><tr><td>idlj</td><td>对象请求代理守护进程( Object Request Broker Daemon),提供从客户端查找和调用 CORBA 环境服务端上的持久化对象的功能。使用ORBD代替瞬态命名服务tnameserv。ORBD包括瞬态orb 命名服务和持久命名服务。ORBD工具集成了服务器管理器、互操作命名服务和引导名称服务器的功能。当客户端想进行服务器时定位、注册和激活功能时,可以与 servertool一起使用</td></tr><tr><td>servertool</td><td>为应用程序注册、注销、启动和关闭服务器提供易用的接口</td></tr></tbody></table><h3 id="部署工具"><a class="header-anchor" href="#部署工具">¶</a>部署工具</h3><p>用于程序打包、发布和部署</p><table><thead><tr><th>名称</th><th>主要作用</th></tr></thead><tbody><tr><td>javapackager</td><td>打包、签名Java和 Javafx应用程序,在JDK11中被移除</td></tr><tr><td>pack200</td><td>使用 Java GZIP压缩器将JAR文件转换为压缩的Pack200文件。压缩的压缩文件是高度压缩的JAR,可以直接部署,节省带宽并减少下载时间</td></tr><tr><td>unpack200</td><td>将Pack200生成的打包文件解压提取为JAR文件</td></tr></tbody></table><h3 id="Java-Web-Start"><a class="header-anchor" href="#Java-Web-Start">¶</a>Java Web Start</h3><table><thead><tr><th>名称</th><th>主要作用</th></tr></thead><tbody><tr><td>javaws</td><td>启动 Java Web Start并设置各种选项的工具。在JDK11中被移除</td></tr></tbody></table><h3 id="性能监控和故障处理"><a class="header-anchor" href="#性能监控和故障处理">¶</a>性能监控和故障处理</h3><p>用于监控分析Java虚拟机运行信息,排查问题</p><table><thead><tr><th>名称</th><th>主要作用</th></tr></thead><tbody><tr><td>jps</td><td>JVM Process Status Tool,显示指定系统内所有的 Hotspot虚拟机进程</td></tr><tr><td>jstat</td><td>JVM Statistics Monitoring Tool,用于收集 Hotspot虚拟机各方面的运行数据</td></tr><tr><td>jstad</td><td>JVM Statistics Monitoring Tool Daemon, jstat的守护程序,启动一个RMI服务器应用程序, statd 用于监视测试的 Hotspot虚拟机的创建和终止,并提供一个界面,允许远程监控工具附加到在本地系统上运行的虚拟机。在JDK9中集成到了 JHSDB中</td></tr><tr><td>jinfo</td><td>Configuration Info for Java,显示虚拟机配置信息。在JDK9中集成到了 JHSDB中</td></tr><tr><td>jmap</td><td>Memory Map for Java,生成虚拟机的内存转储快照( headup文件)。在JDK9中集成到了JHSDB中</td></tr><tr><td>jhat</td><td>JVMHeapAnalysisTool,用于分析堆转储快照,它会建立一个HTTP/WEB服务器,让用户可以在浏览器上査看分析结果。在JDK9中被 JHSDB代替</td></tr><tr><td>jstack</td><td>stack Stack Trace for Java,显示虚拟机的线程快照。在JDK9中集成到了 JHSDB中</td></tr><tr><td>jhsdb</td><td>Java Hotspot Debugger,一个基于 Serviceability Agent的 Hotspot进程调试器,从JDK9开始提供</td></tr><tr><td>jsadebugd</td><td>Java Serviceability Agent Debug Daemon,适用于Java的可维护性代理调试守护程序,主要用于附加到指定的Java进程、核心文件,或充当一个调试服务器</td></tr><tr><td>jcmd</td><td>JVM Command,虚拟机诊断命令工具,将诊断命令请求发送到正在运行的Java虚拟机。从JDK7开始提供</td></tr><tr><td>jconsole</td><td>Java Console,用于监控Java虚拟机的使用JMX规范的图形工具。它可以监控本地和远程jconsole Java虚拟机,还可以监控和管理应用程序</td></tr><tr><td>jmc</td><td>Java Mission Control,包含用于监控和管理Java应用程序的工具,而不会引入与这些工具相Jmc 关联的性能开销。开发者可以使用jme命令来创建JMC工具,从JDK7 Update40开始集成到Oraclejdk中</td></tr><tr><td>jvisualvm</td><td>Java Visualvm,一种图形化工具,可在Java虚拟机中运行时提供有关基于Java技术的应用程序(Java应用程序)的详细信息。 Java Visualvm提供内存和CPU分析、堆转储分析、内存泄漏检测、 Mbean访问和垃圾收集。从JDK6 Update7开始提供;从JDK9开始不再打包入JDK 中,但仍保持更新发展,可以独立下载</td></tr></tbody></table><h3 id="Web-Service工具"><a class="header-anchor" href="#Web-Service工具">¶</a>Web Service工具</h3><p>与CORBA一起在JDK11中被移除</p><table><thead><tr><th>名称</th><th>主要作用</th></tr></thead><tbody><tr><td>schemagen</td><td>用于XML绑定的 Schema生成器,用于生成 XML Schema文件</td></tr><tr><td>wsgen</td><td>XML Web Service2.0的 Java API,生成用于JAX- WS Web Service的JAX-WS便携式产物</td></tr><tr><td>wsimport</td><td>XML Web Service2.0的 Java API,主要用于根据服务端发布的WSDL文件生成客户端</td></tr><tr><td>xjc</td><td>主要用于根据 XML Schema文件生成对应的Java类</td></tr></tbody></table><h3 id="REPL和脚本工具"><a class="header-anchor" href="#REPL和脚本工具">¶</a>REPL和脚本工具</h3><table><thead><tr><th>名称</th><th>主要作用</th></tr></thead><tbody><tr><td>jshell</td><td>基于Java的 Shell REPL(Read-Eval-Print Loop)交互工具</td></tr><tr><td>jjs</td><td>对 Nashorn引擎的调用入口。 Nashorn是基于Java实现的一个轻量级高性能 Javascript运行环境</td></tr><tr><td>jrunscript</td><td>Java命令行脚本外売工具( Command Line Script Shell),主要用于解释执行Javascript、 Groovy、 Ruby等脚本语言</td></tr></tbody></table><h1>图形化工具</h1><h2 id="JHSDB"><a class="header-anchor" href="#JHSDB">¶</a>JHSDB</h2><p>JDK中提供了JCMD和JHSDB两个集成式的多功能工具箱,它们不仅整合了上面的所有基础工具所能提供的专项功能,而且由于有着“后发优势”,能够做得往往比之前的老工具们更好、更强大。</p><p>JHSDB虽然名义上是JDK 9中才正式提供,但之前已经以sa-jdi.jar包里面的HSDB(可视化工具)和CLHSDB(命令行工具)的形式存在了很长一段时间。它们两个都是JDK的正式成员,随着JDK一同发布,无须独立下载,使用也是完全免费的。准确来说是Linux和Solaris在OracleJDK 6就可以使用HSDB和CLHSDB了,Windows上要到Oracle-JDK 7才可以用。</p><p>JHSDB是一款基于服务性代理(Serviceability Agent,SA)实现的进程外调试工具。服务性代理是HotSpot虚拟机中一组用于映射Java虚拟机运行信息的、主要基于Java语言(含少量JNI代码)实现的API集合。服务性代理以HotSpot内部的数据结构为参照物进行设计,把这些C<ins>的数据抽象出Java模型对象,相当于HotSpot的C</ins>代码的一个镜像。通过服务性代理的API,<strong>可以在一个独立的Java虚拟机的进程里分析其他HotSpot虚拟机的内部数据,或者从HotSpot虚拟机进程内存中dump出来的转储快照里还原出它的运行状态细节</strong>。服务性代理的工作原理跟Linux上的GDB或者Windows上的Windbg是相似的。</p><p>JCMD、JHSDB与原基础工具实现相同功能的简要对比：</p><table><thead><tr><th>基础工具</th><th>JCMD</th><th>JHSDB</th></tr></thead><tbody><tr><td>jps -lm</td><td>jcmd</td><td>N/A</td></tr><tr><td>jmap -dump <code>&lt;pid&gt;</code></td><td>jcmd <code>&lt;pid&gt;</code> GC.heap_dump</td><td>jhsdb jmap --binaryheap</td></tr><tr><td>jmap -histo <code>&lt;pid&gt;</code></td><td>jcmd <code>&lt;pid&gt;</code> GC.classhistogram</td><td>jhsdb jmap --histo</td></tr><tr><td>jstack <code>&lt;pid&gt;</code></td><td>jcmd <code>&lt;pid&gt;</code> Thread.print</td><td>jhsdb jstack --locks</td></tr><tr><td>jinto -sysprops <code>&lt;pid&gt;</code></td><td>jcmd <code>&lt;pid&gt;</code> VM.system_properties</td><td>jhsdb info --sysprops</td></tr><tr><td>jinfo -flags <code>&lt;pid&gt;</code></td><td>jcmd <code>&lt;pid&gt;</code> VM.flags</td><td>jhsdb jinfo --flags</td></tr></tbody></table><h3 id="实战示例"><a class="header-anchor" href="#实战示例">¶</a>实战示例</h3><p>通过实验来回答一个简单问题:staticObj、instanceObj、localObj这三个变量本身(而不是它们所指向的对象)存放在哪里。</p><pre class="line-numbers language-language-java"><code class="language-language-java">package demo;/** * -Xmx10m -XX:+UseSerialGC -XX:-UseCompressedOops * * @author: honphan.john * @date: 2020/9/20 10:55 * @description: */public class JHSDB_TestCase {    static class Test {        static ObjectHolder staticObj = new ObjectHolder();        ObjectHolder instanceObj = new ObjectHolder();        void foo() {            ObjectHolder localObj = new ObjectHolder();            System.out.println("done");    // 这里设一个断点        }    }    private static class ObjectHolder {    }    public static void main(String[] args) {        Test test = new JHSDB_TestCase.Test();        test.foo();    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>首先,我们要确保这三个变量已经在内存中分配好,然后将程序暂停下来,以便有空隙进行实验,这只要把断点设置在代码中加粗的打印语句上,然后在调试模式下运行程序即可。由于JHSDB本身对压缩指针的支持存在很多缺陷,建议用64位系统实验时禁用压缩指针,另外为了后续操作时可以加快在内存中搜索对象的速度,也建议限制一下Java堆的大小：<code>-Xmx10m -XX:+UseSerialGC -XX:-UseCompressedOops</code>。</p><p>程序执行后通过jps查询到测试程序的进程ID,具体如下:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">zhonghongpeng@bogon jvm % jps    6644 Launcher6645 JHSDB_TestCase6647 Jps1119 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>启动JHSDB(本次试验基于Java8，在${JAVA_HOME}/bin下还没有JHSDB命令行工具，JDK9及之后使用<code>jhsdb hsdb --pid &lt;pid&gt;</code>)</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">sudo java -cp ,:/Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home/lib/sa-jdi.jar sun.jvm.hotspot.HSDB 6645<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232500.png" alt="image-20200920114157856"></p><p>下面直接在堆中查找创建的三个对象</p><p>首先点击菜单中的<code>Tools-&gt;Heap Parameters</code>, 因为运行参数中指定了使用的是Serial收集器,图中我们看到了典型的Serial的分代内存布局,Heap Parameters窗口中清楚列出了新生代的Eden、S1、S2和老年代的容量(单位为字节)以及它们的虚拟内存地址起止范围。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232507.png" alt="image-20200920114430925"></p><p>开Windows-&gt;Console窗口,使用scanoops命令在Java堆的新生代(从Eden起始地址到To Survivor结束地址)范围内查找ObjectHolder的实例,结果如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232514.png" alt="image-20200920114738658"></p><p>果然找出了三个实例的地址,而且它们的地址都落到了Eden的范围之内,算是顺带验证了一般情况下新对象在Eden中创建的分配规则。接下来要根据堆中对象实例地址找出引用它们的指针,原本JHSDB的Tools菜单中有Compute Reverse Ptrs来完成这个功能，但是低版本的貌似都有问题，改为在console面板使用命令行替代(所有图形化操作都可以在console使用命令行替代，输入<code>help</code>获取帮助信息)。</p><p>在下图上半部分可以看到使用<code>revptrs</code>命令找到了一个引用了第一个对象&quot;0x000000010f465e70&quot;的对象地址&quot;0x000000010f454270&quot;，它存储的是一个<code>Class</code>对象**（一个&quot;.class&quot;文件会生成一个Java<code>Class</code>对象，一些静态成员会称为<code>Class</code>对象的成员，这些信息在JDK7之前在方法区/永久代，JDK7及之后和字符串常量池一起移到了堆/老年代）**。</p><p>下半部分使用Tools-&gt;Inspector功能根据找到的对象内存地址检查存放的对象。Inspector为我们展示了对象头和指向对象元数据的指针,里面包括了Java类型的名字、继承关系、实现接口关系,字段信息、方法信息、运行时常量池的指针、内嵌的虚方法表(vtable)以及接口方法表(itable)等。</p><p>可以看到这个对象有一个成员正是<code>staticObj</code>存储的内容就是&quot;0x000000010f465e70&quot;。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232521.png" alt="image-20200920115225042"></p><p>接着我们查找第二个对象被谁引用了。如下图可以看到是一个在内存地址为&quot;0x000000010f465e80&quot;的<code>JHSDB_TestCase$Test</code>对象的一个<code>instanceObj</code>存储了该对象的地址&quot;0x000000010f465e98&quot;。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232529.png" alt="image-20200920115931689"></p><p>尝试寻找最后一个对象的时候得到一个空指针，可能该命令还不支持栈上查找：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">hsdb> revptrs 0x000000010f465ea8nullnull<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>在Java Thread窗口选中main线程后点击Stack Memory按钮查看该线程的栈内存。可以直接在栈上找到了对该最后一个对象<code>localObj</code>的引用：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232535.png" alt="image-20200920120439531"></p><h2 id="JConsole-Java-Monitoring-and-Management-Console"><a class="header-anchor" href="#JConsole-Java-Monitoring-and-Management-Console">¶</a>JConsole(Java Monitoring and Management Console)</h2><p>JConsole是一款基于JMX(Java Management Extensions)的可视化监视、管理工具。它的主要功能是通过JMX的MBean(Managed Bean)对系统进行信息收集和参数动态调整。JMX是一种开放性的技术,不仅可以用在虚拟机本身的管理上,还可以运行于虚拟机之上的软件中,典型的如中间件大多也基于JMX来实现管理与监控。虚拟机对JMX MBean的访问也是完全开放的,可以使用代码调用API、支持JMX协议的管理控制台,或者其他符合JMX规范的软件进行访问。</p><h3 id="使用"><a class="header-anchor" href="#使用">¶</a>使用</h3><h4 id="启动"><a class="header-anchor" href="#启动">¶</a>启动</h4><p>如果是从命令行启动，使 JDK 在 PATH 上，运行 <code>jconsole</code> 即可。<br>如果从 GUI shell 启动，找到 JDK 安装路径，打开 bin 文件夹，双击 jconsole 。</p><h4 id="连接"><a class="header-anchor" href="#连接">¶</a>连接</h4><ul><li>jconsole启动后会自动搜索出本机运行的所有虚拟机进程,而不需要用户自己使用jps来查询。双击选择其中一个进程便可进入主界面开始监控。</li><li>JMX支持跨服务器的管理,也可以使用下面的“远程进程”功能来连接远程服务器,对远程虚拟机进行监控<ul><li>通过<code>jconsole host:port</code>命令</li><li>也可以在已经打开的JConsole界面操作：连接-&gt;新建连接-&gt;选择远程进程-&gt;输入远程主机IP和端口号- &gt;点击“连接”</li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232544.png" alt="image-20200920155644799"></p><h3 id="界面介绍"><a class="header-anchor" href="#界面介绍">¶</a>界面介绍</h3><p>进入视图后包括这六个标签:</p><h4 id="Overview"><a class="header-anchor" href="#Overview">¶</a>Overview:</h4><p>Displays overview information about the Java VM and monitored values.</p><h4 id="Memory-显示内存使用信息"><a class="header-anchor" href="#Memory-显示内存使用信息">¶</a>Memory: 显示内存使用信息</h4><p>“内存”页签的作用相当于可视化的jstat命令,用于监视被收集器管理的虚拟机内存(被收集器直接管理的Java堆和被间接管理的方法区)的变化趋势。包括Eden、Survivor、Ternuring、Metaspace等等维度的内存监控。</p><h4 id="Threads-显示线程使用信息"><a class="header-anchor" href="#Threads-显示线程使用信息">¶</a>Threads: 显示线程使用信息</h4><p>“线程”页签的功能就相当于可视化的jstack命令了,遇到线程停顿的时候可以使用这个页签的功能进行分析。如线程长时间停顿的主要原因有等待外部资源(数据库连接、网络资源、设备资源等)、死循环、锁等待等。</p><h5 id="示例："><a class="header-anchor" href="#示例：">¶</a>示例：</h5><pre class="line-numbers language-language-java"><code class="language-language-java">package demo.jconsole;import java.io.BufferedReader;import java.io.InputStreamReader;/** * @author: honphan.john * @date: 2020/9/20 15:55 * @description: */public class ThreadTest {    /**     * 线程死循环演示     */    public static void createBusyThread() {        Thread thread = new Thread(new Runnable() {            @Override            public void run() {                while (true)   // 第19行                {                    ;                }            }        }, "testBusyThread");        thread.start();    }    /**     * 线程锁等待演示     */    public static void createLockThread(final Object lock) {        Thread thread = new Thread(new Runnable() {            @Override            public void run() {                synchronized (lock) {                    try {                        lock.wait();                    } catch (InterruptedException e) {                        e.printStackTrace();                    }                }            }        }, "testLockThread");        thread.start();    }    public static void main(String[] args) throws Exception {        BufferedReader br = new BufferedReader(new InputStreamReader(System.in));        br.readLine();        createBusyThread();        br.readLine();        Object obj = new Object();        createLockThread(obj);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="主线程等待输入"><a class="header-anchor" href="#主线程等待输入">¶</a>主线程等待输入</h5><p>程序运行后,首先在“线程”页签中选择main线程。堆栈追踪显示BufferedReader的<code>readBytes()</code>方法正在等待<code>System.in</code>的键盘输入,这时候线程为Runnable状态,Runnable状态的线程仍会被分配运行时间,但<code>readBytes()</code>方法检查到流没有更新就会立刻归还执行令牌给操作系统,这种等待只消耗很小的处理器资源：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232552.png" alt="image-20200920160644113"></p><h5 id="死循环线程"><a class="header-anchor" href="#死循环线程">¶</a>死循环线程</h5><p>接着监控<code>testBusyThread</code>线程。<code>testBusyThread</code>线程一直在执行空循环,从堆栈追踪中看到一直在MonitoringTest.java代码的41行停留,19行的代码为while(true)。这时候线程为Runnable 状态,而且没有归还线程执行令牌的动作,所以会在空循环耗尽操作系统分配给它的执行时间,直到线程切换为止,这种等待会消耗大量的处理器资源。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232559.png" alt="image-20200920161217055"></p><h5 id="等待线程"><a class="header-anchor" href="#等待线程">¶</a>等待线程</h5><p><code>testLockThread</code>线程在等待lock对象的notify()或notifyAll()方法的出现,线程这时候处于WAITING状态,在重新唤醒前不会被分配执行时间。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232604.png" alt="image-20200920161417066"></p><h5 id="死锁检测"><a class="header-anchor" href="#死锁检测">¶</a>死锁检测</h5><p>下面是一段会产生死锁的代码</p><pre class="line-numbers language-language-java"><code class="language-language-java">package demo.jconsole;/** * @author: honphan.john * @date: 2020/9/20 16:16 * @description: */public class DeadLock {    /**     * 线程死锁等待演示     */    static class SynAddRunalbe implements Runnable {        int a, b;        public SynAddRunalbe(int a, int b) {            this.a = a;            this.b = b;        }        @Override        public void run() {            synchronized (Integer.valueOf(a)) {                synchronized (Integer.valueOf(b)) {                    System.out.println(a + b);                }            }        }    }    public static void main(String[] args) {        for (int i = 0; i < 100; i++) {            new Thread(new SynAddRunalbe(1, 2)).start();            new Thread(new SynAddRunalbe(2, 1)).start();        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用jconsole点击&quot;检测死锁&quot;即可显示死锁的线程，可以看到现在的线程是&quot;Blocked&quot;状态，和&quot;WAITING&quot;状态，它们是不同的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232610.png" alt="image-20200920161811620"></p><h4 id="Classes"><a class="header-anchor" href="#Classes">¶</a>Classes</h4><p>显示类装载信息</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232615.png" alt="image-20200920162217671"></p><h4 id="VM-Summary"><a class="header-anchor" href="#VM-Summary">¶</a>VM Summary</h4><p>显示java VM信息</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232623.png" alt="image-20200920162241281"></p><h4 id="MBeans-显示-MBeans"><a class="header-anchor" href="#MBeans-显示-MBeans">¶</a>MBeans: 显示 MBeans</h4><p>JMX监控指标。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232631.png" alt="image-20200920162439313"></p><h2 id="VisualVM-All-in-One-Java-Troubleshooting-Tool"><a class="header-anchor" href="#VisualVM-All-in-One-Java-Troubleshooting-Tool">¶</a>VisualVM(All-in-One Java Troubleshooting Tool)</h2><p>VisualVM是功能最强大的运行监视和故障处理程序之一, 曾经在很长一段时间内是Oracle官方主力发展的虚拟机故障处理工具。Oracle曾在VisualVM的软件说明中写上了“All-in-One”的字样,预示着它除了常规的运行监视、故障处理外,还将提供其他方面的能力,譬如性能分析(Profiling)。VisualVM的性能分析功能比起JProfiler、YourKit等专业且收费的Profiling工具都不遑多让。而且相比这些第三方工具,VisualVM还有一个很大的优点:不需要被监视的程序基于特殊Agent去运行,因此它的通用性很强,对应用程序实际性能的影响也较小,使得它可以直接应用在生产环境中。这个优点是JProfiler、YourKit等工具无法与之媲美的。</p><h3 id="插件"><a class="header-anchor" href="#插件">¶</a>插件</h3><p>VisualVM基于NetBeans平台开发工具,所以一开始它就具备了通过插件扩展功能的能力,有了插件扩展支持,VisualVM可以做到:</p><ul><li><strong>显示虚拟机进程以及进程的配置、环境信息</strong>(jps、jinfo)。</li><li><strong>监视应用程序的处理器、垃圾收集、堆、方法区以及线程的信息</strong>(jstat、jstack)。</li><li><strong>dump以及加载分析堆转储快照(jmap、jhat)</strong>。</li><li><strong>方法级的程序运行性能分析,找出被调用最多、运行时间最长的方法</strong>。</li><li><strong>离线程序快照:收集程序的运行时配置、线程dump、内存dump等信息建立一个快照,可以将快照发送开发者处进行Bug反馈</strong>。</li><li><strong>查看JFR文件(JMC)</strong></li><li>其他插件带来的无限可能性。</li></ul><p>VisualVM自带插件安装系统，位置在&quot;Tools-&gt;Plugin&quot;，但是最近发现它的插件中心好像无法访问了，可以在<a href="https://github.com/oracle/visualvm/releases" target="_blank" rel="noopener">这个地址</a>进行VisualVM以及它的插件的下载，然后手动安装，插件为&quot;.nbm&quot;文件，每个版本不一定携带插件，如果最新版本没有找到插件列表就一直往下一个版本找。</p><h3 id="其中一些功能说明"><a class="header-anchor" href="#其中一些功能说明">¶</a>其中一些功能说明</h3><h4 id="分析程序性能"><a class="header-anchor" href="#分析程序性能">¶</a>分析程序性能</h4><p>在Profiler页签中,VisualVM提供了程序运行期间方法级的处理器执行时间分析以及内存分析。<strong>做Profiling分析肯定会对程序运行性能有比较大的影响,所以一般不在生产环境使用这项功能,或者改用JMC来完成,JMC的Profiling能力更强,对应用的影响非常轻微</strong>。</p><p>要开始性能分析,先选择“CPU”和“内存”按钮中的一个,然后切换到应用程序中对程序进行操作,VisualVM会记录这段时间中应用程序执行过的所有方法。如果是进行处理器执行时间分析,将会统计每个方法的执行次数、执行耗时;如果是内存分析,则会统计每个方法关联的对象数以及这些对象所占的空间。等要分析的操作执行结束后,点击“停止”按钮结束监控过程。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232646.png" alt="image-20200920173128281"></p><h4 id="BTrace插件动态日志跟踪"><a class="header-anchor" href="#BTrace插件动态日志跟踪">¶</a>BTrace插件动态日志跟踪</h4><p>BTrace是一个很神奇的VisualVM插件,它本身也是一个可运行的独立程序。BTrace的作用是在不中断目标程序运行的前提下,通过HotSpot虚拟机的Instrument功能动态加入原本并不存在的调试代码。这项功能对实际生产中的程序很有意义:如当程序出现问题时,排查错误的一些必要信息时(譬如方法参数、返回值等),在开发时并没有打印到日志之中以至于不得不停掉服务时,都可以通过调试增量来加入日志代码以解决问题。可惜在尝试安装VisualVM插件的时候发现好像不支持了。</p><p>不过BTrace同时也是一个独立运行的软件，这是<a href="https://github.com/btraceio/btrace" target="_blank" rel="noopener">官方Github</a>。</p><p>BTrace能够实现动态修改程序行为,是因为它是基于Java虚拟机的Instrument开发的。Instrument是Java虚拟机工具接口(Java Virtual Machine Tool Interface,JVMTI)的重要组件,提供了一套代理(Agent)机制,使得第三方工具程序可以以代理的方式访问和修改Java虚拟机内部的数据。<strong>阿里巴巴开源的诊断工具Arthas也通过Instrument实现了与BTrace类似的功能</strong>。</p><h3 id="远程连接"><a class="header-anchor" href="#远程连接">¶</a>远程连接</h3><h4 id="配置JMX"><a class="header-anchor" href="#配置JMX">¶</a>配置JMX</h4><p>tomcat参数</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">CATALINA_OPTS="-xms800m -xmx800m -xmn350m -XX: Survivorratio=8 -XX: + HeapDumpOnOutOfMemoryError -Dcom.sun.management.jmxremote=true  -Djava.rmi.server.hostname=192.168.1.105 -Dcom.Sun.Management.jmxremote.port=6666 -Dcom.sun.management.jmxremote.ssl=false  -Dcom.Sun.Managementote.ssl=false -Dcom.Sun.management.jmxremote.authenticate=false"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="配置jstatd"><a class="header-anchor" href="#配置jstatd">¶</a>配置jstatd</h4><ol><li>自定义一个 <code>statd.policy</code> 文件，添加</li></ol><pre><code>grant codebase &quot;jrt:/jdk.jstatd&quot; {permission java.security.Allpermission;};grant codebase &quot;jrt:/jdk.Internal.jvmstat&quot; { permission java.security.Allpermission;}</code></pre><ol start="2"><li>然后在 <code>JDK_HOME/bin</code>下面运行<code>jstatd</code>，例如：</li></ol><pre class="line-numbers language-language-shell"><code class="language-language-shell">./jstatd -J-Djava.rmi.hostname=192.168.1.102 -J-Djava.security.policy="上面配置的policy文件路径" -p 1099 &<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="客户端VisualVM连接"><a class="header-anchor" href="#客户端VisualVM连接">¶</a>客户端VisualVM连接</h4><p>然后在VisualVM分别连接即可</p><h2 id="JMC-Java-Mission-Control"><a class="header-anchor" href="#JMC-Java-Mission-Control">¶</a>JMC(Java Mission Control)</h2><p>除了大家熟知的面向通用计算(General Purpose Computing)可免费使用的Java SE外,Oracle公司还开辟过带商业技术支持的Oracle Java SE Support和面向独立软件供应商(ISV)的Oracle Java SE Advanced &amp; Suite产品线。</p><p>除去带有7×24小时的技术支持以及可以为企业专门定制安装包这些非技术类的增强服务外, Oracle Java SE Advanced &amp; Suite与普通Oracle Java SE在功能上的主要差别是前者包含了一系列的监控、管理工具,譬如用于企业JRE定制管理的AMC(Java Advanced Management Console)控制台、JUT(Java Usage Tracker)跟踪系统,用于持续收集数据的JFR(Java Flight Recorder)飞行记录仪和用于监控Java虚拟机的JMC(Java Mission Control)。这些功能全部都是需要商业授权才能在生产环境中使用,但根据Oracle Binary Code协议,在个人开发环境中,允许免费使用JMC和JFR,本节笔者将简要介绍它们的原理和使用。</p><h3 id="JFR-Java-Flight-Recorder"><a class="header-anchor" href="#JFR-Java-Flight-Recorder">¶</a>JFR(Java Flight Recorder)</h3><p>JFR是一套内建在HotSpot虚拟机里面的监控和基于事件的信息搜集框架,与其他的监控工具(如JProfiling)相比,Oracle特别强调它“可持续在线”(Always-On)的特性。JFR在生产环境中对吞吐量的影响一般不会高于1%(甚至号称是Zero Performance Overhead),而且JFR监控过程的开始、停止都是完全可动态的,即不需要重启应用。JFR的监控对应用也是完全透明的,即不需要对应用程序的源码做任何修改,或者基于特定的代理来运行。</p><p>JMC最初是BEA公司的产品,因此并没有像VisualVM那样一开始就基于自家的Net-Beans平台来开发,而是选择了由IBM捐赠的Eclipse RCP作为基础框架,现在的JMC不仅可以下载到<a href="https://www.oracle.com/java/technologies/javase/products-jmc7-downloads.html" target="_blank" rel="noopener">独立程序</a>,更常见的是作为Eclipse的插件来使用。JMC与虚拟机之间同样采取JMX协议进行通信,JMC一方面作为JMX控制台,显示来自虚拟机MBean提供的数据;另一方面作为JFR的分析工具,展示来自JFR的数据。</p><h3 id="启动JMC并连接JVM"><a class="header-anchor" href="#启动JMC并连接JVM">¶</a>启动JMC并连接JVM</h3><ul><li><p>本地JVM</p><p>打开JMC后在左侧的“JVM浏览器”面板中自动显示了通过JDP协议(Java Discovery Protocol)找到的本机正在运行的HotSpot虚拟机进程<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232656.png" alt="image-20200920180627703"></p></li><li><p>远程JVM</p><ul><li><p>如果需要监控其他远程服务器上的虚拟机,可在“文件-&gt;连接”菜单中创建远程连接。然后根据引导输入远程连接信息，通常包括host、port、authenticatin等信息。</p></li><li><p>另外需要远程服务器的JVM启动时增加参数：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">-Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=192.168.31.4 -XX:+UnlockCommercialFeatures -XX:+FlightRecorder<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li></ul><h3 id="使用飞行记录仪"><a class="header-anchor" href="#使用飞行记录仪">¶</a>使用飞行记录仪</h3><p>双击“飞行记录器”,将会出现“启动飞行记录”窗口。</p><p>在启动飞行记录时,可以进行记录时间、垃圾收集器、编译器、方法采样、线程记录、异常记录、网络和文件I/O、事件记录等选项和频率设定。点击“完成”按钮后马上就会开始记录,记录时间结束以后会生成飞行记录报告：</p><p>飞行记录报告里包含以下几类信息:</p><ul><li>一般信息:关于虚拟机、操作系统和记录的一般信息。</li><li>内存:关于内存管理和垃圾收集的信息。</li><li>代码:关于方法、异常错误、编译和类加载的信息。</li><li>线程:关于应用程序中线程和锁的信息。</li><li>I/O:关于文件和套接字输入、输出的信息。</li><li>系统:关于正在运行Java虚拟机的系统、进程和环境变量的信息。</li><li>事件:关于记录中的事件类型的信息,可以根据线程或堆栈跟踪,按照日志或图形的格式查看。</li></ul><p>JFR的基本工作逻辑是开启一系列事件的录制动作,当某个事件发生时,这个事件的所有上下文数据将会以循环日志的形式被保存至内存或者指定的某个文件当中,循环日志相当于数据流被保留在一个环形缓存中,所以只有最近发生的事件的数据才是可用的。JMC从虚拟机内存或者文件中读取并展示这些事件数据,并通过这些数据进行性能分析。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232705.png" alt="image-20200920181646036"></p><p>即使不考虑对被测试程序性能影响方面的优势,JFR提供的数据质量通常也要比其他工具通过代理形式采样获得或者从MBean中取得的数据高得多。以垃圾搜集为例,HotSpot的MBean中一般有各个分代大小、收集次数、时间、占用率等数据(根据收集器不同有所差别),这些都属于“结果”类的信息,而JFR中还可以看到内存中这段时间分配了哪些对象、哪些在TLAB中(或外部)分配、分配速率和压力大小如何、分配归属的线程、收集时对象分代晋升的情况等,这些就是属于“过程”类的信息, 对排查问题的价值是难以估量的。</p><h3 id="使用命令行启动飞行记录仪"><a class="header-anchor" href="#使用命令行启动飞行记录仪">¶</a>使用命令行启动飞行记录仪</h3><p>解锁JDK的商业特性：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">jcmd 1152 VM.unlock_commercial_features<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>使用命令行启动JFR</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">jcmd 41250 JFR.start delay=10s duration=1m filename=/Users/cc/Desktop/log.jfr<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>保存下来的JFR文件除了JMC可以打开，VisualVm也可以打开。</p><h1>HotSpot虚拟机插件及工具</h1><p>一些HotSpot研发过程中编写的插件和工具，这些工具大多数都在JDK源码(存放在HotSpot源码<code>hotspot/src/share/tools</code>目录下)中包含：</p><ul><li>Ideal Graph Visualizer:用于可视化展示C2即时编译器是如何将字节码转化为理想图,然后转化为机器码的。</li><li>Client Compiler Visualizer:用于查看C1即时编译器生成高级中间表示(HIR),转换成低级中间表示(LIR)和做物理寄存器分配的过程(源码其实从未进入过HotSpot的代码仓库)。</li><li>MakeDeps:帮助处理HotSpot的编译依赖的工具。</li><li>Project Creator:帮忙生成Visual Studio的.project文件的工具。</li><li>LogCompilation:将<code>-XX:+LogCompilation</code>输出的日志整理成更容易阅读的格式的工具。</li><li>HSDIS:即时编译器的反汇编插件(OpenJDK源码中的位置：hotspot/src/share/tools/hsdis/)。</li></ul><h2 id="HSDIS"><a class="header-anchor" href="#HSDIS">¶</a>HSDIS</h2><p>HSDIS是一个被官方推荐的HotSpot虚拟机即时编译代码的反汇编插件,它包含在HotSpot虚拟机的源码当中[2],在OpenJDK的网站[3]也可以找到单独的源码下载,但并没有提供编译后的程序。</p><p>HSDIS插件的作用是让HotSpot的<code>-XX:+PrintAssembly</code>指令调用它来把即时编译器动态生成的本地代码还原为汇编代码输出,同时还会自动产生大量非常有价值的注释,这样我们就可以通过输出的汇编代码来从最本质的角度分析问题。</p><ul><li>可以根据自己的操作系统和处理器型号,从网上直接搜索（<a href="http://hllvm.group.iteye.com" target="_blank" rel="noopener">HLLVM圈子有编译好的</a>）、下载编译好的插件,直接放到<code>JDK_HOME/jre/bin/server</code>目录(JDK 9以下)或<code>JDK_HOME/lib/amd64/server</code>(JDK 9或以上)中即可使用。</li><li>或者自己用源码编译一遍(网上能找到各种操作系统下的编译教程)。</li></ul><p>另外还有一点需要注意,如果读者使用的是SlowDebug或者FastDebug版的HotSpot,那可以直接通过<code>-XX:+PrintAssembly</code>指令使用的插件;如果读者使用的是Product版的HotSpot,则还要额外加入一个<code>-XX:+UnlockDiagnosticVMOptions</code>参数才可以工作。</p><h3 id="例子"><a class="header-anchor" href="#例子">¶</a>例子</h3><pre class="line-numbers language-language-java"><code class="language-language-java">package john;/** * 参数： * -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly //打印编译器的汇编 * -Xcomp  //使用编译器模式 * -XX:+TraceClassLoading -XX:+LogCompilation  * -XX:LogFile=./logfile.log    //将日志输出到一个文件  * -XX:CompileCommand=dontinline,*Bar.sum -XX:CompileCommand=compileonly,*Bar.sum   //不进行方法内联 *  * @author: honphan.john * @date: 2020/9/19 08:34 * @description: */public class Bar {    int a = 1;    static int b = 2;    public int sum(int c) {        return a + b + c;    }    public static void main(String[] args) {        new Bar().sum(3);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这个例子中测试代码比较简单,肉眼直接看日志中的汇编输出是可行的,但在正式环境中<code>-XX:+PrintAssembly</code>的日志输出量巨大,且难以和代码对应起来,这就必须使用工具来辅助了。</p><h3 id="JITWatch"><a class="header-anchor" href="#JITWatch">¶</a><a href="https://github.com/AdoptOpenJDK/jitwatch" target="_blank" rel="noopener">JITWatch</a></h3><p>JITWatch是HSDIS经常搭配使用的可视化的编译日志分析工具,为便于在JITWatch中读取。下载JITWatch后即可导入输出的汇编日志，即可进行Java源码、字节码、汇编的对比查看。</p><h1></h1><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>需要远程主机提供RMI支持,JDK中提供了jstatd工具可以很方便地建立远程RMI服务器 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10_StringTable</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/10-stringtable/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/10-stringtable/</url>
      
        <content type="html"><![CDATA[<h1>String的基本特性</h1><ul><li><p>String:字符串,使用一对<code>&quot;&quot;</code>引起来表示。<br>String sl1=“atguigu”;//字面量的定义方式<br>String s2= new String(“hello”);</p></li><li><p>String 被final声明,不可被继承</p></li><li><p>String实现了 Serializable接口:表示字符串是支持序列化的</p></li><li><p>实现了 Comparable接口:表示 String可以比较大小</p></li><li><p>String final在jdk8及以前内部定义了<code>char[] value</code>用于存储字符串数据。jdk9时改为<code>byte[]</code></p><p>变更原因：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235142.png" alt="image-20200917150221054"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235153.png" alt="image-20200917150355524"></p></li><li><p>String:代表不可变的字符序列。简称:不可变性。</p></li></ul><h2 id="字符串的不可变性"><a class="header-anchor" href="#字符串的不可变性">¶</a>字符串的不可变性</h2><ul><li><p>通过字面量的方式(区别于new)给一个字符串赋值,此时的字符串值声明在字符串常量池中，之后再使用<code>intern()</code>方法或者字面量赋值相同的字符串，会直接返回当前字符串分配到的地址引用。</p></li><li><p>当对已经赋值字符串引用的字符串变量重新赋值时,会新开辟一块空间存储新的字符串,然后将新的引用赋值到该字符串变量</p><pre class="line-numbers language-language-java"><code class="language-language-java">String s1 = "abc";String s2 = "abc";System.out.println(s1==s2);//true。定义s1的时候"abc"字面量进入了常量池，定义s2的时候检查到常量池已存在该常量，直接获取其引用s1 = "hello";System.out.println(s1==s2);//false，"hello"字面量会在常量池另外开辟内存进行存储并重新赋值新引用到使s2，不会覆盖"abc"的空间System.out.println(s1);//abc，没有被覆盖System.out.println(s2);//hello，新内存地址引用<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>当对现有的字符串进行连接操作时,也需要重新分配内存进行存储连接后的新值,不能对变量已指向的常量池内存空间进行覆盖。</p><pre class="line-numbers language-language-java"><code class="language-language-java">String s1 = "abc";String s2 = "abc";s1 += "def";System.out.println(s1==s2);//false，还是会在常量池新开辟一块内存空间存储拼接后的"abcdef"System.out.println(s1);//abc，没有被覆盖System.out.println(s2);//abcdef，新内存地址引用<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>当调用String的<code>replace()</code>方法修改指定字符或字符串时,也需要重新分配内存进行存储连接后的新值,不能对变量已指向的常量池内存空间进行覆盖。</p><pre class="line-numbers language-language-java"><code class="language-language-java">String s1 = "abc";String s2 = s1.replace('a', 'm');System.out.println(s1==s2);//false，还是会在常量池新开辟一块内存空间存储替换后得到的"mbc"System.out.println(s1);//abc，没有被覆盖System.out.println(s2);//mbc，新内存地址引用<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h2 id="StringTable"><a class="header-anchor" href="#StringTable">¶</a>StringTable</h2><p>字符串常量池中是不会存储相同内容的字符串的。</p><ul><li>String的 String Pool是一个固定大小的HashTable,默认值大小长度是1009。如果放进 String Pool的string非常多,就可能造成较多的Hash冲突,从而导致链表会很长,而链表长了后直接会造成的影响就是当调用<code>String.intern()</code>时性能会大幅下降。</li><li>使用<code>-XX: StringTableSize</code>可设置StringTable的长度</li><li>在jdk6中StringTable是固定的,就是1009的长度,所以如果常量池中的字符串过多就会导致效率下降很快。StringTablesize设置没有要求</li><li>在jdk7中, StringTable的长度默认值是60013,1009是可设置的最小值。</li></ul><p>使用<code>-XX:+PrintStringTableStatistics</code>可以在退出的时候打印StringTable的信息</p><h1>String的内存分配</h1><p>在Java语言中有8种基本数据类型和一种比较特殊的类型String。这些类型为了使它们在运行过程中速度更快、更节省内存,都提供了一种常量池的概念。常量池就类似一个Java系统级别提供的缓存。8种基本数据类型的常量池都是系统协调的, String类型的常量池比较特殊。它的主要使用方法有两种。</p><ul><li>直接使用双引号声明出来的 String对象会直接存储在常量池中。<ul><li>比如: String info=“<a href="http://atguigu.com" target="_blank" rel="noopener">atguigu.com</a>”;</li></ul></li><li>如果不是用双引号声明的String对象可以使用 String提供的 <code>intern()</code>方法。</li></ul><h3 id="字符串常量池位置变化"><a class="header-anchor" href="#字符串常量池位置变化">¶</a>字符串常量池位置变化</h3><ol><li>Java6及以前字符串常量池存放在永久代。</li><li>Java7中 oracle的工程师对字符串池的逻辑做了很大的改变,即将字符串常量池的位置调整到Java堆内。<ul><li>所有的字符串都保存在堆(Heap)中,和其他普通对象一样,这样可以让你在进行调优应用时仅需要调整堆大小就可以了。</li><li>字符串常量池概念原本使用得比较多,但是这个改动使得我们有足够的理由让我们重新考虑在Java7中使用 <code>String.intern()</code>。</li></ul></li><li>Java8元空间,字符串常量在堆。</li></ol><h4 id="为什么要变化？"><a class="header-anchor" href="#为什么要变化？">¶</a>为什么要变化？</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235202.png" alt="image-20200917154123382"></p><h1>String例子说明</h1><ol><li><p>运行下面代码，通过IDEA下方的memory窗口可以查看当前JVM内存对象情况，其中String对象在运行到第一个&quot;10&quot;之后String对象变为2331个，在之后就一直不变了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235210.png" alt="image-20200917154527425"></p></li><li><p>以下方法运行过程的引用分析</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235218.png" alt="image-20200917155005412"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235230.png" alt="image-20200917155021370"></p><p>A string is created in line7. it goes in the String pool in the heap space and a reference is created in the foo() stack space for it.</p></li></ol><h1>字符串拼接操作</h1><p>前面提到被作用右值引用的字符串字面量都会进入到字符串常量值中，下面介绍当出现字符串拼接（使用&quot;+&quot;或者通过StringBuilder等工具类进行拼接得到的结果）的时候拼接得到的结果会不会出现在常量池中：</p><ol><li><p>字符串拼接结果直接进入常量池的情况：</p><ul><li><p>常量与常量的拼接结果在常量池, 原理是编译期优化（即编译期会完成字符串常量池初始化，将所有在编译期识别的字符串值在字符串常量池进行创建），这里的常量就是指<strong>字符串字面量（右值）以及使用final修饰的字符串变量（左值）</strong>。</p><pre class="line-numbers language-language-java"><code class="language-language-java">String s1 = "a" + "b" + "c"; //前端编译直接合成"abc"String s2 = "abc";System.out.println(s1 == s2); //true<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>常量池中不会存在相同内容的常量。</p></li></ul></li><li><p>字符串拼接结果不进入常量池的情况：</p><ul><li><p>只要参与拼接的字符串中有一个是变量（即非上面描述的常量范围，这样的符号/symbol在编译期无法确定其值）,  字符串拼接将在运行时进行，此时拼接结果将会产生一个<code>String</code>对象放在堆中（不进入常量池）。变量拼接的原理是 StringBuilder</p><pre class="line-numbers language-language-java"><code class="language-language-java"> string s1 ="javaEE"; string s2 ="hadoop"; string s3 ="javaEEhadoop"; string s4 ="javaEE"+ "hadoop"; string s5=s1+"hadoop"; string s6="javaEE"+s2; string s7=s1+s2; System.out.printIn(s3 ==s4);//true System.out.printIn(s3 ==s5);//false System.out.printIn(s3 = s6);//false System.out.printIn(s3 =s7);//false System.out.printIn(s5 ==s6);//false System.out.printIn(s5 ==s7);//false System.out.printIn(s6==s7);//false string s8=s6.intern(); System.out.println(s3 ==s8);//true<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>如果拼接的结果调用<code>intern()</code>方法,则主动将常量池中还没有的字符串对象放入池中,并返回此对象地址；如果已经存在，则返回已存在字符串地址。</p></li></ul></li></ol><h2 id="字符串拼接-解析"><a class="header-anchor" href="#字符串拼接-解析">¶</a>字符串拼接&quot;+&quot;解析</h2><p>可以看到下面的字节码解析中字符串的拼接通过<code>StringBuilder</code>来实现的，在没有<code>StringBuilder</code>(5.0)之前都是使用<code>StringBuffer</code>。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235240.png" alt="image-20200917161645127"></p><p><code>StringBuilder#toString()</code>方法的底层如下：</p><pre class="line-numbers language-language-java"><code class="language-language-java">    @Override    public String toString() {        // Create a copy, don't share the array        return new String(value, 0, count);    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到是直接<code>new</code>了一个String对象，注意这种方式与<code>new String(&quot;我是字符串&quot;)</code>是有区别的，前者对字符串常量池没有任何影响；后者会将&quot;我是字符串&quot;字面量放入常量池，然后返回分配到的内存地址赋值到变量(左值)中。即前者会在堆产生一个<code>String</code>对象，后者会在字符串常量池建立一个字符串常量。</p><h2 id="使用-和StringBuilder-append-拼接的效率"><a class="header-anchor" href="#使用-和StringBuilder-append-拼接的效率">¶</a>使用&quot;+&quot;和<code>StringBuilder#append()</code>拼接的效率</h2><p>由上面可以得知每一个&quot;+“都会编译为创建一个<code>StringBuilder</code>和<code>toString</code>new一个<code>String</code>对象，所以如果在一个循环次数很高的代码中使用”+&quot;就会涉及常见对象的消耗以及内存占用(以及带来GC)的消耗。所以相较于我们手动使用<code>StringBuilder#append</code>来说，效率会差别非常大。</p><p>另外如果我们使用<code>StringBuilder</code>的时候，如果可以提前可以预知字符串长度则可以调用有参构造传入<code>capacity</code>创建指定长度的<code>Builder</code>，防止多次扩容。</p><h2 id="final"><a class="header-anchor" href="#final">¶</a>final</h2><p>final可以修饰一个左值为一个常量：</p><pre class="line-numbers language-language-java"><code class="language-language-java">    public void test1() {        String s1 = "javaEEhadoop";        String s2 = "javaEE";        String s3 = s2 + "hoodp";        System.out.println(s1 == s3); //false        final String s4 = "javaEE"; //s4常量        String s5 = s4 + "hadoop";        System.out.println(s1 == s5);//true    }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1>intern()的使用</h1><p><code>intern()</code>方法主动将常量池中还没有的字符串对象放入池中,并返回此对象地址；如果已经存在，则返回已存在字符串地址。。</p><p>如果不是用双引号声明的 string对象,可以使用 string提供的intern方法: intern方法会从字符串常量池中查询当前字符串是否存在,若不存在就会将当前字符串放入常量池中。</p><ul><li>比如: <code>String myInfo= new String(aStringVariable).intern()</code>;</li></ul><p>当且仅当两个字符串变量<code>equals</code>的时候它们调用<code>intern()</code>方法得到的结果是<code>=</code>的。因此,下列表达式的值必定是true:</p><pre class="line-numbers language-language-java"><code class="language-language-java">("a"+"b"+"c").intern() == "abc"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通俗点讲, Interned String就是确保字符串在内存里只有一份拷贝,这样可以节约内存空间,加快字符串操作任务的执行速度。注意,这个值会被存放在字符串内部池(String Intern Pool)。</p><h2 id="JDK6和JDK7变化例子"><a class="header-anchor" href="#JDK6和JDK7变化例子">¶</a>JDK6和JDK7变化例子</h2><h3 id="例1："><a class="header-anchor" href="#例1：">¶</a>例1：</h3><p>求以下输出：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235247.png" alt="image-20200917164159401"></p><h4 id="intern-方法变化说明"><a class="header-anchor" href="#intern-方法变化说明">¶</a><code>intern()</code>方法变化说明</h4><ul><li><p>JDK6及之前，<code>intern()</code>方法会在常量池中寻找该字符串常量是否存在，如果存在，则方法返回常量池中该地址；如果不存在，则在常量池中为该常量开辟空间存储后返回该新地址。</p><ul><li>第一个输出：false<ol><li>第一行&quot;1&quot;是一个字面量，编译期初始化进入字符串常量池，然后<code>new String(&quot;1&quot;)</code>会在堆中创建一个String对象，本地变量<code>s</code>存储的是该String对象的引用，而该String对象中保存了&quot;1&quot;字符串常量的引用</li><li><code>s.intern()</code>相当于没做任何事情，因为没有将返回结果进行赋值</li><li><code>String s2 = &quot;1&quot;</code>将&quot;1&quot;在字符串常量池地址返回该s2.</li><li>很自然s != s2.</li></ol></li><li>第二个输出：false<ol><li><code>String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;)</code>会在堆中创建两个String对象，分别保存了&quot;1&quot;的引用</li><li>此时<code>intern()</code>方法就有作用了，它会将<code>s3</code>指向的新拼接好的第三个保存在堆中的String对象中保存的字符串保存到字符串常量池。因为代码中没有任何地方定义了字面量&quot;11&quot;或者由常量拼接成的&quot;11&quot;，所以在调用<code>intern()</code>方法之前，它都是以String对象的一个字节成员字段保存在堆中的。但是即使是这样，依然没有将返回值覆盖到<code>s3</code></li><li>此时<code>String s4 = &quot;11&quot;</code>就会从常量池加载得到&quot;11&quot;，返回该引用到<code>s4</code></li><li>所以很自然，<code>s3</code>是一个堆中地址，<code>s4</code>是常量池地址，s3 != s4</li></ol></li></ul></li><li><p>JDK7及之后，<code>intern()</code>方法的语义发生了变化，它会在常量池中寻找该字符串常量是否存在，如果存在，则方法返回常量池中该地址；如果不存在，将不会在常量池中开辟新空间，而是直接将当前字符串地址插入到常量池表中。</p><p>即JDK6其实发生了字符串复制，而JDK7没有，因为在JDK7及之后，字符串常量池被移到了堆中(老年代)，在JDK6之前是在永久代的，所以在JDK7可以这样做。所以以下输出也产生了变化</p><ul><li>第一个输出：false<ol><li>这里其实没有变化，&quot;1&quot;已经存在常量池</li><li>结果一样</li></ol></li><li>第二个输出：true<ol><li>这里的变化就大了，在<code>s3.intern()</code>会将s3的引用直接更新到常量池表中</li><li>此时<code>String s4 = &quot;11&quot;;</code>将会得到<code>s3</code>的引用，故s3==s4</li></ol></li></ul></li></ul><blockquote><p>另外学到的是，我们可以从字节码角度对一些代码进行分析，以下是JDK8的字节码分析：<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235254.png" alt="image-20200917165013913"><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235307.png" alt="image-20200917165217870"></p></blockquote><h3 id="例2："><a class="header-anchor" href="#例2：">¶</a>例2：</h3><pre class="line-numbers language-language-java"><code class="language-language-java"># JDK7及之后String s3 = new String("1") + new String("1");String s4 = "11"; //常量"11"已经存在，所以"11" == s4 != s3String s5 = s3.intern(); //"11" == s5 System.out.println(s3 == s4);//falseSystem.out.println(s4 == s5);//true# JDK6及之前String s = new String("b") + new String("b");String s2 = s.intern();//发生了字符串复制，s2 == "ab" != sSystem.out.println(s2 == "ab");//trueSystem.out.println(s == "ab");//false# 无论是任何版本String ss = new String("ab"); //"ab"编译期存在常量池，先从常量池加载该常量引用并利用它在池外创建一个String对象ss.intern();String ss2 = "ab";System.out.println(ss == ss2);//false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="intern-的用处"><a class="header-anchor" href="#intern-的用处">¶</a>intern()的用处</h2><p>如果在需要动态生成大量字符串（非字面量）的情况下，推荐使用<code>intern()</code>方法可以大大降低堆的空间使用（复用常量池内存）。</p><h1>StringTable的垃圾回收</h1><p>和堆无区别，本身就在堆中，由垃圾收集器决定如何回收。</p><h1>G1中的String去重操作</h1><p>背景:对许多Java应用(有大的也有小的)做的测试得出以下结果:</p><ul><li>堆存活数据集合里面string对象占了25%</li><li>堆存活数据集合里面重复的string对象有13.5%</li><li>String对象的平均长度是45</li></ul><p>许多大规模的Java应用的瓶颈在于内存,测试表明,在这些类型的应用里面,Java堆中存活的数据集合差不多25%是String对象。更进一步,<br>这里面差不多一半 String对象是重复的,重复的意思是说:<br><code>stringl.equals(string2)=true</code><br>堆上存在重复的 String对象必然是一种内存的浪费。这个项目将在G1垃圾收集器中实现自动持续对重复的 String对象进行去重,这样就能避免浪费内存。</p><h2 id="实现"><a class="header-anchor" href="#实现">¶</a>实现</h2><ol><li>当垃圾收集器工作的时候,会访问堆上存活的对象。对每一个访问的对象都会检查是否是候选的要去重的 String对象。</li><li>如果是,把这个对象的一个引用插入到队列中等待后续的处理。一个去重的线程在后台运行,处理这个队列。处理队列的一个元素意味着从队列删除这个元素,然后尝试去重它引用的String对象。</li><li>使用一个hashtable来记录所有的被string对象使用的不重复的char数组。当去重的时候,会查这个hashtable,来看堆上是否已经存在一个一模一样的char数组。</li><li>如果存在, String对象会被调整引用那个数组,释放对原来的数组的引用,最终会被垃圾收集器回收掉。</li><li>如果查找失败,char数组会被 hasht插入到,这样以后的时候就可以共享这个数组了。</li></ol><h2 id="配置使用"><a class="header-anchor" href="#配置使用">¶</a>配置使用</h2><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 开启G1 string去重,默认是不开启的,需要手动开启。-XX:+/-UseStringDeduplication# 打印详细的去重统计信息-XX:+/-PrintStringDeduplicationStatistics# 达到这个年龄的 string对象被认为是去重的候选对象-XX:StringDeduplicationAgeThreshold=<N><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>15_垃圾回收器</title>
      <link href="/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/15-la-ji-hui-shou-qi/"/>
      <url>/2020/12/22/jvm/shen-ru-li-jie-java-xu-ni-ji-bi-ji/15-la-ji-hui-shou-qi/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1>GC分类</h1><p>垃圾收集器没有在规范中进行过多的规定,可以由不同的厂商、不同版本的JVM来实现。由于JDK的版本处于高速迭代过程中,因此Java发展至今已经衍生了众多的GC版本。</p><p>从不同角度分析垃圾收集器,可以将GC分为不同的类型。</p><h2 id="垃圾回收器分类"><a class="header-anchor" href="#垃圾回收器分类">¶</a>垃圾回收器分类</h2><h3 id="按垃圾回收器的线程数分"><a class="header-anchor" href="#按垃圾回收器的线程数分">¶</a>按垃圾回收器的线程数分</h3><p>可以分为串行垃圾回收器(单线程处理)和并行垃圾回收器(多线程处理)</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235908.png" alt="image-20200918100326513"></p><ul><li><p>串行回收指的是在同一时间段内只有一个CPU用于执行垃圾回收操作,此时工作线程被暂停,直至垃圾收集工作结束。</p><ul><li>在诸如单CPU处理器或者较小的应用内存等硬件平台不是特别优越的场合,串行回收器的性能表现可以超过并行回收器和并发回收器。所以,串行回收默认被应用在客户端的 client模式下的JVM中</li><li>在并发能力比较强的CPU上,并行回收器产生的停顿时间要短于串行回收器。</li></ul></li><li><p>和串行回收相反,并行收集可以运用多个CPU同时执行垃圾回收,因此提升了应用的吞吐量。</p></li></ul><blockquote><p>不过这里仅仅是根据回收器的工作线程是并行还是串行的维度来进行分类, 并没有针对是否采用独占式,使用了“stop-the-world”机制维度进行分类。</p></blockquote><h3 id="按照工作模式分"><a class="header-anchor" href="#按照工作模式分">¶</a>按照工作模式分</h3><p>可以分为并发式(与应用线程)垃圾回收器和独占式垃圾回收器。并发式垃圾回收器与应用程序线程交替工作,以尽可能减少应用程序的停顿时间。独占式垃圾回收器(Stop The World)一旦运行,就停止应用程序中的所有用户线程,直到垃圾回收过程完全结束。<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235914.png" alt="image-20200918100948865"></p><h3 id="按碎片处理方式分"><a class="header-anchor" href="#按碎片处理方式分">¶</a>按碎片处理方式分</h3><p>可分为压缩式垃圾回收器和非压缩式垃圾回收器。</p><ul><li>压缩式垃圾回收器会在回收完成后,对存活对象进行压缩整理,消除回收后的碎片。</li><li>非压缩式的垃圾回收器不进行这步操作。</li></ul><h3 id="按工作的内存区间分"><a class="header-anchor" href="#按工作的内存区间分">¶</a>按工作的内存区间分</h3><p>又可分为年轻代垃圾回收器和老年代垃圾回收器。</p><h1>GC性能指标</h1><ul><li>暂停时间:执行垃圾收集时,程序的工作线程被暂停的时间。</li><li>吞吐量:运行用户代码的时间占总运行时间的比例<ul><li>(总运行时间:程序的运行时间+内存回收的时间)</li></ul></li><li>内存占用:垃圾回收工作内存占Java堆区的内存大小。</li><li>垃圾收集开销:<u><em>吞吐量</em></u>的补数,垃圾收集所用时间与总运行时间的比例。</li><li>收集频率:相对于应用程序的执行收集操作发生的频率。</li><li>快速:一个对象从诞生到被回收所经历的时间。</li></ul><p><strong>暂停时间</strong>、<strong>吞吐量</strong>和<strong>内存占用</strong>这三者共同构成一个“不可能三角”。三者总体的表现会随着技术进步而越来越好。一款优秀的收集器通常最多同时满足其中的两项。这三项里,暂停时间的重要性日益凸显。因为随着硬件发展,内存占用多些越来越能容忍,硬件性能的提升也有助于降低收集器运行时对应用程序的影响,即提高了吞吐量。而内的扩大,对延迟反而带来负面效果。<br>简单来说,主要抓住两点:</p><ul><li>吞吐量</li><li>暂停时间</li></ul><h2 id="吞吐量-throughPUT"><a class="header-anchor" href="#吞吐量-throughPUT">¶</a>吞吐量(throughPUT)</h2><p>吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值,即：</p><pre><code>吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)。(例如：虚拟机总共运行了100分钟,其中垃圾收集花掉1分钟,那吞吐量就是99%)</code></pre><p>高吞吐量的应用程序有更长的时间基准(即不以单次的响应时长为基准，而是以某单位内总响应时长为基准)，快速响应是不必考虑的，应用程序能容忍较高的暂停时间。</p><p>吞吐量优先,<strong>意味着在单位(基准)时间内,STW的时间之和</strong>最短:0.2+0.2=0.4<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235921.png" alt="image-20200918102140066"></p><h2 id="暂停时间-pause-time"><a class="header-anchor" href="#暂停时间-pause-time">¶</a>暂停时间(pause time)</h2><p>“暂停时间”是指用户线程被全部暂停以让垃圾回收工作线程执行的期间。例如,GC期间100毫秒的暂停时间意味着在这100毫秒期间内没有应用程序线程是活动的。</p><p>暂停时间优先,意味着尽可能让单次STW的时间最短:0.1+0.1+0.1+0.1+0.1=0.5<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221235926.png" alt="image-20200918102825249"></p><h2 id="对比"><a class="header-anchor" href="#对比">¶</a>对比</h2><ul><li><p>高吞吐量较好因为这会让应用程序的最终用户感觉只有应用程序线程在做“生产性”工作。直觉上,吞吐量越高程序运行越快。</p></li><li><p>低暂停时间(低延迟)较好因为从最终用户的角度来看不管是GC还是其他原因导致一个应用被挂起始终是不好的。这取决于应用程序的类型,有时候甚至短暂的200毫秒暂停都可能打断终端用户体验。因此,具有低的较大暂停时间是非常重要的,特别是对于一个交互式应用程序。</p></li></ul><p>不幸的是”高吞吐量”和”低暂停时间”是一对相互竞争的目标(矛盾)。</p><ul><li>因为如果选择以吞吐量优先,那么必然需要降低内存回收的执行频率,但是这样会导致GC需要更长的暂停时间来执行内存回收。</li><li>相反的,如果选择以低延迟优先为原则,那么为了降低每次执行内存回收时的暂停时间,也只能频繁地执行内存回收,但这又引起了年轻代内存的缩减和导致程序吞吐量的下降。</li></ul><p>在设计(或使用)GC算法时,我们必须确定我们的目标:一个GC算法只可能针对两个目标之一(即只专注于较大吞吐量或最小暂停时间),或<br>尝试找到一个二者的折衷。</p><p>现在标准: <strong>在最大吞吐量优先的情况下,降低停顿时间</strong>。</p><h1>不同的垃圾回收器概述</h1><p>有了虚拟机,就一定需要收集垃圾的机制这就是Garbage Collection,对应的产品我们称为 Garbage Collector。</p><ul><li>1999年随JDK1.3.1一起来的是串行方式的Serial GC,它是第一款 ParNew垃圾收集器是 Serial收集器的多线程版本</li><li>2002年2月26日, ParalleGC和 Concurrent Mark Sweep GC跟随JDK1.4.2一起发布</li><li><strong>Parallel GC在JDK6之后成为HotSpot默认GC</strong></li><li>2012年,在JDK1.7u4版本中,G1可用。</li><li>2017年,<strong>JDK9中G1变成默认的垃圾收集器</strong>,以替代CMS。</li><li>2018年3月,JDK10中G1垃圾回收器的并行完整垃圾回收,实现并行性来改善最坏情况下的延迟。</li><li>2018年9月,JDK11发布。引入 Epsilon垃圾回收器,又被称为&quot;No-op(无操作)&quot;回收器。同时,引入ZGC:可伸缩的低延迟垃圾回收器(Experimental)</li><li>2019年3月,JDK12发布增强G1,自动返回未用堆内存给操作系统。同时,引入Shenandoah GC:低停顿时间的GC(Experimental)</li><li>2019年9月,JDK13发布。增强ZGC,自动返回未用堆内存给操作系统。</li><li>2020年3月,JDK14发布。删除CMS垃圾回收器。扩展ZGC在 macos和Windows上的应用</li></ul><h3 id="7款经典的垃圾回收器的工作线程数"><a class="header-anchor" href="#7款经典的垃圾回收器的工作线程数">¶</a>7款经典的垃圾回收器的工作线程数</h3><ul><li>串行回收器：Serial、Serial Old<ul><li>STW+只有一个垃圾回收线程工作</li></ul></li><li>并行回收器：ParNew、Parallel Scavenge、Parallel Old<ul><li>STW+垃圾回收工作线程并行工作</li></ul></li><li>并发回收器：CMS、G1<ul><li>与用户线程并行执行</li></ul></li></ul><blockquote><p><a href="https://www.oracle.com/technetwork/java/javase/tech/memorymanagement-whitepaper-1-150020.pdf" target="_blank" rel="noopener">HotSpot虚拟机内存管理白皮书</a></p></blockquote><h4 id="图示并行、并发、分区"><a class="header-anchor" href="#图示并行、并发、分区">¶</a>图示并行、并发、分区</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000046.png" alt="image-20200918104428044"></p><h3 id="7款经典收集器与垃圾分代"><a class="header-anchor" href="#7款经典收集器与垃圾分代">¶</a>7款经典收集器与垃圾分代</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000052.png" alt="image-20200918104836599"></p><ul><li>新生代收集器：Serial、ParNew、Parallel Scavenge</li><li>老年代收集器：Serial Old、Parallel Old、CMS</li><li>整堆收集器：G1</li></ul><h3 id="垃圾回收器组合"><a class="header-anchor" href="#垃圾回收器组合">¶</a>垃圾回收器组合</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000057.png" alt="image-20200918105011842"></p><ol><li><p>两个收集器间有连线,表明它们可以搭配使用:</p><p>Serial/Serial Old、 Serial/CMS、 ParNew/Serial Old、 ParNew/CMS、Parallel Scavenge/Serial Old、Parallel Scavenge/Parallel Old、G1；</p></li><li><p><strong>其中 Serial Old作为CMS出现&quot;Concurrent Mode Failure&quot;失败的后备预案。</strong></p></li><li><p>(红色虚线)由于维护和兼容性测试的成本,在JDK8时将 Serial+CMS、ParNew+Serial Old这两个组合声明为废弃(JEP173),并在JDK9中完全取消了这些组合的支持(JEP214),即: 移除。</p></li><li><p>(绿色虚线)JDK14中:弃用 Parallel Scavenge和Serial Old组合(JEP366)</p></li><li><p>(青色虚线)JDK14中:删除CMS垃圾回收器(JEP363)</p></li></ol><h3 id="概述"><a class="header-anchor" href="#概述">¶</a>概述</h3><p>为什么要有很多收集器,一个不够吗?因为ava的使用场景很多,移动端,服务器等。所以就需要针对不同的场景,提供不同的垃圾收集器,提高垃圾收集的性能。</p><p>虽然我们会对各个收集器进行比较,但并非为了挑选一个最好的收集器出来。没有一种放之四海皆准、任何场景下都适用的完美收集器存在,更加没有万能的收集器。所以我们选择的只是对具体应用最合适的收集器。</p><h3 id="如何查看默认的垃圾回收器"><a class="header-anchor" href="#如何查看默认的垃圾回收器">¶</a>如何查看默认的垃圾回收器</h3><ul><li><p><code>-XX:+/-PrintCommandLineFlags</code>：程序运行打印命令行相关参数（包含使用的垃圾收集器）</p></li><li><p>使用命令行指令：<code>jinfo -flag 相关垃圾回收参数 进程ID</code></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000109.png" alt="image-20200918110614096"></p></li></ul><h1>Serial回收器：串行回收</h1><p>Seria收集器是最基本、历史最悠久的垃圾收集器了。JDK1.3之前回收新生代唯一的选择。Serial收集器作为HotSpot中 <strong>client模式</strong> 下的默认新生代垃圾收集器。</p><p>Serial收集器采用<strong>复制算法、串行回收和&quot;Stop-The-World&quot;机制</strong>的方式执行内存回收。</p><p>除了年轻代之外, Serial收集器还提供用于执行老年代垃圾收集的 Serial Old收集器。 Serial Old收集器同样也采用了<strong>串行回收和&quot;Stop the World&quot;机制</strong>,只不过内存回收算法使用的是<strong>标记-压缩算法</strong>。</p><ul><li>Serial Old是运行在client模式下默认的老年代的垃圾回收器</li><li>Serial Old在Server模式下主要有两个用途:<ol><li>与新生代的 Parallel Scavenge配合使用</li><li>作为老年代CMS收集器的后备垃圾收集方案</li></ol></li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000115.png" alt="image-20200918111327599"></p><p>这个收集器是一个单线程的收集器,但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作,更重要的是在它进行垃圾收集时,必须暂停其他所有的工作线程,直到它收集结束(Stop The World)。</p><h2 id="优势"><a class="header-anchor" href="#优势">¶</a>优势</h2><p>简单而高效(与其他收集器的单线程比),对于限定单个CPU的环境来说, Serial 收集器由于没有线程交互的开销,专心做垃圾收集自然可以获得最高的单线程收集效率。运行在client模式下的虚拟机是个不错的选择。</p><p>在用户的桌面应用场景中,可用内存一般不大(几十MB至一两百MB),可以在较短时间内完成垃圾收集(几十ms至一百多ms),只要不频繁发生,使用串行回收器是可以接受的。</p><h2 id="使用参数"><a class="header-anchor" href="#使用参数">¶</a>使用参数</h2><p>在 HotSpot虚拟机中,使用<code>-XX:+UseSerialGC</code>参数可以指定年轻代和老年代都使用串行收集器。表示新生代用Serial GC,且老年代用 Serial Old GC（<strong>没有专门指定使用Serial Old GC的选项</strong>）。</p><h2 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h2><p>现在已经不用串行了，而且在限定单核cpu才可以用，现在都不是单核的了。对于交互较强的应用而言，这种垃圾收集器是不能接收的。一般在Java Web应用程序中是不会采用串行垃圾收集器的。</p><h1>ParNew回收器：并行回收</h1><p>如果说 SerialGC是年轻代中的单线程垃圾收集器,那么 ParNew收集器则是 Serial 收集器的多线程版本。</p><ul><li>Par是Parallel的缩写</li><li><strong>New:只能处理的是新生代</strong></li></ul><p>ParNew收集器除了采用并行回收的方式执行内存回收外,两款垃圾收集器之间几乎没有任何区别。 ParNew收集器在年轻代中同样也是采用复制算法、&quot;Stop-The-World&quot;机制。</p><p>ParNew是很多JVM运行 Server在模式下新生代的默认垃圾收集器。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000124.png" alt="image-20200918112511566"></p><ul><li>对于新生代，回收次数频繁，使用并行方式高效。</li><li>对于老年代，回收次数少，使用串行方式（默认情况使用Serial Old，可以指定使用CMS）节省资源(Switch Context)。</li></ul><h2 id="优势对比"><a class="header-anchor" href="#优势对比">¶</a>优势对比</h2><p>由于 ParNew收集器是基于并行回收,那么是否可以断定 ParNew收集器的回收效率在任何场景下都会比 Serial 收集器更高效?</p><ul><li>ParNew收集器运行在多CPU的环境下,由于可以充分利用多CPU、多核心等物理硬件资源优势,可以更快速地完成垃圾收集,提升程序的吞吐量。</li><li>但是在单个CPU的环境下, ParNew收集器不比Serial收集器更高效。虽然Serial收集器是基于串 行回收,但是由于CPU不需要频繁地做任务切换,因此可以有效避免多线程交互过程中产生的一些额外开销。</li></ul><p>除Serial外,目前只有 ParNew GC能与CMS收集器配合工作</p><h2 id="使用参数-v2"><a class="header-anchor" href="#使用参数-v2">¶</a>使用参数</h2><ul><li><p>在程序中，开发人员可以通过选项<code>-XX:+UseParNewGC</code>手动指定使用ParNew收集器执行内存回收任务。它表示年轻代使用并行收集器，不影响老年代</p><ul><li><p>即如果已经指定了老年代收集器如CMS，则使用CMS，如果没有就默认使用Serial Old。</p><p>因为在一开始只有Seiral收集器，它分为Serial新生代和Serial Old老年代两部分，后面发展出现了ParNew可以替代Serial的部分，但是老年代还是只能用Serial Old，再到后面出现了CMS，此时可以指定老年代为CMS。</p></li></ul></li><li><p><code>-XX:ParallelGCThreads</code>限制线程数量，默认开启和CPU数量相同的线程数。</p></li></ul><h1>Parallel回收器：吞吐量优先</h1><p>Hotspot的年轻代中除了拥有ParNew收集器是基于并行回收的以外,Parallel Scavenge收集器同样也采用了复制算法、并行回收和&quot;Stop The World&quot;机制。那么 Parallel 收集器的出现是否多此一举?</p><ul><li>和 ParNew收集器不同, Parallel Scavenge收集器的目标则是达到一个<strong>可控制的吞吐量</strong>(Throughput),它也被称为吞吐量优先的垃<br>圾收集器。</li><li><strong>自适应调节策略</strong>也是Parallel Scavenge与ParNew一个重要区别</li></ul><p>高吞吐量则可以高效率地利用CPU时间,尽快完成程序的运算任务,主要适合在后台运算而<strong>不需要太多交互</strong>的任务。因此,常见在服务器环境中使用。例如,那些执行批量处理、订单处理、工资支付、科学计算的应用程序。</p><p>Parallel收集器在JDK1.6时提供了用于执行老年代垃圾收集的Parallel Old收集器, 用来代替老年代的 Serial Old收集器。Parallel Old收集器采用了<strong>标记-压缩算法</strong>,但同样也是基于并行回收和&quot;Stop-The-World&quot;机制。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000132.png" alt="image-20200918115632298"></p><h1>优势</h1><p>在程序吞吐量优先的应用场景中，Parallel收集器和Parallel Old收集器的组合，在Server模式下的内存回收性能很不错。在Java8中，默认是此垃圾收集器。</p><h1>设置参数</h1><ul><li><code>-XX:+UseParallelGC</code>手动指定年轻代使用 Parallel 并行收集器执行内存回收任务。</li><li><code>-XX:+UseParallelOldGC</code>手动指定老年代都是使用并行回收收集器。<ul><li>分别适用于新生代和老年代。默认jdk8是开启的。</li><li>上面两个参数,默认开启一个,另一个也会被开启。(互相激活)</li><li><strong>如果在设置其中一个参数的时候同时设置一个其他的收集器会报错。</strong></li></ul></li><li><code>-XX: ParallelGCThreads=&lt;N&gt;</code>设置年轻代并行收集器的线程数。一般地,最好与CPU数量相等,以避免过多的线程数影响垃圾收集性能。<ul><li>在默认情况下,当CPU数量小于8个,<code>ParallelGCThreads</code>的值等于CPU数量。</li><li>当CPU数量大于8个, ParallelGCThreads的值等于 <code>3+[5*CPU_COUNT]/8]</code>。</li></ul></li><li><code>-XX:MaxGCPauseMillis=&lt;N&gt;</code>设置垃圾收集器最大停顿时间(即STW的时间)。单位是毫秒。<ul><li>为了尽可能地把停顿时间控制在<code>MaxGCPauseMillis</code>以内,收集器在工作时会调整Java堆大小或者其他一些参数。</li><li>对于用户来讲,停顿时间越短体验越好；但是在服务器端,我们注重高并发,整体的吞吐量。所以服务器端适合 Parallel,进行控制。</li><li>该参数使用需谨慎。</li></ul></li><li><code>-XX:GCTimeRatio=&lt;N&gt;</code>垃圾收集时间占总时间的比例<code>(=1/(N+1))</code>。用于衡量吞吐量的大小。<ul><li>取值范围(0,100)。默认值99,也就是垃圾回收时间不超过1%。</li><li>与前一个<code>-XX: MaxGCPauseMillis</code>参数有一定矛盾性。暂停时间越长, Radio参数就容易超过设定的比例。</li></ul></li><li><code>-XX:+UseAdaptiveSizePolicy</code>设置 Parallel Scavenge收集器具有自适应调节策略<ul><li>在这种模式下,年轻代的大小、Eden和 Survivor的比例、晋升老年代的对象年龄等参数会被自动调整,以达到在堆大小、吞吐量和停顿时间之间的平衡点。</li><li>在手动调优比较困难的场合,可以直接使用这种自适应的方式, 仅指定虚拟机的最大堆<code>-Xmx</code>、目标的吞吐量(<code>GCTimeRatio</code>)和停顿时间(<code>MaxGCPauseMillis</code>),让虚拟机自己完成调优工作。</li></ul></li></ul><h1>CMS回收器：低延迟</h1><p>在JDK1.5时期, HotSpot推出了一款在<strong>强交互应用</strong>中几乎可认为有划时代意义的垃圾收集器:CMS(Concurrent-Mark-Sweep)收集器,这款收集器是 HotSpot虚拟机中第一款真正意义上的并发收集器,它第一次实现了<strong>让垃圾收集线程与用户线程同时工作</strong>。</p><p>CMS收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间。停顿时间越短(低延迟)就越适合与用户交互的程序,良好的响应速度能提升用户体验。</p><ul><li>目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上,这类应用尤其重视服务的响应速度,希望系统停顿时间最短,以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。</li><li>CMS的垃圾收集算法采用标记-清除算法,并且也会&quot;Stop-The-World&quot;。</li></ul><p>不幸的是,CMS作为老年代的收集器,却无法与JDK1.4.0中已经存在的新生代收集器 Parallel Scavenge配合工作,所以在JDK1.5中使用CMS来收集老年代的时候,新生代只能选择 ParNew或者Serial收集器中的一个。</p><p>在G1出现之前,CMS使用还是非常广泛的。一直到今天,仍然有很多系统使用 CMS GC。</p><h2 id="CMS工作阶段"><a class="header-anchor" href="#CMS工作阶段">¶</a>CMS工作阶段</h2><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000140.png" alt="image-20200918141846706"></p><p>CMS整个过程比之前的收集器要复杂,整个过程分为4个主要阶段,即<strong>初始标记阶段、并发标记阶段、重新标记阶段和并发清除阶段</strong>。</p><ul><li>初始标记(Initial-Mark)阶段:在这个阶段中,程序中所有的工作线程都将会因为**“Stop-The-Word”**机制而出现短暂的暂停,这个阶段的主要任务仅仅只是标记出 GC Roots能直接关联到的对象。一旦标记完成之后就会恢复之前被暂停的所有应用线程。由于直接关联对象比较小,所以这里的速度非常快。</li><li>并发标记(Concurrent-Mark)阶段:从 GC Roots的直接关联对象开始遍历整个对象图的过程,这个过程耗时较长但是不需要停顿用户线程,可以与垃圾收集线程一起并发运行。</li><li>重新标记( Remark)阶段:由于在并发标记阶段中,程序的工作线程会和垃圾收集线程同时运行或者交叉运行,因此为了修正并发标记期间,因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录,这个阶段再次<strong>STW</strong>，本次停顿时间通常会比初始标记阶段稍长一些,但也远比并发标记阶段的时间短。</li><li>并发清除(Concurrent-Sweep)阶段:此阶段清理删除掉标记阶段判断的已经死亡的对象,释放内存空间。<strong>由于不需要移动存活对象</strong>,所以这个阶段也是可以与用户线程同时并发的</li></ul><p>尽管CMS收集器采用的是并发回收(非独占式),但是在其初始化标记和再次标记这两个阶段中仍然需要执行“Stop-The-World”机制暂停程序中的工作线程,不过暂停时间并不会太长,因此可以说明目前所有的垃圾收集器都做不到完全不需要“Stop-The-World”,只是尽可能地缩短暂停时间。</p><p>由于最耗费时间的并发标记与并发清除阶段都不需要暂停工作,所以整体的回收是低停顿的。</p><p>另外,由于在垃圾收集阶段用户线程没有中断,所以在CMS回收过程中,<strong>还应该确保应用程序用户线程有足够的内存可用</strong>。因此,CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集,<strong>而是当堆内存使用率达到某一阈值时,便开始进行回收</strong>,以确保应用程序在CMS工作过程中依然有足够的空间支持应用程序运行。要是CMS运行期间预留的内存无法满足程序需要,就会出现一次**“Concurrent Mode Failure”**失败,这时虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集,这样停顿时间就很长了。</p><h2 id="CMS的标记清除算法"><a class="header-anchor" href="#CMS的标记清除算法">¶</a>CMS的标记清除算法</h2><p>CMS收集器的垃圾收集算法采用的是<strong>标记清除</strong>算法,这意味着每次执行完内存回收后,由于被执行内存回收的无用对象所占用的内存空间极有可能是不连续的一些内存块,不可避免地将会产生一些内存碎片。那么CMS在为新对象分配内存空间时,将无法使用指针碰撞(Bump the Pointer)技术,而只能够选择空闲列表(Free List)执行内存分配。<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000147.png" alt="image-20200918142904676"></p><h3 id="为什么不用标记整理算法"><a class="header-anchor" href="#为什么不用标记整理算法">¶</a>为什么不用标记整理算法</h3><p>因为CMS追求短延迟(STW时间)，而在内存整理期间，是要移动对象的内存位置的，此时引用了这些对象的其它对象就要对引用进行修改，这个阶段必须要STW，不然会数据错乱。</p><h2 id="CMS的优点"><a class="header-anchor" href="#CMS的优点">¶</a>CMS的优点:</h2><ul><li>并发收集</li><li>低延迟</li></ul><h2 id="CMS的弊端"><a class="header-anchor" href="#CMS的弊端">¶</a>CMS的弊端:</h2><ol><li>会产生内存碎片,导致并发清除后,用户线程可用的空间不足。在无法分配大对象的情况下,不得不提前触发Full GC</li><li>CMS收集器对CPU资源非常敏感。在并发阶段,它虽然不会导致用户停顿,但是会因为占用了一部分线程而导致应用程序变慢,总吞吐量会降低。</li><li>可能出现“Concurrent Mode Failure&quot;失败而导致另一次Fu11 GC的产生。</li><li>CMS收集器无法处理浮动垃圾。在并发标记阶段由于程序的工作线程和垃圾收集线程是同时运行或者交叉运行的,那么在并发标记阶段如果产生新的垃圾对象,CMS将无法对这些垃圾对象进行标记,最终会导致这些新产生的垃圾对象没有被及时回收,从而只能在下一次执行GC时释放这些之前未被回收的内存空间。</li></ol><h2 id="使用参数-v3"><a class="header-anchor" href="#使用参数-v3">¶</a>使用参数</h2><ul><li><p><code>-XX:+UseConcMarkSweepGC</code>手动指定使用CMS收集器执行内存回收任务。</p><ul><li>开启该参数后会自动将<code>-XX:+UseParNewGC</code>开。即: ParNew(Young区用)+CMS(Old区用)+Serial Old的组合。</li></ul></li><li><p><code>-XX:CMSInitiatingOccupanyFraction=&lt;N&gt;</code>设置堆内存使用率的阈值,一旦达到该阈值,便开始进行回收。</p><ul><li>JDK5及以前版本的默认值为68,即当老年代的空间使用率达到68%时,会执行一次CMS回收。JDK6及以上版本默认值为92%<ul><li>如果内存增长缓慢,则可以设置一个稍大的值,大的阈值可以有效降低CMS的触发频率,减少老年代回收的次数可以较为明显地改善应用程序性能。</li><li>反之,如果应用程序内存使用率增长很快,则应该降低这个阈值,以避免频繁触发老年代串行收集器。因此通过该选项便可以有效降低Full GC的执行次数。</li></ul></li></ul></li><li><p><code>-XX:+UseCMSCompactAtFullCollection</code><strong>用于指定在执行完Full GC后对内存空间进行压缩整理</strong>,以此避免内存碎片的产生。不过由于内存压缩整理过程无法并发执行,所带来的问题就是停顿时间变得更长了。</p></li><li><p><code>-XX:CMSFullGCsBeforeCompaction=&lt;N&gt;</code>设置在<strong>执行多少次Fu1lGC后对内存空间进行压缩整理</strong>。</p></li><li><p><code>-XX: ParallelCMSThreads=&lt;N&gt;</code>设置CMS的线程数量。</p><ul><li>CMS默认启动的线程数是(ParallelGCThreads+3)/4, 是年轻代并行收集器的线程数。当CPU资源比较紧张时,受到CMS收集器线程的影响,应用程序的性能在垃圾回收阶段可能会非常糟糕。</li></ul></li></ul><h1>G1回收器：区域化分代式</h1><p>既然我们已经有了前面几个强大的GC,为什么还要发布 Garbage First(G1) GC?</p><p>原因就在于应用程序所应对的业务越来越庞大、复杂,用户越来越多,没有GC就不能保证应用程序正常进行,而经常造成STW的GC又跟不上实际的需求,所以才会不断地尝试对GC进行优化。G1(Garbage-First)垃圾回收器是在Java7 update4之后引入的一个新的垃圾回收器,是当今收集器技术发展的最前沿成果之一。</p><p>与此同时,为了适应现在不断扩大的内存和不断增加的处理器数量,<strong>进一步降低暂停时间(pause time),同时兼顾良好的吞吐量</strong>。官方给G1设定的目标是在延迟可控的情况下获得尽可能高的吞吐量,所以才担当起“全功能收集器”的重任与期望。</p><h2 id="概述-v2"><a class="header-anchor" href="#概述-v2">¶</a>概述</h2><h3 id="命名"><a class="header-anchor" href="#命名">¶</a>命名</h3><p>为什么名字叫做 Garbage First(G1)呢?</p><p>因为G1是一个并行回收器,它把堆内存分割为很多不相关的区域(Region)(物理上不连续的)。使用不同的 Region来表示Eden、幸存者0区,幸存者1区,老年代等。</p><p>G1 GC有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个 Region里面的垃圾堆积的价值大小(回收所获得的空间大小以及回收所需时间的经验值),在后台维护一个优先列表,每次根据允许的收集时间,优先回收价值最大的 Region。</p><p>由于这种方式的侧重点在于回收垃圾最大量的区间(Region),所以我们给G1一个名字:垃圾优先(Garbage First)。</p><h3 id="历程"><a class="header-anchor" href="#历程">¶</a>历程</h3><p>G1(Garbage-First)是一款面向服务端应用的垃圾收集器,主要针对配备多核CPU及大容量内存的机器,以极高概率满足GC停顿时间的同时,还兼具高吞吐量的性能特征。</p><p>在JDK1.7版本正式启用,移除了 Experimental 的标识,是JDK9以后的默认垃圾回收器,取代了CMS回收器以及 Parallel+ Parallel old组合。被 Oracle官方称为“全功能的垃圾收集器”。与此同时,CMS已经在JDK9中被标记为废弃(deprecated)。</p><p>在JDK8中G1还不是默认的垃圾回收器,需要使用<code>-XX:+UseG1GC</code>来启用。</p><h2 id="G1回收器的特点-优势"><a class="header-anchor" href="#G1回收器的特点-优势">¶</a>G1回收器的特点(优势)</h2><p>与其他GC收集器相比,G1使用了全新的分区算法,其特点如下所示:</p><h3 id="并行与并发"><a class="header-anchor" href="#并行与并发">¶</a>并行与并发</h3><ul><li>并行性:G1在回收期间,可以有多个GC线程同时工作,有效利用多核计算能力。此时用户线程STW</li><li>并发性:G1拥有与应用程序交替执行的能力,部分工作可以和应用程序同时执行,  因此,一般来说,不会在整个回收阶段发生完全阻塞应用程序的情况</li></ul><h3 id="分代收集"><a class="header-anchor" href="#分代收集">¶</a>分代收集</h3><ul><li>从分代上看,G1依然属于分代型垃圾回收器,它会区分年轻代和老年代,年轻代依然有Eden区 Survivor和区。但从堆的结构上看,它不要求整个Eden区、年轻代或者老年代都是连续的,也不再坚持固定大小和固定数量。</li><li>将堆空间分为若干个区域(Region),这些区域中包含了逻辑上的年轻代和老年代。和之前的各类回收器不同,它同时兼顾年轻代和老年代。对比其他回收器,或者工作在年轻代,或者工作在老年代。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000156.png" alt="image-20200918150258888"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000203.png" alt="image-20200918150309556"></p><h3 id="空间整合"><a class="header-anchor" href="#空间整合">¶</a>空间整合</h3><ul><li>CMS:“标记-清除”算法、内存碎片若干次GC后进行一次碎片整理</li><li>G1将内存划分为一个个的。内存的回收是以 region作为基本单位的。Region之间是复制算法,但整体上实际可看作是标记-压缩(Mark-Compact)算法,两种算法都可以避免内存碎片。这种特性有利于程序长时间运行,分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。尤其是当Java堆非常大的时候,G1的优势更加明显。</li></ul><h3 id="可预测的停顿时间模型-即-软实时soft-real-time"><a class="header-anchor" href="#可预测的停顿时间模型-即-软实时soft-real-time">¶</a>可预测的停顿时间模型(即:软实时soft real-time)</h3><p>这是G1相对于CMS的另一大优势,G1除了追求低停顿外,还能建立可预测的停顿时间模型,能让使用者明确指定在一个长度为M毫秒的时间片段内,消耗在垃圾收集上的时间不得超过N毫秒。</p><ul><li><p>由于分区的原因,G1可以只选取部分区域进行内存回收,这样缩小了回收的范围,因此对于全局停顿情况的发生也能得到较好的控制。</p></li><li><p>G1跟踪各个 Region里面的垃圾堆积的价值大小(回收所获得的空间大小以及回收所需时间的经验值),在后台维护一个优先列表,每次根据允许的收集时间,优先回收价值最大的 Region。保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。</p></li><li><p>相比于CMS GC,G1未必能做到CMS在最好情况下的延时停顿,但是最差情况要好很多。</p></li></ul><h2 id="对比CMS"><a class="header-anchor" href="#对比CMS">¶</a>对比CMS</h2><p>相较于CMS,G1还不具备全方位、压倒性优势。比如在用户程序运行过程中,G1无论是为了垃圾收集产生的内存占用(Footprint)还是程序运行时的额外执行负载(Overload)都要比CMS要高。</p><p>从经验上来说,<strong>在小内存应用上CMS的表现大概率会优于G1,而G1在大内存应用上则发挥其优势</strong>。平衡点在6-8GB之间。</p><h2 id="使用参数-v4"><a class="header-anchor" href="#使用参数-v4">¶</a>使用参数</h2><ul><li><code>-XX:+UseG1GC</code>手动指定使用G1收集器执行内存回收任务。</li><li><code>-XX:G1HeapRegionSize=&lt;N&gt;</code>设置每个 Region的大小。值是2的幂,范围是1MB到32MB之间,目标是根据最小的Java堆大小划分出约2048个区域。默认是堆内存的1/2000。</li><li><code>-XX:MaxGCPauseMillis=&lt;N&gt;</code>设置期望达到的最大GC停顿时间指标(JVM会尽力实现,但不保证达到)。默认值是200ms</li><li><code>-XX:ParallelGCThread=&lt;N&gt;</code>设置STW工作线程数的值。最多设置为8</li><li><code>-XX:ConcGCThreads=&lt;n&gt;</code>设置并发标记的线程数。将N设置为并行垃圾回收线程数(<code>ParallelGCThreads</code>)的1/4左右。</li><li><code>-XX:InitiatingHeapOccupancyPercent=&lt;N&gt;</code>设置触发并发GC周期的Java堆占用率阈值。超过此值,就触发GC。默认值是45</li></ul><h2 id="常见操作"><a class="header-anchor" href="#常见操作">¶</a>常见操作</h2><p>G1的设计原则就是简化VM性能调优,开发人员只需要简单的三步即可完成调优:</p><ul><li>第一步:开启G1垃圾收集器</li><li>第二步:设置堆的最大内存</li><li>第三步:设置最大的停顿时间</li></ul><p>G1中提供了三种垃圾回收模式: YoungGC、 Mixed GC和Full GC,在不同的条件下被触发。</p><h2 id="适用场景"><a class="header-anchor" href="#适用场景">¶</a>适用场景</h2><ul><li>面向服务端应用,针对具有大内存、多处理器的机器。(在普通大小的堆里表现并不惊喜)</li><li>最主要的应用是需要低GC延迟,并具有大堆的应用程序提供解决方案<ul><li>如:在堆大小约6GB或更大时,可预测的暂停时间可以低于0.5秒;(G1通过每次只清理一部分而不是全部的 Region的增量式清理来保证每次GC停顿时间不会过长)。</li></ul></li><li>用来替换掉JDK1.5中的CMS收集器;在下面的情况时,使用G1可能比CMS好:<ol><li>超过50%的Java堆被活动数据占用;</li><li>对象分配频率或年代提升频率变化很大;</li><li>GC停顿时间过长(长于0.5至1秒)。</li></ol></li><li>HotSpot垃圾收集器里,除了G1以外,其他的垃圾收集器使用内置的JVM线程执行GC的多线程操作,而G1 GC可以采用应用线程承担后台运行的GC工作,即当JVM的GC线程处理速度慢时,系统会调用应用程序线程帮助加速垃圾回收过程。</li></ul><h2 id="分区-Region-化整为零"><a class="header-anchor" href="#分区-Region-化整为零">¶</a>分区 Region:化整为零</h2><p>使用G1收集器时,它将整个Java堆划分成约2048个大小相同的独立 Region块,每个Region块大小根据堆空间的实际大小而定,整体被控制在1MB到32MB之间,且为2的N次幂,即1MB,2MB,4MB,8MB,16MB,32MB可以通过<code>-XX:G1HeapRegionSize=&lt;N&gt;</code>设定。所有的 Region大小相同,且在JVM生命周期内不会被改变。</p><p>虽然还保留有新生代和老年代的概念,但新生代和老年代不再是物理隔离的了,它们都是一部分 Region(不需要连续)的集合。通过Region的动态分配方式实现逻辑上的连续。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000211.png" alt="image-20200918152658094"></p><p>一个region有可能属于Eden, Survivor或者old/Tenured内存区域。但是一个 region只可能属于一个角色。图中的E表示该 region属于Eden内存区域,S表示属于 Survivor内存区域,O表示属于Old内存区域。图中空白的表示未使用的内存空间。</p><p>G1垃圾收集器还增加了一种新的内存区域,叫做 Humongous内存区域,如图中的H块。主要用于存储大对象,如果超过1.5个region,就放到H。</p><h3 id="设置H的原因？？？？？？"><a class="header-anchor" href="#设置H的原因？？？？？？">¶</a>设置H的原因？？？？？？</h3><p>对于堆中的大对象,默认直接会被分配到老年代,但是如果它是一个短期存在的大对象就会对垃圾收集器造成负面影响。为了解决这个问题,G1划分 Humongous了一个区,它用来专门存放大对象。如果一个H区装不下一个大对象,那么G1会寻找连续的H区来存储。为了能找到连续的H区,有时候不得不启动FullGC。G1的大多数行为都把H区作为老年代的一部分来看待。</p><h3 id="指针碰撞与TLAB"><a class="header-anchor" href="#指针碰撞与TLAB">¶</a>指针碰撞与TLAB</h3><ul><li>每个region中使用指针碰撞进行内存分配。</li><li>可能存在TLAB区域</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000218.png" alt="image-20200918153043508"></p><h2 id="G1垃圾回收过程"><a class="header-anchor" href="#G1垃圾回收过程">¶</a>G1垃圾回收过程</h2><p>G1 GC的垃圾回收过程主要包括如下三个环节:</p><ul><li>年轻代GC(Young GC)</li><li>老年代并发标记过程(Concurrent Marking)</li><li>混合回收(Mixed GC)</li><li>(如果需要,单线程、独占式、高强度的Fu11 GC还是继续存在的。它针对GC的评估失败提供了一种失败保护机制,即强力回收。)</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000223.png" alt="image-20200918153421896"></p><h3 id="大体步骤"><a class="header-anchor" href="#大体步骤">¶</a>大体步骤</h3><ol><li><p>应用程序分配内存,当年轻代的Eden区用尽时开始年轻代回收过程;G1的年轻代收集阶段是一个并行的独占式收集器。在年轻代回收期,G1 GC暂停所有应用程序线程,启动多线程执行年轻代回收。然后从年轻代区间移动存活对象到 Survivor区间或者老年区间,也有可能是两个区间都会涉及。</p></li><li><p>当堆内存使用达到一定值(默认45%)时,开始老年代并发标记过程。</p></li><li><p>标记完成马上开始混合回收过程。对于一个混合回收期,G1 GC从老年区间移动存活对象到空闲区间,这些空闲区间也就成为了老年代的一部分。和年轻代不同,老年代的G1回收器和其他GC不同,G1的老年代回收器不需要整个老年代被回收,一次只需要扫描/回收一小部分老年代的 Region就可以了。同时,这个老年代 Region是和年轻代一起被回收的。</p><p>举个例子:一个Web服务器,Java进程最大堆内存为4G,每分钟响应1500个请求,每45秒钟会新分配大约2G的内存。G1会每45秒钟进行一次年轻代回收,每31个小时整个堆的使用率会达到45%,会开始老年代并发标记过程,标记完成后开始四到五次的混合回收。</p></li></ol><h3 id="Remembered-Set"><a class="header-anchor" href="#Remembered-Set">¶</a>Remembered Set</h3><ul><li><p>一个对象被不同区域引用的问题：</p><p>一个Region不可能是孤立的,一个Region中的对象可能被其他任意中对象引用,判断对象存活时,是否需要扫描整个Java堆才能保证准确？在其他的分代收集器,也存在这样的问题(而G1更突出)回收新生代也不得不同时扫描老年代?这样的话会降低Minor GC的效率。</p></li><li><p>解决方法:</p><ol><li><p>无论G1还是其他分代收集器,JVM都是使用Remembered Set来避免全局扫描:每个Region都有一个对应的Remembered Set。</p></li><li><p>每次Reference类型数据写操作时,都会产生一个 Write Barrier(写屏障)暂时中断操作</p></li><li><p>然后检查将要写入的引用指向的对象是否和该 Reference类型数据在不同的Region(其他收集器:检查老年代对象是否引用了新生代对象);</p></li><li><p>如果不同,通过CardTable把相关引用信息记录到引用指向对象的所在 Region对应的 Remembered Set中（<strong>即记录引用了本Region的数据的引用地址</strong>）;</p></li><li><p>当进行垃圾收集时,在GC根节点的枚举范围加入 Remembered Set，就可以保证不进行全局扫描,也不会有遗漏。</p></li></ol></li><li><p>R Set示意图：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000230.png" alt="image-20200918154406803"></p></li></ul><h3 id="具体过程"><a class="header-anchor" href="#具体过程">¶</a>具体过程</h3><h4 id="1-YoungGC"><a class="header-anchor" href="#1-YoungGC">¶</a>1&gt;YoungGC</h4><h5 id="概述-v3"><a class="header-anchor" href="#概述-v3">¶</a>概述</h5><p>JVM启动时,G1先准备好Eden区,程序在运行过程中不断创建对象到Eden区,当Eden空间耗尽时,G1会启动一次年轻代垃圾回收过程。年轻代垃圾回收只会回收Eden区和 Survivor区。YGC时,首先G1停止应用程序的执行(Stop-The-World),G1创建回收集( Collection Set),回收集是指需要被回收的内存分段的集合,年轻代回收过程的回收集包含年轻代Eden区和Survivor区所有的内存分段。</p><h6 id="回收前"><a class="header-anchor" href="#回收前">¶</a>回收前</h6><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000235.png" alt="image-20200918155156083"></p><h6 id="回收后"><a class="header-anchor" href="#回收后">¶</a>回收后</h6><ol><li><p>坐标为(0,2)、(3,1)、(3,2)、(3,6)的1个Survior from区和3个Eden区region被分析到回收价值大，并经过计算可以将三个区域的数据压缩到(0,1)region（它们的数据没满）。</p></li><li><p>坐标为(0,6)、(1,5)、(1,6)的1个Survior from区和2个Eden区region被分析到回收价值大，并经过计算可以将三个区域的数据压缩到(2,3)region（它们的数据没满）。</p></li><li><p>而(1,5)的Survior from区数据被判定需要晋升为老年代，然后被复制到了(3,5)</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000241.png" alt="image-20200918155209036"></p><h5 id="详细描述"><a class="header-anchor" href="#详细描述">¶</a>详细描述</h5><h6 id="第一阶段-扫描根"><a class="header-anchor" href="#第一阶段-扫描根">¶</a>第一阶段,扫描根</h6><p>GC Roots连同 Rset 记录的外部引用作为扫描存活对象的入口。</p><h6 id="第二阶段-更新RSet"><a class="header-anchor" href="#第二阶段-更新RSet">¶</a>第二阶段,更新RSet</h6><p>处理dirty card queue<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>中的card,更新 Rset.此阶段完成后,Rset可以准确的反映老年代对所在的内存分段中对象的引用。</p><p>那为什么不在引用赋值语句处直接更新RSet呢?是为了性能的需要,RSet的处理需要线程同步开销会很大,使用队列性能会好很多</p><h6 id="第三阶段-处理RSet"><a class="header-anchor" href="#第三阶段-处理RSet">¶</a>第三阶段,处理RSet</h6><p>识别被老年代对象指向的Eden中的对象,这些被指向的Eden中的对象被认为是存活的对象。</p><h6 id="第四阶段-复制对象"><a class="header-anchor" href="#第四阶段-复制对象">¶</a>第四阶段,复制对象</h6><p>此阶段,对象树被遍历,Eden区内存段中存活的对象会被复制到 Survivor区中空的内存分段, Survivor区内存段中存活的对象如果年龄未达阈值,年龄会加1,达到阀值会被会被复制到Old区中空的内存分段。如果 Survivor空间不够,Eden空间的部分数据会直接晋升到老年代空间。</p><h6 id="第五阶段-处理引用"><a class="header-anchor" href="#第五阶段-处理引用">¶</a>第五阶段,处理引用</h6><p>处理Soft,Weak,Phantom,Final,JNI Weak等引用。最终Eden空间的数据为空,GC停止工作,而目标内存中的对象都是连续存储的,没有碎片,所以复制过程可以达到内存整理的效果,减少碎片。</p><h4 id="2-并发标记过程"><a class="header-anchor" href="#2-并发标记过程">¶</a>2&gt;并发标记过程</h4><h5 id="1-初始标记阶段"><a class="header-anchor" href="#1-初始标记阶段">¶</a>1)初始标记阶段:</h5><p>标记从根节点直接可达的对象。这个阶段是STW的,并且会触发一次年轻代GC。</p><h5 id="2-根区域扫描-Root-Region-Scanning"><a class="header-anchor" href="#2-根区域扫描-Root-Region-Scanning">¶</a>2)根区域扫描(Root Region Scanning)</h5><p>G1 GC扫描Survivor区直接可达的老年代区域对象,并标记被引用的对象。这一过程必须在 Young GC之前完成。</p><h5 id="3-并发标记-Concurrent-Marking"><a class="header-anchor" href="#3-并发标记-Concurrent-Marking">¶</a>3)并发标记(Concurrent Marking)</h5><p>在整个堆中进行并发标记(和应用程序并发执行),此过程可能被 Young GC中断。**在并发标记阶段,若发现区域对象中的所有对象都是垃圾,那这个区域会被立即回收。**同时,并发标记过程中,会计算每个区域的对象活性(区域中存活对象的比例)。</p><h5 id="4-再次标记-Remark"><a class="header-anchor" href="#4-再次标记-Remark">¶</a>4)再次标记(Remark)</h5><p>由于应用程序持续进行,需要修正上一次的标记结果，STW。G1中采用了比CMS更快的初始快照算法: snapshot-at-the-beginning(SATB)。</p><h5 id="5-独占清理-cleanup-STW"><a class="header-anchor" href="#5-独占清理-cleanup-STW">¶</a>5)独占清理(cleanup,STW)</h5><p>计算各个区域的存活对象和GC回收比例,并进行排序, 识别可以混合回收的区域。为下阶段做铺垫。STW。这个阶段并不会实际上去做垃圾的收集。</p><h5 id="6-并发清理阶段"><a class="header-anchor" href="#6-并发清理阶段">¶</a>6)并发清理阶段</h5><p>识别并清理完全空闲的区域。</p><h4 id="3-混合回收"><a class="header-anchor" href="#3-混合回收">¶</a>3&gt;混合回收</h4><p>当越来越多的对象晋升到老年代Old Region时,为了避免堆内存被耗尽,虚拟机会触发一个混合的垃圾收集器,即 Mixed GC,该算法并不是一个Old GC,除了回收<strong>整个</strong>Young Region,还会回收<strong>一部分</strong>的Old Region。这里需要注意:是一部分老年代,而不是全部老年代。可以选择哪些Old Region进行收集,从而可以对垃圾回收的耗时时间进行控制。也要注意的是 Mixed GC并不是Full GC。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000249.png" alt="image-20200918162819176"></p><ul><li><p>并发标记结束以后,老年代中百分百为垃圾的内存分段被回收了,部分为垃圾的内存分段被计算了出来。默认情况下,这些老年代的内存分段会分8次(可以通过<code>-XX:G1MixedGCCountTarget=&lt;N&gt;</code>设置)被回收。</p></li><li><p>混合回收的回收集(collection Set)包括八分之一的老年代内存分段,Eden区内存分段, Survivor区内存分段。混合回收的算法和年轻代回收的算法完全一样,只是回收集多了老年代的内存分段。具体过程请参考上面的年轻代回收过程。</p></li><li><p>由于老年代中的内存分段默认分8次回收,G1会优先回收垃圾多的内存分段。<strong>垃圾占内存分段比例越高的</strong>,越会被先回收。并且有一个阈值会决定内存分段是否被回收, <code>-XX:G1MixedGCLiveThresholdPercent=&lt;N&gt;</code>, 默认为65%,意思是垃圾占内存分段比例要达到65%才会被回收。如果垃圾占比太低,意味着存活的对象占比高,在复制的时候会花费更多的时间。</p></li><li><p>混合回收并不一定要进行8次。有一个阈值<code>-XX:G1HeapWastePercent</code> ,默认值为10%, 意思是允许整个堆内存中有10%的空间被浪费,意味着如果发现可以回收的垃圾占堆内存的比例低于10%,则不再进行混合回收。因为GC会花费很多的时间但是回收到的内存却很少。</p></li></ul><h4 id="4-Full-GC"><a class="header-anchor" href="#4-Full-GC">¶</a>4&gt;Full GC</h4><p>G1的初衷就是要避免Full GC的出现。但是如果上述方式不能正常工作,G1会停止应用程序的执行(Stop-The-World),使用单线程的内存回收算法进行垃圾回收,性能会非常差,应用程序停顿时间会很长。</p><p>要避免FullGC的发生,一旦发生需要进行调整。什么时候会发生Full GC呢?比如堆内存太小,当G1在复制存活对象的时候没有空的内存分段可用,则会回退到Full GC,这种情况可以通过增大内存解决。导致G1 Full GC的原因可能有两个:</p><ol><li>Evacuation的时候没有足够的to-space来存放晋升的对象。</li><li>并发处理过程完成之前空间耗尽。</li></ol><h2 id="关于G1回收阶段的STW"><a class="header-anchor" href="#关于G1回收阶段的STW">¶</a>关于G1回收阶段的STW</h2><p>从 oracle官方透露出来的信息可获知,回收阶段(Evacuation)其实本也有想过设计成与用户程序一起并发执行,但这件事情做起来比较复<br>杂,考虑到G1只是回Region收一部分,停顿时间是用户可控制的,所以并不迫切去实现,而选择把这个特性放到了G1之后出现的低延迟垃圾<br>收集器(即ZGC)中。另外,还考虑到G1不是仅仅面向低延迟,停顿用户线程能够最大幅度提高垃圾收集效率,为了保证吞吐量所以才选择了完全暂停用户线程的实现方案。</p><h2 id="G1优化建议"><a class="header-anchor" href="#G1优化建议">¶</a>G1优化建议</h2><ul><li><p>年轻代大小</p><p>避免使用<code>-Xmn</code>或<code>-XX:NewRatio</code>等相关选项显式设置年轻代大小。固定年轻代的大小会覆盖暂停时间目标</p></li><li><p>暂停时间目标不要太过严苛</p><p>G1 GC的吞吐量目标是90%的应用程序时间和10%的垃圾回收时间。评估G1 GC的吞吐量时,暂停时间目标不要太严苛。目标太过严苛表示你愿意承受更多的垃圾回收开销,而这些会直接影响到吞吐量。</p></li></ul><h1>垃圾回收器总结</h1><p>截止JDK1.8，一共有7款不同的垃圾收集器。每一款不同的垃圾收集器都有不同的特点，在具体使用的时候，要根据具体的情况选用不同的垃圾收集器。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000256.png" alt="image-20200918164309707"></p><h2 id="GC发展阶段"><a class="header-anchor" href="#GC发展阶段">¶</a>GC发展阶段</h2><p>Serial-&gt;Parallel-&gt;CMS-&gt;G1-&gt;ZGC。</p><p>除了一个面向高吞吐量一个面向低延迟的目标不一致外,技术上的原因是Parallel Scavenge收集器及后面提到的G1收集器等都没有使用HotSpot中原本设计的垃圾收集器的分代框架,而选择另外独立实现。Serial、ParNew收集器则共用了这部分的框架代码,详细可参考: <a href="https://blogs.oracle.com/jonthecollector/our_collectors" target="_blank" rel="noopener">https://blogs.oracle.com/jonthecollector/our_collectors</a>。</p><h3 id="废弃的回收器"><a class="header-anchor" href="#废弃的回收器">¶</a>废弃的回收器</h3><ul><li>JDK9新特性:CMS被标记为 Deprecate(JEP291)<ul><li>如果对JDK9及以上版本的 HotSpot虚拟机使用参数<code>-XX:+UseConcMarkSweepGC</code>来开启CMS收集器的话,用户会收到一个警告信息,提示CMS未来将会被废弃。</li></ul></li><li>JDK14新特性:删除CMS圾回收器(JEP363)<ul><li>移除了CMS垃圾收集器,如果在JDK14中使用<code>-XX:+UseConcMarkSweepGC</code>的话,JVM不会报错,只是给出一个warning信息,但是不会exit。VM会自动回退以默认GC方式启动JVM<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000304.png" alt="image-20200918145000481"></li></ul></li></ul><h2 id="怎么选择垃圾回收器"><a class="header-anchor" href="#怎么选择垃圾回收器">¶</a>怎么选择垃圾回收器?</h2><p>Java垃圾收集器的配置对于JVM优化来说是一个很重要的选择选择合适的垃圾收集器可以让VM的性能有一个很大的提升。<br>怎么选择垃圾收集器?</p><ol><li>优先调整堆的大小让VM自适应完成。</li><li>如果内存小于100M,使用串行收集器</li><li>如果是单核、单机程序, 并且没有停顿时间的要求,串行收集器</li><li>如果是多CPU、需要高吞吐量、允许停顿时间超过1秒, 选择并行或者JVM自己选择</li><li>如果是多CPU、追求低停顿时间,需快速响应(比如延迟不能超过1秒,如互联网应用),使用并发收集器。官方推荐G1,性能高。现在互联网的项目,基本都是使用G1。</li></ol><h2 id="垃圾收集器搭配总结"><a class="header-anchor" href="#垃圾收集器搭配总结">¶</a>垃圾收集器搭配总结</h2><ol><li><p>设置UseSerialGC的语义就是指定串行垃圾回收器，会指定新生代收集为Serial，老年代收集为Serial Old。</p></li><li><p>设置UseParNewGC的语义就是设置新生代收集为ParNew，如果老年代没有被指定就使用Serial Old（ParNew只能搭配CMS和Serial Old使用，设置其他的会报错）。</p></li><li><p>只启用UseParrelGC或者只启用UseParrelOldGC或者两者都启用的时候，其语义都是设置新生代老年代GC为Parallel(Scavenge)的。</p><p>启用UseParrelGC以及关闭UseParrelOldGC(<code>-XX:-UseParralOldGC</code>)的语义是新生代GC为Parallel的，老年代GC为Serial Old。</p><p>剩下的其它搭配都会报错。</p></li><li><p>上面描述到Serial和ParNew的默认老年代回收器是Serial Old，另外可以显示配置使用CMS(<code>-XX:+UseConcMarkSweepGC</code>)。</p></li><li><p>使用<code>-XX:+UseConcMarkSweepGC</code>选项激活CMS后的默认新生代收集器是ParNew收集器(不是Serial)，可以使用<code>-XX:+/-UseParNewGC</code>选项来强制指定或者禁用它。</p></li><li><p>另外Serial Old是CMS的一个backup。</p></li><li><p>G1是整堆收集器，只能显示启用它自己。</p></li><li><p>JDK6开始到JDK8默认的垃圾收集器是Parallel组合；JDK9为G1。</p></li></ol><h1>GC日志分析</h1><h2 id="内存分配与垃圾回收的参数"><a class="header-anchor" href="#内存分配与垃圾回收的参数">¶</a>内存分配与垃圾回收的参数</h2><h3 id="JDK9之前"><a class="header-anchor" href="#JDK9之前">¶</a>JDK9之前</h3><ol><li><p><code>-XX:+PrintGC</code># 输出GC日志。类似 -verbose:gc</p><p>输出信息<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000312.png" alt="image-20200918171108035"></p><p>解析</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000317.png" alt="image-20200918171120084"></p></li><li><p><code>-XX:+PrintGCDetails</code># 输出GC的详细日志</p><p>输出信息</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000324.png" alt="image-20200918171453022"></p><p>解析</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000330.png" alt="image-20200918171517595"></p></li><li><p><code>-XX:+PrintGCTimeStamps</code># 在输出GC日志的时候，增加输出时间戳(从JVM启动依赖经历了多长时间)</p><p>输出信息</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000337.png" alt="image-20200918171820638"></p></li><li><p><code>-XX:+PrintGCDateStamps</code># 在输出GC日志的时候，增加输出GC的时间戳(以日期的形式,如2013-05-04T21:53:59.234+0800)</p><p>输出信息</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000344.png" alt="image-20200918171808838"></p></li><li><p><code>-XX:+PrintHeapAtGC</code># 在进行GC的前后打印出堆的信息</p></li><li><p><code>-X1oggc:../1ogs/gc.1og</code># 日志文件的输出路径</p></li></ol><h3 id="JDK9及之后"><a class="header-anchor" href="#JDK9及之后">¶</a>JDK9及之后</h3><p>HotSpot所有功能的日志都收归到了“-Xlog”参数上,这个参数的能力也相应被极大拓展了:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">-Xlog[:[selector][:[output][:[decorators][:output-options]]]]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>命令行中最关键的参数是选择器(Selector),它由标签(Tag)和日志级别(Level)共同组成。<br>标签可理解为虚拟机中某个功能模块的名字,它告诉日志框架用户希望得到虚拟机哪些功能的日志输出。垃圾收集器的标签名称为“gc”,由此可见,垃圾收集器日志只是HotSpot众多功能日志的其中一项,支持的功能模块标签名如下所示:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">add,age,alloc,annotation,aot,arguments,attach,barrier,biasedlocking,blocks,bot,breakpoint,bytecode......<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>日志级别从低到高,共有Trace,Debug,Info,Warning,Error,Off六种级别,日志级别决定了输出信息的详细程度,默认级别为Info,HotSpot的日志规则与Log4j、SLF4j这类Java日志框架大体上是一致的。另外,还可以使用修饰器(Decorator)来要求每行日志输出都附加上额外的内容,支持附加在日志行上的信息包括:</p><ul><li>time:当前日期和时间。</li><li>uptime:虚拟机启动到现在经过的时间,以秒为单位。</li><li>timemillis:当前时间的毫秒数,相当于System.currentTimeMillis()的输出。</li><li>uptimemillis:虚拟机启动到现在经过的毫秒数。</li><li>timenanos:当前时间的纳秒数,相当于System.nanoTime()的输出。</li><li>uptimenanos:虚拟机启动到现在经过的纳秒数。</li><li>pid:进程ID。</li><li>tid:线程ID。</li><li>level:日志级别。</li></ul><p>tags:日志输出的标签集。<br>如果不指定,默认值是uptime、level、tags这三个,此时日志输出类似于以下形式:</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[3.080s][info][gc,cpu] GC(5) User=0.03s Sys=0.00s Real=0.01s<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="GC日志中的时间"><a class="header-anchor" href="#GC日志中的时间">¶</a>GC日志中的时间</h3><ul><li>user:进程执行用户态代码所耗费的处理器时间。</li><li>sys:进程执行核心态代码所耗费的处理器时间。</li><li>real:执行动作从开始到结束耗费的时钟时间。</li></ul><p>请注意,前面两个是处理器时间,而最后一个是时钟时间,它们的区别是处理器时间代表的是线程占用处理器一个核心的耗时计数,而时钟时间就是现实世界中的时间计数。</p><p>如果是单核单线程的场景下,这两者可以认为是等价的,但如果是多核环境下,同一个时钟时间内有多少处理器核心正在工作,就会有多少倍的处理器时间被消耗和记录下来（即 user = coreNum * userTimePerCore、sys = coreNum * sysTimePerCore ）。</p><p>在垃圾收集调优时,我们主要依据real时间为目标来优化程序,因为最终用户只关心发出请求到得到响应所花费的时间,也就是响应速度,而不太关心程序到底使用了多少个线程或者处理器来完成任务。</p><h3 id="一些JDK9前后的例子"><a class="header-anchor" href="#一些JDK9前后的例子">¶</a>一些JDK9前后的例子</h3><h4 id="例1：打印GC基本信息"><a class="header-anchor" href="#例1：打印GC基本信息">¶</a>例1：打印GC基本信息</h4><p>在JDK 9之前使用<code>-XX:+PrintGC</code>,JDK 9后使用<code>-Xlog:gc</code></p><h4 id="例2：打印详细GC信息"><a class="header-anchor" href="#例2：打印详细GC信息">¶</a>例2：打印详细GC信息</h4><p>在JDK 9之前使用<code>-XX:+PrintGCDetails</code>,在JDK 9之后使用<code>-Xlog:gc*</code>, 用通配符<code>*</code>将GC标签下所有细分过程都打印出来,如果把日志级别调整到Debug或者Trace(基于版面篇幅考虑,例子中并没有),还将获得更多细节信息</p><h4 id="例3：打印GC前后的堆、方法区容量"><a class="header-anchor" href="#例3：打印GC前后的堆、方法区容量">¶</a>例3：打印GC前后的堆、方法区容量</h4><p>在JDK 9之前使用<code>-XX:+PrintHeapAtGC</code>,JDK 9之后使用<code>-Xlog:gc+heap=debug</code></p><h4 id="例4：查看GC过程中用户线程并发时间以及停顿的时间"><a class="header-anchor" href="#例4：查看GC过程中用户线程并发时间以及停顿的时间">¶</a>例4：查看GC过程中用户线程并发时间以及停顿的时间</h4><p>在JDK 9之前使用<code>-XX:+PrintGCApplicationConcurrentTime</code>以及<code>-XX:+PrintGCApplicationStoppedTime</code>, JDK 9之后使用<code>-Xlog:safepoint</code></p><h4 id="例5：查看收集器Ergonomics机制"><a class="header-anchor" href="#例5：查看收集器Ergonomics机制">¶</a>例5：查看收集器Ergonomics机制</h4><p>即自动设置堆空间各分代区域大小、收集目标等内容。从Parallel收集器开始支持自动调节的相关信息。在JDK 9之前使用<code>-XX:+PrintAdaptiveSizePolicy</code>,JDK 9之后使用<code>-Xlog:gc+ergo*=trace</code></p><h4 id="例6：查看熬过收集后剩余对象的年龄分布信息"><a class="header-anchor" href="#例6：查看熬过收集后剩余对象的年龄分布信息">¶</a>例6：查看熬过收集后剩余对象的年龄分布信息</h4><p>在JDK 9前使用<code>-XX:+PrintTenuringDistribution</code>, JDK 9之后使用<code>-Xlog:gc+age=trace</code></p><h3 id="JDK9中废弃的日志参数及替换列表"><a class="header-anchor" href="#JDK9中废弃的日志参数及替换列表">¶</a>JDK9中废弃的日志参数及替换列表</h3><p>[参考](file:///Users/zhonghongpeng/笔记/jvm/尚硅谷/附录.md)</p><h2 id="补充说明"><a class="header-anchor" href="#补充说明">¶</a>补充说明</h2><h4 id="GC日志打印组成"><a class="header-anchor" href="#GC日志打印组成">¶</a>GC日志打印组成</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000354.png" alt="image-20200918172138361"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000401.png" alt="image-20200918172208169"></p><h4 id="堆空间输出组成"><a class="header-anchor" href="#堆空间输出组成">¶</a>堆空间输出组成</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000408.png" alt="image-20200918172252516"></p><h4 id="Minor-GC日志组成"><a class="header-anchor" href="#Minor-GC日志组成">¶</a>Minor GC日志组成</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000416.png" alt="image-20200918172424412"></p><h4 id="Full-GC日志组成"><a class="header-anchor" href="#Full-GC日志组成">¶</a>Full GC日志组成</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000422.png" alt="image-20200918172534060"></p><h2 id="日志分析工具"><a class="header-anchor" href="#日志分析工具">¶</a>日志分析工具</h2><p>可以配合<code>-X1oggc</code>输出日志然后用一些工具去分析这些GC日志。</p><p>常用的日志分析工具有：<a href="https://github.com/chewiebug/GCViewer" target="_blank" rel="noopener">GCViewer</a>、<a href="https://gceasy.io/" target="_blank" rel="noopener">GCEasy</a>、GCHisto、GCLogViewer、Hpjmeter、garbagecat等。</p><h1>垃圾回收器的新发展</h1><p>GC仍然处于飞速发展之中,目前的默认选项G1 GC在不断的进行改进,很多我们原来认为的缺点,例如串行的Full GC、 Card Table扫描的低效等,都已经被大幅改进, 例如, JDK10以后, Full GC已经是并行运行,在很多场景下,其表现还略优于 Parallel GC的并行Full GC实现。</p><p>即使是 Serial GC,虽然比较古老,但是简单的设计和实现未必就是过时的,它本身的开销,不管是GC相关数据结构的开销,还是线程的开销,都是非常小的,所以随着云计算的兴起,在 Serverless等新的应用场景下, Serial GC找到了新的舞台。</p><p>比较不幸的是 CMS GC,因为其算法的理论缺陷等原因,虽然现在还有非常大的用户群体,但在JDK9中已经被标记为废弃,并在JDK14版本中移除。</p><h2 id="JDK11新特性"><a class="header-anchor" href="#JDK11新特性">¶</a>JDK11新特性</h2><ul><li><p><a href="http://openjdk.java.net/jeps/318" target="_blank" rel="noopener">JEP318</a></p><p>Epsilon：A No-Op Garbage Collector(Epsilon 垃圾回收器，&quot;No-Op&quot;无操作回收器)</p></li><li><p>JEP333</p><p>ZGC(JDK11)：A Scalable Low-Latency Garbage Collector(Experimental)（ZGC：可伸缩的低延迟垃圾回收器，处于实验性阶段）</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000429.png" alt="image-20200918174255760"></p><h2 id="Open-JDK12：Shenandoah"><a class="header-anchor" href="#Open-JDK12：Shenandoah">¶</a>Open JDK12：Shenandoah</h2><p>Open JDK12的Shenandoah GC：低停顿时间的GC(实验性)。<br>Shenandoah,无疑是众多GC中最孤独的一个。是第一款不由 Oracle公司团队领导开发的 HotSpot垃圾收集器。不可避免的受到官方的排挤。比如号称 OpenJDK和 OracleJDK没有区别的Oracle公司仍拒绝在Oracle JDK12中支持 Shenandoah。</p><p>Shenandoah垃圾回收器最初由RedHat进行的一项垃圾收集器研究项目 PauselessGC 的实现,旨在针对JVM上的内存回收实现低停顿的需求。在2014年贡献给 OpenJDK.</p><p>Red Hat研发团队对外宣称, <strong>Shenandoah垃圾回收器的暂停时间与堆大小无关</strong>,这意味着无论将堆设置为200MB还是200GB,99.9%的目标都可以把垃圾收集的停顿时间限制在十毫秒以内。不过实际使用性能将取决于实际工作堆的大小和工作负载。</p><h3 id="Shenandoah开发团队在实际应用中的测试数据"><a class="header-anchor" href="#Shenandoah开发团队在实际应用中的测试数据">¶</a>Shenandoah开发团队在实际应用中的测试数据</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000437.png" alt="image-20200918175024741"></p><p>这是 RedHat在2016年发表的论文数据,测试内容是使用ES对200GB的维基百科数据进行索引。从结果看:</p><ul><li>停顿时间比其他几款收集器确实有了质的飞跃,但也未实现最大停顿时间控制在十毫秒以内的目标。</li><li>而吞吐量方面出现了明显的下降,总运行时间是所有测试收集器里最长的。</li></ul><h3 id="总结-v2"><a class="header-anchor" href="#总结-v2">¶</a>总结:</h3><ul><li>Shenandoah GC的弱项:高运行负担下的吞吐量下降。</li><li>Shenandoah GC的强项:低延迟时间。</li></ul><p>Shenandoah GC的工作过程大致分为九个阶段，参考<a href="https://www.bilibili.com/video/BV1jJ411M7kQ?from=search&amp;seid=12339069673726242866" target="_blank" rel="noopener">JDK12新特性</a>。</p><h2 id="ZGC"><a class="header-anchor" href="#ZGC">¶</a>ZGC</h2><p><a href="https://docs.oracle.com/en/java/javase/12/gctuning/" target="_blank" rel="noopener">https://docs.oracle.com/en/java/javase/12/gctuning/</a></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000443.png" alt="image-20200918175746290"></p><ul><li><p>ZGC与 Shenandoah目标高度相似,在尽可能对吞吐量影响不大的前提下, 实现在任意堆内存大小下都可以把垃圾收集的停顿时间限制在十毫秒以内的低延迟。</p></li><li><p>《深入理解Java虚拟机》一书中这样定义ZGC：</p><p>ZGC收集器是一款基于 Region内存布局的,(暂时)不设分代的,使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记压缩算法的,以低延迟为首要目标的一款垃圾收集器。</p></li><li><p>ZGC的工作过程可以分为4个阶段:并发标记-并发预备重分配并发重分配并发重映射等。</p></li><li><p>ZGC几乎在所有地方并发执行的,除了初始标记的是STW的。所以停顿时间几乎就耗费在初始标记上,这部分的实际时间是非常少的。</p></li></ul><h3 id="测试数据"><a class="header-anchor" href="#测试数据">¶</a>测试数据</h3><h4 id="吞吐量"><a class="header-anchor" href="#吞吐量">¶</a>吞吐量</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000450.png" alt="image-20200918175941331"></p><h4 id="延时"><a class="header-anchor" href="#延时">¶</a>延时</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000458.png" alt="image-20200918180107249"></p><p>虽然ZGC还在试验状态，没有完成所有特性，但此时性能已经相当亮眼，用&quot;令人震惊、革命性&quot;来形容，不为过。未来将在服务端、大内存、低延迟应用的首选垃圾收集器。</p><h3 id="ZGC的JDK14新特性"><a class="header-anchor" href="#ZGC的JDK14新特性">¶</a>ZGC的JDK14新特性</h3><ul><li>JEP364:ZGC应用 macos在上</li><li>JEP365:ZGC应用 Windows在上</li></ul><p>JDK14之前,ZGC仅 Linux才支持。尽管许多使用ZGC的用户都使用类Linux的环境,但在 Windows和 macos上,人们也需要ZGC进行开发部署和测试。许多桌面应用也可以从ZGC中受益。因此,ZGC特性被移植到了 Windows和 macos上。</p><p>现在mac或Windows上也能使用ZGC了,示例如下:</p><ul><li><p><code>-XX:+UnlockExperimentalVMOption</code></p></li><li><p><code>-XX:+UseZGC</code></p></li></ul><h2 id="其他垃圾回收器"><a class="header-anchor" href="#其他垃圾回收器">¶</a>其他垃圾回收器</h2><h3 id="AliGC"><a class="header-anchor" href="#AliGC">¶</a>AliGC</h3><p>AliGC是阿里巴巴JVM团队基于G1算法，面向大堆（LargeHeap）应用场景。指定场景下的对比：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222000506.png" alt="image-20200918180601848"></p><h3 id="其他"><a class="header-anchor" href="#其他">¶</a>其他</h3><p>当然,其他厂商也提供了各种独具一格的GC实现, 例如比较有名的低延迟GC, <a href="https://www.infoq.com/articles/azul_gc_in_detail" target="_blank" rel="noopener">Zing</a>,</p><h1>参考阅读</h1><p><a href="https://www.infoq.cn/article/3WyReTKqrHIvtw4frmr3" target="_blank" rel="noopener">infoq：一文看懂 JVM 内存布局及 GC 原理</a></p><p><a href="https://juejin.im/post/6844903953004494856#heading-6" target="_blank" rel="noopener">掘金：老大难的GC原理及调优，这下全说清楚了</a></p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>应用程序的引用赋值语句 object field= object，JVM会在之前和之后执行特殊的错左以在dirty card queue中入队一个保存了对象引用信息的card在年轻代回收的时候,G1会对 Dirty Card Queue 中所有的card进行处理,更新RSet,保证RSet实时准确的反映引用关系 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
      
      
      <categories>
          
          <category> JVM学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>012_kibana</title>
      <link href="/2020/12/22/elasticsearch/012-kibana/"/>
      <url>/2020/12/22/elasticsearch/012-kibana/</url>
      
        <content type="html"><![CDATA[<h1>一、使用 Index Pattern 配置数据</h1><p>在 Kibana 中，对于索引数据的操作基本都围绕着 Index Pattern 展开，下面我们来做个演示。</p><h3 id="初始化数据"><a class="header-anchor" href="#初始化数据">¶</a>初始化数据</h3><p>我们先初始化三个索引数据，因为这三个 index 里面都含有一个类型为地理位置类型的字段，所以需要手动设置，如果使用 dynamic mapping 会被识别为 text。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">PUT /logstash-2015.05.18{  "mappings": {    "properties": {      "geo": {        "properties": {          "coordinates": {            "type": "geo_point"          }        }      }    }  }}PUT /logstash-2015.05.19{  "mappings": {    "properties": {      "geo": {        "properties": {          "coordinates": {            "type": "geo_point"          }        }      }    }  }}PUT /logstash-2015.05.20{  "mappings": {    "properties": {      "geo": {        "properties": {          "coordinates": {            "type": "geo_point"          }        }      }    }  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后我们分别从本地请求导入一些测试文档数据到 ES</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">curl -H 'Content-Type: application/x-ndjson' -XPOST 'myecs.com:9200/_bulk?pretty' --data-binary @logs.jsoncurl -H 'Content-Type: application/x-ndjson' -XPOST 'myecs.com:9200/bank/account/_bulk?pretty' --data-binary @accounts.json<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="创建-index-pattern"><a class="header-anchor" href="#创建-index-pattern">¶</a>创建 index pattern</h3><h4 id="logs-数据的-index-pattern"><a class="header-anchor" href="#logs-数据的-index-pattern">¶</a>logs 数据的 index pattern</h4><p>我们来到 Index Pattern 的界面，可以看到已经有一些 index pattern 已经创建好了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223709.png" alt="image-20200503224338616"></p><p>然后我们为我们刚刚创建的三个索引创建一个 Index pattern，我们通过一个通配符命名的方式将我们刚刚创建的三个索引都匹配到我们准备创建的 Index Pattern 中，点击 next</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223737.png" alt="image-20200503224312640"></p><p>然后 ES 会要求我们选择一个字段作为数据的一个时间戳（因为我们的索引中定义了多个时间戳类型的字段，所以要指定一个，点击下拉框会下拉出所有时间戳字段，其中也有一个选项是不选用时间戳字段），然后点击 create</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223752.png" alt="image-20200503224448322"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223802.png" alt="image-20200503224509496"></p><p>可以看到我们的 index pattern 就被创建出来了，下图是界面中一些按钮的介绍</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223826.png" alt="image-20200503225212773"></p><p>其中我们还看到一个&quot;格式&quot;一列，它定义了Kibana 会以什么样的格式来显示这个字段，点击编辑按钮可以对格式进行编辑。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223843.png" alt="image-20200503224807630"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223920.png" alt="image-20200503224929701"></p><h4 id="银行数据的-index-pattern"><a class="header-anchor" href="#银行数据的-index-pattern">¶</a>银行数据的 index pattern</h4><p>然后我们再对导入的另外一个银行文档数据创建 index pattern</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223935.png" alt="image-20200503225411235"></p><p>因为银行数据中不包含任何时间戳类型字段，所以Kibana 没有显示需要我们选择一个作为时间排序过滤数据的字段</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221224653.png" alt="image-20200503225515393"></p><h1>二、使用 Kibana Discover 探索数据</h1><p>首先我们选择左边面板的 discovery 按钮进入 discovery 的模块。然后选择我们前面创建的&quot;logstash-*&quot;的 index pattern，默认显示的是最近15分钟的数据，而这些数据都是很久之前的了，所以没有数据显示。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221224038.png" alt="image-20200503225727849"></p><p>选择10年以前的数据</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221224129.png" alt="image-20200503230032573"></p><p>可以看到出来了一些数据，但是柱子区间太大</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221224300.png" alt="image-20200503230217633"></p><p>通过选中这个柱子对他放大，可以看到这些数据都是几种在2015-05-19到05-21这三天</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221224459.png" alt="image-20200503230236775"></p><p>直方图下面显示的就是我们选中的直方图范围中的详细文档数据</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221224513.png" alt="image-20200503231402075"></p><p>另外我们点开每一条文档数据就可以看到它的详细内容，其中它分为了表格的显示方式和 JSON 的显示方式</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221224809.png" alt="image-20200503231452474"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221224837.png" alt="image-20200503231531763"></p><p>其中以表格形式显示的时候，每个字段前面都会有4个功能按钮</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221224910.png" alt="image-20200503231714915"></p><ul><li><p>第一个按钮：将当前字段匹配当前值作为筛选条件，过滤出满足的数据</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221224923.png" alt="image-20200503232201675"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221224936.png" alt="image-20200503232231898"></p></li><li><p>第二个按钮：将当前字段不匹配当前值作为筛选条件，过滤出满足的文档</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221224951.png" alt="image-20200503232259824"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232218.png" alt="image-20200503232322812"></p></li><li><p>第三个按钮：将当前字段作为显示列字段</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225017.png" alt="image-20200503232350120"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232247.png" alt="image-20200503232441530"></p></li><li><p>第四个按钮：过滤出当前字段必须有值的文档</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225029.png" alt="image-20200503232506283"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232310.png" alt="image-20200503232517911"></p></li></ul><p>另外我们可以直接添加一个 filter 进行文档数据的筛选</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225051.png" alt="image-20200503232612349"></p><p>我们再来看一下左边的菜单栏</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225106.png" alt="image-20200503232831397"></p><p>当我们鼠标悬浮到某个可用字段上会出现一个&quot;添加&quot;的按钮，点击添加也会将这个字段添加到展示列表的字段</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225118.png" alt="image-20200503232932307"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225131.png" alt="image-20200503232947307"></p><p>现在我们选择查看一个 memory 字段，发现显示的数值不是那么友好，这时候我们就可以使用前面介绍的 index pattern 中的字段的格式了</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225147.png" alt="image-20200503233120634"></p><p>来到字段编辑页面，进行编辑</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225158.png" alt="image-20200503233327260"></p><p>再回到 discovery 的界面，可以看到为我们显示了单位</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225210.png" alt="image-20200503233418357"></p><p>另外我们还可以直接点击左边菜单栏的字段，就会显示这个字段的一些文档的聚合分析信息</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225226.png" alt="image-20200503233514032"></p><h1>三、基本可视化组件</h1><p>可视化其实就是对一下数据的聚合分析形成一个直观可视的图表。</p><p>我们先点击面板左边的可视化。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225242.png" alt="image-20200504071558951"></p><p>可以看到 kibana 中已经生成了一些可视化的图表，包括它自带的三个样例测试数据集以及我们之前导进去的 metricbeat 的 dashboard。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225255.png" alt="image-20200504072103707"></p><p>我们基于我们刚刚导入的两份数据来分别创建一些可视化图表，下面先来创建一个饼图：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225318.png" alt="image-20200504072354301"></p><p>点击后会让我们选择 index pattern，我们搜索选择我们之前导入的&quot;bank*&quot;：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225333.png" alt="image-20200504072458833"></p><p>创建好后就进来了一个可视化界面，可以看到，左边比较显眼的有&quot;指标&quot;和&quot;存储桶&quot;两个模块，它们分别就是 Metric 和 Bucket，右边就是一个默认的饼图，没有分桶下的所有数据条数。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225349.png" alt="image-20200504072749206"></p><p>先选择metric，选择计数</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225401.png" alt="image-20200504073322011"></p><p>bucket分了两种类型：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225414.png" alt="image-20200504073357960"></p><p>我们先看第一种：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225425.png" alt="image-20200504073446282"></p><p>选择直方图</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225439.png" alt="image-20200504073504054"></p><p>选择字段和直方图的间隔，点击上面的执行后就能看到根据我们的分桶逻辑对一个饼图进行了数据划分。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225451.png" alt="image-20200504073633502"></p><p>我们上面是对人们的余额的多少做了一个直方图，我们还能进行嵌套，例如35000到40000的区间下男和女分别是多少人。</p><p>先选择添加子存储桶：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225507.png" alt="image-20200504073855815"></p><p>可以看到外面又出来了一层</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225522.png" alt="image-20200504074040282"></p><p>这个按钮是可以暂时禁用聚合的</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225534.png" alt="image-20200504074111884"></p><p>这个是拖拽修改优先级</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225549.png" alt="image-20200504074129033"></p><p>右边的饼图还能通过点击进行颜色自定义</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225600.png" alt="image-20200504074206626"></p><p>下面是左边 bucket 中第二种桶的具体逻辑，可以看到它们是按照我们的分桶逻辑对图表进行了分桶，上面是在一个图表种对数据进行分桶：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225613.png" alt="image-20200504074317733"></p><p>上面一栏搜索栏可以对我们需要聚合的数据范围进行筛选：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225634.png" alt="image-20200504074939019"></p><p>这里的选项可以对图表的一些属性进行设置：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225657.png" alt="image-20200504074417701"></p><p>另外我们知道这些数据都是通过请求一个 api 获取的，我们可以通过上面的检查按钮来查看我们的 request、response 等等的数据：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225710.png" alt="image-20200504074515780"></p><p>最后我们配置了一个 count 的 metric 和一个基于性别的拆分图表的桶和一个子的基于银行余额的拆分数据的直方图的桶，点击保存：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225724.png" alt="image-20200504074826097">Markdown: Open Preview to the Side</p><p>输入名称</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225737.png" alt="image-20200504074909167"></p><p>再次来到可视化的列表页，就能搜索到我们保存的&quot;我的饼图&quot;拉</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225752.png" alt="image-20200504075048142"></p><p>其他的组件大同小异，有时间再看。</p><h1>四、构建 Dashboard</h1><p>dashboard 中其实就是一组可视化组件的集合。我们可以用我们前面介绍的可视化构建出多个可视化图表并全部整合到一个 dashboard 中。</p><p>选择左边面板的仪表板，进到 dashboard 界面：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225804.png" alt="image-20200504075306606"></p><p>添加我们刚刚创建的饼图，另外还可以通过中间的超链接点击到可视化组件界面进行可视化图表创建</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225817.png" alt="image-20200504075544206"></p><p>右边弹出一个弹窗，点击我们保存的可视化组件的名字即可添加到了 dashboard</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225832.png" alt="image-20200504075718574"></p><p>我们还能对这个图表做以下操作</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225846.png" alt="image-20200504075927994"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225856.png" alt="image-20200504075959750"></p><p>点击保存，即可对我们的dashboard 进行保存。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225909.png" alt="image-20200504080043086"></p><h3 id="官方自带的测试样例"><a class="header-anchor" href="#官方自带的测试样例">¶</a>官方自带的测试样例</h3><p>另外我们还可以参考官方开箱即用的3个测试数据集：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225920.png" alt="image-20200504080210996"></p><p>其中一个 dashboard</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225929.png" alt="image-20200504080232164"></p><p>这些都是很专业的图表，我们可以进行参考，同时我们还能直接修改这些图表。</p><h1>五、在 Kibana 中探索 X-Pack 套件</h1><h3 id="1-用-Monitoring-和-Alerting-监控-Elasticsearch-集群"><a class="header-anchor" href="#1-用-Monitoring-和-Alerting-监控-Elasticsearch-集群">¶</a>&lt;1&gt;用 Monitoring 和 Alerting 监控 Elasticsearch 集群</h3><p>X-pack 提供了免费的监控 Elasticsearch 集群和 Kibana 的功能。默认的定时检查时间间隔是10秒，可以通过<code>Xpack.monitoring.collection.interval</code>来配置。</p><p>下面是 Monitoring的一些配置</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225942.png" alt="image-20200504081205333"></p><p>详细可以参考：<a href="https://www.elastic.co/guide/en/x-pack/current/monitoring-settings.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/x-pack/current/monitoring-settings.html</a></p><p>在生产环境中，建议搭建 dedicated 集群用于 ES 集群的监控。有以下好处：</p><ul><li>减少负载和数据</li><li>当被监控集群出现问题，还能看到监控相关的数据</li></ul><p>另外，X-pack 中还有报警的功能，但是这个是需要 Gold 账户的。这个功能叫 Watcher for Alerting，一个 Watcher 由5个部分组成：</p><ul><li>Trigger：多久被触发一次（例如：5分钟触发一次）</li><li>Input：查询条件（在所有日志索引中查看&quot;ERROR&quot;相关）</li><li>condition：查询是否满足条件（例如：大于1000条返回）</li><li>Actions：执行相关操作（例如：发送邮件）</li></ul><h4 id="Demo"><a class="header-anchor" href="#Demo">¶</a>Demo</h4><p>我们点击左边面板中的&quot;堆栈检测&quot;，可以看到默认情况下 X-Pack 的 monitoring 功能是关闭的，我们打开它：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221225957.png" alt="image-20200504081548396"></p><p>几秒的搜集数据之后，就进入了一个总览界面，分别有 ES 的总览级别的监测、节点级别的监测、索引级别的监测以及 Kibana 的总览级别的监测和实例级别的监测，我们分别进入查看一下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230011.png" alt="image-20200504081800336"></p><ol><li><p>ES 的总览监测</p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230036.png" alt="image-20200504081932283" style="zoom:50%;"></li><li><p>ES 的节点监测</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230100.png" alt="image-20200504082009995"></p><p>点击节点名称进入详细监控界面，下面是详细界面的概览部分</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230111.png" alt="image-20200504082109646"></p><p>下面是高级部分</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230124.png" alt="image-20200504082130869"></p></li><li><p>ES 索引级别监控</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230143.png" alt="image-20200504082212532"></p><p>点击具体的索引名称进入详细监控界面，同样分了概览和高级</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230218.png" alt="image-20200504082249079"></p></li><li><p>这里还有一个 CCR(Cross Cluster Replitaion) 跨集群备份的监控</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230256.png" alt="image-20200504082420038"></p></li><li><p>Kibana 概览级别监控</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230510.png" alt="image-20200504082455102"></p></li><li><p>Kibana 实例级别监控</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230525.png" alt="image-20200504082517433"></p><p>同样点击实例名称进入详细界面</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230543.png" alt="image-20200504082711739"></p></li></ol><p>上面是关于 monitoring 的介绍，下面介绍 alerting 的功能，因为 alerting 是收费的，所有我们要先开启试用：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230628.png" alt="image-20200504082935647"></p><p>可以看到这里多了一个 watcher 的选项，我们点击：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230648.png" alt="image-20200504083012456"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230711.png" alt="image-20200504083054867"></p><p>我们尝试创建一个&quot;阈值告警&quot;：</p><p>当我们选择一个&quot;bank*&quot;索引进行监听的时候，发现提示索引没有关联的时间字段，因为我们这个索引里面确实没有时间戳类型字段，而我们在kibana创建index pattern 的时候也就没有指定时间字段，而这里的&quot;阈值告警&quot;是指定一个过去的时间区间内如果文档数量超过了多少的数值就会发出一个怎样的告警。所以对于&quot;bank*&quot;这个索引，&quot;阈值告警&quot;就做不了了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230733.png" alt="image-20200504083318159"></p><p>我们选择一个有时间戳的索引</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230759.png" alt="image-20200504084151178"></p><p>另外我们还能创建一个高级的 alerting，通过一个 JSON 配置，还能点击&quot;语法&quot;来查看具体的参数等等。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230830.png" alt="image-20200504084241390"></p><h3 id="2-用-APM-进行程序性能监控"><a class="header-anchor" href="#2-用-APM-进行程序性能监控">¶</a>&lt;2&gt;用 APM 进行程序性能监控</h3><p>APM 顾名思义就是 Application Performance Monitoring，是 Elastic 公司开发的一个用来监控应用程序的工具。它提供了以下的监控能力：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230848.png" alt="image-20200504094017576"></p><p>包括用户行为监控、程序级别的监控、服务器级别的监控以及日志监控。</p><p>APM 核心功能：请求响应时间监控、未处理的错误及异常监控、可视化调用关系、帮助用户发现性能瓶颈、代码下钻等。</p><p>官方网址：<a href="https://www.elastic.co/cn/apm" target="_blank" rel="noopener">https://www.elastic.co/cn/apm</a></p><p>我们可以可以到官网上去查看 APM 的一些详细的信息。它主要是通过一个 APM Agent 内嵌到应用程序中，然后配置 APM Agent的服务端连接信息，APM Agent 就会定时地收集应用程序的一些指标发送到 APM Server，APM Server 负责将收到地数据写入到 Elasticsearch，我们就可以试用 Kibana 来分析这些数据了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221230929.png" alt="image-20200504102643258"></p><p>而在 Kibana 中我们可以对应用程序构建出一个很好地可视化组件，并构建自己的专有的 dashboard，另外还可以试用机器学习来监测异常响应时间，还可以通过 Alerting 功能对监测到的异常进行告警。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231014.png" alt="image-20200504102930443"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231034.png" alt="image-20200504102942660"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231050.png" alt="image-20200504103001043"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231204.png" alt="image-20200504103208671"></p><h4 id="APM-的使用"><a class="header-anchor" href="#APM-的使用">¶</a>APM 的使用</h4><p>现在我们来看下具体怎么构建一个 Java 程序的 APM 的环境。（详细步骤参考官网的最下面）</p><h5 id="1、Elasticsearch-Kibana"><a class="header-anchor" href="#1、Elasticsearch-Kibana">¶</a>1、Elasticsearch &amp; Kibana</h5><p>首先我们在构建 APM 之前保障 Elasticsearch 和 Kibana 服务都已经构建好了。官网中提供了 Hosted 和 Download 的两种不同方案：Hosted 其实指的是我们的 ELasticsearch 和 Kibana 是基于 ELastic cloud 方案构建的；Download 其实指的是我们自己下载了 Elasticsearch 和 Kibana 在自己的服务器中进行了构建。我们选择后者，因为我们已经安转部署好 ES 集群和 Kibana 实例了。</p><h5 id="2、下载-APM-Server-并安装"><a class="header-anchor" href="#2、下载-APM-Server-并安装">¶</a>2、下载 APM Server 并安装</h5><p>到 <a href="https://www.elastic.co/cn/downloads/apm" target="_blank" rel="noopener">链接</a> 中下载对应版本的 APM Server。然后上传到指定服务器，并解压下载下来的压缩包。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z elasticsearch]# cd apm-server-7.1.0-linux-x86_64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果你的ES 集群(localhost:9200)和 Kibana (localhost:5601)都是是运行在默认的 hosts 上的，那么就无需在<code>apm-server.yml</code>中进行相关配置了，直接启动 apm sever</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z apm-server-7.1.0-linux-x86_64]# ./apm-server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后我们进入 Kibana，点击左边面板中的 APM，进入到 APM 的管理面板，可以看到面板中还没有任何数据，我们点击右上角的&quot;设置说明&quot;：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231230.png" alt="image-20200504111721539"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231249.png" alt="image-20200504112041032"></p><p>进入到设置说明界面后，可以看到在这里也有关于 APM 服务构建的详细说明，包括我们要先下载 APM Server 并配置后启动，并通过点击&quot;检查 APM Server 状态&quot;来确认 APM Server 是否运行。我们点击检查，可以看到我们的 APM Server 是正常启动的了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231302.png" alt="image-20200504112152920"></p><h5 id="3、在应用程序中配置-APM-代理"><a class="header-anchor" href="#3、在应用程序中配置-APM-代理">¶</a>3、在应用程序中配置 APM 代理</h5><p>在上述的 APM Server 正确启动之后，我们下一步就是设置我们的应用程序中的 APM Agent 了，这个在 Kibana 的&quot;设置说明&quot;也是有介绍的：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231329.png" alt="image-20200504112311452"></p><ol><li><p>首先我们需要从 <a href="http://search.maven.org/#search%7Cga%7C1%7Ca%3Aelastic-apm-agent" target="_blank" rel="noopener">Maven Central</a> 中下载 APM 的 Java Agent 的 jar 包。</p></li><li><p>启动自己的 Java 应用程序（现在一般都是 spring boot 应用），并添加以下 JVM 参数来分别指定我们下载的 APM Agent jar 包路径、apm的服务名称(应该是在 apm 显示界面中当前启动应用程序的显示名称)、apm服务的连接(就是我们启动的apm 服务)、apm 服务的 token、apm 服务需要监测的Java 程序的包路径：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">java -javaagent:/path/to/elastic-apm-agent-<version>.jar \ -Delastic.apm.service_name=my-application \ -Delastic.apm.server_url=http://localhost:8200 \ -Delastic.apm.secret_token= \ -Delastic.apm.application_packages=org.example \ -jar my-application.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>其他的详细参数可以参考<a href="https://www.elastic.co/guide/en/apm/agent/java/current/index.html" target="_blank" rel="noopener">文档</a>。</p><ol start="3"><li><p>在启动我们的 Java 程序之后，点击&quot;检查代理状态&quot;来查看我们的应用程序是否正常运行并且agent 也正常地工作了(有时候是需要应用程序产生了一次具体地调用才能被监测到代理状态正常)。<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231408.png" alt="image-20200504113947106"></p></li><li><p>在监测到代理对象正常工作之后，我们可以试用一些压测工具或者一些测试脚本使得应用程序在产生持续地调用，此时我们再回到 Kibana 的 APM 的界面<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231418.png" alt="image-20200504114248627">可以看到，在 Services 一栏下面已经有了一个&quot;my_application&quot;的 service，它就是我们刚刚启动的 Java 应用中通过<code>-Delastic.apm.service_name</code>指定的名称。<br>我们对其进行点击，就可以进入到这个应用程序监测的详情页面了<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231431.png" alt="image-20200504114622149">我们可以看到在下面有两个<code>MainCotroller#getAllUsers</code>和<code>MainController#addNewUser</code>的方法。我们分别点入这两个方法，就可以看到对于这个方法调用的具体监测信息了：<br>包括一些 transaction 的信息，还有一些请求响应的时间消耗<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231443.png" alt="image-20200504115049889"></p><p>我们看到下面还提供了关于 Transaction 的详细信息，包括整个调用链各阶段的消耗时间以及数据库的一些调用的操作</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231457.png" alt="image-20200504115308785"><br>还能查看操作数据库的时候的一些详细的 sql 以及其他信息</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231509.png" alt="image-20200504115502831"><br>我们还能查看一些 HTTP 的详细信息（包含请求连接、请求头、请求体等）、还有 Service 的一些信息，Process 的信息等等。</p></li><li><p>另外我们还可以在 Kibana 的 APM 面板的最后一行&quot;加载 Kibana 对象&quot;来设置该 APM 相关的 Kibana  对象（可视化组件、dashboard 等）从而构建更好的监测结果展示。</p></li></ol><h5 id="4、小结"><a class="header-anchor" href="#4、小结">¶</a>4、小结</h5><p>可以看到，APM 的功能还是很强大的，我们在实际应用中结合一些压测工具就可以很好地对我们的程序进行一个压力测试的操作。另外，对于 Java 应用程序来说，最近比较火的一个链路跟踪组件是 SkyWalking，以后有机会可以比较一下。</p><h3 id="3-用机器学习实现时序数据的异常检测"><a class="header-anchor" href="#3-用机器学习实现时序数据的异常检测">¶</a>&lt;3&gt;用机器学习实现时序数据的异常检测</h3><p>X-Pack 中的收费功能。它的应用场景就是去解决一些基于规则或者使用 Dashboard 难以实时发现的问题。</p><ul><li>在 IT 运维领域，如何知道系统正常运行、如何自动调节阈值触发合适的报警、当问题发生的时候如何进行归因分析。</li><li>在信息安全领域，我们也想及时地知道哪些用户构成了威胁、系统是否感染了病毒。</li><li>在物联网领域，很多时候我们需要管理很多的设备，我们怎么得知工厂和设备是否正常运营，如何发现设备中的潜在问题。</li></ul><p>以上场景当中，机器学习都能帮助我们实现我们的工作，及时发现一些问题。</p><p>我们先看两个基础概念：正常和异常。</p><h4 id="正常"><a class="header-anchor" href="#正常">¶</a>正常</h4><p>正常主要分下面两种情况：</p><ul><li>随着时间的推移，某个个体一直表现出一致的行为</li><li>某个个体和他的同类比较，一致表现出和其他个体一致的行为</li></ul><h4 id="异常"><a class="header-anchor" href="#异常">¶</a>异常</h4><p>异常主要分为下面两种情况：</p><ul><li>和自己比：个体的行为发生了急剧变化</li><li>和他人比：个体明显区别于其他的个体</li></ul><p>下面是两个异常的例子：<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231530.png" alt="异常1"><br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231541.png" alt="异常2"></p><p>上面的两个异常的例子都是很好的识别的，但是有一些异常的例子却需要一定的指导才能发现：<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231555.png" alt="异常3"><br>参考上图，如果没有给出具体的指标我们是很难得出哪条狗是不正常的，如果我们说不吐舌头是正常，吐舌头是异常，那么就可以得出一个结果；如果我们说站着是正常的，坐着是异常的，那么也可以得出一个结果。</p><h4 id="相关术语"><a class="header-anchor" href="#相关术语">¶</a>相关术语</h4><p><strong>机器学习</strong>是可以被运用到非常多的领域的，包括人脸识别等等，而Elastic 平台的机器学习功能主要针对时序数据的异常检测和预测。<br>Elastic 平台的机器学习是<strong>非监督机器学习</strong>，即不需要使用人工标签的数据来学习，仅仅依靠历史数据自动学习；同时它使用的还是<strong>贝叶斯统计</strong>方法，这是一种概率计算方法，使用先验结果来计算现值或者预测未来的数值。<br>在<strong>异常检测</strong>方面，异常代表的是不同的，但未必代表的是坏的（例如在双十一大促的时候订单量暴增，这在业务上是一件好事，但是此时系统和之前的状态是有着明显的不同的）；另外定义异常需要一些指导，从哪个方面去看(例如上面狗的例子)。</p><h4 id="如何学习-正常"><a class="header-anchor" href="#如何学习-正常">¶</a>如何学习&quot;正常&quot;</h4><p>我们观察正常可以从两个方面进行，一个是将现在的自己和过去的自己进行比较，另一个是将自己和群体中的其他个体进行比较。<br>举个例子，观察不同的人每天走路的步数，由此预测明天他会走多少步，但是观察不同的人，我们需要定义一个观察的时间，是一天、一周、一个月、一年还是十年，这个根据具体的业务情况来定。当然观察的数据越多，预测理论上是越准的。<br>这时候我们使用这些观察来创建一个模型，它其实是一个概率分布的函数，通过这个模型找出一些低概率出现的事件，其实它就是一个异常。<br>而机器学习就是帮助我们自动挑选模型，使用成熟的机器学习技术，挑选适合数据的更好的、更正确的统计模型。更好的模型等于更好的异常检测等于更少的误报和漏报。</p><h4 id="模型与学习周期"><a class="header-anchor" href="#模型与学习周期">¶</a>模型与学习周期</h4><p>我们在选择学习周期的时候需要尽量选择合适的周期，不然如果时间太长，会涉及到一些不需要的影响因素加入进来，导致结果的不准确；如果学习时间太短，结果也是过于&quot;随机&quot;，不准确。</p><h4 id="ES-机器学习Demo"><a class="header-anchor" href="#ES-机器学习Demo">¶</a>ES 机器学习Demo</h4><p>ES 提供了以下机器学习：<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231612.png" alt="ES 机器学习"></p><h5 id="single-metric"><a class="header-anchor" href="#single-metric">¶</a>single metric</h5><ol><li><p>来到 Kibana，点击左边面板中的 Machine Learning，然后点击右边的&quot;创建新作业&quot;按钮<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231626.png" alt="single metric1"></p></li><li><p>选择我们要进行机器学习的 index pattern，我们选择&quot;server-metrics&quot;<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231638.png" alt="single metric2"><br>然后再选择 single metric<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231651.png" alt="single metric3"><br>进入到以下界面之后，我们进行如界面中的设置<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231703.png" alt="single metric4"><br>这几个字段的意思是，该机器学习算法会对索引&quot;server-metrics&quot;全量数据做以下操作：每隔15分钟之内的数据取出来然后对 total 字段进行求和，然后将所有的间隔内数据的该字段之和来求出一个我们前面提到的概率分布函数模型，得出概率低的值，那么这些概率低的值对应的区间以及区间的数据就会被认为是&quot;异常&quot;的。</p></li><li><p>然后我们输入作业的名称，并选择创建作业<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231718.png" alt="single metric5"><br>这时候我们就可以看到 Elasticsearch 就会在后台帮助我们在计算了<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231730.png" alt="single metric6"><br>很快我们就能得到一个结果，点击 view result<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231742.png" alt="single metric7"><br>这时候我们就能得到一个时序图，时序图分为了两部分，上面较宽的部分显示的是&quot;放大图&quot;，下面较窄的显示的是&quot;缩略图&quot;，我们可以通过扩大缩小&quot;缩略图&quot;中的一个窗口来确定&quot;放大图&quot;中的内容。<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231753.png" alt="single metric8"><br>我们也可以点击界面上的每一个点，它们都代表一个异常的点<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231805.png" alt="single metric9"><br>同时在下面的 Anomalies 的模块中也显示了所有异常的点，按照异常的&quot;程度&quot;进行优先排序。我们点开其中一个点的详细信息，可以看到这个区间数据的具体情况，包括它和&quot;正常&quot;的值(total 字段的求和)的差距<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231817.png" alt="single metric10"></p></li><li><p>另外在右上角还有一个 forecast 的按钮，我们可以点击它使得 ES 的 ML 对于现有模型对未来的数据进行预测，我们预测2天的数据：<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231827.png" alt="single metric11"><br>可以看到，ES 给我们算出了未来2天的曲线（另外我们还可以通过勾选上面的3个 checkbox 取消或者显示其对应的内容的显示）<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231838.png" alt="single metric12"></p></li><li><p>点击&quot;Job Management&quot;回到 ML 的界面，我们通过以下动作进入到 job 的定制界面<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231850.png" alt="single metric13"><br>我们可以将这个 job 做一个链接，链接到 Dashboard 或者 Discover 的界面<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231901.png" alt="single metric14"><br>我们再回到 job management 的界面，然后点击 single metric viewer 再回到刚刚的&quot;single metric&quot;的计算结果界面：<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231911.png" alt="single metric15"><br>选择一个异常点，这时候我们发现多了一个我们前面定制的链接的名称&quot;single-anomaly&quot;，我们点击这个链接<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231936.png" alt="single metric16"><br>我们就可以直接跳转到 discovery 的界面了<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221231947.png" alt="single metric17"><br>然后我们在这个界面查看该异常点的具体的一些数据，例如我们看到以下的一个数据的 total 是负数，我们认为负数数据应该被忽略，它也不属于异常数据，所以我们应该要过滤出大于0的数据进行检查<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232000.png" alt="single metric18"><br>我们在 discovery 的条件搜索里加上&quot;total&gt;0&quot;的条件，并点击 update 按钮，然后保存为一个名为&quot;total gte 0&quot;的 query，然后不再选择 “server-metrics” index pattern 而是基于这个 query 重新创建一个 ML Single Metric Job 进行一个学习，这样我们就可以基于一个新的准确的数据集进行异常检测。<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232012.png" alt="single metric19"><br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232027.png" alt="single metric20"><br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232039.png" alt="single metric21"></p></li></ol><h5 id="multi-metric-populate-metric"><a class="header-anchor" href="#multi-metric-populate-metric">¶</a>multi metric &amp; populate metric</h5><p><a href="https://time.geekbang.org/course/detail/100030501-142415" target="_blank" rel="noopener">https://time.geekbang.org/course/detail/100030501-142415</a></p><ol><li>讲了 multi metric 的案例，多个指标（字段）数据的机器学习来实现异常检测，就是比 single metric 支持更多字段的学习</li><li>populate metric 和 single metric、multi metric 的区别在于后两者的区间数据是由一个时间区间来划分的，例如以15分钟为一个间隔的数据作为一个分析单元，而 populate metric 则是通过我们来指定一个具体的区间划分条件（其实就是数据分桶的条件），例如根据字段&quot;username.keyword&quot;的值进行分桶，同时 populate metric 也是可以进行多指标(字段)学习的。视频中就是举了一个通过用户名来对用户数据进行分桶并分析用户行为来进行用户的异常检测</li><li>前面提到我们的学习区间&quot;bucket span&quot;要是适合的，不能太长也不能太短，ES 在定义学习期间（分桶逻辑）的输入框都提供了一个&quot;estimate bucket span&quot;的按钮，点击它可以获得一个 ES 推荐的学习区间值，当然我们也可以自己手动设置一个。</li><li>通过 Calendar 组件控制机器学习 job 的执行时间（避开业务高峰期进行机器学习）</li><li>机器学习是在一些拥有机器学习角色的节点上进行的，如果我们的机器学习节点很多，可以设置一些 dedicated 的节点。</li></ol><h3 id="4-用Canvas-做数据演示"><a class="header-anchor" href="#4-用Canvas-做数据演示">¶</a>&lt;4&gt; 用Canvas 做数据演示</h3><p><a href="https://time.geekbang.org/course/detail/100030501-142434" target="_blank" rel="noopener">https://time.geekbang.org/course/detail/100030501-142434</a></p><p>Canvas 是 X-Pack 中的功能，但是它是可以免费使用的。它一般用于实时展示数据，并且达到完美像素级要求，用更加酷炫的方式，演绎你的数据。它和之前介绍的可视化组件和 dashboard 不一样，整个界面都是可以高度定制的（向一个画板一样，为每一个像素关联上一个具体的索引或者文档或者字段，随着数据的变化，画板上的像素也随着变化，实现一个动态的大屏）。<br>所以我们可以用 Canvas 来做那些放在公共场合展示的大图（例如向客户展示我们的公司数据、在大促的时候的秒杀的流量大图等等）。</p><p>下面是 Kibana 开箱即用的三个数据集中包含的三个 Canvas 对象：</p><ol><li>网站流量数据集<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232102.png" alt="canvas1"></li><li>飞行航班的航班信息大屏（类似机场那种）<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232113.png" alt="canvas2"></li><li>电商销量大屏<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232127.png" alt="canvas3"></li></ol><p>这些大屏都是在一个画布中编辑的，我们可以编辑任意一个像素点。</p>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>001_前言</title>
      <link href="/2020/12/22/elasticsearch/001-qian-yan/"/>
      <url>/2020/12/22/elasticsearch/001-qian-yan/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1>为什么要学 ElasticSearch</h1><h3 id="主要功能"><a class="header-anchor" href="#主要功能">¶</a>主要功能</h3><ol><li>开源的分布式搜索引擎</li><li>大数据近实时分析引擎，性能很高，相对 hadoop 的离线计算需要等待一天来说，他立即可以拿到数据。</li><li>容易使用（自己的电脑都能安装），容易拓展。</li></ol><h1>学习目标</h1><h3 id="开发"><a class="header-anchor" href="#开发">¶</a>开发</h3><ul><li>产品基本功能</li><li>底层工作原理</li><li>数据建模最佳实践</li></ul><h3 id="运维"><a class="header-anchor" href="#运维">¶</a>运维</h3><ul><li>容量规划</li><li>性能优化</li><li>问题诊断</li><li>滚动升级</li></ul><h3 id="方案"><a class="header-anchor" href="#方案">¶</a>方案</h3><ul><li>搜索与如何解决搜索的相关性问题</li><li>大数据分析实践与项目实战，理论知识运用到实际场景</li><li>大数据分析案例，将 ElasticStack 用到这个场景</li></ul><h3 id="考试与证书"><a class="header-anchor" href="#考试与证书">¶</a>考试与证书</h3><p><a href="https://www.elastic.co/cn/training/certification" target="_blank" rel="noopener">官方含金量很高的认证考试</a>。3个小时解决12个问题。</p><h1>内容和结构</h1><h3 id="Elasticsearch-入门与深入"><a class="header-anchor" href="#Elasticsearch-入门与深入">¶</a>Elasticsearch 入门与深入</h3><ul><li>环境搭建</li><li>搜索与聚合</li><li>架构原理</li><li>数据建模</li></ul><h3 id="Elasticsearch-集群管理"><a class="header-anchor" href="#Elasticsearch-集群管理">¶</a>Elasticsearch 集群管理</h3><ul><li>水平扩展及性能优化</li><li>最佳实践</li></ul><h3 id="ELK进行大数据分析"><a class="header-anchor" href="#ELK进行大数据分析">¶</a>ELK进行大数据分析</h3><ul><li>可视化分析</li><li>时序型数据</li><li>异常检测</li></ul><h3 id="项目实战和知识点回顾"><a class="header-anchor" href="#项目实战和知识点回顾">¶</a>项目实战和知识点回顾</h3><ul><li>电影搜索</li><li>问卷分析</li><li>Elastic 认证</li></ul><h1>学习建议</h1><ul><li><p>勤动手</p><p>本地搭建多节点的集群的环境，理解分布式工作原理，执行教程中的每一个范例</p></li><li><p>多思考</p><p>结合实际的业务场景，深入思考，学会查阅相关的技术文档</p></li><li><p>定目标</p><p>做一次分享，开发一个具体的项目，参加 Elastic 认证考试</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>010_logstash</title>
      <link href="/2020/12/22/elasticsearch/010-logstash/"/>
      <url>/2020/12/22/elasticsearch/010-logstash/</url>
      
        <content type="html"><![CDATA[<h1>Logstash 入门及架构介绍</h1><p>Logstash 是一款开源的 ETL 工具，支持200多个插件，下面是它可以抽取的一些数据源的例子以及一些支持写入数据的一些例子：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223407.png" alt="image-20200503141441300"></p><h3 id="Logstash-Concepts"><a class="header-anchor" href="#Logstash-Concepts">¶</a>Logstash Concepts</h3><ol><li><p>Pipeline</p><ul><li>包含了 input-filter-output 三个阶段的处理流程，其中 input是抽取数据、filter 是数据转换、output 是数据输出</li><li>插件生命周期管理</li><li>队列管理（Logstash 内部实现了一个消息队列）</li></ul></li><li><p>Logstash Event：数据在内部流转的时候的具体表现形式。数据在 input 阶段被转换成 Event，在 output 的时候被转化成目标格式数据。一个 Event 其实是一个 Java Object，在配置文件中，对 Event 的属性进行增删改查。</p></li><li><p>Codec（code/decode）：上面提到的 Event 和原始数据格式、输出数据的格式之间的转换就是由 Codec 完成。在 Logstash 中它指的是两个动作的集合，分别是&quot;将原始数据 decode 成 Event&quot;以及&quot;将 Event encode 成目标数据&quot;。</p></li></ol><p>下面是 Logstash 的一个架构简介：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223413.png" alt="image-20200503142106246"></p><p>Input 、Filter 和 Output 三个阶段都是由不同的插件堆砌而成的，例如上面：</p><ul><li>input 我们使用了一个&quot;Stdin&quot;从控制台获取数据以及使用JDBC 获取数据的插件（Logstash 支持多数据源输入）</li><li>在 FIlter 阶段我们使用 Mutate、Date、User Agent 等转换插件对数据进行转换</li><li>在 output 的阶段使用了 Elasticsearch 这个插件将数据输出到 ES</li></ul><h3 id="Queue"><a class="header-anchor" href="#Queue">¶</a>Queue</h3><p>Logstash 内部实现了一个消息队列，所有经过 Input 采集到的数据经过 Codec 转换成 Event 之后都会扔到 Queue 中，由 Batcher 自己去Queue 中获取 Event 进行消费，传递给 Filter，完了之后再给 Output。Logstash 的消息是支持持久化的，也就是可以配置数据落盘，这样即使是在运行过程中Logstash 被中止了，已经转换好并入队的 Event 也不会丢失。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223418.png" alt="image-20200503150602714"></p><p>在 Logstash 中，queue 按照存储方式分为两种：</p><ul><li>In Memory Queue：进程 Crash、机器宕机，都会引起数据的丢失，它是默认的存储方式。</li><li><a href="https://www.elastic.co/guide/en/logstash/7.1/persistent-queues.html" target="_blank" rel="noopener">Persistent Queue</a>： 在 pipeline配置文件中配置 <code>Queue.type:persisted</code>，Logstash 会对 queue 中的数据进行落盘，机器宕机数据也不会丢失，保证数据会被消费，一定程度上可以替代 Kafka 等消息队列缓冲区的作用。</li></ul><p>另外，queue 的默认大小为4GB，可以通过<code>queue.max_bytes:4GB</code>来实现自定义。</p><h3 id="Multi-Pipeline"><a class="header-anchor" href="#Multi-Pipeline">¶</a>Multi-Pipeline</h3><p>Logstash 除了可以在一个 Pipeline 中有多个 input 之外，其实还可以支持多个 pipeline，以下是多 pipeline 的一个配置示例（pipelines.yml）：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223424.png" alt="image-20200503151109871"></p><ul><li><a href="http://pipeline.id" target="_blank" rel="noopener">pipeline.id</a>：指定 pipeline 的唯一标识</li><li>path.config：指定了 pipeline 的逻辑配置文件配置（对应前面介绍到的 logstash-sample.conf）</li><li>pipelnie.works：该配置项配置的是该pipeline的线程数，默认是 CPU 核心数。</li><li>pipeline.batch.size：batcher 一次批量获取等待处理的event (可以认为是 es 中的文档数，也就是&quot;一行数据&quot;)，默认是126。需要结合 jvm.options 调节。</li><li>pipeline.batch.delay：batcher 等待时间。</li><li>queue.type：设置queue 的类型是持久的还是基于内存的。</li></ul><h3 id="LogStash-配置文件"><a class="header-anchor" href="#LogStash-配置文件">¶</a>LogStash 配置文件</h3><p>Logstash 配置文件在&quot;${Logstash_Home}/config&quot;下面，分别有</p><ul><li>jvm.options：JVM 配置</li><li>log4j2.properties：日志文件配置</li><li>logstash-sample.conf：一个具体 pipeline 的逻辑的配置样例（对 input、filter、output 进行配置）</li><li>logstash.yml：logstash 本身的一些系统级属性配置</li><li>pipelines.yml： logstash 支持多 pipeline，这是对于pipelines的一些配置</li><li>startup.options：一些启动配置项</li></ul><h4 id="logstash-sample-conf"><a class="header-anchor" href="#logstash-sample-conf">¶</a>logstash-sample.conf</h4><p>下面是一个 Logstash 的 pipeline 逻辑配置文件的示例，可以看到分别分成了 input、filter、output 三个部分。我们通过<code>${Logstash_Home}/bin/logstash -f demo.conf</code>命令即可根据一个 demo.conf 的配置文件来启动 logstash 执行ETL 工作。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223430.png" alt="image-20200503142622855"></p><p>下面是一个使用 file input 插件从一个 csv文件中读取数据并经过多个 filter 插件的转换最终使用 elasticsearch output 插件写入到 es 索引中的例子：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">input {  file {    path => "/usr/local/software/elasticsearch/movielens/ml-latest-small/movies.csv"    start_position => "beginning"    sincedb_path => "/dev/null"  }}filter {  csv {    separator => ","    columns => ["id","content","genre"]  }  mutate {    split => { "genre" => "|" }    remove_field => ["path", "host","@timestamp","message"]  }  mutate {    split => ["content", "("]    add_field => { "title" => "%{[content][0]}"}    add_field => { "year" => "%{[content][1]}"}  }  mutate {    convert => {      "year" => "integer"    }    strip => ["title"]    remove_field => ["path", "host","@timestamp","message","content"]  }}output {   elasticsearch {     hosts => "http://localhost:9200"     index => "movies"     document_id => "%{id}"   }  stdout {}}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Input-Plugins"><a class="header-anchor" href="#Input-Plugins">¶</a>Input Plugins</h3><p>一个 Pipeline 可以有 input 插件，Logstash 提供了许多开箱即用的输入插件：</p><ul><li>一些没有规范格式的输入：Stdin、File</li><li>一些现有中间件的输入：Beats、Log4J、Elasticsearch、JDBC、Kafka、Rabbitmq、Redis</li><li>一些抽象协议的输入：JMX、HTTP、Websocket、UDP、TCP</li><li>一些云存储的输入：Google Cloud Storage、S3</li><li>Github、Twitter</li></ul><h5 id="Input-Plugin：File"><a class="header-anchor" href="#Input-Plugin：File">¶</a>Input Plugin：File</h5><p>支持从文件中读取数据，如日志文件。从文件中读取数据有一些通用的需求，就是一个文件只会被读取一次（数据不被重复读取），如果读取的过程中发生了重启，需要从上一次读取的位置继续，logstash 都实现了这些需求（通过 sincedb 实现，把位置信息保存到 sincedb 中）。</p><p>读取到文件新内容，发现新文件的时候都会自动处理。</p><p>文档发生归档操作（文档位置发生变化，日志 rotation），不会影响当前的内容读取。</p><h3 id="Output-Plugins"><a class="header-anchor" href="#Output-Plugins">¶</a><a href="https://www.elastic.co/guide/en/logstash/7.1/output-plugins.html" target="_blank" rel="noopener">Output Plugins</a></h3><p>output 是 pipeline 的最后阶段，负责将 Event 发送到特定的目的地。常见的 plugins：</p><ul><li>ELasticsearch</li><li>Email、Pageduty</li><li>Influxdb、Kafka、Mongodb、Opentsdb、Zabbix</li><li>Http、TCP、Websocket</li></ul><h3 id="Codec-Plugins"><a class="header-anchor" href="#Codec-Plugins">¶</a><a href="https://www.elastic.co/guide/en/logstash/7.1/codec-plugins.html" target="_blank" rel="noopener">Codec Plugins</a></h3><p>将原始数据 decode 成 event，将 event encode 成目标数据：</p><ul><li>Line、Multiline</li><li>JSON、Avro、Cef（ArcSight Common Event Format）</li><li>Dots、Rubydebug</li></ul><h5 id="Codec-Plugin：Single-Line、dots"><a class="header-anchor" href="#Codec-Plugin：Single-Line、dots">¶</a>Codec Plugin：Single Line、dots</h5><p>通过在pipeline 逻辑配置文件中指定 input 里面的某个 input 插件的 codec 为 line（“<strong>codec=&gt;line</strong>”）来实现，这会使得 codec 将input 插件抓取过来的数据按照每一行（换行符）数据转换成一个 Event 对象：</p><ol><li>通过<code>-e</code>参数在命令行启动 logstash 的时候动态输入配置文件指定 input 为 stdin（codec 为 line），output 为 stdout</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223439.png" alt="image-20200503152946281"></p><ol start="2"><li><p>logstash在启动后就等待着我们的输入，这时候我们输入一个&quot;hello world&quot;，可以看到它立马就返回一个输出，然后再等待下一次输入</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223444.png" alt="image-20200503153400540"></p></li><li><p>当我们将输出插件中的 codec 从 rubydebug 改成 dots，然后重启 logstash，可以看到我们输入 hello world 之后，dots codec 直接将所有的 events 都转换成了一个点传递给 stdout，控制台就输出了一个点给我们</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223452.png" alt="image-20200503153713973"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223547.png" alt="image-20200503153733348"></p></li></ol><h5 id="Codec-Plugin：json"><a class="header-anchor" href="#Codec-Plugin：json">¶</a>Codec Plugin：json</h5><ol><li><p>将前面例子中的 stdin 里面的 codec 改成 json，重启 logstash</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223501.png" alt="image-20200503153950382"></p></li><li><p>此时还是输入 hello world，此时报了一个 json 转换的异常</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223507.png" alt="image-20200503154115785"></p></li><li><p>输入{“hello”:“world”}，json 转换成功并输出</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223513.png" alt="image-20200503154219251"></p></li></ol><h5 id="Codec-Plugin：Multiline"><a class="header-anchor" href="#Codec-Plugin：Multiline">¶</a>Codec Plugin：Multiline</h5><p>前面示例中 input 插件中的 codec 都是对输入数据按行转换 events 的，我们可以通过指定 input 插件的 codec 为 multiline，并为 multiline 指定一些参数即可实现多行识别：</p><ul><li>pattern：设置行匹配的正则表达式</li><li>what：如果匹配成功，那么当前行是和前面的行一起作为一个 event （合并到前面的 event 中）还是和后面的行一起作为一个 event（另起一个 event）。<ul><li>参数值：pervious/next</li></ul></li><li>negate：是否对 pattern 结果取反<ul><li>参数值：true/false</li></ul></li></ul><p>下面是一个具体的例子：</p><p>对于以下的一个多行输入：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223519.png" alt="image-20200503154830826"></p><p>我们有这么一个配置文件</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223527.png" alt="image-20200503154856370"></p><p>可以看到我们为标准输入 stdin 配置了一个 multiliine 的 codec：</p><ul><li>其中 pattern 为 “^\s”</li><li>what 为 “previous”</li></ul><p>即当一行数据是以空白字符开头的时候，它就和前面的行数据一起作为一个 event，看到我们前面的一个多行输入，第一行是以&quot;E&quot;开头的，后面三行都是空白字符开头，所以这四行数据都会被作为一个 Event 进行转换。</p><h3 id="Filter-Plugins"><a class="header-anchor" href="#Filter-Plugins">¶</a><a href="https://www.elastic.co/guide/en/logstash/7.1/filter-plugins.html" target="_blank" rel="noopener">Filter Plugins</a></h3><p>处理 event，进行相关的数据转换动作</p><ul><li>Mutate：操作 Event 的字段</li><li>Metrics：Aggregate metrics</li><li>Ruby：执行 Ruby 代码动态修改 Event</li><li>Date：日期解析</li><li>Dissect：分隔符解析</li><li>Grok：正则匹配解析</li></ul><h5 id="Filter-Plugin：Mutate"><a class="header-anchor" href="#Filter-Plugin：Mutate">¶</a>Filter Plugin：Mutate</h5><ul><li>Convert：类型转换</li><li>Gsub：字符串替换</li><li>Split、Join、Merge：字符串切割、数组合并字符串、数组合并数组</li><li>Rename：字段重命名</li><li>Update、Replace：字段内容更新替换</li><li>Remove_field：字段删除</li></ul><h3 id="相关阅读"><a class="header-anchor" href="#相关阅读">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/guide/en/logstash/7.1/output-plugins.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/7.1/output-plugins.html</a></p><p><a href="https://www.elastic.co/guide/en/logstash/7.1/codec-plugins.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/7.1/codec-plugins.html</a></p><p><a href="https://www.elastic.co/guide/en/logstash/7.1/filter-plugins.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/7.1/filter-plugins.html</a></p><p><a href="https://www.elastic.co/guide/en/logstash/7.1/persistent-queues.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/7.1/persistent-queues.html</a></p></blockquote><h1>利用Logstash JDBC 插件导入数据到 Elasticsearch</h1><h3 id="需求"><a class="header-anchor" href="#需求">¶</a>需求</h3><p>将数据库中的数据同步到ES，借助 ES 的全文搜索，提高搜索速度。</p><ul><li>需要把新增用户信息同步到 Elasticsearch 中</li><li>用户信息 update 后，需要能被更新到 Elasticsearch</li><li>支持增量更新</li><li>用户注销后，不能被 ES 搜索到</li></ul><h3 id="Logstash-JDBC-Input-Plugin-设计实现思路"><a class="header-anchor" href="#Logstash-JDBC-Input-Plugin-设计实现思路">¶</a>Logstash JDBC Input Plugin &amp; 设计实现思路</h3><h4 id="1、对于新增和更新数据的同步"><a class="header-anchor" href="#1、对于新增和更新数据的同步">¶</a>1、对于新增和更新数据的同步</h4><p>本节中使用 logstash 的 jdbc 插件实现从 mysql 中抽取数据写入到 ES。这个 jdbc input 插件还支持 Scheduling，其语法来自 Rufus-scheduler，扩展了 Cron，支持时区。所以我们大概的实现思路就是：</p><ol><li>在每个需要同步数据到 ES 的表中增加了最后更新时间的字段</li><li>然后启用 jdbc input 插件中的定时任务，定时从数据库中查询最后更新时间大于上一次更新时间的数据（上一次更新时间要进行保存，初始值设置为0），然后将查出来的数据覆盖到 ES，并将其上一次更新时间字段更新为当前时间</li></ol><p>需要注意的是，我们需要自备 jdbc 的 jar 包，通过配置文件中的<code>input.jdbc.jdbc_driver_library</code>指定 jar 包路径。( 如果不想指定，就将这个 jar 包拷贝到 Logstash 的 classpath 路径，就是其 jar 包lib 目录，“${logstash_home}/logstash-core/lib/jars”)</p><blockquote><p>上面提到的最后更新时间字段通过配置文件的<code>input.jdbc.use_column_value</code>、<code>input.jdbc.tracking_column</code>、<code>input.jdbc.tracking_column_type</code>、<code>record_last_run</code>、<code>last_run_metadata_path</code>实现，另外&quot;查询最后更新时间大于上一次更新时间的逻辑&quot;参考<code>input.jdbc.statemetn</code>中的 <code>where last_updated &gt; :sql_last_value</code>，<code>sql_last_value</code>貌似是一个关键字，待研究。</p></blockquote><pre class="line-numbers language-language-shell"><code class="language-language-shell">input {  jdbc {  jdbc_driver_library => "the_path_of_your_jdbc.jar"    jdbc_driver_class => "com.mysql.jdbc.Driver"    jdbc_connection_string => "jdbc:mysql://localhost:3306/db_example"    jdbc_user => root    jdbc_password => ymruan123    #启用追踪，如果为true，则需要指定tracking_column    use_column_value => true    #指定追踪的字段，    tracking_column => "last_updated"    #追踪字段的类型，目前只有数字(numeric)和时间类型(timestamp)，默认是数字类型    tracking_column_type => "numeric"    #记录最后一次运行的结果    record_last_run => true    #上面运行结果的保存位置    last_run_metadata_path => "jdbc-position.txt"    # 获取数据的 sql    statement => "SELECT * FROM user where last_updated >:sql_last_value;"    # 定时任务 Cron 表达式    schedule => " * * * * * *"  }}output {  elasticsearch {    document_id => "%{id}"    document_type => "_doc"    index => "users"    hosts => ["http://localhost:9200"]  }  stdout{    codec => rubydebug  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2、对于删除数据的同步"><a class="header-anchor" href="#2、对于删除数据的同步">¶</a>2、对于删除数据的同步</h4><p>以上都是对于新增和更新数据的同步方案，但是如果是删除数据的话，物理删除对上以上方案中的 logstash 来说是无感知的，因为它都是使用&quot;select *&quot;来获取数据的。所以对于删除数据的同步方案，我们考虑在 mysql 中设置一个&quot;id_deleted&quot;的字段来标识一条记录是否被删除（逻辑删除），在要删除一条数据的时候我们并不是真正地在 mysql 中对其 delete 掉，而是将这行记录地这个字段更新为 true（integer 的 1），然后更新最后更新时间字段为当前时间。</p><p>然后我们需要解决的是 ES 中查询逻辑删除地数据的问题，因为即使是逻辑删除的数据在 ES 中也是可以直接查询出来的，如果用户想要根据索引来查询没有删除的数据，就要手动加上一个&quot;is_deleted=false&quot;的条件，很不友好，所以我们可以使用 ES 的 aliases 的功能，为这个索引建议一个 alias，然后在 alias 中定义一个 filter，过滤出那些&quot;is_deleted=false&quot;的数据，这样用户查询的时候直接根据这个 alias 来查询得到全部都是没有被删除的数据了。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 创建 alias，只显示没有被标记 deleted的用户POST /_aliases{  "actions": [    {      "add": {        "index": "users",        "alias": "view_users",         "filter" : { "term" : { "is_deleted" : false } }      }    }  ]}# 通过 Alias查询，查不到被标记成 deleted的用户POST view_users/_search{}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h3><p>这种方案采用的是轮询&quot;select *&quot;的方式同步数据，其中还经过了 jdbc 协议的转换，性能可能是不太好的，现有的一些比较好的方案都是通过同步 binlog 的方式进行的。</p>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>004_Elasticsearch 入门</title>
      <link href="/2020/12/22/elasticsearch/004-elasticsearch-ru-men/"/>
      <url>/2020/12/22/elasticsearch/004-elasticsearch-ru-men/</url>
      
        <content type="html"><![CDATA[<p>[toc]</p><h1>一、基本概念：索引、文档和 REST API</h1><h2 id="文档"><a class="header-anchor" href="#文档">¶</a>文档</h2><ol><li><p>Elasticsearch 是面向文档的，文档是所有可搜索数据的最小单位，以下都可以理解为一个文档</p><ul><li>日志文件中的日志项</li><li>一本电影的具体信息、一张唱片的详细信息</li><li>MP3播放器里的一首歌、一篇 PDF 文档中的具体内容</li></ul><p>从数据结构的定位上来讲可以类比到关系型数据库中的行或者记录(row/record)。</p></li><li><p>文档会被序列化成 JSON 格式，保存在 Elasticsearch 中</p><ul><li>JSON 对象由字段组成</li><li>每个字段都有对应的字段类型（字符串、数值、布尔、日期、二进制、范围类型）</li></ul><ul><li>JSON 文档，格式灵活，不需要预先定义格式，字段类型可以指定或者通过 Elasticsearch 自动推算</li><li>支持数组、支持嵌套</li></ul><p>下面是一个  CSV 文件的一行数据导入 Es 之后转换成的一个 JSON 文档:<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210942.png" alt="image-20200424004733019"></p></li><li><p>每个文档都有一个 Unique ID</p><ul><li>可以自己指定 ID</li><li>或者通过 Elasticsearch 自动生成</li></ul></li><li><p>文档的元数据，用于标注文档的相关信息</p><ul><li>_index：文档所属的索引名</li><li>_type：文档的类型的名称</li><li>_id：文档唯一 ID</li><li>_source：文档的原始 JSON 数据</li><li>_all：整合所有字段内容到该字段，7.0开始已被废除。（早期是将所有这些字段整合到这一个字段，方便文档的检索）</li><li>_version：文档的版本信息（当有大量数据并发读写的时候，可以解决文档冲突问题）</li><li>_score：相关性打分</li></ul></li></ol><h2 id="索引"><a class="header-anchor" href="#索引">¶</a>索引</h2><ol><li><p>Index：索引是文档的容器，是一类相似文档的集合</p><ul><li>Index 体现了逻辑空间的概念：每个索引都有自己的 Mapping 定义，用于定义包含的文档的字段名和字段类型</li><li>Shard 体现了物理空间的概念：索引中的数据分散在 Shard 上。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210950.png" alt="image-20200424005500809"></p></li><li><p>索引的 Mapping 和 Settings</p><ul><li>Mapping 定义文档字段的类型</li><li>Setting 定义不同的数据分布（Shard）</li></ul></li><li><p>索引的不同语意</p><ul><li>名称：一个 Elasticsearch 集群中，可以创建很多不同的索引</li><li>动词：保存一个文档到 Elasticsearch 的过程也叫索引（indexing）<ul><li>ES 中，创建一个倒排索引的过程</li></ul></li><li>名称：一个 B 树索引，一个倒排索引</li></ul></li><li><p>Type</p><ul><li>在7.0之前，一个 Index 可以设置多个 Type，每个 Type 下面拥有一些相同结构的文档</li><li>6.0开始，Type 已经被 Deprecated。7.0开始，一个索引只能创建一个 Type–“_doc”。</li></ul><blockquote><p><a href="https://www.elastic.co/cn/blog/moving-from-types-to-typeless-apis-in-elasticsearch-7-0" target="_blank" rel="noopener">为什么不再支持单个Index下，多个Types</a></p></blockquote></li></ol><h2 id="抽象与类比"><a class="header-anchor" href="#抽象与类比">¶</a>抽象与类比</h2><ul><li><p>传统关系型数据库和 ES概念类比<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210956.png" alt="image-20200424010237527"></p></li><li><p>两者区别：</p><ul><li>Elasticsearch：Schemaless、相关性、高性能全文检索</li><li>RDBMS：事务性、Join</li></ul></li></ul><h2 id="REST-API"><a class="header-anchor" href="#REST-API">¶</a>REST API</h2><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211001.png" alt="image-20200424010449342"></p><p>Elasticsearch 支持 Transport API 和 REST API，推荐使用 REST API。</p><h3 id="一些基本的-API"><a class="header-anchor" href="#一些基本的-API">¶</a>一些基本的 API</h3><ul><li><p>Indices</p><ul><li>创建 Index<ul><li>PUT Movies</li></ul></li><li>查看所有 Index<ul><li>_cat/indices</li></ul></li></ul></li><li><p>API 尝试</p><pre><code>#查看索引相关信息GET kibana_sample_data_ecommerce#查看索引的文档总数GET kibana_sample_data_ecommerce/_count#查看前10条文档，了解文档格式POST kibana_sample_data_ecommerce/_search{}#_cat indices API#查看indicesGET /_cat/indices/kibana*?v&amp;s=index#查看状态为绿的索引GET /_cat/indices?v&amp;health=green#按照文档个数排序GET /_cat/indices?v&amp;s=docs.count:desc#查看具体的字段GET /_cat/indices/kibana*?pri&amp;v&amp;h=health,index,pri,rep,docs.count,mt#How much memory is used per index?GET /_cat/indices?v&amp;h=i,tm&amp;s=tm:desc</code></pre></li></ul><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/cat-indices.html" target="_blank" rel="noopener">CAT Index API</a></p></blockquote><h3 id="索引管理功能"><a class="header-anchor" href="#索引管理功能">¶</a>索引管理功能</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211007.png" alt="image-20200424010738677"></p><h1>二、基本概念：节点、集群、分片及副本</h1><h2 id="分布式系统的可用性与扩展性"><a class="header-anchor" href="#分布式系统的可用性与扩展性">¶</a>分布式系统的可用性与扩展性</h2><ol><li>高可用性<ul><li>服务可用性：允许有节点停止服务</li><li>数据可用性：部分节点丢失，不会丢失数据</li></ul></li><li>可扩展性<ul><li>请求量提升、数据的不断增长（将数据分布到所有节点上，实现水平扩展）</li></ul></li></ol><h2 id="分布式特性"><a class="header-anchor" href="#分布式特性">¶</a>分布式特性</h2><ol><li>Elasticsearch 的分布式架构的好处<ul><li>存储的水平扩容</li><li>提高系统的可用性，部分节点停止服务，整个集群的服务不受影响</li></ul></li><li>Elasticsearach 的分布式架构<ul><li>不同的集群通过不同的名字来区分，默认名称&quot;elasticsearch&quot;</li><li>通过配置文件修改，或者在命令行<code>-E cluster.name=geektime</code> 进行设定</li><li>一个集群可以有一个或者多个节点</li></ul></li></ol><h2 id="节点"><a class="header-anchor" href="#节点">¶</a>节点</h2><ol><li>节点是一个 Elasticsearch 的实例<ul><li>本质上就是一个 JAVA 进程</li><li>一台机器上可以运行多个 Elasticsearch 进程，但是生产环境一般建议一台机器上只运行一个 Elasticsearch 实例</li></ul></li><li>每一个节点都有名字，通过配置文件配置，或者启动的时候<code>-E node.name=node1</code>指定</li><li>每一个节点在启动之后，会分配一个 UID，保存在 data 目录下</li></ol><h3 id="Master-eligible-nodes-和-Master-Node"><a class="header-anchor" href="#Master-eligible-nodes-和-Master-Node">¶</a>Master-eligible nodes 和 Master Node</h3><ul><li>每个节点启动后，默认就是一个 Master eligible 节点<ul><li>可以设置<code>node.master:false</code>禁止</li></ul></li><li>Master-eligible 节点可以参加选主流程，称为 Master 节点</li><li>当第一个节点启动的时候，它会将自己选举成 Master 节点</li><li>每个节点上都保存了集群的状态，只有 Master 节点才能修改集群的状态信息<ul><li>集群状态（Cluster State），维护了一个集群中必要的信息<ul><li>所有的节点信息</li><li>所有的索引和其相关的 Mapping 与 Setting 信息</li><li>分片的路由信息</li></ul></li><li>如果任意节点都能修改信息会导致数据的不一致性，使得集群变得混乱</li></ul></li></ul><h3 id="Data-Node-Coordinating-Node"><a class="header-anchor" href="#Data-Node-Coordinating-Node">¶</a>Data Node &amp; Coordinating Node</h3><ul><li>Data Node<ul><li>可以保存数据的节点，叫做 Data Node。负责保存分片数据。在数据扩展是起到了至关重要的作用</li><li>当集群无法再分配数据的时候，可以增加一个数据节点来解决</li></ul></li><li>Coordinating Node<ul><li>负责接受 Client 的请求，将请求分发到合适的节点，最终把结果汇集到一起进行响应给调用的客户端</li><li>每个节点默认都起到了 Coordinating Node 的职责</li></ul></li></ul><h3 id="其他类型的节点"><a class="header-anchor" href="#其他类型的节点">¶</a>其他类型的节点</h3><ul><li>Hot &amp; Warm Node<ul><li>不同硬件配置的 Data Node，用来实现 Hot &amp; Warm 架构，热数据存储在 Hot 节点（高配），冷数据存储在 Warm 节点（低配），降低集群部署的成本</li></ul></li><li>Machine Learning Node<ul><li>负责跑机器学习的 Job，用来做异常检测及告警</li></ul></li><li>Tribe Node<ul><li>（5.3开始使用 Cross Cluster Search）Tribe Node 连接到不同的 Elasticsearch 集群，并且支持将这些集群当成一个单独的集群处理</li></ul></li></ul><h3 id="配置节点类型"><a class="header-anchor" href="#配置节点类型">¶</a>配置节点类型</h3><ul><li>开发环境中一个节点可以承担多种角色</li><li>生产环境中，应该设置单一的角色的节点（dedicated node）<ul><li>可以有更好的性能</li><li>职责明确，根据不同节点配置不同硬件</li></ul></li></ul><table><thead><tr><th>节点类型</th><th>配置参数</th><th>默认值</th></tr></thead><tbody><tr><td>Master eligible</td><td>node.master</td><td>true</td></tr><tr><td>data</td><td>node.data</td><td>true</td></tr><tr><td>ingest</td><td>node.ingest</td><td>true</td></tr><tr><td>coordinating only</td><td>无</td><td>每一个节点默认都是 coordinating 节点。设置其他类型全部为 false。</td></tr><tr><td>Machine learning</td><td><a href="http://node.ml" target="_blank" rel="noopener">node.ml</a></td><td>True（需要 enable x=pack）</td></tr></tbody></table><h2 id="分片（Primary-Shard-Replica-Shard）"><a class="header-anchor" href="#分片（Primary-Shard-Replica-Shard）">¶</a>分片（Primary Shard &amp; Replica Shard）</h2><ol><li><p>主分片</p><p>用来解决数据水平扩展的问题。通过主分片，可以将数据分布到集群内的所有节点之上</p><ul><li>一个分片是一个运行的 Lucene 的实例（索引）</li><li>主分片数在索引创建时指定，后续不允许修改，除非 Reindex</li></ul></li><li><p>副本分片</p><p>用来解决数据高可用的问题，避免部分节点不可用导致数据丢失。分片是主分片的拷贝</p><ul><li>副本分片数，可以动态调整</li><li>增加副本数，还可以在一定程度上提高服务的可用性（读取的吞吐）</li></ul></li><li><p>举例</p><p>一个3节点的集群中，blogs 索引的分片分布情况</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211020.png" alt="image-20200424070058325"></p></li><li><p>分片的设定</p></li></ol><p>对于生产环境中分片的设定，需要提前做好容量规划</p><ul><li>分片数设置过小<ul><li>导致后续无法增加节点实现水平扩展</li><li>单个分片的数据量太大，导致数据重新分配耗时</li></ul></li><li>分片数设置过大，7.0开始，默认主分片从5改成1，解决了 over-sharding 的问题<ul><li>影响搜索结果的相关性打分，影响统计结果的准确性</li><li>单个节点上过多的分片，会导致资源浪费，同时也会影响性能</li></ul></li></ul><h2 id="查看集群的健康状态"><a class="header-anchor" href="#查看集群的健康状态">¶</a>查看集群的健康状态</h2><ol><li><p>REST API: <code>GET _cluster/health</code></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211026.png" alt="image-20200424070550671"></p><ul><li>Green：主分片与副本都正常分配</li><li>Yellow：主分片全部正常分配，有副本分片未正常分配</li><li>Red：有主分片未能分配<ul><li>例如，当服务器的磁盘容量超过85%时，去创建了一个新的索引</li></ul></li></ul></li><li><p>通过 Kibana 查看集群状态</p><ul><li><p>查看一个集群的健康状态</p><p><a href="http://myecs.com:9200/_cluster/health" target="_blank" rel="noopener">http://myecs.com:9200/_cluster/health</a></p></li><li><p>CAT API</p><ul><li>httpL//myecs.com:9200/_cat/nodes</li><li>查看索引和分片</li></ul></li><li><p>设置分片数</p></li></ul><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/cat-nodes.html" target="_blank" rel="noopener">CAT Nodes API</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/cluster.html" target="_blank" rel="noopener">Cluster API</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/cat-shards.html" target="_blank" rel="noopener">CAT Shards API</a></p></blockquote><pre><code>GET _cat/nodes?vGET /_nodes/es7_01,es7_02GET /_cat/nodes?vGET /_cat/nodes?v&amp;h=id,ip,port,v,mGET _cluster/healthGET _cluster/health?level=shardsGET /_cluster/health/kibana_sample_data_ecommerce,kibana_sample_data_flightsGET /_cluster/health/kibana_sample_data_flights?level=shards#### cluster stateThe cluster state API allows access to metadata representing the state of the whole cluster. This includes information such asGET /_cluster/state#cluster get settingsGET /_cluster/settingsGET /_cluster/settings?include_defaults=trueGET _cat/shardsGET _cat/shards?h=index,shard,prirep,state,unassigned.reason</code></pre></li><li><p>通过 Cerebro 查看集群状态</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211033.png" alt="image-20200424072047317"></p><p>当我们尝试停掉一个节点的时候，发现上面的长条变成了黄色</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211041.png" alt="image-20200424072222820"></p><h1>三、文档的 CRUD与批量操作</h1><h2 id="文档的-CRUD"><a class="header-anchor" href="#文档的-CRUD">¶</a>文档的 CRUD</h2><ul><li>Type名，约定都用_doc</li><li>Create：如果 ID 已经存在，会失败</li><li>Index：如果 ID 不存在，创建新的文档；否则，先删除现有的文档，再创建新的文档，版本会增加</li><li>Update：文档必须已经存在，然后对相应字段做增量修改，版本号增加</li></ul><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/docs.html" target="_blank" rel="noopener">Document API</a></p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211048.png" alt="image-20200424073808066"></p><h3 id="create"><a class="header-anchor" href="#create">¶</a>create</h3><ul><li>支持自动生成文档 id 和指定文档 id 两种方式</li><li>通过调用<code>post /users/_doc</code><ul><li>系统会自动生成 document id</li></ul></li><li>使用 HTTP PUT user/_create/1 创建时，URI中显示指定_create，此时如果该 ID 的文档已经存在，操作失败</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211054.png" alt="image-20200424074516551"></p><h3 id="get"><a class="header-anchor" href="#get">¶</a>get</h3><ul><li>找到文档，返回 HTTP 200</li><li>文档元信息<ul><li>_index、_type</li><li>版本信息，同一个 id 的文档，被删除，version 号不断增加</li><li>_source 中默认包含了了文档的所有原始信息</li></ul></li><li>找不到文档，返回 HTTP 404</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211103.png" alt="image-20200424074539766"></p><h3 id="index"><a class="header-anchor" href="#index">¶</a>index</h3><ul><li>index 和 create 区别：如果文档(ID)已存在，前者会删除然后重建然后版本+1；后者会报错</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211109.png" alt="image-20200424074731377"></p><h3 id="update"><a class="header-anchor" href="#update">¶</a>update</h3><ul><li><p>update 方法不会删除原来的文档，要求文档必须存在，否则失败。是实现真正的数据更新</p></li><li><p>post 方法，在请求体中将信息包含在&quot;doc&quot;中</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211116.png" alt="image-20200424074841642"></p></li></ul><h3 id="Bulk-API"><a class="header-anchor" href="#Bulk-API">¶</a>Bulk API</h3><ul><li>支持在一次 API 调用中，对不同的索引进行操作，减少网络请求</li><li>支持4种操作类型<ul><li>index</li><li>create</li><li>update</li><li>delete</li></ul></li><li>可以在 URI 中指定 index，也可以在请求的 payload 中进行</li><li>操作中单挑操作失败，并不会影响其他操作</li><li>返回结果包含了每一条操作执行的结果</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211123.png" alt="image-20200424075319487"></p><h3 id="mget-批量读取"><a class="header-anchor" href="#mget-批量读取">¶</a>mget-批量读取</h3><p>批量操作，可以减少网络连接所产生的开销，提高性能</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211130.png" alt="image-20200424075501736"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211136.png" alt="image-20200424075508922"></p><h3 id="msearch-批量查询"><a class="header-anchor" href="#msearch-批量查询">¶</a>msearch-批量查询</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211143.png" alt="image-20200424075601707"></p><blockquote><p>注意，虽然上面介绍了批量查询API，但是单次批量查询的数据过大也会引发性能问题。</p></blockquote><h3 id="操作的-API-demo"><a class="header-anchor" href="#操作的-API-demo">¶</a>操作的 API demo</h3><pre><code>############Create Document#############create document. 自动生成 _idPOST users/_doc{&quot;user&quot; : &quot;Mike&quot;,    &quot;post_date&quot; : &quot;2019-04-15T14:12:12&quot;,    &quot;message&quot; : &quot;trying out Kibana&quot;}#create document. 指定Id。如果id已经存在，报错PUT users/_doc/1?op_type=create{    &quot;user&quot; : &quot;Jack&quot;,    &quot;post_date&quot; : &quot;2019-05-15T14:12:12&quot;,    &quot;message&quot; : &quot;trying out Elasticsearch&quot;}#create document. 指定 ID 如果已经存在，就报错PUT users/_create/1{     &quot;user&quot; : &quot;Jack&quot;,    &quot;post_date&quot; : &quot;2019-05-15T14:12:12&quot;,    &quot;message&quot; : &quot;trying out Elasticsearch&quot;}### Get Document by ID#Get the document by IDGET users/_doc/1###  Index &amp; Update#Update 指定 ID  (先删除，在写入)GET users/_doc/1PUT users/_doc/1{&quot;user&quot; : &quot;Mike&quot;}#GET users/_doc/1#在原文档上增加字段POST users/_update/1/{    &quot;doc&quot;:{        &quot;post_date&quot; : &quot;2019-05-15T14:12:12&quot;,        &quot;message&quot; : &quot;trying out Elasticsearch&quot;    }}### Delete by Id# 删除文档DELETE users/_doc/1### Bulk 操作#执行两次，查看每次的结果#执行第1次POST _bulk{ &quot;index&quot; : { &quot;_index&quot; : &quot;test&quot;, &quot;_id&quot; : &quot;1&quot; } }{ &quot;field1&quot; : &quot;value1&quot; }{ &quot;delete&quot; : { &quot;_index&quot; : &quot;test&quot;, &quot;_id&quot; : &quot;2&quot; } }{ &quot;create&quot; : { &quot;_index&quot; : &quot;test2&quot;, &quot;_id&quot; : &quot;3&quot; } }{ &quot;field1&quot; : &quot;value3&quot; }{ &quot;update&quot; : {&quot;_id&quot; : &quot;1&quot;, &quot;_index&quot; : &quot;test&quot;} }{ &quot;doc&quot; : {&quot;field2&quot; : &quot;value2&quot;} }#执行第2次POST _bulk{ &quot;index&quot; : { &quot;_index&quot; : &quot;test&quot;, &quot;_id&quot; : &quot;1&quot; } }{ &quot;field1&quot; : &quot;value1&quot; }{ &quot;delete&quot; : { &quot;_index&quot; : &quot;test&quot;, &quot;_id&quot; : &quot;2&quot; } }{ &quot;create&quot; : { &quot;_index&quot; : &quot;test2&quot;, &quot;_id&quot; : &quot;3&quot; } }{ &quot;field1&quot; : &quot;value3&quot; }{ &quot;update&quot; : {&quot;_id&quot; : &quot;1&quot;, &quot;_index&quot; : &quot;test&quot;} }{ &quot;doc&quot; : {&quot;field2&quot; : &quot;value2&quot;} }### mget 操作GET /_mget{    &quot;docs&quot; : [        {            &quot;_index&quot; : &quot;test&quot;,            &quot;_id&quot; : &quot;1&quot;        },        {            &quot;_index&quot; : &quot;test&quot;,            &quot;_id&quot; : &quot;2&quot;        }    ]}#URI中指定indexGET /test/_mget{    &quot;docs&quot; : [        {            &quot;_id&quot; : &quot;1&quot;        },        {            &quot;_id&quot; : &quot;2&quot;        }    ]}GET /_mget{    &quot;docs&quot; : [        {            &quot;_index&quot; : &quot;test&quot;,            &quot;_id&quot; : &quot;1&quot;,            &quot;_source&quot; : false        },        {            &quot;_index&quot; : &quot;test&quot;,            &quot;_id&quot; : &quot;2&quot;,            &quot;_source&quot; : [&quot;field3&quot;, &quot;field4&quot;]        },        {            &quot;_index&quot; : &quot;test&quot;,            &quot;_id&quot; : &quot;3&quot;,            &quot;_source&quot; : {                &quot;include&quot;: [&quot;user&quot;],                &quot;exclude&quot;: [&quot;user.location&quot;]            }        }    ]}### msearch 操作POST kibana_sample_data_ecommerce/_msearch{}{&quot;query&quot; : {&quot;match_all&quot; : {}},&quot;size&quot;:1}{&quot;index&quot; : &quot;kibana_sample_data_flights&quot;}{&quot;query&quot; : {&quot;match_all&quot; : {}},&quot;size&quot;:2}### 清除测试数据#清除数据DELETE usersDELETE testDELETE test2</code></pre><h3 id="常见错误返回"><a class="header-anchor" href="#常见错误返回">¶</a>常见错误返回</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211151.png" alt="image-20200424075635645"></p><h1>四、倒排索引介绍</h1><h2 id="正排索引和倒排索引"><a class="header-anchor" href="#正排索引和倒排索引">¶</a>正排索引和倒排索引</h2><h3 id="类比理解"><a class="header-anchor" href="#类比理解">¶</a>类比理解</h3><p>假设现在有一本关于 Elasticsearch 的书籍，书籍中的每一页可以类比为 Elasticsearch 中的document，文档中所有字段从第一个到最后一个形成一个链条列表，拥有唯一的位置索引。</p><p>书籍的目录上记录了页码以及对应的内容名称，整本书可以理解为一个物理存储介质，页码让我们可以快速定位到我们想要找的文档。所以这个目录就是一个索引，而从 id 指向一个文档就是一个正排索引。</p><p>另外一些技术书籍会在最后几页放一些技术术语(单词，term)的列表，并标注了它在哪几页出现，这个将文档中的内容指向文档 id 再找到文档进行加载文档内容的过程就是一个倒排索引。</p><p>看下表，右边就是一个倒排索引。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211158.png" alt="image-20200424094916737"></p><h3 id="倒排索引的核心组成"><a class="header-anchor" href="#倒排索引的核心组成">¶</a>倒排索引的核心组成</h3><p>倒排索引包含两个部分</p><ul><li>单词词典(Term Directory)，记录所有文档的单词，记录单词到倒排列表的关联关系（<strong>另外，需要注意，文档下面还有 Field 的概念，它是由 Field 构成的，而 Field 则由 Term 构成</strong>）。单词词典一般比较大，可以通过 B+树或者哈希拉链实现存储，以满足高性能的插入与查询</li><li>倒排列表(Posting Lisrt)，记录了单词对应的文档集合，由<strong>倒排索引项</strong>组成：<ul><li>文档 ID</li><li>词频 TF：该单词在文档中出现的次数，用于相关性评分</li><li>位置（Position）：单词在文档中分词的位置。用于语句搜索（phrase query）</li><li>偏移（Offset）：记录单词的开始结束位置，实现高亮显示</li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211204.png" alt="image-20200424140003886"></p><h3 id="一个例子"><a class="header-anchor" href="#一个例子">¶</a>一个例子</h3><p>Term：“Elasticsearch”</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211210.png" alt="image-20200424101338760"></p><blockquote><p><a href="https://zh.wikipedia.org/wiki/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95" target="_blank" rel="noopener">维基百科倒排索引</a></p><p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/inverted-index.html" target="_blank" rel="noopener">Elasticsearch 官方倒排索引介绍</a></p></blockquote><h3 id="Elasticsearch-的倒排索引"><a class="header-anchor" href="#Elasticsearch-的倒排索引">¶</a>Elasticsearch 的倒排索引</h3><ul><li>Elasticsearch 的 JSON 文档中的每个字段，都有自己的倒排索引</li><li>可以指定对<strong>某些字段</strong>不做索引<ul><li>优点：节省存储空间</li><li>缺点：字段无法被搜索</li></ul></li></ul><h1>五、通过 Analyzer 进行分词</h1><h2 id="Analysis-与-Analyzer"><a class="header-anchor" href="#Analysis-与-Analyzer">¶</a>Analysis 与 Analyzer</h2><ol><li><p>Analyses（动词）：文本分析是把全文本转换一系列单次（term/token）的过程，也叫分词。</p></li><li><p>Analysis 是通过 Analyzer 来实现的， Analyzer 叫分析器也叫分词器，可以使用 Elasticsearch 内置的分词器，或者按需定制化分词器。</p><p>在数据写入的时候，Es 对所有需要进行索引的字段或者字符串进行分词转换成词条（Term）并建立倒排索引，在匹配 Query 语句（例如用户搜索）的时候也需要用相同的分词器对查询语句进行分析</p></li></ol><h2 id="Analyzer-的组成"><a class="header-anchor" href="#Analyzer-的组成">¶</a>Analyzer 的组成</h2><p>分词器时专门处理分词的组件，Analyzer 由三部分组成</p><ul><li>Character Filters：针对原始文本处理，例如去除 html 标签等</li><li>Tokenizer：按照规则切分为单词</li><li>Token Filter：将切分的单词进行加工，例如转小写、删除<code>stopwords</code>、增加同义词等。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211217.png" alt="image-20200424102801647"></p><h2 id="Elasticsearch-的内置分词器"><a class="header-anchor" href="#Elasticsearch-的内置分词器">¶</a>Elasticsearch 的内置分词器</h2><ul><li><p>Standard Analyzer：默认分词器，按词切分，小写处理</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211222.png" alt="image-20200424103654570"></p></li><li><p>Simple Analyzer：按照非字母切分（非字母字符被过滤），小写处理</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211230.png" alt="image-20200424103757386"></p></li><li><p>Stop Analyzer：小写处理，过滤停用词（the，a，is 等）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211235.png" alt="image-20200424103910533"></p></li><li><p>Whitespace Analyzer：按照空格切分，不转小写</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211242.png" alt="image-20200424103844356"></p></li><li><p>Keyword Analyzer：不分词，直接将输入当做输出</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211248.png" alt="image-20200424103930169"></p></li><li><p>Patter Analyzer：按照正则表达式作为词条匹配进行分词，默认&quot;\W+&quot;（非字符分割）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211254.png" alt="image-20200424103949168"></p></li><li><p>Customer Analyzer：自定义分词器</p></li><li><p>Language：提供了30多种常见语言的分词器</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211301.png" alt="image-20200424104052168"></p></li></ul><h2 id="特别的中文分词与非官方分词器"><a class="header-anchor" href="#特别的中文分词与非官方分词器">¶</a>特别的中文分词与非官方分词器</h2><ol><li><p>中文分词的难点：</p><ul><li>中文句子不像英文这样单词之间有自然的空格作为分隔，也不能直接将一个句子直接切分一个个字。</li><li>一句中文，在不同的上下文，有不同的理解。（“这个苹果，不大好吃&quot;与&quot;这个苹果不大，好吃”、&quot;他说的确实在理&quot;和&quot;这事的确定不下来&quot;的&quot;确实&quot;怎么分词）</li></ul></li><li><p>ICU Analyzer：提供了 Unicode 的支持，更好的支持亚洲语言。它是一个插件，需要额外安装<code>Elasticsearch-plugin install analysis-icu</code></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211308.png" alt="image-20200424104737117"></p><p>docker 容器安装 ICU Analyzer：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z ~]# docker psCONTAINER ID        IMAGE                    COMMAND                  CREATED             STATUS              PORTS                              NAMESd9b19ed43e4c        kibana:7.1.0             "/usr/local/bin/ki..."   12 hours ago        Up 12 hours         0.0.0.0:5601->5601/tcp             kibana7d5e50115e6ad        elasticsearch:7.1.0      "/usr/local/bin/do..."   12 hours ago        Up 12 hours         0.0.0.0:9200->9200/tcp, 9300/tcp   es7_01cc44536c68b5        elasticsearch:7.1.0      "/usr/local/bin/do..."   12 hours ago        Up 12 hours         9200/tcp, 9300/tcp                 es7_02e99e24660b33        lmenezes/cerebro:0.8.3   "/opt/cerebro/bin/..."   12 hours ago        Up 12 hours         0.0.0.0:9000->9000/tcp             cerebro[root@izwz920kp0myp15p982vp4z ~]# docker exec -it es7_01 bash[root@d5e50115e6ad elasticsearch]# ./bin/elasticsearch-plugin install analysis-icu-> Downloading analysis-icu from elastic[=================================================] 100%??WARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by org.bouncycastle.jcajce.provider.drbg.DRBG (file:/usr/share/elasticsearch/lib/tools/plugin-cli/bcprov-jdk15on-1.61.jar) to constructor sun.security.provider.Sun()WARNING: Please consider reporting this to the maintainers of org.bouncycastle.jcajce.provider.drbg.DRBGWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future release-> Installed analysis-icu[root@d5e50115e6ad elasticsearch]# exitexit[root@izwz920kp0myp15p982vp4z ~]# docker exec -it es7_02 bash[root@cc44536c68b5 elasticsearch]# ./bin/elasticsearch-plugin install analysis-icu-> Downloading analysis-icu from elastic[=================================================] 100%??WARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by org.bouncycastle.jcajce.provider.drbg.DRBG (file:/usr/share/elasticsearch/lib/tools/plugin-cli/bcprov-jdk15on-1.61.jar) to constructor sun.security.provider.Sun()WARNING: Please consider reporting this to the maintainers of org.bouncycastle.jcajce.provider.drbg.DRBGWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future release-> Installed analysis-icu[root@cc44536c68b5 elasticsearch]# exitexit[root@izwz920kp0myp15p982vp4z ~]# cd /usr/local/software/elasticsearch/docker-es-7.x/[root@izwz920kp0myp15p982vp4z docker-es-7.x]# docker-compose restartRestarting kibana7 ... doneRestarting es7_01  ... doneRestarting es7_02  ... doneRestarting cerebro ... done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211315.png" alt="image-20200424110740213"></p><p>安装成功！</p></li><li><p>更多的中文分词器</p><ul><li><p><a href="https://github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">IK</a>：支持自定义词库，支持热更新分词字典。安装方法参考上面的<code>AnalysisICU</code>。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@cc44536c68b5 elasticsearch]# bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.1.0/elasticsearch-analysis-ik-7.1.0.zip<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211321.png" alt="image-20200424111035461"></p><p>分词效果测试：</p><pre><code>POST _analyze{  &quot;analyzer&quot;: &quot;ik_smart&quot;  , &quot;text&quot;: &quot;中华人民共和国国歌&quot;}POST _analyze{  &quot;analyzer&quot;: &quot;ik_max_word&quot;  , &quot;text&quot;: &quot;中华人民共和国国歌&quot;}</code></pre><p>结果：</p><ul><li><p>ik_max_word：会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合，适合 Term Query；</p></li><li><p>ik_smart：会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”，适合 Phrase 查询。</p></li></ul></li><li><p><a href="https://github.com/microbun/elasticsearch-thulac-plugin" target="_blank" rel="noopener">THULAC</a>：THU Lexucal Analyzer for Chinese，清华大学自然语言处理和社会人文计算实验室的一套中文分词器</p></li></ul></li></ol><h3 id="使用-analyzer-API"><a class="header-anchor" href="#使用-analyzer-API">¶</a>使用_analyzer API</h3><ol><li><p>直接指定 Analyzer 进行测试，并传入一个字符串看分词器对字符串的分词结果</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211326.png" alt="image-20200424103412283"></p></li><li><p>指定索引的字段进行测试</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211331.png" alt="image-20200424103444135"></p></li><li><p>自定义分词器进行测试（例如自定义它的&quot;tokenizer&quot;和&quot;filter&quot;）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211337.png" alt="image-20200424103504473"></p><p>测试请求：</p></li></ol><pre><code>#Simple Analyzer – 按照非字母切分（符号被过滤），小写处理#Stop Analyzer – 小写处理，停用词过滤（the，a，is）#Whitespace Analyzer – 按照空格切分，不转小写#Keyword Analyzer – 不分词，直接将输入当作输出#Patter Analyzer – 正则表达式，默认 \W+ (非字符分隔)#Language – 提供了30多种常见语言的分词器#2 running Quick brown-foxes leap over lazy dogs in the summer evening#查看不同的analyzer的效果#standardGET _analyze{  &quot;analyzer&quot;: &quot;standard&quot;,  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over lazy dogs in the summer evening.&quot;}#simpeGET _analyze{  &quot;analyzer&quot;: &quot;simple&quot;,  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over lazy dogs in the summer evening.&quot;}GET _analyze{  &quot;analyzer&quot;: &quot;stop&quot;,  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over lazy dogs in the summer evening.&quot;}#stopGET _analyze{  &quot;analyzer&quot;: &quot;whitespace&quot;,  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over lazy dogs in the summer evening.&quot;}#keywordGET _analyze{  &quot;analyzer&quot;: &quot;keyword&quot;,  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over lazy dogs in the summer evening.&quot;}GET _analyze{  &quot;analyzer&quot;: &quot;pattern&quot;,  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over lazy dogs in the summer evening.&quot;}#englishGET _analyze{  &quot;analyzer&quot;: &quot;english&quot;,  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over lazy dogs in the summer evening.&quot;}POST _analyze{  &quot;analyzer&quot;: &quot;icu_analyzer&quot;,  &quot;text&quot;: &quot;他说的确实在理”&quot;}POST _analyze{  &quot;analyzer&quot;: &quot;standard&quot;,  &quot;text&quot;: &quot;他说的确实在理”&quot;}POST _analyze{  &quot;analyzer&quot;: &quot;icu_analyzer&quot;,  &quot;text&quot;: &quot;这个苹果不大好吃&quot;}POST _analyze{  &quot;analyzer&quot;: &quot;ik_smart&quot;  , &quot;text&quot;: &quot;中华人民共和国国歌&quot;}POST _analyze{  &quot;analyzer&quot;: &quot;ik_max_word&quot;  , &quot;text&quot;: &quot;中华人民共和国国歌&quot;}</code></pre><h1>六、Search API</h1><h2 id="API-URI"><a class="header-anchor" href="#API-URI">¶</a>API URI</h2><table><thead><tr><th>语法</th><th>范围</th></tr></thead><tbody><tr><td>/_search</td><td>集群上所有的索引</td></tr><tr><td>/index1/_search</td><td>index1</td></tr><tr><td>/index,index2/_search</td><td>index1和 index2</td></tr><tr><td>/index*/_search</td><td>以index 开头的索引</td></tr></tbody></table><h2 id="API-请求方式"><a class="header-anchor" href="#API-请求方式">¶</a>API 请求方式</h2><ol><li><p>URI Search（GET）</p><p>在 URL 中使用查询参数</p><ul><li><p>&quot;q&quot;为 http get 作为参数，“query string syntax&quot;为 http get 参数值，内容为&quot;key:value”</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211345.png" alt="image-20200424113906460"></p></li></ul></li><li><p>Request Body Search（GET、POST）</p><p>使用 Elasticsearch 提供的，基于 JSON 格式的更加完备的 Query Domain Specific Language（DSL）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211353.png" alt="image-20200424113930239"></p></li></ol><h2 id="返回结果"><a class="header-anchor" href="#返回结果">¶</a>返回结果</h2><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211400.png" alt="image-20200424114052223"></p><h3 id="文档元信息：-score"><a class="header-anchor" href="#文档元信息：-score">¶</a>文档元信息：_score</h3><p>这个字段表示了这个文档的匹配打分，表示了其与搜索关键字的相关性（Relevance）。</p><ul><li><p>搜索是用户和搜索引擎的对话</p></li><li><p>用户关心的是搜索结果的相关性：</p><ol><li>是否可以找到所有相关的内容</li><li>有多少不相关的内容被返回了</li><li>文档的打分是否合理</li><li>结合业务需求，平衡结果排名</li></ol><p>例如搜索苹果，如果我想找的是苹果手机就不能返回水果的苹果</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211409.png" alt="image-20200424114432782"></p></li></ul><h3 id="Web搜索"><a class="header-anchor" href="#Web搜索">¶</a>Web搜索</h3><ul><li><p>Page Rank算法</p><ul><li>不仅仅是内容相关性</li><li>更重要的是内容的可信度</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211416.png" alt="image-20200424114907945"></p></li></ul><h3 id="电商搜索"><a class="header-anchor" href="#电商搜索">¶</a>电商搜索</h3><ul><li><p>搜索引擎扮演-销售的角色</p><ul><li>提高用户购物体验</li><li>提升网站销售业绩</li><li>帮助仓库消除积压库存，需要对这些需要清仓的商品进行排序提升</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211424.png" alt="image-20200424114954157"></p></li></ul><h3 id="衡量相关性（Information-Retrieval）"><a class="header-anchor" href="#衡量相关性（Information-Retrieval）">¶</a>衡量相关性（Information Retrieval）</h3><ul><li>Precision（查准率）：尽可能返回较少的无关文档</li><li>Recall（查全率）：尽量返回较多的相关文档</li><li>Ranking：是否能够按照相关度进行排序</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211432.png" alt="image-20200424115313132"></p><p>Elasticsearch 提供了很多参数来调整 Precision 和 Recall。</p><h2 id="URI-search-详解"><a class="header-anchor" href="#URI-search-详解">¶</a>URI search 详解</h2><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211439.png" alt="image-20200424123444164"></p><ul><li>q指定查询语句，使用 Query String Syntax</li><li>df 默认字段，不指定时，会对所有字段进行查询</li><li>sort 排序</li><li>from、size 用于分页</li><li>Profile 可以查看查询是如何被执行的</li></ul><h3 id="Query-String-Syntax"><a class="header-anchor" href="#Query-String-Syntax">¶</a>Query String Syntax</h3><ol><li><p>指定字段 v.s. 泛查询(DisjunctionMaxQuery)</p><p>q=title:2012、q=2012&amp;df=title</p><p>q=2012、没有指定字段，会对所有字段进行查询</p></li><li><p>TermQuery v.s. PhraseQuery（最严格的规则求尽量准的合集）</p><ul><li><p>TermQuery：最松懈的规则匹配的求尽量大的合集，也就是将查询字符串尽可能地拆分成最多的 Term 进行到倒排索引中检索文档，示例：</p><p>Beautiful Mind（等效于 Beautiful OR Mind）</p></li><li><p>PhraseQuery：最严格的规则求尽量准的合集，示例：</p><p>“Beautiful Mind”（<strong>用双引号包住</strong>，等效于 Beautiful AND Mind。还要求前后顺序保持一致）</p></li></ul></li><li><p>分组（圆括号）与引号</p><ul><li><p>title:Beautiful Mind</p><p>会对&quot;Beautiful&quot;做&quot;title&quot;字段的 TremQuery，对&quot;Mind&quot;做所有字段的 DisjunctionMaxQuery，和我们预计的对 title 字段做&quot;Beautiful OR Mind&quot;的操作不一致，此时需要用到 Elasticsearch 的分组的概念，就是用圆括号括住</p></li><li><p>title:(Beautiful Mind)</p><p>对字段 title 做&quot;Beautiful OR Mind&quot;的查询</p></li><li><p>title:(Beautilful AND Mind)</p></li><li><p>tile=“Beautiful Mind”（PhraseQuery）</p></li></ul></li><li><p>布尔操作</p><p>AND、OR、NOT 或者 &amp;&amp;、||、!</p><ul><li>必须大写</li><li>title:(matrix NOT reloaded)</li></ul></li><li><p>是否必须</p><ul><li>+表示 MUST（URI 编码之后为&quot;%2B&quot;）</li><li>-表示 MUST_NOT（同样也可以使用 URI 编码）</li><li>title:(+matrix -reloaded)</li></ul></li><li><p>范围查询</p><ul><li>[]：闭区间；{}开区间<ul><li>year:[2019 TO 2018]</li><li>year:[* TO 2018]</li></ul></li><li>算术符号<ul><li>year:&gt;2010</li><li>year:(&gt;2010 &amp;&amp; &lt;=2018)</li><li>year:(+&gt;2010 +&lt;=2018)</li></ul></li></ul></li><li><p>通配符查询</p><p>通配符查询效率低，占用内存大，不建议使用，特别是放查询条件在最前面</p><ul><li>? 表示 i个字符：title:mi?d</li><li>* 表示0个字符：title:be*</li></ul><p>正则表达</p><ul><li>title:[bt]oy</li></ul><p>模糊匹配与近似查询（通过波浪号调整 recall，后面的数字越大，recall 值越大，precision 越小）</p><ul><li>title:befutifl~1</li></ul></li><li><p>相关阅读</p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.0/search-uri-request.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.0/search-uri-request.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.0/search-search.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.0/search-search.html</a></p></li><li><p>Kibana请求示例：</p></li></ol><pre><code>#基本查询GET /movies/_search?q=2012&amp;df=title&amp;sort=year:desc&amp;from=0&amp;size=10&amp;timeout=1s#带profileGET /movies/_search?q=2012&amp;df=title{&quot;profile&quot;:&quot;true&quot;}# 指定字段GET /movies/_search?q=title:2012{&quot;profile&quot;:&quot;true&quot;}#泛查询，正对_all,所有字段GET /movies/_search?q=2012{&quot;profile&quot;:&quot;true&quot;}#指定字段GET /movies/_search?q=title:2012&amp;sort=year:desc&amp;from=0&amp;size=10&amp;timeout=1s{&quot;profile&quot;:&quot;true&quot;}# 查找美丽心灵, Mind为泛查询GET /movies/_search?q=title:Beautiful Mind{&quot;profile&quot;:&quot;true&quot;}#使用引号，Phrase查询GET /movies/_search?q=title:&quot;Beautiful Mind&quot;{&quot;profile&quot;:&quot;true&quot;}#分组，Bool查询GET /movies/_search?q=title:(Beautiful Mind){&quot;profile&quot;:&quot;true&quot;}#布尔操作符# 查找美丽心灵GET /movies/_search?q=title:(Beautiful AND Mind){&quot;profile&quot;:&quot;true&quot;}# 查找美丽心灵GET /movies/_search?q=title:(Beautiful NOT Mind){&quot;profile&quot;:&quot;true&quot;}# 查找美丽心灵GET /movies/_search?q=title:(Beautiful %2BMind){&quot;profile&quot;:&quot;true&quot;}#范围查询 ,区间写法GET /movies/_search?q=title:beautiful AND year:[2002 TO 2018%7D{&quot;profile&quot;:&quot;true&quot;}#通配符查询GET /movies/_search?q=title:[bt]oy{&quot;profile&quot;:&quot;true&quot;}//模糊匹配&amp;近似度匹配GET /movies/_search?q=title:beatifl~2{&quot;profile&quot;:&quot;true&quot;}GET /movies/_search?q=title:&quot;Lord Rings&quot;~6{&quot;profile&quot;:&quot;true&quot;}</code></pre><h2 id="Request-Body-与-Query-DSL-简介"><a class="header-anchor" href="#Request-Body-与-Query-DSL-简介">¶</a>Request Body 与 Query DSL 简介</h2><p>前面介绍了 URI 的 search 方式，另外我们还可以将查询语句（<strong>Query DSL</strong>）通过 HTTP 将 Request Body 发送给 Elasticsearch 进行 query。在 Elasticsearch 中，一些高阶的 search 操作只能在 Request Body 中做，所以建议使用 Request Body 的方式进行query 。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211449.png" alt="image-20200424140444451"></p><h3 id="分页"><a class="header-anchor" href="#分页">¶</a>分页</h3><p>在请求体第一层属性设置 from 和 size，from 从0开始，默认 size 是10。<strong>另外获取靠后的翻页成本较高</strong></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211455.png" alt="image-20200424140545527"></p><h3 id="排序"><a class="header-anchor" href="#排序">¶</a>排序</h3><p>在请求体第一层属性设置 sort 属性。<strong>最好在&quot;数字型&quot;与&quot;日期型&quot;字段上排序</strong></p><p>因为由于多值类型或分析过的字段排序，系统会选一个值，无法得知该值？</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211500.png" alt="image-20200424140745331"></p><h3 id="source-filtering"><a class="header-anchor" href="#source-filtering">¶</a>_source filtering</h3><p>Es 默认返回的是匹配的文档的所有 Field，如果我们只需要特定的 Field，可以在请求体第一层设置_source属性</p><ul><li>如果设置_source为空 ，那就只返回匹配的文档的元数据</li><li>_source 支持使用通配符：_source[“name*, desc*”]</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211507.png" alt="image-20200424140924145"></p><h3 id="脚本字段"><a class="header-anchor" href="#脚本字段">¶</a>脚本字段</h3><p>我们根据提供的脚本计算得到一个值作为一个新字段进行输出，示例：</p><p>订单中有不同的汇率，需要结合汇率对，订单价格进行排序。下面通过 Es 的&quot;painless&quot;脚本对文档中的订单日期字段拼接上一个 hello：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211517.png" alt="image-20200424141519876"></p><h3 id="使用查询表达式：Match"><a class="header-anchor" href="#使用查询表达式：Match">¶</a>使用查询表达式：Match</h3><p>如下所示：</p><ul><li>第一个示例中 comment 直接输入一个字符串，则会默认对该字符串进行分词之后得到的 term 进行 or 匹配。</li><li>如果想进行 AND 匹配，则看第二个示例，comment 需要传入一个 JSON 对象，这个对象的 query 属性是要查询的字符串，operator 属性指定了 AND 逻辑。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211523.png" alt="image-20200424141832507"></p><h3 id="短语搜索：Match-Phrase"><a class="header-anchor" href="#短语搜索：Match-Phrase">¶</a>短语搜索：Match Phrase</h3><p>这里会导致 query 属性进行 Phrase Query，所有 Term 都要匹配并且顺序一致。</p><p>另外通过指定一个 slop 字段来指定 Term 之间可以插入的字符数量</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211530.png" alt="image-20200424142153515"></p><h3 id="Kibana-测试请求"><a class="header-anchor" href="#Kibana-测试请求">¶</a>Kibana 测试请求</h3><pre><code>#ignore_unavailable=true，可以忽略尝试访问不存在的索引“404_idx”导致的报错#查询movies分页POST /movies,404_idx/_search?ignore_unavailable=true{  &quot;profile&quot;: true,&quot;query&quot;: {&quot;match_all&quot;: {}}}POST /kibana_sample_data_ecommerce/_search{  &quot;from&quot;:10,  &quot;size&quot;:20,  &quot;query&quot;:{    &quot;match_all&quot;: {}  }}#对日期排序POST kibana_sample_data_ecommerce/_search{  &quot;sort&quot;:[{&quot;order_date&quot;:&quot;desc&quot;}],  &quot;query&quot;:{    &quot;match_all&quot;: {}  }}#source filteringPOST kibana_sample_data_ecommerce/_search{  &quot;_source&quot;:[&quot;order_date&quot;],  &quot;query&quot;:{    &quot;match_all&quot;: {}  }}#脚本字段GET kibana_sample_data_ecommerce/_search{  &quot;script_fields&quot;: {    &quot;new_field&quot;: {      &quot;script&quot;: {        &quot;lang&quot;: &quot;painless&quot;,        &quot;source&quot;: &quot;doc['order_date'].value+'hello'&quot;      }    }  },  &quot;query&quot;: {    &quot;match_all&quot;: {}  }}POST movies/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;title&quot;: &quot;last christmas&quot;    }  }}POST movies/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;title&quot;: {        &quot;query&quot;: &quot;last christmas&quot;,        &quot;operator&quot;: &quot;and&quot;      }    }  }}POST movies/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;title&quot;:{        &quot;query&quot;: &quot;one love&quot;      }    }  }}POST movies/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;title&quot;:{        &quot;query&quot;: &quot;one love&quot;,        &quot;slop&quot;: 1      }    }  }}</code></pre><h3 id="Query-String-Simple-Query-String-查询"><a class="header-anchor" href="#Query-String-Simple-Query-String-查询">¶</a>Query String &amp; Simple Query String 查询</h3><ul><li><p>Query String：类似 URI Query</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211537.png" alt="image-20200424143218072"></p></li><li><p>Simple Query String</p><ul><li>类似 Query String，但是会忽略错误的语法，同时只支持部分查询语法</li><li>不支持 AND、OR、NOT，会当成字符串处理</li><li>Term 之间默认的关系是 OR，可以指定 Operator</li><li>支持部分逻辑：+替代 AND、|替代 OR、-替代 NOT</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211543.png" alt="image-20200424143404916"></p></li><li><p>Kibana测试请求</p><pre><code>PUT /users/_doc/1{  &quot;name&quot;:&quot;Ruan Yiming&quot;,  &quot;about&quot;:&quot;java, golang, node, swift, elasticsearch&quot;}PUT /users/_doc/2{  &quot;name&quot;:&quot;Li Yiming&quot;,  &quot;about&quot;:&quot;Hadoop&quot;}POST users/_search{  &quot;query&quot;: {    &quot;query_string&quot;: {      &quot;default_field&quot;: &quot;name&quot;,      &quot;query&quot;: &quot;Ruan AND Yiming&quot;    }  }}POST users/_search{  &quot;query&quot;: {    &quot;query_string&quot;: {      &quot;fields&quot;:[&quot;name&quot;,&quot;about&quot;],      &quot;query&quot;: &quot;(Ruan AND Yiming) OR (Java AND Elasticsearch)&quot;    }  }}#Simple Query 默认的operator是 OrPOST users/_search{  &quot;query&quot;: {    &quot;simple_query_string&quot;: {      &quot;query&quot;: &quot;Ruan AND Yiming&quot;,      &quot;fields&quot;: [&quot;name&quot;]    }  }}POST users/_search{  &quot;query&quot;: {    &quot;simple_query_string&quot;: {      &quot;query&quot;: &quot;Ruan Yiming&quot;,      &quot;fields&quot;: [&quot;name&quot;],      &quot;default_operator&quot;: &quot;AND&quot;    }  }}GET /movies/_search{&quot;profile&quot;: true,&quot;query&quot;:{&quot;query_string&quot;:{&quot;default_field&quot;: &quot;title&quot;,&quot;query&quot;: &quot;Beafiful AND Mind&quot;}}}# 多fieldsGET /movies/_search{&quot;profile&quot;: true,&quot;query&quot;:{&quot;query_string&quot;:{&quot;fields&quot;:[&quot;title&quot;,&quot;year&quot;],&quot;query&quot;: &quot;2012&quot;}}}GET /movies/_search{&quot;profile&quot;:true,&quot;query&quot;:{&quot;simple_query_string&quot;:{&quot;query&quot;:&quot;Beautiful +mind&quot;,&quot;fields&quot;:[&quot;title&quot;]}}}</code></pre></li></ul><h1>七、Dynamic Mapping 和常见字段类型</h1><h2 id="1、什么是-Mapping"><a class="header-anchor" href="#1、什么是-Mapping">¶</a>1、什么是 Mapping</h2><p>Mapping 类似数据库中的 schema 的定义，作用如下：</p><ul><li>定义索引中包含的字段名称（即哪些字段可以被索引）</li><li>定义可索引字段的数据类型，例如字符串，数字，布尔… …</li><li>字段，倒排索引的相关配置（ Analyzed or Not Analyzed、分词器）</li></ul><p>Mapping 会把 JSON 文档映射成 Lucene 所需要的扁平格式</p><p>在第一节中提到，在7.0之前，一个索引可以有多个 Type，每一个 Type 对应一个 Mapping 定义，Mapping 定义了这个 Type 下面被索引的文档需要满足的结构（文档只会属于一个 type），所以文档在索引中被 Type 进行了分组。（也就说，在以前应该是可以同一个字段可以定义多种类型在一个 Index 下多个 Type 中的 Mapping 的，这样是的索引更加抽象，可以兼容更多结构的数据）</p><p>但是在7.0之后，一个索引只会有一个 Type，即&quot;_DOC&quot;，这样就会导致一个字段在一个索引中只能是一种类型。也因为只有一个Type，所以不需要在 Mapping 定义中指定 type 信息。</p><h2 id="2、字段的数据类型"><a class="header-anchor" href="#2、字段的数据类型">¶</a>2、字段的数据类型</h2><p>简单类型</p><ul><li>Text、Keyword</li><li>Date</li><li>Integer、Floating</li><li>Boolean</li><li>IPv4 &amp; IPv6</li></ul><p>复杂类型（对象和嵌套对象）</p><ul><li>对象类型、嵌套类型</li></ul><p>特殊类型</p><ul><li>geo_point &amp; geo_shape、percolator(过滤器？)</li></ul><h2 id="3、Dynamic-Mapping"><a class="header-anchor" href="#3、Dynamic-Mapping">¶</a>3、Dynamic Mapping</h2><ol><li>在写入文档时，如果索引不存在，会自动创建索引</li><li>Dynamic Mapping 的机制，使得我们无需手动定义 Mappinigs。Elasticsearch 会自动根据文档信息，推算出字段类型</li><li>但是有时候会推算得不对，例如地理位置信息</li><li>当类型如果设置不对时，会导致一些功能无法正常运行，例如 Range 查询。</li></ol><h2 id="4、类型识别"><a class="header-anchor" href="#4、类型识别">¶</a>4、类型识别</h2><table><thead><tr><th>JSON 类型</th><th>Elasticsearch 类型</th></tr></thead><tbody><tr><td>字符串</td><td>1. 匹配日期格式，设置成 Date，这个也是可以配置的，默认是开启的；2. 通过配置是的其识别数字设置成 float 或者 long，该选项默认关闭；3. 设置为 Text，并且增加 keyword 子字段</td></tr><tr><td>布尔值</td><td>boolean</td></tr><tr><td>浮点型</td><td>float</td></tr><tr><td>整数</td><td>long</td></tr><tr><td>对象</td><td>Object</td></tr><tr><td>数组</td><td>由第一个非空数字得类型所决定</td></tr><tr><td>空值</td><td>忽略</td></tr><tr><td></td><td></td></tr></tbody></table><p>我们看一下下面的示例：uid 和 isAdmin 字段都将被设置成 text，因为默认下是没有开启自动识别数字字符串的，而对于 boolean 值字符串是更加不会自动转换了<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211551.png" alt="image-20200424152015964"></p><h2 id="5、能否更改-Mapping-的字段类型"><a class="header-anchor" href="#5、能否更改-Mapping-的字段类型">¶</a>5、能否更改 Mapping 的字段类型</h2><h3 id="新增字段"><a class="header-anchor" href="#新增字段">¶</a>新增字段</h3><ul><li>如果 Dynamic 设置为 true时，一旦有新增字段的文档写入，Mapping 也同时被更新</li><li>Dynamic 设为 false，Mapping 不会被更新，新增字段不会被索引，如果用户根据指定这个字段来搜索信息，就会报错（如果不指定该字段搜索，不会报错，但是不会检索该字段内容）；但是字段的信息会被随着文档存储到 Elasticsearch 中，如果这个文档其他字段被索引了，那么这个文档还是可以被搜索出来，该字段也会出现在文档的_source 中</li><li>Dynamic 设置为 Strict，这个文档写入动作将直接抛出错误 400</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211557.png" alt="image-20200424152951556"></p><h3 id="已有字段"><a class="header-anchor" href="#已有字段">¶</a>已有字段</h3><ul><li>对已有字段，<strong>一旦已经有数据写入</strong>，就不再支持修改字段定义（Lucene 实现的倒排索引，一旦生成后，就不允许修改）</li><li>如果希望修改字段类型，必须 ReIndex API，重新索引</li></ul><h3 id="原因"><a class="header-anchor" href="#原因">¶</a>原因</h3><ul><li>如果修改了字段的数据类型，会导致已被索引的索引无法被搜索</li><li>但是如果是增加新的字段，就不会有这样的影响</li></ul><h3 id="Kibana-测试请求数据"><a class="header-anchor" href="#Kibana-测试请求数据">¶</a>Kibana 测试请求数据</h3><pre><code>#写入文档，查看 MappingPUT mapping_test/_doc/1{  &quot;firstName&quot;:&quot;Chan&quot;,  &quot;lastName&quot;: &quot;Jackie&quot;,  &quot;loginDate&quot;:&quot;2018-07-24T10:29:48.103Z&quot;}#查看 Mapping文件GET mapping_test/_mapping#Delete indexDELETE mapping_test#dynamic mapping，推断字段的类型PUT mapping_test/_doc/1{    &quot;uid&quot; : &quot;123&quot;,    &quot;isVip&quot; : false,    &quot;isAdmin&quot;: &quot;true&quot;,    &quot;age&quot;:19,    &quot;heigh&quot;:180}#查看 DynamicGET mapping_test/_mapping#默认Mapping支持dynamic，写入的文档中加入新的字段PUT dynamic_mapping_test/_doc/1{  &quot;newField&quot;:&quot;someValue&quot;}#该字段可以被搜索，数据也在_source中出现POST dynamic_mapping_test/_search{  &quot;query&quot;:{    &quot;match&quot;:{      &quot;newField&quot;:&quot;someValue&quot;    }  }}#修改为dynamic falsePUT dynamic_mapping_test/_mapping{  &quot;dynamic&quot;: false}#新增 anotherFieldPUT dynamic_mapping_test/_doc/10{  &quot;anotherField&quot;:&quot;someValue&quot;}#该字段不可以被搜索，因为dynamic已经被设置为falsePOST dynamic_mapping_test/_search{  &quot;query&quot;:{    &quot;match&quot;:{      &quot;anotherField&quot;:&quot;someValue&quot;    }  }}get dynamic_mapping_test/_doc/10#修改为strictPUT dynamic_mapping_test/_mapping{  &quot;dynamic&quot;: &quot;strict&quot;}#写入数据出错，HTTP Code 400PUT dynamic_mapping_test/_doc/12{  &quot;lastField&quot;:&quot;value&quot;}DELETE dynamic_mapping_test</code></pre><h2 id="6、显式-Mapping-设置与常见参数介绍"><a class="header-anchor" href="#6、显式-Mapping-设置与常见参数介绍">¶</a>6、显式 Mapping 设置与常见参数介绍</h2><h3 id="如何定义一个-Mapping"><a class="header-anchor" href="#如何定义一个-Mapping">¶</a>如何定义一个 Mapping</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211609.png" alt="image-20200424154409744"></p><ol><li><p>可以参考 API 手册，纯手写</p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/dynamic-mapping.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/dynamic-mapping.html</a></p></li><li><p>为了减少输入的工作量，减少出错率，可以依照以下步骤</p><ul><li>创建一个临时的 index，写入一些样本数据</li><li>通过访问 Mapping API获得临时文件的动态 Mapping 定义</li><li>修改后用，使用该配置创建你的索引</li><li>删除临时索引</li></ul></li></ol><h3 id="Mapping-参数设置-官网介绍"><a class="header-anchor" href="#Mapping-参数设置-官网介绍">¶</a>Mapping 参数设置(<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/mapping-params.html" target="_blank" rel="noopener">官网介绍</a>)</h3><ul><li><p>通过字段的 index 属性设置控制当前字段是否被索引，默认为 true，即可被索引</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211616.png" alt="image-20200424154722660"></p><p>设置为 false 之后，如果还指定该字段进行索引，将会遇到以下报错</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211621.png" alt="image-20200424154820530"></p></li><li><p>通过 index_options 属性设置字段索引的级别</p><ol><li>docs：记录 doc id</li><li>freqs：记录 doc id 和 term frequencies</li><li>position：记录 doc id 、term frequencies 和 term position</li><li>offsets：记录 doc id、term frequencies、term position 和 character offsets</li></ol><p>Text 类型默认记录 positions，其他默认为 docs。（记录内容越多，占用存储空间越大）</p></li><li><p>实现对字段进行 null 值搜索</p><p>通过设定索引字段的&quot;null_value&quot;属性为字符串&quot;NULL&quot;，即可进行 NULL 值搜索。（<strong>注意：只有 Keyword 类型支持设定 Null_value</strong>）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211628.png" alt="image-20200424155413611"></p></li><li><p>通过 copy_to 属性指定一个字段表示将当前字段的索引映射到该字段，从而可以实现一个字段索引其他多个字段的内容</p><ol><li>copy_to 将字段的数值拷贝到目标字段，实现类似_all的作用</li><li>之前的_all 字段，在7中已经被 copy_to 所替代</li><li>满足一些特定的搜索需求</li><li>copy_to 的目标字段不出现在_source 中</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211634.png" alt="image-20200424155747257"></p></li></ul><h3 id="数组类型"><a class="header-anchor" href="#数组类型">¶</a>数组类型</h3><p>Elasticsearch 中不提供专门的数组类型。但是任何字段，都可以包含多个相同类型的数据。可以看下以下测试内容，第一个请求执行之后，插入了一个 text 类型的 interests 的字段，第二个请求也是可以执行成功，我们看一下此时的 Mapping 定义，发现这个字段的类型还是 text，并不是一个数组，同时也符合我们前面讲到的，Mapping 的字段类型在该字段已经有数据被索引之后是不可以被修改的</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211642.png" alt="image-20200424155935807"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211648.png" alt="image-20200424160319336"></p><h3 id="多字段类型"><a class="header-anchor" href="#多字段类型">¶</a>多字段类型</h3><p>当我们为一个索引定义 mapping的时候，可以为索引字段定义子字段，而 Elasticsearch 本身对于 text 类型的字段都会加上一个&quot;keyword&quot;类型的子字段。</p><p>这个多字段的特性使得我们可以为一个字段定制更多其他的索引以及检索方式（通过指定不同的 analyzer）：</p><ul><li>例如一个字段同时支持不同语言的搜索</li><li>对字段支持 pinyin 的搜索</li><li>还支持设置在搜索和索引的时候使用不同的 analyzer</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211656.png" alt="image-20200424163132903"></p><h3 id="Exact-Values-v-s-Full-Text"><a class="header-anchor" href="#Exact-Values-v-s-Full-Text">¶</a>Exact Values v.s. Full Text</h3><p>精确值与全文本</p><ul><li>Exact Value：包括数字、日期、具体一个字符串（例如&quot;App Store&quot;，这是一个业务意义上的最小单元短语，<strong>这在 Elasticsearch 中类型为 keyword</strong>）</li><li>Full Text：非结构化的文本数据（<strong>Elasticsearch 中的 text</strong>）</li></ul><p>对于 keyword 类型的数据来说，是没有必要再进行分词处理的了，在 Elasticsearch 中定义了 keyword 类型就是为了避免不必要的分词处理，所以 Elasticsearch 在对每一个字段进行检索的时候如果遇到 Exact Value（如果是创建的时候遇到了自定义了 keyword 类型的字段呢？），不需要做特殊的分词处理，较少性能的浪费。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211703.png" alt="image-20200424171205492"></p><h3 id="自定义分词"><a class="header-anchor" href="#自定义分词">¶</a>自定义分词</h3><p>当 Elasticsearch 自带的分词器无法满足时，可以自定义分词器。通过自组合不同的组件实现：</p><ul><li><p>Character Filter</p><p>在 Tokenizer 之前对文本进行处理，例如增加删除及替换字符。可以配置多个 Character Filters。会影响 Tokenizer 的 position 和 offset 信息。以下是一些 Es 自带的 Character FIlters：</p><ul><li>HTML strip：去掉 html 标签</li><li>Mapping：字符串替换</li><li>Pattern replace：正则匹配替换</li></ul></li><li><p>Tokenizer</p><p>将原始文本按照一定的规则，切分为词（Term or token），以下是一些 Es 内置的 Tokenizer，当然也可以自己使用 Java 开发实现自己的 Tokenizer：</p><ul><li>whitespace</li><li>standard</li><li>uax_url_email</li><li>pattern</li><li>keyword：不做任何处理</li><li>path hierarchy</li></ul></li><li><p>Token Filter</p><p>将 Tokenizer 输出的单词（term）进行增加修改删除，以下时自带的一些 Token FIlters：</p><ul><li>Lowercase</li><li>stop</li><li>synonym（添加同义词）</li></ul></li></ul><p>在定义索引的 mapping 的时候通过组合以上三种组件定义自己想要的分词器</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211712.png" alt="image-20200424172350477"></p><p>Kibana 请求参数测试：</p><pre><code>PUT logs/_doc/1{&quot;level&quot;:&quot;DEBUG&quot;}GET /logs/_mappingPOST _analyze{  &quot;tokenizer&quot;:&quot;keyword&quot;,  &quot;char_filter&quot;:[&quot;html_strip&quot;],  &quot;text&quot;: &quot;&lt;b&gt;hello world&lt;/b&gt;&quot;}POST _analyze{  &quot;tokenizer&quot;:&quot;path_hierarchy&quot;,  &quot;text&quot;:&quot;/user/ymruan/a/b/c/d/e&quot;}#使用char filter进行替换POST _analyze{  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;char_filter&quot;: [      {        &quot;type&quot; : &quot;mapping&quot;,        &quot;mappings&quot; : [ &quot;- =&gt; _&quot;]      }    ],  &quot;text&quot;: &quot;123-456, I-test! test-990 650-555-1234&quot;}//char filter 替换表情符号POST _analyze{  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;char_filter&quot;: [      {        &quot;type&quot; : &quot;mapping&quot;,        &quot;mappings&quot; : [ &quot;:) =&gt; happy&quot;, &quot;:( =&gt; sad&quot;]      }    ],    &quot;text&quot;: [&quot;I am felling :)&quot;, &quot;Feeling :( today&quot;]}// white space and snowballGET _analyze{  &quot;tokenizer&quot;: &quot;whitespace&quot;,  &quot;filter&quot;: [&quot;stop&quot;,&quot;snowball&quot;],  &quot;text&quot;: [&quot;The gilrs in China are playing this game!&quot;]}// whitespace与stopGET _analyze{  &quot;tokenizer&quot;: &quot;whitespace&quot;,  &quot;filter&quot;: [&quot;stop&quot;,&quot;snowball&quot;],  &quot;text&quot;: [&quot;The rain in Spain falls mainly on the plain.&quot;]}//remove 加入lowercase后，The被当成 stopword删除GET _analyze{  &quot;tokenizer&quot;: &quot;whitespace&quot;,  &quot;filter&quot;: [&quot;lowercase&quot;,&quot;stop&quot;,&quot;snowball&quot;],  &quot;text&quot;: [&quot;The gilrs in China are playing this game!&quot;]}//正则表达式GET _analyze{  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;char_filter&quot;: [      {        &quot;type&quot; : &quot;pattern_replace&quot;,        &quot;pattern&quot; : &quot;http://(.*)&quot;,        &quot;replacement&quot; : &quot;$1&quot;      }    ],    &quot;text&quot; : &quot;http://www.elastic.co&quot;}</code></pre><h2 id="7、Index-Template和-Dynamic-Template"><a class="header-anchor" href="#7、Index-Template和-Dynamic-Template">¶</a>7、Index Template和 Dynamic Template</h2><h3 id="Index-Template"><a class="header-anchor" href="#Index-Template">¶</a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/indices-templates.html" target="_blank" rel="noopener">Index Template</a></h3><p>帮助你设定 Mappings 和 Settings，并按照一定的规则，自动匹配到新创建的索引之上（<strong>其匹配属性是一个数组，即可以设定多个匹配规则</strong>）</p><ul><li>模板仅在一个索引被新创建之前存在，才会对这个准备新建的索引产生作用。修改模板不会影响已创建的索引。</li><li>你可以设定多个索引模板，这些设置会被&quot;merge&quot;在一起</li><li>你可以指定&quot;order&quot;的数值，控制&quot;merging&quot;的过程</li></ul><h4 id="两个-Index-Templates-例子："><a class="header-anchor" href="#两个-Index-Templates-例子：">¶</a>两个 Index Templates 例子：</h4><ul><li>第一个例子中设定了所有索引的创建都设定主分片和副本分片数量是1</li><li>第二个例子中设定了以test 开头的索引的主分片数量是1，副本分片数量是2；另外我们将 Es 自动识别日期字符串且转换类型的功能关闭，然后把自动识别数值字符串且转换类型的功能启用。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211720.png" alt="image-20200424180915555"></p><h4 id="Index-Template-的工作方式"><a class="header-anchor" href="#Index-Template-的工作方式">¶</a>Index Template 的工作方式</h4><p>当一个索引被新创建时，会按照一下步骤设置 Mappings：</p><ol><li>应用 Elasticsearch 默认的 settings 和 mappings</li><li>应用 order 数值低的 index template 中的设定，之前的设定会被覆盖</li><li>应用 order 高的 index template 中的设定，之前的设定会被覆盖</li><li>如果用户创建索引的时候自己指定了 Settings 和 Mappings，则覆盖其设置的设定到之前的设定中。</li></ol><h3 id="Dynamic-Template"><a class="header-anchor" href="#Dynamic-Template">¶</a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/dynamic-mapping.html" target="_blank" rel="noopener">Dynamic Template</a></h3><p>上面提到的 Index Template 是应用在所有索引上面的，它是定义在一个_template 的命名空间的，index_patterns 是它的其中一个匹配属性（<strong>其匹配属性也是一个数组，即可以设定多个匹配规则</strong>），该属性匹配的是索引对象；</p><p>而 Dynamic Template 是定义在一个具体的索引上的，同样它也有匹配属性，但是它的匹配属性匹配的是当前这个 Mapping 的字段，也就是说 Dynamic Template 是直接应用在当前 Index 的字段上的，所以我们可以使用 Dynamic Template 设置字段匹配规则对特定的字段进行特定 mapping 设定，从而实现一个&quot;动态的索引&quot;。例如可以实现以下需求：</p><ul><li>所有的字符串类型都设定成 Keyword，或者关闭 keyword 字段。</li><li>is 开头的字段都设置成 boolean</li><li>long_开头的都设置成 long 类型</li></ul><p>下面是三个 Dynamic Template 的例子：</p><ul><li>第一个 Index 中定义了两个 Dynamic Template，它们的名字分别是&quot;strings_as_boolean&quot;和&quot;strings_as_keywords&quot;，前者将所有 is 开头的字符串设置成 boolean 类型，后者将其他类型转成 keyword 类型（所以 templates 的应用优先顺序应该是和定义顺序是一样的）</li><li>第二个 Index 定义了一个 Dynamic Template，将 name.开头，非.middle 结尾的字段设置为 text 类型并链接索引到一个 full_name 字段</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211741.png" alt="image-20200424182832139"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211752.png" alt="image-20200424182839704"></p><h3 id="Kibana-测试请求-v2"><a class="header-anchor" href="#Kibana-测试请求-v2">¶</a>Kibana 测试请求</h3><pre><code>#数字字符串被映射成text，日期字符串被映射成日期PUT ttemplate/_doc/1{&quot;someNumber&quot;:&quot;1&quot;,&quot;someDate&quot;:&quot;2019/01/01&quot;}GET ttemplate/_mapping#Create a default templatePUT _template/template_default{  &quot;index_patterns&quot;: [&quot;*&quot;],  &quot;order&quot; : 0,  &quot;version&quot;: 1,  &quot;settings&quot;: {    &quot;number_of_shards&quot;: 1,    &quot;number_of_replicas&quot;:1  }}PUT /_template/template_test{    &quot;index_patterns&quot; : [&quot;test*&quot;],    &quot;order&quot; : 1,    &quot;settings&quot; : {    &quot;number_of_shards&quot;: 1,        &quot;number_of_replicas&quot; : 2    },    &quot;mappings&quot; : {    &quot;date_detection&quot;: false,    &quot;numeric_detection&quot;: true    }}#查看template信息GET /_template/template_defaultGET /_template/temp*#写入新的数据，index以test开头PUT testtemplate/_doc/1{&quot;someNumber&quot;:&quot;1&quot;,&quot;someDate&quot;:&quot;2019/01/01&quot;}GET testtemplate/_mappingget testtemplate/_settingsPUT testmy{&quot;settings&quot;:{&quot;number_of_replicas&quot;:5}}put testmy/_doc/1{  &quot;key&quot;:&quot;value&quot;}get testmy/_settingsDELETE testmyDELETE /_template/template_defaultDELETE /_template/template_test#Dynaminc Mapping 根据类型和字段名DELETE my_indexPUT my_index/_doc/1{  &quot;firstName&quot;:&quot;Ruan&quot;,  &quot;isVIP&quot;:&quot;true&quot;}GET my_index/_mappingDELETE my_indexPUT my_index{  &quot;mappings&quot;: {    &quot;dynamic_templates&quot;: [            {        &quot;strings_as_boolean&quot;: {          &quot;match_mapping_type&quot;:   &quot;string&quot;,          &quot;match&quot;:&quot;is*&quot;,          &quot;mapping&quot;: {            &quot;type&quot;: &quot;boolean&quot;          }        }      },      {        &quot;strings_as_keywords&quot;: {          &quot;match_mapping_type&quot;:   &quot;string&quot;,          &quot;mapping&quot;: {            &quot;type&quot;: &quot;keyword&quot;          }        }      }    ]  }}DELETE my_index#结合路径PUT my_index{  &quot;mappings&quot;: {    &quot;dynamic_templates&quot;: [      {        &quot;full_name&quot;: {          &quot;path_match&quot;:   &quot;name.*&quot;,          &quot;path_unmatch&quot;: &quot;*.middle&quot;,          &quot;mapping&quot;: {            &quot;type&quot;:       &quot;text&quot;,            &quot;copy_to&quot;:    &quot;full_name&quot;          }        }      }    ]  }}PUT my_index/_doc/1{  &quot;name&quot;: {    &quot;first&quot;:  &quot;John&quot;,    &quot;middle&quot;: &quot;Winston&quot;,    &quot;last&quot;:   &quot;Lennon&quot;  }}GET my_index/_search?q=full_name:John</code></pre><h1>八、Elasticsearch 聚合分析简介（<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations.html" target="_blank" rel="noopener">官方介绍地址</a>）</h1><p>Elasticsearch 除搜索以外，提供的针对 ES 数据进行统计分析的功能</p><ul><li>实时性高</li><li>Hadoop（T+1）</li></ul><p>通过聚合，我们会得到一个数据的概览，是分析和总结全套的数据，而不是寻找单个文档</p><ul><li>尖沙咀和香港岛的客户数量</li><li>不同的价格区间，可预定的经济型酒店和五星级酒店的数量</li></ul><p>高性能，只需要一条语句，就可以从 Elasticsearch 得到分析结果，无需在客户端自己去实现分析逻辑</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211800.png" alt="image-20200424185029724"></p><h2 id="集合的分类"><a class="header-anchor" href="#集合的分类">¶</a>集合的分类</h2><h3 id="Bucket-和-Metric"><a class="header-anchor" href="#Bucket-和-Metric">¶</a>Bucket 和 Metric</h3><ol><li>Bucket Aggregation：一系列满足特定条件的文档的集合</li></ol><ul><li>一些例子：<ul><li>杭州属于浙江、一个演员属于男性或者女性</li><li>嵌套关系：杭州属于浙江属于中国属于亚洲</li></ul></li><li>Elasticsearch 提供了很多类型的 Bucket，帮助你用多种方式划分文档。（如 Term 或者 Range，按照时间、年龄区间、地理位置进行划分等）</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211806.png" alt="image-20200424185849559"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211812.png" alt="image-20200424190233006"></p><ol start="2"><li>Metric Aggregation：一些数学运算，可以对文档字段进行统计分析</li></ol><ul><li>Metric 会基于数据集计算结果，除了支持在字段上进行计算，同样也支持在脚本（painless script）产生的结果之上进行计算</li><li>大多数 Metric 是数学计算，仅输出一个值：min、max、sum、avg、cardinlity</li><li>部分 Metric 支持输出多个数值：stats、percentiles、precentille_ranks</li></ul><ol start="3"><li>两者类比</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211819.png" alt="image-20200424185407354"></p><ol start="4"><li>Kibana 测试请求</li></ol><pre><code>#按照目的地进行分桶统计GET kibana_sample_data_flights/_search{&quot;size&quot;: 0,&quot;aggs&quot;:{&quot;flight_dest&quot;:{&quot;terms&quot;:{&quot;field&quot;:&quot;DestCountry&quot;}}}}#查看航班目的地的统计信息，增加平均，最高最低价格GET kibana_sample_data_flights/_search{&quot;size&quot;: 0,&quot;aggs&quot;:{&quot;flight_dest&quot;:{&quot;terms&quot;:{&quot;field&quot;:&quot;DestCountry&quot;},&quot;aggs&quot;:{&quot;avg_price&quot;:{&quot;avg&quot;:{&quot;field&quot;:&quot;AvgTicketPrice&quot;}},&quot;max_price&quot;:{&quot;max&quot;:{&quot;field&quot;:&quot;AvgTicketPrice&quot;}},&quot;min_price&quot;:{&quot;min&quot;:{&quot;field&quot;:&quot;AvgTicketPrice&quot;}}}}}}#价格统计信息+天气信息GET kibana_sample_data_flights/_search{&quot;size&quot;: 0,&quot;aggs&quot;:{&quot;flight_dest&quot;:{&quot;terms&quot;:{&quot;field&quot;:&quot;DestCountry&quot;},&quot;aggs&quot;:{&quot;stats_price&quot;:{&quot;stats&quot;:{&quot;field&quot;:&quot;AvgTicketPrice&quot;}},&quot;wather&quot;:{  &quot;terms&quot;: {    &quot;field&quot;: &quot;DestWeather&quot;,    &quot;size&quot;: 5  }}}}}}</code></pre><ul><li><p>Pipeline Aggregation：对其他的聚合结果进行二次聚合</p></li><li><p>Matrix Aggregation：支持对多个字段的操作并提供一个结果矩阵</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>008_数据建模</title>
      <link href="/2020/12/22/elasticsearch/008-shu-ju-jian-mo/"/>
      <url>/2020/12/22/elasticsearch/008-shu-ju-jian-mo/</url>
      
        <content type="html"><![CDATA[<p>[toc]</p><h1>数据的关联关系</h1><p>真实世界中有很多重要的关联关系：</p><ul><li>博客、作者、评论</li><li>银行账户有多次交易记录</li><li>客户有多个银行账户</li><li>目录文件有多个文件和子目录</li></ul><p>在关系型数据库中，提供了一些范式化设计。</p><ul><li>1NF：消除非主属性对键的部分函数依赖</li><li>2NF：消除非主要属性对键的传递函数依赖</li><li>3NF：消除主属性对键的传递函数依赖</li><li>BCNF：主属性不依赖于主属性</li></ul><p>范式化设计（Normalization） 主要目的是&quot;减少不必要的更新&quot;。但是带来的副作用就是，一个完全范式化设计的数据库会经常面临&quot;查询缓慢&quot;的问题（数据库越范式化，就需要 join 越多的表）在最近的场景中，随着查询场景的增多，这个问题会暴露的越明显。除了可以简化操作（减少不必要的更新）之外还有节省存储空间的优点。但是最近存储空间却越来越便宜。</p><p>所以就有了反范式化设计（Denormalization）的概念。反范式化设计就是使得数据&quot;Flattening&quot;（扁平化），不使用关联关系，而是在文档中保存冗余的数据拷贝。</p><ul><li>其优点是无需处理 join 操作，数据读取性能好。Elasticsearch 通过压缩_source 字段，减少磁盘空间的开销。</li><li>缺点是不适合在数据频繁修改的场景，一条数据的改动，可能会引起很多数据的更新。</li></ul><p>关系型数据库一般会考虑 Normalize 数据；而在 Elasticsearch 中，往往考虑 Denormalize 数据，读取数据的时候无需连接表、无需行锁、读取速度变快。</p><p>Elasticsearch 并不擅长处理关联关系。我们一般采用以下4种方法处理关联：</p><ul><li>对象类型</li><li>嵌套对象（Nested Object）</li><li>父子关联关系（Parent/Child）</li><li>用户自己在应用端关联</li></ul><h3 id="对象及-Nested-对象"><a class="header-anchor" href="#对象及-Nested-对象">¶</a>对象及 Nested 对象</h3><p>数据关系其实可以最终抽象为一对一、一对多的关系（多对一和多对多关系都是由它们转化或者组合而来）。</p><h4 id="案例1：一对一关系（对象）"><a class="header-anchor" href="#案例1：一对一关系（对象）">¶</a>案例1：一对一关系（对象）</h4><p>我们来看一个以博客为主导的博客和作者的关系，对于一个博客来说，它只会有一个作者。所以我们可以通过以下设置来设定&quot;博客&quot;索引的 mapping。可以看到：</p><ul><li>我们在mappings 下面的 properties 属性中设置博客索引的子属性，通过设置每个 properties 的子属性的一个 type 属性来指定其具体的&quot;ES 普通类型&quot;。（content、time 属性）</li><li>但是在 user 属性中，我们没有对其 type 属性值进行设定，<strong>而是设定了一个 properties 属性</strong>，属性值是一个嵌套的 JSON 对象，它包含了&quot;text&quot;类型的&quot;city&quot;属性、&quot;long&quot;类型的&quot;userid&quot;属性、&quot;keyword&quot;类型的&quot;username&quot;属性。这就是 ES 的 &quot;对象&quot;类型数据的设定方式。</li></ul><pre><code>DELETE blog# 设置blog的 MappingPUT /blog{  &quot;mappings&quot;: {    &quot;properties&quot;: {      &quot;content&quot;: {        &quot;type&quot;: &quot;text&quot;      },      &quot;time&quot;: {        &quot;type&quot;: &quot;date&quot;      },      &quot;user&quot;: {        &quot;properties&quot;: {          &quot;city&quot;: {            &quot;type&quot;: &quot;text&quot;          },          &quot;userid&quot;: {            &quot;type&quot;: &quot;long&quot;          },          &quot;username&quot;: {            &quot;type&quot;: &quot;keyword&quot;          }        }      }    }  }}</code></pre><p>其实我们插入一条文档数据</p><pre><code># 插入一条 Blog 信息PUT blog/_doc/1{  &quot;content&quot;:&quot;I like Elasticsearch&quot;,  &quot;time&quot;:&quot;2019-01-01T00:00:00&quot;,  &quot;user&quot;:{    &quot;userid&quot;:1,    &quot;username&quot;:&quot;Jack&quot;,    &quot;city&quot;:&quot;Shanghai&quot;  }}</code></pre><p>在查询的时候通过 <code>user.xxx=xxx</code> 的指定作者的信息进行条件查询（包括查询的时候也是这样来更新指定博客文档中的作者信息）：</p><pre><code># 查询 Blog 信息POST blog/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: [        {&quot;match&quot;: {&quot;content&quot;: &quot;Elasticsearch&quot;}},        {&quot;match&quot;: {&quot;user.username&quot;: &quot;Jack&quot;}}      ]    }  }}</code></pre><h4 id="案例2：一对多关系（Nested-对象）"><a class="header-anchor" href="#案例2：一对多关系（Nested-对象）">¶</a>案例2：一对多关系（Nested 对象）</h4><p>我们来看一个电影和演员的例子，这是一个一对多关系，一个电影可以包含多个演员。下面我们来分析下在 ES 中关于一对多关系是如何存储的。</p><h5 id="1、在索引中设置对象型字段"><a class="header-anchor" href="#1、在索引中设置对象型字段">¶</a>1、在索引中设置对象型字段</h5><p>先准备数据。可以看到我们创建了一个电影索引，其包含了两个字段：一个是 title 字段，类型为普通类型&quot;text&quot;；另一个 actors 字段是一个对象类型。这个对象包含一个&quot;keyword&quot;普通类型的 first_name 字段和一个&quot;keyword&quot;普通类型的 last_name 字段（<strong>注意，在 ES 中不用指定数组类型，每个文档的每个字段默认可以存储多个值</strong>）。</p><p>然后我们写入了一条电影文档数据：title 为 “Speed”；actors 有：“Keanu Reeves&quot;和&quot;Dnnis Hopper” 两位。</p><pre><code>DELETE my_movies# 电影的Mapping信息PUT my_movies{      &quot;mappings&quot; : {      &quot;properties&quot; : {        &quot;actors&quot; : {          &quot;properties&quot; : {            &quot;first_name&quot; : {              &quot;type&quot; : &quot;keyword&quot;            },            &quot;last_name&quot; : {              &quot;type&quot; : &quot;keyword&quot;            }          }        },        &quot;title&quot; : {          &quot;type&quot; : &quot;text&quot;,          &quot;fields&quot; : {            &quot;keyword&quot; : {              &quot;type&quot; : &quot;keyword&quot;,              &quot;ignore_above&quot; : 256            }          }        }      }    }}# 写入一条电影信息POST my_movies/_doc/1{  &quot;title&quot;:&quot;Speed&quot;,  &quot;actors&quot;:[    {      &quot;first_name&quot;:&quot;Keanu&quot;,      &quot;last_name&quot;:&quot;Reeves&quot;    },    {      &quot;first_name&quot;:&quot;Dennis&quot;,      &quot;last_name&quot;:&quot;Hopper&quot;    }  ]}</code></pre><h5 id="2、基于对象型字段的查询"><a class="header-anchor" href="#2、基于对象型字段的查询">¶</a>2、基于对象型字段的查询</h5><p>下面我们尝试来查询数据，分别指定&quot;actors.first_name&quot;和&quot;actors.last_name&quot;为&quot;Keanu&quot;和&quot;Hopper&quot;，理论上应该查询不出来数据。但是实际上看到竟然匹配到了数据。下面我们来分析下为什么会匹配到了数据</p><pre><code># 查询电影信息POST my_movies/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: [        {&quot;match&quot;: {&quot;actors.first_name&quot;: &quot;Keanu&quot;}},        {&quot;match&quot;: {&quot;actors.last_name&quot;: &quot;Hopper&quot;}}      ]    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214954.png" alt="image-20200429143625922"></p><h5 id="3、ES-对对象型字段的存储方法"><a class="header-anchor" href="#3、ES-对对象型字段的存储方法">¶</a>3、ES 对对象型字段的存储方法</h5><p>为什么上面会匹配到数据呢？这是因为，ES 在对文档数据进行存储的时候，内部对象的边界是没有考虑在内的，JSON 格式被处理成扁平式键值对的结构。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215012.png" alt="image-20200429144129911"></p><p>当对一个对象类型的属性进行多值&quot;并&quot;查询的时候就会导致了意外的搜索结果。此时我们可以通过用 Nested Data Type解决这个问题。</p><h5 id="4、创建-nested-对象型字段"><a class="header-anchor" href="#4、创建-nested-对象型字段">¶</a>4、创建 nested 对象型字段</h5><p>创建 nested 类型字段。删除之前创建的索引，重新创建索引，可以看到，<strong>我们在设定&quot;actors&quot;字段的时候除了指定&quot;properties&quot;属性之外，还设定了一个&quot;type&quot;属性为&quot;nested&quot;</strong>。</p><pre><code>DELETE my_movies# 创建 Nested 对象 MappingPUT my_movies{      &quot;mappings&quot; : {      &quot;properties&quot; : {        &quot;actors&quot; : {          &quot;type&quot;: &quot;nested&quot;,          &quot;properties&quot; : {            &quot;first_name&quot; : {&quot;type&quot; : &quot;keyword&quot;},            &quot;last_name&quot; : {&quot;type&quot; : &quot;keyword&quot;}          }},        &quot;title&quot; : {          &quot;type&quot; : &quot;text&quot;,          &quot;fields&quot; : {&quot;keyword&quot;:{&quot;type&quot;:&quot;keyword&quot;,&quot;ignore_above&quot;:256}}        }      }    }}POST my_movies/_doc/1{  &quot;title&quot;:&quot;Speed&quot;,  &quot;actors&quot;:[    {      &quot;first_name&quot;:&quot;Keanu&quot;,      &quot;last_name&quot;:&quot;Reeves&quot;    },    {      &quot;first_name&quot;:&quot;Dennis&quot;,      &quot;last_name&quot;:&quot;Hopper&quot;    }  ]}</code></pre><h5 id="5、基于-nested-型字段的查询和聚合"><a class="header-anchor" href="#5、基于-nested-型字段的查询和聚合">¶</a>5、基于 nested 型字段的查询和聚合</h5><p>基于 nested 类型字段的查询。此时我们如果需要对 nested 类型字段进行查询，就需要使用一个 “nested” 查询，然后通过设定其&quot;path&quot;属性为我们要查询的&quot;nested&quot;类型的字段名称&quot;actors&quot;。然后再在里面嵌套上我们前面的 bool 查询的内容。可以看到，这次查询不正确的姓和名组合就没有返回数据了。</p><pre><code># Nested 查询POST my_movies/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: [        {&quot;match&quot;: {&quot;title&quot;: &quot;Speed&quot;}},        {          &quot;nested&quot;: {            &quot;path&quot;: &quot;actors&quot;,            &quot;query&quot;: {              &quot;bool&quot;: {                &quot;must&quot;: [                  {&quot;match&quot;: {                    &quot;actors.first_name&quot;: &quot;Keanu&quot;                  }},                  {&quot;match&quot;: {                    &quot;actors.last_name&quot;: &quot;Hopper&quot;                  }}                ]              }            }          }        }      ]    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215018.png" alt="image-20200429145346645"></p><p>当我们查询正确的姓名组合的时候，就可以返回正确的数据</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215027.png" alt="image-20200429145518567"></p><p>当我们再用一个正确的姓名组合去做一个普通的非 nested 的 bool 查询的时候，会发现也匹配不到数据了，为什么会这样呢？下面我们来分析一下原因。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215035.png" alt="image-20200429145635416"></p><p>另外当我们需要对 nested 类型的字段进行聚合的时候，我们一样要声明当前聚合操作是对于 nested 类型字段的聚合。通过在具体的 agg 对象内部声明一个&quot;nested&quot;的属性对象，一样的，该对象的&quot;path&quot;属性设置为 nested 类型字段的名称。</p><pre><code># Nested AggregationPOST my_movies/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;actors&quot;: {      &quot;nested&quot;: {        &quot;path&quot;: &quot;actors&quot;      },      &quot;aggs&quot;: {        &quot;actor_name&quot;: {          &quot;terms&quot;: {            &quot;field&quot;: &quot;actors.first_name&quot;,            &quot;size&quot;: 10          }        }      }    }  }}</code></pre><h5 id="6、ES-对于-nested-型字段的存储方法"><a class="header-anchor" href="#6、ES-对于-nested-型字段的存储方法">¶</a>6、ES 对于 nested 型字段的存储方法</h5><p>在 ES 中，对于 nested 数据类型，会对该字段所有对象进行独立索引。在 ES 内部会将这个多个nested 类型属性对象索引到多个分隔的 Lucene 文档中，在查询的时候做 Join 处理。所以我们在对 nested 类型数据的时候需要 nested 查询，该查询会让 ES 知道当前用户需要到另外的一个独立的 nested 文档集合进行数据查找，而 nested 这个文档集合的名称（用来在当前索引中聚合这些文档，其实可以理解为给这些文档起了个统一前缀）在建立的时候是取的该 nested 类型字段名做关联的，所以我们需要指定字段名告诉 ES 到哪个nested 文档集合进行关联查询。</p><p>另外我们上面还尝试使用正确姓和名的组合是查询不出来数据的。正如我们上面的描述，ES 在存储 nested 类型数据的时候是存储到另外一个专门存储 nested 类型字段数据的独立文档中的，所以一个正常的 bool 查询就是在当前文档中进行指定的&quot;键值匹配&quot;。当然找不到数据！</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215042.png" alt="image-20200429150333417"></p><h4 id="相关阅读"><a class="header-anchor" href="#相关阅读">¶</a>相关阅读</h4><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-nested-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-nested-query.html</a></p></blockquote><h3 id="文档的父子关系"><a class="header-anchor" href="#文档的父子关系">¶</a>文档的父子关系</h3><p>经过上面的介绍我们知道了可以使用对象类型字段和 nested 对象类型字段存储有关系的数据。但是使用这两种数据类型有一个局限性就是，当需要对文档中的嵌套的对象类型字段或者 nested 对象类型字段进行更新的时候，我们往往也要更新其他文档中的数据。</p><p>例如1个作者有3篇文章，我们在 ES 中存储了以文章为主导的文档数据，其中文章文档中有一个对象（或者 nested 对象）类型字段表示其作者。所以当前索引中是有三个文章文档的作者字段内容是一样的，但我们修改了这个作者的信息的时候，需要同时更新这三个文章文档。</p><p>这在某些索引的写操作远远比读操作要频繁的时候，是很不友好的。所以 ES 还提供了另外一种类似关系型数据库中 join 的实现。使用 join 数据类型实现，可以 通过维护 parent、child 的关系，从而分离两个对象：</p><ul><li>父文档和子文档是同时存在于索引中的两个独立的文档</li><li>更新父文档无需重新索引子文档。子文当被添加，更新或者删除也不会影响父文档和其他的子文档。</li></ul><h5 id="1、定义父子关系的几个步骤"><a class="header-anchor" href="#1、定义父子关系的几个步骤">¶</a>1、定义父子关系的几个步骤</h5><p>我们使用以下请求创建一个名为&quot;my_blogs&quot;的索引：</p><ol><li><p>通过 settings 设定了该索引的分片数为2</p></li><li><p>在 mappinigs 中显示设置了两个字段为 context 和 title，前者为 text 类型，后者为 keyword 类型。在业务上，这两个字段都属于博客的字段。</p></li><li><p>此外在 mappings 中我们还设置了一个关键属性&quot;blog_comments_relation&quot;，它的 type 字段不是 ES 中的普通字段类型也不是 nested 类型，而是&quot;join&quot;，ES 会基于该属性在该索引上建立一个父子文档关系对象。</p><p>其中由&quot;relations&quot;关键字来维护多个父子关系集合，relation 对象的每个属性都代表一个父子关系，可以通过设置多个属性来设置多个父子关系：其中属性名为当前父子关系中的父文档的标识；属性值为当前父子关系的子文档标识。在往当前索引中索引文档的时候通过设置文档字段&quot;blog_comments_relation.name&quot;为 relation 中某个属性的属性名后者属性值来指定当前文档是哪对父子关系中的父或者子文档。</p><p><strong>（注意：同一个索引中不能创建多个&quot;join&quot;类型的同级属性；relations 关键字不支持多值。设置了就会报4xx 的错误）</strong></p></li></ol><pre><code>DELETE my_blogs# 设定 Parent/Child MappingPUT my_blogs{  &quot;settings&quot;: {    &quot;number_of_shards&quot;: 2  },  &quot;mappings&quot;: {    &quot;properties&quot;: {      &quot;blog_comments_relation&quot;: {        &quot;type&quot;: &quot;join&quot;,        &quot;relations&quot;: {          &quot;blog&quot;: &quot;comment&quot;        }      },      &quot;content&quot;: {        &quot;type&quot;: &quot;text&quot;      },      &quot;title&quot;: {        &quot;type&quot;: &quot;keyword&quot;      }    }  }}</code></pre><h5 id="2、索引父文档"><a class="header-anchor" href="#2、索引父文档">¶</a>2、索引父文档</h5><p>下面我们索引两个父文档（博客数据对象）到索引中：</p><ol><li>我们分别为它们指定了 id 为&quot;blog1&quot;和&quot;blog2&quot;，为了后面索引子文档的时候方便获取该 id</li><li>它们包含的字段有&quot;title&quot;和&quot;content&quot;</li><li>其中我们还通过指定文档数据的&quot;blog_comments_relation.name&quot;来标识其为&quot;blog:comment&quot;父子关系中的父文档（blog）</li></ol><pre><code>#索引父文档PUT my_blogs/_doc/blog1{  &quot;title&quot;:&quot;Learning Elasticsearch&quot;,  &quot;content&quot;:&quot;learning ELK @ geektime&quot;,  &quot;blog_comments_relation&quot;:{    &quot;name&quot;:&quot;blog&quot;  }}#索引父文档PUT my_blogs/_doc/blog2{  &quot;title&quot;:&quot;Learning Hadoop&quot;,  &quot;content&quot;:&quot;learning Hadoop&quot;,    &quot;blog_comments_relation&quot;:{    &quot;name&quot;:&quot;blog&quot;  }}</code></pre><h5 id="3、索引子文档"><a class="header-anchor" href="#3、索引子文档">¶</a>3、索引子文档</h5><p>下面我们往索引中索引了3个子文档：</p><ol><li><p>我们分别指定了它们的 id 为 comment1、comment2和 comment3并<strong>给他们设置了路由分片的 hash key 为对应的父文档 id，这非常重要，我们需要保证父文档和子文档必须存在相同的分片上以确保查询 join 的性能。</strong>（如果父文档和子文档没有同时在同一个分片上会发生什么？这个待后续研究）</p></li><li><p>子文档包含了两个未在 mapping 上显示声明的字段 comment 和 username</p></li><li><p><strong>通过指定文档的&quot;blog_comments_relation.name&quot;属性为 comment 来指定当前文档为&quot;blog:comment&quot;父子关系中的子文档。</strong></p><p><strong>通过指定文档的&quot;blog_comments_relation.parent&quot;属性为当前文档的父文档 id 来指定当前子文档的父文档，这是必须的</strong></p></li></ol><pre><code>#索引子文档PUT my_blogs/_doc/comment1?routing=blog1{  &quot;comment&quot;:&quot;I am learning ELK&quot;,  &quot;username&quot;:&quot;Jack&quot;,  &quot;blog_comments_relation&quot;:{    &quot;name&quot;:&quot;comment&quot;,    &quot;parent&quot;:&quot;blog1&quot;  }}#索引子文档PUT my_blogs/_doc/comment2?routing=blog2{  &quot;comment&quot;:&quot;I like Hadoop!!!!!&quot;,  &quot;username&quot;:&quot;Jack&quot;,  &quot;blog_comments_relation&quot;:{    &quot;name&quot;:&quot;comment&quot;,    &quot;parent&quot;:&quot;blog2&quot;  }}#索引子文档PUT my_blogs/_doc/comment3?routing=blog2{  &quot;comment&quot;:&quot;Hello Hadoop&quot;,  &quot;username&quot;:&quot;Bob&quot;,  &quot;blog_comments_relation&quot;:{    &quot;name&quot;:&quot;comment&quot;,    &quot;parent&quot;:&quot;blog2&quot;  }}</code></pre><h5 id="4、查询"><a class="header-anchor" href="#4、查询">¶</a>4、查询</h5><h6 id="1）查询所有文档"><a class="header-anchor" href="#1）查询所有文档">¶</a>1）查询所有文档</h6><p>可以看到查询所有文档的时候，索引内的所有父子文档都是可以返回的，包括文档的父子关系标识信息。</p><pre><code># 查询所有文档POST my_blogs/_search{}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215051.png" alt="image-20200429170601599"></p><h6 id="2）通过文档-id-直接查询父文档（不包含子文档内容）"><a class="header-anchor" href="#2）通过文档-id-直接查询父文档（不包含子文档内容）">¶</a>2）通过文档 id 直接查询父文档（不包含子文档内容）</h6><p>可以看到也是可以返回的，父文档不包含子文档的内容</p><pre><code>#根据父文档ID查看GET my_blogs/_doc/blog2</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215104.png" alt="image-20200429170747744"></p><h6 id="3）通过-“parent-id”-查询查询子文档信息"><a class="header-anchor" href="#3）通过-“parent-id”-查询查询子文档信息">¶</a>3）通过 “parent_id” 查询查询子文档信息</h6><ul><li>指定 query 为 parent_id 类型的查询</li><li>并设置parent_id 的子属性 type 为 comment（即 mapping 中设置的 relations 关键字中的属性值）指定子文档的类型</li><li>指定 parent_id 的子属性 id 为父文档的 id “blog2”</li></ul><p>可以看到，ES 返回了 blog2 父文档的2个子文档 comment2和 comment3</p><pre><code># Parent Id 查询POST my_blogs/_search{  &quot;query&quot;: {    &quot;parent_id&quot;: {      &quot;type&quot;: &quot;comment&quot;,      &quot;id&quot;: &quot;blog2&quot;    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215114.png" alt="image-20200429171114422"></p><h6 id="4）“has-child”-查询通过子文档的信息查询父文档"><a class="header-anchor" href="#4）“has-child”-查询通过子文档的信息查询父文档">¶</a>4）“has_child” 查询通过子文档的信息查询父文档</h6><ul><li>指定 query 类型为&quot;has_child&quot;查询类型</li><li>通过设置 has_child 的子属性 type 为comment（即 mapping 中设置的 relations 关键字中的属性值）指定子文档的类型</li><li>设置一个查询对象到 has_child 的子属性，这里设置为 match 查询类型，查询字段是 username，值为 “Jack”</li></ul><p>以上请求在收到信息之后会去查询类型为 comment 的子文档中是否有 username 为&quot;jack&quot;的文档，如果有，则返回其关联的父文档。可以看到，结果中返回了 blog1和 blog2父文档，它们分别关联一个comment1和 comment2子文档其中 username 字段都是 Jack。</p><pre><code># Has Child 查询,返回父文档POST my_blogs/_search{  &quot;query&quot;: {    &quot;has_child&quot;: {      &quot;type&quot;: &quot;comment&quot;,      &quot;query&quot; : {          &quot;match&quot;: {              &quot;username&quot; : &quot;Jack&quot;          }      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215121.png" alt="image-20200429171625009"></p><h6 id="5）“has-parent”-查询通过父文档的信息查询子文档"><a class="header-anchor" href="#5）“has-parent”-查询通过父文档的信息查询子文档">¶</a>5）“has_parent” 查询通过父文档的信息查询子文档</h6><p>和&quot;has_child&quot;类似，&quot;has_parent&quot;则是通过父文档的信息查询子文档。</p><ul><li>指定 query 类型为&quot;has_parent&quot;查询类型</li><li>通过设置 has_parent 的子属性 type 为 blog（即 mapping 中设置的 relations 关键字中的属性值）指定父文档的类型</li><li>设置一个查询对象到 has_parent 的子属性，这里设置为 match 查询类型，查询字段是  title，值为 “Learning Hadoop”</li></ul><p>以上请求在收到信息之后会去查询类型为 blog 的父文档中进行&quot;titile = Learning Hadoop&quot;的 match 查询，如果匹配到了文档数据，则返回其关联的子文档。可以看到，结果中返回了 comment2和 comment3 子文档，它们都关联 blog2父文档，而该父文档的 title 就是&quot;Learning Hadoop&quot;（该字段类型是 keyword，精准匹配）。</p><pre><code># Has Parent 查询，返回相关的子文档POST my_blogs/_search{  &quot;query&quot;: {    &quot;has_parent&quot;: {      &quot;parent_type&quot;: &quot;blog&quot;,      &quot;query&quot; : {        &quot;match&quot;: {            &quot;title&quot; : &quot;Learning Hadoop&quot;        }      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215129.png" alt="image-20200429172448481"></p><h6 id="6）-通过文档-id-直接访问子文档"><a class="header-anchor" href="#6）-通过文档-id-直接访问子文档">¶</a>6） 通过文档 id 直接访问子文档</h6><p>当我们直接通过子文档的 id 进行访问子文档的时候，是查询不到子文档的。</p><pre><code>#通过ID ，访问子文档GET my_blogs/_doc/comment3</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215136.png" alt="image-20200429173007166"></p><p>需要在id 后面加上 routing 才行：</p><pre><code>#通过ID和routing ，访问子文档GET my_blogs/_doc/comment3?routing=blog2</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215141.png" alt="image-20200429173042470"></p><p>另外通过 id 更新子文档的时候也要指定 routing：</p><pre><code>#更新子文档PUT my_blogs/_doc/comment3?routing=blog2{    &quot;comment&quot;: &quot;Hello Hadoop??&quot;,    &quot;blog_comments_relation&quot;: {      &quot;name&quot;: &quot;comment&quot;,      &quot;parent&quot;: &quot;blog2&quot;    }}</code></pre><h3 id="嵌套对象-v-s-父子文档"><a class="header-anchor" href="#嵌套对象-v-s-父子文档">¶</a>嵌套对象 v.s. 父子文档</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215151.png" alt="image-20200429173328674"></p><h3 id="相关阅读-v2"><a class="header-anchor" href="#相关阅读-v2">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-has-child-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-has-child-query.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-has-parent-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-has-parent-query.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-parent-id-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-parent-id-query.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-parent-id-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-parent-id-query.html</a></p></blockquote><h1>重建索引</h1><p>一般在以下几种情况时，我们需要重建索引：</p><ol><li>索引的 Mappings 发生变更：字段类型更改、分词器及字段更新</li><li>索引的 Settings 发生变更：索引的主分片数发生改变</li><li>集群内/集群间需要做数据迁移</li></ol><p>ES 内置的关于重建索引的 API 两个：</p><ul><li>Update By Query：在现有索引上重建</li><li>Reindex：在其他索引上重新构建出当前索引</li></ul><h3 id="案例1：为索引增加子字段（Update-By-Query）"><a class="header-anchor" href="#案例1：为索引增加子字段（Update-By-Query）">¶</a>案例1：为索引增加子字段（Update By Query）</h3><p>下面我们来描述一个给索引 mapping 中的字段增加一个子字段并使用 Update By Query 重建索引的过程。</p><ol><li><p>直接往一个索引在写入文档，使用 ES 的 Dynamic Mapping 自动创建索引</p><pre><code>DELETE blogs/# 写入文档PUT blogs/_doc/1{  &quot;content&quot;:&quot;Hadoop is cool&quot;,  &quot;keyword&quot;:&quot;hadoop&quot;}</code></pre></li><li><p>查看刚刚创建的索引，可以看到 ES  为这个索引创建了一个 Mapping，并自动设置content和 keyword 字段，类型都是 text，并且都为他们创建一个子字段keyword，类型为 keyword。</p></li></ol><pre><code># 查看 MappingGET blogs/_mapping</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215159.png" alt="image-20200429175813394"></p><ol start="3"><li><p>其实我们想修改 Mapping 中的 content 字段，为其增加一个子字段&quot;english&quot;，类型不变，设置分词器为&quot;english&quot;，使得我们更好地使用英文内容对该字段进行搜索。</p><pre><code># 修改 Mapping，增加子字段，使用英文分词器PUT blogs/_mapping{  &quot;properties&quot; : {    &quot;content&quot; : {      &quot;type&quot; : &quot;text&quot;,      &quot;fields&quot; : {        &quot;english&quot; : {          &quot;type&quot; : &quot;text&quot;,          &quot;analyzer&quot;:&quot;english&quot;        }      }    }  }}</code></pre></li><li><p>写入新的文档并对新加的字段进行查询，是可以查出来数据的</p><pre><code># 写入文档PUT blogs/_doc/2{  &quot;content&quot;:&quot;Elasticsearch rocks&quot;,  &quot;keyword&quot;:&quot;elasticsearch&quot;}# 查询新写入文档POST blogs/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;content.english&quot;: &quot;Elasticsearch&quot;    }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215219.png" alt="image-20200429180358045"></p></li><li><p>但是当我们对旧的文档对新加字段进行查询的时候，发现查询不到数据。</p><pre><code># 查询 Mapping 变更前写入的文档POST blogs/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;content.english&quot;: &quot;Hadoop&quot;    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215228.png" alt="image-20200429180541028"></p></li><li><p>使用 <code>_update_by_query</code> api 进行现有的索引重建后再查询新数据。即可查询出来了。</p><pre><code># Update所有文档POST blogs/_update_by_query{}# 查询之前写入的文档POST blogs/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;content.english&quot;: &quot;Hadoop&quot;    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215239.png" alt="image-20200429180708458"></p></li></ol><h3 id="案例2：更改-Mapping-中的字段的类型（ReIndex）"><a class="header-anchor" href="#案例2：更改-Mapping-中的字段的类型（ReIndex）">¶</a>案例2：更改 Mapping 中的字段的类型（ReIndex）</h3><p>ES 是不允许我们修改现有 mapping 中已经定义的字段的类型的，直接报错：</p><pre><code>PUT blogs/_mapping{        &quot;properties&quot; : {        &quot;content&quot; : {          &quot;type&quot; : &quot;text&quot;,          &quot;fields&quot; : {            &quot;english&quot; : {              &quot;type&quot; : &quot;text&quot;,              &quot;analyzer&quot; : &quot;english&quot;            }          }        },        &quot;keyword&quot; : {          &quot;type&quot; : &quot;keyword&quot;        }      }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215248.png" alt="image-20200429181124513"></p><p>那么如果我们确实要修改字段类型怎么办呢？只能创建新的索引，并且设置正确的字段类型，再通过 reindex api 将老索引的数据导入到新索引。下面我们来描述一个修改Mapping 中字段的场景：</p><ol><li><p>创建新索引并设置正确的字段类型</p><pre><code>DELETE blogs_fix# 创建新的索引并且设定新的MappingPUT blogs_fix/{  &quot;mappings&quot;: {        &quot;properties&quot; : {        &quot;content&quot; : {          &quot;type&quot; : &quot;text&quot;,          &quot;fields&quot; : {            &quot;english&quot; : {              &quot;type&quot; : &quot;text&quot;,              &quot;analyzer&quot; : &quot;english&quot;            }          }        },        &quot;keyword&quot; : {          &quot;type&quot; : &quot;keyword&quot;        }      }      }}</code></pre></li><li><p>调用 ES 的 <code>_reindex</code> api 将老索引的数据重新导入到新索引</p><pre><code># Reindx APIPOST  _reindex{  &quot;source&quot;: {    &quot;index&quot;: &quot;blogs&quot;  },  &quot;dest&quot;: {    &quot;index&quot;: &quot;blogs_fix&quot;  }}</code></pre><p>从新索引查询 id 为1的文档</p><pre><code>GET  blogs_fix/_doc/1</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215256.png" alt="image-20200429181628754"></p><p>我们刚刚将一个 keyword 字段从 text 类型修改为 keyword 类型，通过 terms agg 进行测试，是没有问题的：</p><pre><code># 测试 Term AggregationPOST blogs_fix/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;blog_keyword&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;keyword&quot;,        &quot;size&quot;: 10      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215303.png" alt="image-20200429181927451"></p></li></ol><h4 id="ReIndex-总结"><a class="header-anchor" href="#ReIndex-总结">¶</a>ReIndex 总结</h4><h6 id="1、使用场景"><a class="header-anchor" href="#1、使用场景">¶</a>1、使用场景</h6><ul><li>修改索引的主分片数</li><li>改变 Mapping 中的字段类型</li><li>集群内数据迁移/跨集群的数据迁移</li></ul><h6 id="2、数据冲突的解决方案"><a class="header-anchor" href="#2、数据冲突的解决方案">¶</a>2、数据冲突的解决方案</h6><p>另外当我们往新索引中进行 _reindex 的时候，有可能已经存在了一些数据。在默认情况下以及设置&quot;dest.version_type=internal&quot;的时候，ES 将会将强制覆盖所有已经存在的文档，然后版本号+1。</p><pre><code>//默认情况POST _reindex{  &quot;source&quot;: {    &quot;index&quot;: &quot;twitter&quot;  },  &quot;dest&quot;: {    &quot;index&quot;: &quot;new_twitter&quot;  }}//设置 version_type 为 internalPOST _reindex{  &quot;source&quot;: {    &quot;index&quot;: &quot;twitter&quot;  },  &quot;dest&quot;: {    &quot;index&quot;: &quot;new_twitter&quot;,    &quot;version_type&quot;: &quot;internal&quot;  }}</code></pre><p>通过设置&quot;dest.version_type=external&quot;可以让 ES 在遇到已经存在的文档的时候比较两者的版本，当已存在于 dest 中的文档的版本低于 source 中版本的时候，就会更新dest 中的该文档；如果无冲突将直接索引文档。</p><p>另外我们可以通过设置&quot;dest.op_type=create&quot;来让 _reindex 仅仅创建目标 index 中缺失的文档。所有的已经存在的文档都会导致一个版本冲突。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215313.png" alt="image-20200429200157335"></p><p>默认情况下，以上版本冲突会使得 _reindex 操作中止。我们可以通过设置 _reindex 的直接属性 “conflicts=proceed” 让 _reindex 在遇到版本冲突的时候跳过当前这个文档，继续处理下一个文档，当 _reindex 完成之后会返回遇到版本冲突的数量。（注意，这个参数仅仅可以对版本冲突错误有效，其他错误还是会中止 _reindex 操作）</p><h6 id="3、筛选需要-reindex-的数据"><a class="header-anchor" href="#3、筛选需要-reindex-的数据">¶</a>3、筛选需要 _reindex 的数据</h6><p>有时，我们并不想对所有的文档进行迁移。我们可以通过在 source 属性中指定一个查询来筛选我们需要 _reindex 的数据。此外，对于 size、sort 等在查询动作中设定的参数都是可以设置的，具体参考官方文档。</p><pre><code>POST _reindex{  &quot;source&quot;: {    &quot;index&quot;: &quot;twitter&quot;,    &quot;query&quot;: {      &quot;term&quot;: {        &quot;user&quot;: &quot;kimchy&quot;      }    }  },  &quot;dest&quot;: {    &quot;index&quot;: &quot;new_twitter&quot;  }}</code></pre><h6 id="4、跨集群-Reindex"><a class="header-anchor" href="#4、跨集群-Reindex">¶</a>4、跨集群 Reindex</h6><p>ES 同时还支持跨集群的 reindex，我们先在本地（dest）中修改 elasticearch.yml 文件中的配置<code>reindex.remote.whitelist: &quot;otherhost:9200, another:9200”</code>开启白名单（对 source 的端口），然后设置 source 的 remote 属性进行远程连接配置，最后发起 _reindex 操作</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215338.png" alt="image-20200429201706072"></p><h6 id="5、异步-reiindex"><a class="header-anchor" href="#5、异步-reiindex">¶</a>5、异步 reiindex</h6><p>同时 reindex 还支持异步操作。通过指定 url 参数<code>wait_for_completion=false</code>来实现：</p><pre><code>POST _reindex?wait_for_completion=false{... ...}</code></pre><p>此时执行该请求将会得到一个 task id。可以通过 _task api 来查看任务状态：</p><pre><code>GET _tsak?detailed=true&amp;actions=*reindex{}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215345.png" alt="image-20200429202014925"></p><blockquote><p>使用 Reindex API 的注意点：</p><ol><li>在进行 reindex 操作的 source index 中，必须保证所有文档的 _source 字段是可用的。</li><li>reindex api 不会去尝试创建目标索引，也不会复制源索引的 settings 到目标索引。用户必须在进行 _reindex 之前手动设置目标索引的 mappings、shard  数量、replicas 等。</li><li>建议对 api 使用 alias，在 reindex 好之后可以直接切换 alias 指向的新 index 即可。</li></ol></blockquote><h3 id="相关阅读-v3"><a class="header-anchor" href="#相关阅读-v3">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/docs-reindex.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/docs-reindex.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/docs-update-by-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/docs-update-by-query.html</a></p></blockquote><h1>Ingest Pipeline &amp; Painless Script</h1><h3 id="Ingest-Node"><a class="header-anchor" href="#Ingest-Node">¶</a>Ingest Node</h3><p>Ingest Node 是在 Elasticsearch 5.0后，引入了一种新的节点。默认配置下，每个节点都是Ingest Node。</p><ol><li>可拦截 Index 或者 Bulk API 的请求，对数据进行预处理（如：为某个字段设置默认值、重命名某个字段的字段名、对字段值进行 Split 操作等），处理完成之后重新返回给 index 或者 Buik API</li><li>相对 Logstash 无需额外引入新的工具依赖，就可以进行数据预处理</li><li>支持设置 Painless 脚本，对数据进行更加复杂的加工</li></ol><p>例如以下 index 的请求中 tags 字段时候一个使用逗号分隔的文本，我们现在需要对其进行分隔之后再存入 ES，方便后期需要对 Tags 字段进行Aggregation 统计：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215356.png" alt="image-20200429205049625"></p><h4 id="1、Pipeline-Processor"><a class="header-anchor" href="#1、Pipeline-Processor">¶</a>1、Pipeline &amp; Processor</h4><p>Pipeline：管道会对通过的数据（文档）按照顺序进行加工。</p><p>Processor：Elasticsearch 对一些加工的行为进行了抽象包装，它提供了很多内置的 Processors。也支持通过插件的方式，实现自己的 Processor。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215405.png" alt="image-20200429205543898"></p><h4 id="2、Ingest-API"><a class="header-anchor" href="#2、Ingest-API">¶</a>2、Ingest API</h4><p>参考下面的示例，ingest api 在 ES 中是一个定级 api，路径为_ingest。后面紧跟的就是 pipeline，即我们上面提到的概念。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215411.png" alt="image-20200429213050917"></p><h5 id="1）Ingest-pipeline-测试"><a class="header-anchor" href="#1）Ingest-pipeline-测试">¶</a>1）Ingest pipeline 测试</h5><p>在 pipeline 后面定义的路径或者 restful 方法就是ES 实际提供的 ingest api。_simulate 是 ES 提供的一个可以对 ingest pipeline 进行测试的 api。参考以下示例：</p><ul><li><p>我们对该 api 的请求体对象中的 pipeline属性进行了定义，包括这个 pipeline 的描述和 pipeliine 中包含的 processors。</p><p>这里仅定义了两个 processors：第一个是&quot;split&quot; processor，它对所有文档的&quot;tags&quot;字段进行一个以&quot;,“为分隔符的分隔操作，然后将分隔后得到的一个字符串数组覆盖到文档的 tags 属性中；第二个是&quot;set” processor，为每一个文档增加一个字段，并设置默认值为0。</p></li><li><p>然后在 api 请求体中通过设置 docs 填充测试文档数据。可以看到这些文档数据都包含一个 tags 字段，都是以逗号分隔。且都增加了一个 view 字段，值为0。</p></li></ul><p>可以看到api 发出调用后返回的结果中，两个文档的 tags 字段都被分隔成了一个数组。</p><pre><code>//对 tags 字段进行逗号切割，并为所有文档增加一个字段默认值为0POST _ingest/pipeline/_simulate{  &quot;pipeline&quot;: {    &quot;description&quot;: &quot;to split blog tags&quot;,    &quot;processors&quot;: [      {        &quot;split&quot;: {          &quot;field&quot;: &quot;tags&quot;,          &quot;separator&quot;: &quot;,&quot;        }      },       {        &quot;set&quot;:{          &quot;field&quot;: &quot;views&quot;,          &quot;value&quot;: 0        }      }    ]  },  &quot;docs&quot;: [    {      &quot;_index&quot;:&quot;index&quot;,      &quot;_id&quot;:&quot;id&quot;,      &quot;_source&quot;:{        &quot;title&quot;:&quot;Introducing big data......&quot;,        &quot;tags&quot;:&quot;hadoop,elasticsearch,spark&quot;,        &quot;content&quot;:&quot;You konw, for big data&quot;      }    },    {      &quot;_index&quot;:&quot;index&quot;,      &quot;_id&quot;:&quot;idxx&quot;,      &quot;_source&quot;:{        &quot;title&quot;:&quot;Introducing cloud computering&quot;,        &quot;tags&quot;:&quot;openstack,k8s&quot;,        &quot;content&quot;:&quot;You konw, for cloud&quot;      }    }  ]}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215420.png" alt="image-20200429211257800"></p><h5 id="2）新增一个-ingest-pipeline"><a class="header-anchor" href="#2）新增一个-ingest-pipeline">¶</a>2）新增一个 ingest pipeline</h5><p>在上面经过测试之后我们的 ingest pipeline 是没有问题的，此时我们就可以创建这个 pipeline 对象了。通过调用 PUT 方法并在 _ingest/pipeline/ 后面加上我们要创建的这个 pipeline 对象的 id进行创建。</p><p>然后可以通过 GET 方法使用同样的 URI 进行查询动作。</p><p>另外我们还能对创建之后的 pipeline 再次进行 _simulate 的测试动作，请求方法为 POST 方法，URI 则是上面创建和查询使用的 URI 拼接上子路径 _simulate，然后在请求体中直接设置测试文档到&quot;docs&quot;属性。而不用像前面的测试动作一样需要指定&quot;pipeline&quot;属性。</p><pre><code># 为ES添加一个 PipelinePUT _ingest/pipeline/blog_pipeline{  &quot;description&quot;: &quot;a blog pipeline&quot;,  &quot;processors&quot;: [      {        &quot;split&quot;: {          &quot;field&quot;: &quot;tags&quot;,          &quot;separator&quot;: &quot;,&quot;        }      },      {        &quot;set&quot;:{          &quot;field&quot;: &quot;views&quot;,          &quot;value&quot;: 0        }      }    ]}#查看PiplelineGET _ingest/pipeline/blog_pipeline#测试pipelinePOST _ingest/pipeline/blog_pipeline/_simulate{  &quot;docs&quot;: [    {      &quot;_source&quot;: {        &quot;title&quot;: &quot;Introducing cloud computering&quot;,        &quot;tags&quot;: &quot;openstack,k8s&quot;,        &quot;content&quot;: &quot;You konw, for cloud&quot;      }    }  ]}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215429.png" alt="image-20200429211636889"></p><h5 id="3）使用创建之后的-ingest-pipeline"><a class="header-anchor" href="#3）使用创建之后的-ingest-pipeline">¶</a>3）使用创建之后的 ingest pipeline</h5><p>在创建了 ingest pipeline 之后我们就可以在对文档 index 的时候（通过 index或者 bulk api）使用这些 pipeline 了。</p><p>下面我们来看一些例子：</p><p>我们在第一个请求中没使用 ingest pipeline，tags 中的数据是原封不动地存储到文档中然后被索引；而在第二个请求中，我们<strong>在索引数据的 URI 后面使用了一个&quot;piipeline=${pipeline_name}&quot;的参数</strong>，指定了我们要对本次文档数据使用id 为&quot;blog_pipeline&quot;的 ingest pipeline 进行预处理，即我们前面创建的 pipeline。</p><p>两个索引文档的请求都执行之后，我们通过 _search api 查询索引后的两个文档。可以看到第一个文档的 tags 还是没有处理的；而第二个文档的 tags 字段则是被分隔成了一个字符串数组。</p><pre><code>#不使用pipeline更新数据PUT tech_blogs/_doc/1{  &quot;title&quot;:&quot;Introducing big data......&quot;,  &quot;tags&quot;:&quot;hadoop,elasticsearch,spark&quot;,  &quot;content&quot;:&quot;You konw, for big data&quot;}#使用pipeline更新数据PUT tech_blogs/_doc/2?pipeline=blog_pipeline{  &quot;title&quot;: &quot;Introducing cloud computering&quot;,  &quot;tags&quot;: &quot;openstack,k8s&quot;,  &quot;content&quot;: &quot;You konw, for cloud&quot;}#查看两条数据，一条被处理，一条未被处理POST tech_blogs/_search{}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215435.png" alt="image-20200429212336066"></p><p>除了上面的例子，我们还可以在前面提到的重构索引的 api <code>_update_by_query</code>中使用 ingest pipeline。但是如果基于上面的数据直接执行的话，会得到类型转换异常的错误，因为有一个文档的该字段已经被转成了数组类型，对应 java 中的 ArrayList，&quot;split&quot;操作需要的是一个字符串类型字段，而此时它已经不是一个 String，解决方法看下面。</p><pre><code>#update_by_query 会导致错误POST tech_blogs/_update_by_query?pipeline=blog_pipeline{}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215455.png" alt="image-20200429212605175"></p><p>此时我们可以通过设置 <code>_update_by_query</code>的 api 设置查询参数实现将我们更新过的数据进行过滤。可以看到我们前面设置的 pipeline 中其实还设置了一个给文档增加一个新字段 view 的操作。所以我们可以将查询条件设置为必须不存在一个 view字段的数据才进行 _update_by_query 操作。此时再对该字段指定我们前面设置的pipeline，就不会遇到已经被处理过的数据了，即可正常执行。</p><pre><code>#增加update_by_query的条件POST tech_blogs/_update_by_query?pipeline=blog_pipeline{    &quot;query&quot;: {        &quot;bool&quot;: {            &quot;must_not&quot;: {                &quot;exists&quot;: {                    &quot;field&quot;: &quot;views&quot;                }            }        }    }}</code></pre><h4 id="3、一些内置Processors"><a class="header-anchor" href="#3、一些内置Processors">¶</a>3、一些内置Processors</h4><ul><li><p>Split Processor (例:将给定字段值分成⼀一个数组)</p></li><li><p>Remove / Rename Processor (例:移除⼀个重命名字段)</p></li><li><p>Append (例:为商品增加⼀个新的标签)</p></li><li><p>Convert(例:将商品价格，从字符串转换成 float 类型)</p></li><li><p>Date / JSON(例:⽇期格式转换，字符串转 JSON 对象)</p></li><li><p>Date Index Name Processor (例:将通过该处理器的⽂档，分配到指定时间格式的索引中)</p></li><li><p>Fail Processor (⼀旦出现异常，该 Pipeline 指定的错误信息能返回给用户)</p></li><li><p>Foreach Process(数组字段，数组的每个元素都会使⽤到一个相同的处理器)</p></li><li><p>Grok Processor(⽇志的⽇期格式切割)</p></li><li><p>Gsub / Join / Split(字符串替换 / 数组转字符串/ 字符串转数组)</p></li><li><p>Lowercase / Upcase(⼤小写转换)</p></li></ul><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-processors.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-processors.html</a></p></blockquote><h4 id="4、Ingest-Node-v-s-Logstash"><a class="header-anchor" href="#4、Ingest-Node-v-s-Logstash">¶</a>4、Ingest Node v.s. Logstash</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215503.png" alt="image-20200429213426597"></p><blockquote><p>我应该使用 logstash 还是 es ingest node：<a href="https://www.elastic.co/cn/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes</a></p></blockquote><h3 id="Painless"><a class="header-anchor" href="#Painless">¶</a>Painless</h3><p>自 Elasticsearch 5.x 后引入，专门为 Elasticsearch 设计，扩展了 Java 的语法。</p><p>6.0 开始，ES 只支持 Painless。Groovy、Javascript 和 Python 都不再支持。</p><p>Painless 支持所有 Java 的数据类型及 Java API 子集。具备以下特性：</p><ul><li>高性能</li><li>安全</li><li>支持显示类型或者动态定义类型</li></ul><p>Painless 的用途：</p><ul><li>可以对文档字段进行加工处理：<ul><li>更新或者删除字段，处理数据聚合操作</li><li>Script Field：对返回的字段提前进行计算</li><li>Function Score：对文档的算分进行处理</li></ul></li><li>在 Ingest Pipeline 中执行脚本</li><li>在 Reindex API、Update By Query 时，对数据进行处理</li></ul><h4 id="1、在-Painless-脚本中访问字段"><a class="header-anchor" href="#1、在-Painless-脚本中访问字段">¶</a>1、在 Painless 脚本中访问字段</h4><p>在 Painless 脚本中访问字段根据当前使用脚本的上下文的不同对字段的访问语法也不同，具体参考下列表格：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215511.png" alt="image-20200429213955719"></p><p>可以看到在 Ingestion 中，ctx 引用的是文档的 _source 属性对象；在 Update 的时候，ctx 引用的就是文档对象；在 Search 和 Agg 的时候， 没有提供 ctx 的引用，提供了一个 doc 的引用，引用的是文档的 _source 属性对象。</p><h4 id="2、-在-Ingest-Pipeline-中的使用示例"><a class="header-anchor" href="#2、-在-Ingest-Pipeline-中的使用示例">¶</a>2、 在 Ingest Pipeline 中的使用示例</h4><p>可以看到在下面的例子中，我们在之前的 ingest pipeline 中加入了一个新的 processor，这是一个&quot;script&quot; processor。它需要处理的字段是&quot;source&quot;。即直接访问文档的封装了所有字段的属性。处理逻辑是：如果文档（的 _source）中包含一个 content 字段，就将该字段的长度设置到一个&quot;content_length&quot;字段中，没有该字段就新增；如果不包含一个 content 字段，则直接设置 content_length 为0。</p><p>可以看到输出结果中增加了一个 content_length 字段，值为 content 的内容长度。</p><pre><code># 增加一个 Script PrcessorPOST _ingest/pipeline/_simulate{  &quot;pipeline&quot;: {    &quot;description&quot;: &quot;to split blog tags&quot;,    &quot;processors&quot;: [      {        &quot;split&quot;: {          &quot;field&quot;: &quot;tags&quot;,          &quot;separator&quot;: &quot;,&quot;        }      },      {        &quot;script&quot;: {          &quot;source&quot;: &quot;&quot;&quot;            if(ctx.containsKey(&quot;content&quot;)){              ctx.content_length = ctx.content.length();            }else{              ctx.content_length=0;            }          &quot;&quot;&quot;        }      },      {        &quot;set&quot;:{          &quot;field&quot;: &quot;views&quot;,          &quot;value&quot;: 0        }      }    ]  },  &quot;docs&quot;: [    {      &quot;_index&quot;:&quot;index&quot;,      &quot;_id&quot;:&quot;id&quot;,      &quot;_source&quot;:{        &quot;title&quot;:&quot;Introducing big data......&quot;,        &quot;tags&quot;:&quot;hadoop,elasticsearch,spark&quot;,        &quot;content&quot;:&quot;You konw, for big data&quot;      }    },    {      &quot;_index&quot;:&quot;index&quot;,      &quot;_id&quot;:&quot;idxx&quot;,      &quot;_source&quot;:{        &quot;title&quot;:&quot;Introducing cloud computering&quot;,        &quot;tags&quot;:&quot;openstack,k8s&quot;,        &quot;content&quot;:&quot;You konw, for cloud&quot;      }    }  ]}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215518.png" alt="image-20200429214426689"></p><h4 id="3、在文档字段更新中使用示例"><a class="header-anchor" href="#3、在文档字段更新中使用示例">¶</a>3、在文档字段更新中使用示例</h4><p>我们先是初始化了一个浏览数是0的博客文档。然后在更新的时候使用了一个&quot;script&quot;类型的更新操作，在其子属性source 中指定了 painless 脚本的内容，并可以利用请求体中的 script 对象的子属性构建脚本执行的时候的参数上下文。</p><p>例如下面例子中我们给&quot;script&quot;设置了一个&quot;params&quot;属性对象，并给该对象设置了一个&quot;new_views:100&quot;的属性对。此时脚本在执行的时候会将&quot;script&quot;对象作为其上下文的一部分，在识别脚本中的&quot;params.new_views&quot;部分的时候就可以匹配到&quot;scirpt&quot;对象的&quot;params.newviews&quot;属性值100了。所以构成的更新语义就是将 id 为1的文档的 views 字段的值加上100。</p><pre><code>DELETE tech_blogs# 输入一个博客文档，并设置其浏览数 view 为0PUT tech_blogs/_doc/1{  &quot;title&quot;:&quot;Introducing big data......&quot;,  &quot;tags&quot;:&quot;hadoop,elasticsearch,spark&quot;,  &quot;content&quot;:&quot;You konw, for big data&quot;,  &quot;views&quot;:0}# 将id 为1的博客文档的浏览数加上100POST tech_blogs/_update/1{  &quot;script&quot;: {    &quot;source&quot;: &quot;ctx._source.views += params.new_views&quot;,    &quot;params&quot;: {      &quot;new_views&quot;:100    }  }}# 查看views计数POST tech_blogs/_search{}</code></pre><h4 id="4、在搜索的时候使用示例"><a class="header-anchor" href="#4、在搜索的时候使用示例">¶</a>4、在搜索的时候使用示例</h4><p>参考下面的例子，我们在 _search api 中指定了一个 “script_fields” api，然后再后面定义了一个match_all 的&quot;query&quot; api。</p><ul><li>match_all query api 表示查询出所有文档数据</li><li>而 _search 会将 query 得到的文档数据输入到定义在它下面的&quot;script_fields&quot;对象中，该对象的子属性名&quot;rnd_views&quot;将表示当前&quot;script_fields&quot;的名称。而&quot;rnd_views&quot;属性对象中我们通过指定该对象的子属性&quot;lang&quot;为 palinless 标识它为一个 painless 脚本，并在 source 中填入了脚本内容，脚本逻辑为调用 Java 的 Random 函数随机生成一个值并加上每一个文档中的 views 字段的值。</li></ul><p>可以看到返回的结果中只包含了&quot;script_fields&quot;的结果，文档的字段都没有被返回。</p><pre><code>GET tech_blogs/_search{  &quot;script_fields&quot;: {    &quot;rnd_views&quot;: {      &quot;script&quot;: {        &quot;lang&quot;: &quot;painless&quot;,        &quot;source&quot;: &quot;&quot;&quot;          java.util.Random rnd = new Random();          doc['views'].value+rnd.nextInt(1000);        &quot;&quot;&quot;      }    }  },  &quot;query&quot;: {    &quot;match_all&quot;: {}  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215526.png" alt="image-20200429220656262"></p><h4 id="5、脚本缓存"><a class="header-anchor" href="#5、脚本缓存">¶</a>5、脚本缓存</h4><p>上面的在 api 中直接输入脚本的源字符串，在 api 执行的时候实时编译脚本，这种脚本叫做 inline script；此外还可以将脚本进行预编译之后缓存到 ES 中，之后可以直接通过预编译的脚本 id 直接对编译后的脚本对象进行调用，而这种脚本叫做 Stored Script。</p><p>脚本的预编译通过 _script api 实现，可以看到下面例子中先是对脚本进行了预编译并，然后直接通过脚本 id 调用预编译之后的脚本。</p><pre><code>#保存脚本在 Cluster StatePOST _scripts/update_views{  &quot;script&quot;:{    &quot;lang&quot;: &quot;painless&quot;,    &quot;source&quot;: &quot;ctx._source.views += params.new_views&quot;  }}# 通过指定script 的 id直接取出编译后的脚本进行使用POST tech_blogs/_update/1{  &quot;script&quot;: {    &quot;id&quot;: &quot;update_views&quot;,    &quot;params&quot;: {      &quot;new_views&quot;:1000    }  }}</code></pre><p>因为脚本编译的开销相较大，所以推荐使用预编译的脚本。在 ES 中，对于Inline Scripts 和 Stored Scripts 都会进行缓存，默认缓存数量是100个。可以通过以下参数进行设置。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215536.png" alt="image-20200429221126585"></p><h3 id="相关阅读-v4"><a class="header-anchor" href="#相关阅读-v4">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/cn/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-apis.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-apis.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-processors.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-processors.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/painless/7.1/painless-lang-spec.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/painless/7.1/painless-lang-spec.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/painless/7.1/painless-api-reference.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/painless/7.1/painless-api-reference.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-processors.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-processors.html</a></p><p><a href="https://www.elastic.co/cn/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes</a></p></blockquote><h1>Elasticsearch 数据建模</h1><p>数据建模（Data modeling），是创建数据模型的过程。数据模型是对真实世界进行抽象描述的一种工具和方法，实现对现实世界的映射。</p><p>数据建模包含3个过程：</p><ol><li>概念模型</li><li>逻辑模型</li><li>数据模型（第三范式）：结合具体的数据库，在满足业务读写性能等需求的前提下，确定最终的定义。</li></ol><p>数据建模一般基于功能需求和性能需求两个角度进行考虑：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215544.png" alt="image-20200430080436915"></p><p>那么在 ES 中我们应该如何进行数据建模呢？ES 中数据建模主要分为两方面：一方面是对于索引、文档和对象关系的规划建模；另一方面是对于文档字段的建模。</p><h3 id="字段建模"><a class="header-anchor" href="#字段建模">¶</a>字段建模</h3><p>在对字段建模的过程，我们一般从以下4个方面进行分析：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215556.png" alt="image-20200430080744087"></p><h4 id="1、字段类型"><a class="header-anchor" href="#1、字段类型">¶</a>1、字段类型</h4><ul><li>Text &amp; Keyword<ul><li>Text：用于全文本字段，文本会被 Analyzer 分词。默认不支持聚合分析及排序，需要设置 fielddata 为 true。</li><li>keyword：用于 id，枚举及不需要分词的文本。例如电话号码、email 地址、手机号码、邮政编码、性别等。适用于字段需要被 Filter（精确匹配），Soring 和 Aggregation 的场景。</li><li>设置多字段类型：如果用户没有在 mappnig 中显式设置字符串字段的类型，ES 默认会将其设置为 text 类型并且设置一个 keyword 的子字段。在处理人类语言时，通过增加&quot;英文&quot;，&quot;拼音&quot;和&quot;标准&quot;分词器，提高搜索结构。</li></ul></li><li>结构化数据<ul><li>数值类型：尽量选择贴近的类型。例如可用用 byte，就不要用 long。</li><li>枚举类型：设置为 keyword。即便时数字，也应该设置成 keyword，获取更好的性能。</li><li>其他：日期、布尔、地理信息… …都需要将其设置为正确的字段类型。</li></ul></li></ul><h4 id="2、是否需要搜索"><a class="header-anchor" href="#2、是否需要搜索">¶</a>2、是否需要搜索</h4><ul><li>如果不需要对该字段进行检索、排序和聚合分析：Enable 设置为 false。</li><li>如果仅仅是不需要检索：只将 index 设置为 false。</li><li>对需要检索的字段，可以通过如下配置：<ul><li>index_options：设置索引的粒度</li><li>norms：该字段用于在查询的时候进行查询的分值字段的，如果对这个字段的查询不需要计算分值，可以关闭这个选项，它也会占用一定的存储空间。</li><li>… …</li></ul></li></ul><h4 id="3、聚合及排序"><a class="header-anchor" href="#3、聚合及排序">¶</a>3、聚合及排序</h4><ul><li>如果不需要对该字段进行检索、排序和聚合分析：Enable 设置为 false。</li><li>如果仅仅是不需要排序或者聚合分析功能：Doc_values/fielddata 设置为 false。</li><li>更新频繁、聚合查询频繁的 keyword 类型的字段：推荐将 eager_global_ordinals 设置为 true。</li></ul><h4 id="4、额外的存储"><a class="header-anchor" href="#4、额外的存储">¶</a>4、额外的存储</h4><p>文档的所有字段默认都是存储在 _source 字段下的，我们需要基于一些特定场景来判断是否需要将这些字段存储在 _source 之外。</p><ul><li><p>_source 字段是否必须：当文档中的内容相当大或者查询文档并不需要每次都返回所有字段的内容的时候，基于节约磁盘的角度，可以考虑 disable _source。当 disable _source 字段之后：</p><ul><li>将在查询的时候在文档的返回结果中无法看到 _source 字段</li><li>且无法做 reindex，无法做 update</li><li>Kibana 中无法做 discovery</li></ul><p>所以一般建议先考虑增加压缩比来节约磁盘。一般是一些指标型数据适合关闭 _source，参考下图中的官方描述：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215605.png" alt="image-20200430083724859"></p></li></ul><ul><li>是否需要专门存储当前字段数据，Store 设置成 true，可以对该字段的原始内容进行专门的存储。一般结合 _source 的 enable 设置为 false 使用。</li></ul><h4 id="5、一个字段建模实例"><a class="header-anchor" href="#5、一个字段建模实例">¶</a>5、一个字段建模实例</h4><ol><li><p>使用 ES 的默认 Dynamic Mapping 创建索引 Mapping。可以看到我们下面先是索引了一本书的信息，其包含以下字段信息：</p><ul><li>书名</li><li>简介</li><li>作者</li><li>发行日期</li><li>图书封面链接</li></ul><p>ES 会为我们默认创建一个索引。可以看到所有字段都设置成了 text 类型并且增加了一个keyword 类型的子字段。</p><pre><code># Index 一本书的信息PUT books/_doc/1{  &quot;title&quot;:&quot;Mastering ElasticSearch 5.0&quot;,  &quot;description&quot;:&quot;Master the searching, indexing, and aggregation features in ElasticSearch Improve users’ search experience with Elasticsearch’s functionalities and develop your own Elasticsearch plugins&quot;,  &quot;author&quot;:&quot;Bharvi Dixit&quot;,  &quot;public_date&quot;:&quot;2017&quot;,  &quot;cover_url&quot;:&quot;https://images-na.ssl-images-amazon.com/images/I/51OeaMFxcML.jpg&quot;}#查询自动创建的MappingGET books/_mapping</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215615.png" alt="image-20200430085140227"></p></li><li><p>优化字段设定。</p><ul><li>类型：我们知道，图书的作者、封面链接都是一个精确值，所以将它们都设置为 keyword；另外，将发行日期设置为日期格式；而简介时不需要一个 keyword 子字段的，它本身在99.99%的情况下都不会作为一个精确值被检索，所以无需再针对这个字段进行精确索引；而书名在一般情况下都会支持全文检索和精确检索两种情况，所以保持默认类型不用变化。</li><li>是否需要索引：对于封面链接，一般是不会有人基于该字段来检索图书，所以我们设置 index 为 false。</li></ul><pre><code>DELETE books#优化字段类型PUT books{      &quot;mappings&quot; : {      &quot;properties&quot; : {        &quot;author&quot; : {&quot;type&quot; : &quot;keyword&quot;},        &quot;cover_url&quot; : {&quot;type&quot; : &quot;keyword&quot;,&quot;index&quot;: false},        &quot;description&quot; : {&quot;type&quot; : &quot;text&quot;},        &quot;public_date&quot; : {&quot;type&quot; : &quot;date&quot;},        &quot;title&quot; : {          &quot;type&quot; : &quot;text&quot;,          &quot;fields&quot; : {            &quot;keyword&quot; : {              &quot;type&quot; : &quot;keyword&quot;,              &quot;ignore_above&quot; : 100            }          }        }      }    }}#Cover URL index 设置成false，无法对该字段进行搜索，尝试对该字段进行搜索会报错。POST books/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;cover_url&quot;: {        &quot;value&quot;: &quot;https://images-na.ssl-images-amazon.com/images/I/51OeaMFxcML.jpg&quot;      }    }  }}#Cover URL index 设置成false，依然支持聚合分析POST books/_search{  &quot;aggs&quot;: {    &quot;cover&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;cover_url&quot;,        &quot;size&quot;: 10      }    }  }}</code></pre></li><li><p>需求变更。现在我们收到了新的需求变更，需要在图书文档中增加一个图书内容的字段，并要求能对图书的内容进行全文检索的同时支持高亮显示。</p><p>这个新需求会导致 _source 的内容过大。默认情况下对于文档的检索无论是 data node 返回数据给 coordinating node 还是 coordinating node 返回数据给用户都会携带着 _source 一起返回，这样每次查询无论用户是否真的需要获取全部的字段（或者数据量比较大的图书内容字段）信息都会导致大量数据的传输。</p><p>考虑到图书信息一般在导入之后就不再会有 update 操作，我们可以通过关闭 _source 字段，并将所有字段的 “store” 设置为 true 来解决问题。下面我们删除图书索引并重新设置 mapping，然后重新索引一个图书文档。</p><pre><code>DELETE books#新增 Content字段。数据量很大。选择将Source 关闭PUT books{      &quot;mappings&quot; : {      &quot;_source&quot;: {&quot;enabled&quot;: false},      &quot;properties&quot; : {        &quot;author&quot; : {&quot;type&quot; : &quot;keyword&quot;,&quot;store&quot;: true},        &quot;cover_url&quot; : {&quot;type&quot; : &quot;keyword&quot;,&quot;index&quot;: false,&quot;store&quot;: true},        &quot;description&quot; : {&quot;type&quot; : &quot;text&quot;,&quot;store&quot;: true},         &quot;content&quot; : {&quot;type&quot; : &quot;text&quot;,&quot;store&quot;: true},        &quot;public_date&quot; : {&quot;type&quot; : &quot;date&quot;,&quot;store&quot;: true},        &quot;title&quot; : {          &quot;type&quot; : &quot;text&quot;,          &quot;fields&quot; : {            &quot;keyword&quot; : {              &quot;type&quot; : &quot;keyword&quot;,              &quot;ignore_above&quot; : 100            }          },          &quot;store&quot;: true        }      }    }}# Index 一本书的信息,包含ContentPUT books/_doc/1{  &quot;title&quot;:&quot;Mastering ElasticSearch 5.0&quot;,  &quot;description&quot;:&quot;Master the searching, indexing, and aggregation features in ElasticSearch Improve users’ search experience with Elasticsearch’s functionalities and develop your own Elasticsearch plugins&quot;,  &quot;content&quot;:&quot;The content of the book......Indexing data, aggregation, searching.    something else. something in the way............&quot;,  &quot;author&quot;:&quot;Bharvi Dixit&quot;,  &quot;public_date&quot;:&quot;2017&quot;,  &quot;cover_url&quot;:&quot;https://images-na.ssl-images-amazon.com/images/I/51OeaMFxcML.jpg&quot;}</code></pre><p>此时尝试查询的时候，_source 字段关闭了，ES 默认是不会返回文档额外存储的字段的。</p><pre><code>#查询结果中，Source不包含数据POST books/_search{}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215628.png" alt="image-20200430090941895"></p><p>我们需要指定 API 中具体需要操作或者查询的字段</p><ul><li>下面我们通过在 _search API 的 &quot;stored_fields&quot;的动作对象，这个对象会抓取经过查询出来的文档数据的具体字段值然后封装到一个&quot;fields&quot;对象中，这个&quot;fields&quot;对象会作为返回信息的文档对象的一个属性值返回，这样我们就能看到一个文档中我们指定的具体字段信息了。</li><li>另外我们还通过在 _search API 的 “highlight” 动作对象，该对象和&quot;stored_fields&quot;对象的逻辑差不多，只不过它在从文档的（用户）指定字段中把字段数据抓取出来之后经过高亮标签拼接再封装到一个&quot;highlight&quot;对象，然后设置到返回信息的文档对象的&quot;highlight&quot;属性中。</li></ul><pre><code>#搜索，通过store 字段显示数据，同时高亮显示 conent的内容POST books/_search{  &quot;stored_fields&quot;: [&quot;title&quot;,&quot;author&quot;,&quot;public_date&quot;],  &quot;query&quot;: {    &quot;match&quot;: {      &quot;content&quot;: &quot;searching&quot;    }  },  &quot;highlight&quot;: {    &quot;fields&quot;: {      &quot;content&quot;:{}    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215641.png" alt="image-20200430091119890"></p></li></ol><h4 id="6、Mapping-字段的相关设置"><a class="header-anchor" href="#6、Mapping-字段的相关设置">¶</a>6、<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html" target="_blank" rel="noopener">Mapping 字段的相关设置</a></h4><ul><li>Enabled – 设置成 false，仅做存储，不支持搜索和聚合分析 (数据保存在 _source 中)</li><li>Index – 是否构倒排索引。设置成 false，⽆法被搜索，但还是支持 aggregation，并出现在 _source中</li><li>Norms – 如果字段仅用做过滤和聚合分析，可以关闭，节约存储</li><li>Doc_values – 是否启⽤用 doc_values，用于排序和聚合分析</li><li>Field_data – 如果要对 text 类型启用排序和聚合分析， fielddata 需要设置成true</li><li>Store – 默认不存储，数据默认存储在 _source。</li><li>Coerce – 默认开启，是否开启数据类型的自动转换(例如，字符串转数字)</li><li>Multifields 多字段特性</li><li>Dynamic – true / false / strict 控制 Mapping 的⾃动更新</li></ul><h4 id="7、数据建模中一些相关的-API"><a class="header-anchor" href="#7、数据建模中一些相关的-API">¶</a>7、数据建模中一些相关的 API</h4><ul><li>Index Template &amp; Dynamic Template：根据索引的名字匹配不同的 Mapping 和 Settings。可以在一个 Mapping 上动态的设定字段类型</li><li>Index Alias：无需停机，无需修改程序，修改 alias 之后立即生效，即可使用该 alias（可进行零停机 reindex 等动作）</li><li>Update By Query &amp; Reindex</li></ul><h4 id="8、相关阅读"><a class="header-anchor" href="#8、相关阅读">¶</a>8、相关阅读</h4><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html</a></p></blockquote><h3 id="文档及关系建模及一些数据建模最佳实践"><a class="header-anchor" href="#文档及关系建模及一些数据建模最佳实践">¶</a>文档及关系建模及一些数据建模最佳实践</h3><h4 id="建模建议-一-：如何处理关联关系"><a class="header-anchor" href="#建模建议-一-：如何处理关联关系">¶</a>建模建议(一)：如何处理关联关系</h4><p>下图就是我们在选择索引中的文档关系的一个优先考虑流程：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215650.png" alt="image-20200430095305105"></p><blockquote><p>需要注意的是：在 Kibana 中目前暂时没有对 nested 类型和 parent/child 类型提供一个很好的支持。在未来有可能会支持。如果需要使用 Kibana 进行数据分析，在数据建模时仍需对嵌套和父子关系类型作出取舍。</p></blockquote><h4 id="建模建议-二-：避免过多字段"><a class="header-anchor" href="#建模建议-二-：避免过多字段">¶</a>建模建议(二)：避免过多字段</h4><p>一个文档中，最好避免大量的字段：</p><ul><li>过多的字段不容易维护</li><li>Mapping 信息保存在 Cluster State 中，数据量过大，对集群性能会有影响（Cluster State 信息需要和所有的节点同步）</li><li>后期再删除或者修改字段需求 reindex</li></ul><p>ES 中默认最大字段数是1000，可以通过设置<code>index.mapping.total)fields.limit</code>限定最大字段数。</p><p><strong>可能导致文档中有成百上千的字段的原因：</strong></p><p>可能是因为启用了 Dynamic Mapping，用户在对其数据结构不是很准确的了解和控制的情况下会导致一些为止的新字段的写入。所以在生产环境中我们尽量不要使用 Dynamic Mapping。通过 Mapping 中的&quot;_doc.dynamic&quot;属性控制：</p><ul><li>true：未知字段会被自动加入以及索引</li><li>false：新字段不会被索引，但是会保存到 _source</li><li>strict：索引未知字段会失败，直接报错</li></ul><h5 id="示例：Cookie-Service-的数据"><a class="header-anchor" href="#示例：Cookie-Service-的数据">¶</a>示例：Cookie Service 的数据</h5><p>我们现在有一个保存 Cookie 的服务，我们打算将 cookie 数据索引到 ES 的一个 cookie_service 中，并在一开始使用了 dynamic mapping，直接索引数据。</p><p>可以看到在下面的例子中，我们分别保存了两个 cookies，而两个 cookie 中的含有的键值对是不一样的，主要是 cookie 的键，<strong>因为 cookie 是一个可以由用户自定义的一个键值对，所以cookie 对象中的属性字段输入到 ES 可能就会有成千上百以上了</strong>！</p><pre><code>##索引数据，dynamic mapping 会不断加入新增字段PUT cookie_service/_doc/1{ &quot;url&quot;:&quot;www.google.com&quot;, &quot;cookies&quot;:{   &quot;username&quot;:&quot;tom&quot;,   &quot;age&quot;:32 }}PUT cookie_service/_doc/2{ &quot;url&quot;:&quot;www.amazon.com&quot;, &quot;cookies&quot;:{   &quot;login&quot;:&quot;2019-01-01&quot;,   &quot;email&quot;:&quot;xyz@abc.com&quot; }}</code></pre><p>此时，我们可以使用 nested Object 来解决这个问题。看下面的例子，我们删除了原本的 cookie_service 索引，并进行显示 mapping 设置。我们重新定义了索引中文档的&quot;cookies&quot;字段为一个&quot;nested&quot;类型的字段，这个对象有4个属性：</p><ul><li>“name”：存储的就是一个 cookie 键</li><li>根据cookie 值的不同类型存储到不同的value字段：<ul><li>“dataValue”：date 类型</li><li>“keywordValue”：keyword 类型</li><li>“intValue”：integer 类型</li></ul></li></ul><p><strong>经过这样的数据字段抽象定义和约定</strong>，我们在写入以上的 cookies 对象的时候，就可以通过对一个对象只支持一组 “key-value” 属性的cookies对象数组来存储到一个URL链接对象中，而不是像一开始那样设置一个 cookies 对象然后设置不同的属性名存储到 URL 链接对象中。</p><p>在查询的时候，也需要通过 nested 查询来根据指定的 cookie 信息进行检索。</p><p>这样即可起到控制cookies 字段数量但是又支持 cookies 属性自定义的作用。</p><pre><code>DELETE cookie_service#使用 Nested 对象，增加key/valuePUT cookie_service{  &quot;mappings&quot;: {    &quot;properties&quot;: {      &quot;cookies&quot;: {        &quot;type&quot;: &quot;nested&quot;,        &quot;properties&quot;: {          &quot;name&quot;: {            &quot;type&quot;: &quot;keyword&quot;          },          &quot;dateValue&quot;: {            &quot;type&quot;: &quot;date&quot;          },          &quot;keywordValue&quot;: {            &quot;type&quot;: &quot;keyword&quot;          },          &quot;IntValue&quot;: {            &quot;type&quot;: &quot;integer&quot;          }        }      },      &quot;url&quot;: {        &quot;type&quot;: &quot;text&quot;,        &quot;fields&quot;: {          &quot;keyword&quot;: {            &quot;type&quot;: &quot;keyword&quot;,            &quot;ignore_above&quot;: 256          }        }      }    }  }}##写入数据，使用key和合适类型的value字段PUT cookie_service/_doc/1{ &quot;url&quot;:&quot;www.google.com&quot;, &quot;cookies&quot;:[    {      &quot;name&quot;:&quot;username&quot;,      &quot;keywordValue&quot;:&quot;tom&quot;    },    {      &quot;name&quot;:&quot;age&quot;,      &quot;intValue&quot;:32    }  ]}PUT cookie_service/_doc/2{ &quot;url&quot;:&quot;www.amazon.com&quot;, &quot;cookies&quot;:[    {      &quot;name&quot;:&quot;login&quot;,      &quot;dateValue&quot;:&quot;2019-01-01&quot;    },    {      &quot;name&quot;:&quot;email&quot;,      &quot;IntValue&quot;:32    } ]}# Nested 查询，通过bool查询进行过滤POST cookie_service/_search{  &quot;query&quot;: {    &quot;nested&quot;: {      &quot;path&quot;: &quot;cookies&quot;,      &quot;query&quot;: {        &quot;bool&quot;: {          &quot;filter&quot;: [            {              &quot;term&quot;: {                &quot;cookies.name&quot;: &quot;age&quot;              }            },            {              &quot;range&quot;:{                &quot;cookies.intValue&quot;:{                  &quot;gte&quot;:30                }              }            }          ]        }      }    }  }}</code></pre><blockquote><p>但是虽然通过 Nested 对象保存这种 key/value 数据可以减少字段数量，解决了 Cluster State 中保存过多 Meta 信息的问题，但是同时也导致了查询语句复杂度增加；另外 nested 对象不利于在 Kibana 中实现可视化分析。</p></blockquote><h4 id="建模建议-三-：避免正则查询"><a class="header-anchor" href="#建模建议-三-：避免正则查询">¶</a>建模建议(三)：避免正则查询</h4><p>我们应该尽量避免在 ES 中使用正则、通配符查询，特别是将通配符放在开头，会导致性能的灾难。前面也提到 ES 提供了一个基于前缀的 terms 查询，但是性能不够好。</p><p>下面我们来分析一个案例提供一些对于&quot;匹配&quot;查询的一些优化思路。</p><h5 id="示例：模糊查询版本信息"><a class="header-anchor" href="#示例：模糊查询版本信息">¶</a>示例：模糊查询版本信息</h5><p>我们拥有一个 softwares 的一个索引，里面索引了一些软件的信息。其中的一个 version 字段包含了软件的版本信息，以 ES 为例，可能包含一个值为&quot;7.1.0&quot;的ES文档。 现在我们需要该字段支持模糊查询，例如：搜索所有是 bug fix 版本的软件并返回每个主版本号所关联的文档？</p><pre><code>PUT softwares/_doc/1{  &quot;software_version&quot;:&quot;7.1.0&quot;}GET softwares/_mapping</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215700.png" alt="image-20200430104356697"></p><p>解决方案可以将 version 经过各部分的拆分之后，从字符串类型转为对象类型，可以看到我们为 version 属性设置了4个属性：</p><ul><li>display_name：keyword 类型，维护原始的版本字符串信息</li><li>hot_fix：byte 类型，将版本信息拆分之后截取出来的 hot fix 版本号</li><li>marjor：byte 类型，将版本信息拆分之后截取出来的 major 版本号</li><li>minor：byte 类型，将版本信息拆分之后截取出来的 minor 版本号</li></ul><p>这样，原本的&quot;7.1.0&quot;我们就拆成了&quot;hot_fix=7;marjor=1;minor=0&quot;，在检索的时候根据具体子版本号使用 bool 查询即可，大大提升性能：</p><pre><code>DELETE softwares# 优化,使用inner objectPUT softwares/{    &quot;properties&quot;: {      &quot;version&quot;: {        &quot;properties&quot;: {          &quot;display_name&quot;: {            &quot;type&quot;: &quot;keyword&quot;          },          &quot;hot_fix&quot;: {            &quot;type&quot;: &quot;byte&quot;          },          &quot;marjor&quot;: {            &quot;type&quot;: &quot;byte&quot;          },          &quot;minor&quot;: {            &quot;type&quot;: &quot;byte&quot;          }        }      }    }  }}#通过 Inner Object 写入多个文档PUT softwares/_doc/1{  &quot;version&quot;:{  &quot;display_name&quot;:&quot;7.1.0&quot;,  &quot;marjor&quot;:7,  &quot;minor&quot;:1,  &quot;hot_fix&quot;:0    }}PUT softwares/_doc/2{  &quot;version&quot;:{  &quot;display_name&quot;:&quot;7.2.0&quot;,  &quot;marjor&quot;:7,  &quot;minor&quot;:2,  &quot;hot_fix&quot;:0    }}PUT softwares/_doc/3{  &quot;version&quot;:{  &quot;display_name&quot;:&quot;7.2.1&quot;,  &quot;marjor&quot;:7,  &quot;minor&quot;:2,  &quot;hot_fix&quot;:1    }}# 通过 bool 查询，POST softwares/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;filter&quot;: [        {          &quot;match&quot;:{            &quot;version.marjor&quot;:7          }        },        {          &quot;match&quot;:{            &quot;version.minor&quot;:2          }        }      ]    }  }}</code></pre><h4 id="建模建议-四-：避免空值引起的聚合不准"><a class="header-anchor" href="#建模建议-四-：避免空值引起的聚合不准">¶</a>建模建议(四)：避免空值引起的聚合不准</h4><p>请看下面示例，我们分别一个ratings 索引中创建了两个文档，它们都只有一个字段&quot;rating&quot;，文档1的值为5，文档2的值为 null。</p><p>然后我们进行了一次对&quot;rating&quot;的 avg metric agg，发现得到的 rating 平均值是5，因为 ES 在进行字段 Metric计算的时候，是会过滤空值的，但是对于用户来说，一个文档在这个字段的空值其实指的应该是该文档语义下该字段的默认值，比如这里的 rating 字段，如果是空我们认为它是排名第一的，在这种语义下，下面的 Metric 结果就是错误的。</p><pre><code>PUT ratings/_doc/1{ &quot;rating&quot;:5}PUT ratings/_doc/2{ &quot;rating&quot;:null}POST ratings/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;avg&quot;: {      &quot;avg&quot;: {        &quot;field&quot;: &quot;rating&quot;      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215708.png" alt="image-20200430105104466"></p><p>基于上面的问题，我们可以通过 <code>mapping.properties.null_value</code>属性来处理空值，这个属性的值就指定了其所属字段的默认值。下面的例子中我们设置了 rating 的字段的默认值是1，这样我们重新索引文档后再进行 metric 操作就能得到一个想要的值了。</p><pre><code># Not Null 解决聚合的问题DELETE ratingsPUT ratings{  &quot;mappings&quot;: {      &quot;properties&quot;: {        &quot;rating&quot;: {          &quot;type&quot;: &quot;float&quot;,          &quot;null_value&quot;: 1.0        }      }    }}# 重新索引文档PUT ratings/_doc/1{ &quot;rating&quot;:5}PUT ratings/_doc/2{ &quot;rating&quot;:null}POST ratings/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;rating&quot;: {        &quot;value&quot;: 1      }    }  }}POST ratings/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;avg&quot;: {      &quot;avg&quot;: {        &quot;field&quot;: &quot;rating&quot;      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215713.png" alt="image-20200430105634440"></p><h4 id="建模建议-五-：为索引的-Mapping-加入-Meta-信息"><a class="header-anchor" href="#建模建议-五-：为索引的-Mapping-加入-Meta-信息">¶</a>建模建议(五)：为索引的 Mapping 加入 Meta 信息</h4><p>Mappings 设置非常重要，需要从两个维度进行考虑：</p><ul><li>功能：搜索、聚合、排序</li><li>性能：存储的开销、内存的开销、搜索的开销</li></ul><p>同时 Mappings 的设置也是一个迭代的过程</p><ul><li><p>加入新的字段很容易（必要时需要 update_by_query）</p></li><li><p>更新删除字段不允许（需要 reindex 到一个新的索引）</p></li><li><p>最好能对 Mappings 加入 Meta 信息，更好的进行版本控制</p><p>参考下面例子，一开始在 _mapping 中设置了一个 _meta 属性，并在这个属性中再增加一个子属性 software_version_mapping 表示当前 mapping 的版本号，在之后的 mapping 更新中要手动的维护这个版本号：</p><pre><code># 在Mapping中加入元信息，便于管理PUT softwares/{  &quot;mappings&quot;: {    &quot;_meta&quot;: {      &quot;software_version_mapping&quot;: &quot;1.0&quot;    }  }}PUT softwares/_mapping{  &quot;_meta&quot;: {      &quot;software_version_mapping&quot;: &quot;2.0&quot;  },  &quot;properties&quot;: {    &quot;new_file&quot;: {      &quot;type&quot;: &quot;keyword&quot;    }  }}</code></pre></li><li><p>可以考虑将 Mapping 文件上传 git 进行管理</p></li></ul><h3 id="相关阅读-v5"><a class="header-anchor" href="#相关阅读-v5">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/general-recommendations.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/general-recommendations.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-disk-usage.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-disk-usage.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-search-speed.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-search-speed.html</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>013_ELK日志管理</title>
      <link href="/2020/12/22/elasticsearch/013-elk-ri-zhi-guan-li/"/>
      <url>/2020/12/22/elasticsearch/013-elk-ri-zhi-guan-li/</url>
      
        <content type="html"><![CDATA[<h1>问题</h1><p>日志分布太散，格式不一，维护困难，并且出现问题的时候来排查日志更是困难。</p><h2 id="解决方案"><a class="header-anchor" href="#解决方案">¶</a>解决方案</h2><p>通过 ELK 生态进行日志管理，使用 filebeat、logstash、kafka 等将数据导入到 ES，然后在 Kibana 的 logs 模块就可以进行查看，然后我们可以在 Kibana 中对数据进行一些可视化组件、dashboard 的构建，也可以使用机器学习对日志进行异常检测，也可以使用 alerting 进行异常告警。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221232343.png" alt="image-20200504164417830"></p><blockquote><p>参考链接：<a href="https://time.geekbang.org/course/detail/100030501-142433" target="_blank" rel="noopener">https://time.geekbang.org/course/detail/100030501-142433</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>007_深入聚合</title>
      <link href="/2020/12/22/elasticsearch/007-shen-ru-ju-he/"/>
      <url>/2020/12/22/elasticsearch/007-shen-ru-ju-he/</url>
      
        <content type="html"><![CDATA[<p>[toc]</p><h1>Bucket &amp; Metrc 聚合分析及嵌套聚合</h1><p>在&quot;ES入门&quot;中最后的章节提到 ES 也提供了类似对文档进行聚合（分桶）和统计的方法，称之为 Aggregation。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214328.png" alt="image-20200427153438802"></p><h3 id="零、Aggregation-语法"><a class="header-anchor" href="#零、Aggregation-语法">¶</a>零、Aggregation 语法</h3><p>Aggregation 属于 search 的一部分。一般情况下，建议将其 size 指定为0（表示不返回具体的文档信息，如果不这样设置，查询会像正常的查询一样也会在 hits 中返回查询命中的一些具体的文档信息）。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214333.png" alt="image-20200427153847421"></p><h3 id="一、Metric-Aggregation"><a class="header-anchor" href="#一、Metric-Aggregation">¶</a>一、Metric Aggregation</h3><p>Metric Aggregation 用来统计数据的，它可以分为两类：</p><ol><li>单值分析：指输出一个分析结果<ul><li>min、max、avg、sum</li><li>Cardinality（类似 distinct count）</li></ul></li><li>多值分析：输出多个分析结果<ul><li>stats、extened stats</li><li>percentile、percentile rank</li><li>top hits</li></ul></li></ol><h4 id="示例"><a class="header-anchor" href="#示例">¶</a>示例</h4><p>下面我们来看一下一些具体的示例：</p><ol><li><p>先准备1个索引和20个员工信息的文档数据</p><pre><code>DELETE /employeesPUT /employees/{  &quot;mappings&quot; : {      &quot;properties&quot; : {        &quot;age&quot; : {          &quot;type&quot; : &quot;integer&quot;        },        &quot;gender&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;job&quot; : {          &quot;type&quot; : &quot;text&quot;,          &quot;fields&quot; : {            &quot;keyword&quot; : {              &quot;type&quot; : &quot;keyword&quot;,              &quot;ignore_above&quot; : 50            }          }        },        &quot;name&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;salary&quot; : {          &quot;type&quot; : &quot;integer&quot;        }      }    }}PUT /employees/_bulk{ &quot;index&quot; : {  &quot;_id&quot; : &quot;1&quot; } }{ &quot;name&quot; : &quot;Emma&quot;,&quot;age&quot;:32,&quot;job&quot;:&quot;Product Manager&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;:35000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;2&quot; } }{ &quot;name&quot; : &quot;Underwood&quot;,&quot;age&quot;:41,&quot;job&quot;:&quot;Dev Manager&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 50000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;3&quot; } }{ &quot;name&quot; : &quot;Tran&quot;,&quot;age&quot;:25,&quot;job&quot;:&quot;Web Designer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;:18000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;4&quot; } }{ &quot;name&quot; : &quot;Rivera&quot;,&quot;age&quot;:26,&quot;job&quot;:&quot;Web Designer&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;: 22000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;5&quot; } }{ &quot;name&quot; : &quot;Rose&quot;,&quot;age&quot;:25,&quot;job&quot;:&quot;QA&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;:18000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;6&quot; } }{ &quot;name&quot; : &quot;Lucy&quot;,&quot;age&quot;:31,&quot;job&quot;:&quot;QA&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;: 25000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;7&quot; } }{ &quot;name&quot; : &quot;Byrd&quot;,&quot;age&quot;:27,&quot;job&quot;:&quot;QA&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;:20000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;8&quot; } }{ &quot;name&quot; : &quot;Foster&quot;,&quot;age&quot;:27,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 20000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;9&quot; } }{ &quot;name&quot; : &quot;Gregory&quot;,&quot;age&quot;:32,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;:22000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;10&quot; } }{ &quot;name&quot; : &quot;Bryant&quot;,&quot;age&quot;:20,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 9000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;11&quot; } }{ &quot;name&quot; : &quot;Jenny&quot;,&quot;age&quot;:36,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;:38000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;12&quot; } }{ &quot;name&quot; : &quot;Mcdonald&quot;,&quot;age&quot;:31,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 32000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;13&quot; } }{ &quot;name&quot; : &quot;Jonthna&quot;,&quot;age&quot;:30,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;:30000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;14&quot; } }{ &quot;name&quot; : &quot;Marshall&quot;,&quot;age&quot;:32,&quot;job&quot;:&quot;Javascript Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 25000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;15&quot; } }{ &quot;name&quot; : &quot;King&quot;,&quot;age&quot;:33,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;:28000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;16&quot; } }{ &quot;name&quot; : &quot;Mccarthy&quot;,&quot;age&quot;:21,&quot;job&quot;:&quot;Javascript Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 16000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;17&quot; } }{ &quot;name&quot; : &quot;Goodwin&quot;,&quot;age&quot;:25,&quot;job&quot;:&quot;Javascript Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 16000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;18&quot; } }{ &quot;name&quot; : &quot;Catherine&quot;,&quot;age&quot;:29,&quot;job&quot;:&quot;Javascript Programmer&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;: 20000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;19&quot; } }{ &quot;name&quot; : &quot;Boone&quot;,&quot;age&quot;:30,&quot;job&quot;:&quot;DBA&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 30000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;20&quot; } }{ &quot;name&quot; : &quot;Kathy&quot;,&quot;age&quot;:29,&quot;job&quot;:&quot;DBA&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;: 20000}</code></pre></li><li><p>简单的Metrc 聚合：</p><p>我们下面分别通过调用_search api 进行了 agg 的操作。我们在第一个和第二个调用中分别使用了 “min” 和 “max” agg，其中&quot;min_salary&quot;和&quot;max_salary&quot;是我们对于这次agg 的业务操作的名称定义，可以看到在 ES 返回给我们的信息中的&quot;aggregations&quot;对象下面就是以我们起的这些业务名称作为它的属性进行返回的，里面包含了我们需要统计的信息。</p><p>另外，可以看到返回的结果中都命中了20条数据，因为我们的查询并没有加上任何条件，仅仅是一次简单的 agg 操作，所以命中了我们写入的全部20条文档数据。但是因为我们在查询的时候指定了 size 是0，所以在返回的 hits 下面的再一个 hits 属性数组是空的，没有返回任何详细的文档数据。</p><p>而在第三个 _serach查询中，我们在 aggs 下面同时指定了3个 agg，进行三个 agg 操作，ES 在返回信息给我们的时候在 aggregation 数组中将3个 agg 操作的结果全部一起返回。并用我们起的agg名字进行分隔。</p><p>而第四个操作，我们使用了一个 stats 聚合分析，它作为一个聚合 api 会同时对指定数值字段（salary）的最小、最大、平均、和、行数这5个统计。</p><pre><code># Metric 聚合，找到最低的工资POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;min_salary&quot;: {      &quot;min&quot;: {        &quot;field&quot;:&quot;salary&quot;      }    }  }}# Metric 聚合，找到最高的工资POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;max_salary&quot;: {      &quot;max&quot;: {        &quot;field&quot;:&quot;salary&quot;      }    }  }}# 多个 Metric 聚合，找到最低最高和平均工资POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;max_salary&quot;: {      &quot;max&quot;: {        &quot;field&quot;: &quot;salary&quot;      }    },    &quot;min_salary&quot;: {      &quot;min&quot;: {        &quot;field&quot;: &quot;salary&quot;      }    },    &quot;avg_salary&quot;: {      &quot;avg&quot;: {        &quot;field&quot;: &quot;salary&quot;      }    }  }}# 一个聚合，输出多值POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;stats_salary&quot;: {      &quot;stats&quot;: {        &quot;field&quot;:&quot;salary&quot;      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214343.png" alt="image-20200427160734050"></p></li></ol><h3 id="二、Bucket-Aggregation"><a class="header-anchor" href="#二、Bucket-Aggregation">¶</a>二、Bucket Aggregation</h3><p>这个 agg 是按照一定的规则，将文档分配到不同桶中，从而达到分类的目的。ES 提供了一些常见的 Bucket Aggregation</p><ul><li>terms</li><li>对于数字类型有：<ul><li>Range、Date Range</li><li>Histogram、Date Histogram</li></ul></li></ul><p>另外，Bucket Aggregation 是支持嵌套的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214350.png" alt="image-20200427161220024"></p><h4 id="Terms-Aggregation"><a class="header-anchor" href="#Terms-Aggregation">¶</a>Terms Aggregation</h4><h6 id="1、对结构化数据进行-term-aggregation"><a class="header-anchor" href="#1、对结构化数据进行-term-aggregation">¶</a>1、对结构化数据进行 term aggregation</h6><p>结构化数据（keyword、时间、数值、布尔）默认支持 doc_values，对于这类字段默认可以进行 Terms Aggregation。但是如果是对 text 类型的字段进行 Terms Aggregation 的时候，需要打开 fielddata（在 Mapping 中设置为 enable），然后会<strong>按照分词之后的词条（term）进行分组聚合</strong>。</p><p>下面是我们对 job.keyword 字段进行 terms aggregation</p><pre><code># 对keword 进行聚合POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;:&quot;job.keyword&quot;      }    }  }}</code></pre><p>可以看到是可以正常执行并返回结果的，ES 将我们的文档按照我们 job.keyword 的内容对文档进行了分桶，但是并没有将我们的 job 字段的内容进行分词（例如 Java Programmer 它还是完整的）。我们可以看到 ES 给我们返回的数据信息主要包含分桶的 key 和 桶中文档的数量，所有的桶作为一个个元素放到一个 buckets 数组中进行返回。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214401.png" alt="image-20200427162335350"></p><h6 id="2、对-text-数据进行-term-aggregation"><a class="header-anchor" href="#2、对-text-数据进行-term-aggregation">¶</a>2、对 text 数据进行 term aggregation</h6><p>下面我们对 text 类型的 job 字段进行 term aggregation 操作，可以看到，ES 直接给我们搞错了。“Fielddata is disabled on text fields by default. Set fielddata=true on [job] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory. Alternatively use a keyword field instead.”。告诉我们需要打开 Fieiddata</p><pre><code># 对 Text 字段进行 terms 聚合查询，失败POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;:&quot;job&quot;      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214411.png" alt="image-20200427162538195"></p><p>下面我们打开 fielddata</p><pre><code># 对 Text 字段打开 fielddata，支持terms aggregationPUT employees/_mapping{  &quot;properties&quot; : {    &quot;job&quot;:{       &quot;type&quot;:     &quot;text&quot;,       &quot;fielddata&quot;: true    }  }}</code></pre><p>再进行term aggregation 操作</p><pre><code># 对 Text 字段进行 terms 分词。分词后的termsPOST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;:&quot;job&quot;      }    }  }}</code></pre><p>可以看到，现在是可以对 text 字段进行 terms aggregation 操作了，但是有个问题就是它是将 text 字段进行分词之后对词条进行分组统计，例如 Java Programmer 有7个员工，Javascript Programmer 有 4个员工，那么 ES 会对这两个文本进行分词为 java、javascript和 programmer，其中 java 词条关联的文档就是7个，javascript 词条关联的文档就是4个，但是 programmer 因为关联了7个&quot;Java Programmer&quot;和4个&quot;Javascript Programmer&quot;的文档，所以这个词条（桶）下的文档数就是11个。</p><p>对于这样的结果，我们需要知道，然后根据需求来判断这个结果是否是我们需要的，如果我们的需求是原本的文本类型字段的内容作为一个完整的key对文档进行分桶，那么就像上面那样使用text 类型字段的子字段 keyword（keyword 类型）进行分桶。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214419.png" alt="image-20200427162743328"></p><h6 id="3、Bucket-Size"><a class="header-anchor" href="#3、Bucket-Size">¶</a>3、Bucket Size</h6><p>我们可以通过指定 terms agg 的 size 来配置ES 给我们返回的桶数量，看下面的例子，我们通过分别指定了 terms agg的 size 为5或者3，ES 分别给我们返回了前5个桶和前3个桶（这里我们没有指定桶的排序，所以是按照 ES 的默认排序）。</p><pre><code>#指定 bucket 的 sizePOST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;ages_5&quot;: {      &quot;terms&quot;: {        &quot;field&quot;:&quot;age&quot;,        //&quot;size&quot;:5        &quot;size&quot;: 3      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214428.png" alt="image-20200427164618181"></p><h6 id="4、Top-Hits"><a class="header-anchor" href="#4、Top-Hits">¶</a>4、Top Hits</h6><p>在现实生活中往往有这样的需求，在某某范围内找出最 XX 的数据，即 Top K 问题。下面是一个这样的需求的实现：我们需要将所有员工按照不同工种（job）进行分类，然后找出每个工种中年龄最大的三个员工。</p><ol><li>可以看到我们是先在 _search 请求 body 下面指定了一个 agg，我们起名为&quot;jobs&quot;，然后设置一个对字段&quot;job.keyword&quot; 进行 terms aggregation，实现对员工按照工种分类。</li><li>然后在我们配置的&quot;jobs&quot;（会被 ES 转化成一个 term agg 对象）agg 对象下面再嵌套定义一个子的 agg，我们起名为&quot;old_employee&quot;，然后设置该 agg 类型为 <strong>top_hits</strong>，并设置 size属性 为3，表示找出前3个文档，然后通过 sort 属性来指定按照某个字段进行排序。</li></ol><p>可以看到 ES 给我们返回了我们想要的数据，首先是在返回对象中包含了&quot;aggregations&quot;属性，下面的一个子属性&quot;jobs&quot; 就是对应我们的第一层对于字段 job.keyword 的 terms aggregation的结果，即根据工种进行分类的各个员工桶，所有的桶又放到一个子属性&quot;buckets&quot;中。其中每个桶都有它的名字，即job.keyword 的一个字段值，另外还通过 doc_count 告诉了我们这个桶中有多少文档命中。而每个桶中还有一个属性就是&quot;old_emplyee&quot;，它就是我们指定的第二个 agg，嵌套在 terms agg 内的 top_hits agg的处理结果。它包含了一个 hits 属性，该属性下面有一个 total 属性告诉我们 这个子 agg 中命中了多个文档，并在另外一个一个子属性 hits 数组中给我们返回了按照指定排序的前三个文档。</p><pre><code># 指定size，不同工种中，年纪最大的3个员工的具体信息POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;:&quot;job.keyword&quot;      },      &quot;aggs&quot;:{        &quot;old_employee&quot;:{          &quot;top_hits&quot;:{            &quot;size&quot;:3,            &quot;sort&quot;:[              {                &quot;age&quot;:{                  &quot;order&quot;:&quot;desc&quot;                }              }            ]          }        }      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214436.png" alt="image-20200427170126884"></p><h6 id="优化-Terms-聚合的性能"><a class="header-anchor" href="#优化-Terms-聚合的性能">¶</a>优化 Terms 聚合的性能</h6><p>关于 Terms 聚合的性能优化，参考下面的官方文档在要进行Terms 聚合的字段的 mapping 上配置一个&quot;eager_global_ordinals&quot;的参数为 true。总的来说就是ES 中对于 terms aggregations 的操作需要保存一个&quot;global ordinals&quot;的数据结构在内存中的，但是默认这个数据结构是懒加载的（就是在具体收到 terms agg 请求之后才会去加载这个数据结构或者更新这个数据结构到和当前的索引数据一致），因为 ES 不知道用户要对哪个字段进行 term agg。用户可以通过对特定字段进行配置，这样 ES 就会立即在内存中对该字段加载这个数据结构，并且之后每当有新的索引进来的时候，新索引的信息也会立即同步到这个数据结构中。那么当我们进行 terms agg的时候，所有的数据都是预加载好的，在查询的时候就会有很好的性能。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214450.png" alt="image-20200427223850435"></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-search-speed.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-search-speed.html</a></p><p><strong>开启这个选项的一些场景：</strong></p><p>我们明确清除哪些字段是需要做 term agg 的，并且这个操作是比较频繁的，然后该索引是一直不断有数据写入的。</p><h4 id="Cardinality"><a class="header-anchor" href="#Cardinality">¶</a>Cardinality</h4><p>前面介绍到 Cardinality 类似 sql 中的 distinct 操作，即对分组中的数据进行去重操作（可以指定某个或者某些字段，也可以不指定）。看下面的例子，我们在开启了 fielddata 之后分别对字段 job 和它的子字段 job.keyword 进行了 cardinality 操作，可以看到分别得到了两个不同的结果。作别 job 字段得到的结果是10、右边 job.keyword 得到的结果是7。这个也是因为对于结构化数据和 text 类型数据的处理差异导致的。</p><pre><code># 对job.keyword 和 job 进行 terms 聚合，分桶的总数并不一样POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;cardinate&quot;: {      &quot;cardinality&quot;: {        &quot;field&quot;: &quot;job&quot;        //&quot;field&quot;: &quot;job.keyword&quot;      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214459.png" alt="image-20200427163715421"></p><h4 id="Range聚合"><a class="header-anchor" href="#Range聚合">¶</a>Range聚合</h4><p>前面我们提到，在 Bucket aggregation 中，除了进行 Terms 分桶之后，还可以使用 Range 对一个范围进行分桶。在 Range Aggregatioin 中可以自定义 Key。可以看到下面的例子，我们对于员工的薪资范围（数值型字段）进行分桶，通过在 _search api 的 “aggs” 属性中指定 agg 名称，然后指定 agg 类型为 “range” ，并通过&quot;field&quot;属性指定分桶字段为&quot;salary&quot;，最后在&quot;rangs&quot;属性中定义分桶的逻辑：其中第一个桶为最小值到10000的范围的员工文档，第二个桶为10000到20000范围的员工文档，第三个范围为从20000到最大值的员工文档。</p><p>另外我们还能手动设置 range agg 中的桶的 key，例如我们在定义第三个桶的范围的时候就指定了 key 为&quot;&gt;20000&quot;。</p><p>然后通过执行看到 ES 给我们返回的数据中看到，第一个桶的文档有1个，第二个有4个，第三个有15个。另外第三个桶的 key 就是我们设置的&quot;&gt;20000&quot;，而其他 key 因为没有指定，所以是 ES 默认生成的。</p><pre><code>#Salary Ranges 分桶，可以自己定义 keyPOST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;salary_range&quot;: {      &quot;range&quot;: {        &quot;field&quot;:&quot;salary&quot;,        &quot;ranges&quot;:[          {            &quot;to&quot;:10000          },          {            &quot;from&quot;:10000,            &quot;to&quot;:20000          },          {            &quot;key&quot;:&quot;&gt;20000&quot;,            &quot;from&quot;:20000          }        ]      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214516.png" alt="image-20200427225842278"></p><h4 id="Histogram-聚合"><a class="header-anchor" href="#Histogram-聚合">¶</a>Histogram 聚合</h4><p>下面我们来介绍 Histogram 聚合（直方图、柱状图）。同样的我们在 _search.aggs 中设置我们的 agg 名称，然后指定 agg type 为 “histogram”，并指定 field 为 salary，然后设置间隔 interval 为5000。并通过 extened_bounds 指定了上限和下限。这指示 ES 对检索查询之后的员工文档数据取薪资为0到100000之间的数据，每差5000则分为一个桶，然后返回 agg 的结果。</p><p>通过观察结果可以看到，即使桶中没有信息，ES 也会进行返回，但是桶中文档 doc_value 的数量是0.</p><pre><code>#Salary Histogram,工资0到10万，以 5000一个区间进行分桶POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;salary_histrogram&quot;: {      &quot;histogram&quot;: {        &quot;field&quot;:&quot;salary&quot;,        &quot;interval&quot;:5000,        &quot;extended_bounds&quot;:{          &quot;min&quot;:0,          &quot;max&quot;:100000        }      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214522.png" alt="image-20200427225907495"></p><h4 id="Bucket-Metric-Aggregation"><a class="header-anchor" href="#Bucket-Metric-Aggregation">¶</a>Bucket + Metric Aggregation</h4><h6 id="Demo1："><a class="header-anchor" href="#Demo1：">¶</a>Demo1：</h6><p>前面提到，Bucket 聚合分析允许通过添加子聚合分析来进一步分析（即嵌套），其子聚合分析可以是 Bucket 和 Metric。</p><p>下面是一个 Bucket 嵌套 Metic 的例子，可以看到我们在第一层 aggs 中设定一个 term agg，它根据&quot;job.keyword&quot;进行分桶；然后在 term agg（ 名称为Job_salary_stats）中又指定了一个 stats agg，表示对桶内的数据进行常用的数值统计。</p><p>ES 给我们的返回结果也是按照第一个 term agg 分组之后的各个桶进行返回，然后桶内是第二个 stats agg 统计的相关数据。</p><pre><code># 嵌套聚合1，按照工作类型分桶，并统计工资信息POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;Job_salary_stats&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;job.keyword&quot;      },      &quot;aggs&quot;: {        &quot;salary&quot;: {          &quot;stats&quot;: {            &quot;field&quot;: &quot;salary&quot;          }        }      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214529.png" alt="image-20200427230608950"></p><h6 id="Demo2："><a class="header-anchor" href="#Demo2：">¶</a>Demo2：</h6><p>下面我们再来看一个相对又复杂了一点的 Agg 嵌套，这次我们是先对 字段 “job.keyword” 进行分桶，即将所有员工按照工种进行分类，然后在各个工种桶中再按照性别字段 “gender” 进行分桶，即在工种之下再对员工进行性别的分类，然后再在性别桶下使用 stats agg 对员工薪资&quot;salary&quot;字段进行统计。</p><pre><code># 多次嵌套。根据工作类型分桶，然后按照性别分桶，计算工资的统计信息POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;Job_gender_stats&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;job.keyword&quot;      },      &quot;aggs&quot;: {        &quot;gender_stats&quot;: {          &quot;terms&quot;: {            &quot;field&quot;: &quot;gender&quot;          },          &quot;aggs&quot;: {            &quot;salary_stats&quot;: {              &quot;stats&quot;: {                &quot;field&quot;: &quot;salary&quot;              }            }          }        }      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214538.png" alt="image-20200427230929788"></p><h3 id="三、Pipeline-Aggregation"><a class="header-anchor" href="#三、Pipeline-Aggregation">¶</a>三、Pipeline Aggregation</h3><p>Pipeline Aggregation 指的是支持对聚合分析的结果（ 即经过分桶之后的或者还同时进行 Metric 的Bucket），再次进行聚合分析。</p><p>Pipeline 的分析结果会输出到愿结果中，根据位置的不同，分为两类：</p><ul><li>Sibling：结果和现有分析结果同级<ul><li>max、min、avg &amp; sum Bucket</li><li>Stats、Extended Stats Bucket</li><li>Percentiles Bucket</li></ul></li><li>Parent：结果内嵌到现有的聚合分析结果中<ul><li>Derivative（求导）</li><li>Cumultive Sum（累计求和）</li><li>Moving Function（滑动窗口）</li></ul></li></ul><h4 id="Sibling-Pipeline"><a class="header-anchor" href="#Sibling-Pipeline">¶</a>Sibling Pipeline</h4><h5 id="1）求所有工种中平均员工薪资最低的工种"><a class="header-anchor" href="#1）求所有工种中平均员工薪资最低的工种">¶</a>1）求所有工种中平均员工薪资最低的工种</h5><ol><li><p>准备数据</p><pre><code>DELETE employeesPUT /employees/_bulk{ &quot;index&quot; : {  &quot;_id&quot; : &quot;1&quot; } }{ &quot;name&quot; : &quot;Emma&quot;,&quot;age&quot;:32,&quot;job&quot;:&quot;Product Manager&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;:35000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;2&quot; } }{ &quot;name&quot; : &quot;Underwood&quot;,&quot;age&quot;:41,&quot;job&quot;:&quot;Dev Manager&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 50000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;3&quot; } }{ &quot;name&quot; : &quot;Tran&quot;,&quot;age&quot;:25,&quot;job&quot;:&quot;Web Designer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;:18000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;4&quot; } }{ &quot;name&quot; : &quot;Rivera&quot;,&quot;age&quot;:26,&quot;job&quot;:&quot;Web Designer&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;: 22000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;5&quot; } }{ &quot;name&quot; : &quot;Rose&quot;,&quot;age&quot;:25,&quot;job&quot;:&quot;QA&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;:18000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;6&quot; } }{ &quot;name&quot; : &quot;Lucy&quot;,&quot;age&quot;:31,&quot;job&quot;:&quot;QA&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;: 25000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;7&quot; } }{ &quot;name&quot; : &quot;Byrd&quot;,&quot;age&quot;:27,&quot;job&quot;:&quot;QA&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;:20000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;8&quot; } }{ &quot;name&quot; : &quot;Foster&quot;,&quot;age&quot;:27,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 20000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;9&quot; } }{ &quot;name&quot; : &quot;Gregory&quot;,&quot;age&quot;:32,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;:22000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;10&quot; } }{ &quot;name&quot; : &quot;Bryant&quot;,&quot;age&quot;:20,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 9000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;11&quot; } }{ &quot;name&quot; : &quot;Jenny&quot;,&quot;age&quot;:36,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;:38000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;12&quot; } }{ &quot;name&quot; : &quot;Mcdonald&quot;,&quot;age&quot;:31,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 32000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;13&quot; } }{ &quot;name&quot; : &quot;Jonthna&quot;,&quot;age&quot;:30,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;:30000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;14&quot; } }{ &quot;name&quot; : &quot;Marshall&quot;,&quot;age&quot;:32,&quot;job&quot;:&quot;Javascript Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 25000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;15&quot; } }{ &quot;name&quot; : &quot;King&quot;,&quot;age&quot;:33,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;:28000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;16&quot; } }{ &quot;name&quot; : &quot;Mccarthy&quot;,&quot;age&quot;:21,&quot;job&quot;:&quot;Javascript Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 16000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;17&quot; } }{ &quot;name&quot; : &quot;Goodwin&quot;,&quot;age&quot;:25,&quot;job&quot;:&quot;Javascript Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 16000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;18&quot; } }{ &quot;name&quot; : &quot;Catherine&quot;,&quot;age&quot;:29,&quot;job&quot;:&quot;Javascript Programmer&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;: 20000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;19&quot; } }{ &quot;name&quot; : &quot;Boone&quot;,&quot;age&quot;:30,&quot;job&quot;:&quot;DBA&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 30000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;20&quot; } }{ &quot;name&quot; : &quot;Kathy&quot;,&quot;age&quot;:29,&quot;job&quot;:&quot;DBA&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;: 20000}</code></pre></li><li><p>我们对员工按照工种进行分组之后，找出平均工资最低的工种。</p><p>可以看到，上面的需求可以理解为，将员工文档按照工种&quot;job.keyword&quot;进行分组分组之后(Terms of Bucket Agg)，然后求出所有分桶中员工文档的平均工资 salary(Metric Agg)，然后再对所有的桶进行分析（每个返回的桶都包含了这个 Metric Agg 的结果），即求出 Metric Agg 结果最低的那个桶。</p><p>我们在 aggs 同级的属性中声明了一个&quot;min_salary_by_job&quot;的属性，然后再给它设置一个&quot;min_bucket&quot; 的子属性。表述这是一个用户自定义的名为&quot;min_salary_by_job&quot;的 &quot;min_bucket&quot;类型的 Pipeline Agg，然后给&quot;min_bucket&quot;设置一个&quot;buckets_path&quot;的子属性， 这是一个 pipeline Agg 的通用属性，表示需要进行分析的 Aggregation 的路径，我们上面先是名为&quot;jobs&quot;的 trems agg 进行了分桶，然后在&quot;jobs&quot;里面嵌套定义了一个 “avg_salary&quot;的 Metric agg。所以我们需要做 pipeline agg 的路径就是&quot;jobs &gt; avg_salary”。</p><p>后面的返回结果中在 “jobs” agg 的结果下面有一个同级的返回就是&quot;min_salary_by_job&quot;，即我们的 pipeline agg 的结果，返回的就是平均工资最少的 key 为&quot;Javascript Programmer&quot;的 Bucket。</p><p>因为它是定义在我们需要分析的桶的同级的，然后在&quot;buckets_path&quot;中指定要分析的对象是bucket agg 的一个子属性（Metric agg），返回结果也是同级，所以称之为 Sibling Pipeline（Bucket As Sibling/Brothers）。</p><pre><code># 平均工资最低的工作类型POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;job.keyword&quot;,        &quot;size&quot;: 10      },      &quot;aggs&quot;: {        &quot;avg_salary&quot;: {          &quot;avg&quot;: {            &quot;field&quot;: &quot;salary&quot;          }        }      }    },    &quot;min_salary_by_job&quot;:{      &quot;min_bucket&quot;: {        &quot;buckets_path&quot;: &quot;jobs&gt;avg_salary&quot;      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214546.png" alt="image-20200429081227260"></p></li></ol><h5 id="2）基于所有工种的平均工资进行求平均工资"><a class="header-anchor" href="#2）基于所有工种的平均工资进行求平均工资">¶</a>2）基于所有工种的平均工资进行求平均工资</h5><p>以下是对分桶后的工种 Buckets 进行一次求平均工资的 pipeline agg，可以看到这次  pipeline agg 返回的结果仅仅是一个数值。</p><pre><code># 平均工资的平均工资POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;job.keyword&quot;,        &quot;size&quot;: 10      },      &quot;aggs&quot;: {        &quot;avg_salary&quot;: {          &quot;avg&quot;: {            &quot;field&quot;: &quot;salary&quot;          }        }      }    },    &quot;avg_salary_by_job&quot;:{      &quot;avg_bucket&quot;: {        &quot;buckets_path&quot;: &quot;jobs&gt;avg_salary&quot;      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214553.png" alt="image-20200429082330968"></p><h5 id="3）对各工种的平均工资求百分数"><a class="header-anchor" href="#3）对各工种的平均工资求百分数">¶</a>3）对各工种的平均工资求<a href="https://baike.baidu.com/item/%E7%99%BE%E5%88%86%E4%BD%8D%E6%95%B0/10064171?fr=aladdin" target="_blank" rel="noopener">百分数</a></h5><p>可以看到 ES 默认只是求出第1、5、25、50、75、95、99百分位数，分别是19250（Javascript Programmer）、21000（QA）、25000（DBA）、35000（Product Manager）、50000（Dev Manager）、50000（Dev Manager）。即只有百分之一的工种的平均工资低于等于19250（Js）、有百分之五低于等于21000（QA）、有百分之五十低于等于25000（DBA）有百分之七十五的工资低于等于35000（PM）、有百分之九十五和九十九工种都低于等于50000（Dev Manager）。</p><pre><code># 平均工资的百分位数POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;job.keyword&quot;,        &quot;size&quot;: 10      },      &quot;aggs&quot;: {        &quot;avg_salary&quot;: {          &quot;avg&quot;: {            &quot;field&quot;: &quot;salary&quot;          }        }      }    },    &quot;percentiles_salary_by_job&quot;:{      &quot;percentiles_bucket&quot;: {        &quot;buckets_path&quot;: &quot;jobs&gt;avg_salary&quot;      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214601.png" alt="image-20200429085248609"></p><h5 id="4）其他例子"><a class="header-anchor" href="#4）其他例子">¶</a>4）其他例子</h5><pre><code># 平均工资最高的工作类型POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;job.keyword&quot;,        &quot;size&quot;: 10      },      &quot;aggs&quot;: {        &quot;avg_salary&quot;: {          &quot;avg&quot;: {            &quot;field&quot;: &quot;salary&quot;          }        }      }    },    &quot;max_salary_by_job&quot;:{      &quot;max_bucket&quot;: {        &quot;buckets_path&quot;: &quot;jobs&gt;avg_salary&quot;      }    }  }}# 平均工资的统计分析POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;job.keyword&quot;,        &quot;size&quot;: 10      },      &quot;aggs&quot;: {        &quot;avg_salary&quot;: {          &quot;avg&quot;: {            &quot;field&quot;: &quot;salary&quot;          }        }      }    },    &quot;stats_salary_by_job&quot;:{      &quot;stats_bucket&quot;: {        &quot;buckets_path&quot;: &quot;jobs&gt;avg_salary&quot;      }    }  }}</code></pre><h4 id="Parent-Pipeline"><a class="header-anchor" href="#Parent-Pipeline">¶</a>Parent Pipeline</h4><h5 id="1）Derivative-Aggregation"><a class="header-anchor" href="#1）Derivative-Aggregation">¶</a>1）Derivative Aggregation</h5><p>对员工的年龄每间隔一岁为一组进行分组，然后求分组内的平均工资（直方图），并求出所有年龄分组的平均工资与（减去）前一个年龄分组的平均工资的差值。这里我们使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-pipeline-derivative-aggregation.html#_second_order_derivative" target="_blank" rel="noopener">Derivative Aggregation</a>。</p><p>可以看到，我们先是定义了一个 “histogram” (bucket) agg，实现员工按照一岁的年龄间隔的分桶，然后再对每个桶定义一个 “avg” (Metric) agg求每隔桶内员工的平均工资。最后我们在avg metric agg 的同级，也是 histogram bucket agg 的子级（桶内）定义了一个名为&quot;derivative_avg_salary&quot;的derivative (pipeline) agg，进行直方图每个区间(bucket)与上一个区间的 metic agg 的差值求解。</p><p>可以看到我们这个pipeline agg 是定义在 bucket agg 之内的（因为每个 bucket 都会对应一个属于该 bucket 的 pipeline 分析结果，所以理所应当定义在每隔 bucket 之内），而 pipeline agg的 “buckets_path&quot;属性指定的是&quot;avg_salary”，它是&quot;histogram&quot; bucket agg 的子 agg（Metric agg）。</p><p>另外看到 ES 的返回结果，除了第一个 histogram bucket之外其他的 bucket 之内都带有&quot;derivative_avg_salary&quot;的一个分析结果。所以我们称这种 pipeline agg 为 Parent Pipeline（Bucket As Parent）。</p><pre><code>#按照年龄对平均工资求导POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;age&quot;: {      &quot;histogram&quot;: {        &quot;field&quot;: &quot;age&quot;,        &quot;min_doc_count&quot;: 1,        &quot;interval&quot;: 1      },      &quot;aggs&quot;: {        &quot;avg_salary&quot;: {          &quot;avg&quot;: {            &quot;field&quot;: &quot;salary&quot;          }        },        &quot;derivative_avg_salary&quot;:{          &quot;derivative&quot;: {            &quot;buckets_path&quot;: &quot;avg_salary&quot;          }        }      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214609.png" alt="image-20200429094332945"></p><h5 id="2）cumulative-sum-aggregation"><a class="header-anchor" href="#2）cumulative-sum-aggregation">¶</a>2）cumulative_sum aggregation</h5><p>这是一个对 bucket(parent of pipeline) 进行累加求和的 agg，可以看到结果返回的每一个 bucket 中都包含了对其 Metric agg 的结果再次进行 cumulative_sum agg 的结果，第一个 bucket 的cumulative_sum 的结果就 Metric agg 原本的结果，之后每个cumulative_sum agg 的结果都是对前一个 cumulative agg 结果的累加。</p><pre><code>#Cumulative_sumPOST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;age&quot;: {      &quot;histogram&quot;: {        &quot;field&quot;: &quot;age&quot;,        &quot;min_doc_count&quot;: 1,        &quot;interval&quot;: 1      },      &quot;aggs&quot;: {        &quot;avg_salary&quot;: {          &quot;avg&quot;: {            &quot;field&quot;: &quot;salary&quot;          }        },        &quot;cumulative_salary&quot;:{          &quot;cumulative_sum&quot;: {            &quot;buckets_path&quot;: &quot;avg_salary&quot;          }        }      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214618.png" alt="image-20200429095145755"></p><h5 id="3）Moving-Function"><a class="header-anchor" href="#3）Moving-Function">¶</a>3）Moving Function</h5><p>Moving Function也是一个Parent Pipeline Agg。它表示对于一个一定顺序的集合，维护一个窗口大小 N（当前 Bucket 往前的 N 个Buckets，支持用户自定义，默认不确定，待看，这里指定了是10），然后对这 N 个 Buckets 进行一个 Function 求解（默认值不确定，待看，支持用户自定义，这里我们定义了一个&quot;script&quot;类型的 Function：“MovingFunctions.min(values)” ：表示对 &quot;avg_salary&quot;的结果&quot;value&quot;求最小值，也就是求窗口之内的 Bucket 的 Metric 最小值）。</p><pre><code>#Moving FunctionPOST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;age&quot;: {      &quot;histogram&quot;: {        &quot;field&quot;: &quot;age&quot;,        &quot;min_doc_count&quot;: 1,        &quot;interval&quot;: 1      },      &quot;aggs&quot;: {        &quot;avg_salary&quot;: {          &quot;avg&quot;: {            &quot;field&quot;: &quot;salary&quot;          }        },        &quot;moving_avg_salary&quot;:{          &quot;moving_fn&quot;: {            &quot;buckets_path&quot;: &quot;avg_salary&quot;,            &quot;window&quot;:10,            &quot;script&quot;: &quot;MovingFunctions.min(values)&quot;          }        }      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214625.png" alt="image-20200429100413498"></p><h3 id="四、Matrix-Aggregation"><a class="header-anchor" href="#四、Matrix-Aggregation">¶</a>四、Matrix Aggregation</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-matrix.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-matrix.html</a></p><h3 id="五、相关阅读"><a class="header-anchor" href="#五、相关阅读">¶</a>五、相关阅读</h3><p>以上介绍都是一些入门的介绍，当遇到要详细使用的时候，如果上面的介绍无法满足，可以去阅读以下文档，或者去寻找其他相关的文档。</p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-metrics.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-metrics.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-bucket.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-bucket.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-pipeline.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-pipeline.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-matrix.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-matrix.html</a></p><h1>聚合的作用范围与排序</h1><p>ES 聚合分析的默认作用范围是 query 的查询结果集，如果没有使用指定 query，那么就是指定索引的所有文档数据。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214634.png" alt="image-20200429101259036"></p><p>同时 ES 还支持以下方式改变聚合的作用范围：</p><ul><li>Filter</li><li>Post_Filter</li><li>Global</li></ul><p>下面我们来对这三种改变聚合的作用范围的操作进行分析，在此之前先准备数据：</p><pre><code>DELETE /employeesPUT /employees/{  &quot;mappings&quot; : {      &quot;properties&quot; : {        &quot;age&quot; : {          &quot;type&quot; : &quot;integer&quot;        },        &quot;gender&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;job&quot; : {          &quot;type&quot; : &quot;text&quot;,          &quot;fields&quot; : {            &quot;keyword&quot; : {              &quot;type&quot; : &quot;keyword&quot;,              &quot;ignore_above&quot; : 50            }          }        },        &quot;name&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;salary&quot; : {          &quot;type&quot; : &quot;integer&quot;        }      }    }}PUT /employees/_bulk{ &quot;index&quot; : {  &quot;_id&quot; : &quot;1&quot; } }{ &quot;name&quot; : &quot;Emma&quot;,&quot;age&quot;:32,&quot;job&quot;:&quot;Product Manager&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;:35000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;2&quot; } }{ &quot;name&quot; : &quot;Underwood&quot;,&quot;age&quot;:41,&quot;job&quot;:&quot;Dev Manager&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 50000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;3&quot; } }{ &quot;name&quot; : &quot;Tran&quot;,&quot;age&quot;:25,&quot;job&quot;:&quot;Web Designer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;:18000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;4&quot; } }{ &quot;name&quot; : &quot;Rivera&quot;,&quot;age&quot;:26,&quot;job&quot;:&quot;Web Designer&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;: 22000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;5&quot; } }{ &quot;name&quot; : &quot;Rose&quot;,&quot;age&quot;:25,&quot;job&quot;:&quot;QA&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;:18000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;6&quot; } }{ &quot;name&quot; : &quot;Lucy&quot;,&quot;age&quot;:31,&quot;job&quot;:&quot;QA&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;: 25000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;7&quot; } }{ &quot;name&quot; : &quot;Byrd&quot;,&quot;age&quot;:27,&quot;job&quot;:&quot;QA&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;:20000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;8&quot; } }{ &quot;name&quot; : &quot;Foster&quot;,&quot;age&quot;:27,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 20000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;9&quot; } }{ &quot;name&quot; : &quot;Gregory&quot;,&quot;age&quot;:32,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;:22000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;10&quot; } }{ &quot;name&quot; : &quot;Bryant&quot;,&quot;age&quot;:20,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 9000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;11&quot; } }{ &quot;name&quot; : &quot;Jenny&quot;,&quot;age&quot;:36,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;:38000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;12&quot; } }{ &quot;name&quot; : &quot;Mcdonald&quot;,&quot;age&quot;:31,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 32000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;13&quot; } }{ &quot;name&quot; : &quot;Jonthna&quot;,&quot;age&quot;:30,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;:30000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;14&quot; } }{ &quot;name&quot; : &quot;Marshall&quot;,&quot;age&quot;:32,&quot;job&quot;:&quot;Javascript Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 25000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;15&quot; } }{ &quot;name&quot; : &quot;King&quot;,&quot;age&quot;:33,&quot;job&quot;:&quot;Java Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;:28000 }{ &quot;index&quot; : {  &quot;_id&quot; : &quot;16&quot; } }{ &quot;name&quot; : &quot;Mccarthy&quot;,&quot;age&quot;:21,&quot;job&quot;:&quot;Javascript Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 16000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;17&quot; } }{ &quot;name&quot; : &quot;Goodwin&quot;,&quot;age&quot;:25,&quot;job&quot;:&quot;Javascript Programmer&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 16000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;18&quot; } }{ &quot;name&quot; : &quot;Catherine&quot;,&quot;age&quot;:29,&quot;job&quot;:&quot;Javascript Programmer&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;: 20000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;19&quot; } }{ &quot;name&quot; : &quot;Boone&quot;,&quot;age&quot;:30,&quot;job&quot;:&quot;DBA&quot;,&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;: 30000}{ &quot;index&quot; : {  &quot;_id&quot; : &quot;20&quot; } }{ &quot;name&quot; : &quot;Kathy&quot;,&quot;age&quot;:29,&quot;job&quot;:&quot;DBA&quot;,&quot;gender&quot;:&quot;female&quot;,&quot;salary&quot;: 20000}</code></pre><h3 id="Filter"><a class="header-anchor" href="#Filter">¶</a>Filter</h3><p>前面提到 agg 是基于query 的结果进行的，但是我们还可以基于 query 的结果再进行一次 filter，然后将 filter 之后的数据进行 agg。这里将介绍在 agg 内部使用 filter 对查询出来的数据范围进行过滤。</p><p>可以看到下面的例子中，我们没有使用 query 操作，那么 agg 接收到的数据将是 employees 下的所有文档数据。然后我们在 aggs 属性下定义了两个 agg，分别是 older_person 和 all_jobs：</p><ul><li><p>其中 older_person 下面先是指定了一个 filter 子属性以及再定义了一个 aggs 子属性。这表示一个 filter 操作，ES 会对该&quot;older_person&quot; agg 的数据先进行一个 filter操作（过滤数据），然后将操作之后的结果输入到&quot;aggs&quot;，其中 aggs 中定义了一个 term 类型的名为 jobs 的 bucket agg。</p><p>所以整个操作就是在所有员工中过滤出来35岁以上的员工然后按照工种进行分桶。</p></li><li><p>而下面的 all_jobs 子属性直接定义了一个&quot;term&quot;类型的 agg 操作，所以就是不过滤任何数据，直接进行一个 term agg 的分桶操作。</p></li></ul><p>从返回结果可以看到进过 filter 操作之后的 older_person 只有2个员工文档数据，分桶之后得到了&quot;Dev Manager&quot;和&quot;Java Programmer&quot;两个桶，桶中分别有1个文档。</p><pre><code>#FilterPOST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;older_person&quot;: {      &quot;filter&quot;:{        &quot;range&quot;:{          &quot;age&quot;:{            &quot;from&quot;:35          }        }      },      &quot;aggs&quot;:{         &quot;jobs&quot;:{           &quot;terms&quot;: {        &quot;field&quot;:&quot;job.keyword&quot;      }      }    }},    &quot;all_jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;:&quot;job.keyword&quot;              }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214641.png" alt="image-20200429102556623"></p><h3 id="Post-Filter"><a class="header-anchor" href="#Post-Filter">¶</a>Post Filter</h3><p>顾名思义，Post FIlter 指的就是进行 agg 之后再进行一次 filter，当然，和 filter 的作用对象一样，就是 query 之后的所有文档数据，也就是输入到 aggs 中的所有进行 agg 的文档。</p><p>可以看到下面例子中，我们默认对 emplyees 中的所有文档数据以&quot;job.keyword&quot;字段进行 term agg 分桶。然后在 “aggs” 对象后面定义了一个同级的&quot;post_filter&quot;对象，并指定 filter 类型为 match，指定 match 的字段和值分别是&quot;job.keyword&quot;和&quot;Dev Manager&quot;。表示我们对所有的数据进行 aggs 操作之后（只有一个名为&quot;jobs&quot;的 term bucket agg）再进行&quot;job.keyword=Dev Manager&quot;到数据匹配的过滤。</p><p>从返回结果可以看到，“hits” 中返回了所有字段&quot;job&quot;为&quot;Dev Manager&quot; 的文档数据，只有一条，而下面的 “aggregations” 就是terms agg 的结果了。</p><pre><code>#Post field. 一条语句，找出所有的job类型。还能找到聚合后符合条件的结果POST employees/_search{  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;: &quot;job.keyword&quot;      }    }  },  &quot;post_filter&quot;: {    &quot;match&quot;: {      &quot;job.keyword&quot;: &quot;Dev Manager&quot;    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214648.png" alt="image-20200429103209572"></p><h3 id="Global"><a class="header-anchor" href="#Global">¶</a>Global</h3><p>在下面的例子，我们在第一层 aggs 前面定义了一个 query 对象查询出大于等于40岁的员工。然后传入到第一层 aggs 对象中。而 aggs 对象中定义了两个子对象，一个是 jobs，一个是 all。</p><ul><li><p>jobs 是一个 term bucket agg，它下面还定义了一个 aggs，里面只有一个 avg metric agg。表示对员工按照工种分桶然后求平均工资，而作用范围就是 query 传入到第一层 aggs 的所有数据，即求所有工种中40以上的员工的平均工资。</p></li><li><p>而 all 下面则是直接定义了一个 avg metric agg，即没有进行分桶操作直接求员工的平均值。但是留意到前面还定义了一个&quot;global&quot;属性，它表示一个查询对象，即和第一层&quot;query&quot;生成的对象是一样的，在这里定义的查询对象会忽略第一层 query传入到第一层 aggs 传入到 all 的数据范围（实际上就是忽略所有输入数据），用这个查询对象去查询当前指定索引的文档数据直接进行 avg metric agg 操作。</p></li></ul><p>可以看到结果返回中名为 all 的 agg 命中数据有20条，而 jobs 只有1条。</p><pre><code>#globalPOST employees/_search{  &quot;size&quot;: 0,  &quot;query&quot;: {    &quot;range&quot;: {      &quot;age&quot;: {        &quot;gte&quot;: 40      }    }  },  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;:&quot;job.keyword&quot;      },      &quot;aggs&quot;: {        &quot;salary_avg&quot;: {          &quot;avg&quot;: {            &quot;field&quot;: &quot;salary&quot;          }        }      }    },        &quot;all&quot;:{      &quot;global&quot;:{},      &quot;aggs&quot;:{        &quot;salary_avg&quot;:{          &quot;avg&quot;:{            &quot;field&quot;:&quot;salary&quot;          }        }      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214656.png" alt="image-20200429104336799"></p><h3 id="排序"><a class="header-anchor" href="#排序">¶</a>排序</h3><h5 id="1、基于-bucket-agg-的普通属性进行排序"><a class="header-anchor" href="#1、基于-bucket-agg-的普通属性进行排序">¶</a>1、基于 bucket agg 的普通属性进行排序</h5><p><strong>默认情况下，aggs 的结果是按照 buckets 的 doc_count（_count）进行降序排序返回的</strong>（所有 agg 都基于 buckets agg，即数据聚合分组，有了一个数据分组才会有其他分析的操作，如果不进行 bucket 操作，那么所有数据就是一个缺省的 bucket）。</p><p>可以看到下面的例子中，没有指定任何排序，返回的分桶按照 doc_count 从7到1进行降序排序返回。</p><pre><code>POST employees/_search{  &quot;size&quot;: 0,  &quot;query&quot;: {    &quot;range&quot;: {      &quot;age&quot;: {        &quot;gte&quot;: 20      }    }  },  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;:&quot;job.keyword&quot;      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214702.png" alt="image-20200429105754832"></p><p><strong>我们通过给 agg 对象指定 order 属性可以实现对于返回 bucket 的自定义排序。可以看到下面例子中，我们通过给一个 terms agg 对象 job 指定一个&quot;order&quot;属性</strong>，并定义了两个排序规则，分别是按照bucket 的&quot;_count&quot;字段进行升序排序，在&quot;_count&quot;字段一样的 buckets 中按照 bucket 的&quot;_key&quot;对象进行降序排序。</p><p>从返回结果可以看到所有 bucket 按照从1到7的_count 字段的升序排序。其中前两个 bucket 的 doc_count 是一样的，此时按照 _key 进行降序排序。</p><pre><code>POST employees/_search{  &quot;size&quot;: 0,  &quot;query&quot;: {    &quot;range&quot;: {      &quot;age&quot;: {        &quot;gte&quot;: 20      }    }  },  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;:&quot;job.keyword&quot;,        &quot;order&quot;:[          {&quot;_count&quot;:&quot;asc&quot;},          {&quot;_key&quot;:&quot;desc&quot;}        ]      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214710.png" alt="image-20200429110003715"></p><h5 id="2、基于-bucket-agg-的子-agg-的属性-多层属性-进行排序"><a class="header-anchor" href="#2、基于-bucket-agg-的子-agg-的属性-多层属性-进行排序">¶</a>2、基于 bucket agg 的子 agg 的属性(多层属性)进行排序</h5><p><strong>此外，我们还能在 order 中指定对 bucket agg的子 metric agg 的结果进行排序</strong>，请看下面例子，我们在 order 中指定了 jobs （terms bucket）agg 的子 avg metric agg 的名称，并指定排序类型为降序排序。</p><p>下面的 ES 返回结果中对返回的按照工种分桶的 buckets 按照平均工资 降序返回。</p><pre><code>POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;:&quot;job.keyword&quot;,        &quot;order&quot;:[  {            &quot;avg_salary&quot;:&quot;desc&quot;          }]      },      &quot;aggs&quot;: {        &quot;avg_salary&quot;: {          &quot;avg&quot;: {            &quot;field&quot;:&quot;salary&quot;          }        }      }    }  }}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214717.png" alt="image-20200429110534988"></p><p><strong>上面的例子中，term bucket agg 的子 agg 是一个只有一个输出值的 avg metric agg。下面的例子展示的是一个拥有多输出值的 stats agg。可以看到我们可以通过&quot;xxx.属性&quot;的方式来指定按照 bucket 的子对象（应该不仅仅包括子 bucket）进行排序。</strong></p><pre><code>POST employees/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;jobs&quot;: {      &quot;terms&quot;: {        &quot;field&quot;:&quot;job.keyword&quot;,        &quot;order&quot;:[  {            &quot;stats_salary.min&quot;:&quot;desc&quot;          }]        },      &quot;aggs&quot;: {        &quot;stats_salary&quot;: {          &quot;stats&quot;: {            &quot;field&quot;:&quot;salary&quot;          }        }      }    }  }}</code></pre><h1>聚合的精准问题</h1><p>前面提到，ES 是一个可以支持对海量数据进行一个近实时搜索的搜索引擎，但是 ES 是牺牲了一定的搜索精准度来实现这个近实时的效果的。</p><p>对于所有的数据计算来说，在数据量、精准度和实时性三个维度，只能同时满足两个。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214803.png" alt="image-20200429113150987"></p><h3 id="Min-聚合分析的执行流程-准确"><a class="header-anchor" href="#Min-聚合分析的执行流程-准确">¶</a>Min 聚合分析的执行流程(准确)</h3><p>我们可以看到，当 ES 的一个 coordinating节点接收到一个 min 聚合请求的时候，当聚合的数据范围分布在三个分片上，那么 coordinating 节点就会分别像这三个 data node 发出求 min 聚合的请求，此时这三个数据节点都分别求出自己的 min 聚合结果然后返回到 coordinating node，coordinating node 再在三个分片的结果中求出最小值，最终把结果返回给用户。</p><p>所以对于 min 操作来说，是完全没有精准度损失的问题的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214809.png" alt="image-20200429113448585"></p><h3 id="Terms-聚合分析的执行流程-可能不准"><a class="header-anchor" href="#Terms-聚合分析的执行流程-可能不准">¶</a>Terms 聚合分析的执行流程(可能不准)</h3><p>我们从 terms aggregation 的两个参数入手分析其执行流程：</p><ul><li><p>doc_count_error_upper_cound：指的是在对各分片进行 buckets agg 的时候各个分片中没有返回的桶（例如用户请求返回前 N 个桶，此时 coordinating 节点向所有数据分片发出返回前 N 个桶的请求，此时指的就是按照顺序的第 N+1个桶中的可能的最大的文档数）中 doc_count 的可能最大值的总和。</p><p>这个属性在agg 的返回信息中有一个对所有桶的总值，另外在每个桶下面还有一个对于该桶计算的值。 桶的 doc_count_error_upper_bound 属性默认没有计算和返回，通过设置 terms agg 对象的<code>show_term_doc_count_error:true</code>属性启用。这个属性反应了可能当前桶内少算的文档数量的最大值。</p><p>我们可以通过观察和调低这个值来让 terms agg 更加准确。</p></li><li><p>sum_other_doc_count：指的是实际的文档总数与返回的分桶数中的文档总数的差值。</p></li></ul><p>我们通过下面的详细例子来了解这两个参数的含义：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214840.png" alt="image-20200429130549611"></p><p>我们来看下面 terms 聚合的一个流程：</p><p>当一个 coordinating node 接收到一个 terms agg 操作的请求，该请求还通过指定了一个 _size 字段要求返回前3个分桶。</p><blockquote><p>前面提到 ES 的 agg 默认情况下 bucket 是按照 doc_count 进行降序排序的。所以理论上应该返回前三个文档数最多的分桶。</p></blockquote><p>ES 发现需要进行分桶的数据分布在三个分片上面，就会分别发送请求到这三个分片上面分别求出在该 data node 上的前三个分桶，然后在 coordinating node 进行汇总并返回。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214845.png" alt="image-20200429114200737"></p><p>我们以下面例子来分析 term agg 可能会出现不准确的情况：</p><p>coordinating 收到一个求前三个桶的请求，发现数据分布在两个数据节点上，然后发送求前三个桶的请求到这两个分片上：</p><ul><li>分片1对数据进行分组之后有 A、B、C、D 4个桶，桶内数据分别是6、4、4、3，所以分片1会返回 A、B、C 3个桶；</li><li>分片2对数据进行分组之后刚好也有A、B、C、D 3个桶，桶内数据分别是 6、2、1、3，所以分片2会返回 A、B、D3个桶。</li></ul><p>此时 coordinating 收到两个分片的返回数据之后会对返回数据进行汇总。得到 <strong>A</strong>(6+6=12)、<strong>B</strong>(4+2=6)、<strong>C</strong>(4+0=3&gt;D(0+3=3)) 三个桶作为前三个桶进行返回。但是我们发现其实 D分组中的文档总数其实是6，是比 C 要大的，但是因为在分片1中的排序之后的第3个桶的文档数已经比 D 要大，而分片1收到的请求是返回前3个桶，所以 D 并没有被返回，导致其在分片1中的文档数&quot;丢失&quot;了。</p><p>我们看到，此时：</p><ul><li><p>总的<strong>doc_count_error_upper_bound 的数量就是分片1返回的最后一个桶的文档数4（ES 找到第3个桶就返回了，并不会再去看第4个桶的文档数是多少，所以这里指的是第4个桶的可能最大文档数，按照降序不可能超过桶 C 的文档数4，所以是4） 加上分片2返回的最后一个桶的文档数2等于6</strong>。</p><p>而桶 A 的doc_count_error_upper_bound就是0（两个分片都返回了桶 A和它的文档数）、桶 B 也是0、桶 C 是2（分片2没有返回桶 C ，而返回的桶中最小的桶 B 的数量是2，所以没有返回的桶最大文档数按照降序只能是2）、桶 D 是4（分片1没有返回桶 D，返回的最少分文档数的桶文档数是4）。</p></li><li><p>而 <strong>sum_other_doc_count 的数量就是两份片文档数之和17+12减去返回的总文档数12+6+4得到7</strong>。</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214908.png" alt="image-20200429115333875"></p><h3 id="解决-Terms-agg-不准的问题"><a class="header-anchor" href="#解决-Terms-agg-不准的问题">¶</a>解决 Terms agg 不准的问题</h3><p>Terms 聚合分析不准的根本原因是数据分散在多个分片上，负责最终汇总的 coordinating node 无法获取数据全貌。所以有以下两个角度对这个问题进行解决：</p><ul><li><p>当数据量不大的时候，设置 Primary Shard 为1，实现准确性。</p></li><li><p>通过调整 terms agg 对象的一个属性&quot;shard_size&quot;字段参数，提高精准度：</p><p>shard_size 字段的意义就是设定在进行 terms agg 的时候从各个分片上返回的桶的数量，在上面的例子中 shard_size 就是3，我们通过设置为4，就可以解决这个问题。</p><p>但是虽然调高了 shard_size，降低了 doc_count_error_upper_bound 数值，但是带来的就是整体计算量的增加，提高了准确度，但是也会导致计算时间变长。</p><p>所以调整准确率可以通过这样来实现：在进行 terms agg 的时候打开<code>show_term_doc_count_error</code>来计算各个桶的 doc_count_error_upper_bound 并返回，通过不断调高 shard_size 来降低各个doc_count_error_upper_bound值为0。此时coordinating 获得的各个分片返回的桶就是准确的，汇总并返回给我们的就是准确的数据。</p><blockquote><p>默认的情况下，shard_size = size(要求返回的桶的数量) * 1.5 + 10。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214914.png" alt="image-20200429132356896"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214919.png" alt="image-20200429132430277"></p><p>为什么当各个桶中的 doc_count_error_upper_bound 都是0的时候，计算返回的桶就是完全准确的呢？计算返回的桶完全准确的意思是，coordinating node 收到的所有分片返回的桶中包含了实际上应该准确返回给用户的前 N 个桶。我们用反证法来推导：</p><ul><li>前提：各个桶中的 doc_count_error_upper_bound 都是0<ul><li>只有一个分片中包含了一个实际上排在前 N 的桶 Z，但是没有返回到 coordiinating node，导致计算不准：如果存在这种情况，那么 doc_count_error_upper_bound 就不可能都是0。因为其他分片返回了桶Z，就会将没有返回桶Z的分片返回的最少文档数量的桶的文档数作为 桶 Z 的 doc_count_error_upper_bound。</li><li>部分分片包含了某些实际上排在前 N 的桶 Z 但是没有返回到 coordinating node：证明同上。</li><li>所有分片都没有返回一个实际上排在前 N 的桶 Z：回到我们的大前提，各个桶中的 doc_count_error_upper_bound 都是0，说明所有的分片返回的桶都是一样的，不可能存在这个分片返回的某个桶在那个分片中没有的情况，这点前两条证明已经回答。那么为什么桶 Z 没有返回呢，因为它在所有分片中都排在返回的这些桶的后面。所以即使将基于我们设置了 shard_size 之后各个分片返回的各个桶的文档数汇总起来，也都会超过从各个分片中汇总的桶 Z 的总数。</li></ul></li></ul></li></ul><blockquote><p>相关阅读：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-bucket-terms-aggregation.html#search-aggregations-bucket-terms-aggregation-approximate-counts" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-bucket-terms-aggregation.html#search-aggregations-bucket-terms-aggregation-approximate-counts</a></p></blockquote><h3 id="Kibana-测试请求"><a class="header-anchor" href="#Kibana-测试请求">¶</a>Kibana 测试请求</h3><pre><code>DELETE my_flightsPUT my_flights{  &quot;settings&quot;: {    &quot;number_of_shards&quot;: 20  },  &quot;mappings&quot; : {      &quot;properties&quot; : {        &quot;AvgTicketPrice&quot; : {          &quot;type&quot; : &quot;float&quot;        },        &quot;Cancelled&quot; : {          &quot;type&quot; : &quot;boolean&quot;        },        &quot;Carrier&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;Dest&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;DestAirportID&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;DestCityName&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;DestCountry&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;DestLocation&quot; : {          &quot;type&quot; : &quot;geo_point&quot;        },        &quot;DestRegion&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;DestWeather&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;DistanceKilometers&quot; : {          &quot;type&quot; : &quot;float&quot;        },        &quot;DistanceMiles&quot; : {          &quot;type&quot; : &quot;float&quot;        },        &quot;FlightDelay&quot; : {          &quot;type&quot; : &quot;boolean&quot;        },        &quot;FlightDelayMin&quot; : {          &quot;type&quot; : &quot;integer&quot;        },        &quot;FlightDelayType&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;FlightNum&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;FlightTimeHour&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;FlightTimeMin&quot; : {          &quot;type&quot; : &quot;float&quot;        },        &quot;Origin&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;OriginAirportID&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;OriginCityName&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;OriginCountry&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;OriginLocation&quot; : {          &quot;type&quot; : &quot;geo_point&quot;        },        &quot;OriginRegion&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;OriginWeather&quot; : {          &quot;type&quot; : &quot;keyword&quot;        },        &quot;dayOfWeek&quot; : {          &quot;type&quot; : &quot;integer&quot;        },        &quot;timestamp&quot; : {          &quot;type&quot; : &quot;date&quot;        }      }    }}POST _reindex{  &quot;source&quot;: {    &quot;index&quot;: &quot;kibana_sample_data_flights&quot;  },  &quot;dest&quot;: {    &quot;index&quot;: &quot;my_flights&quot;  }}GET kibana_sample_data_flights/_countGET my_flights/_countget kibana_sample_data_flights/_searchGET kibana_sample_data_flights/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;weather&quot;: {      &quot;terms&quot;: {        &quot;field&quot;:&quot;OriginWeather&quot;,        &quot;size&quot;:5,        &quot;show_term_doc_count_error&quot;:true      }    }  }}GET my_flights/_search{  &quot;size&quot;: 0,  &quot;aggs&quot;: {    &quot;weather&quot;: {      &quot;terms&quot;: {        &quot;field&quot;:&quot;OriginWeather&quot;,        &quot;size&quot;:1,        &quot;shard_size&quot;: 4,        &quot;show_term_doc_count_error&quot;:true      }    }  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>006_分布式特性及分布式搜索的机制</title>
      <link href="/2020/12/22/elasticsearch/006-fen-bu-shi-te-xing-ji-fen-bu-shi-sou-suo-de-ji-zhi/"/>
      <url>/2020/12/22/elasticsearch/006-fen-bu-shi-te-xing-ji-fen-bu-shi-sou-suo-de-ji-zhi/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1>一、配置跨集群搜索</h1><h3 id="1、水平扩展的痛点"><a class="header-anchor" href="#1、水平扩展的痛点">¶</a>1、水平扩展的痛点</h3><p>如果 Es 一直以单集群的状态运行的时候，当水平扩展的时候，节点数不能无限增加。因为随着节点数的增加，集群的 meta 信息（节点、索引、集群状态）过多，会导致更新压力变大，单个 Active Master 会称为性能瓶颈，导致整个集群无法正常工作。</p><p>在早期版本，通过 Tribe Node 可以实现多集群访问的需求，但是还是存在一定的问题：</p><ul><li>当前集群的 Tribe Node 会以 Client Node 的方式加入其他每个集群。其他集群中 Master节点的任务变更需要当前集群的 Tribe Node 的回应才能继续。</li><li>Tribe Node 不保存 Cluster State 信息，一旦重启，初始化很慢</li><li>当多个集群存在索引重名的情况时，只能设置一种 Prefer 规则</li></ul><h3 id="2、Cross-Cluster-Search（跨集群搜索）"><a class="header-anchor" href="#2、Cross-Cluster-Search（跨集群搜索）">¶</a>2、Cross Cluster Search（跨集群搜索）</h3><p>早期 Tribe Node 的方案存在一定的问题，现已被 Deprecated。在 Elasticsearch 5.3 引入了跨集群搜索的功能（Cross Cluster Search），推荐使用：</p><ul><li>允许任何节点扮演 federated 节点，以轻量的方式，将搜索请求进行代理</li><li>不需要以 Client Node 的形式加入其他集群</li></ul><h3 id="3、设定步骤"><a class="header-anchor" href="#3、设定步骤">¶</a>3、设定步骤</h3><ol><li><p>分别启动各个 Cluster（前面也提到过这个启动命令，这里的区别是我们指定了3个集群名称，每个集群只有一个节点）</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">//启动3个集群bin/elasticsearch -E node.name=cluster0node -E cluster.name=cluster0 -E path.data=cluster0_data -E discovery.type=single-node -E http.port=9200 -E transport.port=9300bin/elasticsearch -E node.name=cluster1node -E cluster.name=cluster1 -E path.data=cluster1_data -E discovery.type=single-node -E http.port=9201 -E transport.port=9301bin/elasticsearch -E node.name=cluster2node -E cluster.name=cluster2 -E path.data=cluster2_data -E discovery.type=single-node -E http.port=9202 -E transport.port=9302<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>通过_cluster/setting api 设定 Cross Cluster Search</strong>（persistent.cluster.remote.${clustername}.seeds:“ip:port”），另外我们可以在各个集群的配置中进行一些定制化配置，例如下面集群0的<code>transport.ping_schedule=30s</code>、集群1的<code>transport.compress=true</code>和<code>skip_unavailable=true</code>（表示当前集群如果挂了，无响应，可以跳过它）… …</p><p>参考模板</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">//在每个集群上设置动态的设置PUT _cluster/settings{  "persistent": {    "cluster": {      "remote": {        "cluster0": {          "seeds": [            "127.0.0.1:9300"          ],          "transport.ping_schedule": "30s"        },        "cluster1": {          "seeds": [            "127.0.0.1:9301"          ],          "transport.compress": true,          "skip_unavailable": true        },        "cluster2": {          "seeds": [            "127.0.0.1:9302"          ]        }      }    }  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们通过以下<code>curl</code>命令进行 cross cluster search 的设置：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">#CURLcurl -XPUT "http://localhost:9200/_cluster/settings" -H 'Content-Type: application/json' -d'{"persistent":{"cluster":{"remote":{"cluster0":{"seeds":["127.0.0.1:9300"],"transport.ping_schedule":"30s"},"cluster1":{"seeds":["127.0.0.1:9301"],"transport.compress":true,"skip_unavailable":true},"cluster2":{"seeds":["127.0.0.1:9302"]}}}}}'curl -XPUT "http://localhost:9201/_cluster/settings" -H 'Content-Type: application/json' -d'{"persistent":{"cluster":{"remote":{"cluster0":{"seeds":["127.0.0.1:9300"],"transport.ping_schedule":"30s"},"cluster1":{"seeds":["127.0.0.1:9301"],"transport.compress":true,"skip_unavailable":true},"cluster2":{"seeds":["127.0.0.1:9302"]}}}}}'curl -XPUT "http://localhost:9202/_cluster/settings" -H 'Content-Type: application/json' -d'{"persistent":{"cluster":{"remote":{"cluster0":{"seeds":["127.0.0.1:9300"],"transport.ping_schedule":"30s"},"cluster1":{"seeds":["127.0.0.1:9301"],"transport.compress":true,"skip_unavailable":true},"cluster2":{"seeds":["127.0.0.1:9302"]}}}}}'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>分别为各个集群添加文档数据到具有相同索引名称&quot;users&quot;的索引中</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">#创建测试数据curl -XPOST "http://localhost:9200/users/_doc" -H 'Content-Type: application/json' -d'{"name":"user1","age":10}'curl -XPOST "http://localhost:9201/users/_doc" -H 'Content-Type: application/json' -d'{"name":"user2","age":20}'curl -XPOST "http://localhost:9202/users/_doc" -H 'Content-Type: application/json' -d'{"name":"user3","age":30}'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>在查询的时候可以通过指定&quot;集群名称:索引名&quot;来进行搜索，如果不指定&quot;集群名称&quot;，默认在当前集群内进行搜索：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">#查询GET /users,cluster1:users,cluster2:users/_search{  "query": {    "range": {      "age": {        "gte": 20,        "lte": 40      }    }  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>而返回结果中也包含了索引的完整名字&quot;${集群名字}:索引名&quot;</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213506.png" alt="image-20200426141114160"></p></li><li><p>设置 Kibana 中的&quot;索引管理&quot;对多集群可见</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213515.png" alt="image-20200426140800887"></p><p>进入 Discover 面板可以看到多集群中的 users 索引 的信息了：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213523.png" alt="image-20200426141003924"></p><h3 id="相关阅读"><a class="header-anchor" href="#相关阅读">¶</a>相关阅读</h3><p><a href="https://kelonsoftware.com/cross-cluster-search-kibana/" target="_blank" rel="noopener">https://kelonsoftware.com/cross-cluster-search-kibana/</a></p></li></ol><h1>二、集群分布式模型及选主与脑裂问题</h1><h3 id="1、分布式特性"><a class="header-anchor" href="#1、分布式特性">¶</a>1、分布式特性</h3><p>Elasticsearch 的分布式架构带来了以下好处：</p><ul><li>存储的水平扩容，支持 PB 级数据</li><li>提高系统的可用性，部分节点停止服务，整个集群的服务不受影响</li></ul><p>Elasticsearch 的分布式架构</p><ul><li>不同的集群通过不同的名字来区分，默认名字&quot;elasticsearch&quot;</li><li>通过配置文件(elasticsearch.yml)修改，或者在命令行<code>-E cluster.name=geektime</code> 进行设定</li></ul><h3 id="2、Elasticsearch-中的节点"><a class="header-anchor" href="#2、Elasticsearch-中的节点">¶</a>2、Elasticsearch 中的节点</h3><p>节点是一个 Elasticsearch 实例，其本质上就是一个 Java 进程。一台机器上可以运行多个 Elasticsearch 进程，但是生产环境一般建议一台机器上就运行一个 Elasticsearch 实例。</p><p>每个节点都有名字，通过配置文件(elasticsearch.yml)配置，或者启动时<code>-E node.name=geektime</code> 指定</p><p>每一个节点在启动之后，会分配一个 UID，保存在 data 目录下</p><h3 id="3、Coordinating-Node"><a class="header-anchor" href="#3、Coordinating-Node">¶</a>3、Coordinating Node</h3><p>处理请求的节点，叫 Coordinating Node。它负责路由请求到正确的节点，例如创建索引的请求，需要路由到 Master节点。</p><p>默认情况下，所有节点都是 Coordinating Node，我们可以通过将<code>node.xxxx</code>的参数全部设置为 false，使其成为 Dedicated Coordinating Node（专职）。<strong>但是不能取消任何一个节点作为 Coordinating Node的功能！</strong></p><h3 id="4、Data-Node"><a class="header-anchor" href="#4、Data-Node">¶</a>4、Data Node</h3><p>可以保存数据的节点，叫做 Data Node。节点启动后，默认就是数据节点。可以设置 node.data:false 禁止其称为 Data Node。</p><p>Data Node 的职责是保存分片数据。在数据扩展上起到了至关重要的作用（由Master Node 决定如何把分片分发到数据节点上），通过增加数据节点，可以解决<strong>数据水平扩展</strong>和解决<strong>数据单点</strong>问题。</p><h3 id="5、Master-Node"><a class="header-anchor" href="#5、Master-Node">¶</a>5、Master Node</h3><p>Master Node 的职责是</p><ul><li>处理创建，删除索引等请求</li><li>决定分片被分配到哪个节点</li><li>维护并且更新 Cluster State</li></ul><p>Master Node 的最佳实践</p><p>Master 节点非常重要，在部署上需要考虑解决单点的问题。为一个集群设置多个 Master（Eligible、备选）节点，每个节点只承担 Master 的单一角色，如果 Master 节点发生故障，其他备选 Master 节点就可以顶上。</p><h4 id="Master-Eligible-Nodes"><a class="header-anchor" href="#Master-Eligible-Nodes">¶</a>Master Eligible Nodes</h4><p>一个集群，支持配置多个 Master Eligible 节点。这些节点可以在必要时（Master 节点出现故障，网络故障时）参与选主流程，称为 Master 节点。</p><p>每个节点启动后，默认就是一个 Master Eligible 节点，我们可以通过设置<code>node.master:flase</code>禁止。这样该节点可以加入集群，但是不会参与 Master 节点选主称为 Master 节点。</p><h4 id="选主流程"><a class="header-anchor" href="#选主流程">¶</a>选主流程</h4><ul><li>当集群内第一个 Master Eligible 节点启动的时候，它会将自己选举称为 Master 节点。</li><li>一旦发现被选中的主节点丢失，就会选举出新的 Master 节点，所有节点互相 ping 对方，Node Id 低的会被选举为 Master。</li></ul><h3 id="6、集群状态"><a class="header-anchor" href="#6、集群状态">¶</a>6、集群状态</h3><p>集群状态信息（Cluster State）维护了一个集群中必要的信息：</p><ul><li>所有的节点信息</li><li>所有的索引和其相关的 Mapping 与 Setting 信息</li><li>分片的路由信息</li></ul><p>在每个节点上都保存了集群的状态信息，但是只有 Master 节点才能修改集群的状态信息，并负责同步给其他节点，因为任意节点都能修改信息会导致 Cluster State 信息的不一致。</p><h3 id="7、脑裂问题-Split-Brain"><a class="header-anchor" href="#7、脑裂问题-Split-Brain">¶</a>7、脑裂问题(Split-Brain)</h3><p>这是分布式系统的经典网络问题。我们看下面示例：当出现网络问题，一个节点node1和其他节点 node2 和 node3 无法连接：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213534.png" alt="image-20200426154857050"></p><ul><li>Node2和 Node3会重新选举 Master</li><li>Node1自己还是作为 Master，组成一个集群，同时更新 Cluster State</li><li>导致2个 master 维护不同的 Cluster State，当网络恢复的时候，造成混乱，无法正确恢复集群状态。</li></ul><p>针对这个问题，我们需要限定一个选举条件，设置 quorum（仲裁），只有在 Master eligible 节点数大于 quorum 时才能进行选举：</p><ul><li>Quorum = (Master Eligible 节点总数 / 2) + 1。</li><li>当3个 master eligible 时，设置 <code>discovery.zen.minimum_master_nodes=2</code>，即可避免脑裂。（其他节点数量视情况而设定）</li></ul><p>从ES7.0开始，无需进行这个配置，它移除了 <code>minimum_master_nodes</code>参数，让 Elasticsearch 自己选择可以形成仲裁的节点。典型的主节点选举现在只需要很短的时间就可以完成。集群的伸缩变得更安全、更容易，并且可能造成丢失数据的系统配置选项更少了。节点更清除地记录它们的状态，有助于诊断为什么它们不能加入集群或为什么无法选举出主节点。</p><h3 id="8、通过-Cerebro-观察集群状态"><a class="header-anchor" href="#8、通过-Cerebro-观察集群状态">¶</a>8、通过 Cerebro 观察集群状态</h3><ol><li>通过命令行方式启动一个 ES 集群</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213540.png" alt="image-20200426160933084"></p><ol start="2"><li>启动 cerebro</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213546.png" alt="image-20200426161022552"></p><ol start="3"><li><p>进入 cerebro 界面，可以看到只有一个节点，索引、分片、文档等都是空的。该节点也是一个 master 节点</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213552.png" alt="image-20200426161110351"></p></li><li><p>通过 more-create index 创建索引</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213558.png" alt="image-20200426161221166"></p></li><li><p>创建一个 “test” 索引，有3个主分片，1个副本分片，点击创建，返回成功。但是我们留意到上面的状态条变成了黄色。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213612.png" alt="image-20200426161345627"></p></li><li><p>回到主界面，我们可以发现刚刚我们创建的 test 索引已经显示出来了，我们指定了三个主分片也分片到了 Master 节点上。但是我们指定的3份副本分片（每个主分片都有一个副本，所有是3个）是一个待分配状态，因为现在集群中只有一个节点，所以无法分配副本分片。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213619.png" alt="image-20200426161546194"></p></li><li><p>这时候我们再启动一个节点</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213627.png" alt="image-20200426161840329"></p></li><li><p>切换 cerebro 界面进行刷新。我们可以发现状态条恢复绿色。有一个节点加入了集群，副本分片也分配到了该节点上。这样，当另一个节点发生故障的时候，数据不会发生丢失。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213635.png" alt="image-20200426161936831"></p></li></ol><h3 id="9、配置节点类型"><a class="header-anchor" href="#9、配置节点类型">¶</a>9、配置节点类型</h3><p>一个节点默认情况下时一个 Master Eligible、Data And Ingest Node。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213641.png" alt="image-20200426162125107"></p><blockquote><p>所有的节点都是默认支持ingest的，任何节点都可以处理ingest请求，也可以创建一个专门的Ingest nodes。</p></blockquote><h3 id="10、相关阅读"><a class="header-anchor" href="#10、相关阅读">¶</a>10、相关阅读</h3><p><a href="https://www.elastic.co/cn/blog/a-new-era-for-cluster-coordination-in-elasticsearch" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/a-new-era-for-cluster-coordination-in-elasticsearch</a></p><h1>三、分片与集群的故障转移</h1><p>分片是 Elasticsearch 分布式集群存储的基石，其中分为主分片和副本分片。</p><h3 id="1、Primary-Shard"><a class="header-anchor" href="#1、Primary-Shard">¶</a>1、Primary Shard</h3><p>通过主分片，ES 将数据分布在所有Data Ndoe上，实现存储的水平扩展。主分片数在索引创建的时候指定，后续默认不能修改，如要修改，需要重建索引。</p><h3 id="2、Replica-Shard"><a class="header-anchor" href="#2、Replica-Shard">¶</a>2、Replica Shard</h3><p>副本分片可以提高数据的可用性。一旦主分片丢失，副本分片可以 Promote 成主分片。副本分片数可以动态调整。每个节点上都有完备的数据。如果不设置副本分片，一旦出现节点硬件故障，就有可能造成数据丢失。</p><p>副本分片由主分片同步。通过支持增加 Replica 个数，一定程度可以提高读取的吞吐量。</p><h3 id="3、分片数的设定"><a class="header-anchor" href="#3、分片数的设定">¶</a>3、分片数的设定</h3><p>我们需要谨慎规划一个索引的主分片和副本分片数：</p><p>如果主分片数过小，例如 ES 现在最新版本是默认创建一个主分片，如果一个索引只创建了一个主分片，如果该索引增长很快，集群无法通过增加节点实现对这个索引的数据扩展。</p><p>如果主分片数量设置过大，也会导致单个 Shard 容量很小，引发一个节点上有过多分片，影响性能。</p><p>如果副本分片数量设置过多，会降低集群整体的写入性能。</p><h3 id="4、集群故障转移过程"><a class="header-anchor" href="#4、集群故障转移过程">¶</a>4、集群故障转移过程</h3><p>上一节中我们也看到了一例子，我们启动了一个只有一个节点的集群，然后创建一个索引，指定其主分片数量为3，副本分片数量为1。会发现副本分片无法分配，集群状态为黄色。（<strong>另外，可以看到多个主分片是可以分布在同一个节点中的</strong>）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213649.png" alt="image-20200426172249108"></p><p>这时候我们可以通过增加一个数据节点，集群将Node1中的所有主分片备份到 Node2的副本分片之后集群状态恢复绿色。<strong>此时整个集群已经具备故障转移的能力。</strong></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213658.png" alt="image-20200426172322292"></p><p>此时我们再为集群增加一个数据节点，Master 节点会决定分片分配到哪个节点上。可以看到此时三个主分片都分布到了三个不同的节点上，并且三个节点互相备份其他节点的 Master 分片。（通过增加节点，提高集群的计算能力）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213705.png" alt="image-20200426172623206"></p><p>现在我们模拟一个故障过程：</p><p>节点1Master 节点意外出现故障，此时整个集群状态变红。集群重新选举 Master 节点，Node3上的 R0 副本分片提升为 P0 主分片进行数据接收，提升完毕之后集群状态变黄，P0 和 P1两个主分片的数据待备份，此时 Node3 负责备份 P1主分片为 R1，Node2负责备份 P0主分片为 R0，备份完毕之后集群状态变绿。</p><p>其中这里面有几个时间点需要注意：</p><ul><li>如果存在数据写入 P0 之后P0没来得及备份到 R0副本，Node1就挂掉了，这时候 R0是没有这些数据的，在 Node1恢复之前数据都无法获得，而当 Node1恢复重新加入集群之后，会从 <code>translog</code>中恢复没有写入的数据。</li><li>Node1挂掉之后，P0主分片还没选举出来之前应该路由到 P0的数据进来了，如果有创建index或者分片reallocation有可能会出错。（即集群是黄色变绿的过程，副本分片提升为主分片，不影响读写；如果集群在红变黄的过程，缺少主分片，会影响读写）</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213713.png" alt="image-20200426172744223"></p><h3 id="5、集群健康状态"><a class="header-anchor" href="#5、集群健康状态">¶</a>5、集群健康状态</h3><ul><li>Green：健康状态，所有的主分片和副本分片都可用</li><li>Yellow：亚健康，所有的主分片可用，部分副本分片不可用</li><li>Red：不健康状态，部分主分片不可用</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213719.png" alt="image-20200426173700072"></p><h1>四、文档分布式存储</h1><h3 id="1、文档存储在分片上"><a class="header-anchor" href="#1、文档存储在分片上">¶</a>1、文档存储在分片上</h3><p>文档会存储到具体的某个主分片和副本分片上，而存储到哪个分片上则需要一个映射算法来负责，而这个算法需要确保文档能均匀分布在所用分片上，充分利用硬件资源，避免部分机器控线，部分机器繁忙。</p><p>潜在的算法：</p><ul><li>随机、Round Robin（轮询）：当查询文档1，分片数很多，需要多次查询才可能查到文档1</li><li>维护文档到分片的映射关系，当文档数据量很大的时候，维护成本高</li><li>通过 hash 算法对文档的 hash key 进行实时计算，自动算出，需要到哪个分片上获取文档</li></ul><h3 id="2、ES-中的路由算法"><a class="header-anchor" href="#2、ES-中的路由算法">¶</a>2、ES 中的路由算法</h3><p>shard = hash(_routing) % number_of_primary_shards</p><ul><li>由 hash 算法确保文档均匀地 hash 到各个分片中</li><li>默认的_routing 值是文档 id</li><li>可以自行制定 routing 数值，例如用相同国家的商品，都分配到指定的 shard</li><li>设置 index settings 后，Primary shard数不能随意修改的根本愿意就是这里的文档 hash 到分片对主分片数进行了计算</li></ul><h3 id="3、更新一个文档的流程（没有副本分片）"><a class="header-anchor" href="#3、更新一个文档的流程（没有副本分片）">¶</a>3、更新一个文档的流程（没有副本分片）</h3><p>一个更新请求发送到 coordinating 节点，该节点对文档进行 hash 计算（根据集群状态），最终将这个请求路由到该文档对应的主分片节点上，主分片节点对文档进行删除操作之后再进行索引操作，然后返回成功到 coordinating 节点，然后 coordinating 节点响应用户。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213726.png" alt="image-20200426175142090"></p><h3 id="4、删除一个文档的流程（涉及副本分片）"><a class="header-anchor" href="#4、删除一个文档的流程（涉及副本分片）">¶</a>4、删除一个文档的流程（涉及副本分片）</h3><p>一个删除请求发送到 coordinating 节点，该节点对文档进行 hash 计算（根据集群状态），最终将这个请求路由到该文档对应的主分片节点上，主分片节点对文档进行删除操作之后，发送同步请求到副本分片节点进行删除（根据集群状态），副本分片删除索引之后返回成功到主分片节点，主分片节点收到响应之后返回成功到 coordinating 节点，然后 coordinating 节点响应用户。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213732.png" alt="image-20200426175344500"></p><h3 id="5、-为什么-ES-不支持一致性-Hash-算法动态增加主分片"><a class="header-anchor" href="#5、-为什么-ES-不支持一致性-Hash-算法动态增加主分片">¶</a>5、 为什么 ES 不支持一致性 Hash 算法动态增加主分片</h3><blockquote><p>Why doesn’t Elasticsearch support incremental resharding?<br>Going from N shards to N+1 shards, aka. incremental resharding, is indeed a feature that is supported by many key-value stores. Adding a new shard and pushing new data to this new shard only is not an option: this would likely be an indexing bottleneck, and figuring out which shard a document belongs to given its _id, which is necessary for get, delete and update requests, would become quite complex. This means that we need to rebalance existing data using a different hashing scheme.</p><p>The most common way that key-value stores do this efficiently is by using consistent hashing. Consistent hashing only requires 1/N-th of the keys to be relocated when growing the number of shards from N to N+1. However Elasticsearch’s unit of storage, shards, are Lucene indices. Because of their search-oriented data structure, taking a significant portion of a Lucene index, be it only 5% of documents, deleting them and indexing them on another shard typically comes with a much higher cost than with a key-value store. This cost is kept reasonable when growing the number of shards by a multiplicative factor as described in the above section: this allows Elasticsearch to perform the split locally, which in-turn allows to perform the split at the index level rather than reindexing documents that need to move, as well as using hard links for efficient file copying.</p><p>In the case of append-only data, it is possible to get more flexibility by creating a new index and pushing new data to it, while adding an alias that covers both the old and the new index for read operations. Assuming that the old and new indices have respectively M and N shards, this has no overhead compared to searching an index that would have M+N shards.</p></blockquote><h1>五、分片及生命周期</h1><h3 id="1、分片的内部原理"><a class="header-anchor" href="#1、分片的内部原理">¶</a>1、分片的内部原理</h3><p>ES 中的分片是最小的工作单元，也是一个 Lucene 的 Index。</p><p>我们从以下一些问题出发探索 ES 中的分片：</p><ol><li>为什么 ES 的搜索是近实时的（1秒后被搜到）</li><li>ES 如何保证在断点时数据也不会丢失</li><li>为什么删除文档，并不会立刻释放空间</li></ol><h3 id="2、倒排索引不可变性"><a class="header-anchor" href="#2、倒排索引不可变性">¶</a>2、倒排索引不可变性</h3><p>倒排索引采用 Immutable Design，一旦生成就不可更改。不可变性带来了如下好处：</p><ul><li>无需考虑并发写文件的问题，避免了锁机制带来的性能问题。（如果可以更新可能会出现并发更新的情况，为了保持数据一致性，往往需要加锁，而倒排索引都是直接删除然后新增，执行的是覆盖操作）</li><li>一旦写入内核的文件系统缓存，便留在那里。只要文件系统存有足够的空间，大部分请求就会直接请求内存，不会命中磁盘，提升了很大的性能</li><li>缓存容易生成和维护，数据可以被压缩</li></ul><p>不可变更性也带来了挑战：如果需要让一个新的文档可以被搜索，需要重建整个索引。</p><h3 id="3、Lucene-Index"><a class="header-anchor" href="#3、Lucene-Index">¶</a>3、Lucene Index</h3><p>在 Lucene 中，单个倒排索引文件被称为 Segment。<strong>Segment 是自包含的，不可变更的</strong>。当有新文档写入的时候，会生成新 Segment，查询时会同时查询所有 Segments，并且对结果汇总。多个 Segments 汇总在一起，称为 Lucene 的 Index，其对应的就是 ES 中的 Shard。</p><p>Lucene 中有一个文件，用来记录所有 Segments 信息，叫做 Commit Point。删除的文档信息，保存在&quot;.del&quot;文件中。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213739.png" alt="image-20200426221226567"></p><h3 id="4、什么是-Refresh"><a class="header-anchor" href="#4、什么是-Refresh">¶</a>4、什么是 Refresh</h3><p>在将一个新的文档写入到 ES 的时候，会将这个文档先写入到一个 Index Buffer 中，当到达一定的时候，会将 Index Buffer 写入 Segment ，然后清空 Buffer，从 Index Buffer写入信息到 Segment 的过程就叫做 Refresh。（Refresh 不执行 fsync 操作）</p><p>Refresh 频率默认是1秒发生一次，可通过 index.refresh_interval 配置。Refresh 后，数据就可以被搜索到了。这也是为什么 Elasticsearch 被称为近实时搜索。</p><p>如果系统有大量的数据写入，那就会产生很多的 Segment，当 Index Buffer 被占满时，也会触发 Refresh，这个 Buffer默认值是 JVM 的10%。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213746.png" alt="image-20200426221735235"></p><h3 id="5、什么是-Transaction-Log"><a class="header-anchor" href="#5、什么是-Transaction-Log">¶</a>5、什么是 Transaction Log</h3><p>上面介绍了一个新的文档的写入是先写入 ES 的 Index Buffer 中，在一定时候&quot;refresh&quot;到 Segments，而Segment 写入磁盘的过程相对耗时（特别时存在大量写入文档操作的时候），借助文件系统缓存，Refresh 时，先将 Segment 写入缓存以开放查询。</p><p>但是因为此时数据是写入到内存中的，为了保证此段时间数据不会丢失。所以ES 在 Index 一个新创建的文档的时候，除了将其写入到 Index Buffer 中，同时还写 Transaction Log（这是一个异步动作，不会阻塞文档写入 Index Buffer 以及 refresh）。高版本开始，Transaction Log 默认落盘。每个分片都有一个 Transaction Log。</p><p>在 ES Refresh 时，即使是Index Buffer 被清空，刷到 Segments 的缓存当中，Transaction log 不会清空。所以为什么 ES 节点产生&quot;断电&quot;的时候，它已经写入的数据是&quot;不会&quot;丢失的，就是因为它已经将 Transaction log 进行了落盘，在这个节点重启之后，会重新加载 Transaction Log 对数据进行 recover。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213752.png" alt="image-20200426221940337"></p><h3 id="6、什么是-FLush"><a class="header-anchor" href="#6、什么是-FLush">¶</a>6、什么是 FLush</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213758.png" alt="image-20200426222022291"></p><p>它可以理解为&quot;ES FLush&quot;和&quot;Lucene Commit&quot;两个过程：</p><ol><li>先执行一次 Refresh，Index Buffer 清空并且将数据刷到 Segments cache</li><li>调用 fsync，将缓存中的 Segments 写入磁盘</li><li>清空（删除）Transaction Log</li></ol><p>Flush 操作默认30分钟调用一次；另外当 Transaction Log满地时候也会触发调用（默认512MB）</p><h3 id="7、Merge"><a class="header-anchor" href="#7、Merge">¶</a>7、Merge</h3><p>Merge 操作指的是当 Segment 很多地时候，需要被定期合并，减少 Segments，并真正删除已经删除地文档。</p><p>ES 和 Lucene 会自动进行 Merge 操作，我们也可以通过 <code>POST my_index/_forcemerge</code>API 进行强制 merge。</p><h3 id="8、总结"><a class="header-anchor" href="#8、总结">¶</a>8、总结</h3><ol><li>客户端发起数据写入请求，对你写的这条数据根据_routing规则选择发给哪个Shard。<ul><li>确认Index Request中是否设置了使用哪个Filed的值作为路由参数</li><li>如果没有设置，则使用Mapping中的配置，</li><li>如果mapping中也没有配置，则使用_id作为路由参数，然后通过_routing的Hash值选择出Shard，最后从集群的Meta中找出出该Shard的Primary节点。</li></ul></li><li>写入请求到达Shard后，先把数据写入到内存（index buffer）中，同时会写入一条日志到translog日志文件中去。<ul><li>当写入请求到shard后，首先是写Lucene，其实就是创建索引。</li><li>索引创建好后并不是马上生成segment，这个时候索引数据还在缓存中，这里的缓存是lucene的缓存，并非Elasticsearch缓存，lucene缓存中的数据是不可被查询的。</li></ul></li><li>执行refresh操作：从内存buffer中将数据写入os cache(操作系统的内存)，产生一个segment file文件，buffer清空。<ul><li>写入os cache的同时，建立倒排索引，这时数据就可以供客户端进行访问了。</li><li>默认是每隔1秒refresh一次的，所以es是准实时的，因为写入的数据1秒之后才能被看到。</li><li>buffer内存占满的时候也会执行refresh操作，buffer默认值是JVM内存的10%。</li><li>通过es的restful api或者java api，手动执行一次refresh操作，就是手动将buffer中的数据刷入os cache中，让数据立马就可以被搜索到。</li><li>若要优化索引速度, 而不注重实时性, 可以降低刷新频率。</li></ul></li><li>translog会每隔5秒或者在一个变更请求完成之后，将translog从缓存刷入磁盘。<ul><li>translog是存储在os cache中，每个分片有一个，如果节点宕机会有5秒数据丢失，但是性能比较好，最多丢5秒的数据。。</li><li>可以将translog设置成每次写操作必须是直接fsync到磁盘，但是性能会差很多。</li><li>可以通过配置增加transLog刷磁盘的频率来增加数据可靠性，最小可配置100ms，但不建议这么做，因为这会对性能有非常大的影响。</li></ul></li><li>每30分钟或者当tanslog的大小达到512M时候，就会执行commit操作（flush操作），将os cache中所有的数据全以segment file的形式，持久到磁盘上去。<ul><li>第一步，就是将buffer中现有数据refresh到os cache中去。</li><li>清空buffer 然后强行将os cache中所有的数据全都一个一个的通过segmentfile的形式，持久到磁盘上去。</li><li>将commit point这个文件更新到磁盘中，每个Shard都有一个提交点(commit point), 其中保存了当前Shard成功写入磁盘的所有segment。</li><li>把translog文件删掉清空，再开一个空的translog文件。</li><li>flush参数设置：<ul><li>index.translog.flush_threshold_period:</li><li>index.translog.flush_threshold_size:</li><li># 控制每收到多少条数据后flush一次</li><li>index.translog.flush_threshold_ops:</li></ul></li></ul></li><li>Segment的merge操作：<ul><li>随着时间，磁盘上的segment越来越多，需要定期进行合并。</li><li>Es和Lucene 会自动进行merge操作，合并segment和删除已经删除的文档。</li><li>我们可以手动进行merge：POST index/_forcemerge。一般不需要，这是一个比较消耗资源的操作。</li></ul></li></ol><h1>六、剖析分布式查询及相关性算分</h1><p>Elasticsearch 的搜索，会分两个阶段进行：</p><ul><li>第一阶段-Query</li><li>第二阶段-Fetch</li></ul><p>即Query-Then-Fetch。</p><h3 id="1、Query-阶段"><a class="header-anchor" href="#1、Query-阶段">¶</a>1、Query 阶段</h3><ol><li>用户发出搜索请求到 ES 节点。节点收到请求后，会以Coordinating 节点的身份，在6个主副分片中随机选择3个分片，发送查询请求。</li><li>被选中的分片执行查询，执行排序。然后，每个分片都会查询 From + Size 个排序后的文档 id 和排序值给 Coordinating 节点。</li></ol><h3 id="2、Fetch-阶段"><a class="header-anchor" href="#2、Fetch-阶段">¶</a>2、Fetch 阶段</h3><ol><li>Coordinating Node 会将 Query 阶段，从每个分片获取的排序后的文档 id 列表，重新进行排序。再获取第 from 索引开始的 size 个文档进行返回。</li><li>以 multi get 请求的方式，到相应的分片获取详细的文档数据。</li></ol><h3 id="3、Query-Then-Fetch-潜在问题"><a class="header-anchor" href="#3、Query-Then-Fetch-潜在问题">¶</a>3、Query Then Fetch 潜在问题</h3><ul><li><p>性能问题</p><p>每个分片上需要查询的文档个数=from+size，最终协调节点需要处理：number_of_shard * (from+size)，如果查询的数量很大，协调节点就需要处理很多的文档。对于分布式搜索来说，搜索引擎在处理深度分页的时候对性能有很大的挑战。</p></li><li><p>相关性算分</p><p>每个分片都基于自己的分片上的数据进行相关度计算。这会导致打分偏离的情况。特别是数据量很少时。相关性算分在分片之间是相互独立。当文档总数很少的情况下，如果主分片大于1，主分片数越多，相关性算分会越不准。</p></li></ul><h3 id="4、解决算分不准的方法"><a class="header-anchor" href="#4、解决算分不准的方法">¶</a>4、解决算分不准的方法</h3><ol><li><p>数据量不大的时候，可以将主分片数设置为1，当数据量足够大的时候只要保证文档均匀分散在各个分片上，结果一般就不会出现偏差。</p></li><li><p>使用 DFS Query Then Fetch</p><p>在搜索的 URL中指定参数<code>_search?search_type=dfs_query_then_fetch</code>，到每个分片把各分片的词频和文档频率进行搜集，然后完整地进行一次相关性算分，这会耗费更多的 CPU 和内存，执行性能底下，一般不建议使用。</p></li></ol><h3 id="5、-算分不准演示例子"><a class="header-anchor" href="#5、-算分不准演示例子">¶</a>5、 算分不准演示例子</h3><ol><li><p>建立一个索引分别写入三个文档，不指定分片数，默认1个主分片，不会出现分布式算分不准的情况，我们调用一次对于 content 字段的 term 查询。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213810.png" alt="image-20200427063900495"></p><p>发现得到的结果确实是正确的，good 的算分是最高的</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213815.png" alt="image-20200427064056926"></p></li><li><p>设置主分片数为20，重新写入数据并指定它们的路由 key 为1、2、3将它们路由到不同的节点上</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213828.png" alt="image-20200427064225713"></p></li><li><p>然后再进行一次查询：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213840.png" alt="image-20200427064410756"></p></li><li><p>发现返回的3条结果的分值是一样的，&quot;good&quot;排在了最后。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213848.png" alt="image-20200427064450602"></p></li><li><p>我们对查询加上 explain 参数之后可以发现3个文档是位于不同的分片上的</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213859.png" alt="image-20200427064628146"></p></li><li><p>使用<code>_search?search_type=dfs_query_then_fetch</code>参数查询，算分又正确了</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213906.png" alt="image-20200427064758833"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213916.png" alt="image-20200427064808784"></p><h3 id="6、Kibana-测试请求"><a class="header-anchor" href="#6、Kibana-测试请求">¶</a>6、Kibana 测试请求</h3><pre><code>DELETE messagePUT message{  &quot;settings&quot;: {    &quot;number_of_shards&quot;: 20  }}GET messagePOST message/_doc?routing=1{  &quot;content&quot;:&quot;good&quot;}POST message/_doc?routing=2{  &quot;content&quot;:&quot;good morning&quot;}POST message/_doc?routing=3{  &quot;content&quot;:&quot;good morning everyone&quot;}POST message/_search{  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;match_all&quot;: {}  }}POST message/_search{  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;term&quot;: {      &quot;content&quot;: {        &quot;value&quot;: &quot;good&quot;      }    }  }}POST message/_search?search_type=dfs_query_then_fetch{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;content&quot;: {        &quot;value&quot;: &quot;good&quot;      }    }  }}</code></pre><h1>七、排序及 Doc Value&amp;Fielddata</h1><h3 id="1、排序"><a class="header-anchor" href="#1、排序">¶</a>1、排序</h3><p>Elasticsearch 默认采用相关性算分对结果进行降序排序，可以通过设定 sort 参数，自行设定排序。如果不指定_score 排序，算分为 null。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213932.png" alt="image-20200427065630653"></p><h3 id="2、多字段进行排序"><a class="header-anchor" href="#2、多字段进行排序">¶</a>2、多字段进行排序</h3><p>传入一个数组到 sort 属性，组合多个条件，优先考虑写在前面的字段的排序，支持混合相关性算分进行排序</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213942.png" alt="image-20200427065811847"></p><h3 id="3、Doc-Values-vs-Fielddata"><a class="header-anchor" href="#3、Doc-Values-vs-Fielddata">¶</a>3、Doc Values vs Fielddata</h3><h4 id="对-Text-类型字段排序"><a class="header-anchor" href="#对-Text-类型字段排序">¶</a>对 Text 类型字段排序</h4><p>当我们尝试对一个 text 类型的字段&quot;customer_full_name&quot;进行排序的时候，遇到一个报错告诉我们<code>fielddata</code>默认是关闭的，需要打开才能执行</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213949.png" alt="image-20200427070442266"></p><p>现在我们来了解一下排序的过程：</p><ul><li>排序是真毒 i字段原始内容进行的。此时倒排索引无法发挥作用，需要用到正排索引。通过文档 id 和字段快速得到字段原始内容。</li><li>Elasticsearch 对于排序有两种实现方法：Fielddata 和 DocValues（列式存储，对 Text 类型无效）</li></ul><p>Doc Values 现在的版本是默认打开的，它是随着倒排索引的创建一起创建（非文本类型都是结构化数据）放在磁盘上的；而 Fielddata 现在的版本默认是关闭的，因为对于文本类型数据的排序本来就是意义不大的，它是将文本数据加载到内存中进行排序的，如果排序的内容很多，就会导致内存占用很大。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213956.png" alt="image-20200427070654710"></p><h4 id="打开-Fieldata"><a class="header-anchor" href="#打开-Fieldata">¶</a>打开 Fieldata</h4><p>通过 Mapping 设置打开。修改设置后，即时生效，无需重建索引。</p><p>只支持对 Text 进行设定，其他字段类型不支持。打开后可以对 Text 字段进行排序。但是是对分词后的 term排序，所以，结果往往无法满足预期，不建议使用。</p><p><strong>部分情况下打开，满足一些聚合分析的特定需求</strong>。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214002.png" alt="image-20200427071221773"></p><h4 id="关闭-Doc-Values"><a class="header-anchor" href="#关闭-Doc-Values">¶</a>关闭 Doc Values</h4><p>通过 Mapping 设置关闭，可以增加索引的速度，减少磁盘空间。</p><p>如果关闭之后重新打开，需要重建索引。所以我们要再明确不需要做排序和聚合分析的时候才关闭。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214008.png" alt="image-20200427071516025"></p><h4 id="获取-Doc-Values-Fielddata-中存储的内容"><a class="header-anchor" href="#获取-Doc-Values-Fielddata-中存储的内容">¶</a>获取 Doc Values &amp; Fielddata 中存储的内容</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214015.png" alt="image-20200427072026009"></p><h1>八、分页与遍历：From、Size、Search After &amp; Scroll API</h1><h3 id="From-Size"><a class="header-anchor" href="#From-Size">¶</a>From &amp; Size</h3><p><strong>默认情况下，ES 查询按照相关度算分排序，返回前10条记录</strong>。这是一个比较标准的容易理解的分页方案，from 表示开始位置，size 表示期望获取文档的总数。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214024.png" alt="image-20200427085551796"></p><h4 id="分布式系统中深度分页的问题"><a class="header-anchor" href="#分布式系统中深度分页的问题">¶</a>分布式系统中深度分页的问题</h4><p>ES 天生就是分布式的。查询信息的时候数据分别保存在多个分片，多台机器上，ES 天生就需要满足排序的需要（按照相关性算分）。</p><p>如果一个查询是分页参数from=990、size=10。ES 会在每个分片上先都获取1000个文档。然后，通过 Coordinating Node 聚合所有结果。最后再通过排序选取出前1000个文档，然后取第990位开始的后10个文档进行返回。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214030.png" alt="image-20200427085922577"></p><p>当页数越深的时候，占用内存就越多。为了避免深度分页带来的内存开销。ES 有一个设定，默认限定到10000 个(from + size)文档。另外，我们可以通过<code>index.max_result_window</code>来调整这个数值。</p><p>下面我们在图一图二分别尝试设置 from 和 size 到比较大的数量，让 from+size 超过10000，就会获得图三的报错。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214036.png" alt="image-20200427090103760"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214043.png" alt="image-20200427090144141"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214048.png" alt="image-20200427090123802"></p><p>如果我们设置在10000的范围之内，可以返回结果，但是需要消耗比较长的时间，本示例消耗了2-3秒。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214100.png" alt="image-20200427090305345"></p><h3 id="Search-After"><a class="header-anchor" href="#Search-After">¶</a>Search After</h3><p>我们可以使用 Search After 来避免深度分页带来的性能问题，这个 API 表示实时获取下一页文档信息。但是它在功能上有以下的限制：</p><ul><li>不支持指定页数（设定 From 值）</li><li>只能往下翻</li></ul><p>调用 Search After：</p><ul><li>第一步搜索需要指定 sort，并且保证值是唯一的（可以通过加入_id 保证唯一性）</li><li>然后后面的查询就使用上一次返回的文档的 sort 值进行查询</li></ul><p>Demo：</p><ol><li><p>写入数据</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214106.png" alt="image-20200427090802728"></p></li><li><p>第一次查询：指定 size 是1，表示每次查询只返回1条记录，然后我们是根据 age 来排序并分页的，但是为了保证排序的唯一性，我们加入了_id 字段。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214113.png" alt="image-20200427090843029"></p><p>执行之后返回以下数据，包含了一个文档，同时也返回了一个 sort 值（返回文档中按照指定排序之后的最后一个文档的 sort 字段的值）给我们用于下一次查询。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214119.png" alt="image-20200427091124426"></p></li><li><p>将第一次获取到的 sort 值传入到 search_after 属性中</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214126.png" alt="image-20200427091328864"></p><p>执行，即可得到第2次结果，这次执行又返回了一个 sort 值，我们通过不断地将上一次查询返回的 sort 值放到查询的 search_after 属性中进行下一次查询即可达到一个不断分页的效果，直到达到了最后 size 条数据，则没有返回一个没有文档数据的空数组。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214132.png" alt="image-20200427091410238"></p><h4 id="Search-After-如何解决深度分页问题"><a class="header-anchor" href="#Search-After-如何解决深度分页问题">¶</a>Search After 如何解决深度分页问题</h4><p>每个 ES 分片通过指定唯一排序值定位到大于等于唯一排序值之后的 size 个文档进行返回。</p><p>这样的话在 from 比较大，size 比较小的深度分页问题上，例如当查询from=990，size=10 的时候，原本每个分片都会返回 i000个文档，现在只会返回10个文档给 coordinating 节点进行处理。（但是如果是 size 非常大的深度分页，还是有一定的问题）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214138.png" alt="image-20200427093011710"></p><h3 id="Scroll-API"><a class="header-anchor" href="#Scroll-API">¶</a>Scroll API</h3><p>ES 还提供了一个 Scoll API，它会基于当前的查询创建一个快照，用户可以对这个快照进行遍历操作。<strong>但是如果创建快照之后有新的数据写入到该索引，这个快照对于这个数据是无感知的，也就是说在遍历快照的时候是查询不到这个数据的</strong>。</p><p>我们看一下下面的 Demo，在第一次查询的时候我们执行一个 search 操作，并通过参数<code>scroll=5m</code>表示基于当前的查询结果创建一个5分钟的快照。执行之后可以看到返回结果中包含了一个 _scroll_id，表示我们下一次遍历的指针。( 同时下面也返回了查询的结果，这里截图没有截出来)</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214143.png" alt="image-20200427093505612"></p><p>然后我们将这个_scroll_id 拿出来放到下面的 _search/ scroll api进行进行遍历操作，可以看到，我们拿到了当前遍历的结果，并且返回了下一次遍历要用到的 _scroll_id，以此类推，我们就可以实现对一个快照进行遍历的操作。（另外，scroll api 应该还有其他的一些配置项，带研究）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214150.png" alt="image-20200427093906382"></p><h3 id="不同的搜索类型和使用场景"><a class="header-anchor" href="#不同的搜索类型和使用场景">¶</a>不同的搜索类型和使用场景</h3><ul><li>Regular：需要实时获取顶部的部分文档。例如查询最新的订单</li><li>Scroll：需要全部文档，例如导出全部数据</li><li>Pagination：From 和 Size；如果需要深度分页，则选用 Search API。（ 深度分页，并不是搜索引擎所擅长的。google也一样。应该结合其他存储介质例如关系型数据库和es一起使用。es用来实现全文检索）</li></ul><h1>九、 处理读写操作</h1><h3 id="并发控制的必要性"><a class="header-anchor" href="#并发控制的必要性">¶</a>并发控制的必要性</h3><p>举个例子，当有两个 Web 应用分别销售了一个商品，这时候需要进行扣减库存的操作，那么它们同时从 ES 中获取了一个商品的库存为100，然后分别做了库存扣减1的动作，然后 WEB1更新 ES 中该商品库存为99，然后 WEB2又将 ES 中该商品库存进行更新为99。那么这时候这个库存就不对了。它实际上应该是98，这就是修改丢失的并发问题。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214205.png" alt="image-20200427135812392"></p><p>处理这种问题有两种方式：</p><ul><li><p>悲观并发控制</p><p>假定有变更冲突的可能。会对资源加锁，防止冲突，例如数据库行锁。</p></li></ul><ul><li><p>乐观并发控制</p><p>假定冲突是不会发生的，不会阻塞正在尝试的操作。如果数据在读写中被修改，更新将会失败。应用程序决定如何解决冲突，例如重试更新，使用新的数据，或者将错误报告给用户。</p></li></ul><p>而 ES 采用的是乐观并发控制。</p><h3 id="ES-的乐观并发控制"><a class="header-anchor" href="#ES-的乐观并发控制">¶</a>ES 的乐观并发控制</h3><p>ES 中的文档是不可变更的。如果你更新一个文档，会将该文档标记为删除，同时增加一个全新的文档。同时文档的 version 字段加1。</p><p>ES 提供的乐观并发控制分为内部版本控制和外部版本控制：</p><ul><li><p>内部版本控制：使用 _seq_no 和 _primary_term 两个字段</p><p>在 ES 的早期版本中，它是可以通过 _version 属性来实现内部的版本控制的，但是在新版本中使用 _version 来进行并发控制已经被废除了。现在我们来看一个例子。</p><p>我们先建立一个 products 的索引然后写入一个 id为1的文档。可以看到写入数据成功，ES 给我们返回的 _version 是1，另外还有 _seq_no 和 _primary_term 两个属性值为0和1。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214213.png" alt="image-20200427140658437"></p><p>现在我们尝试对该文档进行更新，并使用 ES 的乐观版本控制，我们在请求的时候带上我们在修改数据之前通过查询得到的 _seq_no 和 _primary_term （0和1）。可以看到更新成功，返回的版本号 _version 被更新为2。另外 _seq_no 被更新为1， _primary_term 不变，还是1（这个 _primary_term 个人猜测应该是一个文档的唯一标识，这里应该就是 _id）。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214235.png" alt="image-20200427141023663"></p><p>然后我们尝试对该请求参数再发起一次请求，ES 给我们返回了版本冲突错误：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214241.png" alt="image-20200427141405280"></p></li></ul><ul><li><p>外部版本控制：使用 _version 和 _version_type 属性</p><p>如果我们是使用数据库作为主要的数据存储介质，ES 仅仅是作为一个搜索引擎将数据同步到其中，那么我们可以设计在数据库中存储一个版本字段，然后将这个字段的值在 ES 中进行版本控制。我们看下面例子，在请求将 id 为1的文档进行更新的时候，我们对两个请求参数进行了设置： _version_type 设置为 external，这时候 ES 就允许我们对 _version 进行设值，我们可以将我们在数据库中设计的那个版本控制的字段的值设置到该字段，进行更新操作。可以看到更新成功，商品的版本号变成了我们写入的那个。（因为 _seq_no 不能被我们外部修改，所以区分了内部版本控制和外部版本控制）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214253.png" alt="image-20200427141827385"></p><p>此时我们再将该请求发送到 ES 的时候，将会收到版本冲突报错</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221214259.png" alt="image-20200427142143538"></p></li></ul><h3 id="其他注意"><a class="header-anchor" href="#其他注意">¶</a>其他注意</h3><p>可以看到 ES 为我们提供了乐观版本控制的方式来解决&quot;修改丢失&quot;（或者叫修改覆盖）的方法。但是它并没有提供相关的传统关系型数据库中的事务解决方案（四大隔离级别，解决脏读、幻读、不可重复读的问题），所以如果我们对于事务有很强的要求，那么必须使用数据库进行数据更新的交互，在一个事务最终完成之后得到了一个当前事务的结果之后再使用以上的 ES 乐观版本控制进行 ES 的同步。</p>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>011_beats</title>
      <link href="/2020/12/22/elasticsearch/011-beats/"/>
      <url>/2020/12/22/elasticsearch/011-beats/</url>
      
        <content type="html"><![CDATA[<h1>Beats</h1><p>Beats 是一个基于 Go 开发的 Light weight data shippers（也可以自己基于 Elastic 公司提供的规范开发自定义的 beat）：</p><ul><li>以收集数据为主，收集到数据之后写入到 ES 然后使用 Kibana 进行图形化界面的展示和数据分析（Dashboard）</li><li>支持与 Logstash 或 ES 无缝集成</li></ul><p>Elastic 公司开发了很多开箱即用的 beats：</p><ul><li>filebeat</li><li>metricbeat</li><li>packetbeat</li><li>winlogbeat</li><li>auditbeat</li><li>heartbeat</li><li>functionbeat</li></ul><p>全品类、轻量级、开箱即用、可插拨、可扩展、可视化</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223611.png" alt="image-20200503171457303"></p><h3 id="Metricbeat"><a class="header-anchor" href="#Metricbeat">¶</a><a href="https://www.elastic.co/guide/en/beats/metricbeat/7.1/index.html" target="_blank" rel="noopener">Metricbeat</a></h3><p>用来定期搜集操作系统，软件的指标数据，存储到 Elasticsearch 当中，可以通过 Kibana 进行实时的数据分析。</p><blockquote><p>metric 和 logs 类型数据的对比：</p><ul><li>metric：可聚合的数据，定期搜集</li><li>logs：文本数据，随机搜集</li></ul></blockquote><p>在 Metricbeat 中有两个重要概念：</p><ul><li><p>Module：需要搜集相关指标的对象，它可以是一个操作系统、数据库、软件应用等等，ES 内置了很多开箱即用的 Modules</p></li><li><p>Metricset：具体的指标集合，一个 Module 可以包含多个 metricset。（metricset 以减少调用次数为原则进行划分，不同的 metrcset 可以设置不同的抓取数据的 interval）</p><p>下面是 system module 的 mertric set</p><ul><li>core</li><li>cpu</li><li>disk io</li><li>filesystem</li><li>load</li><li>memory</li></ul></li></ul><p>Metricbeat 还提供了大量的开箱即用的 module，可以到<a href="https://www.elastic.co/guide/en/beats/metricbeat/7.1/index.html" target="_blank" rel="noopener">官网</a>进行查看，也可以通过执行<code>metricbeat module list</code>查看，通过执行<code>metricbeat module enable ${module_name}</code>开启相关的module。</p><h4 id="Demo"><a class="header-anchor" href="#Demo">¶</a>Demo</h4><ol><li><p><a href="https://www.elastic.co/guide/en/beats/metricbeat/7.1/metricbeat-installation.html" target="_blank" rel="noopener">下载安装 metricbeat</a>。</p></li><li><p>解压下载好的压缩包，然后分配权限</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z elasticsearch]# tar -zxvf ./metricbeat-7.1.0-linux-x86_64.tar.gz[root@izwz920kp0myp15p982vp4z elasticsearch]# cd metricbeat-7.1.0-linux-x86_64[root@izwz920kp0myp15p982vp4z metricbeat-7.1.0-linux-x86_64]# chmod go-w ./metricbeat.yml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>我们现在看一下 Kibana 的 Dashboard 界面，基本没有什么数据</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223619.png" alt="image-20200503180059695"></p></li><li><p>查看 metricbeat 的 modules，可以看到默认启用(enabled)了<code>system</code>module，即监控操作系统的 module。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z metricbeat-7.1.0-linux-x86_64]# ./metricbeat modules listEnabled:systemDisabled:aerospikeapacheawscephcouchbasecouchdbdockerdropwizardelasticsearchenvoyproxyetcdgolanggraphitehaproxyhttpjolokiakafkakibanakuberneteskvmlogstashmemcachedmongodbmssqlmuninmysqlnatsnginxphp_fpmpostgresqlprometheusrabbitmqredistraefikuwsgivspherewindowszookeeper<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>enable kibana 和 elasticsearch，然后设置 Kibana 的 dashboard</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z metricbeat-7.1.0-linux-x86_64]# ./metricbeat modules enable kibanaEnabled kibana[root@izwz920kp0myp15p982vp4z metricbeat-7.1.0-linux-x86_64]# ./metricbeat modules enable elasticsearchEnabled elasticsearch[root@izwz920kp0myp15p982vp4z metricbeat-7.1.0-linux-x86_64]# ./metricbeat setup --dashboardsLoading dashboards (Kibana must be running and reachable)Loaded dashboards<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>此时再查看 kibana 的 dashboard 界面，发现加载了很多新的数据进来</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223625.png" alt="image-20200503190119322"></p></li><li><p>我们搜索 system，查看以下操作系统的指标</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223632.png" alt="image-20200503190605880"></p><p>进来之后可以看到有各项系统指标的聚合模块，但是可能是因为一些配置项没有配置或者哪些的权限没有配置的原因，没有数据显示，这个后续再看。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223637.png" alt="image-20200503190959959"></p></li><li><p>另外如果我们有安转 mysql，需要监控 mysql 的一些指标，也可以启动 mysql 的 module。并到配置文件<code>./modules.d/mysql.yml</code>中配置 mysql 的一些连接信息。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z metricbeat-7.1.0-linux-x86_64]# ./metricbeat modules enable mysqlEnabled mysql[root@izwz920kp0myp15p982vp4z metricbeat-7.1.0-linux-x86_64]# vim ./modules.d/mysql.yml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><blockquote><p>所有一些其他模块的连接或者一些配置文件都在 <code>${beat_home}/modules.d/xxx.yml</code>中进行配置</p></blockquote><h3 id="Packetbeat-https-www-elastic-co-guide-en-beats-packetbeat-7-1-packetbeat-getting-started-html"><a class="header-anchor" href="#Packetbeat-https-www-elastic-co-guide-en-beats-packetbeat-7-1-packetbeat-getting-started-html">¶</a>[Packetbeat](<a href="https://www.elastic.co/guide/en/beats/packetbeat/7.1/packetbeat-getting-" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/packetbeat/7.1/packetbeat-getting-</a> started.html)</h3><p>实时网络数据分析，监控应用服务器之间的网络流量。 常见的抓包工具有：Tcpdump、wireshark等。这些工具很多都是基于 Pcap来开发的，而 Pcap 底层是依赖于 libpcap（跨平台、基于内存映射嗅探、高性能），packetbeat 也是基于 pcap 来开发。</p><p>packetbeat 支持的协议：ICMP、DHCP、DNS、HTTP、Cassandra、Mysql、PostgresSQL、Redis、MongoDB、Memcache、TLS 等。同时它还有基于 network flos 的方式抓取记录网络流量数据，不涉及协议解析。</p><h4 id="Demo-v2"><a class="header-anchor" href="#Demo-v2">¶</a>Demo</h4><ol><li>安装配置</li><li>配置 Kibana Dashboard：<code>packetbeat setup --dashboards</code></li><li>运行 packetbeat</li><li>查看 dashboard</li></ol><h3 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h3><p>各个 beats 的操作都是大同小异的，它们收集各种各样的指标数据根据配置可以存储到 logstash 和 Elasticsearch 中，我们上面的 Metricbeat 的例子启用了 Kibana 和 Elasticsearch 的 module，metricbeat 会将收集到的数据和 logstash 一样转换成一个 event 的结构：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223646.png" alt="image-20200503192752900"></p><p>然后写入到 ES（我们没有配置 Kibana 和 ES 的连接信息，使用的是 beats 的默认配置，即 Kibana 和 Elasticsearch 都是取 localhost:5601和 localhost:9200 去通信的）。</p><p>另外以上例子中我们对于 beat 的一些特殊配置，我们也没有进行配置，例如 metricbeat 各个 modules的一些配置（mysql 连接信息等等）也没有配置，等到之后真正有这个需求再具体去看文档吧。</p><h3 id="相关阅读"><a class="header-anchor" href="#相关阅读">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/guide/en/beats/metricbeat/7.1/index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/metricbeat/7.1/index.html</a></p><p>[<a href="https://www.elastic.co/guide/en/beats/packetbeat/7.1/packetbeat-getting-" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/packetbeat/7.1/packetbeat-getting-</a> started.html](<a href="https://www.elastic.co/guide/en/beats/packetbeat/7.1/packetbeat-getting-" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/packetbeat/7.1/packetbeat-getting-</a> started.html)</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>003_安装上手</title>
      <link href="/2020/12/22/elasticsearch/003-an-zhuang-shang-shou/"/>
      <url>/2020/12/22/elasticsearch/003-an-zhuang-shang-shou/</url>
      
        <content type="html"><![CDATA[<h1>Elasticsearch 的安装与简单配置</h1><h2 id="依赖环境"><a class="header-anchor" href="#依赖环境">¶</a>依赖环境</h2><ul><li>运行 ES 需要安装并配置 Java<ul><li>配置$JAVA_HOME</li></ul></li><li>各个版本对 Java 的依赖<ul><li>ES5需要 Java8以上的版本</li><li>ES 从6.5开始支持 Java11</li><li><a href="http://www.elastic.co/support/matrix#matrix_jvm" target="_blank" rel="noopener">http://www.elastic.co/support/matrix#matrix_jvm</a></li><li>7.0开始，内置了 Java 环境</li></ul></li></ul><h2 id="下载安装"><a class="header-anchor" href="#下载安装">¶</a>下载安装</h2><h3 id="1、下载"><a class="header-anchor" href="#1、下载">¶</a>1、下载</h3><p>我们可以到Elasticsearch 的官方<a href="https://www.elastic.co/cn/downloads?elektra=home&amp;amp&amp;storm=banner" target="_blank" rel="noopener">下载地址</a>下载需要的软件，也可以通过包管理器安装的方式或者 docker 容器启动：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210710.png" alt="image-20200423173101180"></p><h3 id="2、-安装"><a class="header-anchor" href="#2、-安装">¶</a>2、 安装</h3><p>这里我选择下载 linux 版本然后上传到 aliyun 服务器</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z ~]# cd /usr/local/software/elasticsearch/[root@izwz920kp0myp15p982vp4z elasticsearch]# ll总用量 534476-rw-r--r-- 1 root root 296477546 4月  23 17:00 elasticsearch-7.6.2-linux-x86_64.tar.gz-rw-r--r-- 1 root root 249555386 3月  31 23:38 kibana-7.6.2-linux-x86_64.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>解压到当前目录</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z elasticsearch]# tar -zxvf elasticsearch-7.6.2-linux-x86_64.tar.gz[root@izwz920kp0myp15p982vp4z elasticsearch]# cd elasticsearch-7.6.2[root@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]# ll总用量 564drwxr-xr-x  2 root root   4096 3月  26 14:36 bindrwxr-xr-x  2 root root   4096 3月  26 14:36 configdrwxr-xr-x  9 root root   4096 3月  26 14:36 jdkdrwxr-xr-x  3 root root   4096 3月  26 14:36 lib-rw-r--r--  1 root root  13675 3月  26 14:28 LICENSE.txtdrwxr-xr-x  2 root root   4096 3月  26 14:36 logsdrwxr-xr-x 38 root root   4096 3月  26 14:37 modules-rw-r--r--  1 root root 523209 3月  26 14:36 NOTICE.txtdrwxr-xr-x  2 root root   4096 3月  26 14:36 plugins-rw-r--r--  1 root root   8164 3月  26 14:28 README.asciidoc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>进入解压后的 ES 目录，可以看到以下目录结构：</p><table><thead><tr><th>目录</th><th>相关文件</th><th>描述</th></tr></thead><tbody><tr><td>bin</td><td></td><td>所有运行的脚本文件，包括启动 ES，安装插件。运行统计数据等</td></tr><tr><td>config</td><td>如 elasticsearch.yml 等</td><td>集群配置文件，user，role based 相关配置</td></tr><tr><td>JDK</td><td></td><td>Java 运行环境。从7.0开始 ES 自动集成 JDK 到安装文件中</td></tr><tr><td>data</td><td>path.data</td><td>包含了 ES 所有的相关数据文件</td></tr><tr><td>lib</td><td></td><td>Java 类库</td></tr><tr><td>logs</td><td>path.log</td><td>日志文件</td></tr><tr><td>modules</td><td></td><td>包含所有 ES 模块</td></tr><tr><td>plugins</td><td></td><td>包含所有已安装插件</td></tr><tr><td></td><td></td><td></td></tr></tbody></table><h3 id="3、JVM-配置"><a class="header-anchor" href="#3、JVM-配置">¶</a>3、JVM 配置</h3><ul><li>修改 JVM，在 option/jvm.options<ul><li>7.1 下载的默认设置时1GB</li></ul></li><li>配置的建议<ul><li>Xmx 和 Xms设置成一样</li><li>Xmx 不要超过机器内存的50%</li><li>不要超过30GB - <a href="https://www.elastic.co/blog/a-heap-of-touble" target="_blank" rel="noopener">https://www.elastic.co/blog/a-heap-of-touble</a></li></ul></li></ul><h3 id="4、尝试启动-ES"><a class="header-anchor" href="#4、尝试启动-ES">¶</a>4、尝试启动 ES</h3><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]# bin/elasticsearchOpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.[2020-04-23T17:47:45,074][ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [izwz920kp0myp15p982vp4z] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.lang.RuntimeException: can not run elasticsearch as rootat ... ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>启动失败。看到 es 不能以 root 用户启动。</p><h3 id="5、创建新用户"><a class="header-anchor" href="#5、创建新用户">¶</a>5、创建新用户</h3><p>创建用户<code>elasticsearch</code>输入，新的密码<code>zhonghongpeng</code>并赋予权限</p><pre class="line-numbers language-language-sh"><code class="language-language-sh">[root@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]# adduser elasticsearch[root@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]# passwd elasticsearch更改用户 elasticsearch 的密码 。新的 密码：重新输入新的 密码：passwd：所有的身份验证令牌已经成功更新。[root@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6、用户内存过小问题"><a class="header-anchor" href="#6、用户内存过小问题">¶</a>6、用户内存过小问题</h3><p>切换用户再次启动，还是遇到问题<code>max virtual memory areas vm.max_map_count [65530] is too low</code>用户虚拟内存太小</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]# su elasticsearch[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ bin/elasticsearchOpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.[2020-04-23T17:53:32,277][INFO ][o.e.e.NodeEnvironment    ] [izwz920kp0myp15p982vp4z] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.3gb], net total_space [39.2gb], types [rootfs]... ... ERROR: [1] bootstrap checks failed[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]... ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>再次切换回 root 用户，并执行以下执行进行修改，然后编辑<code>/etc/sysctl.conf</code>在最后一行添加<code>vm.max_map_count = 262144</code>保证永久生效</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[elasticsearch@izwz920kp0myp15p982vp4z config]$ su - root密码：上一次登录：四 4月 23 17:55:21 CST 2020从 219.137.74.3pts/0 上[root@izwz920kp0myp15p982vp4z ~]# sysctl -a|grep vm.max_map_countvm.max_map_count = 65530[root@izwz920kp0myp15p982vp4z ~]# sysctl -w vm.max_map_count=262144vm.max_map_count = 262144[root@izwz920kp0myp15p982vp4z ~]# sysctl -a|grep vm.max_map_countvm.max_map_count = 262144[root@izwz920kp0myp15p982vp4z ~]# vi /etc/sysctl.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>切换回elasticsearch用户再次启动，启动成功！</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z ~]# su elasticsearch[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch]$ cd /usr/local/software/elasticsearch/elasticsearch-7.6.2[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ ./bin/elasticsearchOpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.[2020-04-23T18:32:39,304][INFO ][o.e.e.NodeEnvironment    ] [izwz920kp0myp15p982vp4z] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.3gb], net total_space [39.2gb], types [rootfs][2020-04-23T18:32:39,309][INFO ][o.e.e.NodeEnvironment    ] [izwz920kp0myp15p982vp4z] heap size [1007.3mb], compressed ordinary object pointers [true][2020-04-23T18:32:39,461][INFO ][o.e.n.Node               ] [izwz920kp0myp15p982vp4z] node name [izwz920kp0myp15p982vp4z], node ID [AZUJJ0XhR0qwGYFxZ0O0xQ], cluster name [elasticsearch][2020-04-23T18:32:39,462][INFO ][o.e.n.Node               ] [izwz920kp0myp15p982vp4z] version[7.6.2], pid[17383], build[default/tar/ef48eb35cf30adf4db14086e8aabd07ef6fb113f/2020-03-26T06:34:37.794943Z], OS[Linux/3.10.0-693.2.2.el7.x86_64/amd64], JVM[AdoptOpenJDK/OpenJDK 64-Bit Server VM/13.0.2/13.0.2+8][2020-04-23T18:32:39,462][INFO ][o.e.n.Node               ] [izwz920kp0myp15p982vp4z] JVM home [/usr/local/software/elasticsearch/elasticsearch-7.6.2/jdk][2020-04-23T18:32:39,463][INFO ][o.e.n.Node               ] [izwz920kp0myp15p982vp4z] JVM arguments [-Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.locale.providers=COMPAT, -Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Djava.io.tmpdir=/tmp/elasticsearch-10878863762573310172, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -XX:MaxDirectMemorySize=536870912, -Des.path.home=/usr/local/software/elasticsearch/elasticsearch-7.6.2, -Des.path.conf=/usr/local/software/elasticsearch/elasticsearch-7.6.2/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 ssh 终端中测试连接，成功！</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z config]# curl localhost:9200{  "name" : "izwz920kp0myp15p982vp4z",  "cluster_name" : "elasticsearch",  "cluster_uuid" : "0lHe6Dh7TOKSTX2Jy6PDSw",  "version" : {    "number" : "7.6.2",    "build_flavor" : "default",    "build_type" : "tar",    "build_hash" : "ef48eb35cf30adf4db14086e8aabd07ef6fb113f",    "build_date" : "2020-03-26T06:34:37.794943Z",    "build_snapshot" : false,    "lucene_version" : "8.4.0",    "minimum_wire_compatibility_version" : "6.8.0",    "minimum_index_compatibility_version" : "6.0.0-beta1"  },  "tagline" : "You Know, for Search"}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="7、默认监听接口问题"><a class="header-anchor" href="#7、默认监听接口问题">¶</a>7、默认监听接口问题</h3><p>但是在本地电脑的浏览器中访问不成功：（<a href="http://myecs.com" target="_blank" rel="noopener">myecs.com</a> 配置本地 hosts 指向了 aliyun ecs ip）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210719.png" alt="image-20200423190146363"></p><p>在本地电脑直接telnet 也连不上，一直无响应：</p><pre><code>zhonghongpeng@bogon ~ % telnet 120.24.80.237 9200</code></pre><p>看了一下 ES 输出的日志，发现它在监听的接口是127.0.0.1:9200</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[2020-04-23T18:23:33,314][INFO ][o.e.t.TransportService   ] [izwz920kp0myp15p982vp4z] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改配置文件./config/elasticsearch.yml</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">network.host: 0.0.0.0discovery.seed_hosts: ["0.0.0.0", "[::1]"]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>再次启动，绑定接口为0.0.0.0:9200：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[2020-04-23T18:23:33,314][INFO ][o.e.t.TransportService   ] [izwz920kp0myp15p982vp4z] publish_address {172.18.93.184:9200}, bound_addresses {0.0.0.0:9200}<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>回到本地电脑浏览器测试，成功！</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210726.png" alt="image-20200423183357949"></p><h2 id="插件安装"><a class="header-anchor" href="#插件安装">¶</a>插件安装</h2><p><code>elasticsearch-plugin list</code>命令可以查看插件列表</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ bin/elasticsearch-plugin list[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><code>install</code>命令可以安装插件，我们来安装一个国际化的分词插件<code>analysis-icu</code></p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ ./bin/elasticsearch-plugin install analysis-icu-> Installing analysis-icu-> Downloading analysis-icu from elastic[=================================================] 100%-> Installed analysis-icu[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ ./bin/elasticsearch-plugin listanalysis-icu<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过浏览器输入<code>http://myecs.com:9200/_cat/plugins</code>也可以显示插件列表：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210732.png" alt="image-20200423192829097"></p><p>通过插件机制用户可以自定义拓展其功能：</p><ul><li>Discovery Plugin</li><li>Analysis Plugin</li><li>Security Plugin</li><li>Management Plugin</li><li>Ingest Plugin</li><li>Mapper Plugin</li><li>Backup Plugin</li></ul><p><a href="Https://elastic.co/guide/en/elasticsearch/plugins/current/intro.html" target="_blank" rel="noopener">Https://elastic.co/guide/en/elasticsearch/plugins/current/intro.html</a></p><h2 id="启动集群"><a class="header-anchor" href="#启动集群">¶</a>启动集群</h2><p><code>elasticsearch -E node.name=节点名称 -E cluster.name=集群名称 -E path.data=节点数据文件名称 -d</code>，其中<code>-E</code>通过 name=value 形式配置参数，<code>-d</code>后台启动，启动之前我们需要配置<code>./config/elasticsearch.yml</code>以下配置包含我们需要启动的节点名称</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">cluster.initial_master_nodes: ["node1", "node2", "node3"]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后启动</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">bin/elasticsearch -E node.name=node1 -E cluster.name=john -E path.data=node1_data -dbin/elasticsearch -E node.name=node2 -E cluster.name=john -E path.data=node2_data -dbin/elasticsearch -E node.name=node3 -E cluster.name=john -E path.data=node3_data -d<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>浏览器访问<code>http://myecs.com:9200/_cat/nodes</code>，可以看到我们启动集群了</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210740.png" alt="image-20200423194555267"></p><h1>Kibana 的安装</h1><h2 id="安装"><a class="header-anchor" href="#安装">¶</a>安装</h2><p>同 Elasticsearch 下载好安装文件，并解压（注意，如果用 root 用户进行解压，需要对解压之后的文件夹进行 chmod 授权，或者直接用 elasticsearch 用户进行解压，不然elasticsearch 用户启动 kibana 的时候就会因为 kibana需要写入一些文件没有权限导致启动失败）</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z elasticsearch]# tar -zxvf kibana-7.6.2-linux-x86_64.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改配置<code>${kibana_home}/config/kibana.yml</code>：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">server.host: "0.0.0.0"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>如果需要汉化需要配置<code>i18n.locale: &quot;zh-CN&quot;</code></p></blockquote><p>启动</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[elasticsearch@izwz920kp0myp15p982vp4z kibana-7.6.2-linux-x86_64]$ ./bin/kibana  log   [12:07:17.644] [info][plugins-service] Plugin "case" is disabled.  log   [12:07:22.407] [info][plugins-system] Setting up [37] plugins: [taskManager,siem,licensing,infra,encryptedSavedObjects,code,usageCollection,metrics,canvas,timelion,features,security,apm_oss,translations,reporting,uiActions,data,navigation,status_page,share,newsfeed,kibana_legacy,management,dev_tools,inspector,expressions,visualizations,embeddable,advancedUiActions,dashboard_embeddable_container,home,spaces,cloud,apm,graph,eui_utils,bfetch]  log   [12:07:22.408] [info][plugins][taskManager] Setting up plugin  log   [12:07:22.422] [info][plugins][siem] Setting up plugin  log   [12:07:22.423] [info][licensing][plugins] Setting up plugin  log   [12:07:22.425] [info][infra][plugins] Setting up plugin  log   [12:07:22.426] [info][encryptedSavedObjects][plugins] Setting up plugin  log   [12:07:22.427] [warning][config][encryptedSavedObjects][plugins] Generating a random key for xpack.encryptedSavedObjects.encryptionKey. To be able to decrypt encrypted saved objects attributes after restart, please set xpack.encryptedSavedObjects.encryptionKey in kibana.yml  log   [12:07:22.431] [info][code][plugins] Setting up plugin  log   [12:07:22.432] [info][plugins][usageCollection] Setting up plugin  log   [12:07:22.434] [info][metrics][plugins] Setting up plugin  log   [12:07:22.434] [info][canvas][plugins] Setting up plugin  ... ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>访问<code>myecs.com:5601</code></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210746.png" alt="image-20200423201017670"></p><p>启动成功！</p><h2 id="一些样例数据"><a class="header-anchor" href="#一些样例数据">¶</a>一些样例数据</h2><p>ES 在 Kibana 的开箱即64用的版本中加入了一些样例数据：电商网站订单、航空公司飞行记录、web 应用的日志。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210753.png" alt="image-20200423201345278"></p><p>我们可以点击添加这些数据来打入这些数据到 Elasticsearch 中</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210800.png" alt="image-20200423201447873"></p><p>asd</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210807.png" alt="image-20200423201711721"></p><p>通过点击右边的 dashboard 可以发现这三份数据的 dashboard 已经构建好了，我们点击其中一个</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210814.png" alt="image-20200423201737858"></p><p>进来后看到一些数据面板</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210819.png" alt="image-20200423201755072"></p><h2 id="Dev-Tools"><a class="header-anchor" href="#Dev-Tools">¶</a>Dev Tools</h2><p>下面我们来看左边面板的一个 Dev Tools 工具</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210826.png" alt="image-20200423201938833"></p><p>它可以方便我们进行 Elasticsearch 的 api 的调用</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210833.png" alt="image-20200423202058260"></p><p>另外它还提供了一些键盘快捷操作：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210838.png" alt="image-20200423202150145"></p><h2 id="插件"><a class="header-anchor" href="#插件">¶</a>插件</h2><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210846.png" alt="image-20200423202556262"></p><h1>Docker 的安装</h1><h3 id="相关阅读与安装"><a class="header-anchor" href="#相关阅读与安装">¶</a>相关阅读与安装</h3><ul><li><a href="https://www.docker.com/products/docker-desktop" target="_blank" rel="noopener">安装docker</a></li></ul><ul><li><a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener">安装 docker-compose</a></li></ul><ul><li><p><a href="https://www.elastic.co/cn/blog/how-to-make-a-dockerfile-for-elasticsearch" target="_blank" rel="noopener">如何创建自己的Docker Image</a></p></li><li><p><a href="https://www.elastic.co/cn/blog/elasticsearch-docker-plugin-management" target="_blank" rel="noopener">如何在为docker image安装 Elasticsearch 插件</a></p></li><li><p><a href="https://www.elastic.co/cn/blog/docker-networking" target="_blank" rel="noopener">如何设置 Docker 网络</a></p></li><li><p><a href="https://github.com/lmenezes/cerebro" target="_blank" rel="noopener">Cerebro 源码</a></p></li><li><p><a href="https://github.com/deviantony/docker-elk" target="_blank" rel="noopener">一个开源的 ELK（Elasticsearch + Logstash + Kibana） docker-compose 配置</a></p></li><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.2/docker.html" target="_blank" rel="noopener">Install Elasticsearch with Docker</a></p></li></ul><h3 id="docker-compose命令"><a class="header-anchor" href="#docker-compose命令">¶</a>docker-compose命令</h3><ul><li><p>启动<code>docker-compose up</code></p></li><li><p>停止容器<code>docker-compose down</code></p></li><li><p>停止容器并且移除数据<code>docker-compose down -v</code></p></li></ul><h3 id="docker-命令"><a class="header-anchor" href="#docker-命令">¶</a>docker 命令</h3><ul><li><p><code>docker ps</code></p></li><li><p><code>docker stop Name/ContainerId</code></p></li><li><p><code>docker start Name/ContainerId</code></p></li><li><p>删除单个容器 <code>docker rm Name/ID -f, –force=false; -l, –link=false Remove the specified link and not the underlying container; -v, –volumes=false Remove the volumes associated to the container</code></p></li><li><p>删除所有容器 docker rm <code>docker ps -a -q</code></p></li><li><p>停止、启动、杀死、重启一个容器<br><code>​docker stop Name/ID</code><br><code>docker start Name/ID </code></p><p><code>docker kill Name/ID</code><br><code>docker restart name/ID</code></p></li></ul><h3 id="Docker-compse-配置文件"><a class="header-anchor" href="#Docker-compse-配置文件">¶</a>Docker-compse 配置文件</h3><pre class="line-numbers language-language-shell"><code class="language-language-shell">version: '2.2'services:  cerebro:    image: lmenezes/cerebro:0.8.3    container_name: cerebro    ports:      - "9000:9000"    command:      - -Dhosts.0.host=http://elasticsearch:9200    networks:      - es72net  kibana:    image: kibana:7.2.0    container_name: kibana72    environment:      #- I18N_LOCALE=zh-CN      - XPACK_GRAPH_ENABLED=true      - TIMELION_ENABLED=true      - XPACK_MONITORING_COLLECTION_ENABLED="true"    ports:      - "5601:5601"    networks:      - es72net  elasticsearch:    image: elasticsearch:7.2.0    container_name: es72_01    environment:      - cluster.name=geektime      - node.name=es72_01      - bootstrap.memory_lock=true      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"      - discovery.seed_hosts=es72_01,es72_02      - cluster.initial_master_nodes=es72_01,es72_02    ulimits:      memlock:        soft: -1        hard: -1    volumes:      - es72data1:/usr/share/elasticsearch/data    ports:      - 9200:9200    networks:      - es72net  elasticsearch2:    image: elasticsearch:7.2.0    container_name: es72_02    environment:      - cluster.name=geektime      - node.name=es72_02      - bootstrap.memory_lock=true      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"      - discovery.seed_hosts=es72_01,es72_02      - cluster.initial_master_nodes=es72_01,es72_02    ulimits:      memlock:        soft: -1        hard: -1    volumes:      - es72data2:/usr/share/elasticsearch/data    networks:      - es72netvolumes:  es72data1:    driver: local  es72data2:    driver: localnetworks:  es72net:    driver: bridge<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="docker-阿里云镜像加速器"><a class="header-anchor" href="#docker-阿里云镜像加速器">¶</a><a href="https://cr.console.aliyun.com/undefined/instances/mirrors" target="_blank" rel="noopener">docker 阿里云镜像加速器</a></h3><h3 id="docker-中的服务"><a class="header-anchor" href="#docker-中的服务">¶</a>docker 中的服务</h3><p>以上准备工作就绪之后执行以下指令启动 docker 容器</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">/usr/local/software/elasticsearch/docker-es-7.2[root@izwz920kp0myp15p982vp4z docker-es-7.2]# lsdocker-compose.yaml[root@izwz920kp0myp15p982vp4z docker-es-7.2]# docker-compose up<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>启动完成后。我们一共启动了以下三个服务</p><ol><li><p>kibana</p><p>端口:5601</p></li><li><p>elasticsearch</p><p>端口:9200</p></li><li><p>cerebro</p><p>端口:9000</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210855.png" alt="image-20200423231524850"></p><p>可以看到上面6行信息分别表示有一个 elasticsearch集群叫 geektime，有两个节点，有2个索引，分布在4个分片上，有6个文档，总共存储消耗了123.50KB 的磁盘空间。</p></li></ol><h1>Logstash 安装</h1><h3 id="Logstash-下载安装"><a class="header-anchor" href="#Logstash-下载安装">¶</a><a href="https://www.elastic.co/cn/downloads/logstash" target="_blank" rel="noopener">Logstash 下载安装</a></h3><p>同上面的 Elasticsearch 和 Kibana到官网进行下载，注意 Logstash 并没有集成 Jdk，所以需要先安装 Jdk 并配置$JAVA_HOME 环境变量</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z logstash-7.1.0]# pwd/usr/local/software/elasticsearch/logstash-7.1.0[root@izwz920kp0myp15p982vp4z logstash-7.1.0]# ./bin/logstash --versionlogstash 7.1.0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>附：<a href="https://www.elastic.co/guide/en/logstash/current/index.html" target="_blank" rel="noopener">Logstash 参考文档</a></p></blockquote><h3 id="下载最MovieLens最小测试数据集"><a class="header-anchor" href="#下载最MovieLens最小测试数据集">¶</a><a href="https://grouplens.org/datasets/movielens/" target="_blank" rel="noopener">下载最MovieLens最小测试数据集</a></h3><p>下载完毕：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z movielens]# pwd/usr/local/software/elasticsearch/movielens[root@izwz920kp0myp15p982vp4z movielens]# ll总用量 980drwxr-xr-x 2 root root   4096 4月  24 00:09 ml-latest-small-rw-r--r-- 1 root root   9703 4月  24 00:09 ml-latest-small-README.html-rw-r--r-- 1 root root 978202 4月  24 00:09 ml-latest-small.zip-rw-r--r-- 1 root root    166 4月  24 00:09 movies_settings.json<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Logstash-配置文件"><a class="header-anchor" href="#Logstash-配置文件">¶</a>Logstash 配置文件</h3><p>logstash.conf</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">input {  file {    # 指向测试数据csv文件    path => "/usr/local/software/elasticsearch/movielens/ml-latest-small/movies.csv"    start_position => "beginning"    sincedb_path => "/dev/null"  }}filter {  csv {    separator => ","    columns => ["id","content","genre"]  }  mutate {    split => { "genre" => "|" }    remove_field => ["path", "host","@timestamp","message"]  }  mutate {    split => ["content", "("]    add_field => { "title" => "%{[content][0]}"}    add_field => { "year" => "%{[content][1]}"}  }  mutate {    convert => {      "year" => "integer"    }    strip => ["title"]    remove_field => ["path", "host","@timestamp","message","content"]  }}output {   elasticsearch {     hosts => "http://localhost:9200"     index => "movies"     document_id => "%{id}"   }  stdout {}}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="启动-Logstash-抓取测试数据"><a class="header-anchor" href="#启动-Logstash-抓取测试数据">¶</a>启动 Logstash 抓取测试数据</h3><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z logstash-7.1.0]# pwd/usr/local/software/elasticsearch/logstash-7.1.0[root@izwz920kp0myp15p982vp4z logstash-7.1.0]# ./bin/logstash -f ../movielens/logstash.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>005_深入搜索</title>
      <link href="/2020/12/22/elasticsearch/005-shen-ru-sou-suo/"/>
      <url>/2020/12/22/elasticsearch/005-shen-ru-sou-suo/</url>
      
        <content type="html"><![CDATA[<p>[toc]</p><h1>基于词项和基于全文的搜索</h1><h2 id="基于-Term的查询"><a class="header-anchor" href="#基于-Term的查询">¶</a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/term-level-queries.html" target="_blank" rel="noopener">基于 Term的查询</a></h2><h3 id="Term-的重要性"><a class="header-anchor" href="#Term-的重要性">¶</a>Term 的重要性</h3><p>term 是表达语意的最小单位。搜索和利用统计语言模型进行自然语言处理都需要处理 term。</p><h3 id="Es-中的特点"><a class="header-anchor" href="#Es-中的特点">¶</a>Es 中的特点</h3><ol><li><p>在 Es 中，Term 查询包括以下查询：</p><p>Term Query、Range Query、Exists Query、Prefix Query、Wildcard Query</p></li><li><p>在 Es 中，Term 查询，对输入<strong>不做分词</strong>。会将输入作为一个整体的词项，在倒排索引中查询准确的词项，并且使用相关度算分公式为每个包含该词项的文档进行<strong>相关度算分</strong>，例如&quot;App Store&quot;</p></li><li><p>可以通过 Constant Score 将查询转换成一个 <strong>Filtering，避免算法，并利用缓存</strong>，提高性能。</p></li></ol><h3 id="关于-Term-查询的例子"><a class="header-anchor" href="#关于-Term-查询的例子">¶</a>关于 Term 查询的例子</h3><ol><li><p>先插入以下索引</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211842.png" alt="image-20200424222441712"></p></li><li><p>执行以下查询语句</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211854.png" alt="image-20200424223011086"></p><p>当查询&quot;iPhone&quot;的时候是得不到结果的，查询&quot;iphone&quot;的时候就可以。</p><p>这是因为对于上面创建索引的时候认为 desc 字段是一个 text 类型的数据，所以会做默认的分词处理，即&quot;iPhone&quot;最终被转换成了小写。而我们这里指定了 term 查询，而 term 查询是一个精准词条查询，不会对数据做任何分词处理，直接进行 term 匹配，即&quot;iPhone&quot;，所以是匹配不到经过分词处理之后的&quot;iphone&quot;的。</p></li><li><p>执行以下查询语句</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211848.png" alt="image-20200424223706206"></p><p>我们会发现也不会返回任何结果。同理，那是因为 Es 也在创建这条索引的时候对这个字段进行了默认的分词，如下图所示，整个内容被切分成了好几个 term。而我们将该完整 ID到该字段中进行 term 检索是匹配不到数据的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211902.png" alt="image-20200424223930419"></p><p>此时如果我们查询的值改成&quot;xhdk&quot;，将得到匹配。但是如果我们就想对<strong>这个输入值</strong>进行精确匹配，应该怎么做呢？（我们不想返回其他不相关但是相似的数据）此时我们将检索字段改成&quot;productId.keyword&quot;即可返回精确匹配的文档，keyword 是Es 为每一个 text 类型的字段生成的子字段，它对 text 字段的原值进行了索引。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211911.png" alt="image-20200424224312908"></p></li><li><p>Es 的查询默认都会返回一个算分结果</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211918.png" alt="image-20200424224536835"></p><p>如果我们希望跳过这个步骤，则可以利用：复合查询-Constant Score 转为 Filter</p><ul><li>将 Query 转成 Filter，忽略 TF-IDF 计算，避免相关性算分的开销</li><li>FIlter 可以有效利用缓存</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211923.png" alt="image-20200424224637345"></p></li></ol><h2 id="基于全文的查询"><a class="header-anchor" href="#基于全文的查询">¶</a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/full-text-queries.html" target="_blank" rel="noopener">基于全文的查询</a></h2><h3 id="Es-基于全文本的查找"><a class="header-anchor" href="#Es-基于全文本的查找">¶</a>Es 基于全文本的查找</h3><p>Match Query、Match Phrase Query、Query String Query</p><h3 id="特点："><a class="header-anchor" href="#特点：">¶</a>特点：</h3><ul><li>索引和搜索时都会进行分词，查询字符串先传递到一个合适的分词器，然后生成一个供查询的词项列表到倒排索引中进行检索</li><li>查询时，先会对输入的查询进行分词，然后每个词项逐个进行底层的查询，最终将结果进行合并。并为每个文档生成一个算分。例如查&quot;Matrix reloaded&quot;，会查到包括 Matrix 或者 reloaded 的所有结果。</li></ul><h3 id="Match-Query-Result"><a class="header-anchor" href="#Match-Query-Result">¶</a>Match Query Result</h3><p>以下返回包含所有包含 Matrix 或者 reloaded 的文档</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221211932.png" alt="image-20200424225433514"></p><h3 id="Operator"><a class="header-anchor" href="#Operator">¶</a>Operator</h3><p>使用 AND 操作符，返回所有包含 Matrix 以及 reloaded 的文档</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212112.png" alt="image-20200424225934203"></p><h3 id="Minimum-shold-match"><a class="header-anchor" href="#Minimum-shold-match">¶</a>Minimum_shold_match</h3><p>Minimum_should_match 参数可以调整 persicion 或者 recall 使我们返回的结果更加理想，该参s数可以控制应该匹配的词条的最少数量。</p><p>数字可以是负数，例如有4个term的匹配，当匹配度为-25%与75%，其意义是一样的，都是最少匹配三个，但处理5个term时，-25%表示至少匹配四个，而75%表示至少匹配三个term。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212126.png" alt="image-20200424230033637"></p><h3 id="Match-Phrase-Query"><a class="header-anchor" href="#Match-Phrase-Query">¶</a>Match Phrase Query</h3><p>match_phrase 查询的 slop 也可以对 persicion 和 recall 进行调整</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212132.png" alt="image-20200424230209902"></p><h3 id="查询过程"><a class="header-anchor" href="#查询过程">¶</a>查询过程</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212139.png" alt="image-20200424230310798"></p><h2 id="Kibana-测试请求"><a class="header-anchor" href="#Kibana-测试请求">¶</a>Kibana 测试请求</h2><pre><code>DELETE productsPUT products{  &quot;settings&quot;: {    &quot;number_of_shards&quot;: 1  }}POST /products/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 }}{ &quot;productID&quot; : &quot;XHDK-A-1293-#fJ3&quot;,&quot;desc&quot;:&quot;iPhone&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 }}{ &quot;productID&quot; : &quot;KDKE-B-9947-#kL5&quot;,&quot;desc&quot;:&quot;iPad&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 3 }}{ &quot;productID&quot; : &quot;JODL-X-1937-#pV7&quot;,&quot;desc&quot;:&quot;MBP&quot; }GET /productsPOST /products/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;desc&quot;: {        //&quot;value&quot;: &quot;iPhone&quot;        &quot;value&quot;:&quot;iphone&quot;      }    }  }}POST /products/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;desc.keyword&quot;: {        //&quot;value&quot;: &quot;iPhone&quot;        //&quot;value&quot;:&quot;iphone&quot;      }    }  }}POST /products/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;productID&quot;: {        &quot;value&quot;: &quot;XHDK-A-1293-#fJ3&quot;      }    }  }}POST /products/_search{  //&quot;explain&quot;: true,  &quot;query&quot;: {    &quot;term&quot;: {      &quot;productID.keyword&quot;: {        &quot;value&quot;: &quot;XHDK-A-1293-#fJ3&quot;      }    }  }}POST /products/_search{  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;term&quot;: {          &quot;productID.keyword&quot;: &quot;XHDK-A-1293-#fJ3&quot;        }      }    }  }}#设置 position_increment_gapDELETE groupsPUT groups{  &quot;mappings&quot;: {    &quot;properties&quot;: {      &quot;names&quot;:{        &quot;type&quot;: &quot;text&quot;,        &quot;position_increment_gap&quot;: 0      }    }  }}GET groups/_mappingPOST groups/_doc{  &quot;names&quot;: [ &quot;John Water&quot;, &quot;Water Smith&quot;]}POST groups/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;names&quot;: {        &quot;query&quot;: &quot;Water Water&quot;,        &quot;slop&quot;: 100      }    }  }}POST groups/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;names&quot;: &quot;Water Smith&quot;    }  }}</code></pre><h1>结构化搜索</h1><p>结构化搜索（Structured search）是指对结构化数据的搜索。日期、布尔类型和数字都是结构化的。</p><p>文本也可以使结构化的。</p><ul><li>如彩色笔可以有离散的颜色集合：红、绿、蓝</li><li>一个博客可能被标记了标签，例如：分布式、搜索</li><li>电商网站上的商品都有 UPCs（通用产品码 Universal Product Codes）或者其他的唯一标识，它们都需要遵从严格规定的、格式化的格式。</li></ul><h3 id="1、Es-中的结构化搜索"><a class="header-anchor" href="#1、Es-中的结构化搜索">¶</a>1、Es 中的结构化搜索</h3><p>布尔、时间、日期和数字这类结构化数据：有精确的格式，我们可以对这些格式进行逻辑操作。包括比较数字或时间的范围，或判定两个值的大小。</p><p>结构化的文本可以做精确匹配或者部分匹配：Term 查询、Prefix 前缀查询</p><p>结构化结果只有&quot;是&quot;或者&quot;否&quot;两个值，根据场景需要，可以决定结构化搜索是否需要打分（如果不需要就转成 Constant Score Query）</p><h3 id="2、布尔值Term-查询示例"><a class="header-anchor" href="#2、布尔值Term-查询示例">¶</a>2、布尔值Term 查询示例</h3><p>右边使用 constant_score 去掉算分的过程</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212148.png" alt="image-20200424231700038"></p><h3 id="3、数字-Range查询示例"><a class="header-anchor" href="#3、数字-Range查询示例">¶</a>3、数字 Range查询示例</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212154.png" alt="image-20200424231747274"></p><h3 id="4、日期-Range-查询示例"><a class="header-anchor" href="#4、日期-Range-查询示例">¶</a>4、日期 Range 查询示例</h3><p>右边是日期表达式，根据这个表达式可以构建我们想要的时间区间</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212202.png" alt="image-20200424231820590"></p><h3 id="5、空值相关查询"><a class="header-anchor" href="#5、空值相关查询">¶</a>5、空值相关查询</h3><p>左边是查询 date 字段不是空的数据、右边是查询 date 字段是空的数据</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212208.png" alt="image-20200424232538063"></p><h3 id="6、精确查找多个值"><a class="header-anchor" href="#6、精确查找多个值">¶</a>6、精确查找多个值</h3><p>前两个查询是对一个字段进行多值 term 查询，可以发现只要包含任一个值都会进行返回。而第三个精准查询也是，只要该文档中该字段的值有一个是匹配该规则的，都会进行返回，不管其他值是否匹配。如果我们想要该字段是内容和值个数完全匹配才返回的话，解决方案：增加一个 genre_count 字段进行计数。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212214.png" alt="image-20200424234452478"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212223.png" alt="image-20200424234525290"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212231.png" alt="image-20200424234335266"></p><h3 id="7、Kibana-测试请求"><a class="header-anchor" href="#7、Kibana-测试请求">¶</a>7、Kibana 测试请求</h3><pre><code>#结构化搜索，精确匹配DELETE productsPOST /products/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 }}{ &quot;price&quot; : 10,&quot;avaliable&quot;:true,&quot;date&quot;:&quot;2018-01-01&quot;, &quot;productID&quot; : &quot;XHDK-A-1293-#fJ3&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 }}{ &quot;price&quot; : 20,&quot;avaliable&quot;:true,&quot;date&quot;:&quot;2019-01-01&quot;, &quot;productID&quot; : &quot;KDKE-B-9947-#kL5&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 3 }}{ &quot;price&quot; : 30,&quot;avaliable&quot;:true, &quot;productID&quot; : &quot;JODL-X-1937-#pV7&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 4 }}{ &quot;price&quot; : 30,&quot;avaliable&quot;:false, &quot;productID&quot; : &quot;QQPX-R-3956-#aD8&quot; }GET products/_mapping#对布尔值 match 查询，有算分POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;term&quot;: {      &quot;avaliable&quot;: true    }  }}#对布尔值，通过constant score 转成 filtering，没有算分POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;term&quot;: {          &quot;avaliable&quot;: true        }      }    }  }}#数字类型 TermPOST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;term&quot;: {      &quot;price&quot;: 30    }  }}#数字类型 termsPOST products/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;terms&quot;: {          &quot;price&quot;: [            &quot;20&quot;,            &quot;30&quot;          ]        }      }    }  }}#数字 Range 查询GET products/_search{    &quot;query&quot; : {        &quot;constant_score&quot; : {            &quot;filter&quot; : {                &quot;range&quot; : {                    &quot;price&quot; : {                        &quot;gte&quot; : 20,                        &quot;lte&quot;  : 30                    }                }            }        }    }}# 日期 rangePOST products/_search{    &quot;query&quot; : {        &quot;constant_score&quot; : {            &quot;filter&quot; : {                &quot;range&quot; : {                    &quot;date&quot; : {                      &quot;gte&quot; : &quot;now-1y&quot;                    }                }            }        }    }}#exists查询POST products/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;exists&quot;: {          &quot;field&quot;: &quot;date&quot;        }      }    }  }}#处理多值字段POST /movies/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 }}{ &quot;title&quot; : &quot;Father of the Bridge Part II&quot;,&quot;year&quot;:1995, &quot;genre&quot;:&quot;Comedy&quot;}{ &quot;index&quot;: { &quot;_id&quot;: 2 }}{ &quot;title&quot; : &quot;Dave&quot;,&quot;year&quot;:1993,&quot;genre&quot;:[&quot;Comedy&quot;,&quot;Romance&quot;] }#处理多值字段，term 查询是包含，而不是等于POST movies/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;term&quot;: {          &quot;genre.keyword&quot;: &quot;Comedy&quot;        }      }    }  }}#字符类型 termsPOST products/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;terms&quot;: {          &quot;productID.keyword&quot;: [            &quot;QQPX-R-3956-#aD8&quot;,            &quot;JODL-X-1937-#pV7&quot;          ]        }      }    }  }}POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;match&quot;: {      &quot;price&quot;: 30    }  }}POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;term&quot;: {      &quot;date&quot;: &quot;2019-01-01&quot;    }  }}POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;match&quot;: {      &quot;date&quot;: &quot;2019-01-01&quot;    }  }}POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;term&quot;: {          &quot;productID.keyword&quot;: &quot;XHDK-A-1293-#fJ3&quot;        }      }    }  }}POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;term&quot;: {      &quot;productID.keyword&quot;: &quot;XHDK-A-1293-#fJ3&quot;    }  }}#对布尔数值POST products/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;term&quot;: {          &quot;avaliable&quot;: &quot;false&quot;        }      }    }  }}POST products/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;avaliable&quot;: {        &quot;value&quot;: &quot;false&quot;      }    }  }}POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;term&quot;: {      &quot;price&quot;: {        &quot;value&quot;: &quot;20&quot;      }    }  }}POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;match&quot;: {      &quot;price&quot;: &quot;20&quot;    }    }  }}POST products/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;bool&quot;: {          &quot;must_not&quot;: {            &quot;exists&quot;: {              &quot;field&quot;: &quot;date&quot;            }          }        }      }    }  }}</code></pre><h1>搜索的相关性算法</h1><h3 id="1、相关性（Relevance）"><a class="header-anchor" href="#1、相关性（Relevance）">¶</a>1、相关性（Relevance）</h3><p>搜索的相关算分，描述了一个文档和查询语句匹配的程度。ES 会对每个匹配查询条件的解雇哦进行算分_score。</p><p>打分的本质是排序，需要把符合用户需求的文档排在前面。在 ES5之前，默认的相关性算分采用 TF-IDF，现在采用 BM 25。我们来看下面的例子：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212243.png" alt="image-20200425100254189"></p><p>我们搜索&quot;区块链的应用&quot;被拆分成了三个 term，可以看到 id 为2和3的文档都包含了这三个 term，它们三个的相关性较之其他文档来说肯定是最高的。现在的问题是这三个中谁的相关性最高呢？</p><h3 id="2、TF-IDF"><a class="header-anchor" href="#2、TF-IDF">¶</a>2、TF-IDF</h3><p>TF-IDF 被公认为是信息检索领域最重要的发明，除了在信息检索这方面，在文献分类和其他相关领域有着非常广泛的引用。</p><h4 id="词频（TF）"><a class="header-anchor" href="#词频（TF）">¶</a>词频（TF）</h4><p>Term Frequency：检索词在一篇文档中出现的频率，检索词出现的次数除以文档的总字数。</p><p>度量一条查询和结果文档相关性的简单方法，就是简单地将搜索中每一个词地 TF 进行相加：TF(区块链)+TF(的)+TF(应用)。另外，对于停用词（Stop word）&quot;的&quot;在文档中出现了很多次，但是对贡献相关度几乎没有用处，我们似乎不应该考虑它们地 TF。</p><h4 id="逆文档频率（IDF）"><a class="header-anchor" href="#逆文档频率（IDF）">¶</a>逆文档频率（IDF）</h4><ol><li><p>DF：检索词在所有文档中出现地频率</p><ul><li>&quot;区块链&quot;在相对比较少的文档中出现</li><li>&quot;应用&quot;在相对比较多的文档中出现</li><li>&quot;Stop word&quot;在大量的文档中出现</li></ul></li><li><p>Inverse Document Frequency：简单说=log(全部文档数/检索词出现过的文档总数)，它可以认为是一个 term 在搜索语句中的权重。</p><p>如果某个 term 出现过的文档数越多，说明在计算整个搜索&quot;语句&quot;的文档相关性的时候，它的计算权重应该越低。所以我们可以通过式子&quot;全部文档数/检索词 term 出现过的文档总数&quot;可以计算到 term 的相对出现文档频率。但是为了可以将这个运算结果应用到整个文档的相关性中，我们可以对它&quot;log&quot;一下，这样我们可以使得运算结果变小可以乘到 term 的 TF 中，但是它的函数曲线趋势还是不变的，即随着 term 在所有文档中出现的次数越多，它的 IDF 就越低，只不过在次数越来越多的时候，它的 IDF 下降的速度越来越慢。</p></li></ol><p><strong>TF-IDF 本质上就是将 TF 求和变成了加权求和</strong>：搜索语句&quot;XXXX&quot;被分隔成 n 个 term，搜索出来的所有文档的_score 计算就是&quot;当前文档中第一个 term 出现的频率*第一个 term 的计算权重+当前文档中第二个 term 出现的频率*第二个term 的计算权重+… …&quot;，而上面例子的计算公式就是：TF(区块链)*IDF(区块链)+TF(的)*IDF(的)+TF(应用)*IDF(应用)</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212249.png" alt="image-20200425101606360"></p><ol><li><p>IDF 的概念，最早是剑桥大学的&quot;斯巴克*琼斯&quot;提出</p><ul><li>1972年-“关键词特殊性的统计解释和它在文献检索中的应用”</li><li>但是没有从理论上解释 IDF 应该是用 log(全部文档数/检索词出现过的文档总数)，而不是其他函数。也没有做进一步的研究</li></ul></li><li><p>1970、1980年代萨尔顿和罗宾逊，进行了进一步的证明和研究，并用香农信息论做了证明：<a href="http://www.staff.city.ac.uk/~sb317/papers/foundations_bm25_review.pdf" target="_blank" rel="noopener">http://www.staff.city.ac.uk/~sb317/papers/foundations_bm25_review.pdf</a></p></li><li><p>现代搜索引擎，对 TF-IDF 进行了大量细微的优化。</p><ul><li><p>Lucene 中的 TF-IDF 公式</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212255.png" alt="image-20200425103957877"></p></li></ul></li></ol><h3 id="3、BM25"><a class="header-anchor" href="#3、BM25">¶</a>3、BM25</h3><p>从 ES5 开始，默认算分算法改为 BM25。BM25做了一定的优化，它和经典的 TF-IDF 相比：当 TF 无限增加的时候，后者的 score 会不断增长；对于前者来说，随着 TF 的增长，TF 对于算法的影响会慢慢下降。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212302.png" alt="image-20200425104604283"></p><h3 id="4、定制-Similarity-相似度"><a class="header-anchor" href="#4、定制-Similarity-相似度">¶</a>4、定制 Similarity(相似度)</h3><p>在 ES 中创建索引的时候对于相似度算分的计算是可以定制的：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212307.png" alt="image-20200425104944347"></p><p>K 默认值是 1.2，数值越⼩小，饱和度越⾼高，b 默认值是 0.75(取值范围 0-1)，0 代表禁⽌止 Normalization。</p><p>BM25公式：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212323.png" alt="image-20200425105031183"></p><h3 id="4、通过-Explain-API-查看-TF-IDF"><a class="header-anchor" href="#4、通过-Explain-API-查看-TF-IDF">¶</a>4、通过 Explain API 查看 TF-IDF</h3><ol><li><p>建立索引并写入文档</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212328.png" alt="image-20200425105935930"></p></li><li><p>搜索查看算分结果</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212333.png" alt="image-20200425110126666"></p><p>我们看到搜索&quot;elasticsearch&quot;的时候，返回了两条记录&quot;we like elasticsearch&quot;和&quot;we use elasticsearch to power the search&quot;，前者算分比后者高，其实两者中&quot;elasticsearch&quot;出现的次数都是一样的，但是前者更短，所以最终算分更高。</p></li><li><p>explain 查看算分过程，我们加上&quot;expalin&quot;参数之后，看到右边的结果为我们显示了每一个文档的算分过程。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212341.png" alt="image-20200425110652436"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212349.png" alt="image-20200425110523125"></p></li></ol><h3 id="5、通过-Boosting-Relevance-控制相关度算分"><a class="header-anchor" href="#5、通过-Boosting-Relevance-控制相关度算分">¶</a>5、通过 Boosting Relevance 控制相关度算分</h3><p>Boosting 是控制相关度的一种手段，我们可以在索引的 mapping、字段 的 mapping或者查询条件中对 Boosting 进行设置。</p><ul><li>当 boost &gt; 1时，打分的相关度相对性提升</li><li>当0 &lt; boost &lt; 1时，打分的权重相对性降低</li><li>当 boost &lt; 0时，贡献负分</li></ul><p>另外 es 还提供了一个 Boosting 的复合查询，其中包含 positive 和 negative 子查询，下面就是这样一个例子。</p><ul><li>我们将对于字段content 的&quot;elasticsearch&quot;词条的 term 查询纳入到 positive，表示这个查询会贡献正向分值。</li><li>将对于同一个字段 content 的&quot;like&quot;词条的 term 查询纳入到 negative，表示这个查询会贡献负分，并设置 boosting 的一个属性&quot;negative_boost&quot;来指定负分基础数值。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212358.png" alt="image-20200425111223205"></p><h3 id="6、Kibana-测试请求"><a class="header-anchor" href="#6、Kibana-测试请求">¶</a>6、Kibana 测试请求</h3><pre><code>PUT testscore{  &quot;settings&quot;: {    &quot;number_of_shards&quot;: 1  },  &quot;mappings&quot;: {    &quot;properties&quot;: {      &quot;content&quot;: {        &quot;type&quot;: &quot;text&quot;      }    }  }}PUT testscore/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 }}{ &quot;content&quot;:&quot;we use Elasticsearch to power the search&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 }}{ &quot;content&quot;:&quot;we like elasticsearch&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 3 }}{ &quot;content&quot;:&quot;The scoring of documents is caculated by the scoring formula&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 4 }}{ &quot;content&quot;:&quot;you know, for search&quot; }POST /testscore/_search{  //&quot;explain&quot;: true,  &quot;query&quot;: {    &quot;match&quot;: {      &quot;content&quot;:&quot;you&quot;      //&quot;content&quot;: &quot;elasticsearch&quot;      //&quot;content&quot;:&quot;the&quot;      //&quot;content&quot;: &quot;the elasticsearch&quot;    }  }}POST testscore/_search{    &quot;query&quot;: {        &quot;boosting&quot; : {            &quot;positive&quot; : {                &quot;term&quot; : {                    &quot;content&quot; : &quot;elasticsearch&quot;                }            },            &quot;negative&quot; : {                 &quot;term&quot; : {                     &quot;content&quot; : &quot;like&quot;                }            },            &quot;negative_boost&quot; : 0.2        }    }}POST tmdb/_search{  &quot;_source&quot;: [&quot;title&quot;,&quot;overview&quot;],  &quot;query&quot;: {    &quot;more_like_this&quot;: {      &quot;fields&quot;: [        &quot;title^10&quot;,&quot;overview&quot;      ],      &quot;like&quot;: [{&quot;_id&quot;:&quot;14191&quot;}],      &quot;min_term_freq&quot;: 1,      &quot;max_query_terms&quot;: 12    }  }}</code></pre><h1>Query&amp;Filtering 与多字符串多字段查询</h1><h3 id="Query-Context-Filter-Context"><a class="header-anchor" href="#Query-Context-Filter-Context">¶</a>Query Context &amp; Filter Context</h3><p>下面是高级搜索的功能：支持多项文本输入，针对多个字段进行搜索。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212409.png" alt="image-20200425111639203"></p><p>搜索引擎一般也提供基于时间，价格等条件的过滤。在 Elasticsearch 中，有 Query 和 Filter 两种不同的搜索 Context：</p><ul><li>Query Context：会进行相关性算分</li><li>Filter Context：不需要进行算分（Yes or No），可以利用 Cache，获得更好的性能</li></ul><h3 id="条件组合"><a class="header-anchor" href="#条件组合">¶</a>条件组合</h3><p>问题：假设要搜索一部电影，包含了以下一些条件：</p><ol><li>评论中包含了 Guitar</li><li>用户打分高于3分</li><li>上映日期要在1993年与2000年之间</li></ol><p>这个搜索包含了3段逻辑针对不同字段，我们可以使用<strong>复合查询：bool Query</strong>来同时实现这三个逻辑，并且有比较好的性能。</p><h3 id="bool-查询"><a class="header-anchor" href="#bool-查询">¶</a>bool 查询</h3><p>一个 bool 查询，是一个或者多个查询子句的组合，它有4种子句，其中2种会影响算分，2种不影响算分。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212416.png" alt="image-20200425112512762"></p><p>相关性打分并不只是全文本检索的专利。也适用于 yes|no 的子句，匹配的子句越多，相关性评分越高。如果多条查询子句被合并为一条复合查询语句，比如bool查询，则每个查询子句计算得出的评分会被合并到总的相关性评分中。</p><h4 id="1、bool-查询语法"><a class="header-anchor" href="#1、bool-查询语法">¶</a>1、bool 查询语法</h4><ul><li>子查询可以任意顺序出现</li><li>可以嵌套多个查询</li><li>如果你的 bool 查询中，没有 must 条件，should 中必须至少满足一条查询</li></ul><p>下面是一个 bool 查询例子：</p><ul><li>第一个 must 子句表示第一个查询必须匹配到文档，并进行算分</li><li>最后一个 should 检索满足其中一个条件的文档，并进行算分</li><li>filter 对匹配文档进行过滤，不进行算分</li><li>下面的 must_not 子句过滤价格小于等于10的文档，没有算分</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212423.png" alt="image-20200425112834474"></p><h4 id="2、解决结构化查询：-包含而不是相等-的问题"><a class="header-anchor" href="#2、解决结构化查询：-包含而不是相等-的问题">¶</a>2、解决结构化查询：&quot;包含而不是相等&quot;的问题</h4><p>在&quot;结构化搜索&quot;章节的&quot;精确查找多个值&quot;小节中提到对于一个多值字段的结构化查询的语义是包含查询的，即这个字段只要是有一个值匹配了检索的 term，那么当前这个文档就是被命中了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212430.png" alt="image-20200425125615342"></p><p>为了解决这个问题，我们可以针对这个字段引入一个&quot;count&quot;字段专门用来存储对这个字段的值个数，在查询的时候我们使用 bool 复合查询，在对某个字段检索我们需要的内容的同时，限制该字段的值的个数，从而实现精准匹配：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212436.png" alt="image-20200425125717640"></p><h4 id="3、Query-Context、should-和-Filter-Context、must-not下的算分规则"><a class="header-anchor" href="#3、Query-Context、should-和-Filter-Context、must-not下的算分规则">¶</a>3、Query Context、should 和 Filter Context、must_not下的算分规则</h4><p>示例一：Query Context 和 should：影响算分</p><p>前面我们提到，当前两个操作是会对匹配的文档进行算分的。</p><ul><li>对于 es 来说，query context 的语义就是寻找最接近用户意愿的数据，固然会对 query context 的&quot;查询条件&quot;对商品进行匹配并进行匹配相关度的计算。</li><li>而 should 的语义也是寻找最接近用户意愿的数据，只不过 should 是包含一项仅匹配，且有它自己维度的算分规则。</li></ul><p>可以看到经过下面的 should 条件 或者 term query context 匹配到的文档是有分值的。然后在最顶层属性会有一个&quot;max_score&quot;属性用来聚合当前查询所有文档的分值表示当前查询的分值。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212443.png" alt="image-20200425130426352"></p><p>示例二：Filter Context 和 must_not 查询不会进行算分</p><p>可以看到下面的查询中只有 filter 和 must_not 条件：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212449.png" alt="image-20200425130212003"></p><ul><li>filter 的语意就是过滤，es认为这个功能仅仅就是筛选出匹配的数据即可，所以经过这个条件命中出来的文档分值都是0。（当然，如果有一个 should 或者 must 条件也命中了这个文档，那么应该就是将这两个条件计算的分值相加，然后加上当前 filter 的分值0得到这个文档的最终分值）</li><li>而 must_not 的语义是用户想要排除这些数据，只要剩下的数据，那么返回的文档就是剩下的数据，理所当然的 must_not 条件并不是&quot;匹配&quot;了这些文档数据，也就没有&quot;查询条件匹配相关度&quot;这么个概念了，固然不会进行分值计算，所以经过排除 must_not 之后返回的文档没有被should 或者 must 条件命中，分值就是0。如果命中了，就按照上面提到的计算方式计算分值。</li></ul><p>根据上面的规则对每个返回的文档的分值进行计算并返回分值。然后也会对当前查询的所有分值进行汇总。</p><h4 id="4、bool-嵌套"><a class="header-anchor" href="#4、bool-嵌套">¶</a>4、bool 嵌套</h4><p>另外，bool 复合查询是支持嵌套的。下面的例子是利用嵌套 bool 实现&quot;shuold not&quot;的逻辑</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212456.png" alt="image-20200425132255987"></p><h4 id="5、-bool-语句结构影响算分"><a class="header-anchor" href="#5、-bool-语句结构影响算分">¶</a>5、 bool 语句结构影响算分</h4><p>bool 查询语句的结构是会对相关度算分产生影响的：</p><ul><li>同一层级下的竞争字段，具有相同的权重</li><li>通过嵌套 bool 查询，可以改变对算分的影响</li></ul><p>看下面的例子，我们通过将左边的颜色下放一层，导致关于颜色的匹配算分低于其他算分</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212502.png" alt="image-20200425152642186"></p><h4 id="6、控制字段的-Boosting"><a class="header-anchor" href="#6、控制字段的-Boosting">¶</a>6、控制字段的 Boosting</h4><p>在&quot;搜索的相关性算法&quot;的章节我们提到可以通过 Boosting 控制算分的逻辑，其中可以索引mapping、字段 mapping 以及查询中进行boosting 控制。</p><p>下面是 bool 查询中进行 boosting 修改的一个例子。可以看到我们建立了一个索引写入了两个文档，其中包含两个字段 title 和 content，我们并没有对索引进行 mapping 定义，所以是动态生成的，boosting 的值都是默认的。</p><p>下面我们对这个索引进行一个 bool 查询，可以看到一个 bool 查询中包含了两个 match 查询，分别是针对 title 字段和 content 字段，而这两个字段的查询的内容都是一样的&quot;apple ipad&quot;。其中我们还对这两个查询分别定义了不同的 boost。</p><p>此时我们设置 title match 查询的 boost 是4，content match 查询的 boost 是1，那么我们插入的两个文档将都会被命中返回。因为 title match 的 boost 值较高，所以针对 title 字段的算分权重高，那么由于文档2的 title字段包含了两个&quot;Apple iPad&quot;，固然返回结果中文档2会排在文档1前面。但是如果我们将它们的两个 boost 值互调，那么返回的排序就也会互调了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212508.png" alt="image-20200425153207293"></p><h4 id="7、Not-Quite-Not"><a class="header-anchor" href="#7、Not-Quite-Not">¶</a>7、Not Quite Not</h4><p>我们看下面这样的一个例子。我们插入三条文档数据。然后通过 bool 复合 match 查询 content 中包含 apple 的新闻。可以看到三条文档数据都返回了。但是实际上我们只是想查询关于苹果公司产品新闻，排在第一位的新闻是&quot;苹果公司员工喜欢苹果派和苹果汁&quot;，不是我们想要的数据。我们可以怎样优化呢？看下面操作</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212514.png" alt="image-20200425155444685"></p><ol><li><p>那么我们可以做以下修改，加入一个 must_not 的 bool 查询，这样我们就会过滤掉包含&quot;派&quot;的数据：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212521.png" alt="image-20200425155750331"></p></li><li><p>但是有时候我们并不是想直接过滤这些其他数据，而是想将它排在较后面的位置，那么我们可以使用 boosting 查询，将&quot;派&quot;纳入到贡献负分的 boosting-negative 查询中，并设置贡献分值为0.5，这样就能实现我们想要的效果了</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212526.png" alt="image-20200425155933321"></p></li></ol><h4 id="8、相关阅读"><a class="header-anchor" href="#8、相关阅读">¶</a>8、相关阅读</h4><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-filter-context.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/query-filter-context.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-boosting-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-boosting-query.html</a></p><h4 id="9、Kibana-测试请求"><a class="header-anchor" href="#9、Kibana-测试请求">¶</a>9、Kibana 测试请求</h4><pre><code>POST /products/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 }}{ &quot;price&quot; : 10,&quot;avaliable&quot;:true,&quot;date&quot;:&quot;2018-01-01&quot;, &quot;productID&quot; : &quot;XHDK-A-1293-#fJ3&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 }}{ &quot;price&quot; : 20,&quot;avaliable&quot;:true,&quot;date&quot;:&quot;2019-01-01&quot;, &quot;productID&quot; : &quot;KDKE-B-9947-#kL5&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 3 }}{ &quot;price&quot; : 30,&quot;avaliable&quot;:true, &quot;productID&quot; : &quot;JODL-X-1937-#pV7&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 4 }}{ &quot;price&quot; : 30,&quot;avaliable&quot;:false, &quot;productID&quot; : &quot;QQPX-R-3956-#aD8&quot; }#基本语法POST /products/_search{  &quot;query&quot;: {    &quot;bool&quot; : {      &quot;must&quot; : {        &quot;term&quot; : { &quot;price&quot; : &quot;30&quot; }      },      &quot;filter&quot;: {        &quot;term&quot; : { &quot;avaliable&quot; : &quot;true&quot; }      },      &quot;must_not&quot; : {        &quot;range&quot; : {          &quot;price&quot; : { &quot;lte&quot; : 10 }        }      },      &quot;should&quot; : [        { &quot;term&quot; : { &quot;productID.keyword&quot; : &quot;JODL-X-1937-#pV7&quot; } },        { &quot;term&quot; : { &quot;productID.keyword&quot; : &quot;XHDK-A-1293-#fJ3&quot; } }      ],      &quot;minimum_should_match&quot; :1    }  }}#改变数据模型，增加字段。解决数组包含而不是精确匹配的问题POST /newmovies/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 }}{ &quot;title&quot; : &quot;Father of the Bridge Part II&quot;,&quot;year&quot;:1995, &quot;genre&quot;:&quot;Comedy&quot;,&quot;genre_count&quot;:1 }{ &quot;index&quot;: { &quot;_id&quot;: 2 }}{ &quot;title&quot; : &quot;Dave&quot;,&quot;year&quot;:1993,&quot;genre&quot;:[&quot;Comedy&quot;,&quot;Romance&quot;],&quot;genre_count&quot;:2 }#must，有算分POST /newmovies/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: [        {&quot;term&quot;: {&quot;genre.keyword&quot;: {&quot;value&quot;: &quot;Comedy&quot;}}},        {&quot;term&quot;: {&quot;genre_count&quot;: {&quot;value&quot;: 1}}}      ]    }  }}#Filter。不参与算分，结果的score是0POST /newmovies/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;filter&quot;: [        {&quot;term&quot;: {&quot;genre.keyword&quot;: {&quot;value&quot;: &quot;Comedy&quot;}}},        {&quot;term&quot;: {&quot;genre_count&quot;: {&quot;value&quot;: 1}}}        ]    }  }}#Filtering ContextPOST _search{  &quot;query&quot;: {    &quot;bool&quot; : {      &quot;filter&quot;: {        &quot;term&quot; : { &quot;avaliable&quot; : &quot;true&quot; }      },      &quot;must_not&quot; : {        &quot;range&quot; : {          &quot;price&quot; : { &quot;lte&quot; : 10 }        }      }    }  }}#Query ContextPOST /products/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 }}{ &quot;price&quot; : 10,&quot;avaliable&quot;:true,&quot;date&quot;:&quot;2018-01-01&quot;, &quot;productID&quot; : &quot;XHDK-A-1293-#fJ3&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 }}{ &quot;price&quot; : 20,&quot;avaliable&quot;:true,&quot;date&quot;:&quot;2019-01-01&quot;, &quot;productID&quot; : &quot;KDKE-B-9947-#kL5&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 3 }}{ &quot;price&quot; : 30,&quot;avaliable&quot;:true, &quot;productID&quot; : &quot;JODL-X-1937-#pV7&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 4 }}{ &quot;price&quot; : 30,&quot;avaliable&quot;:false, &quot;productID&quot; : &quot;QQPX-R-3956-#aD8&quot; }POST /products/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;should&quot;: [        {          &quot;term&quot;: {            &quot;productID.keyword&quot;: {              &quot;value&quot;: &quot;JODL-X-1937-#pV7&quot;}}        },        {&quot;term&quot;: {&quot;avaliable&quot;: {&quot;value&quot;: true}}        }      ]    }  }}#嵌套，实现了 should not 逻辑POST /products/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: {        &quot;term&quot;: {          &quot;price&quot;: &quot;30&quot;        }      },      &quot;should&quot;: [        {          &quot;bool&quot;: {            &quot;must_not&quot;: {              &quot;term&quot;: {                &quot;avaliable&quot;: &quot;false&quot;              }            }          }        }      ],      &quot;minimum_should_match&quot;: 1    }  }}#Controll the PrecisionPOST _search{  &quot;query&quot;: {    &quot;bool&quot; : {      &quot;must&quot; : {        &quot;term&quot; : { &quot;price&quot; : &quot;30&quot; }      },      &quot;filter&quot;: {        &quot;term&quot; : { &quot;avaliable&quot; : &quot;true&quot; }      },      &quot;must_not&quot; : {        &quot;range&quot; : {          &quot;price&quot; : { &quot;lte&quot; : 10 }        }      },      &quot;should&quot; : [        { &quot;term&quot; : { &quot;productID.keyword&quot; : &quot;JODL-X-1937-#pV7&quot; } },        { &quot;term&quot; : { &quot;productID.keyword&quot; : &quot;XHDK-A-1293-#fJ3&quot; } }      ],      &quot;minimum_should_match&quot; :2    }  }}POST /animals/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;should&quot;: [        { &quot;term&quot;: { &quot;text&quot;: &quot;brown&quot; }},        { &quot;term&quot;: { &quot;text&quot;: &quot;red&quot; }},        { &quot;term&quot;: { &quot;text&quot;: &quot;quick&quot;   }},        { &quot;term&quot;: { &quot;text&quot;: &quot;dog&quot;   }}      ]    }  }}POST /animals/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;should&quot;: [        { &quot;term&quot;: { &quot;text&quot;: &quot;quick&quot; }},        { &quot;term&quot;: { &quot;text&quot;: &quot;dog&quot;   }},        {          &quot;bool&quot;:{            &quot;should&quot;:[               { &quot;term&quot;: { &quot;text&quot;: &quot;brown&quot; }},                 { &quot;term&quot;: { &quot;text&quot;: &quot;brown&quot; }},            ]          }        }      ]    }  }}DELETE blogsPOST /blogs/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 }}{&quot;title&quot;:&quot;Apple iPad&quot;, &quot;content&quot;:&quot;Apple iPad,Apple iPad&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 }}{&quot;title&quot;:&quot;Apple iPad,Apple iPad&quot;, &quot;content&quot;:&quot;Apple iPad&quot; }POST blogs/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;should&quot;: [        {&quot;match&quot;: {          &quot;title&quot;: {            &quot;query&quot;: &quot;apple,ipad&quot;,            &quot;boost&quot;: 1.1          }        }},        {&quot;match&quot;: {          &quot;content&quot;: {            &quot;query&quot;: &quot;apple,ipad&quot;,            &quot;boost&quot;:          }        }}      ]    }  }}DELETE newsPOST /news/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 }}{ &quot;content&quot;:&quot;Apple Mac&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 }}{ &quot;content&quot;:&quot;Apple iPad&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 3 }}{ &quot;content&quot;:&quot;Apple employee like Apple Pie and Apple Juice&quot; }POST news/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: {        &quot;match&quot;:{&quot;content&quot;:&quot;apple&quot;}      }    }  }}POST news/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;must&quot;: {        &quot;match&quot;:{&quot;content&quot;:&quot;apple&quot;}      },      &quot;must_not&quot;: {        &quot;match&quot;:{&quot;content&quot;:&quot;pie&quot;}      }    }  }}POST news/_search{  &quot;query&quot;: {    &quot;boosting&quot;: {      &quot;positive&quot;: {        &quot;match&quot;: {          &quot;content&quot;: &quot;apple&quot;        }      },      &quot;negative&quot;: {        &quot;match&quot;: {          &quot;content&quot;: &quot;pie&quot;        }      },      &quot;negative_boost&quot;: 0.5    }  }}</code></pre><h1>单字符串多字段查询</h1><h3 id="单字符串查询"><a class="header-anchor" href="#单字符串查询">¶</a>单字符串查询</h3><p>例如像搜索引擎 google 只提供了一个输入框，底层是查询相关的多个字段，支持按照价格、时间等其他字段进行过滤。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212539.png" alt="image-20200425161137411"></p><h3 id="Disjunction-Max-Query"><a class="header-anchor" href="#Disjunction-Max-Query">¶</a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-dis-max-query.html" target="_blank" rel="noopener">Disjunction Max Query</a></h3><h4 id="1、单字符串多字段查询的算分排序问题"><a class="header-anchor" href="#1、单字符串多字段查询的算分排序问题">¶</a>1、单字符串多字段查询的算分排序问题</h4><p>我们插入两个文档到索引中：</p><ul><li>第一个文档的标题是&quot;敏捷的灰兔子&quot;，内容是&quot;灰兔子是很常见的&quot;。</li><li>第二个文档的标题是&quot;保持宠物的健康&quot;，内容是&quot;我的敏捷的灰色狐狸会定期地吃兔子&quot;。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212546.png" alt="image-20200425184604609"></p><p>此时我们同时对标题和内容搜索&quot;Brown fox&quot;，希望优先搜索到关于&quot;灰色狐狸&quot;的内容，要不然搜索到&quot;灰色&quot;或者&quot;狐狸&quot;也是可以的。现在我们发出一个 bool_should query：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212553.png" alt="image-20200425184626266"></p><p>但是发现返回结果虽然两条内容都返回了，文档1却排在文档2的前面，这并不符合我们的预期，因为文档2的内容里面是拥有&quot;brown fox&quot;这个&quot;连贯&quot;（前后顺序一致）的 term 组合的。为什么会出现这样的情况呢？ 请看以下内容。</p><h4 id="2、Dis-Max-Query解决该场景问题"><a class="header-anchor" href="#2、Dis-Max-Query解决该场景问题">¶</a>2、Dis-Max Query解决该场景问题</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212558.png" alt="image-20200425192332460"></p><p>我们通过&quot;explain&quot;分析 should 查询的算分过程，得知它的逻辑是将每一个获得匹配的 match 查询的算分进行相加，而 match 查询的算分则是将查询内容拆解出来的所有 term 在当前文档当前字段的 TF*IDF 之后进行相加。</p><ul><li>查询 should 语句中的两个查询</li><li>加和两个查询的评分</li><li>乘以匹配语句的总数?</li><li>处理所有语句的总数?</li></ul><p>简单来说，should 查询就是将所有 term 在所有匹配字段的算分进行相加。那么上面的查询对于第一个文档来说 brown 字段在 title 和 body 字段同时命中，而第二个文档只在 body 字段命中了 brown 字段和 fox 字段，因为 brown 字段长度比 fox 长，文档一的两个字段都比文档二的两个字段要短，最终相加出来的评分必然比文档二大。</p><p>经过上面的分析我们找到的问题的所在，根据我们的需求，查询&quot;Brown fox&quot;虽然是希望可以跨字段查询，但是我们想优先得到的文档是在标题或者内容中同时包含&quot;Brown fox&quot;，<strong>此时它作为一个词组出现的意义相对更高</strong>。但是我们又希望可以查询到&quot;brown&quot;或者&quot;fox&quot;的内容，只不过放在后面而已。 <strong>所以我们需要的应该是这样一个查询语义：任何被检索到的文档将其匹配评分最高的字段作为该文档的评分进行返回</strong>，而不是 bool 的累加所有字段的评分。此时我们可以引进 <strong>Disjuction Max Query</strong>，它的查询语义就是如此。</p><p>看下面的操作，就可以得到我们想要的效果</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212606.png" alt="image-20200425190909309"></p><blockquote><p>以上关于&quot;brown fox&quot;的例子可能不是很恰当，我们的实际需求可能也不是这样子的。但是针对单个字段作为文档的最高评分返回这个需求肯定是有的。所以先了解、理解这个功能吧。遇到了需求自然就懂了。</p></blockquote><h4 id="3、通过-Tie-Breaker-参数进行优化调整"><a class="header-anchor" href="#3、通过-Tie-Breaker-参数进行优化调整">¶</a>3、通过 Tie Breaker 参数进行优化调整</h4><p>通过上面的例子了解了 Disjuction Max Query 之后，我们来看下面的例子，我们还是基于上面的索引和文档进行查询，本次是同时对 title 和 body 检索&quot;Quick pets&quot;，可以看到右边显示的结果是两个文档的分值都是一样的。这就引出一个新问题：</p><p>有一些情况下，所有文档都没有字段同时存在&quot;Quick&quot;和&quot;pets&quot;，即我们所检索的内容作为一个词组存在与某个文档的字段中，现在我们的需求就退化了，希望优先得到&quot;<strong>所有字段尽量匹配</strong>&quot;的数据。但是我们发现，在下面的例子中，文档1的标题中匹配了一个 quick，而文档2的标题中匹配了一个  pets，内容中匹配了一个quick，文档2才是我们优先想得到的文档。而 Disjuction Max Query 仅仅是得到最优匹配字段的分值作为文档分值返回，那么文档1的最优匹配字段自然是匹配了 “quick” 的 title 了，而文档2也是匹配了&quot;pets&quot;的 title，所以导致它们分值一致。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212612.png" alt="image-20200425193552947"></p><p>针对上面的问题，我们引入了 Disjuction Max Query 的一个属性Tie Breaker进行优化，这个属性的语义是：</p><ol><li>获得最佳匹配语句的评分_score，</li><li>将其他匹配语句的评分与 tie_breaker 相乘</li><li>对以上评分求和并规范化作为整个 Disjuction Max Query 的评分返回</li></ol><blockquote><p>Tie Breaker 是一个介于0-1之间的浮点数。0代表使用最佳匹配；1代表所有语句同等重要，即退化成了 bool_should 查询。</p></blockquote><p>我们加上该属性进行查询，得到了想要的效果：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212621.png" alt="image-20200425194957062"></p><p>加上 expain 查看算分过程：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212627.png" alt="image-20200425195144954"></p><h4 id="4、Kibana-测试请求"><a class="header-anchor" href="#4、Kibana-测试请求">¶</a>4、Kibana 测试请求</h4><pre><code>PUT /blogs/_doc/1{    &quot;title&quot;: &quot;Quick brown rabbits&quot;,    &quot;body&quot;:  &quot;Brown rabbits are commonly seen.&quot;}PUT /blogs/_doc/2{    &quot;title&quot;: &quot;Keeping pets healthy&quot;,    &quot;body&quot;:  &quot;My quick brown fox eats rabbits on a regular basis.&quot;}POST /blogs/_search{    &quot;query&quot;: {        &quot;bool&quot;: {            &quot;should&quot;: [                { &quot;match&quot;: { &quot;title&quot;: &quot;Brown fox&quot; }},                { &quot;match&quot;: { &quot;body&quot;:  &quot;Brown fox&quot; }}            ]        }    }}POST blogs/_search{    &quot;query&quot;: {        &quot;dis_max&quot;: {            &quot;queries&quot;: [                { &quot;match&quot;: { &quot;title&quot;: &quot;Quick pets&quot; }},                { &quot;match&quot;: { &quot;body&quot;:  &quot;Quick pets&quot; }}            ]        }    }}POST blogs/_search{    &quot;query&quot;: {        &quot;dis_max&quot;: {            &quot;queries&quot;: [                { &quot;match&quot;: { &quot;title&quot;: &quot;Quick pets&quot; }},                { &quot;match&quot;: { &quot;body&quot;:  &quot;Quick pets&quot; }}            ],            &quot;tie_breaker&quot;: 0.2        }    }}</code></pre><h3 id="Multi-Match-Query"><a class="header-anchor" href="#Multi-Match-Query">¶</a>Multi Match Query</h3><p>对于单字符串多字段查询有以下三种查询场景：</p><h4 id="1、最佳字段（Best-Fields）"><a class="header-anchor" href="#1、最佳字段（Best-Fields）">¶</a>1、最佳字段（Best Fields）</h4><p>当字段之间相互竞争，又相互关联。例如上面的 title 和 body 这样的字段。评分来自最佳匹配字段。该场景我们可以使用上面的 disjuction max query 实现，也可以使用这里介绍的 multi match query 实现。</p><p>在这种查询场景下，以我们上面的例子为例，multi_match 查询的实现调用如下（可以达到和 dis-max query 一样的效果）：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212635.png" alt="image-20200425203340340"></p><ul><li>Best Fields 是默认类型，可以不用指定</li><li>Minimum should Match 等参数可以传递到生成的 query 中</li></ul><h4 id="2、多数字段（Most-Fileds）"><a class="header-anchor" href="#2、多数字段（Most-Fileds）">¶</a>2、多数字段（Most Fileds）</h4><p>在处理多字段检索英文内容的时，一种常见的手段是：</p><ul><li>针对检索内容的&quot;<strong>主要或者重要字段</strong>&quot;字段设置分词器为 English Analyzer，该分词器会抽取英文词干（过去时、现在进行时、派生词等相关词语），将相同词干的词语加入同义词，这样我们对该字段进行检索的时候可以匹配更多的文档（提高 recall）；然后为该字段增加一个子字段，该子字段使用 Standard Analyzer，该分词器仅提供简单的分词操作，匹配会更加精准（提高 precision）。</li><li>检索内容的其他字段作为匹配文档提高相关度的信号，匹配字段越多越好。</li></ul><h5 id="案例和问题"><a class="header-anchor" href="#案例和问题">¶</a>案例和问题</h5><p>查看下面的截图，我们先建立包含一个 text 类型的 title 字段的索引，并为该字段指定英文分词器。然后输入两个文档。并执行了一个对 title 字段执行了一个&quot;barking dogs&quot;的 match 查询。右边是返回结果，我们看到，title 内容为&quot;my dog barks&quot;的文档的分值要比&quot;I see a lot of barking dogs on the road&quot;的分值要高，但是第二个文档中是包含&quot;barking dogs&quot;这个完整内容的，这显然不符合我们预期。<strong>这是因为英文分词器会对字段内容进行词干抽取加入同义词进行索引和检索</strong>，所以&quot;barking&quot;和&quot;barks&quot;都会映射到&quot;bark&quot;索引上，&quot;dogs&quot;会映射到&quot;dog&quot;上，即&quot;barking dogs&quot;最终被解释为&quot;bark&quot;和&quot;dog&quot;两个词条来进行索引和检索，而文档1和文档2都命中了 barking 和 dogs，但是文档1更短，固然分值更高。</p><p>那么我们现在遇到的问题是，我们想保证这两个文档都被命中返回，但是文档2的内容分值更高。也就是在保证尽量多地返回相关文档（recall）的同时保证更准确的文档排在最前面（precision）。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212641.png" alt="image-20200425204850031"></p><h5 id="解决问题"><a class="header-anchor" href="#解决问题">¶</a>解决问题</h5><p>此时我们就引入了我们讲到的 Most Field 了。如下图，我们重构了索引，为字段 title 增加了一个子字段&quot;std&quot;，并为其指定类型为和 title 一样的 text，但是分词器指定为 standard。</p><p>此时我们在执行查询语句的时候，使用了 multi_match 的 most_fields 查询，指定检索内容&quot;query&quot;为&quot;barking dogs&quot;，字段为&quot;title&quot;和&quot;title.std&quot;。这样就能达到我们想要的效果了，两个文档都返回，但是文档2排在前面。</p><p>下面两张截图是加了&quot;explain&quot;之后返回的结果，通过 explain 我们知道，对于检索内容&quot;barking dogs&quot;，es 先对其在 title 字段上进行了检索，自然的两个文档都匹配了，所以必然两个文档都会返回；然后对该字符串在 title.std 字段上进行检索，此时只会有文档2匹配；后面就是算分环节了，文档1命中了字段 title，所以算分就是针对词条&quot;bark&quot;和&quot;dog&quot;的算分总和，而文档2同时命中了字段 title 和 title.std，所以其算分为针对词条&quot;bark&quot;、“dog”、&quot;barking&quot;和&quot;dogs&quot;算分的总和，所以文档2算分大于文档1。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212647.png" alt="image-20200425205824661"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212653.png" alt="image-20200425210534498"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212700.png" alt="image-20200425210548518"></p><h5 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h5><ul><li><p>用广度匹配字段 title 包含尽可能多的文档以提升召回率，同时又使用 title.std 作为信号将相关度更高的问答那个置于结果顶部。</p></li><li><p>每个字段对于最终评分的贡献可以通过自定义值 boost 来控制。比如，我们的文档中可能不只 title 这么一个字段可能还有很多其他的字段，我们为了使得 title 字段更为重要，同时也降低了其他信号字段的作用。（设置 boost 如下所示在字段后面通过&quot;^&quot;符号紧跟一个 boost 值）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212711.png" alt="image-20200425211246523"></p></li></ul><h4 id="3、混合字段（Cross-Field）"><a class="header-anchor" href="#3、混合字段（Cross-Field）">¶</a>3、混合字段（Cross Field）</h4><p>对于某些实体，例如&quot;人&quot;这个实体，拥有人名、地址、图书信息等这些字段信息。我们需要在这多个字段中检索我们想要查询的信息，而单个字段只能作为整体的一部分。希望在任何这些列出的字段中找到尽可能多的词。</p><h5 id="案例和问题-v2"><a class="header-anchor" href="#案例和问题-v2">¶</a>案例和问题</h5><p>下面是一个地址的文档信息：<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212719.png" alt="image-20200425211810699"></p><p>当我们对于一个输入字符串想对这个包含多个字段的地址文档进行检索的时候，我们想到了可以使用 Multi Match-most_fields query实现。但是使用 most_fields 只能在一定程度上实现这个需求，即类似下面这样的搜索，我们认为用户的搜索的内容是一个非结构化的内容，会经过拆分之后形成一个个词条，这些词条允许在不同的字段上被检索到，只要所有词条都能被检索到我们就认为这个文档是匹配的，进行返回与算分：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212724.png" alt="image-20200425211819075"></p><p>但是如果我们的需求产生了变化，认为用户的输入无论是否一个结构化的内容，它最终形成的词条都只能在文档的某一个或者多个字段完全涵盖才算匹配，即使是多个字段分别涵盖这些词条我们也不能认为它是匹配，面对这样的场景most_fields 就不能满足了，我们也不能对它和 Match Query 一样加上一个And Operator 来解决。（为 most_fields 增加And Operator 调用查询 api 是不会报错的，但是返回结果却不是我们的预期效果，本实验返回空）</p><p>虽然针对上面的需求，我们可以用前面提到的 copy_to 将多字段内容复制到同一个字段上，<strong>但是这样需要花费额外的空间，且原本算分可能也会受到影响。</strong></p><h5 id="解决问题-v2"><a class="header-anchor" href="#解决问题-v2">¶</a>解决问题</h5><p>此时我们就引入了 multi_match 的 coress_fields query，它可以完全解决这样的场景：</p><ul><li>支持使用 Operator</li><li>与 copy_to 相比，其中一个优势就是它可以在搜索的时为单个字段提升权重</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212731.png" alt="image-20200425213510342"></p><h1>多语言及中文分词与检索</h1><h3 id="自然语言与查询-recall"><a class="header-anchor" href="#自然语言与查询-recall">¶</a>自然语言与查询 recall</h3><ol><li>当处理人类自然语言时，有些情况，尽管搜索和原文不完全匹配，但是希望搜到一些内容<ul><li>Quick brown fox 和 fast brown fox</li><li>Jumping fox 和 Jumped foxes</li></ul></li><li>一些可采取的优化<ul><li>归一化词元：清除变音符号，如 ròle 的时候也会匹配role</li><li>抽取词根：清除单复数和时态的差异</li><li>包含同义词</li><li>拼写错误或者同音异形词</li></ul></li></ol><h3 id="混合多语言的挑战"><a class="header-anchor" href="#混合多语言的挑战">¶</a>混合多语言的挑战</h3><ol><li><p>一些具体的多语言场景</p><ul><li>不同的索引使用不同的语言</li><li>同一个索引中，不同的字段</li><li>一个文档的一个字段内混合不同的语言</li></ul></li><li><p>混合语言存在的一些挑战</p><ul><li>词干提取：以色列文档，包含了希伯来语、阿拉伯语、俄语和英文</li><li>不正确的文档频率：英文为主的文章中，德文算分高（因为德文的出现频率很低，一旦对德文进行检索，自然算分高）</li><li>需要判断用户搜索时使用的语言，语言识别（Compact Language Detector），然后根据语言查询不同的索引。</li></ul></li><li><p>一个搜索条件(框)支持多语言查询方案</p><ul><li><p>不同语言用不同索引，例如 orders-cn ，orders-en</p></li><li><p>可以通过设置mulfi field创建多个子字段，这个子字段可以使用不同的分词器。</p><p>至于用户在搜索的时候使用什么语言，可以让用户指定，或者通过http header中的accept language来判定。</p></li></ul><p>至于索引的数据，如果你明确知道他所用的语言，用方案一会很简单。否则你需要使用一个学习算法对文档的语言进行归类。有一些现成的库可以使用，例如：chromiu-compact-language-detector ，基于google的CLD开发，支持160多种语言的detect。</p></li></ol><h3 id="分词的挑战"><a class="header-anchor" href="#分词的挑战">¶</a>分词的挑战</h3><ol><li><p>英文分词：You’re 分成一个还是多个？Half-baked 中间的横杠是否去掉。</p></li><li><p>中文分词</p><ul><li><p>分词标准不同：哈工大标准中，姓和名是分开的；HanLP 分词是在一起的。具体情况需指定不同的标准</p></li><li><p>歧义（组合型歧义、交集型歧义、真歧义）</p><p>中华人民共和国、美国会通过对台售武法案、上海仁和服装厂</p></li></ul></li></ol><h3 id="中文分词方法的演变-字典法"><a class="header-anchor" href="#中文分词方法的演变-字典法">¶</a>中文分词方法的演变-字典法</h3><ol><li>查字典：最容易想到的分词方法（北京航空大学的梁南元教授提出）<ul><li>一个句子从左到右扫描一遍。遇到有的词就标示出来。找到复合词，就找最长的</li><li>不认识的字串就分隔成单字词</li></ul></li><li>最小词数的分词理论：哈工大王晓龙博士把查字典的方法理论化<ul><li>一句话应该分成数量最少的词串</li><li>遇到二义性的分割，无能为力（例如：“发展中国家”、“上海大学城书店”）</li><li>用各种文化规则来解决二义性都不成功</li></ul></li></ol><h3 id="中文分词方法的演变-基于统计法的机器学习算法"><a class="header-anchor" href="#中文分词方法的演变-基于统计法的机器学习算法">¶</a>中文分词方法的演变-基于统计法的机器学习算法</h3><ol><li><p>统计语言模型：1990年前后，清华大学电子工程系郭进博士</p><p>解决了二义性问题，将中文分词的错误率降低了一个数量级。概率问题，动态规划+利用维特比算法快速找到最佳分词</p></li><li><p>基于统计的机器学习算法</p><ul><li>这类目前常用的算法是 HMM、CRF、SVM、深度学习等算法。比如 HanLP 分词工具是基于 CRF 算法，以CRF 为例，基本思路是对汉子进行标注训练，不仅考虑了词语出现的频率，还考虑上下文，具备较好的学习能力，因此其对歧义词和未登录词的识别都具有良好的效果。</li><li>随着深度学习的兴起，也出现了基于神经网络的分词器，有人尝试使用双向 LSTM+CRF 实现分词器，其本质上是序列标注，据报道其分词器字符准确率可高达97.5%</li></ul></li></ol><h3 id="中文分词器现状"><a class="header-anchor" href="#中文分词器现状">¶</a>中文分词器现状</h3><ol><li>中文分词器以统计语言模型为基础，经过几十年的发展，今天基本已经可以看做是一个已经解决的问题。</li><li>不同分词器的好坏，主要的差别在于数据的使用和工程使用的精度</li><li>常见的分词都是使用机器学习算法和词典相结合，一方面能够提高分词准确率，另一方面能够改善领域适应性。</li></ol><h3 id="一些中文分词器"><a class="header-anchor" href="#一些中文分词器">¶</a>一些中文分词器</h3><ul><li><p>HanLP：面相生产环境的自然语言处理工具包</p><p><a href="http://hanlp.com/" target="_blank" rel="noopener">http://hanlp.com/</a></p><p><a href="https://github.com/KennFalcon/elasticsearch-analysis-hanlp" target="_blank" rel="noopener">https://github.com/KennFalcon/elasticsearch-analysis-hanlp</a></p></li><li><p>IK 分词器</p><p><a href="https://github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">https://github.com/medcl/elasticsearch-analysis-ik</a></p></li></ul><h4 id="HanLP-Analysis"><a class="header-anchor" href="#HanLP-Analysis">¶</a>HanLP Analysis</h4><p>Es 插件下载：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">./elasticsearch-plugin install https://github.com/KennFalcon/elasticsearch-analysis- hanlp/releases/download/v7.1.0/elasticsearch-analysis-hanlp-7.1.0.zip<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>支持远程词典配置：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212740.png" alt="image-20200425223736717"></p><h4 id="IK-Analysis"><a class="header-anchor" href="#IK-Analysis">¶</a>IK Analysis</h4><p>Es 插件下载：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">./elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.1.0/elasticsearch-analysis-ik-7.1.0.zip<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>支持字典热更更新</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212745.png" alt="image-20200425223843999"></p><h4 id="Pinyin-Analysis"><a class="header-anchor" href="#Pinyin-Analysis">¶</a>Pinyin Analysis</h4><p>Es 插件下载：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">./elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis- pinyin/releases/download/v7.1.0/elasticsearch-analysis-pinyin-7.1.0.zip<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212751.png" alt="image-20200425223920933"></p><h3 id="相关资源"><a class="header-anchor" href="#相关资源">¶</a>相关资源</h3><p><a href="https://github.com/medcl/elasticsearch-analysis-ik/releases" target="_blank" rel="noopener">Elasticsearch IK分词插件</a></p><p><a href="https://github.com/KennFalcon/elasticsearch-analysis-hanlp" target="_blank" rel="noopener">Elasticsearch hanlp 分词插件</a></p><p><a href="https://zhuanlan.zhihu.com/p/50444885" target="_blank" rel="noopener">分词算法综述</a></p><p><strong>一些分词工具，供参考：</strong></p><p><a href="http://ictclas.nlpir.org/nlpir/" target="_blank" rel="noopener">中科院计算所NLPIR</a></p><p><a href="https://github.com/NLPchina/ansj_seg" target="_blank" rel="noopener">ansj分词器</a></p><p><a href="https://github.com/HIT-SCIR/ltp" target="_blank" rel="noopener">哈工大的LTP</a></p><p><a href="https://github.com/thunlp/THULAC" target="_blank" rel="noopener">清华大学THULAC</a></p><p><a href="https://nlp.stanford.edu/software/segmenter.shtml" target="_blank" rel="noopener">斯坦福分词器</a></p><p><a href="https://github.com/hankcs/HanLP" target="_blank" rel="noopener">Hanlp分词器</a></p><p><a href="https://github.com/yanyiwu/cppjieba" target="_blank" rel="noopener">结巴分词</a></p><p><a href="https://github.com/koth/kcws" target="_blank" rel="noopener">KCWS分词器(字嵌入+Bi-LSTM+CRF)</a></p><p><a href="https://github.com/frcchang/zpar/releases" target="_blank" rel="noopener">ZPar</a></p><p><a href="https://github.com/wks/ik-analyzer" target="_blank" rel="noopener">IKAnalyzer</a></p><h3 id="Kibana-测试请求-v2"><a class="header-anchor" href="#Kibana-测试请求-v2">¶</a>Kibana 测试请求</h3><pre><code>#stop wordDELETE my_indexPUT /my_index/_doc/1{ &quot;title&quot;: &quot;I'm happy for this fox&quot; }PUT /my_index/_doc/2{ &quot;title&quot;: &quot;I'm not happy about my fox problem&quot; }POST my_index/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;title&quot;: &quot;not happy fox&quot;    }  }}#虽然通过使用 english （英语）分析器，使得匹配规则更加宽松，我们也因此提高了召回率，但却降低了精准匹配文档的能力。为了获得两方面的优势，我们可以使用multifields（多字段）对 title 字段建立两次索引： 一次使用 `english`（英语）分析器，另一次使用 `standard`（标准）分析器:DELETE my_indexPUT /my_index{  &quot;mappings&quot;: {    &quot;blog&quot;: {      &quot;properties&quot;: {        &quot;title&quot;: {          &quot;type&quot;: &quot;string&quot;,          &quot;analyzer&quot;: &quot;english&quot;        }      }    }  }}PUT /my_index{  &quot;mappings&quot;: {    &quot;blog&quot;: {      &quot;properties&quot;: {        &quot;title&quot;: {          &quot;type&quot;: &quot;string&quot;,          &quot;fields&quot;: {            &quot;english&quot;: {              &quot;type&quot;:     &quot;string&quot;,              &quot;analyzer&quot;: &quot;english&quot;            }          }        }      }    }  }}PUT /my_index/blog/1{ &quot;title&quot;: &quot;I'm happy for this fox&quot; }PUT /my_index/blog/2{ &quot;title&quot;: &quot;I'm not happy about my fox problem&quot; }GET /_search{  &quot;query&quot;: {    &quot;multi_match&quot;: {      &quot;type&quot;:     &quot;most_fields&quot;,      &quot;query&quot;:    &quot;not happy foxes&quot;,      &quot;fields&quot;: [ &quot;title&quot;, &quot;title.english&quot; ]    }  }}#安装插件./elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.1.0/elasticsearch-analysis-ik-7.1.0.zip#安装插件bin/elasticsearch install https://github.com/KennFalcon/elasticsearch-analysis-hanlp/releases/download/v7.1.0/elasticsearch-analysis-hanlp-7.1.0.zip#ik_max_word#ik_smart#hanlp: hanlp默认分词#hanlp_standard: 标准分词#hanlp_index: 索引分词#hanlp_nlp: NLP分词#hanlp_n_short: N-最短路分词#hanlp_dijkstra: 最短路分词#hanlp_crf: CRF分词（在hanlp 1.6.6已开始废弃）#hanlp_speed: 极速词典分词POST _analyze{  &quot;analyzer&quot;: &quot;hanlp_standard&quot;,  &quot;text&quot;: [&quot;剑桥分析公司多位高管对卧底记者说，他们确保了唐纳德·特朗普在总统大选中获胜&quot;]}     #PinyinPUT /artists/{    &quot;settings&quot; : {        &quot;analysis&quot; : {            &quot;analyzer&quot; : {                &quot;user_name_analyzer&quot; : {                    &quot;tokenizer&quot; : &quot;whitespace&quot;,                    &quot;filter&quot; : &quot;pinyin_first_letter_and_full_pinyin_filter&quot;                }            },            &quot;filter&quot; : {                &quot;pinyin_first_letter_and_full_pinyin_filter&quot; : {                    &quot;type&quot; : &quot;pinyin&quot;,                    &quot;keep_first_letter&quot; : true,                    &quot;keep_full_pinyin&quot; : false,                    &quot;keep_none_chinese&quot; : true,                    &quot;keep_original&quot; : false,                    &quot;limit_first_letter_length&quot; : 16,                    &quot;lowercase&quot; : true,                    &quot;trim_whitespace&quot; : true,                    &quot;keep_none_chinese_in_first_letter&quot; : true                }            }        }    }}GET /artists/_analyze{  &quot;text&quot;: [&quot;刘德华 张学友 郭富城 黎明 四大天王&quot;],  &quot;analyzer&quot;: &quot;user_name_analyzer&quot;}</code></pre><h1>平时开发及测试需要注意</h1><h3 id="思考与分析"><a class="header-anchor" href="#思考与分析">¶</a>思考与分析</h3><ul><li>“精确值&quot;还是&quot;全文”</li><li>搜索是怎样的？不同字段需要配置怎样的分词器</li><li>测试不同的选项<ul><li>分词器、多字段属性、是否要 g-grams、what are some critical synonyms、为字段设置不同的权重</li><li>测试不同的选项，测试不同的搜索条件</li><li>查看搜索结果和相关性算分、对搜索结果高亮显示</li></ul></li></ul><h3 id="测试相关性：理解原理-多分析-多调整测试"><a class="header-anchor" href="#测试相关性：理解原理-多分析-多调整测试">¶</a>测试相关性：理解原理+多分析+多调整测试</h3><p>技术分为道和术两种</p><ul><li>道：原理和原则</li><li>术：具体的做法、具体的解法</li></ul><p>关于搜索，为了有一个好的搜索结果。除了真正理解背后的原理，更需要多加实践与分析</p><ul><li>单纯追求&quot;术&quot;，会一直很辛苦。只有掌握了本质和精髓之&quot;道，做事才游刃有余</li><li>要做好搜索，除了理解原理，也需要坚持去分析一些不好的搜索结果。只有通过一定时间的积累，才能真正所有感觉</li><li>总希望一个模型，一个算法，就能毕其功于一役，是不现实的</li></ul><h3 id="监控并理解用户行为"><a class="header-anchor" href="#监控并理解用户行为">¶</a>监控并理解用户行为</h3><p>开发的时候不要过度调试相关度</p><p>而要监控搜索结果，监控用户点击最顶端结果的频次</p><p>将搜索结果提高到几高水平，唯一途径就是</p><ul><li>需要具有度量用户行为的强大能力</li><li>可以在后台实现统计数据，比如：用户的查询和结果，有多少被点击了</li><li>哪些搜索，没有返回结果</li></ul><h1>使用 Search Template 和 Index Alias</h1><h3 id="Search-Template"><a class="header-anchor" href="#Search-Template">¶</a>Search Template</h3><p>主要可用于解耦程序和搜索 DSL。Elasticsearch 的查询语句对相关性算分和查询性能都至关重要。</p><p>在开发初期，虽然可以明确查询参数，但是往往还不能最终定义查询的 DSL 的具体结构。</p><p>我们可以通过 Search Template 定义一个 Contract，解耦开发人员、搜索工程师、性能工程师之间的工作，让其各司其职。</p><ol><li>使用_script api创建一个名为 &quot;tmdb&quot;的 Search Template，我们对DSL中的 multi_match 查询的 query 属性定义为一个template 的变量，这个属性也就是用户查询的时候输入的一个检索字符串</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212814.png" alt="image-20200426000122334"></p><ol start="2"><li><p>使用 Search Template 进行查询</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212821.png" alt="image-20200426000417028"></p></li></ol><blockquote><p>详细语法参考：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-template.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-template.html</a></p></blockquote><h3 id="Index-Alias"><a class="header-anchor" href="#Index-Alias">¶</a>Index Alias</h3><p>主要用于实现零停机运维。当我们如果经常会修改一个索引的名称，但是我们elasticsearch 的上层应用又不想经常性地修改引用索引地名称，这时候我们就可以使用 Index Alias。上层应用对 alias 进行索引地访问。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212829.png" alt="image-20200426001116712"></p><p>另外我们还可以使用 Alias 创建不同地查询的视图，例如下面的动作在创建索引的同时使用了一个 range filter，设定对该 alias 的访问只能获得 rating字段大于等于4的文档数据。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212836.png" alt="image-20200426001144059"></p><h1>Function Score Query 优化算分</h1><p>Elasticsearch 默认会以文档的相关度算分进行排序，可以通过指定一个或者多个查询字段进行排序。但是在某些特定条件，无法针对相关度，对排序实现更多的控制，即使用相关度算分排序无法满足需求。</p><p>而 Function Score Query 可以在查询结束后，对每一个匹配的文档进行一系列的重新算分，根据新生成的分数进行排序。它提供了几种默认的计算分值的函数：</p><ul><li>Weight：为每一个文档设置一个简单而不被规范化的权重</li><li>Field Value Factor：使用该数值来修改_score，例如将&quot;热度&quot;和&quot;点赞数&quot;作为算分的参考因素</li><li>Random Score：对搜索结果进行随机的排序，使得我们可以在实现特定需求例如需要为每一个用户使用一个不同的随机算分</li><li>衰减函数：以某个字段的值为标准，举例某个值越近，得分越高</li><li>Script Score：自定义脚本完全控制所需逻辑</li></ul><h3 id="案例使用-function-score-query"><a class="header-anchor" href="#案例使用-function-score-query">¶</a>案例使用 function score query</h3><p>希望能够将点赞多的 blog，放在搜索列表相对靠前的位置。同时搜索的评分，还是要作为排序的主要依据。 以下就是一个例子，我们写入一个文档到博客索引中，这个文档包含一个标题、内容、投票数三个字段。</p><p>下面就是一个查询博客文档的请求，它使用了 function_score 的 query，我们指定了 votes 字段作为 field_value_factor对搜索结果进行重新算分。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212857.png" alt="image-20200426070338527"></p><p>以上 function_score 的算分规则其实就是：新的算分= 旧的算分 * 投票数；（上面的逻辑就是相关度算分 * 6）</p><h3 id="使用-Modifier-平滑曲线"><a class="header-anchor" href="#使用-Modifier-平滑曲线">¶</a>使用 Modifier 平滑曲线</h3><p>以上查询会存在以下问题，当用户投票数的差异非常大的时候，例如有三篇博客的投票数分别是0，1000，1000000000的时候，算分结果的差异也会非常大，因为它是简单的相乘。</p><p>这时候我们可以引进 function_score 的 field_value_factor 的另一个属性 modifier 了，它可以对算分的函数进行平滑处理，例如我们在下面的例子中使用了 log1p 的 modifiier，它将会导致我们的新算分逻辑产生变化：新的算分 = 旧的算分 * log(1 + 投票数)；（即：相关度算分 * log(1 + 投票数)）log 了一下，这样就能让我们的算分函数曲线在投票数越来越高的时候趋向平滑。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212907.png" alt="image-20200426071341391"></p><p>另外，modifier 还有以下平滑处理方式可以选择，根据实际的场景进行选择：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212928.png" alt="image-20200426071419020"></p><h3 id="Factor"><a class="header-anchor" href="#Factor">¶</a>Factor</h3><p>另外我们还能如下面例子这样使用另一个属性&quot;factor&quot;，它也会影响到我们的算分：新的算分 = 旧的算分 * log(1 + factor * 投票数)；即（相关度算分 * log(1 + factor * 投票数)）。从而实现更精准的控制。下面是不同 factor下的算分函数曲线的平滑度：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221212940.png" alt="image-20200426072018972"></p><h3 id="Boost-Mode-和-Max-Boost"><a class="header-anchor" href="#Boost-Mode-和-Max-Boost">¶</a>Boost Mode 和 Max Boost</h3><p>Function_score query 还可以通过Boost Mode来控制新的算分方式：</p><ul><li>Multiply：算分与log函数值（如果没有进行平滑处理就是该字段值本身）的乘积（默认，就是我们上面例子使用的）</li><li>Sum：算分与log函数值（如果没有进行平滑处理就是该字段值本身）的和</li><li>Min/Max：算分与log函数值（如果没有进行平滑处理就是该字段值本身）取最小/最大值</li><li>Replace：使用log函数值（如果没有进行平滑处理就是该字段值本身）取代算分</li></ul><p>另外Max Boost 可以将返回结果的新算分计算结果维持在一个最大值之内，下面例子没有加入 Max_Boost 之前最大算分为5点几，加入之后 max_boost=3之后变成了3点几：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213057.png" alt="image-20200426074419723"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213106.png" alt="image-20200426074330667"></p><h3 id="一致性随机函数"><a class="header-anchor" href="#一致性随机函数">¶</a>一致性随机函数</h3><p>使用场景：网站的广告需要提高展现率，让每个用户能看到不同的随机排名，但是也希望同一个用户访问时，其访问到的广告的顺序时一致的。</p><p>这样我们就可以使用 function_score 的 random_score 设置其属性 seed 值来实现，它会通过一个随机函数对搜索文档进行随机算分，同一个 seed 值每一个文档获得的随机算分是一致的，这也就保证了随机函数的一致性。</p><p>这样我们就可以通过为不同用户指定不同 seed 值实现随机排序了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213113.png" alt="image-20200426074552470"></p><h3 id="相关阅读"><a class="header-anchor" href="#相关阅读">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-function-score-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-function-score-query.html</a></p></blockquote><h3 id="Kibana-测试请求："><a class="header-anchor" href="#Kibana-测试请求：">¶</a>Kibana 测试请求：</h3><pre><code>DELETE blogsPUT /blogs/_doc/1{  &quot;title&quot;:   &quot;About popularity&quot;,  &quot;content&quot;: &quot;In this post we will talk about...&quot;,  &quot;votes&quot;:   0}PUT /blogs/_doc/2{  &quot;title&quot;:   &quot;About popularity&quot;,  &quot;content&quot;: &quot;In this post we will talk about...&quot;,  &quot;votes&quot;:   100}PUT /blogs/_doc/3{  &quot;title&quot;:   &quot;About popularity&quot;,  &quot;content&quot;: &quot;In this post we will talk about...&quot;,  &quot;votes&quot;:   1000000}POST /blogs/_search{  &quot;query&quot;: {    &quot;function_score&quot;: {      &quot;query&quot;: {        &quot;multi_match&quot;: {          &quot;query&quot;:    &quot;popularity&quot;,          &quot;fields&quot;: [ &quot;title&quot;, &quot;content&quot; ]        }      },      &quot;field_value_factor&quot;: {        &quot;field&quot;: &quot;votes&quot;      }    }  }}POST /blogs/_search{  &quot;query&quot;: {    &quot;function_score&quot;: {      &quot;query&quot;: {        &quot;multi_match&quot;: {          &quot;query&quot;:    &quot;popularity&quot;,          &quot;fields&quot;: [ &quot;title&quot;, &quot;content&quot; ]        }      },      &quot;field_value_factor&quot;: {        &quot;field&quot;: &quot;votes&quot;,        &quot;modifier&quot;: &quot;log1p&quot;      }    }  }}POST /blogs/_search{  &quot;query&quot;: {    &quot;function_score&quot;: {      &quot;query&quot;: {        &quot;multi_match&quot;: {          &quot;query&quot;:    &quot;popularity&quot;,          &quot;fields&quot;: [ &quot;title&quot;, &quot;content&quot; ]        }      },      &quot;field_value_factor&quot;: {        &quot;field&quot;: &quot;votes&quot;,        &quot;modifier&quot;: &quot;log1p&quot; ,        &quot;factor&quot;: 0.1      }    }  }}POST /blogs/_search{  &quot;query&quot;: {    &quot;function_score&quot;: {      &quot;query&quot;: {        &quot;multi_match&quot;: {          &quot;query&quot;:    &quot;popularity&quot;,          &quot;fields&quot;: [ &quot;title&quot;, &quot;content&quot; ]        }      },      &quot;field_value_factor&quot;: {        &quot;field&quot;: &quot;votes&quot;,        &quot;modifier&quot;: &quot;log1p&quot; ,        &quot;factor&quot;: 0.1      },      &quot;boost_mode&quot;: &quot;sum&quot;,      &quot;max_boost&quot;: 3    }  }}POST /blogs/_search{  &quot;query&quot;: {    &quot;function_score&quot;: {      &quot;random_score&quot;: {        &quot;seed&quot;: 911119      }    }  }}</code></pre><h1><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-suggesters-term.html" target="_blank" rel="noopener">Elasticsearch Suggester API</a></h1><p>现代的搜索引擎，一般都会提供 Suggest as type 的功能，帮助用户在输入搜索的过程中，进行自动补全或者纠错。通过协助用户输入更加精准的关键词，提高后续搜索阶段文档匹配的程度。</p><p>在 google 上搜索，一开始会自动补全。当输入到一定长度，如因为单词拼写错误无法补全，就会开始提示相似的词或者句子。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213122.png" alt="image-20200426091217561"></p><p>搜索引擎中类似的功能，在 Elasticsearch 中是通过 Suggester API 实现的，其原理时：将输入的文本分解为 Token，然后在索引的字段里找相似的 Term 并返回。</p><p><strong>根据不同的使用场景，Elasticsearch 设计了4种类别的 Suggesters：</strong></p><ul><li>Term &amp; Phrase Suggester</li><li>Complete &amp; Context Suggester</li></ul><p>下面我们来看几个案例，在此之前先建立一个测试索引和一些文档数据，这些文档都有一个 body 字段，该字段使用默认分词器standard，仅进行了大写转小写的动作，对于它来说&quot;rocks&quot;和&quot;rock&quot;是两个词：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213131.png" alt="image-20200426095728513"></p><h3 id="Term-Suggester"><a class="header-anchor" href="#Term-Suggester">¶</a>Term Suggester</h3><p>Term Suggester 下提供了三种 Suggestion Mode：</p><ul><li>Missing：如果索引中已经存在term，不提供建议</li><li>Popular：推荐出现频率比当前检索词条更加高的词</li><li>Always：无论出现频率是否比当前检索词条更高，都进行返回</li></ul><h5 id="Missing-Mode"><a class="header-anchor" href="#Missing-Mode">¶</a>Missing Mode</h5><p>我们来看下下面的例子，调用_search 的时候我们指定了 suggest 而不是 query，这个就是 es 的 Suggester，这个例子中我们指定了一个 term-suggestion，其中 text 的内容就是用户输入的内容，其中我们指定了 body 作为我们检索建议词条的字段：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213138.png" alt="image-20200426094146863"></p><p>Suggester 其实就是一种特殊类型的搜索。&quot;text&quot;里是调用时提供的文本，通常来自于用户界面上用户输入的内容。</p><p>可以看到上面的用户输入的&quot;lucen&quot;是一个错误的拼写，应该是&quot;lucene&quot;。下面我们分析一下 suggestion 的工作流程：</p><ol><li><p>该 term-suggestion 在接收到 text 的内容之后，会经过分词器的拆分成一个个 terms，然后到索引中进行 term 匹配，此时如果匹配不到或者匹配到了就要看我们配置的&quot;suggest_mode&quot;来决定后面的步骤怎么走</p></li><li><p>可以看到我们在上面的例子中配置了&quot;missing&quot;的&quot;suggest_mode&quot;：当text 拆分之后的 term 在索引的 term 字典中无法匹配的时候， 就会将<strong>一些</strong>&quot;相似的&quot;词条在 options 中进行返回；<strong>如果匹配了，options 中就不会返回任何内容</strong>（最后一个文档&quot;elasticsearch is rock solid&quot;中包含）。</p><p>其中每个&quot;相似的&quot;词条中都包含了一个&quot;score&quot;字段，这个字段描述了当前返回词条和 text 中词条的相似度，这个相似度是通过 Levenshtein Edit DIstance 的算法实现的。核心思想就是一个词改动多少字符就可以和另外一个词一致。es 提供了很多可选参数来控制相似性的模糊程度。例如&quot;max_edits&quot;，它的可输入范围是[1,2]，具体控制逻辑待研究：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213147.png" alt="image-20200426095436658"></p></li><li><p>另外 options 中返回的建议词条默认是按照词频&quot;frequence&quot;进行排序的，我们也可以设定按照相似度&quot;score&quot;进行排序，通过设置一个 sort 属性即可：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213157.png" alt="image-20200426102750909"></p></li></ol><h5 id="Popular-Mode"><a class="header-anchor" href="#Popular-Mode">¶</a>Popular Mode</h5><p>上面的 Missing Mode 的例子中可以看到对于输入&quot;lucen rock&quot;拆解之后的第二个词条 “rock” 已经在索引词条字段中存在了，就不在 suggestion 中返回，如果我们依然想对匹配的索引的字段进行返回，可以通过设置&quot;popular&quot; mode 来实现（但是需要注意的，它只会返回在所有文档中词频比当前匹配的检索词条更高的相似词条）：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213204.png" alt="image-20200426100559190"></p><p>可以看到 es 的 popular mode 是按照出现频率（rocks 在两篇文档中出现了，更 popular）或者相似度给我们进行了返回（匹配的词条本身不会返回，上例中 “rock” 没有返回）。</p><h6 id="Prefix-Length"><a class="header-anchor" href="#Prefix-Length">¶</a>Prefix Length</h6><p>我们针对以上例子做一个改动，将搜索 text 中的&quot;rock&quot;改成了&quot;hock&quot;， 可以看到即使是 popular mode，针对该 term 也没有返回相关的建议。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213222.png" alt="image-20200426101648776"></p><p>这是因为 es 在默认情况下，如果检索词条的第一个字符和被检索词条的第一个字符都不匹配，就认为它们是&quot;不相似的&quot;，这个逻辑es 也提供了一个参数实现可配置化：“prefix_length”，当我们将这个参数设置为0的时候，es 就会跳过第一个字符的检查，即可获得返回&quot;rock&quot;：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213233.png" alt="image-20200426102903196"></p><h5 id="Always-Mode"><a class="header-anchor" href="#Always-Mode">¶</a>Always Mode</h5><p>上面的例子中，我们使用了&quot;popular mode&quot;，它在当前检索的词条在索引的词条字典中已经存在的情况下也可以进行返回，但是有个前提条件就是只返回词频比检索词条更高的其他相似词条。如果我们也想对词频比当前检索词条低的相似词条进行返回，可以通过设置&quot;always mode&quot;进行实现。</p><h3 id="Phrase-Suggester"><a class="header-anchor" href="#Phrase-Suggester">¶</a>Phrase Suggester</h3><p>Phrase Suggester 在 Term Suggester 上增加了一些额外的逻辑，还支持了一些额外的参数：</p><ul><li>Max Errors：最多可以拼错的 Terms 数</li><li>Confidence：限制返回结果数，默认为1</li></ul><p>下面是一个 Phrase Suggester 的例子：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213242.png" alt="image-20200426105038444"></p><p>详细参考<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-suggesters-phrase.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-suggesters-phrase.html</a></p><h3 id="Completion-Suggester"><a class="header-anchor" href="#Completion-Suggester">¶</a>Completion Suggester</h3><p>Completion Suggester 提供了&quot;自动完成&quot;（Auto Complete）的功能。用户每输入一个字符，就需要即时发送一个查询请求到后端查找匹配项。这对性能要求比较苛刻。Elasticsearch 采用了不同的数据结构，并非通过倒排索引来完成。而是将 Analyze 的数据编码成 FST 和索引一起存放。FST 会被 ES 整个加载进内存，速度很快。</p><p>FST 只能用于前缀查找。</p><h5 id="使用-Completion-Suggester-的一些步骤"><a class="header-anchor" href="#使用-Completion-Suggester-的一些步骤">¶</a>使用 Completion Suggester 的一些步骤</h5><ol><li><p>定义 mapping，对需要使用 Completion Suggester 实现自动完成的功能的字段使用&quot;completion&quot; type</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213255.png" alt="image-20200426110259562"></p></li><li><p>索引数据</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213304.png" alt="image-20200426110312381"></p></li><li><p>搜索数据</p><p>可以看到我们也是调用了_search api 然后指定了 suggest，并在它的一个子属性&quot;article-suggest&quot;下面指定了&quot;completion&quot;的 suggest并为其指定了&quot;title_completion&quot;字段，也就是我们在建立索引的时候指定为&quot;completion&quot;type 的字段，<strong>然后设置&quot;prefix&quot;为&quot;el&quot;，这个 &quot;prefix&quot;就是用户目前输入的内容</strong>：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213311.png" alt="image-20200426110326232"></p><p>可以看到，es 为我们返回了所有以&quot;el&quot;为前缀的数据：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213335.png" alt="image-20200426110532849"></p></li></ol><h3 id="Context-Suggester"><a class="header-anchor" href="#Context-Suggester">¶</a>Context Suggester</h3><p>它是 Completion Suggester 的扩展，可以在搜索中加入更多的上下文信息，例如，存在这么个需求，当用户输入&quot;star&quot; 的时候：</p><ul><li>如果用户在咖啡频道，es 给出建议&quot;Starbucks&quot;</li><li>如果用户在电影频道：es 给出建议&quot;star wars&quot;</li></ul><p>es 中 context suggester 可以实现两种 context：</p><ul><li>category：任意字符串</li><li>geo：地理位置信息</li></ul><h5 id="实现-Context-Suggester"><a class="header-anchor" href="#实现-Context-Suggester">¶</a>实现 Context Suggester</h5><ol><li><p>定制一个 Mapping</p><p>如下图我们建立了一个 comments 索引，在其 mapping 中定义了一个字段为  completion_autocomplete，该字段类型也是&quot;completion&quot;，然后为它设置了另外一个属性&quot;context&quot;，然后设置上下文类型 type 为&quot;category&quot;，并起名为&quot; comment_category&quot;上下文：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213347.png" alt="image-20200426111938127"></p></li><li><p>索引数据</p><p>如下图所示我们分别在该索引中设置了两条文档，文档内容分别是&quot;I love the star war movies&quot;和&quot;Where can I find a Starbucks&quot;，我们需要实现上面讲的在不同频道进行输入前缀&quot;sta&quot;的时候提示不同的相应的内容，我们可以像下面这样进行索引数据：</p><ol><li><p>为每个文档进行 comment_autocomplete 字段的设置（该字段类型是 completion，和上面的 Completion Suggester 一样），表示我们想让这个文档可以提供自动提示的内容</p></li><li><p>如果我们没有根据不同上下文提示不同内容的需求，完全可以像上面的 Completion Suggester 的设置那样直接将 Comment 的内容复制到 comment_autocomplete 字段中（或者干脆删掉 comment 字段即可，那么就和 completion suggester 一样了）；但是现在我们现在需要实现这样的需求，所以我们还要对 comment_autocomplete 字段的内容进行定制：</p><ul><li><p>通过设置 contexts 属性将当前文档与不同的上下文绑定，可以看到 contexts 属性是一个数组，也就是说支持设置多个值，而它的值又不是一个字符串类型，我们是可以对它再进行设置的，也就是说这里的上下文划分两个维度支持我们更灵活的数据分类和聚合（例如我们可以设置两层 context：第一层 context 通过在建立索引的时候为 mapping中的 contexts 属性中设置不同的属性来实现；第二层 context 通过在索引文档的时候通过给文档指定不通contexts 属性的值来实现）。</p><p>而在本案例中我们只给索引建立了一个上下文（我们只需要实现一层 context）：comment_category。所以我们直接给不同频道的文档对&quot;comment_category&quot;进行不同的设值，同一频道的文档进行相同的设值，这样就可以实现文档和上下文绑定聚合的功能。对于上下文我们可以理解为 FST 的不同隔离空间。</p></li><li><p>通过设置 input 属性将 input 的内容绑定到指定的上下文，也就是 FST 的隔离空间，然后建立这些 input 值和当前文档的关联关系。（后续用户进行自动完成动作的时候就会到指定的 FST 隔离空间下进行词条检索匹配，一旦匹配到了，就会根据 input 值绑定的文档对文档进行返回）</p></li></ul></li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213356.png" alt="image-20200426112828073"></p></li><li><p>查询数据</p><p>我们现在进行数据查询，可以看到我们设置用户输入的内容&quot;sta&quot;到 prefix 属性，然后指定 completion 的属性 field 为 comment_autocomplete，表示我们要到这个字段中进行&quot;自动完成操作&quot;，然后指定 completion 的 contexts 字段的&quot;comment_category&quot;属性值为&quot;coffee&quot;，表示我们要到comment_category 的一级上下文下的 coffee 二级上下文查找进行词条检索匹配。</p><p>es 将会完成这样的动作，根据我们指定的上下文 contexts 属性值将 sta 到指定的 FST 空间中进行前缀匹配（因为我们设置了comment_autocomplete 字段是上下文自动完成，这里的查询不设置上下文将会报错）。如果匹配到了就会返回和匹配字符串绑定的文档（因为可以在多个文档中设置相同的 input，所以可能会返回多个文档）。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221213403.png" alt="image-20200426114016502"></p><p>根据上面的逻辑，如果我们没有为一个文档进行上下文绑定，那么我们在进行以上的上下文查询的时候将会无法匹配到该文档；另外，我们可以给一个文档设置和文档内容完全不相关的 input（这种情况下，即使不包含上下文功能的功能，也会和上面的 completion suggester 的实现存在差异）。</p></li></ol><h3 id="四种-suggestion-比较"><a class="header-anchor" href="#四种-suggestion-比较">¶</a>四种 suggestion 比较</h3><ul><li><p>精准度</p><p>Completion &gt; Phrase &gt; term</p></li></ul><ul><li><p>召回率</p><p>Term &gt; Phrase &gt; Completion</p></li><li><p>性能</p><p>Completion &gt; Phrase &gt; Term</p></li></ul><h4 id="Kibana-测试请求-v3"><a class="header-anchor" href="#Kibana-测试请求-v3">¶</a>Kibana 测试请求</h4><pre><code>DELETE articlesPUT articles{  &quot;mappings&quot;: {    &quot;properties&quot;: {      &quot;title_completion&quot;:{        &quot;type&quot;: &quot;completion&quot;      }    }  }}POST articles/_bulk{ &quot;index&quot; : { } }{ &quot;title_completion&quot;: &quot;lucene is very cool&quot;}{ &quot;index&quot; : { } }{ &quot;title_completion&quot;: &quot;Elasticsearch builds on top of lucene&quot;}{ &quot;index&quot; : { } }{ &quot;title_completion&quot;: &quot;Elasticsearch rocks&quot;}{ &quot;index&quot; : { } }{ &quot;title_completion&quot;: &quot;elastic is the company behind ELK stack&quot;}{ &quot;index&quot; : { } }{ &quot;title_completion&quot;: &quot;Elk stack rocks&quot;}{ &quot;index&quot; : {} }POST articles/_search?pretty{  &quot;size&quot;: 0,  &quot;suggest&quot;: {    &quot;article-suggester&quot;: {      &quot;prefix&quot;: &quot;elk &quot;,      &quot;completion&quot;: {        &quot;field&quot;: &quot;title_completion&quot;      }    }  }}DELETE articlesPOST articles/_bulk{ &quot;index&quot; : { } }{ &quot;body&quot;: &quot;lucene is very cool&quot;}{ &quot;index&quot; : { } }{ &quot;body&quot;: &quot;Elasticsearch builds on top of lucene&quot;}{ &quot;index&quot; : { } }{ &quot;body&quot;: &quot;Elasticsearch rocks&quot;}{ &quot;index&quot; : { } }{ &quot;body&quot;: &quot;elastic is the company behind ELK stack&quot;}{ &quot;index&quot; : { } }{ &quot;body&quot;: &quot;Elk stack rocks&quot;}{ &quot;index&quot; : {} }{  &quot;body&quot;: &quot;elasticsearch is rock solid&quot;}POST _analyze{  &quot;analyzer&quot;: &quot;standard&quot;,  &quot;text&quot;: [&quot;Elk stack  rocks rock&quot;]}POST /articles/_search{  &quot;size&quot;: 1,  &quot;query&quot;: {    &quot;match&quot;: {      &quot;body&quot;: &quot;lucen rock&quot;    }  },  &quot;suggest&quot;: {    &quot;term-suggestion&quot;: {      &quot;text&quot;: &quot;lucen rock&quot;,      &quot;term&quot;: {        &quot;suggest_mode&quot;: &quot;missing&quot;,        &quot;field&quot;: &quot;body&quot;      }    }  }}POST /articles/_search{  &quot;suggest&quot;: {    &quot;term-suggestion&quot;: {      &quot;text&quot;: &quot;lucen rock&quot;,      &quot;term&quot;: {        &quot;suggest_mode&quot;: &quot;popular&quot;,        &quot;field&quot;: &quot;body&quot;      }    }  }}POST /articles/_search{  &quot;suggest&quot;: {    &quot;term-suggestion&quot;: {      &quot;text&quot;: &quot;lucen rock&quot;,      &quot;term&quot;: {        &quot;suggest_mode&quot;: &quot;always&quot;,        &quot;field&quot;: &quot;body&quot;,      }    }  }}POST /articles/_search{  &quot;suggest&quot;: {    &quot;term-suggestion&quot;: {      &quot;text&quot;: &quot;lucen hocks&quot;,      &quot;term&quot;: {        &quot;suggest_mode&quot;: &quot;always&quot;,        &quot;field&quot;: &quot;body&quot;,        &quot;prefix_length&quot;:0,        &quot;sort&quot;: &quot;frequency&quot;      }    }  }}POST /articles/_search{  &quot;suggest&quot;: {    &quot;my-suggestion&quot;: {      &quot;text&quot;: &quot;lucne and elasticsear rock hello world &quot;,      &quot;phrase&quot;: {        &quot;field&quot;: &quot;body&quot;,        &quot;max_errors&quot;:2,        &quot;confidence&quot;:0,        &quot;direct_generator&quot;:[{          &quot;field&quot;:&quot;body&quot;,          &quot;suggest_mode&quot;:&quot;always&quot;        }],        &quot;highlight&quot;: {          &quot;pre_tag&quot;: &quot;&lt;em&gt;&quot;,          &quot;post_tag&quot;: &quot;&lt;/em&gt;&quot;        }      }    }  }}DELETE articlesPUT articles{  &quot;mappings&quot;: {    &quot;properties&quot;: {      &quot;title_completion&quot;:{        &quot;type&quot;: &quot;completion&quot;      }    }  }}POST articles/_bulk{ &quot;index&quot; : { } }{ &quot;title_completion&quot;: &quot;lucene is very cool&quot;}{ &quot;index&quot; : { } }{ &quot;title_completion&quot;: &quot;Elasticsearch builds on top of lucene&quot;}{ &quot;index&quot; : { } }{ &quot;title_completion&quot;: &quot;Elasticsearch rocks&quot;}{ &quot;index&quot; : { } }{ &quot;title_completion&quot;: &quot;elastic is the company behind ELK stack&quot;}{ &quot;index&quot; : { } }{ &quot;title_completion&quot;: &quot;Elk stack rocks&quot;}{ &quot;index&quot; : {} }POST articles/_search?pretty{  &quot;size&quot;: 0,  &quot;suggest&quot;: {    &quot;article-suggester&quot;: {      &quot;prefix&quot;: &quot;elk &quot;,      &quot;completion&quot;: {        &quot;field&quot;: &quot;title_completion&quot;      }    }  }}DELETE commentsPUT commentsPUT comments/_mapping{  &quot;properties&quot;: {    &quot;comment_autocomplete&quot;:{      &quot;type&quot;: &quot;completion&quot;,      &quot;contexts&quot;:[{        &quot;type&quot;:&quot;category&quot;,        &quot;name&quot;:&quot;comment_category&quot;      }]    }  }}POST comments/_doc{  &quot;comment&quot;:&quot;I love the star war movies&quot;,  &quot;comment_autocomplete&quot;:{    &quot;input&quot;:[&quot;star wars&quot;],    &quot;contexts&quot;:{      &quot;comment_category&quot;:&quot;movies&quot;    }  }}POST comments/_doc{  &quot;comment&quot;:&quot;Where can I find a Starbucks&quot;,  &quot;comment_autocomplete&quot;:{    &quot;input&quot;:[&quot;starbucks&quot;],    &quot;contexts&quot;:{      &quot;comment_category&quot;:&quot;coffee&quot;    }  }}POST comments/_search{  &quot;suggest&quot;: {    &quot;MY_SUGGESTION&quot;: {      &quot;prefix&quot;: &quot;sta&quot;,      &quot;completion&quot;:{        &quot;field&quot;:&quot;comment_autocomplete&quot;,        &quot;contexts&quot;:{          &quot;comment_category&quot;:&quot;coffee&quot;        }      }    }  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>015_Java_ES</title>
      <link href="/2020/12/22/elasticsearch/015-java-es/"/>
      <url>/2020/12/22/elasticsearch/015-java-es/</url>
      
        <content type="html"><![CDATA[<pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z /]# vim /etc/my.cnf[root@izwz920kp0myp15p982vp4z /]# systemctl restart mysqld[root@izwz920kp0myp15p982vp4z /]# mysql -uroot -pEnter password:Welcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 3Server version: 5.7.30-log MySQL Community Server (GPL)Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql> CREATE USER canal IDENTIFIED BY 'canal';Query OK, 0 rows affected (0.00 sec)mysql> GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';Query OK, 0 rows affected (0.00 sec)mysql> FLUSH PRIVILEGES;Query OK, 0 rows affected (0.00 sec)mysql>exitBye[root@izwz920kp0myp15p982vp4z /]#[root@izwz920kp0myp15p982vp4z /]# cd /usr/local/software/[root@izwz920kp0myp15p982vp4z software]# mkdir canal[root@izwz920kp0myp15p982vp4z software]# cd canal/[root@izwz920kp0myp15p982vp4z canal]# wget https://github.com/alibaba/canal/releases/download/canal-1.1.4/canal.deployer-1.1.4.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1>待处理</h1><p><a href="https://gitee.com/zxporz/ESClientRHL" target="_blank" rel="noopener">适配7.xES 基于 high level HTTP REST ful 客户端开发的</a></p><p><a href="https://note.youdao.com/ynoteshare1/index.html?id=b05bc822ea1afd4f2451fda3d8029862&amp;type=note" target="_blank" rel="noopener">springboot 整合 es</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/client/index.html" target="_blank" rel="noopener">官网的 API，包含 HTTP 和 TCP</a></p><p><a href="https://mp.weixin.qq.com/s/mmzeJd7jR32P8Y0GAEnXVA" target="_blank" rel="noopener">Jest 入门</a></p><p><a href="https://mp.weixin.qq.com/s/7Qc5hs1Pm76WyAFQEQgz3Q" target="_blank" rel="noopener">Canal 同步数据库</a></p>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>014_Elastic解决方案</title>
      <link href="/2020/12/22/elasticsearch/014-elastic-jie-jue-fang-an/"/>
      <url>/2020/12/22/elasticsearch/014-elastic-jie-jue-fang-an/</url>
      
        <content type="html"><![CDATA[<h1>Elastic 各类工具</h1><ol><li><p>ELasticsearch 作为搜索引擎提高搜索速度</p></li><li><p>Kibana 作为一个 common 的 UI 管理界面，包含了很多模块的管理</p></li><li><p>Logstash 作为一个 ETL 工具进行数据抽取到 ES 中（也可以输出到其他目的地），相对于 Elastic 的其他数据抓取工具，它更专业，更全面，它提供了大量的插件可以进行更灵活的 ETL 工作。</p></li><li><p>Ingest Node 是 Elasticsearch 中的一种节点类型，或者一个节点可以扮演的角色，对通过 ES 的 REST api 的方式进入 ES 的数据进行预处理后再输入到 ES，相对 Logstash 来说能做的事情不多，但是也更方便</p></li><li><p>beats 是一类专门抓取<strong>特定数据</strong>的轻量ETL 工具的集合，例如 metric beat 用来抓取服务器硬件、操作系统、应用程序（规范、知名的）的指标数据；packetbeat 用来抓取网络流量数据；filebeat 用来抓取文件中的数据（通常可以用来抓取日志数据）等等。</p><p>它的轻量是相对于 Logstash 来说的，对于用户来说，beats 都是开箱即用的，只需要 enable 指定 beat 中的一些特定模块即可，但是 logstash 需要进行一些脚本配置的工作。但是相对于 logstash 来说，它只能完成对于特定数据的抓取工作。</p></li><li><p>APM 是 Elastic 公司开发的一款用来监控用户自己的程序的软件，实现原理是通过讲一个 APM agent 内嵌到用户的程序中，定时向 APM server 发送监控数据，然后APM server 将数据写入到 ES，最后在 Kibana 进行相关可视化操作。</p></li><li><p>Monitering 是 X-pack 中的一个免费模块，可以进行对 Elasticsearch 和 Kibana 的专业监控，它在 KIbana 中拥有一个独立的面板&quot;堆栈检测&quot;。</p></li><li><p>Alerting 也是 X-pack 中的一个收费模块，可以针对一定条件进行告警。</p></li><li><p>Machine Learning 也是 X-Pack 中的一个收费模块，可以对数据进行异常检测、预测。</p></li><li><p>Canvas 也是 X-Pack 中的一个免费模块，它在 Kibana 中也拥有一个独立的面板，可以用于创建&quot;数据大屏&quot;（例如机场大屏、秒杀流量大屏、用户数据大屏等等）</p></li></ol><h1>场景问题分类</h1><ol><li><p>针对异常检测的方案</p><p>对于 Elasticsearch、Kibana 本身的异常检测，我们通过 X-pack 的 monitering 即可解决。</p><p>对于一些通用软件的异常检测我们可以通过 metricbeat 实现。</p><p>对于应用程序的调用链路和性能检测通过 APM 实现（skywalking 待看）。</p><p>对于业务数据或者一些具体的业务异常，我们通过 filebeat、logstash、mq 等将具体的日志导入到 ES 中通过构建可视化组件、Dashboard、机器学习等进行异常检测。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>009_管理Elasticsearch集群</title>
      <link href="/2020/12/22/elasticsearch/009-guan-li-elasticsearch-ji-qun/"/>
      <url>/2020/12/22/elasticsearch/009-guan-li-elasticsearch-ji-qun/</url>
      
        <content type="html"><![CDATA[<p>[toc]</p><h1>安全</h1><h3 id="集群身份认证与用户鉴权"><a class="header-anchor" href="#集群身份认证与用户鉴权">¶</a>集群身份认证与用户鉴权</h3><p>Elasticsearch 在默认安装后，不提供任何形式的安全防护。如果有些管理员为了配置方便，在 elasticsearch.yml 中配置 server.host 为0.0.0.0，此时如果该台 ES 服务器是拥有一个公网 ip 的网络的接口的，那么外部就可以直接通过这个接口访问的 ES，而此时 ES 又是默认状态下没有任何的安全防护，此时外部就可以直接使用 ES api 随意获取数据。这种情况我们从两个角度讨论：</p><ul><li>在 ES 服务器拥有一个公网 ip 的情况下避免配置 server.host 为0.0.0.0；避免 ES 服务器拥有公网 ip，将其部署在内网环境中，并只分配内网 ip；nignx 反向代理。</li><li>为 ES 开启它的 security 功能。在本节中我们重点讨论这一项。</li></ul><h4 id="数据安全性的基本要求"><a class="header-anchor" href="#数据安全性的基本要求">¶</a>数据安全性的基本要求</h4><ol><li>身份认证，鉴定用户是否合法</li><li>用户鉴权：指定哪个用户可以访问哪个索引并可以做哪些操作</li><li>传输信息的加密</li><li>需要拥有日志审计的机制，帮助我们了解过去 ES 集群中发生了什么</li></ol><p>以下时解决数据安全性的一些免费方案：</p><ul><li><p>设置 Nignx 反向代理，避免前面讨论的安全问题1，隔绝外部其他未知访问。</p></li><li><p>安装免费的 Security 插件：</p><p>Search Guard(有商业版和免费版)：<a href="https://search-guard.com/" target="_blank" rel="noopener">https://search-guard.com/</a></p><p>ReadOnly REST：<a href="https://github.com/sscarduzio/elasticsearch-readonlyrest-plugin" target="_blank" rel="noopener">https://github.com/sscarduzio/elasticsearch-readonlyrest-plugin</a></p></li><li><p>X-Pack 的 Basic 版本：</p><p>从 ES 6.8 &amp; ES 7.0开始，Security 纳入 x-pack 的 Basic 版本中，可以免费使用一些基本的功能：<a href="https://www.elastic.co/what-is/elastic-stack-security" target="_blank" rel="noopener">https://www.elastic.co/what-is/elastic-stack-security</a></p></li></ul><h4 id="Authentication：身份认证"><a class="header-anchor" href="#Authentication：身份认证">¶</a>Authentication：身份认证</h4><p>Authentication 主要分为两个体系：</p><ol><li>提供用户名和密码</li><li>提供密钥或者 Kerberos</li></ol><p>在 ES 中，X-Pack 的认证服务功能称为 Realms。ES 中的 Realms 分为两种形式：</p><ul><li>一种是免费的，这种是 native（内置 Realms）的， 用户名和密码保存在 Elasticsearch 的索引当中的。</li><li>另一种是通过和 LDAP、Active Directory、PKI、SAML、Kerberos 进行集成的外部(认证信息存储在外部) Realms，这种是收费的。</li></ul><h4 id="RBAC：用户鉴权"><a class="header-anchor" href="#RBAC：用户鉴权">¶</a>RBAC：用户鉴权</h4><p>Role Based Access Control：定义一个角色，并分配一组权限。权限包括索引级、字段级、集群级的不同操作。然后通过将角色分配给用户，使得用户拥有这些权限。</p><ul><li>User：The authenticated user</li><li>Role：A named set of permissions</li><li>Permission：A set of ne or more privileges against a secured resouce</li><li>Privilege：A named group of 1 or more actions that user may execute against a secured resource</li></ul><p>在 ES 中创建了以下 Privileges：</p><ol><li>Cluster Privileges：all、monitor、manager、manage_index、manage_index_template、manage_rollup</li><li>Indices Privileges：all、create、create_index、delete、delete_index、index、manage、read、write、view_index_metadata</li></ol><p>另外 Elastic X-Pack 内置了一些用户和角色：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215735.png" alt="image-20200430135926838"></p><p>当 ES 打开了 security 的功能之后，还可以使用 security 的功能去创建用户创建不同的角色：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215741.png" alt="image-20200430140139471"></p><h4 id="开启并配置-X-Pack-的认证与鉴权"><a class="header-anchor" href="#开启并配置-X-Pack-的认证与鉴权">¶</a>开启并配置 X-Pack 的认证与鉴权</h4><ol><li><p>通过设置配置项<code>xpack.security.enabled</code>为 true即可启动 X-Pack 的认证与鉴权功能，可以在命令启动的时候通过<code>-E xpack.security.enbaled=true</code>选项来设置；也可以通过修改 elasticsearch.yml 中设置<code>xpack.security.enabled: true</code>，在本例中，我们对 elasticsearch.yml 中进行如下配置：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">network.host: 0.0.0.0http.port: 9800transport.port: 9900discovery.seed_hosts: ["0.0.0.0", "[::1]"]cluster.initial_master_nodes: ["node0"]xpack.security.enabled: truexpack.security.transport.ssl.enabled: true<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后启动 ES：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ ./bin/elasticsearch -E node.name=node0 -E cluster.name=john -E path.data=node0_data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此时我们直接访问 ES 可以看到需要输入用户名：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215751.png" alt="image-20200430143013548"></p></li><li><p>通过<code>bin/elasticsearch-setup-passwords interactive</code>设置在前面提到的 Xpack 中默认内置的用户密码，这里全部设置为<code>.ABCD45.</code>。（原来好像的命令是是<code>bin/elasticsearch-password interactive</code>）</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]# ./bin/elasticsearch-setup-passwords interactivefuture versions of Elasticsearch will require Java 11; your Java version from [/usr/local/software/java/jdk1.8.0_231/jre] does not meet this requirementFailed to determine the health of the cluster running at http://172.18.93.184:9800Unexpected response code [503] from calling GET http://172.18.93.184:9800/_cluster/health?prettyCause: master_not_discovered_exceptionIt is recommended that you resolve the issues with your cluster before running elasticsearch-setup-passwords.It is very likely that the password changes will fail when run against an unhealthy cluster.Do you want to continue with the password setup process [y/N]yInitiating the setup of passwords for reserved users elastic,apm_system,kibana,logstash_system,beats_system,remote_monitoring_user.You will be prompted to enter passwords as the process progresses.Please confirm that you would like to continue [y/N]yEnter password for [elastic]:Reenter password for [elastic]:Enter password for [apm_system]:Reenter password for [apm_system]:Enter password for [kibana]:Reenter password for [kibana]:Enter password for [logstash_system]:Reenter password for [logstash_system]:Enter password for [beats_system]:Reenter password for [beats_system]:Enter password for [remote_monitoring_user]:Reenter password for [remote_monitoring_user]:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>此时直接连接 elasticsearch 并输入账号名密码即可：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215759.png" alt="image-20200501093848208"></p><p>或者</p><pre><code>curl -u elastic 'myecs.com:9800/_cat/nodes?pretty'</code></pre></li><li><p>然后我们进行 Kibana 的设置</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">server.port: 5602server.host: "0.0.0.0"elasticsearch.hosts: ["http://localhost:9800"]elasticsearch.preserveHost: trueelasticsearch.username: "kibana"elasticsearch.password: ".ABCD45."<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>启动 Kibana</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[elasticsearch@izwz920kp0myp15p982vp4z kibana-7.6.2-linux-x86_64]$ ./bin/kibana<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此时我们再来尝试访问 Kibana 的时候，发现需要登录了。因为我们在上面配置了 kibana 读取的 elasticsearch 的信息，而 elasticsearch 启动了 X-pack 的安全功能。所以这里 kibana 应该也是跟着一起启动了 X-pack 的安全功能，并且之前 elasticsearch 配置的 X-pack 的一些信息也是通用的，包括我们配置的内置用户密码，所以这里要输入的也是 X-pack 中的提供的一些内置用户。而我们上面在 kibana 中配置的 elasticsearch.username 则是 kibana 在访问 elasticsearch 的时候需要提供的用户名密码。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215807.png" alt="image-20200501094744680"></p></li><li><p>下面我们用这个&quot;elastic&quot;超级用户（拥有所有权限）来创建一些需要被保护的数据，以下是一些信用卡信息：</p><pre><code>POST orders/_bulk{&quot;index&quot;:{}}{&quot;product&quot; : &quot;1&quot;,&quot;price&quot; : 18,&quot;payment&quot; : &quot;master&quot;,&quot;card&quot; : &quot;9876543210123456&quot;,&quot;name&quot; : &quot;jack&quot;}{&quot;index&quot;:{}}{&quot;product&quot; : &quot;2&quot;,&quot;price&quot; : 99,&quot;payment&quot; : &quot;visa&quot;,&quot;card&quot; : &quot;1234567890123456&quot;,&quot;name&quot; : &quot;bob&quot;}</code></pre></li><li><p>创建数据之后，我们为这个索引创建一些角色</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215816.png" alt="image-20200501101341679"></p><p>然后我们进入了创建角色的界面，分别有关于 elasticsearch 和 kibana 的设置界面，我们下面先看 elasticsearch 的设置界面：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215823.png" alt="image-20200501104004169"></p><p>下面是 Kibana 的设置界面，我们需要给这个用户拥有读取 Kibana 数据的权限，点击&quot;Add space privilege&quot;，然后选择相关权限</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215836.png" alt="image-20200501102455240"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215843.png" alt="image-20200501102821056"></p><p>点击创建角色，完成角色创建。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215850.png" alt="image-20200501102920006"></p></li><li><p>创建角色之后，我们创建一个用户</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215859.png" alt="image-20200501104353218"></p><p>填写相关信息，并选择我们创建的&quot;read_orders&quot;角色，然后创建用户</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215906.png" alt="image-20200501104536497"></p></li><li><p>然后我们登出 elstic 用户并登入新建的 demo 用户</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215915.png" alt="image-20200501104742250"></p><p>对前面创建的orders 索引进行以下操作，发现读数据是没问题的，但是写权限就会报错：</p><pre><code>#验证读权限,可以执行POST orders/_search{}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215928.png" alt="image-20200501104906811"></p><pre><code>#验证写权限,报错POST orders/_bulk{&quot;index&quot;:{}}{&quot;product&quot; : &quot;1&quot;,&quot;price&quot; : 18,&quot;payment&quot; : &quot;master&quot;,&quot;card&quot; : &quot;9876543210123456&quot;,&quot;name&quot; : &quot;jack&quot;}{&quot;index&quot;:{}}{&quot;product&quot; : &quot;2&quot;,&quot;price&quot; : 99,&quot;payment&quot; : &quot;visa&quot;,&quot;card&quot; : &quot;1234567890123456&quot;,&quot;name&quot; : &quot;bob&quot;}</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215946.png" alt="image-20200501104929598"></p></li></ol><h4 id="相关阅读"><a class="header-anchor" href="#相关阅读">¶</a>相关阅读</h4><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/configuring-security.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/configuring-security.html</a></p></blockquote><h3 id="基于TCP协议通信的安全"><a class="header-anchor" href="#基于TCP协议通信的安全">¶</a>基于TCP协议通信的安全</h3><p>上面讲了如何给对于 Elasticsearch 的访问操作加上权限控制，下面我们要讲的是更深层次一点的安全，通讯安全。ES 的通信有两种：TCP 和 HTTP 协议。集群内部通信都是使用 TCP 通信；集群与外部的通信可以使用 TCP，也可以使用 HTTP（推荐是 HTTP 的 RESTful API）。 在本节我们主要介绍 ES 默认提供的保障 TCP 通信安全的方式。</p><p>在本节我们介绍集群内部安全通信，Elasticsearch 默认提供了两种通讯方式，一种是 HTTP，默认在9200端口，另一种是 TCP，默认在9300端口。集群的内部通信是基于9300端口进行的，默认情况下，集群的内部通信是没有任何加密的，另外，集群对于一个新节点的加入也没有做任何校验。那么一些非法之徒在可以访问得到我们的集群的情况下就有可能通过以下两张方式获取我们的数据：</p><ul><li>对数据进行抓包，获取敏感信息</li><li>自己起一个 ES 节点加入我们的集群</li></ul><p>针对以上两点，我们就需要对我们集群的内部通信启用通讯加密并且对新加入的节点进行身份验证。X-pack 中就为我们提供这样的方案，使用 TLS 协议进行通信，TLS 协议中通信双方是需要一个 CA（Certification Authority，在 ES 叫做 Trusted Certificate Authority） 签发的证书的，ES 中需要一个 X.509 的证书。我们可以使用ES 提供的以下工具来为集群节点分别创建证书：</p><pre><code># 为您的Elasticearch集群创建一个证书颁发机构。例如，使用elasticsearch-certutil ca命令：bin/elasticsearch-certutil ca#为群集中的每个节点生成证书和私钥。例如，使用elasticsearch-certutil cert 命令：bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12#将证书拷贝到节点的 config/certs目录下elastic-certificates.p12</code></pre><p>然后在配置文件中或者在启动集群节点的时候指定以下参数：</p><pre><code># 启动 ssl 协议通信xpack.security.transport.ssl.enabled: true# 指定 ssl 通信的级别xpack.security.transport.ssl.verification_mode: certificate# 指定证书位置xpack.security.transport.ssl.keystore.path: certs/elastic-certificates.p12xpack.security.transport.ssl.truststore.path: certs/elastic-certificates.p12</code></pre><p>上面提到通过<code>xpack.security.transport.ssl.verification_mode</code>来指定 ES 对于证书的校验级别，一共有三个级别可配置，默认情况是 none：</p><ul><li>full：节点加入集群需要相同 CA 签发的证书，还需要验证 Host name 或者 IP 地址</li><li>certificate：节点加入需要使用相同 CA 签发的证书即可</li><li>none：任何节点都可以加入，开发环境中用于诊断目的</li></ul><p>下面我们来演示一下：</p><ol><li><p>在其中一个节点中创建 CA（ TLS 中 CA 签发的证书是用来识别一个网络上的一个终端的，所以对于这个终端里面的所有 ES 节点来说使用的都是同一个证书。真实情况中应该是在多台服务器中包含多个 ES 程序，选择其中一个作为创建 CA 作为证书签发机构进行证书签发然后拷贝证书到其他服务器上其他节点的指定目录即可。我们的演示就是在一个程序下启动多个节点，所以就在当前ES 下创建 CA 并只签发一个证书就行拉）。</p><p>然后下面需要我们输入 CA 文件的名称，直接回车使用默认名称&quot;elastic-stack-ca.p12&quot;。然后需要我们输入这个 CA 的密码，直接回车使用空密码。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ ./bin/elasticsearch-certutil cafuture versions of Elasticsearch will require Java 11; your Java version from [/usr/local/software/java/jdk1.8.0_231/jre] does not meet this requirementThis tool assists you in the generation of X.509 certificates and certificatesigning requests for use with SSL/TLS in the Elastic stack.The 'ca' mode generates a new 'certificate authority'This will create a new X.509 certificate and private key that can be usedto sign certificate when running in 'cert' mode.Use the 'ca-dn' option if you wish to configure the 'distinguished name'of the certificate authorityBy default the 'ca' mode produces a single PKCS#12 output file which holds:    * The CA certificate    * The CA's private keyIf you elect to generate PEM format certificates (the -pem option), then the output willbe a zip file containing individual files for the CA certificate and private keyPlease enter the desired output file [elastic-stack-ca.p12]:Enter password for elastic-stack-ca.p12 :<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>为节点签发证书。下面会需要我们输入 CA的密码，直接回车输入空密码；然后是需要我们输入证书的名称，直接回车使用默认名称&quot;elastic-certificates.p12&quot;；最后会让我们输入证书的密码，直接回车使用空密码。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ ./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12future versions of Elasticsearch will require Java 11; your Java version from [/usr/local/software/java/jdk1.8.0_231/jre] does not meet this requirementThis tool assists you in the generation of X.509 certificates and certificatesigning requests for use with SSL/TLS in the Elastic stack.The 'cert' mode generates X.509 certificate and private keys.    * By default, this generates a single certificate and key for use       on a single instance.    * The '-multiple' option will prompt you to enter details for multiple       instances and will generate a certificate and key for each one    * The '-in' option allows for the certificate generation to be automated by describing       the details of each instance in a YAML file    * An instance is any piece of the Elastic Stack that requires an SSL certificate.      Depending on your configuration, Elasticsearch, Logstash, Kibana, and Beats      may all require a certificate and private key.    * The minimum required value for each instance is a name. This can simply be the      hostname, which will be used as the Common Name of the certificate. A full      distinguished name may also be used.    * A filename value may be required for each instance. This is necessary when the      name would result in an invalid file or directory name. The name provided here      is used as the directory name (within the zip) and the prefix for the key and      certificate files. The filename is required if you are prompted and the name      is not displayed in the prompt.    * IP addresses and DNS names are optional. Multiple values can be specified as a      comma separated string. If no IP addresses or DNS names are provided, you may      disable hostname verification in your SSL configuration.    * All certificates generated by this tool will be signed by a certificate authority (CA).    * The tool can automatically generate a new CA for you, or you can provide your own with the         -ca or -ca-cert command line options.By default the 'cert' mode produces a single PKCS#12 output file which holds:    * The instance certificate    * The private key for the instance certificate    * The CA certificateIf you specify any of the following options:    * -pem (PEM formatted output)    * -keep-ca-key (retain generated CA key)    * -multiple (generate multiple certificates)    * -in (generate certificates from an input file)then the output will be be a zip file containing individual certificate/key filesEnter password for CA (elastic-stack-ca.p12) :Please enter the desired output file [elastic-certificates.p12]:Enter password for elastic-certificates.p12 :Certificates written to /usr/local/software/elasticsearch/elasticsearch-7.6.2/elastic-certificates.p12This file should be properly secured as it contains the private key foryour instance.This file is a self contained file and can be copied and used 'as is'For each Elastic product that you wish to configure, you should copythis '.p12' file to the relevant configuration directoryand then follow the SSL configuration instructions in the product guide.For client applications, you may only need to copy the CA certificate andconfigure the client to trust this certificate.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>此时可以看到当前目录下证书已经签发了，我们为证书创建一个 certs 目录来专门存放证书，然后将刚刚创建的证书移动到该目录下。<strong>需要注意的是，ES 强制证书只能存放在 config 目录下面，不然会报错，而配置的值如果指定的是相对路径，也就是相对于 config 的路径</strong></p><pre><code>[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ ll总用量 580drwxrwxrwx  2 elasticsearch root            4096 3月  26 14:36 bindrwxrwxrwx  2 elasticsearch root            4096 5月   1 09:34 configdrwxrwxrwx  3 elasticsearch elasticsearch   4096 4月  23 17:53 data-rw-------  1 elasticsearch elasticsearch   3443 5月   1 11:48 elastic-certificates.p12-rw-------  1 elasticsearch elasticsearch   2527 5月   1 11:45 elastic-stack-ca.p12drwxrwxrwx  9 elasticsearch root            4096 3月  26 14:36 jdkdrwxrwxrwx  3 elasticsearch root            4096 3月  26 14:36 lib-rwxrwxrwx  1 elasticsearch root           13675 3月  26 14:28 LICENSE.txtdrwxrwxrwx  2 elasticsearch root            4096 5月   1 09:27 logsdrwxrwxrwx 38 elasticsearch root            4096 3月  26 14:37 modulesdrwxrwxr-x  3 elasticsearch elasticsearch   4096 5月   1 09:27 node0_data-rwxrwxrwx  1 elasticsearch root          523209 3月  26 14:36 NOTICE.txtdrwxrwxrwx  3 elasticsearch root            4096 4月  23 19:21 plugins-rwxrwxrwx  1 elasticsearch root            8164 3月  26 14:28 README.asciidoc[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ mkdir ./config/certs[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ mv elastic-certificates.p12 ./config/certs/</code></pre></li><li><p>配置节点使用该证书进行 tls 通信，可以在 elasticsearch.yml 中进行配置，也可以在启动的时候通过<code>-E</code>配置，这里我们通过后者配置：</p><p>elasticsearch.yml：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">network.host: 0.0.0.0discovery.seed_hosts: ["0.0.0.0:9900"]cluster.initial_master_nodes: ["node0"]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>通过在启动的时候设置参数，以下两个节点是可以启动成功并形成以 node0 为 master 的集群的</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">#提供证书的节点bin/elasticsearch -E node.name=node0 -E cluster.name=john -E path.data=node0_data -E http.port=9800 -E transport.port=9900 -E xpack.security.transport.ssl.enabled=true -E xpack.security.transport.ssl.verification_mode=certificate -E xpack.security.transport.ssl.keystore.path=certs/elastic-certificates.p12 -E xpack.security.transport.ssl.truststore.path=certs/elastic-certificates.p12bin/elasticsearch -E node.name=node1 -E cluster.name=john -E path.data=node1_data -E http.port=9801 -E transport.port=9901 -E xpack.security.transport.ssl.enabled=true -E xpack.security.transport.ssl.verification_mode=certificate -E xpack.security.transport.ssl.keystore.path=certs/elastic-certificates.p12 -E xpack.security.transport.ssl.truststore.path=certs/elastic-certificates.p12<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221215956.png" alt="image-20200501132144591"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220006.png" alt="image-20200501132200368"></p><p>此后一个没有启用 ssl 协议通信的节点企图加入集群，一直在尝试寻找 master 节点，但是根本就建立不了通信。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">#不使用 TSL 的节点，无法加入（注意配置文件中也要把相关 ssl 参数关闭）bin/elasticsearch -E node.name=node2 -E cluster.name=john -E path.data=node2_data -E http.port=9802 -E transport.port=9902<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220014.png" alt="image-20200501131550736"></p><p>然后是一个启用了 ssl 协议通信，但是没有提供 CA 签发证书的节点妄图加入集群，也能启动，并且可以 i 访问，但是在尝试寻找 master 节点的时候一直在报没有证书的错误。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">#或者不提供证书的节点，无法加入bin/elasticsearch -E node.name=node2 -E cluster.name=john -E path.data=node2_data -E http.port=9802 -E transport.port=9902 -E xpack.security.transport.ssl.enabled=true -E xpack.security.transport.ssl.verification_mode=certificate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220026.png" alt="image-20200501132825243"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220032.png" alt="image-20200501131837571"></p></li></ol><h4 id="相关阅读-v2"><a class="header-anchor" href="#相关阅读-v2">¶</a>相关阅读</h4><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/configuring-tls.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/configuring-tls.html</a></p></blockquote><h3 id="基于HTTP协议通信的安全-外部"><a class="header-anchor" href="#基于HTTP协议通信的安全-外部">¶</a>基于HTTP协议通信的安全(外部)</h3><p>在前面的内容中我们介绍了如何通过设置让 ES 基于 TCP 的通信使用 TLS 通信。在本节中我们将介绍如何让 ES 启用基于 SSL 的 HTTP 通信（HTTPS）。</p><p>Elasticsearch 推荐大家都是用 RESTful 的方式与其进行外部通信，</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220041.png" alt="image-20200501154540265"></p><p>我们看到，从浏览器到 Kibana 的访问、Kibana 到 Elasticsearch 的访问、Logstash 到 Elasticsearch 的访问，我们的 java 应用程序到 Elasticsearch 的访问都是经过 http 协议进行通信的，所以为了我们的一些重要数据更加安全，所以我们需要让它们变成 HTTPS 的通信协议。</p><h4 id="启用-Elasticsearch-的-HTTPS"><a class="header-anchor" href="#启用-Elasticsearch-的-HTTPS">¶</a>启用 Elasticsearch 的 HTTPS</h4><p>那么我们怎样才能让 ES 启用 HTTPS 通信呢？我们需要进行以下的配置即可：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># http 启用 ssl 通信xpack.security.http.ssl.enabled: true# ssl 需要的证书xpack.security.http.ssl.keystore.path: certs/elastic-certificates.p12xpack.security.http.ssl.truststore.path: certs/elastic-certificates.p12<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面我们演示一下：</p><ol><li><p>重启 ES，并且启动 HTTPS 通信</p><pre><code>bin/elasticsearch -E node.name=node0 -E cluster.name=john -E path.data=node0_data -E http.port=9800 -E transport.port=9900 -E xpack.security.http.ssl.enabled=true -E xpack.security.http.ssl.keystore.path=certs/elastic-certificates.p12 -E xpack.security.http.ssl.truststore.path=certs/elastic-certificates.p12</code></pre></li><li><p>此时在通过<code>http://myecs.com:9800</code>的 http 协议进行通信，无法访问</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220057.png" alt="image-20200501155641320"></p></li><li><p>换成<code>https://myecs.com:9800</code>，可以访问到服务器，但是显示如下。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220250.png" alt="image-20200501155759849"></p><p>为什么会这样呢？我们来看下 HTTPS 通信的过程：</p><ul><li><p>用户在浏览器输入 URL 并按下回车</p></li><li><p>浏览器从 DNS (在本例中是本地 DNS)解析得到域名对应的 ip</p></li><li><p>浏览器作为本地 PC 中的一个应用程序向其所在的本地 PC 的网络接口发出一个 HTTP 请求报文</p></li><li><p>本地 PC 的网络接口将 HTTP 请求报文拆开后发现是一个 HTTPS 请求，便在建立 TCP 通道的时候使用 SSL 协议建立连接。</p><p>所谓 SSL 通信就是基于 TCP 协议通信的双方对于每个 TCP 数据报文的传输都要使用 RSA 算法进行加密。而 RSA 算法中的公私钥当然的就是来自于服务方，服务方基于 RSA 算法生成公钥和私钥，私钥自己保存在服务器，公钥在 TCP 通道建立的初始下发到客户端(这里就是浏览器所在PC)。</p><p>从此服务方向客户端发送信息的时候使用私钥进行 RSA 算法对数据报文进行加密，客户端接收到之后使用公钥进行解密。客户端向服务方发送数据的时候使用公钥进行加密，服务方使用私钥进行解密。这个过程使得数据的安全性得到保障。<strong>（RSA 算法的特性是关键，不熟悉的需要自己再了解下）</strong></p></li><li><p>上面提到 SSL 通信在 TCP 通道建立的时候由服务方下发 RSA 公钥，但是这个过程有可能是有风险的。因为这个公钥是可能伪造的。假设一个用户在第一次向一个银行服务器发起存款的请求，但是在他使用正确的银行服务器的URL 发出 HTTPS 请求之后，在建立 SSL 通信的时候，服务方返回给客户端的报文被截取到了，非法之徒篡改了其中下发给客户端的 RSA 公钥，换成自己的然后保存真正服务方的公钥到本地，然后将报文返回给客户端，客户端收到响应之后将被替换了的公钥保存在本地，从此一直使用该公钥和服务端进行通信，而非法之徒一直截取客户端的报文，用自己的私钥解密出报文然后修改之后再用真正的服务方公钥进行对修改后的报文进行加密返回到服务方，这样客户端和服务方之间的通信就是不安全的了。</p><p>所以这时候就需要一个具有权威的机构(Certificated Authority)来作为一个证书颁发机构，它将所有服务方的**唯一标识(可以直接使用ip)**和公钥生成一个标准(规范)的格式保存到自己的档案中，然后将这个证书颁发给服务方。服务方在和客户端建立 SSL 通信的时候将 RSA 公钥和证书的一些相关信息封装起来一起响应给客户端(包含证书的唯一标识)，客户端在收到响应之后会将证书中的服务方的唯一标识和服务方的公钥（或者证书的唯一标识）对 CA 发起请求，CA 校验证书的有效性（在自己的档案中看是否存在这个证书，公钥是否一致）。浏览器收到 CA 的校验通过的响应之后就会正常保存该证书到本地然后和服务方建立通信。<strong>但是很明显，我们这里的证书是在上一节内容中自己使用 ES 的一个工具生成(签发)的，Safari 浏览器向 CA 发出校验后当然校验不通过</strong>。所以此时就发出了这样的提示，（因为像我们现在这样的开发场景确实有自己生成证书的需求）：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220408.png" alt="image-20200501163532027"></p><p>我们点击访问此网站即可：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220421.png" alt="image-20200501163626248"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220525.png" alt="image-20200501163644515"></p></li></ul></li><li><p>上面演示了启用 ES 的 HTTPS 通信的方式以及简单介绍了 HTTPS 的原理。因为我们的 ES 服务器通常都是自己的内部使用的，不会开发给第三方用户，当我们有新的客户端要连接到 ES 服务器的时候，我们再使用一些通用工具(openssl)按照 CA 证书规范解析出证书中的公钥然后复制到客户端的指定目录即可，不需要向去像 CA 申请证书。</p></li></ol><h4 id="配置-Kibana-和-ES-建立-HTTPS-通信"><a class="header-anchor" href="#配置-Kibana-和-ES-建立-HTTPS-通信">¶</a>配置 Kibana 和 ES 建立 HTTPS 通信</h4><p>我们在上面配置了 ES 的 HTTPS 通信，现在我们要用 Kibana来访问它，所以也要配置 Kibana 来和它进行 HTTPS 通信。</p><p>首先我们需要使用<code>openssl</code>这个工具来解析我们之前使用 ES 签发的那个证书并生成一个 Kibana 需要的公钥格式然后保存到一个专门保存安全信息相关的目录（和 ES 一样我们在${Kibana_Home}/config 下面创建一个 certs 目录）。（我们前面提到，对于浏览器来说，它是向服务端发起建立 SSL 的请求后，服务端按照标准的规范在数据报文中填写自己的公钥和证书相关信息，浏览器也按照规范来取出这些信息，之后可以按照自己的格式存放这些信息到自己本地，也可以按照规范来存储，而这里对于 Kibana 来说，它应该也是按照某种规范来的，毕竟 openssl 是一个通用标准工具，它输出的信息也应该是标准的，但是是不是和浏览器的一样就不清楚了）</p><p>过程中可能要我们输入<code>elastic-certificates.p12</code>的密码，我们前面设置了是空密码，回车即可。</p><pre><code>[elasticsearch@izwz920kp0myp15p982vp4z kibana-7.6.2-linux-x86_64]$ mkdir ./config/certs[elasticsearch@izwz920kp0myp15p982vp4z kibana-7.6.2-linux-x86_64]$ openssl pkcs12 -in ../elasticsearch-7.6.2/config/certs/elastic-certificates.p12 -cacerts -nokeys -out ./config/certs/elastic-ca.pemEnter Import Password:MAC verified OK</code></pre><p>然后我们来修改 Kibana 的配置文件：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 配置使用 https 协议通信elasticsearch.hosts: ["https://localhost:9800"]# 配置公钥文件目录，这里使用绝对路径，kibana 好像不支持相对路径elasticsearch.ssl.certificateAuthorities: [ "/usr/local/software/elasticsearch/kibana-7.6.2-linux-x86_64/config/certs/elastic-ca.pem" ]# 配置 ssl 校验等级elasticsearch.ssl.verificationMode: certificate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>启动 kibana</p><pre><code>[elasticsearch@izwz920kp0myp15p982vp4z kibana-7.6.2-linux-x86_64]$ ./bin/kibana</code></pre><p>可以看到是可以正常访问 ES 的</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220534.png" alt="image-20200501171621353"></p><h4 id="配置-Kibana-使用-HTTPS"><a class="header-anchor" href="#配置-Kibana-使用-HTTPS">¶</a>配置 Kibana 使用 HTTPS</h4><p>前面我们介绍了 ES 使用 HTTPS，现在我们介绍开启 KIbana 的 HTTPS 通信。 我们再使用 ES 的证书工具<code>elsaticsearch-certutil</code>生成一个压缩包<code>elastic-stack-ca.zip</code>，里面包含了一个证书实体<code>ca.crt</code>和一个私钥<code>ca.key</code>，我们将它解压之后将证书实体和私钥拷贝到 Kibana 的 config/certs 目录下</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ bin/elasticsearch-certutil ca --pemfuture versions of Elasticsearch will require Java 11; your Java version from [/usr/local/software/java/jdk1.8.0_231/jre] does not meet this requirementThis tool assists you in the generation of X.509 certificates and certificatesigning requests for use with SSL/TLS in the Elastic stack.The 'ca' mode generates a new 'certificate authority'This will create a new X.509 certificate and private key that can be usedto sign certificate when running in 'cert' mode.Use the 'ca-dn' option if you wish to configure the 'distinguished name'of the certificate authorityBy default the 'ca' mode produces a single PKCS#12 output file which holds:    * The CA certificate    * The CA's private keyIf you elect to generate PEM format certificates (the -pem option), then the output willbe a zip file containing individual files for the CA certificate and private keyPlease enter the desired output file [elastic-stack-ca.zip]:[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ mv ./elastic-stack-ca.zip ../kibana-7.6.2-linux-x86_64/config/certs/[elasticsearch@izwz920kp0myp15p982vp4z elasticsearch-7.6.2]$ cd ../kibana-7.6.2-linux-x86_64[elasticsearch@izwz920kp0myp15p982vp4z kibana-7.6.2-linux-x86_64]$ unzip ./config/certs/elastic-stack-ca.zipArchive:  ./config/certs/elastic-stack-ca.zip   creating: ca/  inflating: ca/ca.crt  inflating: ca/ca.key[elasticsearch@izwz920kp0myp15p982vp4z kibana-7.6.2-linux-x86_64]$ mv -f ./ca/* ./config/certs/[elasticsearch@izwz920kp0myp15p982vp4z kibana-7.6.2-linux-x86_64]$ ll ./config/certs/总用量 16-rw-rw-r-- 1 elasticsearch elasticsearch 1200 5月   1 17:19 ca.crt-rw-rw-r-- 1 elasticsearch elasticsearch 1679 5月   1 17:19 ca.key-rw-rw-r-- 1 elasticsearch elasticsearch 1397 5月   1 17:02 elastic-ca.pem-rw------- 1 elasticsearch elasticsearch 2514 5月   1 17:19 elastic-stack-ca.zip<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后修改 kibana 配置文件</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 启用 httpsserver.ssl.enabled: true# 设置证书实体server.ssl.certificate: /usr/local/software/elasticsearch/kibana-7.6.2-linux-x86_64/config/certs/ca.crt# 设置私钥server.ssl.key: /usr/local/software/elasticsearch/kibana-7.6.2-linux-x86_64/config/certs/ca.key<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后启动 kibana</p><pre><code>[elasticsearch@izwz920kp0myp15p982vp4z kibana-7.6.2-linux-x86_64]$ ./bin/kibana</code></pre><p>此时使用 HTTP 已经无法访问了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220545.png" alt="image-20200501173722220"></p><p>使用 https</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220555.png" alt="image-20200501173807997"></p><p>成功</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220603.png" alt="image-20200501173846340"></p><h4 id="相关阅读-v3"><a class="header-anchor" href="#相关阅读-v3">¶</a>相关阅读</h4><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/configuring-tls.html#tls-http" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/configuring-tls.html#tls-http</a></p></blockquote><h1>水平扩展 Elasticsearch 集群</h1><p>在 ES 中根据不同功能聚合成了不同的节点类型：Master eligible、data、ingest、coordinating、machine learning。</p><p>在开发环境中，通常是一个 ES 实例承担多种角色。而在生产环境中，我们往往需要根据数据量，写入和查询的吞吐量，选择合适的部署方式，建议设置ES 实例为一个单一角色的节点（dedicated node）。这样做我们可以使得分配硬件资源的时候粒度更细，充分提高资源利用率 ：</p><ul><li><p>Dedicated master eligible node：负责集群状态(cluster state)的管理</p><p>使用低配置的 CPU、RAM 和磁盘</p></li><li><p>Dedicated data nodes：负责数据存储及处理客户端请求</p><p>使用高配置的 CPU、RAM 和磁盘啊</p></li><li><p>Dedicated ingest nodes：负责数据处理</p><p>使用高配置 CPU、中等配置的 RAM、低配置的磁盘</p></li><li><p>Dedicated coordinating nodes：负责请求转发以及结果汇总（聚合）</p><p>使用中\高配 CPU、中\高配 RAM、低配置的磁盘</p></li></ul><h3 id="节点参数配置"><a class="header-anchor" href="#节点参数配置">¶</a>节点参数配置</h3><p>一个节点在默认情况下会同时扮演：mastetr eligible、data node 和 ingest node</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220614.png" alt="image-20200501180720169"></p><p>我们可以通过以下配置实现让节点职责单一化</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220628.png" alt="image-20200501180758254"></p><h3 id="Dedicated-Coordinating-Only-Node-Client-Node"><a class="header-anchor" href="#Dedicated-Coordinating-Only-Node-Client-Node">¶</a>Dedicated Coordinating Only Node(Client Node)</h3><p>将 master、data、ingest 都配置成 false。</p><p>在生产环境中，建议为一些大的集群配置 coordinating only nodes</p><ul><li>扮演 Load Balancers；同时降低 Master 和 Data Ndoes 的负载。</li><li>负责搜索结果的 Gather 和 Reduce。</li><li>有时候无法阈值客户端会发送怎样的请求，例如大量占用内存的聚合操作，一个深度聚合可能会引发 OOM，导致 data node 或者 master node 这样的重要节点宕机。</li></ul><h3 id="Dedicated-Master-Eligible-Node"><a class="header-anchor" href="#Dedicated-Master-Eligible-Node">¶</a>Dedicated Master (Eligible) Node</h3><p>从高可用以及避免脑裂的角度出发</p><ul><li>一般在生产环境中配置3台，当 master 节点丢失的时候，其他 eligible 节点顶上，保证集群高可用</li><li>一个集群只有1台活跃的主节点，负责分片管理、索引创建、集群管理等操作</li></ul><p>如果和数据节点或者 Coordinating 节点混合部署，可能会有以下问题：</p><ul><li>数据节点相对有比较大的内存占用</li><li>coordinating 节点有时候可能会有开销很高的查询，导致 OOM</li><li>这些都有可能影响 Master 节点，导致集群的不稳定</li></ul><h3 id="几种集群部署方式"><a class="header-anchor" href="#几种集群部署方式">¶</a>几种集群部署方式</h3><p>下面我们将介绍几种 ES 集群的部署方式</p><h4 id="1、基本部署：增加节点，水平扩展"><a class="header-anchor" href="#1、基本部署：增加节点，水平扩展">¶</a>1、基本部署：增加节点，水平扩展</h4><p>当磁盘容量无法满足需求的时候，可以增加数据节点；磁盘读写压力大的时候，增加数据节点。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220639.png" alt="image-20200501182108857"></p><h4 id="2、水平扩展：Coordinating-Only-Node"><a class="header-anchor" href="#2、水平扩展：Coordinating-Only-Node">¶</a>2、水平扩展：Coordinating Only Node</h4><p>当系统中有大量的复杂查询及聚合查询的时候，增加 Coordinating 节点，增加查询的性能。另外我们可以在 coordinating nodes 前面部署一个 Load Balancer，这个 Load Balancer 可以由硬件或者软件来实现。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220646.png" alt="image-20200501182157034"></p><h4 id="3、读写分离"><a class="header-anchor" href="#3、读写分离">¶</a>3、读写分离</h4><p>有一些场景下，需要对写入 ES 的数据做一些比较频繁或者比较复杂的预处理工作，我们需要单独设置一些 Ingest 节点来做这样的工作，将读和写分离开来，根据各自的流量的情况来配置不同的硬件。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220700.png" alt="image-20200501182436402"></p><h4 id="4、在集群中部署-Kibana"><a class="header-anchor" href="#4、在集群中部署-Kibana">¶</a>4、在集群中部署 Kibana</h4><p>当我们需要部署 Kibana 来访问 ES ，官方建议我们将 Kibana 直接部署在 Coordinating Nodes 上，在 Coordinating nodes 前面不是一个 LB，即可实现 Kibana集群的高可用。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220708.png" alt="image-20200501182451714"></p><p>5、异地多活的部署</p><p>在某些情况下，我们拥有多个数据中心，有多个 ES 集群分别分散在这些数据中心上，为了保障更高层面（影响面更大）可能出现的问题（例如交换机、路由器出问题）下，当一个数据中心发生不可用的时候，其他数据中心还能正常的工作。</p><ul><li>一方面，我们可以通过数据多写（即写入数据的时候同时写入到多个中心集群中）实现各中心数据一致性。（这种一般是各中心无法通信的情况）</li><li>另一方面，可以使用 ES 提供的 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.6/xpack-ccr.html#" target="_blank" rel="noopener">Cross-cluster replication</a>来实现数据一致性，不过它是 X-Pack 中的内容，不知道是否需要收费。</li></ul><p>对于应用层的读取操作，可以部署一个负载均衡设备到应用层和各数据中心的 ES 之间进行读取操作的 Load Balance。</p><blockquote><p>GTM(Global Traffic Manager)：一种负载均衡</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220717.png" alt="image-20200501182509269"></p><h1>Hot &amp; Warm 架构与 Shard Filtering</h1><p>上一节介绍到，我们通常可以对 ES 实例设置为单一职责的节点来降低部署的成本。一般情况下，我们对于数据节点的配置都是一样的：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220735.png" alt="image-20200501185422635"></p><h3 id="Hot-Warm-Architecture"><a class="header-anchor" href="#Hot-Warm-Architecture">¶</a>Hot &amp; Warm Architecture</h3><p>有一些索引数据是 Time based（生命周期管理：随着时间的流逝，旧索引一般不会有更新操作，查询也会变少），同时整体的数据量比较大的场景。这时候我们就会引入 Hot &amp; Warm 架构。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220746.png" alt="image-20200501185708786"></p><blockquote><p>注意，我们本节讨论的 Hot &amp; Warm 架构方案仅仅基于 Time based 类型的索引的场景，即索引的访问流量<strong>随时间的流逝而越来越少</strong>，它是有一个变化过程的。以下两种情况不适合使用本节讨论的方案：</p><ol><li><p>如果索引一直都是高负载或者一直是低负载是不需要这种架构的，直接一直使用高配置机器或者一直使用低配置机器即可。</p></li><li><p>Hot &amp; Warm 架构的使用场景其实可以抽象成数据的访问和操作流量会呈现出一些<strong>比较有特征的差异</strong>，这时候我们可以根据这些特征来配置不同的硬件来部署不同流量程度的数据节点以存放不同的数据，从而进一步提高资源的利用率。这里的有特征的差异主要分两种：</p><ul><li>非 time based：这些差异是一直存在的，例如订单数据是肯定访问流量很大的，而一些配置项数据访问流量肯定是很少的，那么我们可以肯定的对订单数据节点使用高配置的(Hot)节点，对配置项数据使用低配置的(Warm)节点，并且这样的配置是不会变的。</li><li>time based：随着时间流逝才会显示出差异，即我们在一开始的时候需要对这些数据用 Hot 节点，随着时间的流逝使用 Warm 节点。例如最近3个月内的订单访问量肯定很大，所以我们对这3个月内的订单数据在一开始使用配置很高的节点存储，到了3个月之后，这些订单的访问量慢慢下来了，此时我们需要将这些订单数据<strong>转移到</strong>低配置的节点上进行存储，并将之后的对于这些订单数据的操作都路由到该低配节点上。本节主要讨论的是这种情况下的 Hot &amp; Warm 架构。</li></ul></li></ol></blockquote><p>这种架构将数据节点分为两类，分别使用不同的硬件配置：</p><ul><li>Hot 节点（通常使用 SSD）：索引有不断的新文档写入和读取</li><li>Warm 节点（通常使用大容量的 HDD）：索引不存在新数据的写入，同时也不存在大量的数据查询</li></ul><h4 id="Hot-Nodes"><a class="header-anchor" href="#Hot-Nodes">¶</a>Hot Nodes</h4><p>主要用于处于 Time based 索引数据的早期阶段存在大量文档写入（以及读取）的场景，对 CPU 和 IO 都有很高的要求，所以需要使用高配置的机器（SSD）。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220901.png" alt="image-20200501192633355"></p><h4 id="Warm-Nodes"><a class="header-anchor" href="#Warm-Nodes">¶</a>Warm Nodes</h4><p>主要用于处于 Time based 索引数据的晚期阶段有很少的数据更新(或者仅仅只读)的情况（俗称比较旧/老的数据），通常使用大容量的磁盘（通常是 Spinning Disks）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220910.png" alt="image-20200501192959006"></p><h4 id="Hot-Warm-Architecture-示例"><a class="header-anchor" href="#Hot-Warm-Architecture-示例">¶</a>Hot &amp; Warm Architecture 示例</h4><p>ES 对于 Hot &amp; Warm 架构的实现主要依赖于它的&quot;shard filtering&quot;，步骤分为以下几步：</p><ol><li>预先分别为 Hot &amp; Warm 节点分配好硬件资源，部署 ES 节点的时候根据其是 Hot节点还是 Warm 节点进行标记（Tagging）</li><li>在 Time based 索引的早期阶段，我们配置该索引的访问操作都路由到 Hot 节点</li><li>到了 Time based 索引的晚期阶段，我们配置该索引搬迁到 Warm 节点上，并配置转移对于该索引的访问操作到 Warm 节点上</li></ol><p>下面我们来看一个演示。</p><h5 id="1、标记-Hot-Warm-节点"><a class="header-anchor" href="#1、标记-Hot-Warm-节点">¶</a>1、标记 Hot &amp; Warm 节点</h5><p>ES 对于节点的配置提供了一个&quot;node.attr&quot;来允许我们灵活地为一个 ES 节点配置attributes，可以是一个任意的 key/value。可以通过 elasticsearch.yml 配置或者通过<code>-E</code>命令选项来指定。在这里我们就利用这个特性来对节点进行 Hot 和 Warm 的标记，如以下命令所示，我们指定了一个&quot;my_node_type&quot;的属性来标记一个节点是 Hot 还是 Warm 节点：</p><pre><code># 标记一个 Hot 节点bin/elasticsearch  -E node.name=hotnode -E cluster.name=geektime -E path.data=hot_data -E node.attr.my_node_type=hot -E http.port=9800 -E transport.port=9900# 标记一个 warm 节点bin/elasticsearch  -E node.name=warmnode -E cluster.name=geektime -E path.data=warm_data -E node.attr.my_node_type=warm -E http.port=9801 -E transport.port=9901</code></pre><p>elasticsearch.yml 配置</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">network.host: 0.0.0.0#  config discovery for master nodediscovery.seed_hosts: ["0.0.0.0:9900"]cluster.initial_master_nodes: ["hotnode"]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在启动 Hot &amp; Warm 节点之后，我们可以通过以下命令查询所有节点上的属性键值</p><pre><code># 查看节点GET /_cat/nodeattrs?v</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220920.png" alt="image-20200501200950243"></p><h5 id="2、Time-based-索引的早期将其路由到-Hot-节点"><a class="header-anchor" href="#2、Time-based-索引的早期将其路由到-Hot-节点">¶</a>2、Time based 索引的早期将其路由到 Hot 节点</h5><p>我们通过设置索引settings 中的<code>index.routing.allocation.require</code>指向我们配置的属性和属性值，那么 ES 在为该索引分配分片的时候，会根据当前分片的所属节点是否拥有&quot;my_node_type&quot;的属性并且值为&quot;hot&quot;对待路由的节点进行过滤，<strong>如果没有找到拥有属性对&quot;my_node_type=hot&quot;的节点，那么分配分片失败，集群状态为&quot;red&quot;</strong>。</p><pre><code># 配置到 Hot节点PUT logs-2019-06-27{  &quot;settings&quot;:{    &quot;number_of_shards&quot;:2,    &quot;number_of_replicas&quot;:0,    &quot;index.routing.allocation.require.my_node_type&quot;:&quot;hot&quot;  }}</code></pre><p>往索引中写入数据</p><pre><code>PUT logs-2019-06-27/_doc/1{  &quot;key&quot;:&quot;value&quot;}</code></pre><p>查看分片情况：可以看到索引<code>logs-2019-06-27</code>虽然在 settings 中被我们设置了主分片数量是2，并且在集群中存在两个节点的情况下，依然都分配到了 hotnode 这个节点上，而我们刚刚写入的文档数据被路由到了hotnode 节点的分片0上</p><pre><code>GET _cat/shards?v</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220927.png" alt="image-20200501203448182"></p><h5 id="3、Time-based-索引晚期将其转移到-Warm-节点"><a class="header-anchor" href="#3、Time-based-索引晚期将其转移到-Warm-节点">¶</a>3、Time based 索引晚期将其转移到 Warm 节点</h5><p>随着时间的推移，现在索引<code>logs-2019-06-27</code>的访问量慢慢下来了（日志当然也不会有更新操作），我们将它转移到 warm 节点上。</p><p>可以看到，我们再次对<code>index.routing.allocation.require.my_node_type</code>设置为&quot;warm&quot;，ES 就会为我们在&quot;标签&quot;为 warm 的节点上为索引<code>logs-2019-06-27</code>创建两个分片并将索引中的现有数据进行迁移到 warmnode 上，然后删除 hotnode 上的相关分片信息</p><pre><code># 配置到 warm 节点PUT logs-2019-06-27/_settings{    &quot;index.routing.allocation.require.my_node_type&quot;:&quot;warm&quot;}# 查看转移后的分片信息GET _cat/shards?v</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220938.png" alt="image-20200501204427674"></p><blockquote><p>可以看到，上面的 index routing reallocate 其实分为在其他节点上创建分片、迁移索引、删除当前节点上分片等过程，那么这个过程如果会持续比较久会不会影响用户对于该索引的访问呢？这个待研究。</p><p>另外，以上提到的 Hot &amp; Warm 架构是对基于 TIme based 数据的方案，一般需要对这些数据按照不同时间段建立索引（如果所有数据都建立在一个索引上，以上的方案就不适合了，需要自己通过reIndex API把&quot;老&quot;的数据进行迁移然后通过deleteByQuery进行当前节点上的数据删除。会比较繁琐，同时不高效），然后在当前时间到达索引的期限后对索引进行迁移到 warm 节点上，并灵活结合 alias (一个 alias 映射到所有时间区间的索引即可让外部访问不受影响)一起使用。</p></blockquote><h3 id="Rack-Awareness"><a class="header-anchor" href="#Rack-Awareness">¶</a>Rack Awareness</h3><p>ES 的节点在默认情况是可能分配在不同的机架上，也可能分配在同一个机架上的，没有限制。如果ES 的一个主分片及其所有的副本分片都被分配到了同一个机架上的时候，一旦这个机架断电，就会可能导致整个分片数据丢失。（例如下面的P0和 R0主副分片都在同一个机架 Rack1上）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220946.png" alt="image-20200501210235020"></p><p>我们可以通过 Rack Awareness 的机器，可以尽可能避免将同一个索引的主副分片同时分配在一个机架上。其实现和前面的 Hot &amp; Warm 的实现有异曲同工的地方。</p><ol><li><p>我们在启动 ES 节点的时候通过给它自定义一个属性为机架编号，并给它设置相应的机架编号值进行打标。</p><pre><code># 标记在 rack1 机架bin/elasticsearch  -E node.name=hotnode -E cluster.name=geektime -E path.data=hot_data -E node.attr.my_rack_id=rack1 -E http.port=9800 -E transport.port=9900# 标记在 rack2 机架bin/elasticsearch  -E node.name=warmnode -E cluster.name=geektime -E path.data=warm_data -E node.attr.my_rack_id=rack2 -E http.port=9801 -E transport.port=9901</code></pre></li><li><p>然后通过设置 _cluster 层级的 settings 中的<code>persistent.cluster.routing.allocation.awaerness.attributes</code>为我们前面设置的&quot;机架属性&quot;，那么 ES 在后面对索引进行分片分配的时候就会避免将同一个索引的主副分片都分配到属性&quot;my_rack_id&quot;是同一个值的节点上（即同一个机架上）</p><pre><code># 设置 ES 在给索引分配分片的时候要将主副分片按照节点的&quot;my_rack_id&quot;的值进行隔离PUT _cluster/settings{  &quot;persistent&quot;: {    &quot;cluster.routing.allocation.awareness.attributes&quot;: &quot;my_rack_id&quot;  }}# 设置索引为两个主分片，一个副本分片PUT my_index1{  &quot;settings&quot;:{    &quot;number_of_shards&quot;:2,    &quot;number_of_replicas&quot;:1  }}# 查看分片信息，可以看到同一个索引的主副本分片被分配到了位于不同 rack 的节点上get _cat/shards?v</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221220956.png" alt="image-20200501212831365"></p></li><li><p>以上的设置和配置项中的字面(awaerness)意思一样，它不是强制的，仅仅是让 ES 留意到这一点，如果集群中存在有不同&quot;my_rack_id&quot;属性值的节点，ES 会<strong>尽量</strong>将主副分片散步到不同 rack 上。所以当我们只启动两个&quot;my_rack_id&quot;为&quot;rack1&quot;的节点的时候，其实分片还是可以分配成功的（当然，如果我们只启动一个节点，副本分片就根本无法分配了，因为没有其他节点可备份了，集群显黄色），都分配到了机架 rack1的节点上。</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221005.png" alt="image-20200501214501354"></p><p>如果我们实在是想强制 ES 不能将主副分片都分配到同一个机架上来对管理员起到一个警告作用，那么可以通过增加一个<code>cluster.routing.allocation.awareness.force.my_rack_id.values</code>设定来实现：</p><pre><code># 覆盖新设置PUT _cluster/settings{  &quot;persistent&quot;: {    &quot;cluster.routing.allocation.awareness.attributes&quot;: &quot;my_rack_id&quot;,    &quot;cluster.routing.allocation.awareness.force.my_rack_id.values&quot;: &quot;rack1,rack2&quot;  }}# 删除索引DELETE my_index1# 重新建立索引PUT my_index1{  &quot;settings&quot;:{    &quot;number_of_shards&quot;:2,    &quot;number_of_replicas&quot;:1  }}# 查看分片情况get _cat/shards?v</code></pre><p>可以看到下面的截图中虽然集群中存在两个节点，但是因为都是&quot;rack1&quot;中的节点，所以副本分片都是无法分配的状态，集群显黄色</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221012.png" alt="image-20200501214926484"></p><pre><code>#  查看集群状态颜色GET _cluster/health</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221021.png" alt="image-20200501213701284"></p><p>通过以下命令可以看到详细的信息</p><pre><code>GET _cluster/allocation/explain?pretty</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221027.png" alt="image-20200501215007128"></p><h3 id="Shard-Filtering"><a class="header-anchor" href="#Shard-Filtering">¶</a>Shard Filtering</h3><p>可以看到我们通过 ES 提供的 Shard Filtering 可以实现对索引进行节点分配以及对分片进行节点分配的前置筛选动作。下面是 Shard Filtering 的一些总结：</p><ul><li>通过&quot;node.attr&quot;来标记节点</li><li>通过&quot;index.routing.allocation&quot;指定索引分配到哪些节点</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221039.png" alt="image-20200501215420918"></p><h3 id="相关阅读-v4"><a class="header-anchor" href="#相关阅读-v4">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/cn/blog/sizing-hot-warm-architectures-for-logging-and-metrics-in-the-elasticsearch-service-on-elastic-cloud" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/sizing-hot-warm-architectures-for-logging-and-metrics-in-the-elasticsearch-service-on-elastic-cloud</a></p><p><a href="https://www.elastic.co/cn/blog/deploying-a-hot-warm-logging-cluster-on-the-elasticsearch-service" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/deploying-a-hot-warm-logging-cluster-on-the-elasticsearch-service</a></p></blockquote><h1>分片设定及管理</h1><h3 id="单个分片"><a class="header-anchor" href="#单个分片">¶</a>单个分片</h3><p>在7.0开始，ES 在新创建一个索引的时候，默认只有一个主分片，单个分片对于查询算分，聚合不准的问题都可以得以避免。但是如果随着索引中的数据量越来越大的时候，节点压力就会越来越大，这时候即使我们加入一个新的节点，也不能分担压力，因为只有一个分片，此时我们可能需要创建新的索引重新设置分片数进行 reindex。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221045.png" alt="image-20200501220732045"></p><h3 id="两个分片"><a class="header-anchor" href="#两个分片">¶</a>两个分片</h3><p>但是如果我们在新建索引的时候，指定了两个及以上的分片，那么在索引数据越来越大之后，我们加入一个新的节点，那么 Elasticsearch 会自动进行分片的移动，也叫 Shard Rebalancing。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221050.png" alt="image-20200501220840158"></p><h3 id="如何设计分片数"><a class="header-anchor" href="#如何设计分片数">¶</a>如何设计分片数</h3><p>当分片数大于节点数的时候，一旦集群中有新的数据节点加入，分片就可以自动进行分配。分片在重新分配的时候，系统也不会有 downtime。同时，及时是在数据量不是很大的情况，也给索引设置不同的分片并且分片分布在不同的机器节点上就可以使得查询可以并行执行，数据写入也可以分布到多个机器上。下面是一些设计分片的例子：</p><ul><li>案例1：每天1GB 的数据，一个索引一个主分片，一个副本分片，需要保留半年的数据，接近360GB 的数据量。</li><li>案例2：5个不同的日志，每天创建一个日志索引，每个日志索引创建10个主分片，保留半年的数据，5 * 10 * 30 * 6 = 9000 个分片。</li></ul><h3 id="分片过多所带来的副作用"><a class="header-anchor" href="#分片过多所带来的副作用">¶</a>分片过多所带来的副作用</h3><p>每个分片是一个 Lucene 的索引，会使用机器的资源。过多的分片会大致额外的性能开销。</p><ul><li>Lucene Indices、File descriptors、RAM、CPU</li><li>每次搜索的请求，需要从每个分片上获取数据</li><li>分片的 Meta 信息由Master 节点维护。过多的分片会增加管理的负担。<strong>经验值是空值分片总数在10W 内。</strong></li></ul><h3 id="如何确定主分片数"><a class="header-anchor" href="#如何确定主分片数">¶</a>如何确定主分片数</h3><p>从存储的物理角度看</p><ul><li>日志类应用，单个分片不要大于50GB</li><li>搜索类应用，单个分片不要超过20GB</li></ul><p>为什么要控制分片存储大小</p><ul><li>提高update 的性能</li><li>merge 时，减少所需的资源</li><li>丢失节点后，具备更快的恢复速度，便于分片在集群内 rebalancing</li></ul><h3 id="如何确定副本分片数"><a class="header-anchor" href="#如何确定副本分片数">¶</a>如何确定副本分片数</h3><p>副本时主分片的拷贝，它能提高系统可用性，防止数据丢失，但是需要占用和主分片一样的资源。</p><p>对性能的影响：</p><ul><li>副本会降低数据的索引速度，有几份副本就会有几倍的 CPU 资源消耗在索引上</li><li>会减缓对主分片的查询压力，但是会消耗同样的内存资源。</li></ul><p>如果机器资源充分，提高副本数，可以提高整体的 QPS。</p><h3 id="调整分片总数设定避免分配不均衡"><a class="header-anchor" href="#调整分片总数设定避免分配不均衡">¶</a>调整分片总数设定避免分配不均衡</h3><p>ES 的分片策略会尽量保证节点上的分片数量大致相同，举个例子，某些情况下，现有的所有节点的负载几乎都满了，当我们加入一个新的节点之后，ES 开始 rebalancing，但是有有可能都是基于各个节点上的分片数来进行 rebalancing 的，不考虑分片上的数据量，如果有几个分片的数据量特别大，刚好都分布在同一个节点上，那么虽然 rebalancing 之后分片数量是均匀的，但是实际上某些节点上的数据量是很大的；或者说有些分片上存储的是热点数据，即使是 rebalancing 之后，如果 ES 继续按照节点上的分片数进行 rebalancing，后续还是可能会出现热点数据集中在某些节点上的问题。此时我们可以通过以下一些设定来进行干预：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221056.png" alt="image-20200501222848669"></p><h3 id="相关阅读-v5"><a class="header-anchor" href="#相关阅读-v5">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/cluster-reroute.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/cluster-reroute.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/indices-forcemerge.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/indices-forcemerge.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/allocation-total-shards.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/allocation-total-shards.html</a></p></blockquote><h1>如何对集群进行容量规划</h1><h3 id="容量规划"><a class="header-anchor" href="#容量规划">¶</a>容量规划</h3><p>首先需要考虑保持一定的余量，当负载出现波动，节点出现丢失的时候，还能正常运行。在做容量规划的时候，一些需要考虑的因素：</p><ul><li>机器的软硬件配置</li><li>单条文档的尺寸、文档的总数据量、索引的总数据量(Time based 数据保留的时间)、副本分片数</li><li>文档是如何写入的(build 的尺寸)</li><li>文档的复杂度、文档是如何进行读取的(查询和聚合的复杂度)</li></ul><h3 id="评估业务的性能需求"><a class="header-anchor" href="#评估业务的性能需求">¶</a>评估业务的性能需求</h3><p>数据吞吐及性能需求</p><ul><li>数据写入的吞吐量，每秒要求写入多少数据</li><li>查询的吞吐量</li><li>单条查询可接收的最大返回时间</li></ul><p>了解你的数据</p><ul><li>数据的格式和数据的 Mapping</li><li>实际的查询和聚合长的是什么样的</li></ul><h3 id="常见用例"><a class="header-anchor" href="#常见用例">¶</a>常见用例</h3><p>简单的来说我们可以将 ES 的应用分为两大类：</p><ul><li>搜索类应用：固定大小的数据集，搜索的数据集增长相对比较缓慢</li><li>日志类应用：基于时间序列的数据。使用 ES 存放日志与性能指标。数据每天不断写入，增长数据较快。结合 Warm Node 做数据的老化处理</li></ul><h3 id="硬件配置"><a class="header-anchor" href="#硬件配置">¶</a>硬件配置</h3><p>所有的数据节点尽可能使用 SSD：</p><ul><li>在搜索类应用或者性能要求高的场景，使用 SSD，按照1:10的比例配置内存和硬盘</li><li>日志类和查询并发低的场景，可以考虑使用机械硬盘存储，按照1:50的比例配置内存和硬盘</li></ul><p>单节点数据建议控制在2TB 以内，最大不建议超过5TB</p><p>JVM 只占机器内存的一般，JVM 内存配置不建议超过32G</p><h3 id="部署方式"><a class="header-anchor" href="#部署方式">¶</a>部署方式</h3><p>前面章节提到了多种部署方式，我们需要根据实际场景进行部署方式的选择：</p><ul><li>如果对于写入的数据进行一些大量的 pipeline 处理，可以配置一些 dedicated 的 ingest node，并为其配置相应的写操作 LB。</li><li>如果数据节点超过了3台，一般建议配置 dedicated 的 master 节点</li><li>如果需要考虑高可用，在使用了 dedicated 的 Master 节点的情况下一般部署3台 dedicated mater nodes（防止脑裂）</li><li>如果有复杂的查询和聚合，建议设置 coordinating 节点</li></ul><h3 id="容量规划案例1：固定大小的数据集"><a class="header-anchor" href="#容量规划案例1：固定大小的数据集">¶</a>容量规划案例1：固定大小的数据集</h3><p>一些案例：唱片信息库/产品信息</p><p>一些特性：</p><ul><li>被搜索的数据集很大，但是增长相对比较慢（不会有突然大量的写入）。更关心搜索和聚合的读取性能</li><li>数据的重要性和时间范围无关，关注的是搜索相关度</li></ul><p>估算索引的数据量，然后确定分片的大小</p><ul><li>前面提到，搜索类应用单个分片的数据不要超过20GB</li><li>可以通过增加副本分片，提高查询的吞吐量</li></ul><p>拆分索引</p><p>如果业务上有大量的查询是基于一个字段进行 filter，该字段又是一个数据有限的枚举值，存在大量的数据在该字段有着重复的枚举值，例如订单所在的地区，可以考虑将索引按照该字段的枚举值拆分成多个索引，使得这些数据可以分配在更多的分片上，这样查询性能可以得到提高；如果要对多个索引进行查询，可以在查询中指定多个索引来实现。</p><p>如果业务上大量的查询是基于一个字段进行 filter，该字段数值并不固定，可以启用 routing 功能，按照 filter 字段的值分布到集群不同的 shard，降低查询时相关的 shard，提高 CPU 利用率。</p><h3 id="容量规划案例2：基于时间序列的数据"><a class="header-anchor" href="#容量规划案例2：基于时间序列的数据">¶</a>容量规划案例2：基于时间序列的数据</h3><p>相关的案例：日志、指标、安全相关的 Events；舆情分析</p><p>一些特性：</p><ul><li>每条数据都有时间戳，文档基本不会被更新（日志和指标数据）</li><li>用户更多的会查询近期的数据，对旧数据查询比较少</li><li>对数据的写入性能要求比较高</li></ul><p>创建基于时间序列的索引</p><ul><li>在索引的名字中增加时间信息</li><li>按照每天、每周、每月的方式进行划分</li></ul><p>这使得更加合理的组织索引，例如随着时间的推移，便于利用 Hot &amp; Warm Architecture 对索引做老化处理，备份和删除的效率高。（因为在 ES 中如果想删除整个索引速度时较快的，而Delete By Query 执行速度慢，底层的 lucene 的 segment 也不会立即释放空间，而 Merge 时又很消耗资源）</p><ol><li><p>基于ES 提供的 Date Math 的方式写入时间序列的数据：Date Math 是 ES 提供的日期运算表达式，容易使用，但是如果时间的规则发生变化，就要重新部署代码。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221111.png" alt="image-20200501231625802"></p><p>我们使用的时候记得对里面的特殊符号进行 URI 编码：</p><p>下面是获取当前日期</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221117.png" alt="image-20200501232252328"></p><p>下面是获取本周第一天</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221127.png" alt="image-20200501232300143"></p><p>详情可以参考官方文档。</p></li><li><p>基于 Index Alias 写入时间序列的数据：每当有新的时间索引创建的时候，将它加入到对应的 alias 映射列表中</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221134.png" alt="image-20200501232010939"></p></li></ol><h3 id="集群监控和扩容"><a class="header-anchor" href="#集群监控和扩容">¶</a>集群监控和扩容</h3><p>即使我们做了容量规划，但是还是需要在上线之后监控集群的使用状况。</p><p>对于 Coordinating 和 Ingest nodes，主要监控 CPU 和内存开销的问题。</p><p>对于 Data nodes，都需要监控，硬盘比较主要。需要及时解决发现的存储容量问题，为避免分片不均的问题，要提前监控磁盘空间，提前清理数据或者增加节点。(70%)</p><h3 id="相关阅读-v6"><a class="header-anchor" href="#相关阅读-v6">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/capacity-planning.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/guide/current/capacity-planning.html</a></p><p><a href="https://yq.aliyun.com/articles/670118" target="_blank" rel="noopener">https://yq.aliyun.com/articles/670118</a></p></blockquote><h1>在私有云上管理 Elasticsearch 集群</h1><p>Elasticsearch 的安装是很方便的，但是如果在生产环境中管理一个集群，其实还是要做很多事情的。首先我们要对集群进行监控，当集群发现集群容量不够的时候，需要手工增加节点。在云环境中，节点的丢失很常见的，如果有节点丢失时，手工修复或者更换节点。同时我们可能还要留意 Rack Awareness 或者其他的 Shard Filtering，那么就需要为我们的节点分别打上不同的标签。Elasticsearch 的更新也比较频繁，对于集群版本的升级、数据备份、滚动升级，如果都手工操作，管理成本高，无法实现统一管理，例如整合变更管理等。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221142.png" alt="image-20200502080339509"></p><h3 id="ECE，帮助你管理多个-ELasticsearch-集群"><a class="header-anchor" href="#ECE，帮助你管理多个-ELasticsearch-集群">¶</a>ECE，帮助你管理多个 ELasticsearch 集群</h3><p>Elasticsearch 其实有一款产品，叫做 <a href="https://www.elastic.co/cn/products/ece" target="_blank" rel="noopener">ECE</a>（Elastic Cloud Enterprise）。提供了一个 UI 界面，实现单个控制台，管理多个集群：</p><ul><li>支持不同方式的集群部署(支持各类部署)、跨数据中心、部署 Anti Affinity</li><li>统一监控所有集群的状态</li><li>图形化操作：<ul><li>增加删除节点</li><li>集群升级、滚动更新、自动数据备份</li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221152.png" alt="image-20200502080934782"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221158.png" alt="image-20200502080949174"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221207.png" alt="image-20200502081007384"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221218.png" alt="image-20200502081019722"></p><h3 id="基于Kubernetes-的方案"><a class="header-anchor" href="#基于Kubernetes-的方案">¶</a>基于Kubernetes 的方案</h3><p>近些年容器化的技术越来越热门了，很多公司也将自己的基础设施往容器上迁移。ELasticsearch 也在今年退出了基于 K8S 管理的方案。它同时提供了基础级和企业级，前者是免费下载的。</p><ul><li>基于容器技术，使用 Operator 模式进行编排管理</li><li>配置，管理，监控多个集群</li><li>支持Hot &amp; Warm</li><li>数据快照和恢复</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221237.png" alt="image-20200502081137159"></p><h4 id="Kubernertes-CRD"><a class="header-anchor" href="#Kubernertes-CRD">¶</a>Kubernertes CRD</h4><p>其实基于 K8S 的部署，简单来说，就是为ES 定义一个K8S 的配置文件，只需要在这个 yml 文件里面定义所需 ES 的版本，所需 Nodes 的总数，ES Operator 就会帮助你把集群部署起来了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221248.png" alt="image-20200502081653827"></p><h3 id="构建自己的管理系统"><a class="header-anchor" href="#构建自己的管理系统">¶</a>构建自己的管理系统</h3><p>上面是 ELastic公司提供的容器管理方案，如果自己在公司中开发一套实现容器编排的系统，大概的实现思路：</p><ol><li>基于虚拟机的编排管理方式：Elasticsearch 还开源了一个 Puppet mdule，利用这个 Puppert module 可以基于 Puppert Infrastructure (Puppet / Elasticsearch Puppert Module / Foreman) 构建一个 Wrokflow based Provision &amp; Management。</li><li>基于 Kubernetes 的容器化编排管理方式：K8S 提供了一种 Operator 的模式，帮助对 K8S 实现一些扩展。我们可以基于 Operator 模式，通过Kubernetes - Customer Resource Definition来实现容器化编排管理。</li></ol><p>以下是一个将 Elasticsearch 部署在 Kubernetes 上的一个示意图：</p><p>首先看一下我们需要在 Kubernetes 上做一个 Elasticsearch 做一个部署，应该怎么做呢？首先我们需要为 master 节点创建一个 Statefulset，为什么需要创建一个 Statefulset 呢？因为在7.0开始我们需要指定节点的个数，所以我们需要利用Statefulset 中的 pod 是有序的特性，来实现 Provision 的一个功能。同时我们会创建一个 Headless Service，实现集群内部的通信，同时对于 data 节点，我们会为他创建一个 Statefulset 的 Deployment。对于 Coordinating nodes，可以为他们创建 Stateless 的 Deployment。同时我们哈可以使用 K8S 的Service 为集群创建 Read 和 Write 的 LB。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221257.png" alt="image-20200502082800507"></p><h4 id="什么是-Kubernetes-Operator"><a class="header-anchor" href="#什么是-Kubernetes-Operator">¶</a>什么是 Kubernetes Operator</h4><p>我们看一下怎么利用 K8S 的 Operator 管理一个集群，简单来说，我们需要先创建一个&quot;spec&quot;，在这个 spec 里面描述了我们需要节点的数量，以及我们需要对集群进行怎样的部署。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221306.png" alt="image-20200502083332535"></p><h4 id="社区上的-Operator-SDK"><a class="header-anchor" href="#社区上的-Operator-SDK">¶</a>社区上的 Operator SDK</h4><p>社区上也提供了很多的 Operator SDK，方便我们编写自己的 operator，实现在 K8S上对集群的管理：<a href="https://github.com/operator-framework/operator-sdk" target="_blank" rel="noopener">https://github.com/operator-framework/operator-sdk</a>。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221317.png" alt="image-20200502083611096"></p><h3 id="相关阅读-v7"><a class="header-anchor" href="#相关阅读-v7">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/cn/blog/introducing-elastic-cloud-on-kubernetes-the-elasticsearch-operator-and-beyond?elektra=products&amp;storm=sub1" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/introducing-elastic-cloud-on-kubernetes-the-elasticsearch-operator-and-beyond?elektra=products&amp;storm=sub1</a></p><p><a href="https://www.elastic.co/blog/introducing-elastic-cloud-on-kubernetes-the-elasticsearch-operator-and-beyond" target="_blank" rel="noopener">https://www.elastic.co/blog/introducing-elastic-cloud-on-kubernetes-the-elasticsearch-operator-and-beyond</a></p><p><a href="https://github.com/operator-framework" target="_blank" rel="noopener">https://github.com/operator-framework</a></p><p><a href="https://github.com/upmc-enterprises/elasticsearch-operator" target="_blank" rel="noopener">https://github.com/upmc-enterprises/elasticsearch-operator</a></p></blockquote><h1>在公有云上管理与部署 Elasticsearch</h1><p>Elastic 本身就有一个云服务 Elastic Cloud，另外它在国内和阿里云、腾讯云都有合作，我们可以有需要可以尝试在这些云上部署我们的 Elasticsearch 集群。</p><h3 id="Elastic-Cloud"><a class="header-anchor" href="#Elastic-Cloud">¶</a><a href="https://www.elastic.co/cloud/" target="_blank" rel="noopener">Elastic Cloud</a></h3><p>只要提供一个邮箱，在验证并登录之后即可进行一个免费的试用。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221324.png" alt="image-20200502084627149"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221331.png" alt="image-20200502084750561"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221339.png" alt="image-20200502084951100"></p><p>点击 quick deployment</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221349.png" alt="image-20200502085106456"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221358.png" alt="image-20200502085206492"></p><p>编辑集群</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221407.png" alt="image-20200502085326546"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221414.png" alt="image-20200502085404205"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221424.png" alt="image-20200502085519162"></p><p>点击 Activity 查看集群的所有变更</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221432.png" alt="image-20200502085607888"></p><p>还可以通过 performance 监控集群的一些指标</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221438.png" alt="image-20200502085823159"></p><h3 id="阿里云"><a class="header-anchor" href="#阿里云">¶</a>阿里云</h3><p><a href="https://www.aliyun.com/product/bigdata/product/elasticsearch" target="_blank" rel="noopener">https://www.aliyun.com/product/bigdata/product/elasticsearch</a></p><p><a href="https://www.elastic.co/cn/blog/elasticsearch-service-on-elastic-cloud-introduces-new-pricing-with-reduced-costs" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/elasticsearch-service-on-elastic-cloud-introduces-new-pricing-with-reduced-costs</a></p><h3 id="腾讯云"><a class="header-anchor" href="#腾讯云">¶</a>腾讯云</h3><p>略</p><blockquote><p>根据客户是国外还是国内选择不同的云</p></blockquote><h1>生产环境常用配置与上线清单</h1><p>从 ES5.0开始，支持 Development 和 Production 两种运行模式。ES 是通过 http.port 和 transport.bind_host (这个现在好像是 transport.host？反正就是检测 ES 绑定的地址是否是本地回环地址)两个参数来判断是什么模式：</p><ul><li><p>开发模式</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221446.png" alt="image-20200502091542377"></p></li><li><p>生产模式</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221453.png" alt="image-20200502091602629"></p></li></ul><h3 id="Bootstrap-Checks"><a class="header-anchor" href="#Bootstrap-Checks">¶</a>Bootstrap Checks</h3><p>一个集群在 Production Mode 的时候，启动时必须通过所有的 Boostrap 检测，否则会启动失败。Bootstrap checks 可以分为两类：JVM &amp; Linux Checks(前提是在 linux 系统上运行)。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221501.png" alt="image-20200502091741488"></p><blockquote><p>boostrap 检查清单：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/bootstrap-checks.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/bootstrap-checks.html</a></p></blockquote><h3 id="JVM-设定"><a class="header-anchor" href="#JVM-设定">¶</a>JVM 设定</h3><p>从 ES 6 开始，只支持64位的 JVM，通过配置<code>${ES_HOME}/config/jvm.options</code>实现 JVM 参数配置。避免修改默认配置：</p><ul><li>将内存 Xms 和 Xmx 设置成一样，避免 heap resize 时引发停顿。</li><li>Xmx 设置不要超过物理内存的50%(剩下的50%交给 lucene 实现全文检索)；单个节点上，最大内存建议不要超过32G内存(因为 JVM 在小于32G 的时候，会使用指针压缩提高性能)（<a href="https://www.elastic.co/blog/a-heap-of-trouble" target="_blank" rel="noopener">https://www.elastic.co/blog/a-heap-of-trouble</a>）</li><li>生产环境，JVM 必须使用 Server 模式</li><li>关闭 JVM Swapping</li></ul><h3 id="集群的-API"><a class="header-anchor" href="#集群的-API">¶</a>集群的 API</h3><p>静态设置和动态设定：</p><ul><li>静态配置文件elasticsearch.yml 尽量简洁：按照文档设置所有相关系统参数，配置文件中尽量只写必备参数。</li><li>其他的设置项可以通过 API 动态进行设定。动态设定分transient 和 persistent 两种，都会覆盖 elasticsearch.yml 中的设置。前者在集群重启后会丢失，后者不会。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221507.png" alt="image-20200502092804094"></p><h3 id="系统设定"><a class="header-anchor" href="#系统设定">¶</a>系统设定</h3><p>前面提到，ES 在生产环境的 boostraps 的时候除了对 JVM 进行一些检查，如果是在 linux 上启动还会对 linux 系统做一些检查。（如：disable swapping、increase file descrriptor、虚拟内存、number of thread 等等的设定）</p><blockquote><p>系统设置参考文档：“<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/system-config.html" target="_blank" rel="noopener">Setup Elasticsearch &gt; Important System Configuration</a>”</p><p>boostrap 检查清单：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/bootstrap-checks.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/bootstrap-checks.html</a></p></blockquote><h3 id="最佳实践：网络"><a class="header-anchor" href="#最佳实践：网络">¶</a>最佳实践：网络</h3><ul><li><p>单个集群不要跨数据中心进行部署（不要使用 WAN）</p></li><li><p>节点之间的 hops (时延)越少越好</p></li><li><p>如果有多块网卡，最好将 transport 和 http 绑定到不同的网卡，并设置不同的防火墙 rules</p></li><li><p>按需为 coordinating node 或 ingest node 配置负载均衡</p></li></ul><h3 id="最佳实践：内存设定计算实例"><a class="header-anchor" href="#最佳实践：内存设定计算实例">¶</a>最佳实践：内存设定计算实例</h3><p>内存大小除了首先要预留50%之外，还要根据 Node 需要存储的数据(和磁盘的比例)来进行估算</p><ul><li>搜索类的比例建议：1:16</li><li>日志类：1:48-1:96之间</li></ul><p>假设现有总数据量1T，设置一个副本=2T 总数据量</p><ul><li>如果是搜索类的项目，一个节点设置31G 内存，那么每个节点的磁盘存储就是31 * 16 = 496 G，(加上预留给 lucene 的31G空间 )，即每个节点最多400G 数据，至少需要5个数据节点才能使得磁盘达到2T 存储量。这时单节点内存总共需要是每个节点62G，5个数据节点为310G。</li><li>如果是日志类项目，每个节点31 * 50 = 1550GB，2个数据节点即可达到磁盘容量。所以单节点内存为62G，整个集群2个节点为124G。</li></ul><h3 id="最佳实践：存储"><a class="header-anchor" href="#最佳实践：存储">¶</a>最佳实践：存储</h3><ul><li><p>推荐使用 SSD，使用本地存储(Local Disk)，避免使用 SAN NFS、AWS、Azure filesystem等网络存储。</p></li><li><p>可以在本地指定多个&quot;path.data&quot;，以支持使用多块磁盘</p></li><li><p>ES 本身提供了很好的 HA 机制，无需使用 RAID 1/5/10</p></li><li><p>可以在 Warm 节点上使用 Spinning DIsk（机械硬盘），但是需要关闭 Concurent Mergs（<code>Index.merge.scheduler.max_thread_count:1</code>）</p></li><li><p>Trem 你的 SSD(对于 SSD 的优化)：<a href="https://www.elastic.co/blog/is-your-elasticsearch-trimmed" target="_blank" rel="noopener">https://www.elastic.co/blog/is-your-elasticsearch-trimmed</a></p></li></ul><h3 id="最佳实践：服务器硬件"><a class="header-anchor" href="#最佳实践：服务器硬件">¶</a>最佳实践：服务器硬件</h3><ul><li><p>建议使用中等配置的机器，不建议使用过于强劲的硬件配置：Medium machine over large machine</p></li><li><p>不建议在一台服务器上运行多个节点</p></li></ul><h3 id="最佳实践：Throttles-限流"><a class="header-anchor" href="#最佳实践：Throttles-限流">¶</a>最佳实践：Throttles 限流</h3><p>为 Relocation 和 Recovery 设置限流，避免过多任务对集群产生的影响</p><ul><li>Recovery：<code>Cluster.routing.allocation.node_concurrent_recoveries:2</code></li><li>Relocation：<code>Cluster.routing.allocation.cluster.cluster_concurrent_rebalance:2</code></li></ul><h3 id="集群设置：关闭-Dynamic-Indexes"><a class="header-anchor" href="#集群设置：关闭-Dynamic-Indexes">¶</a>集群设置：关闭 Dynamic Indexes</h3><p>考虑关闭动态索引创建的功能，避免无意或者非法的跳过 mapping 建模进行过多索引创建</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221514.png" alt="image-20200502095244011"></p><p>或者通过模板设置白名单</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221525.png" alt="image-20200502095301146"></p><h3 id="集群安全设定"><a class="header-anchor" href="#集群安全设定">¶</a>集群安全设定</h3><ul><li><p>为 Elasticsearch 和 Kibana 配置安全功能</p><ul><li>打开 Authentication 和 Authorazatin</li><li>实现索引和字段级的安全控制</li></ul></li><li><p>节点间通信加密</p></li><li><p>Enable HTTPS</p></li><li><p>Audit logs（日志审计）</p></li></ul><h3 id="相关阅读-v8"><a class="header-anchor" href="#相关阅读-v8">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/bootstrap-checks.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/master/bootstrap-checks.html</a></p><p><a href="https://www.elastic.co/blog/a-heap-of-trouble" target="_blank" rel="noopener">https://www.elastic.co/blog/a-heap-of-trouble</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/system-config.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/system-config.html</a></p><p><a href="https://www.elastic.co/blog/is-your-elasticsearch-trimmed" target="_blank" rel="noopener">https://www.elastic.co/blog/is-your-elasticsearch-trimmed</a></p></blockquote><h1>监控 Elasticsearch 集群</h1><p>Elasticsearch 提供了多个监控相关的 api，可以通过这些 api 来查看节点级别、集群级别、索引级别的一些指标：</p><ul><li>node stat：_node/stats</li><li>cluster stat：_cluster/stats</li><li>index stats：index_name/stats</li></ul><p>同时还提供了相关的 Task API：</p><ol><li>查看 Task 相关的 API：<ul><li>Pending Cluster Tasks API：GET _cluster/pending_tasks</li><li>Task Management API：GET _tasks（可以用来 Cancel 一个 Task）</li></ul></li><li>监控 Thread Pools<ul><li>GET _nodes/thread_pool</li><li>GET _node/stats/thread_pool</li><li>GET _cat/threaad_pool?v</li><li>GET _nodes/hot_threads</li></ul></li></ol><p>The Index &amp; Query Slow Log（慢查询日志）：</p><ul><li>支持将分片上，search 和 fetch 阶段的慢查询写入文件</li><li>支持为 Query 和 Fetch 分别定义阈值（超过阈值的查询会写入日志文件）</li><li>索引级的动态设置，可以按需设置，或者通过 iindex template 统一设定</li><li>Slow log 文件通过 log4j2.properties 配置</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221533.png" alt="image-20200502100436437"></p><h3 id="如何创建监控-Dashboard"><a class="header-anchor" href="#如何创建监控-Dashboard">¶</a>如何创建监控 Dashboard</h3><ul><li>开发 Elasticsearch plugin，通过读取相关的监控 API，将数据发送到 ES，或者 TSDB。</li><li>使用 Metricbeats 搜索相关指标</li><li>使用 Kibana 或者 Grafana 创建 Dashboard</li><li>可以开发 Elasticsearch Exproter，通过 Prometheus 监控 Elasticsearch 集群</li></ul><h3 id="Kibana-相关请求"><a class="header-anchor" href="#Kibana-相关请求">¶</a>Kibana 相关请求</h3><pre><code># Node Stats：GET _nodes/stats#Cluster Stats:GET _cluster/stats#Index Stats:GET kibana_sample_data_ecommerce/_stats#Pending Cluster Tasks API:GET _cluster/pending_tasks# 查看所有的 tasks，也支持 cancel taskGET _tasksGET _nodes/thread_poolGET _nodes/stats/thread_poolGET _cat/thread_pool?vGET _nodes/hot_threadsGET _nodes/stats/thread_pool# 设置 Index Slowlogs# the first 1000 characters of the doc's source will be loggedPUT my_index/_settings{  &quot;index.indexing.slowlog&quot;:{    &quot;threshold.index&quot;:{      &quot;warn&quot;:&quot;10s&quot;,      &quot;info&quot;: &quot;4s&quot;,      &quot;debug&quot;:&quot;2s&quot;,      &quot;trace&quot;:&quot;0s&quot;    },    &quot;level&quot;:&quot;trace&quot;,    &quot;source&quot;:1000    }}# 设置查询DELETE my_index//&quot;0&quot; logs all queriesPUT my_index/{  &quot;settings&quot;: {    &quot;index.search.slowlog.threshold&quot;: {      &quot;query.warn&quot;: &quot;10s&quot;,      &quot;query.info&quot;: &quot;3s&quot;,      &quot;query.debug&quot;: &quot;2s&quot;,      &quot;query.trace&quot;: &quot;0s&quot;,      &quot;fetch.warn&quot;: &quot;1s&quot;,      &quot;fetch.info&quot;: &quot;600ms&quot;,      &quot;fetch.debug&quot;: &quot;400ms&quot;,      &quot;fetch.trace&quot;: &quot;0s&quot;    }  }}GET my_index</code></pre><h1>诊断集群的潜在问题</h1><h3 id="集群运维所面临的挑战"><a class="header-anchor" href="#集群运维所面临的挑战">¶</a>集群运维所面临的挑战</h3><ul><li><p>用户集群数量多，业务场景差异大</p></li><li><p>存在使用与配置不当，优化不够的问题</p><ul><li>如何让用户更加高效和正确的使用 ES</li><li>如何让用户更全面的了解自己的集群的使用状况</li></ul></li><li><p>发现问题之后，需要防患于未然</p><ul><li>需要&quot;有迹可循&quot;，做到&quot;有则改之，无则加勉&quot;</li><li>Elastic 有提供 Support Diaagnostics Tool：<a href="https://github.com/elastic/support-diagnostics" target="_blank" rel="noopener">https://github.com/elastic/support-diagnostics</a>。完全基于 Java 语言开发的工具，当集群出现问题的时候，可以运行这个工具，收集集群的一些指标，帮助 ES 公司对一些问题作出诊断。</li></ul></li><li><p>监控指标多并且分散，指标啊的含义不够明确直观（集群的绿色状态只是其中一项指标，并意味着集群足够好了，其仅表示分片是否都已经正常分配）</p></li><li><p>问题分析定位的门槛较高，需要具备非常多的专业知识</p></li></ul><h3 id="为什么要诊断集群的潜在问题"><a class="header-anchor" href="#为什么要诊断集群的潜在问题">¶</a>为什么要诊断集群的潜在问题</h3><p>即便 ES 是在绿色状态，但是我们依然要经常对 ES 做一些指标的分析，防患于未然，避免集群奔溃</p><ul><li>Master 节点或者数据节点宕机；负载过高，导致节点失联，都需要提前介入</li><li>副本丢失，导致数据可靠性受损</li><li>集群压力过大，数据写入失败</li></ul><p>提升集群性能</p><ul><li>数据节点负载不均衡（避免单节点瓶颈）的时候需要优化分片（例如segments数量过多了，手动出发合并）</li><li>规范操作方式（利用别名、避免 Dynamic Mapping 引发过多字段，对索引的合理性进行管控）</li></ul><h3 id="eBay-Diagnostic-Tools"><a class="header-anchor" href="#eBay-Diagnostic-Tools">¶</a>eBay Diagnostic Tools</h3><ul><li>集群健康状态，是否有节点丢失</li><li>索引合理性：索引总数不能过大、副本分片尽量不要设置为0、主分片尺寸检测、索引的字段总数（Dynamic Mapping 关闭）、索引是否分配不均衡、索引 Segment 大小诊断分析、数据节点之间的负载偏差是否过大、冷热数据分配是否正确（例如，Cold 节点上的索引是否设置成只读）</li><li>资源使用合理性：CPU 内存和磁盘的使用状况分析、是否存在节点负载不平衡、是否需要增加节点</li><li>业务操作合理性：集群状态变更频率，是否在业务高峰期有频繁操作；慢查询监控与分析</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221542.png" alt="image-20200502102215609"></p><h3 id="阿里云：EYOU-智能运维工具"><a class="header-anchor" href="#阿里云：EYOU-智能运维工具">¶</a>阿里云：EYOU 智能运维工具</h3><p>每天凌晨定时诊断，也可以自主诊断。每次诊断耗时3分钟。（<a href="https://help.aliyun.com/document_detail/90391.html" target="_blank" rel="noopener">https://help.aliyun.com/document_detail/90391.html</a>）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221552.png" alt="image-20200502102632163"></p><p>诊断 Shard 数</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221643.png" alt="image-20200502102738786"></p><p>磁盘容量估算</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221658.png" alt="image-20200502102754737"></p><h3 id="多维度检测，构建自己的诊断工具"><a class="header-anchor" href="#多维度检测，构建自己的诊断工具">¶</a>多维度检测，构建自己的诊断工具</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221709.png" alt="image-20200502102814615"></p><h3 id="相关阅读-v9"><a class="header-anchor" href="#相关阅读-v9">¶</a>相关阅读</h3><blockquote><p><a href="https://elasticsearch.cn/slides/162" target="_blank" rel="noopener">https://elasticsearch.cn/slides/162</a></p><p><a href="https://yq.aliyun.com/articles/657712" target="_blank" rel="noopener">https://yq.aliyun.com/articles/657712</a></p><p><a href="https://yq.aliyun.com/articles/657108" target="_blank" rel="noopener">https://yq.aliyun.com/articles/657108</a></p><p><a href="https://help.aliyun.com/document_detail/90391.html" target="_blank" rel="noopener">https://help.aliyun.com/document_detail/90391.html</a></p></blockquote><h1>解决集群 Yellow 与 Red 的问题</h1><p>分片健康：</p><ul><li>红：至少有一个主分片没有分配</li><li>黄：至少有一个副本分片没有分配</li><li>绿：主副本分片全部正常分配</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221723.png" alt="image-20200502103351675"></p><h3 id="Health-相关的-API"><a class="header-anchor" href="#Health-相关的-API">¶</a>Health 相关的 API</h3><table><thead><tr><th>API</th><th>描述</th></tr></thead><tbody><tr><td>GET _cluster/health</td><td>集群的状态（检查节点数量）</td></tr><tr><td>GET _cluster/health?level=indices</td><td>所有索引的健康状态（查看有问题的索引）</td></tr><tr><td>GET _cluster/health/my_index</td><td>单个索引的健康状态（查看具体的索引）</td></tr><tr><td>GET _cluster/heaalth?level=shards</td><td>分片级的索引</td></tr><tr><td>GET _cluster/allocation/explain</td><td>返回第一个未分配 shard 的原因</td></tr></tbody></table><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221735.png" alt="image-20200502103808261"></p><h3 id="案例1：集群变红"><a class="header-anchor" href="#案例1：集群变红">¶</a>案例1：集群变红</h3><p>我们在索引的创建初期可能因为一些错误的设置，导致集群无法进行分片分配。这个时候可以通过explain api 找到真正的原因，然后将刚创建的索引进行简单的删除，重新正确设置之后再创建即可。</p><ol><li><p>集群初始状态为绿色</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221746.png" alt="image-20200502192747153"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221755.png" alt="image-20200502192806534"></p><p>集群上一共有3个节点</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221804.png" alt="image-20200502192857735"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221810.png" alt="image-20200502192904871"></p><p>查看节点属性，可以看到我们自定义了属性未 box_type，三个节点的值分别为：hot、warm、cold</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221817.png" alt="image-20200502192940381"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221827.png" alt="image-20200502193029343"></p></li><li><p>我们现在来创建一个 index，创建之后好像 index 没有得到任何的返回</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221833.png" alt="image-20200502193209472"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221840.png" alt="image-20200502193247086"></p></li><li><p>这时候再次尝试去查看集群状态，发现集群为红色</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221845.png" alt="image-20200502193320202"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221850.png" alt="image-20200502193332717"></p></li><li><p>查看是哪一个索引导致集群变红。可以看到，就是刚刚创建的&quot;mytest&quot;索引</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221858.png" alt="image-20200502193421517"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221904.png" alt="image-20200502193444128"></p></li><li><p>尝试使用 explain api 看一下为什么集群会变红，可以看到是因为没有节点是匹配&quot;index.routing.allocation.require&quot;一项的，因为 box_type 的值是&quot;hott&quot;，设置索引 settings 的时候拼写错误了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221913.png" alt="image-20200502193546327"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221918.png" alt="image-20200502193657352"></p></li><li><p>我们先删除索引</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221931.png" alt="image-20200502193809038"></p><p>再查看集群状况，可以看到变回绿色了</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221936.png" alt="image-20200502193834375"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221941.png" alt="image-20200502193842477"></p></li><li><p>重新创建索引，并设置正确的属性值&quot;hot&quot;</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221949.png" alt="image-20200502193937703"></p><p>再次查询集群状况，可以看到是绿色的了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221221955.png" alt="image-20200502194000876"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222000.png" alt="image-20200502194019636"></p></li></ol><h3 id="案例2：集群变黄"><a class="header-anchor" href="#案例2：集群变黄">¶</a>案例2：集群变黄</h3><ol><li>先将前面创建的 mytest 索引删除，然后再重新设定</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222009.png" alt="image-20200502194255230"></p><ol start="2"><li>查看集群状态，发现返回的是 yellow</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222017.png" alt="image-20200502194323886"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222021.png" alt="image-20200502194342547"></p><ol start="3"><li>再通过 explain api 查看具体的原因，可以看到是 mytest 的索引存在一个未分配的情况，通过查看具体的原因发现还是因为没有节点匹配 box_type 为 hot 的问题。但是这一次我们的配置是对的了。然后我们再查看集群的节点属性发现&quot;hot&quot;节点其实只有一个，但是我们设置索引 settings 的时候是为索引指定了一个副本分片的，而我们又设置了&quot;require&quot;box_type 为 hot 才能分配，那么这时候副本分片就找不到其他 hot 节点做备份了。所以处于无法分配的状态。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222029.png" alt="image-20200502194430079"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222035.png" alt="image-20200502194510603"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222042.png" alt="image-20200502194858284"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222048.png" alt="image-20200502194536979"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222055.png" alt="image-20200502194947659"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222105.png" alt="image-20200502195002218"></p><ol start="4"><li>那么此时我们有两个解决方案：一个是增加一个 hot 节点使得可以正确分配一个副本分片；另外一个是重新设置索引的 settings 文件使得副本分片数量为0。</li></ol><h3 id="分片没有被分配的一些原因"><a class="header-anchor" href="#分片没有被分配的一些原因">¶</a>分片没有被分配的一些原因</h3><ul><li>index_create：在创建索引的时候，在索引的全部分片分配完成之前，会有短暂的 red，不一定代表有问题</li><li>cluster_recover：集群重启阶段，会有这个问题</li><li>index_reopen：open 一个之前 close 的索引</li><li>dangling_index_imported：一个节点离开集群期间，有索引被删除。这个节点重新返回时，会导致 Dangling 的问题，此时我们再对这个索引进行删除操作，就可以解决了。</li></ul><h3 id="常见问题与解决方法"><a class="header-anchor" href="#常见问题与解决方法">¶</a>常见问题与解决方法</h3><ul><li><p>集群变红，需要检查是否有节点离线。如果有，通常通过重启离线的节点可以解决问题。</p></li><li><p>由于配置导致的问题，需要修复相关的配置。如果是测试的索引，可以直接删除</p></li><li><p>因为磁盘空间限制，分片规则（Shard Filtering）引发的，需要调整规则或者增加节点</p></li><li><p>对于节点返回集群，导致的 dangling 变红，可以直接删除 dangling 索引</p></li></ul><h3 id="集群-Red-Yellow-问题的总结"><a class="header-anchor" href="#集群-Red-Yellow-问题的总结">¶</a>集群 Red &amp; Yellow 问题的总结</h3><p>Red &amp; Yellow 是集群运维中常见的问题。除了集群故障，一些创建，增加副本等操作，都会导致集群短暂的 red 和 yellow，所以监控和报警时需要设置一定的时延。通过检查节点数，使用 ES 提供的相关 API，找到真正的原因。</p><p><strong>同时根据情况也可以指定 Move 或者 Reallocate 分片：</strong></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222113.png" alt="image-20200502200149661"></p><h3 id="相关阅读-v10"><a class="header-anchor" href="#相关阅读-v10">¶</a>相关阅读</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/cat-shards.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/cat-shards.html</a></p><h3 id="Kibana-请求测试"><a class="header-anchor" href="#Kibana-请求测试">¶</a>Kibana 请求测试</h3><pre><code>#案例1DELETE mytestPUT mytest{  &quot;settings&quot;:{    &quot;number_of_shards&quot;:3,    &quot;number_of_replicas&quot;:0,    &quot;index.routing.allocation.require.box_type&quot;:&quot;hott&quot;  }}# 检查集群状态，查看是否有节点丢失，有多少分片无法分配GET /_cluster/health/# 查看索引级别,找到红色的索引GET /_cluster/health?level=indices#查看索引的分片GET _cluster/health?level=shards# Explain 变红的原因GET /_cluster/allocation/explainGET /_cat/shards/mytestGET _cat/nodeattrsDELETE mytestGET /_cluster/health/PUT mytest{  &quot;settings&quot;:{    &quot;number_of_shards&quot;:3,    &quot;number_of_replicas&quot;:0,    &quot;index.routing.allocation.require.box_type&quot;:&quot;hot&quot;  }}GET /_cluster/health/#案例2, Explain 看 hot 上的 explainDELETE mytestPUT mytest{  &quot;settings&quot;:{    &quot;number_of_shards&quot;:2,    &quot;number_of_replicas&quot;:1,    &quot;index.routing.allocation.require.box_type&quot;:&quot;hot&quot;  }}GET _cluster/healthGET _cat/shards/mytestGET /_cluster/allocation/explainPUT mytest/_settings{    &quot;number_of_replicas&quot;: 0}</code></pre><h1>集群写性能优化</h1><p>写性能的优化目标是增大写吞吐量（Events Per Second），越高越好。性能优化主要分为两个方向，客户端和服务端：</p><ul><li>客户端：使用多线程，buik API 批量写<ul><li>可以通过性能测试，确定一个 bulk api 的最佳文档数量是多少</li><li>多线程写入的情况下，需要观察是否有 HTTP 429的返回，如果有，说明服务端已经无法处理目前的请求量了，这时候客户端需要对返回429的请求有一个重试并自动调节线程数的机制</li></ul></li><li>服务器端：单个性能问题，往往是多个因素造成的。需要先分解问题，在单个节点上进行调整并结合测试，尽可能压榨硬件资源，以达到最高吞吐量<ul><li>使用更好的硬件，观察 CPU、IO Block</li><li>观察线程切换、堆栈情况</li></ul></li></ul><h3 id="服务端优化写入性能的一些手段"><a class="header-anchor" href="#服务端优化写入性能的一些手段">¶</a>服务端优化写入性能的一些手段</h3><ol><li>降低 IO 操作。例如使用 ES 自动生成的文档 id，如果我们自己生成 id，ES会有一个 GET操作，对性能有一定开销。还有其他一些相关的 ES 配置，例如 Refresh Interval</li><li>降低 CPU 和存储开销：减少不必要的分词、避免不需要的 doc_value 文档、文档的字段尽量保证相同的顺序，可以提供文档的压缩率</li><li>尽可能做到<strong>文档写入请求</strong>(Write Load Balancer)和<strong>分片</strong>(Shard Filtering)的负载均衡，实现水平扩展</li><li>调整 Build 线程池和队列</li></ol><h3 id="高质量数据建模"><a class="header-anchor" href="#高质量数据建模">¶</a>高质量数据建模</h3><p>ES 的默认配置已经总和考虑了数据可靠性，搜索的实时性质，写入速度，一般不要盲目修改。一切优化，都要基于当前的数据建模是高质量的。以下是建模的一些建议：</p><ul><li><p>只需要聚合不需要搜索，index 设置成 false</p></li><li><p>不需要算分，norms 设置成 false</p></li><li><p>不要对字符串使用默认的 dynamic mapping，因为默认的 mapping 会对 text 类型数据自动生成一个 keyword 子字段，我们按需自己手动设置。另外一般也不建议是有那个 dynamic mapping，因为可能会导致字段数量过多，会对性能产生较大的影响</p></li><li><p>Index_optiions 控制在创建倒排索引的时，哪些内容会被添加到倒排索引中。优化这些设置，一定程度可以节约 CPU</p></li><li><p>关闭 _source，减少 IO 操作（适合指标型数据）</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222120.png" alt="image-20200502202412916"></p><h3 id="牺牲一定可靠性和实时性增加写入性能"><a class="header-anchor" href="#牺牲一定可靠性和实时性增加写入性能">¶</a>牺牲一定可靠性和实时性增加写入性能</h3><p>如果需要追求极致的写入速度，可以牺牲数据可靠性及搜索实时性以换取性能。</p><ul><li>牺牲可靠性：将副本分片设置为0，写入完毕再调整回去</li><li>牺牲搜索实时性：增加 Refresh Interval 的时间</li><li>牺牲可靠性：修改 Translog 的配置</li></ul><p>下面我们来回顾一下数据写入的过程，来看一下有哪些点可以优化提高写入性能：</p><ol><li>refresh：将文档先保存在 Index Buffer 中，以refresh_interval 为间隔时间，定期清空 buffer，生成 segments，借助文件系统缓存的特性，先将 segments 刷到文件系统缓存中，并开放查询，以提升搜索的实时性</li><li>Translog：Segments 没有写入磁盘，即便发生了宕机，重启后，数据也能恢复，默认配置是每次请求都会落盘</li><li>Flush：请求一次 refresh 生成 Segments cache 并连着 cache 中之前生成的 segments 一起写入磁盘，更新 commit point 并写入磁盘，删除旧的 translog 文件。ES 自动完成，可优化点不多。</li></ol><h4 id="Refresh-Interval的优化"><a class="header-anchor" href="#Refresh-Interval的优化">¶</a>Refresh Interval的优化</h4><p>我们可以通过降低 Refresh 的频率，减少生成 segments cache 的动作以及生成过多的 segment 文件，空出更多的单位时间系统资源以供写入操作的使用（但是会降低搜索的实时性）：</p><ul><li>增加 refresh_interval 的数值。默认值是1s，如果设置成-1，会禁止自动 refresh</li><li>增大静态配置参数<code>indices.memory.index_buffer_size</code>，默认是10%，不然即使我们设置了 refresh_interval，但是在 index_buffer 满了情况下还是会导致自动出发 refresh</li></ul><h4 id="Translog-的优化"><a class="header-anchor" href="#Translog-的优化">¶</a>Translog 的优化</h4><p>另外我们还可以通过以下方式降低 ES 写入 Translog 的频率和实时性，但是会降低容灾能力：</p><ul><li><code>index.translog.durability</code>：默认是 request，每个请求都会同步地进行 translog 落盘操作之后才会返回客户端，设置为 async，异步写入</li><li><code>index.translog.sync_interval</code>：设置为60s，每分钟执行一次 translog 的磁盘写入而不是每一次请求都会导致落盘（配合上面参数使用）</li><li><code>index.translog.flush_threshod_size</code>：默认512mb，可以适当调大。当 translog 超过该值，会触发 flush</li></ul><h4 id="分片设定"><a class="header-anchor" href="#分片设定">¶</a>分片设定</h4><ul><li><p>副本在写入的时候设定为0，完成后再增加。</p></li><li><p>合理设置主分片数，确保均匀分配在所有数据节点上：</p><p><code>index.routing.allocation.total_share_per_node</code>：限定每个索引在每个节点上可以分配的<strong>主副本分片数</strong>（这样可以避免一些热点索引数据集中在一个节点上）</p><p>一个例子：5个节点的集群。索引有5个主分片，1个副本分片，应该如何设置？</p><ul><li>(5+5) / 5 = 2 （ 设置以上参数值）</li><li>生产环境中要适当调大这个数字，避免有节点下线，分片无法正常迁移</li></ul></li></ul><h3 id="Bulk-线程池和队列大小"><a class="header-anchor" href="#Bulk-线程池和队列大小">¶</a>Bulk 线程池和队列大小</h3><p>客户端：</p><ul><li>单个 bulk 请求体的数据量不要太大，官方建议5-15mb</li><li>写入端的 bulk 请求超时需要足够长，需要60s 以上</li><li>写入端尽量将数据轮询打到不同节点（LB）</li></ul><p>服务器端：</p><ul><li>索引创建属于计算密集型任务，应该使用固定大小的线程池来配置。来不及处理的放入队列，线程数应该配置成 CPU 核心数+1，避免过多的上下文切换</li><li>队列大小可以适当增加，不要过大，否则占用的内存会成为 GC 的负担</li></ul><h3 id="一个索引设定的例子"><a class="header-anchor" href="#一个索引设定的例子">¶</a>一个索引设定的例子</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222131.png" alt="image-20200502205658949"></p><pre><code>{    &quot;template&quot;:&quot;logs-*&quot;,    &quot;settings&quot;:{        &quot;index.indexing.slowlog.threshold.index.debug&quot;:&quot;2s&quot;,        &quot;index.indexing.slowlog.threshold.index.info&quot;:&quot;5s&quot;,        &quot;index.indexing.slowlog.threshold.index.trace&quot;:&quot;500ms&quot;,        &quot;index.indexing.slowlog.threshold.index.warn&quot;:&quot;10s&quot;,        &quot;index.merge.policy.max_merged_segment&quot;:&quot;2gb&quot;,        &quot;index.merge.policy.segments_per_tier&quot;:&quot;24&quot;,        &quot;index.number_of_replicas&quot;:&quot;1&quot;,        &quot;index.number_of_shards&quot;:&quot;12&quot;,        &quot;index.optimize_auto_generated_id&quot;:&quot;true&quot;,        &quot;index.refresh_interval&quot;:&quot;600s&quot;,        &quot;index.routing.allocation.total_shards_per_node&quot;:&quot;-1&quot;,        &quot;index.search.slowlog.threshold.fetch.debug&quot;:&quot;500ms&quot;,        &quot;index.search.slowlog.threshold.fetch.info&quot;:&quot;800ms&quot;,        &quot;index.search.slowlog.threshold.fetch.trace&quot;:&quot;200ms&quot;,        &quot;index.search.slowlog.threshold.fetch.warn&quot;:&quot;1s&quot;,        &quot;index.search.slowlog.threshold.query.debug&quot;:&quot;2s&quot;,        &quot;index.search.slowlog.threshold.query.info&quot;:&quot;5s&quot;,        &quot;index.search.slowlog.threshold.query.trace&quot;:&quot;500ms&quot;,        &quot;index.search.slowlog.threshold.query.warn&quot;:&quot;10s&quot;,        &quot;index.translog.durability&quot;:&quot;async&quot;,        &quot;index.translog.flush_threshold_size&quot;:&quot;5000mb&quot;,        &quot;index.translog.sync_interval&quot;:&quot;120s&quot;,        &quot;index.unassigned.node_left.delayed_timeout&quot;:&quot;7200m&quot;    },    &quot;mappings&quot;:{        &quot;_default_&quot;:{            &quot;_all&quot;:{                &quot;store&quot;:&quot;false&quot;            }        },        &quot;typename&quot;:{            &quot;dynamic&quot;:false,            &quot;properties&quot;:{                &quot;full_name&quot;:{                    &quot;type&quot;:&quot;text&quot;                }            }        }    }}</code></pre><h3 id="相关阅读-v11"><a class="header-anchor" href="#相关阅读-v11">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html</a></p></blockquote><h1>集群读性能优化</h1><ol><li>首先我们不能将 ES 当做一个普通的关系型数据库来对待，我们要尽量对数据做Denomalization。从而获取最佳的性能：</li></ol><ul><li>使用 nested 类型的数据。查询速度会慢几倍</li><li>使用 Parent / Child 关系。查询速度会慢几百倍</li></ul><p>所以可以避免使用以上数据类型就尽量避免。</p><ol start="2"><li><p>对于需要进行Script 计算的数据，可以在 index 文档的时候，使用 ingest pipeline 计算然后写入ES。尽量避免查询时使用 Script 计算。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222144.png" alt="image-20200502210602653"></p></li><li><p>尽量使用 Filter Context，利用缓存机制，减少不必要的算分</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222150.png" alt="image-20200502210650530"></p></li><li><p>结合 profile，expalin API 分析慢查询的问题，持续优化数据模型</p></li><li><p>严禁使用 * 开头通配符 Terms 查询</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222200.png" alt="image-20200502210932397"></p></li><li><p>聚合文档消耗内存，特别时针对很大的数据集进行聚合运算，如果可以控制聚合的数量，就能减少内存的开销；当需要使用不同的 Query Scope，可以使用 Filter Bucket（和上面提到的一样，使用 Filter 替代 Query）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222207.png" alt="image-20200502210818880"></p></li><li><p>尽量提高 filesystem cache的大小，前面我们提到过，内存一半空间分给 JVM 一半空间留给lucene 的 segments。ES 检索索引的时候底层都是查询的 lucene 的一个个 segments，会先查os cache 后查 file system，如果在缓存能命中，会大大提高效率。</p></li><li><p>分页能用 scoll api 的方式就经量使用，尽量避免深度分页。</p></li></ol><h3 id="优化分片"><a class="header-anchor" href="#优化分片">¶</a>优化分片</h3><ul><li>避免 Over Sharing（过多分片），它会导致一个查询需要访问每一个分片，分片过多，会导致不必要的查询开销。</li><li>结合应用场景，控制单个分片的尺寸：<ul><li>search：20GB</li><li>Logging：40GB</li></ul></li><li>基于时间序列的索引，我们要及时地对这些数据做老化处理，将它们设置为 read-only 然后对它们做一个 force merge 操作，减少 segments 数量</li></ul><h3 id="相关阅读-v12"><a class="header-anchor" href="#相关阅读-v12">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html</a></p></blockquote><h1>集群压力测试</h1><p>在我们在做一些容量规划和性能调优的时候，都需要进行一些实际的测试，看一下实际的效果。</p><h3 id="压力测试的方法与步骤"><a class="header-anchor" href="#压力测试的方法与步骤">¶</a>压力测试的方法与步骤</h3><ul><li>测试计划（确定测试场景和测试数据集）</li><li>脚本开发</li><li>测试环境搭建（不同的软硬件配置）&amp; 运行测试</li><li>分析比较结果</li></ul><h3 id="测试目标和测试数据"><a class="header-anchor" href="#测试目标和测试数据">¶</a>测试目标和测试数据</h3><ul><li>测试目标<ul><li>测试集群的读写性能、做集群容量规划</li><li>性能问题诊断及优化：<ul><li>对 ES 配置参数进行修改，评估优化效果</li><li>修改 Mapping 和 Setting，对数据建模进行优化，并测试评估性能改进</li></ul></li><li>测试 ES 新版本，结合实际场景和老版本进行比较，评估是否进行升级</li><li>确定系统稳定性，考察系统功能极限和隐患</li></ul></li><li>测试数据集对于压测结果的影响也非常大，我们主要从数据量和数据分布两个方面进行考虑</li></ul><h3 id="测试脚本"><a class="header-anchor" href="#测试脚本">¶</a>测试脚本</h3><p>ES 本身提供了 REST API，所以，可以通过很多传统的性能测试工具：</p><ul><li>Load Runner（商业软件，支持录制+重放+DSL）</li><li>JMeter（Apache 开源，Record &amp; Play）</li><li>Gatling（开源，支持写 Scala 代码+DSL）</li></ul><p>另外，还有一些专门为 Elasticsearch 设计的工具</p><ul><li>ES Pref &amp; Elasticsearch-stress-test</li><li>Elastic Rally</li></ul><h3 id="ES-Rally"><a class="header-anchor" href="#ES-Rally">¶</a><a href="https://github.com/elastic/rally" target="_blank" rel="noopener">ES Rally</a></h3><p>Elastic 官方开源，基于 Python3的压力测试工具：</p><ul><li>github 地址：<a href="https://github.com/elastic/rally" target="_blank" rel="noopener">https://github.com/elastic/rally</a></li><li>官方 ES 性能测试结果比较(通过 Rally 得到的)：<a href="https://elasticsearch-benchmarks.elastic.co" target="_blank" rel="noopener">https://elasticsearch-benchmarks.elastic.co</a></li></ul><p>功能介绍：</p><ul><li>自动创建、配置、运行测试、并且销毁 ES 集群</li><li>支持不同的测试数据（自带一些数据集）的比较，也支持将数据导入 ES集群，进行二次分析</li><li>支持测试时指标数据的搜索，方便对测试结果进行深度的分析</li></ul><h4 id="安装以及入门"><a class="header-anchor" href="#安装以及入门">¶</a>安装以及入门</h4><ol><li>安装<ul><li>Python3.4+和 pip3、JDK 8、git 1.9+</li><li>运行 pip3 install esrally</li><li>运行 esrally configure</li></ul></li><li>运行<ul><li>运行 esrally -distribution-version=7.1.0（会使用默认的数据集进行测试，数据量很大）</li><li>运行1000条测试数据：esrally -distribution-version=7.1.0 --test-mdoe（使用 test mode 默认使用前1000条数据进行测试）</li></ul></li></ol><h4 id="Rally-基本概念讲解"><a class="header-anchor" href="#Rally-基本概念讲解">¶</a>Rally 基本概念讲解</h4><p>Rally 使用了汽车拉力赛中的概念对压力测试进行类比以及引用了相关的术语进行相关模块的命名：</p><ul><li><p><a href="https://esrally.readthedocs.io/en/stable/tournament.html" target="_blank" rel="noopener">Tournament</a>（锦标赛）：定义测试目标，由多个 race 组成</p></li><li><p>Race（锦标赛中的一次比赛）：其实就是一次压力测试操作（esrally list race）</p></li><li><p>[Track](<a href="https://github.com/elastic/rally-" target="_blank" rel="noopener">https://github.com/elastic/rally-</a> tracks)（赛道）：测试数据和测试场景与策略（esrally list tracks）</p></li><li><p>Car（赛车）：代表不同的 ES 实例（来执行测试方案）</p></li><li><p>Award（颁奖）：测试结果和报告</p></li></ul><h4 id="压测流程"><a class="header-anchor" href="#压测流程">¶</a>压测流程</h4><p>Rally 中pipeline 指的是压测的一个流程（通过 <code>esrally list pipelines</code>命令查看有什么 pipeline），表示Rally 默认有以下流程供使用：</p><ul><li>From-source-complete：从源码编译构建出一个 ES并搭建集群，然后在这个集群上运行一个基准(benchmark)测试并报告结果。</li><li>From-source-skip-build：使用已经构建好的一个 ES 搭建集群，然后在这个集群上运行一个基准(benchmark)测试并报告结果。</li><li>From-distribution：下载一个已经发布的 ES，搭建集群，然后在这个集群上运行一个基准(benchmark)测试并报告结果。</li><li>Benchmark-only：在一个已经在运行的 ES 实例上执行一个基准测试并报告结果。</li></ul><h4 id="自定义测试-分布式测试"><a class="header-anchor" href="#自定义测试-分布式测试">¶</a>自定义测试&amp;分布式测试</h4><p>使用不同的 car（不同配置的 ES 集群）：</p><ul><li><p><a href="https://esrally.readthedocs.io/en/latest/car.html" target="_blank" rel="noopener">https://esrally.readthedocs.io/en/latest/car.html</a></p></li><li><p>使用自建的集群</p></li></ul><p>使用不同的 Track（不同测试数据）：</p><ul><li>Rally自带的测试数据集：Nyc_taxis(4.5G)、logging(1.2G)</li><li>更多的测试数据集：<a href="https://github.com/elastic/rally-tracks" target="_blank" rel="noopener"> https://github.com/elastic/rally-tracks</a></li></ul><p>当需要对一个特别大的 ES 集群进行测试的时候，Rally 还支持分布式测试的模式，可以在不同的机器上分别搭建 Rally，进行一个分布式测试：[<a href="https://esrally.readthedocs.io/en/latest/recipes.html#recipe-distributed-load-" target="_blank" rel="noopener">https://esrally.readthedocs.io/en/latest/recipes.html#recipe-distributed-load-</a> driver](<a href="https://esrally.readthedocs.io/en/latest/recipes.html#recipe-distributed-load-" target="_blank" rel="noopener">https://esrally.readthedocs.io/en/latest/recipes.html#recipe-distributed-load-</a> driver)</p><h3 id="实例：比较不同版本的性能"><a class="header-anchor" href="#实例：比较不同版本的性能">¶</a>实例：比较不同版本的性能</h3><p>对 ES6.0和7.1进行测试，使用相同的测试数据集 nyc_taxis：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 6.0esrally race --distribution-version=6.0.0 --track=nyc_taxis --challenge=append-no-conflicts --user-tag="version:6.0.0”# 7.0esrally race --distribution-version=7.1.0 --track=nyc_taxis --challenge=append-no-conflicts --user-tag="version:7.1.0"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>比较结果</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">esrally list racesesrally compare --baseline=[6.0.0 race] --contender=[7.1.0 race]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="实例：比较不同-Mapping-的性能"><a class="header-anchor" href="#实例：比较不同-Mapping-的性能">¶</a>实例：比较不同 Mapping 的性能</h3><p>测试 mapping 文件中 _source 是否 enabled 的性能差异</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 优化前测试esrally race --distribution-version=7.1.0 --track=nyc_taxis --challenge=append-no-conflicts --user-tag="enableSource:true" --include-tasks="type:index”# 修改优化：benchmarks/tracks/default/nyc_taxis/mappings.json，修改 _source.enabled 为 false# 修改后在测试esrally race --distribution-version=7.1.0 --track=nyc_taxis --challenge=append-no-conflicts --user-tag="enableSource:false" --include-tasks="type:index<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>比较</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">esrally compare --baseline=[enableAll race] --contender=[disableAll race]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="实例：测试现有集群的性能"><a class="header-anchor" href="#实例：测试现有集群的性能">¶</a>实例：测试现有集群的性能</h3><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 指定 pipeline 为 benchmark-only 并指定现有集群的连接信息esrally race --pipeline=benchmark-only --target-hosts=127.0.0.1:9200 --track=geonames --challenge=append-no-conflicts<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="相关阅读-v13"><a class="header-anchor" href="#相关阅读-v13">¶</a>相关阅读</h3><blockquote><p><a href="https://github.com/elastic/rally" target="_blank" rel="noopener">https://github.com/elastic/rally</a></p><p><a href="https://github.com/elastic/rally-tracks" target="_blank" rel="noopener">https://github.com/elastic/rally-tracks</a></p><p><a href="https://logz.io/blog/rally/" target="_blank" rel="noopener">https://logz.io/blog/rally/</a></p><p><a href="https://elasticsearch-benchmarks.elastic.co" target="_blank" rel="noopener">https://elasticsearch-benchmarks.elastic.co</a></p><p><a href="https://esrally.readthedocs.io/en/stable/tournament.html" target="_blank" rel="noopener">https://esrally.readthedocs.io/en/stable/tournament.html</a></p><p><a href="https://esrally.readthedocs.io/en/latest/car.html" target="_blank" rel="noopener">https://esrally.readthedocs.io/en/latest/car.html</a></p><p><a href="https://github.com/elastic/rally-tracks" target="_blank" rel="noopener"> https://github.com/elastic/rally-tracks</a></p><p>[<a href="https://esrally.readthedocs.io/en/latest/recipes.html#recipe-distributed-load-" target="_blank" rel="noopener">https://esrally.readthedocs.io/en/latest/recipes.html#recipe-distributed-load-</a> driver](<a href="https://esrally.readthedocs.io/en/latest/recipes.html#recipe-distributed-load-" target="_blank" rel="noopener">https://esrally.readthedocs.io/en/latest/recipes.html#recipe-distributed-load-</a> driver)</p></blockquote><h1>段合并优化及注意事项</h1><h3 id="Lucene-Index-原理回顾"><a class="header-anchor" href="#Lucene-Index-原理回顾">¶</a>Lucene Index 原理回顾</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222221.png" alt="image-20200502222356402"></p><h3 id="Merge-优化"><a class="header-anchor" href="#Merge-优化">¶</a>Merge 优化</h3><p>ES 和 Lucene 默认情况会自动进行 merge 操作，但是 merge 操作相对比较重，需要优化，降低对系统的影响。</p><ol><li><p>优化点1：降低分段产生的数量/频率</p><p>可以将 Refresh Interval 调整到分钟级别、<code>indices.memory.index_buffer_size</code>调大（默认10%）、尽量避免文档的更新操作</p></li><li><p>优化点2：降低最大分段大小，避免较大的分段继续参与 merge，节省系统资源。（这时候一个 ES 分片一个 Lucene 索引下面会一直存在多个分段，检索文档数据就需要分别从各个分段进行检索）</p><ul><li><code>index.merge.policy.segments_per_tier</code>参数修改，默认为10，越小需要越多的合并操作。（ES会定时检查分片中segments 的个数发现超过阈值就立马进行 merge？）</li><li><code>index.merge.policy.max_merged_segment</code>参数修改，默认5GB，经过不断的 segments 合并，当合并后的 segment 到达这个大小的时候，后续即使有新的 segments 生成，该 segment 也不再参与合并</li></ul></li><li><p>优化点3：force marge</p><p>当 index 中不再有写入操作的时候，建议将其改成 read-only，并对其进行 force merge，merged 之后提升查询速度，较少内存开销</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222228.png" alt="image-20200502223311927"></p><p>最终分成几个 segments 比较合适？越少越好，最好可以 force merge 成1个，但是 force merge 会占用大量的网络IO、磁盘IO和 CPU。如果不能在业务高峰期之前做完，就需要考虑增大最终的分段数或者通过一些配置来优化提高 force merge 的效率。（也可以降低一个分片的大小）</p></li></ol><h1>缓存及使用 Breaker 限制内存使用</h1><p>本节来讨论 ES 的缓存结构及一些缓存相关的问题。ES 的缓存主要分为三大类：</p><ul><li>Node Query Cache（Filter Context）</li><li>Shard Query Cache（Cache Query的结果）</li><li>Fielddata Cache</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222234.png" alt="image-20200502225126155"></p><h3 id="Node-Query-Cache"><a class="header-anchor" href="#Node-Query-Cache">¶</a>Node Query Cache</h3><p>每一个节点都有一个 Node Query 缓存</p><ul><li>由该节点的所有 Shard 共享，只缓存 Filter Context 相关内容。</li><li>采用 LRU 算法</li></ul><p>通过在每个 Data Node 的静态文件中进行全局配置以下参数：</p><ul><li>Node Level：<code>indices.queries.cache.size</code>: “10%”(默认值10%)</li><li>Index Level：<code>index.queries.cache.enabled</code>: true</li></ul><h3 id="Shard-Request-cache"><a class="header-anchor" href="#Shard-Request-cache">¶</a>Shard Request cache</h3><p>缓存每个分片上的查询结果，只会缓存设置了 “size=0” 的查询对应的结果，不会缓存 hits。但是会缓存 Aggregations 和 Suggestions。</p><p>这个 Cache 也是使用 LRU 算法，将整个 JSON 查询字符串作为 Key，所以我们需要保证查询的 JSON 字符串中的 JSON 属性顺序是一致的了保证缓存命中。</p><p>通过在数据节点上配置参数：</p><ul><li><p><code>indices.requests.cache.size</code>：“1%”</p></li><li><p><code>index.requests.cache.enable</code>: false</p></li></ul><p>一般来说，第一个参数可以在静态文件中进行全局配置，第二个参数可以通过以下 API 进行索引级别或者请求级别的动态设置</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222240.png" alt="image-20200502225950623"></p><h3 id="Fielddata-Cache"><a class="header-anchor" href="#Fielddata-Cache">¶</a>Fielddata Cache</h3><p>除了 Text 类型，其他类型默认都采用 doc_values（排序、聚合），它和 Aggregation 的 Global Ordinals 都保存在 Fielddata cache 中。</p><p>Text 类型的字段需要打开 fielddata 才能对其进行聚合和排序。text 经过分词，排序和聚合效果不佳，建议不要轻易使用。</p><p>可以通过持续监控 fielddata cache，然后根据情况调整<code>indices.fielddata.cache.size</code>参数来控制 fielddata cache 的大小，避免占用内存过大而产生 GC（默认无限制）</p><h3 id="缓存失效"><a class="header-anchor" href="#缓存失效">¶</a>缓存失效</h3><p>Node Query Cache：保存的是 Segment 级缓存命中的结果，Segments 被合并后，缓存会失效。</p><p>Shard Request Cache：分片 Refresh 的时候，Shard Request Cache 会失效。如果 Shard 对应的数据频繁发生变化，该缓存的效率会很差。</p><p>Fielddata Cache：Segment 被合并后，会失效</p><h3 id="管理内存的重要性"><a class="header-anchor" href="#管理内存的重要性">¶</a>管理内存的重要性</h3><p>Elasticsearch 高效运维依赖于内存的合理分配，服务器的用内存一半分配给 JVM，另一半留给操作系统，缓存索引文件。</p><p>内存相关的一些问题：</p><ul><li>JVM 内存不足，频繁或者长时间的 GC，影响节点，导致集群响应缓慢</li><li>OOM，导致节点宕机丢失</li></ul><p>我们可以通过以下 API 来查看各个节点的内存状况：</p><pre><code>GET _cat/nodes?vGET _nodes/stats/indices?prettyGET _cat/nodes?v&amp;h=name,queryCacheMemory,queryCacheEvictions,requestCacheMemory,reques tCacheHitCount,request_cache.miss_countGET _cat/nodes?h=name,port,segments.memory,segments.index_writer_memory,fielddata.memo ry_size,query_cache.memory_size,request_cache.memory_size&amp;v</code></pre><h3 id="一些常见的内存问题举例"><a class="header-anchor" href="#一些常见的内存问题举例">¶</a>一些常见的内存问题举例</h3><ol><li>Segments 个数过多，导致 full GC<ul><li>现象：集群整体响应缓慢，也没有特别多的数据读写。但是发现节点在持续进行 full gc。</li><li>分析：查看 Elasticsearch 的内存使用，发现 segments.memory 占用很大空间</li><li>解决：通过 force merge，把 segments 合并成一个</li><li>建议：对于不在写入和更新的索引，可以将其设置成只读。同时，进行 force merge 操作。如果问题依然存在，则需要考虑扩容。此外，对索引进行 force merge，还可以减少 global_ordinals 数据结构的构建，减少对 fielddata cache 的开销</li></ul></li><li>fielddata cache过大，导致 full gc<ul><li>现象：集群整体响应缓慢，也没有特别多的数据读写。但是发现节点在持续进行 full gc</li><li>分析：查看 Elasticsearch 的内存使用，发现 fielddata.memory.size 占用很大空间。同时，数据不存在写入和更新，也执行过 segments merge。</li><li>解决：将 indices.fielddata.cache.size 设小，重启节点，堆内存恢复正常</li><li>建议：Field data cache 的构建比较重，Elasticsearch 不会主动释放，所以这个值应该设置得保守一些。如果业务上确实有所需要，可以通过增加节点，扩容解决</li></ul></li><li>复杂的嵌套聚合，导致集群 full gc<ul><li>现象：节点响应缓慢，持续进行 full gc</li><li>分析：导出 Dump 分析，发现内存中有大量 bucket 对象，查看日志，发现复杂的嵌套聚合</li><li>解决：优化聚合</li><li>建议：在大量数据集上进行嵌套聚合查询，需要很大的堆内存来完成。如果业务场景确实需要。则需要增加硬件进行扩展。同时，为了避免这类查询影响整个集群，需要设置 Circuit Breaker 和<code>search.max_buckets</code>的数值</li></ul></li></ol><h3 id="Circuit-Breaker"><a class="header-anchor" href="#Circuit-Breaker">¶</a><a href="https://www.elastic.co/blog/improving-node-resiliency-with-the-real-memory-circuit-breaker" target="_blank" rel="noopener">Circuit Breaker</a></h3><p>ES 提供了多种断路器(熔断)，避免不合理操作引发的 OOM，每个断路器可以指定内存使用的限制（熔断的阈值）。</p><ul><li>Parent circuit breaker：设置所有的熔断器可以使用的内存的总量</li><li>Fielddata circuit breaker：加载 fielddata 所需要的内存</li><li>Request circuit breaker：防止每个请求级数据结构超过一定的内存（例如聚合计算的内存一般会比较大）</li><li>In fight circuit breaker：Request 中的断路器</li><li>Accounting request circuit breaker：请求结束后不能释放的对象所占用的内存</li></ul><p>通过 <code>GET /_nodes/stats/breaker?</code>查询当前熔断器的工作状态：</p><ul><li>Tripped 大于0，说明有过熔断</li><li>Limit size 与 estimated size 越接近，越可能引发熔断</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222254.png" alt="image-20200502232458039"></p><p>千万不要触发了熔断，就盲目调大参数，有可能会导致集群出现问题，也不应该盲目调小，需要进行评估（通过压测等）。建议将集群升级到7.x，更好的 Circuit Breaker 实现机制，增加了<code>indices.breaker.total.use_real_memory</code>配置项，可以更加精准的分析内存状况，避免 OOM。</p><h3 id="相关阅读-v14"><a class="header-anchor" href="#相关阅读-v14">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/blog/improving-node-resiliency-with-the-real-memory-circuit-breaker" target="_blank" rel="noopener">https://www.elastic.co/blog/improving-node-resiliency-with-the-real-memory-circuit-breaker</a></p></blockquote><h1>一些运维的建议</h1><p>需要引入集群的生命周期管理的概念：</p><ol><li><p>预上线</p><p>评估用户的需求及使用场景：数据建模、容量规划、选择适合的部署架构、性能测试</p></li><li><p>上线</p><ul><li>监控流量、定期检查潜在问题（防患于未然，发现错误的使用方式，及时增加机器）</li><li>对索引进行优化(index lifecycle management)，检测是否存在不均衡而导致有部分节点过热</li><li>定期数据备份、滚动升级</li></ul></li><li><p>下架前监控流量，实现 Stage Decommission</p></li></ol><h3 id="部署的建议"><a class="header-anchor" href="#部署的建议">¶</a>部署的建议</h3><p>根据实际场景，选择合适的部署方式，选择合理的硬件配置</p><ul><li>搜索类</li><li>日志/指标</li></ul><p>部署要考虑反亲和性（Anti-Affinity）</p><ul><li>尽量将机器分散在不同的机架。</li><li>善用 Shard Filtering 进行配置</li></ul><h3 id="使用要遵循一定的规范"><a class="header-anchor" href="#使用要遵循一定的规范">¶</a>使用要遵循一定的规范</h3><ul><li><p>生产环境中索引应考虑禁用 Dynamic Index Mapping，避免过多字段导致 Cluster State 占用过多</p></li><li><p>禁止索引自动创建的功能，创建时必须提供 Mapping 或者通过 Index Template 进行设定</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222306.png" alt="image-20200502235305598"></p></li><li><p>开启慢查询日志，发现一些性能不好，甚至是错误的使用。例如：错误的将网址映射成 keyword，然后用通配符查询，应该使用 Text，结合 URL 分词器；严禁一切&quot;*&quot;开头的通配符查询</p></li></ul><h3 id="对重要的数据进行备份"><a class="header-anchor" href="#对重要的数据进行备份">¶</a>对重要的数据进行备份</h3><p>如果是在公有云上使用云厂商提供的服务，一般会有数据备份的服务包。如果是在自己公司的服务器上搭建的集群，参考如何ES 提供的<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/modules-snapshots.html" target="_blank" rel="noopener">快照管理功能</a>或者<a href="https://time.geekbang.org/course/detail/100030501-142590" target="_blank" rel="noopener">极客时间阮一鸣老师的课程介绍</a></p><h3 id="定期更新到新版本"><a class="header-anchor" href="#定期更新到新版本">¶</a>定期更新到新版本</h3><p>ES 在新版本中会持续对性能作出优化，提供更多的新功能，例如最近的 Circuit breaker 有大量的改进；并且也会修复一些已知的 bug 和安全隐患。</p><ol><li><p>ES 的版本：</p><p>Elasticsearch 的版本格式是：x.y.z。x 是 Major 版本；y 是 Minor；z 是 Patch。ES 可以使用上一个主版本的索引，例如 7.x 可以使用 6.x；7.x 不支持使用 5.x；5.x 的上一个版本是2.x，所以可以使用2.x 的索引。</p></li><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/rolling-upgrades.html" target="_blank" rel="noopener">Rolling Upgrade</a> v.s. Full Cluster Restart</p><ul><li><p>Rolling Upgrade：没有 downtime。详细可以参考：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/rolling-upgrades.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/rolling-upgrades.html</a></p></li><li><p>Full Cluster Restart：集群在更新期间不可用，但是升级更快。</p><p>步骤：</p><ol><li><p>停止索引数据，同时备份集群</p></li><li><p>Disable Shard Allocationo（Persistent）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222313.png" alt="image-20200503001306358"></p></li><li><p>执行 Synced Flush</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222322.png" alt="image-20200503001317514"></p></li><li><p>关闭所有节点，然后进行节点更新</p></li><li><p>先运行所有 master 节点、在运行其他节点</p></li><li><p>等集群变黄后打开 Shard Allocation</p></li></ol></li></ul></li></ol><h3 id="运维-Cheat-Sheet"><a class="header-anchor" href="#运维-Cheat-Sheet">¶</a>运维 Cheat Sheet</h3><ol><li><p>移动分片：从一个节点移动分片到另外一个节点，使用场景是当一个数据节点上过多 Hot Shards，可以通过手动分配分片到特定的节点解决</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222327.png" alt="image-20200503001454447"></p></li><li><p>从集群中移除一个节点：当你想移除一个节点，或者对一个机器进行维护。同时你又不希望导致集群的颜色变黄或者变红。执行以下操作，ES 会将指定 ip 的节点上的数据进行转移，在转移完毕之后，直接移除该节点即可。<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222335.png" alt="image-20200503001546359"></p></li><li><p>控制 Allocation 和 Recovery</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222341.png" alt="image-20200503001810882"></p></li><li><p>Synced Flush：当需要重启一个节点的时候，我们要先将 cache 中的 segments 进行一次 flush 到磁盘，保证数据不丢失。（通过 synced flush，可以在索引上防止一个 sync id，这样可以提高这些分片的 recovery 的时间？）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222403.png" alt="image-20200503001956169"></p></li><li><p>清空节点上的缓存：使用场景是节点上出现了高内存占用。可以执行清除缓存的操作，这样是会影响集群的性能的，但是会避免集群出现 OOM 的问题</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222408.png" alt="image-20200503002140844"></p></li><li><p>控制搜索的队列：使用场景是当搜索的响应时间过长，看到有&quot;reject&quot;指标的增加，都可以适当增加该数值</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222414.png" alt="image-20200503002247557"></p></li><li><p>根据场景设置各类的 Circuit Breaker：避免 OOM 的发生</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222420.png" alt="image-20200503002309835"></p></li></ol><h3 id="相关阅读-v15"><a class="header-anchor" href="#相关阅读-v15">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/rolling-upgrades.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/rolling-upgrades.html</a></p></blockquote><h1>close、shrink、split、rollover、rollup API</h1><p>本节我们主要介绍一些相关的索引管理的 API。</p><h3 id="open-close-index"><a class="header-anchor" href="#open-close-index">¶</a>open / close index</h3><p>索引关闭后无法进行读写搜索，对集群的相关开销基本降低为0。但是索引数据不会被删除，所以如果有一些索引我们是暂时不需要进行读取的，可以先将它们关闭，当需要的时候再打开。</p><pre><code># 删除索引的话，用 HEAD RESTful 方法是查询不到这个索引的DELETE test#查看索引是否存在HEAD test</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222426.png" alt="image-20200503092210451"></p><pre><code>PUT test/_doc/1{  &quot;key&quot;:&quot;value&quot;}#关闭索引，用 HEAD 方法是可以检测得到索引的存在的POST /test/_close#索引存在HEAD test</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222434.png" alt="image-20200503092310404"></p><pre><code># 但是无法查询，会报索引已经关闭的异常POST test/_count</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222439.png" alt="image-20200503092355083"></p><h3 id="Shrink-Index"><a class="header-anchor" href="#Shrink-Index">¶</a>Shrink Index</h3><p>这是 ES 5.x 后推出的一个新功能，可以将索引的主分片数搜索到较小的值。其使用场景是有以下</p><ul><li>索引保存的数据量比较小，需要重新设定主分片数。</li><li>索引从 Hot 移动到 Warm 后，需要降低主分片数</li></ul><p>这个 API 会使用和源索引相同的配置创建一个新索引，仅仅降低主分片数：</p><ul><li>源分片数必须是目标分片数的倍数。如果源分片数是素数，目标分片数只能为1。</li><li>如果文件系统支持硬链接，会将 Segments 硬链接到目标索引，所以(和 reindex 相比)性能好。</li><li>新索引创建完成后，可以删除源索引。</li></ul><p>在使用 Shrink API 的时候，ES 会做以下校验：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222446.png" alt="image-20200503093926617"></p><h4 id="Demo"><a class="header-anchor" href="#Demo">¶</a>Demo</h4><ol><li>在一个节点拥有热、温、冷三个节点的集群上进行测试</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222452.png" alt="image-20200503094600253"></p><p>​<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222458.png" alt="image-20200503094643119"></p><ol start="2"><li><p>查看节点属性</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222507.png" alt="image-20200503094657587"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223314.png" alt="image-20200503094723133"></p></li><li><p>源索引初始化，一共有4个主分片，然后写入一个文档，再查看文档的分片情况。可以看到文档落到了位于 es7_cold 的分片0上了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222517.png" alt="image-20200503094858455"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222532.png" alt="image-20200503094922446"></p></li><li><p>尝试执行 Shrink API，设置分片数为3，会报出一个错误：源索引的分片数必须是目标索引3的的倍数</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222538.png" alt="image-20200503095042980"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222546.png" alt="image-20200503095051271"></p><ol start="5"><li>尝试将分片数设置成2，看是否能执行成功。可以看到，又报出一个源索引必须是只读的错误。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222555.png" alt="image-20200503095302081"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222603.png" alt="image-20200503095326463"></p><ol start="6"><li>将源索引设置为只读，再尝试 Shrink。可以看到，再次报错：所有分片必须都在一个节点上，前面看到示例中的源索引的4个分片是分布在3个节点上的。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222610.png" alt="image-20200503095516344"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222616.png" alt="image-20200503095545810"></p><ol start="7"><li><p>现在我们将源索引删除，并设置选项<code>index.routing.all.allocation.include.box_type</code>为 hot，让索引分片数据只会分到 hot 节点上，而我们当前集群中只有一个 hot 节点。然后重新写入文档，查看分片情况，可以看到4个分片都在 es7_hot 节点上，刚刚写入的文档存在了分片0上。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222623.png" alt="image-20200503095834837"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222629.png" alt="image-20200503095812884"></p></li><li><p>然后设置为只读并再次执行 Shrink，这次就可以成功了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222636.png" alt="image-20200503100129305"></p><p>查看新索引的分片情况，被收缩成了两个分片，因为是通过硬链接的方式，所以也都存在于原来的同一个节点上：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222643.png" alt="image-20200503100225608"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222649.png" alt="image-20200503100231713"></p></li><li><p>现在我们对新索引尝试写入数据，发现它也是只读的，因为也拷贝了源索引的配置。我们需要重新设置为可写。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222657.png" alt="image-20200503100401539"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222703.png" alt="image-20200503100406518"></p></li></ol><h3 id="Split-API"><a class="header-anchor" href="#Split-API">¶</a>Split API</h3><p>可以扩大主分片个数。它和 Shrink API 是一个相反的操作：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222710.png" alt="image-20200503100602106"></p><p>同样的，它也需要满足一定的规则才能执行：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222716.png" alt="image-20200503100631605"></p><h4 id="Demo-v2"><a class="header-anchor" href="#Demo-v2">¶</a>Demo</h4><ol><li>源索引初始化，设置主分片为4，可以看到分片分布在4个节点上。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222722.png" alt="image-20200503100733597"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222728.png" alt="image-20200503100756398"></p><ol start="2"><li><p>尝试 Split API 将新的索引的分片数设置成10。会报一个目标索引分片数必须是源索引的倍数的错误</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222736.png" alt="image-20200503100908503"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222743.png" alt="image-20200503100915494"></p></li><li><p>设置成8之后又提示源索引必须是只读</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222748.png" alt="image-20200503100954473"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222757.png" alt="image-20200503101000980"></p></li><li><p>设置只读再执行 Split API，就成功了。Split API 不要求所有分片都在一个节点上。基于源索引的各个分片原本所在的节点上进行 Split。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222803.png" alt="image-20200503101104379"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222810.png" alt="image-20200503101128821"></p></li><li><p>尝试写入数据，和 Shrink 一样，都是拷贝源索引配置，无法写入</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222817.png" alt="image-20200503101249777"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222824.png" alt="image-20200503101255482"></p></li></ol><h3 id="Rollover-Index"><a class="header-anchor" href="#Rollover-Index">¶</a>Rollover Index</h3><p>类似 Log4J 记录日志的方式，索引尺寸或者当前时间超过一定值后，创建新的索引。</p><p>下面我们来看一个场景：我们有一个基于时间序列的索引，我们是按照每天进行新索引的创建并对前一天的索引做老化的，如左图所示，在第一天的时候写入的索引的数据是90GB，但是到了第二天的时候，写入索引暴增到520GB，而第3天的数据暴增到230GB，这种情况下我们应该将这些数据分隔成多个索引存储而不是只存储在一个索引上，从而缓解 ES 服务器压力。如右图所示，我们可以设定一定的规则（按照索引中文档的数量、某个时间阈值、索引大小）来自动创建新的索引，在图中是按照索引大小到达200GB 之后就创建新索引的规则进行的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222831.png" alt="image-20200503102035890"></p><p>而 Rollover API 就是这样一个 API，当我们调用它的时候， 给它设定一定的条件，它会检测这些条件，如果这些条件都满足了，会按照规则创建一个新索引并Alias指向它。Rollover APi 一般和Index Lifecycle Manament Policies 一起使用，它单独作为一个 API 的时候，只有调用它，它才会去做相应的检测，并不会自动监控这些索引。</p><h5 id="Demo1：默认情况下-rollover-之后通过别名只能查询到最新索引"><a class="header-anchor" href="#Demo1：默认情况下-rollover-之后通过别名只能查询到最新索引">¶</a>Demo1：默认情况下 rollover 之后通过别名只能查询到最新索引</h5><ol><li><p>首先我们初始化一个 ngnix-logs-000001的索引，并通过索引属性<code>aliases</code>为其指向了一个别名&quot;nginx_logs_write&quot;，然后写入6个文档。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222838.png" alt="image-20200503102901500"></p></li><li><p>现在我们来调用 rollover api 做一个 rollover 的操作。rollover api 是基于一个别名进行操作的，这里我们指定前面设置 nginx-logs-000001索引的时候设置的别名 nginx_logs_write。并设置 rollover 的条件是：当前索引存在时间已经达到了一天、文档数量已经超过了5个、索引大小已经超过了5GB。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222844.png" alt="image-20200503103209779"></p><p>rollover 成功。返回了 rollover 之前当前别名指向的索引名称&quot;nginx-logs-000001&quot;以及自动新创建的索引名称&quot;nginx-logs-000002&quot;，并通过&quot;rolled_over=true&quot;告诉我们是否触发了 rollover 并执行 成功了，以及通过 conditions 告诉我们是哪些条件触发了 rollover。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222850.png" alt="image-20200503103352536"></p></li><li><p>尝试通过 alias 查看索引文档个数。发现只有一个文档：</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222858.png" alt="image-20200503103803045"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222903.png" alt="image-20200503103817404"></p><p>查看 Alias 信息， 其实这个 alias 现在就是指向了一个索引，就是我们刚刚创建的索引，老索引没有包含，所以老索引中的数据通过别名是访问不到的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222909.png" alt="image-20200503103842746"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222915.png" alt="image-20200503103850138"></p><p>直接通过老索引的名称进行访问，可以访问到老索引中存在6个文档</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222921.png" alt="image-20200503104130892"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222926.png" alt="image-20200503104136054"></p><h5 id="Demo2：通过is-write-index设定使得-rollover-之后通过别名可以访问所有-index"><a class="header-anchor" href="#Demo2：通过is-write-index设定使得-rollover-之后通过别名可以访问所有-index">¶</a>Demo2：通过<code>is_write_index</code>设定使得 rollover 之后通过别名可以访问所有 index</h5><ol><li><p>针对上面的情况我们再重新做一个案例，别名会映射到所有经过 rollover 的索引，包含全部的新旧索引。我们先再初始化一个索引 apache-logs1。<strong>此时设置别名中的一个属性<code>is_write_index</code>为 true。</strong></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222932.png" alt="image-20200503104605854"></p></li><li><p>多次写入文档</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221222959.png" alt="image-20200503104619848"></p></li><li><p>此时我们再做一个 rollover 的操作，这一次我们为这个 rollover 指定了新索引的名称&quot;apache-logs2&quot;，因为 ES 默认情况下如果用户不指定新索引的名称，要求别名现在指向的老索引的名称必须是横杠加数字结尾(“xxxx-00001”)才会基于横杠后面的数字加1自动创建新索引并命名该索引。我们前面的例子就是&quot;nginx-logs-000001&quot;，而这里的例子是&quot;apache_logs1&quot;，没有横杠，所以需要自己指定新索引名称</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223006.png" alt="image-20200503104726817"></p><p>可以看到，再次 rollover 成功。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223018.png" alt="image-20200503105019974"></p></li><li><p>再写入一个文档</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223025.png" alt="image-20200503105058813"></p><p>再做一次 rollover</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223032.png" alt="image-20200503105118574"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223058.png" alt="image-20200503105127370"></p><ol start="5"><li><p>这一次同样对别名&quot;apache_logs&quot;做一次 count 操作，发现和一开始的 demo 不一样，返回的数量不是1而是9。似乎包含了所有索引的文档数。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223045.png" alt="image-20200503105235050"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223051.png" alt="image-20200503105240397"></p></li><li><p>再次查看 alias 信息可以发现这个索引确实是包含了之前的所有索引&quot;apache-logs1&quot;、“apache-logs2&quot;和&quot;apache-logs3”。另外我们还看到只有&quot;apache-logs3&quot;的&quot;apache_logs&quot;属性中的&quot;is_write_index&quot;是 true。所以可以看到如果我们在为一个需要 rollover 的索引对其别名属性&quot;is_write_index&quot;设置为 true的时候，是可以使得在 rollover 操作的时候会将别名包含所有的索引，使得我们可以访问到所有的索引，但是只会写入数据到最新的索引中。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223112.png" alt="image-20200503105530743"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223117.png" alt="image-20200503105546717"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223123.png" alt="image-20200503105510258"></p></li></ol><h3 id="Rollup-Index"><a class="header-anchor" href="#Rollup-Index">¶</a>Rollup Index</h3><p>对数据进行处理后，重新写入到新的索引，减少单个索引的数据量。</p><h3 id="相关阅读-v16"><a class="header-anchor" href="#相关阅读-v16">¶</a>相关阅读</h3><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/indices-shrink-index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/indices-shrink-index.html</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/indices-rollover-index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/indices-rollover-index.html</a></p></blockquote><h1>索引全生命周期管理及工具介绍</h1><p>对于 Time based 的索引，它们的特点是索引中的数据随着时间的增长，访问流量越来越低。前面提到我们可以按照时间序列对这种类型的数据进行索引划分：</p><ul><li>好处：按照时间进行索引划分，会使得管理更加简单。例如，完整删除一个索引，性能比 delete by query 好。</li><li>挑战：如何实现自动化管理，减少人工操作，例如我们需要定期将 Hot 索引迁移为 Warm、定期关闭或者删除索引等。</li></ul><h3 id="索引生命周期常见的阶段"><a class="header-anchor" href="#索引生命周期常见的阶段">¶</a>索引生命周期常见的阶段</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223136.png" alt="image-20200503112649257"></p><ul><li>Hot：索引还存在着大量的读写操作</li><li>Warm：索引不存在写操作，还有被查询的需要</li><li>Cold：数据不存在写操作，读操作也不多</li><li>Delete：索引不再需要，可以被安全删除</li></ul><h3 id="一些索引声明周期管理工具"><a class="header-anchor" href="#一些索引声明周期管理工具">¶</a>一些索引声明周期管理工具</h3><h4 id="Elasticsearch-Curator-https-www-elastic-co-guide-en-elasticsearch-client-curator-current-index-htm-l"><a class="header-anchor" href="#Elasticsearch-Curator-https-www-elastic-co-guide-en-elasticsearch-client-curator-current-index-htm-l">¶</a>[Elasticsearch Curator](<a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.htm" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.htm</a> l)</h4><p>这是 ES 官方推出的工具，基于 python 的命令行工具。它内置了10多种 Index 相关的操作（Actions），每个动作可以顺序执行。 另外它还支持各种条件，过滤出需要操作的索引（Filters）。 <strong>但是它仅仅是一个命令行的用来执行索引管理的工具，并不具有自动检测索引状态+对索引进行相关动作的功能，它仅仅是把索引检查的一些动作聚合成了一个命令行，我们仍然需要定期人工去使用这些命令行来检查索引+操作索引。</strong></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223143.png" alt="image-20200503112959682"></p><p>详细可查看：[<a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.htm" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.htm</a> l](<a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.htm" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.htm</a> l)</p><h4 id="eBay-Lifecycle-Management-Tool"><a class="header-anchor" href="#eBay-Lifecycle-Management-Tool">¶</a>eBay Lifecycle Management Tool</h4><p>这是 eBay Pronto team 自研图形化工具：</p><ul><li>支持 Curator 的功能</li><li>基于图形化配置</li><li>配置 Job 定时触发，无需到时间了再手工操作</li><li>一个界面，管理多个 ES 集群</li><li>支持不同的 ES 版本</li><li>系统高可用，保证一些节点的宕机导致一些操作没有被执行</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223156.png" alt="image-20200503113526070"></p><p>eBay Lifecycle Management Tool 和 Curator 和 rollover api 区别：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223205.png" alt="image-20200503113611695"></p><ul><li>在对索引的操作上，eBay LMT 和 Curator 都是支持所有动作的，而 rollover api 仅仅包含了一个新索引创建和别名 rotation 的动作。</li><li>Curator 和 rollover 并不支持全版本的 ES，后续版本才有的功能</li><li>同时 Curator 和 rollover 也没有自动执行、图形化界面、保证系统高可用、多集群索引操作的支持</li></ul><h4 id="Index-Lifecycle-Management"><a class="header-anchor" href="#Index-Lifecycle-Management">¶</a>Index Lifecycle Management</h4><p>这是ES 6.6推出的一个新功能，基于 X-Pack Basic License，可免费试用。以下是 ILM 的一些相关概念：</p><ul><li>Policy：定义了一个管理索引的方式，它包含了多个 Phases 和 Actions</li><li>Phase：定义了索引的各个阶段，并定义了该阶段中需要对索引执行该阶段包含的 Actions 的条件（索引大小最大值、索引文档数量最大个数、索引创建之后的最大时间），其中每个 Phase 都包含了几个固定的 Actions</li><li>Action：在各个 Phase 中可以对索引进行的操作的集合。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223213.png" alt="image-20200503114713234"></p><p>ILM 通过 Kibana Management 进行图形化界面管理的。&quot;watch-history-ilm-policy&quot;是一个自带的策略，它在Hot Phase没有任何动作，同时还定义了一个delete phase，即表示索引创建之后就从Hot Phase过渡到了 Delete Phase，并启动了 Delete Phase 的 Actions：7天后删除索引。也就是说如果对某个索引使用了这个策略，那么它将在创建7天后被删除。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223220.png" alt="image-20200503115049619"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223247.png" alt="image-20200503115308657"></p><p>点击&quot;创建策略&quot;，其中 Hot Phase 是必须的，每个索引创建之后都是一个 Hot 状态，除非启动了其他Phase，并支持触发索引从 Hot 去到其他 Phase 的条件。另外我们可以启动该阶段的操作(rollover)。其他 Phase 按需设定。：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221223255.png" alt="image-20200503115106680"></p><h5 id="ILM-API-调用-Demo"><a class="header-anchor" href="#ILM-API-调用-Demo">¶</a>ILM API 调用 Demo</h5><p>ILM 其实也是提供了对外的 API 调用的。以下是对于Kibana 的请求Demo</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 运行三个节点，分片 将box_type设置成 hot，warm和cold# 具体参考 github下，docker-hot-warm-cold 下的docker-compose 文件# 删除所有索引DELETE *# 设置 lifecycle 的定时检测时间间隔为1秒，即每秒都会进行一次检测是否有 有索引满足其匹配的 policy 中满足相关 phase 的actions 条件，如果有就执行 actions；生产环境10分种刷新一次PUT _cluster/settings{  "persistent": {    "indices.lifecycle.poll_interval":"1s"  }}# 创建一个 PolicyPUT /_ilm/policy/log_ilm_policy{# 包含4个 phases  "policy": {    "phases": {      "hot": {        # hot 只有一个 rollover 动作        "actions": {          "rollover": {            # 当文档数超过5个就执行 actions            "max_docs": 5          }        }      },      "warm": {        # 设置进入 warm phrase 的条件，10s 后从 hot 进入 warm 阶段，并执行以下 actions        "min_age": "10s",        # warm 也只有一个 allocate 动作        "actions": {          # (re)allocate 索引到一个 warm 标签节点上          "allocate": {            "include": {              "box_type": "warm"            }          }        }      },      "cold": {        # 15s 后从 warm 进入 cold        "min_age": "15s",        # 同 warm        "actions": {          "allocate": {            "include": {              "box_type": "cold"            }          }        }      },      "delete": {      # 20s 后从 cold 进入 delete        "min_age": "20s",        "actions": {          "delete": {}        }      }    }  }}# 设置索引模版PUT /_template/log_ilm_template{  # 指定可以使用当前模板的索引的规则  "index_patterns" : [      "ilm_index-*"  ],  "settings" : {    "index" : {      # 指定索引管理生命周期的策略为我们前面创建的策略      "lifecycle" : {        "name" : "log_ilm_policy",        "rollover_alias" : "ilm_alias"      },      # 索引路由到 hot 节点      "routing" : {        "allocation" : {          "include" : {            "box_type" : "hot"          }        }      },      # 一个主分片      "number_of_shards" : "1",      "number_of_replicas" : "0"    }  },  "mappings" : { },  "aliases" : { }}#创建索引PUT ilm_index-000001{  "settings": {    "number_of_shards": 1,    "number_of_replicas": 0,    # 指定了索引生命周期管理策略为前面创建的"log_ilm_policy"    "index.lifecycle.name": "log_ilm_policy",    # 指定对该索引执行 rollober api动作的时候指定的别名为"ilm_alias"，因为一个索引可能有多个别名，ES 不知道哪个才是用来做 rollover 的    "index.lifecycle.rollover_alias": "ilm_alias",    # 指定该索引路由到 hot 节点    "index.routing.allocation.include.box_type":"hot"  },  #  同时为该索引设置 rollover 的别名并设置"is_write_index"为 true，使得rollover 之后的老索引也可以被通过别名查询  "aliases": {    "ilm_alias": {      "is_write_index": true    }  }}# 对 Alias 写入文档POST ilm_alias/_doc{  "dfd":"dfdsf"}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>002_简介</title>
      <link href="/2020/12/22/elasticsearch/002-jian-jie/"/>
      <url>/2020/12/22/elasticsearch/002-jian-jie/</url>
      
        <content type="html"><![CDATA[<h1>背景介绍</h1><ul><li>Es 是一个开源软件，其所属公司是上市公司 Elastic Inc。</li><li>当前市值超过50亿美金，开盘当天涨幅达94%</li><li>Elasticsearch 软件下载量，超3.5亿次</li><li>10W+的社区成员</li><li>7200+订阅用户，分布在100+国家</li><li>合作的云服务厂商：Elasic、Amazon、阿里巴巴、腾讯</li></ul><h1>Es 客户</h1><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210530.png" alt="image-20200423152034113"></p><h1>同类产品比较</h1><h3 id="存储类型软件的一个比较"><a class="header-anchor" href="#存储类型软件的一个比较">¶</a>存储类型软件的一个比较</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210537.png" alt="image-20200423152819623"></p><h3 id="同类产品-搜索引擎"><a class="header-anchor" href="#同类产品-搜索引擎">¶</a>同类产品(搜索引擎)</h3><ul><li>Es-开源分布式搜索分析引擎<ul><li>近实时（Near Real Time）</li><li>分布式存储/搜索/分析引擎</li></ul></li><li>Solr（Apache 开源项目）</li><li>Splunk（第一家上市的大数据公司，也有类似的产品）</li></ul><h3 id="Solr-和-Es-热门曲线"><a class="header-anchor" href="#Solr-和-Es-热门曲线">¶</a>Solr 和 Es 热门曲线</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210548.png" alt="Solr 和 Es 的热门曲线比较"></p><h1>基于 lucene</h1><p>Es 和 Solr 底层引擎都是 Lucene。Lucene 具有以下特点：</p><ul><li>基于 Java语言开发的搜索引擎类库</li><li>创建于1999年，2005年称为 Apache 顶级开源项目</li><li>Lucene具有高性能、易扩展的优点</li><li>局限性：<ul><li>只能基于 Java 语言开发</li><li>累哭的接口学习曲线陡峭</li><li>原生不支持水平扩展，搜索引擎需要存储海量数据，如果不支持水平扩展，需要自己做很多开发</li></ul></li></ul><h1>Elasticsearch 的分布式架构</h1><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210558.png" alt="image-20200423153558687"></p><ul><li>集群规模可以从单个扩展到数百个节点</li><li>高可用&amp;水平扩展<ul><li>服务和数据两个维度</li></ul></li><li>支持不同的节点类型<ul><li>支持 Hot&amp;Warm 架构</li></ul></li></ul><h1>支持多种方式集成接入</h1><ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/client/index.html" target="_blank" rel="noopener">多种编程语言的类库</a><ul><li>Java/.NET/Python/Ruby/PHP/Groovy/Perl</li></ul></li><li>RESTful API v.s. Transport API<ul><li>9200 v.s. 9300(建议使用 RESTful API)</li></ul></li><li>最新支持JDBC&amp;ODBC接入</li></ul><h1>主要功能</h1><ul><li>海量数据的分布式存储以及集群管理<ul><li>服务与数据的高可用，水平扩展</li></ul></li><li>近实时搜索，性能卓越<ul><li>结构化、全文、地理位置、自动完成</li></ul></li><li>海量数据的近实时分析<ul><li>数据聚合功能</li></ul></li></ul><h1>版本</h1><ul><li>0.4：2010年2月第一次发布</li><li>1.0：2014年1月</li><li>2.0：2015年10月</li><li>5.0：2016年10月<ul><li>新特性-5.x<ul><li>Lucene 6.x，性能提升，默认打分机制从 TF-IDF 改为 BM25</li><li>支持 Ingest 节点/Painless Scripting /Completion suggested 支持/ 原生的 Java REST 客户端</li><li>Type 标记成 deprecated，支持了 Keyword 的类型</li><li>性能优化<ul><li>内部引擎移除了避免同一文档并发更新的竞争锁，带来15%-20%的性能提升</li><li>Instant aggregation，支持分片上聚合的缓存</li><li>新增了 Profile API，方便性能trouble shooting</li></ul></li></ul></li></ul></li><li>6.0：2017年10月<ul><li>新特性-6.x<ul><li>Lucene 7.x</li><li>新功能<ul><li>跨集群复制（CCR）</li><li>索引生命周期管理</li><li>SQL 的支持</li></ul></li></ul></li><li>更友好的升级及数据迁移<ul><li>在主要版本之间的迁移更为简化，体验升级</li><li>全新的基于操作的数据复制框架，可加快恢复数据</li></ul></li><li>性能优化<ul><li>有效存储稀疏字段的新方法，降低了存储成本</li><li>在索引时进行排序，可加快排序的查询性能</li></ul></li></ul></li><li>7.0：2019年4月<ul><li>新特性 7.x<ul><li>Lucene 8.0</li><li>重打改进-正式废除单个索引下多 Type 的支持</li><li>7.1开始，Security 功能免费使用</li><li>ECK-Elasticsearch Operator on Kubernetes</li><li>新功能<ul><li>New Cluster coordination</li><li>Feature-Complete High Level REST Client</li><li>Script Score Query</li></ul></li><li>性能优化<ul><li>默认的 Primary Shard 数从5改为1，避免 Over Sharding</li><li>更快的 Top K</li></ul></li></ul></li></ul></li></ul><h1>Elastic Stack 生态圈</h1><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210610.png" alt="image-20200423155425508"></p><h2 id="Logstash-数据处理管道"><a class="header-anchor" href="#Logstash-数据处理管道">¶</a>Logstash: 数据处理管道</h2><ul><li>开源的服务端数据处理管道，支持从不同来源采集数据，转换数据，并将数据发送到不同的存储库中</li><li>Logstash 诞生于2009年，最初用来做日志的采集和处理</li><li>2013年被 Elasticsearch 收购</li></ul><h3 id="Logstash-特性"><a class="header-anchor" href="#Logstash-特性">¶</a>Logstash 特性</h3><ul><li>实时解析和转换数据<ul><li>从 IP 地址破译出地理坐标</li><li>将 PII 数据匿名化，完全排除敏感字段</li></ul></li><li>可扩展<ul><li>200多个插件（日志/数据库/Arcsigh/Netflow）</li></ul></li><li>可靠性安全性<ul><li>Logstash 会通过持久化队列来保持至少将运行中的事件送达亿次</li><li>数据传输加密</li></ul></li><li>监控</li></ul><h2 id="Kibana-可视化分析利器"><a class="header-anchor" href="#Kibana-可视化分析利器">¶</a>Kibana: 可视化分析利器</h2><ul><li>Kibana 名字的含义 = Kiwifruit + Banana</li><li>数据可视化工具，帮助用户解开对数据的任何疑问</li><li>基于 Logstash 的工具，2013年加入 Elastic 公司</li></ul><h2 id="BEATS-轻量的数据采集器"><a class="header-anchor" href="#BEATS-轻量的数据采集器">¶</a><a href="https://www.elastic.co/cn/products/beats" target="_blank" rel="noopener">BEATS: 轻量的数据采集器</a></h2><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210616.png" alt="image-20200423160135658"></p><h2 id="X-Pack-商业化套件"><a class="header-anchor" href="#X-Pack-商业化套件">¶</a>X-Pack: 商业化套件</h2><ul><li>6.3版本之前的版本，X-Pack以插件方式安装</li><li>X-Pack 开源之后，Elasticsearch &amp; Kibana支持OSS 版和 Basic 两种版本<ul><li>部分 X-Pack 功能支持免费使用，6.8和7.1开始，Security 功能免费</li></ul></li><li>OSS，Basic，黄金级，白金级</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210622.png" alt="image-20200423160528260"></p><h2 id="ELK客户及应用场景"><a class="header-anchor" href="#ELK客户及应用场景">¶</a><a href="https://www.elastic.co/use-cases/" target="_blank" rel="noopener">ELK客户及应用场景</a></h2><p>公布了一些大量客户使用的案例</p><ul><li>网站搜索/垂直搜索/代码搜多</li><li>日志管理与分析/安全指标监控/应用性能监控</li></ul><h1>日志的重要性</h1><h3 id="为什么重要"><a class="header-anchor" href="#为什么重要">¶</a>为什么重要</h3><ul><li>运维：医生给病人看病。日志就是病人对自己的陈述</li><li>恶意攻击，恶意注册，刷单，恶意密码猜测</li></ul><h3 id="挑战"><a class="header-anchor" href="#挑战">¶</a>挑战</h3><ul><li>关注点很多，任何一个点都有可能引起问题</li><li>日志分散在很多机器，除了问题时，才发现日志被删了</li><li>很多运维人员时消防员，哪里有问题去哪里</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210629.png" alt="image-20200423161234086"></p><h3 id="Es的日志管理方案"><a class="header-anchor" href="#Es的日志管理方案">¶</a>Es的日志管理方案</h3><p>Es 天然的对日志管理进行了支持，可以很好地解决以上问题：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210638.png" alt="image-20200423161428158"></p><p>日志经收集入库之后如果发现异常还可以及时地发出一些警告。用户可以在 Kibana 地界面很容易地看到这些日志，并使用 Es 强大地搜索功能进行日志搜索，且可以通过机器学习地方式及时发现异常并发出警告。</p><h1>Es使用架构</h1><h3 id="搜索场景"><a class="header-anchor" href="#搜索场景">¶</a>搜索场景</h3><ul><li><p>单独使用 Elasticsearch 存储数据，架构简单。</p></li><li><p>以下情况可考虑与数据库集成，建立合适地同步机制进行数据同步</p><ul><li><p>与现有系统的集成</p></li><li><p>需考虑事务性</p></li><li><p>数据更新频繁</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210644.png" alt="image-20200423162010910"></p></li></ul></li></ul><h3 id="指标分析-日志分析"><a class="header-anchor" href="#指标分析-日志分析">¶</a>指标分析/日志分析</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221210650.png" alt="image-20200423162115563"></p><ol><li>第一阶段时数据抓取，可以通过自己写地一些 Java 业务客户端或者 beats 进行抓取</li><li>实际情况数据量很大，需要引入一些 mq 或者消息中间件进行缓存</li><li>Logstash 从缓存层获取数据并格式化输入到 Es</li><li>可以使用 Kibana 或者 Grafana 图形化工具进行可视化分析</li></ol><h1>ES 官方网站和文档</h1><p>es官网为：<a href="https://www.elastic.co/" target="_blank" rel="noopener">https://www.elastic.co/</a></p><p>es 官方文档为（以7.1为例）：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/index.html</a></p>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>000_一些摘录</title>
      <link href="/2020/12/22/elasticsearch/000-dai-chu-li/"/>
      <url>/2020/12/22/elasticsearch/000-dai-chu-li/</url>
      
        <content type="html"><![CDATA[<h1>摘录</h1><p><a href="https://mp.weixin.qq.com/s/rw6vmDgXUh0SUUh7uo1APg" target="_blank" rel="noopener">Elasticsearch 写入数据的工作原理是什么</a></p><p><a href="https://mp.weixin.qq.com/s/hs1kPbxOyqgrRUWlhsD3gQ" target="_blank" rel="noopener">Elastiicserach7.x 学习路线图</a></p><p><a href="https://mp.weixin.qq.com/s/RSlAMI29knfslD--weCXcw" target="_blank" rel="noopener">如何规划 Elasticsearch 集群规模和容量</a></p><p><a href="https://mp.weixin.qq.com/s/tq3zMbs-ZmSK-trprq82gg" target="_blank" rel="noopener">Elasticsearch 扫盲，提到了 term 和 posting list 的数据结构和压缩</a></p><p><a href="https://mp.weixin.qq.com/s/kepEeLJlkZYosZr2hugkRA" target="_blank" rel="noopener">Elasticsearch 史上最全最常用工具清单</a></p><p><a href="https://elasticsearch.cn/article/6178" target="_blank" rel="noopener">Elasticsearch 存储结构</a></p><p><a href="https://elasticsearch.cn/article/32" target="_blank" rel="noopener">ES 内存</a></p><p><a href="https://mp.weixin.qq.com/s/QXN84qItcnIjN1Hjxtt3Wg" target="_blank" rel="noopener">微信：图解Elasticsearch搜索原理</a></p><p><a href="https://segmentfault.com/a/1190000021193400" target="_blank" rel="noopener">7.5 破解白金步骤</a></p>]]></content>
      
      
      <categories>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1、docker简介</title>
      <link href="/2020/12/22/docker/yin-xiang-bi-ji/1-docker-jian-jie/"/>
      <url>/2020/12/22/docker/yin-xiang-bi-ji/1-docker-jian-jie/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1>简单、轻量的构建方式</h1><p>Docker 依赖了&quot;<a href="https://cloud.tencent.com/developer/article/1594161" target="_blank" rel="noopener">写时复制</a>&quot;模型，使得修改程序迅速。</p><h1>鼓励面向服务的架构</h1><p>Docker还鼓励面向服务的架构和微服务架构。 Docker推荐单个容器只运行一个应用程序或进程,这样就形成了一个分布式的应用程序模型,在这种模型下,应用程序或服务都可以表示为一系列内部互联的容器,从而使分布式部署应用程序,扩展或调试应用程序都变得非常简单,同时也提高了程序的内省性。</p><p>当然，如果你愿意,当然不必拘泥于这种模式,你可以轻松地在一个容器内运行多个进程的应用程序。</p><h1>组件</h1><p>Docker 核心组件包括：</p><ul><li>Docker 服务端和客户端</li><li>Registry</li><li>Docker 镜像</li><li>Docker 容器</li></ul><p>Docker是一个客户-服务器(C/S)架构的程序。Docker客户端只需向 Docker服务器或守护进程发出请求,服务器或守护进程将完成所有工作并返回结果。 Docker提供了一个命令行工具 docker以及一整套 RESTFUL API。你可以在同一台宿主机上运行 Docker守护进程和客户端,也可以从本地的 Docker客户端连接到运行在另一台宿主机上的远程 Docker守护进程。下图描绘了 Docker的架构。<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221204421.png" alt="34ac113cb1ddf008a44a93154808c6de"></p><h2 id="Dokcer镜像"><a class="header-anchor" href="#Dokcer镜像">¶</a>Dokcer镜像</h2><p>镜像是构建 Docker世界的基石。用户基于镜像来运行自己的容器。镜像也是 Docker生命周期中的“构建”部分。镜像是基于<a href="https://rosystain.com/2019/10/09/269/" target="_blank" rel="noopener">联合(Union)文件系统</a>的一种<strong>层式的结构</strong>,由一系列指令一步一步构建出来。例如:</p><ul><li>添加一个文件</li><li>执行一个命令</li><li>打开一个端口<br>也可以把镜像当作容器的“源代码”。镜像体积很小,非常“便携”,易于分享、存储和更新。</li></ul><h2 id="Registry"><a class="header-anchor" href="#Registry">¶</a>Registry</h2><p>Docker用Registry来保存用户构建的镜像。 Registry分为公共和私有两种。 Docker公司运营的公共 Registry 叫做 Docker Hub。用户可以在 Docker Hub注册账号,分享并保存自己的镜像。<br>根据最新统计, Docker Hub上有超过10000注册用户构建和分享的镜像。需要 Nginx Web 服务器的 Docker镜像,或者 Asterix开源PABX系统的镜像,抑或是 MYSQL数据库的镜像?这些镜像在 Docker Hub上都有,而且具有多种版本。你也可以在 Docker Hub上保存自己的私有镜像。例如,包含源代码或专利信息等需要保密的镜像,或者只在团队或组织内部可见的镜像。你甚至可以架设自己的私有 Registry。私有 Registry 可以受到防火墙的保护,将镜像保存在防火墙后面,以满足一些组织的特殊需求。</p><h2 id="容器"><a class="header-anchor" href="#容器">¶</a>容器</h2><p>Docker可以帮你构建和部署容器,你只需要把自己的应用程序或服务打包放进容器即可。我们刚刚提到,容器是基于镜像启动起来的,容器中可以运行一个或多个进程。我们可以认为,镜像是 Docker生命周期中的构建或打包阶段,而容器则是启动或执行阶段。<br>总结起来, Docker容器就是:</p><ul><li>一个镜像格式:</li><li>一系列标准的操作;</li><li>一个执行环境。</li></ul><p>Docker借鉴了标准集装箱的概念。标准集装箱将货物运往世界各地, Docker将这个模型运用到自己的设计哲学中,唯一不同的是:集装箱运输货物,而 Docker运输软件<br>每个容器都包含一个软件镜像,也就是容器的“货物”,而且与真正的货物一样,容器里的软件镜像可以进行一些操作。例如,镜像可以被创建、启动、关闭、重启以及销毁<br>和集装箱一样, Docker在执行上述操作时,并不关心容器中到底塞进了什么,它不管里面是Web服务器,还是数据库,或者是应用程序服务器什么的。所有容器都按照相同的方式将内容“装载”进去。<br>Docker也不关心你要把容器运到何方:你可以在自己的笔记本中构建容器,上传到Registry,然后下载到一个物理的或者虚拟的服务器来測试,再把容器部署到 Amazon EC2 主机的集群中去。像标准集装箱一样, Docker容器方便替换,可以叠加,易于分发,并且尽量通用。</p><h1>Docker 的技术组件</h1><p>Docker可以运行于任何安装了现代 Linux内核的x64主机上。我们推荐的内核版本是3.8 或者更高。 Docker I的开销比较低,可以用于服务器、台式机或笔记本。它包括以下几个部分。<br>一个原生的 Linux容器格式, Docker中称为1 1ibcontainer,或者很流行的容器平台lxc。1ibcontainer格式现在是 Docker 容器的默认格式。<br>Linxu 内核的命名空间( namespace),用于隔离文件系统、进程和网络。<br>* 文件系统隔离:每个容器都有自己的root文件系统<br>* 进程隔离:每个容器都运行在自己的进程环境中<br>* 网络隔离:容器间的虚拟网络接口和IP地址都是分开的。<br>* 资源隔离和分组:使用 groups°(即 control group, Linux的内核特性之一)将CPU 和内存之类的资源独立分配给每个 Docker容器。<br>* 写时复制:文件系统都是通过写时复制（<strong>多个进程在初始的时候共用的是一个资源，在读取资源的时候用的是同一份，修改资源的时候会复制一份出来进行修改</strong>）创建的,这就意味着文件系统是分层的、快速的,而且占用的磁盘空间更小。<br>* 日志:容器产生的 STDOUT、 STDERR和 STDIN这些1O流都会被收集并记入日志用来进行日志分析和故障排错。<br>* 交互式 shell!用户可以创建一个伪ty终端,将其连接到 STDIN,为容器提供一个交互式的 shell</p><p>​</p><h1>Docker 资源</h1><p><a href="http://www.docker.com/" target="_blank" rel="noopener">Docker官方主页</a><br><a href="http://hub.docker.com" target="_blank" rel="noopener">DockerHub</a><br><a href="http://blog.docker.com/" target="_blank" rel="noopener">Docker官方博客</a><br><a href="http//docs.docker.com/">Docker官方文档</a><br><a href="http://www.docker.com/tryit" target="_blank" rel="noopener">Docker快速入门指南</a><br><a href="https://github.com/docker/docker" target="_blank" rel="noopener">Docker的Github源代码</a><br><a href="https://github.com/dockerforge" target="_blank" rel="noopener">DockerForge</a>:收集了各种Docker工具、组件和服务<br><a href="https:/groups.google.com/forum/#!forum/docker-user" target="_blank" rel="noopener">Docker邮件列表</a><br><a href="irc.freenode.net">Docker的IRC频道</a><br><a href="http://twitter.com/docker" target="_blank" rel="noopener">Docker的 Twitter主页</a><br><a href="http://stackoverflow.com/search?q=docker" target="_blank" rel="noopener">Docker的 Stackoverflow问答主页</a>。<br><a href="http://www.docker.com/" target="_blank" rel="noopener">Docker官网</a></p>]]></content>
      
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4、Docker镜像</title>
      <link href="/2020/12/22/docker/yin-xiang-bi-ji/4-docker-jing-xiang/"/>
      <url>/2020/12/22/docker/yin-xiang-bi-ji/4-docker-jing-xiang/</url>
      
        <content type="html"><![CDATA[<p>[toc]</p><h1>简介</h1><p>Docker镜像是用来启动容器的构建基石。让我们通过进一步学习 Docker镜像来继续我们的Docker之旅。 Docker镜像是由文件系统叠加而成。最底端是一个引导文件系统,即 bootfs,这很像典型的 Linux/Unix的引导文件系统。 Docker用户几乎永远不会和引导文件系统有什么交互。实际上,当一个容器启动后,它将会被移到内存中,而引导文件系统则会被卸载(unmount),以留出更多的内存供initrd磁盘镜像使用。<br>到目前为止, Docker看起来还很像一个典型的Linux虚拟化栈。实际上, Docker镜像的第二层是root文件系统 rootfs,它位于引导文件系统之上。 rootfs可以是一种或多种操作系统(如Debian或者 Ubuntu文件系统)。<br>在传统的Linux引导过程中, root文件系统会最先以只读的方式加载,当引导结束并完成了完整性检査之后,它オ会被切换为读写模式。但是在 Docker里, root文件系统永远只能是只读状态, 并且 Docker利用联合加载(union mount)技术又会在root文件系统层上加载更多的只读文件系统。联合加载指的是一次同时加载多个文件系统,但是在外面看起来只能看到一个文件系统。联合加载会将各层文件系统叠加到一起,这样最终的文件系统会包含所有底层的文件和目录。<br><strong>Docker将这样的文件系统称为镜像（即镜像实际上就是一些硬盘资源的集合，并不包含其他资源如CPU、内存等，而容器则是镜像加上这些其他资源的集合）</strong>。一个镜像可以放到另一个镜像的顶部。位于下面的镜像称为父镜像( parent Image),可以依次类推,直到镜像栈的最底部,最底部的镜像称为基础镜像( base image)。<strong>最后,当从一个镜像启动容器时, Docker会在该镜像的最顶层加载一个读写文件系统。我们想在Docker中运行的程序就是在这个读写层中执行的。当Docker第一次启动一个容器时,初始的读写层是空的。当文件系统发生变化时,这些变化都会应用到这一层上.比如,如果想修改一个文件,这个文件首先会从该读写层下面的只读层复制到该读写层。该文件的只读版本依然存在,但是已经被读写层中的该文件副本所隐藏。（写时复制）</strong><br>通常这种机制被称为写时复制(copy on write),这也是使Docker如此强大的技术之一。<br>每个只读镜像层都是只读的,并且以后永远不会变化。当创建一个新容器时, Docker会构建出一个镜像栈,并在栈的最顶端添加一个读写层。这个读写层再加上其下面的镜像层以及些配置数据,就构成了一个容器。在上一章我们已经知道,容器是可以修改的,它们都有自己的状态,并且是可以启动和停止的。容器的这种特点加上镜像分层框架(image-layering framework),使我们可以快速构建镜像并运行包含我们自己的应用程序和服务的容器。<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221205416.png" alt="b3ef0d1ab7e92e44e9e775682db50deb"></p><h1>命令</h1><h2 id="docker-images"><a class="header-anchor" href="#docker-images">¶</a>docker images</h2><p>我们先从如何列出Docker主机上可用的镜像来开始 Docker镜像之旅。可以使用<code>docker image</code>命令来实现</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker imagesREPOSITORY          TAG                 IMAGE ID            CREATED             SIZEdocker.io/ubuntu    latest              4e5021d210f6        12 days ago         64.2 MB</code></pre><p>可以看到，我们已经获得了一个镜像列表，其中只有一个镜像，该镜像来源于一个名为 ubuntu 的仓库。</p><h3 id="q-参数"><a class="header-anchor" href="#q-参数">¶</a>-q 参数</h3><p>只返回镜像的 id</p><h2 id="docker-pull"><a class="header-anchor" href="#docker-pull">¶</a>docker pull</h2><p><code>docker pull</code>命令默认会去 Docker Hub 拉取 Docker 官方仓库中的 tag 为<code>latest</code>的镜像</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker pull ubuntuUsing default tag: latestTrying to pull repository docker.io/library/ubuntu ...latest: Pulling from docker.io/library/ubuntuDigest: sha256:bec5a2727be7fff3d308193cfde3491f8fba1a2ba392b7546b43a051853a341dStatus: Image is up to date for docker.io/ubuntu:latest</code></pre><p>上面显示已经该镜像已经存在，其中我们可以配置 Registry 为自己的私有 Registry 或者其他大厂商提供的 Registry 而替代 DockerHub 。<br>下面是<code>docker pull</code>的通用格式</p><pre><code>docker pull 仓库名:标签名称</code></pre><p>可以看到我们上面的命令就是到 ubuntu 仓库拉取标签为 latest  的镜像，而 dockerhub 中 ubuntu 仓库会默认重定向到 Docker 官方仓库 <a href="http://docker.io/ubuntu%E3%80%82%E6%89%80%E4%BB%A5%E4%BB%A5%E4%B8%8B%E5%91%BD%E4%BB%A4%E4%B9%9F%E6%98%AF%E4%B8%80%E6%A0%B7%E7%9A%84:" target="_blank" rel="noopener">docker.io/ubuntu。所以以下命令也是一样的:</a></p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker pull docker.io/ubuntu:latest</code></pre><h3 id="a-参数"><a class="header-anchor" href="#a-参数">¶</a>-a 参数</h3><p>该参数会让 docker 去拉取所有指定仓库中所有标签的镜像</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker pull -a ubuntuTrying to pull repository docker.io/library/ubuntu ...10.04: Pulling from docker.io/library/ubuntua3ed95caeb02: Pull complete86b54f4b6a4e: Downloading [=&gt;                                                 ] 2.135 MB/63.53 MB</code></pre><h2 id="docker-search"><a class="header-anchor" href="#docker-search">¶</a>docker search</h2><p>我们也可以通过<code>docker search</code>命令来查找所有Docker Hub上公共的可用镜像</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker search puppetINDEX       NAME                                                         DESCRIPTION                                     STARS     OFFICIAL   AUTOMATEDdocker.io   docker.io/puppet/puppetserver                                A Docker Image for running Puppet Server. ...   90docker.io   docker.io/alekzonder/puppeteer                               GoogleChrome/puppeteer image and screensho...   68                   [OK]docker.io   docker.io/buildkite/puppeteer                                A Puppeteer Docker image based on Puppetee...   38                   [OK]docker.io   docker.io/puppet/puppetserver-standalone                     An image for running a Puppet Server stand...   34docker.io   docker.io/puppet/puppetdb                                    A Docker image for running PuppetDB             32... ...</code></pre><p>上面的命令在Docker Hub上査找了所有带有puppet的镜像。这条命令会完成镜像查找工作,并返回如下信息：</p><ul><li>索引？</li><li>仓库名</li><li>镜像描述</li><li>用户评价（Stars）-- 反应一个镜像的受欢迎程度</li><li>是否官方（Official）-- 由上游开发者管理的镜像（如 fedora 镜像由 fedora 团队管理）</li><li>自动构建（Automated）-- 表示这个镜像是由Docker Hub 的自动构建（Automated Build）流程创建的</li></ul><h2 id="docker-login"><a class="header-anchor" href="#docker-login">¶</a>docker login</h2><p>该命令可以登录到 Docker Hub（Registry?）</p><pre><code>Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.Username: 707845008Password:Login Succeeded</code></pre><p>注册账号：<a href="https://hub.docker.com/" target="_blank" rel="noopener">https://hub.docker.com/</a><br><strong>登录之后你的个人认证信息将会保存到<code>SHOME/.dockercfg</code>文件中。</strong></p><h2 id="docker-commit-这里遇到-commit-之后容器中修改的内容并没有被保存的情况，待解决！！！"><a class="header-anchor" href="#docker-commit-这里遇到-commit-之后容器中修改的内容并没有被保存的情况，待解决！！！">¶</a>docker commit !! 这里遇到 commit 之后容器中修改的内容并没有被保存的情况，待解决！！！</h2><p>下面将是我们自己构建一个镜像并使用<code>docker commit</code>进行提交的过程：</p><ol><li>先基于一个基础镜像启动一个容器</li></ol><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker run -it ubuntu /bin/bashroot@47ef1e6c79ba:/#</code></pre><ol start="2"><li>安装一个 Apache 服务器</li></ol><pre><code>root@47ef1e6c79ba:/# apt-get -yqq updateroot@47ef1e6c79ba:/# apt-get -y install apache2... ...</code></pre><p>此时我们启动了一个容器,并在里面安装了Apache。我们会将这个容器作为一个Web服务器来运行,所以我们想把它的当前状态保存下来。这样就不必每次换到其他宿主机环境都要创建一个新容器并再次在里面安装Apache了。为了完成此项工作,需要先使用exit命令从容器里退出,之后再运行<code>docker commit</code>命令<br>3. 从一个容器提交为一个镜像</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker commit 47ef1e6c79ba john/apache2sha256:8d22890c9e33648036260bc4135ad8e169c1851f850f08926a5d123216165177</code></pre><p>可以看到，上面的指令后面分别指定了&quot;容器ID&quot;和&quot;仓库名称及镜像名&quot;。<strong>需要注意的是，docker commit 提交的只是创建容器的镜像与容器的当前状态之间有差异的部分，这使得该更新非常轻量（所以也就是说，当这个镜像在被推送到 Registry 之后会将底层依赖的 ubuntu 镜像的层信息一起推送的，这样推送之后仓库里面就会有最基础的镜像以及之后的所有层信息，即版本信息。）</strong><br>4. 此时<code>docker images</code>命令便可以看到我们刚刚提交的镜像了，其标签默认为 latest。</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker imagesREPOSITORY          TAG                 IMAGE ID            CREATED             SIZEjohn/apache2        latest              8d22890c9e33        6 minutes ago       189 MBdocker.io/ubuntu    latest              4e5021d210f6        12 days ago         64.2 MB</code></pre><h3 id="m、–author-参数-以及-提交标签"><a class="header-anchor" href="#m、–author-参数-以及-提交标签">¶</a>-m、–author 参数 以及 提交标签</h3><p>这两个参数分别可以在提交镜像的时候提交更多的信息，并提交一个标签&quot;test&quot;</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z ~]# docker commit -m "测试 image" --author "honphan" 47ef1e6c79ba john/apache2:testsha256:679b814d9d1f47bdaffa850767c3b526248417c6cee81ca4f23b694affdd62c7<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>查看结果：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z ~]# docker imagesREPOSITORY          TAG                 IMAGE ID            CREATED              SIZEjohn/apache2        test                679b814d9d1f        About a minute ago   189 MBjohn/apache2        latest              8d22890c9e33        14 minutes ago       189 MBdocker.io/ubuntu    latest              4e5021d210f6        12 days ago          64.2 MB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过 <code>docker inspect</code> 查看详细信息可以看到我们上面标注的信息</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z ~]# docker inspect 679b814d9d1f[    {        "Id": "sha256:679b814d9d1f47bdaffa850767c3b526248417c6cee81ca4f23b694affdd62c7",        "RepoTags": [            "john/apache2:test"        ],... ...        "Comment": "测试 image",        "Created": "2020-04-02T08:36:15.229165996Z",... ...        "Author": "honphan",<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="docker-build"><a class="header-anchor" href="#docker-build">¶</a>docker build</h2><p>并不推荐使用<code>docker commit</code>的方法来构建镜像。相反,推荐使用被称为Dockerfi1e的定义文件和<code>docker bui1d</code>命令来构建镜像。Dockerfile使用基本的基于DSL语法的指令来构建一个Docker镜像,之后使用<code>docker bui1d</code>命令基于该Dockerfile中的指令构建一个新的镜像。</p><h3 id="初次基于-Dockerfile-构建镜像"><a class="header-anchor" href="#初次基于-Dockerfile-构建镜像">¶</a>初次基于 Dockerfile 构建镜像</h3><h4 id="1-创建构建上下文"><a class="header-anchor" href="#1-创建构建上下文">¶</a>1. 创建构建上下文</h4><pre><code>[root@izwz920kp0myp15p982vp4z docker]# mkdir test[root@izwz920kp0myp15p982vp4z docker]# cd test[root@izwz920kp0myp15p982vp4z test]# touch Dockerfile</code></pre><p>我们创建了一个名为test的目录用来保存Dockerfile,这个目录就是我们的构建环境(build environment), Docker则称此环境为上下文(context)或者构建上下文(build context)。 Docker会在构建镜像时将构建上下文和该上下文中的文件和目录上传到 Docker 守护进程。这样Docker守护进程就能直接访问你想在镜像中存储的任何代码、文件或者其他数据。</p><h4 id="2-编辑-Dockerfile"><a class="header-anchor" href="#2-编辑-Dockerfile">¶</a>2. 编辑 Dockerfile</h4><pre><code># Version: 0.0.1FROM ubuntu:latestMAINTAINER JOHN &quot;707845008@qq.dom&quot;RUN apt-get updateRUN apt-get install -y nginxRUN echo 'Hi, I am in your container' &gt; /usr/share/nginx/html/index.htmlEXPOSE 80</code></pre><p>该Dockerfi1e由一系列指令和参数组成。每条指令, 如<code>FROM</code>,都必须为大写字母, 且后面要跟随一个参数: <code>FROM ubuntu:latest</code>。 Dockerfi1e中的指令会按顺序从上到下执行,所以应该根据需要合理安排指令的顺序每条指令都会创建一个新的镜像层并对镜像进行提交。Docker大体上按照如下流程执行 Dockerfile中的指令。</p><ul><li>Docker从基础镜像运行一个容器</li><li>执行一条指令, 对容器做出修改执行类似<code>docker commit</code>的操作,提交一个新的镜像层。</li><li>Docker再基于刚提交的镜像运行一个新容器。</li><li>执行Dockerfile中的下一条指令,直到所有指令都执行完毕。</li></ul><p>从上面也可以看出,如果你的 Dockerfi1e由于某些原因(如某条指令失败了)没有正常结束,那么你将得到了一个可以使用的镜像。这对调试非常有帮助:可以基于该镜像运行一个具备交互功能的容器,使用最后创建的镜像对为什么你的指令会失败进行调试。<br>每个Dockerfile的第一条指令都应该是<code>FROM</code>。<code>FROM</code>指令指定一个已经存在的镜像, 后续指令都将基于该镜像进行,这个镜像被称为基础镜像(base iamge)。<br>在前面的Dockerfile示例里,我们指定了ubuntu:latest作为新镜像的基础镜像。基于这个Dockerfile构建的新镜像将以ubuntu:latest操作系统为基础。在运行一个容器时,必须要指明是基于哪个基础镜像在进行构建。<br>接着指定了MAINTAINER指令,这条指令会告诉Docker该镜像的作者是谁,以及作者的电子邮件地址。这有助于标识镜像的所有者和联系方式在这些指令之后,我们指定了三条<code>RUN</code>指令。<code>RUN</code>指令会在当前镜像中运行指定的命令。在这个例子里,我们通过<code>RUN</code>指令更新了已经安装的APT仓库,安装了 nginx包,之后创建了/usr/share/nginx/html/index.htm1文件,该文件有一些简单的示例文本。<br>像前面说的那样,每条RUN指令都会创建一个新的镜像层,如果该指令执行成功,就会将此镜像层提交,之后继续执行 Dockerfile中的下一条指令默认情况下,RUN指令会在shel里使用命令包装器<code>/bin/sh -c</code>来执行。如果是在一个不支持 shell的平台上运行或者不希望在shel中运行(比如避免shell字符串篡改),也可以使用exec格式的<code>RUN</code>指令,如:</p><pre><code>RUN [&quot;apt-get&quot;, &quot;install&quot;, &quot;-y&quot;, &quot;nginx&quot;]</code></pre><p>在这种方式中,我们使用一个数组来指定要运行的命令和传递给该命令的每个参数。<br>接着设置了<code>EXPOSE</code>指令,这条指令告诉Docker该容器内的应用程序<strong>将会</strong>使用容器的指定端口。这并不意味着基于该镜像启动容器之后就可以自动访问任意容器运行中服务的端口(这里是80)。出于安全的原因, Docker并不会自动打开容器中该端口,而是需要你在使用<code>docker run</code>运行容器时来指定需要打开哪些端口。一会儿我们将会看到如何从这一镜像创建一个新容器。<br>可以指定多个<code>EXPOSE</code>指令来向外部公开多个端口。</p><h4 id="3-基于-Dockerfile-构建新镜像"><a class="header-anchor" href="#3-基于-Dockerfile-构建新镜像">¶</a>3. 基于 Dockerfile 构建新镜像</h4><p>执行<code>docker bui1d</code>命令时, Dockerfile中的所有指令都会被执行并且提交,并且在该命令成功结束后返回一个新镜像。下面就来看看如何构建一个新镜像</p><pre><code>[root@izwz920kp0myp15p982vp4z test]# docker build -t=&quot;john/test_web&quot; .Sending build context to Docker daemon 2.048 kBStep 1/6 : FROM ubuntu:latest ---&gt; 4e5021d210f6Step 2/6 : MAINTAINER JOHN &quot;707845008@qq.dom&quot; ---&gt; Running in 9390c1ed8ced ---&gt; 946627e59809Removing intermediate container 9390c1ed8cedStep 3/6 : RUN apt-get update ---&gt; Running in 6213a4de9f2a... ... ---&gt; 12ea16e6c4eaRemoving intermediate container 6213a4de9f2aStep 4/6 : RUN apt-get install -y nginx ---&gt; Running in f3894c140c14... ... ---&gt; 9db0ad54ee3aRemoving intermediate container f3894c140c14Step 5/6 : RUN echo 'Hi, I am in your container' &gt; /usr/share/nginx/html/index.html ---&gt; Running in 23be203391ad ---&gt; 4c83525bb448Removing intermediate container 23be203391adStep 6/6 : EXPOSE 80 ---&gt; Running in 888c4178cd52 ---&gt; 9f71e9719770Removing intermediate container 888c4178cd52Successfully built 9f71e9719770</code></pre><p>我们使用了<code>docker build</code>命令来构建新镜像。我们通过指定<code>-t</code>选项为新镜像设置了仓库和名称,在本例中仓库为john,镜像名为test_web。强烈建议各位为自己的镜像设置合适的名字以方便追踪和管理。<br>也可以在构建镜像的过程中为镜像设置一个标签,其使用方法为“镜像名:标签&quot;。如果没有制定任何标签, Docker将会自动为镜像设置一个1atest标签。<br>上面命令中最后的<code>.</code>告诉Docker到本地目录中去找Dockerfi1e文件。也可以指定一个Git仓库的源地址来指定Dockerfi1e的位置:</p><pre><code>[root@izwz920kp0myp15p982vp4z test]# docker build -t=&quot;john/test_web:tag_v1&quot; git@github.com:john/docker-test</code></pre><p>这里Docker假设在这个Git仓库的根目录下存在Dockerfile文件。<br>再回到<code>docker build</code>过程。可以看到构建上下文已经上传到了Docker守护进程:</p><pre><code>...Sending build context to Docker daemon 2.048 kB...</code></pre><blockquote><p>如果在构建上下文的根目录下存在以<code>.dockerignore</code>命名的文件的话,那么该文件内容会被按行进行分割,每一行都是一条文件过滤匹配模式。这非常像<code>.gitignore</code>文件, 该文件用来设置哪些文件不会被上传到构建上下文中去。该文件中模式的匹配规则采用了Go语言中的<code>filepath</code>。</p></blockquote><p>之后,可以看到Dockerfile中的每条指令会被顺序执行,每一步都返回了新镜像的ID。构建的每一步及其对应指令都会独立运行, 并且在输出最终镜像ID之前, Docker会提交每步的构建结果。<br>所有一旦上面的构建过程中途失败了，我们可以直接拿到最后得到的镜像 id 启动一个容器，然后拿出 Dockerfile 中对应这一步的指令进行执行，看是因为什么报错，并对症下药解决问题，退出容器后，修改 Dockerfile 为正确的内容，重新构建。</p><h4 id="4-Dockerfile-和构建缓存"><a class="header-anchor" href="#4-Dockerfile-和构建缓存">¶</a>4. Dockerfile 和构建缓存</h4><p>由于每一步的构建过程都会将结果提交为镜像,所以Docker的构建镜像过程就显得非常聪明。它会将之前的镜像层看做缓存。比如,我们在构建指令的第4步失败了,Docker会将之前构建时创建的镜像当做缓存并作为新的开始点。实际上,当再次进行构建时, Docker会直接从第4步开始。当之前的构建步骤没有变化时,这会节省大量的时间。如果真的在第1步到第3步之间做了什么修改, Docker则会从第一条发生了变化的指令开始<br>然而,有些时候需要确保构建过程不会使用缓存。比如,如果已经缓存了前面的第3步, 即<code>apt-get update</code>,那么 Docker将不会再次刷新APT包的缓存。这时你可能需要取得每个包的最新版本。要想略过缓存功能,可以使用<code>docker build</code>的<code>--no-cache</code>标志:</p><pre><code>docker build -t=&quot;john/web-test:tag_2&quot; --no-cache .</code></pre><h4 id="5-基于构建缓存的-Dockerfile-模板"><a class="header-anchor" href="#5-基于构建缓存的-Dockerfile-模板">¶</a>5. 基于构建缓存的 Dockerfile 模板</h4><p>构建缓存带来的一个好处就是,我们可以实现简单的Dockerfile模板(比如在Dockerfile文件顶部增加包仓库或者更新包,从而尽可能确保缓存命中)。比如对 Ubuntu:</p><pre><code>FROM ubuntu:14.04MAINTAINER john &quot;xxx@example.com&quot;ENV REFRESHED_AT 2020-04-02RUN apt-get -qq update</code></pre><p>上面的 Dockerfile 通过ENV指令来设置了一个名为REFRESHED_AT的环境变量, 这个环境变量用来表明该镜像模板最后的更新时间。最后,我使用了RUN指令来运行<code>apt-get -qg update</code>命令。该指令运行时将会刷新APT包的缓存,用来确保我们能将要安装的每个软件包都更新到最新版本<br>有了这个模板,如果想刷新一个构建,只需修改ENV指令中的日期。这使Docker在命中ENV指令时开始重置这个缓存,并运行后续指令而无须依赖该缓存。也就是说, <code>RUN apt-get update</code>这条指令将会被再次执行, 包缓存也将会被刷新为最新内容。可以扩展此模板,比如适配到不同的平台或者添加额外的需求。</p><h4 id="6-查看新镜像"><a class="header-anchor" href="#6-查看新镜像">¶</a>6. 查看新镜像</h4><pre><code>[root@izwz920kp0myp15p982vp4z test]# docker imagesREPOSITORY          TAG                 IMAGE ID            CREATED             SIZEjohn/web-test       tag_2               cff52e402b5c        14 minutes ago      153 MBjohn/test_web       latest              9f71e9719770        35 minutes ago      153 MBjohn/apache2        test                679b814d9d1f        About an hour ago   189 MBjohn/apache2        latest              8d22890c9e33        About an hour ago   189 MBdocker.io/ubuntu    latest              4e5021d210f6        12 days ago         64.2 MB</code></pre><p>刚构建的新镜像已经存在，如果想深入探求镜像是如何构建出来的，可以使用<code>docker history</code>命令</p><h4 id="7-从新镜像启动容器"><a class="header-anchor" href="#7-从新镜像启动容器">¶</a>7. 从新镜像启动容器</h4><p>我们使用<code>-p</code>选项开启了容器的端口80</p><pre><code>[root@izwz920kp0myp15p982vp4z test]# docker run -d -p 80 --name web_test john/test_web nginx -g &quot;daemon off;&quot;6b564a193037976f219bd76a6ef94f27a7daa48103d1bd0d01846a3e8c37de2c</code></pre><p>查看容器的映射端口：</p><pre><code>[root@izwz920kp0myp15p982vp4z test]# docker port web_test 800.0.0.0:32768</code></pre><p>访问容器中的 nginx</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z test]# curl localhost:32768<!DOCTYPE html><html><head><title>Welcome to nginx!</title><style>    body {        width: 35em;        margin: 0 auto;        font-family: Tahoma, Verdana, Arial, sans-serif;    }</style></head><body><h1>Welcome to nginx!</h1><p>If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.</p><p>For online documentation and support please refer to<a href="http://nginx.org/">nginx.org</a>.<br/>Commercial support is available at<a href="http://nginx.com/">nginx.com</a>.</p><p><em>Thank you for using nginx.</em></p></body></html><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Dockerfile-指令"><a class="header-anchor" href="#Dockerfile-指令">¶</a>Dockerfile 指令</h3><p>可以在<a href="http://docs.docker.com/reference/builder/" target="_blank" rel="noopener">http://docs.docker.com/reference/builder/</a>查看Dockerfile中可以使用的全部指令的清单。</p><h4 id="1-CMD"><a class="header-anchor" href="#1-CMD">¶</a>1. CMD</h4><p><code>CMD</code>指令用于<strong>指定基于本 Dockerfile 构建出来之后的镜像启动的容器启动时要运行的命令</strong>。这有点儿类似于<code>RUN</code>指令, 只是<code>RUN</code>指令是指定镜像被构建时要运行的命令, 而<code>CMD</code>是指定基于该镜像的容器被启动时要运行的命令。这和使用<code>docker run [参数] [容器唯一标识] [要执行的命令]</code>命令启动容器时指定要运行的命令非常类似，可以认为两者是等效的。但是后者是会覆盖前者的，如果我们在 Dockerfile 里指定了<code>CMD</code>指令,而同时在<code>docker run</code>命令行中也指定了要运行的命令,命令行中指定的命令会<strong>覆盖</strong>Dockerfile中的<code>CMD</code>指令。</p><p>另外，在Dockerfi1e中只能指定一条<code>CMD</code>指令。如果指定了多条<code>CMD</code>指令,也只有最后一条<code>CMD</code>指令会被使用。如果想在启动容器时运行多个进程或者多条命令,可以考虑使用类似Supervisor这样的服务管理工具。</p><h5 id="CMD、ENTRYPOINT、RUN-的两种格式"><a class="header-anchor" href="#CMD、ENTRYPOINT、RUN-的两种格式">¶</a>CMD、ENTRYPOINT、RUN 的两种格式</h5><h6 id="1-shell-格式"><a class="header-anchor" href="#1-shell-格式">¶</a>1&gt; shell 格式</h6><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">FROM centosENV name DockerCMD echo "hello $name"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Docker会在指定的命令前加上<code>/bin/sh -c</code>，进行程序执行，也就是说 <code>echo &quot;hello $name&quot;</code> 被拼接成 <code>/bin/sh -c echo &quot;hello $name&quot;</code> 进行程序调用，由 bash (shell工具) 来执行。此时 bash 会执行环境变量解析在调用 echo 程序进行输出。此时该 Dockerfile 构建的容器运行后会输出 <code>hello Docker</code>。</p><h6 id="2-exec-格式"><a class="header-anchor" href="#2-exec-格式">¶</a>2&gt; exec 格式</h6><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">FROM centosENV name DockerCMD ["/bin/echo", "hello $name"]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>第二种是一种类似数组的格式，它会直接执行 echo 程序，没有做环境变量解析，echo 程序直接输出 <code>hello $name</code>。此时我们需要对 Dockerfile 进行修改：</p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">FROM centosENV name DockerCMD ["/bin/sh", "-c", "echo hello $name"] # -c 参数的下一个参数是给bash解析的我们要执行的整条命令<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>此时才会得到输出 <code>hello Docker</code>。</p><h6 id="两种格式对比"><a class="header-anchor" href="#两种格式对比">¶</a>两种格式对比</h6><p>第一种格式在执行该命令的时候可能会导致意料之外的行为,所以Docker推荐一直使用以数组语法来设置要执行的命令。</p><h4 id="2-ENTRYPOINT"><a class="header-anchor" href="#2-ENTRYPOINT">¶</a>2. ENTRYPOINT</h4><p><code>ENTRYPOINT</code>指令与<code>CMD</code>指令非常类似,也很容易和<code>CMD</code>指令弄混。这两个指令到底有什么区别呢?为什么要同时保留这两条指令?正如我们已经了解到的那样,我们可以在<code>docker run</code>命令行中覆盖<code>CMD</code>指令。有时候, 我们希望容器会按照我们想象的那样去工作, 这时候CMD就不太合适了。而<code>ENTRYPOINT</code>指令提供的命令则不容易在启动容器时被覆盖。<br>实际上, <code>docker run</code>命令行中指定的任何参数都会被当做参数再次传递给 <code>ENTRYPOINT</code>指令中指定的命令。让我们来看一个<code>ENTRYPOINT</code>指令的例子：</p><p><strong>1. 目前我们的需求是容器启动之后执行命令&quot;/usr/sbin/nginx -g ‘daemon off;’&quot;</strong></p><p>类似于<code>CMD</code>指令，我们也可以在该指令中通过数组的方式为命令指定相应的参数，以下命令即可满足我们目前的需求</p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">ENTRYPOINT ["/usr/sbin/nginx", "-g", "daemon off;"]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>这里我们也使用数组的方式传递命令而避免 docker 在命令前面加入&quot;/bin/sh -c&quot;导致可能产生各种问题</p></blockquote><p>此外我们还有另外一种方式：</p><p>Dockerfile 配置：<code>ENTRYPOINT [&quot;/usr/sbin/nginx&quot;]</code>这里去掉了后面的参数，转而在启动容器的时候指定：<code>docker run -it john/test_web -g &quot;daemon off;&quot;</code>，此时后面的<code>-g</code>和<code>daemon off;</code>都会传递到<code>ENTRYPOINT</code>中进行拼接运行，可以得到同样的效果。此时容器中的 nginx 将会以前台的方式运行。</p><p><strong>2. 此时我们的需求变了，要求<code>docker run</code>如果不传递任何的参数则以后台的方式运行，如果传递了<code>-g</code>和<code>daemon off;</code>则会前台运行。即构成这样的语义，该容器只要启动了，nginx 保证会运行，但是运行方式是可配置的，且默认运行方式是后台运行。</strong></p><p>此时我们可以这样配置：<br>Dockerfile:</p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">ENTRYPOINT [/usr/bin/nginx]# 默认后台运行CMD [-h]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>此时启动容器的时候命令如果是<code>docker run -it john/test_web -g &quot;daemon off;&quot;</code>，<code>CMD</code>则会被覆盖失效，ngnix会前台运行；如果是<code>docker run -it john/test_web</code>，则<code>CMD</code>生效并传递到<code>ENTRYPOINT</code>中，此时 nginx 则会后台运行了。</p><blockquote><p>如果确实需要,你也可以在运行时通过<code>docker run</code>的<code>--entrypoint</code>标志覆盖<code>ENTRYPOINT</code>指令。</p></blockquote><h4 id="3-WORKDIR"><a class="header-anchor" href="#3-WORKDIR">¶</a>3. WORKDIR</h4><p><code>WORKDIR</code>指令用来在从镜像创建一个新容器时,在容器内部设置一个工作目录,<code>ENTRYPOINT</code>、<code>RUN</code>或<code>CMD</code>指定的程序会在这个目录下执行。我们可以使用该指令为Dockerfi1e中后续的一系列指令设置工作目录, 也可以为最终的容器设置工作目录。</p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">WORKDIR /opt/webapp/db RUN bundle install WORKDIR /opt/webapp ENTRYPOINT["rackup"]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>这里,我们将工作目录切换为<code>/opt/webapp/db</code>后运行了<code>bundle insta1l</code>命令,之后又将工作目录设置为<code>/opt/webapp</code>,最后设置了<code>ENTRYPOINT</code>指令来启动<code>rackup</code>命令。<br>另外，我们可以在<code>docker run</code>命令指定<code>-w</code>参数覆盖 Dockerfile 中可能在最后设置了的<code>WORKDIR</code></p><blockquote><p>注意：</p><ol><li>如果该指定目录不存在会创建目录</li><li>使用 WORKDIR，不要使用 RUN cd</li><li>尽量使用绝对目录，更清晰</li></ol></blockquote><h4 id="4-ENV"><a class="header-anchor" href="#4-ENV">¶</a>4. ENV</h4><p><code>ENV</code>指令用来在镜像构建过程中设置环境变量</p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">ENV RVM_PATH /home/rvm/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个新的环境变量可以在后续的任何<code>RUN</code>指令中使用, 这就如同在命令前面指定了环境变量前缀一样：<br><code>RUN gem install unicorn</code> -&gt; <code>RVM_PATH=/home/rvm gem install unicorn</code><br>我们也能在其他指令中直接使用这些环境变量</p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">ENV TARAGET_DIR /opt/appWORKDIR $TARGET_DIR<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>在这里我们设定了一个新的环境变量<code>TARGET_DIR</code>,并在 <code>WORKDIR</code>中使用了它的值。因此实际上<code>WORKDIR</code>指令的值会被设为<code>/opt/app</code></p><blockquote><p>如果需要, 可以通过在环境变量前加上一个反斜线来进行转义。</p></blockquote><p>这些环境变量也会被持久保存到从我们的镜像创建的任何容器中。如果我们在使用<code>ENV RVM PATH/home/rvm/</code>指令构建的容器中运行<code>env</code>命令，将会看到：</p><pre><code>...RVM_PATH=/home/rvm/...</code></pre><p>也可以使用<code>docker run</code>命令行的<code>-e</code>标识来传递环境变量，这些变量将只会在运行时有效：</p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">$ sudo docker run -ti -e "WEB_PORT=8080" ubuntu env HOME=/ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin: /bin HOSTNAME=792b171c5e9f TERM=xterm WEB_PORT=8080<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们可以看到,在容器中<code>WEB_PORT</code>环境变量被设为了8080。</p><h4 id="5-USER"><a class="header-anchor" href="#5-USER">¶</a>5. USER</h4><p><code>USER</code>指令用来指定该镜像启动的容器会以什么样的用户去运行</p><pre><code>USER nginx</code></pre><p>基于该镜像启动的容器会以<code>nginx</code>用户的身份来运行。我们可以指定用户名或UID以及组或GID,甚至是两者的组合</p><pre><code>USER user USER user:group USER uid UUSER uid:gid USER user:gid USER uid:group</code></pre><p>也可以在<code>docker run</code>命令中通过<code>-u</code>选项来覆盖该指令指定的值</p><h4 id="6-VOLUME"><a class="header-anchor" href="#6-VOLUME">¶</a>6. VOLUME</h4><p><code>VOLUME</code>指令用来向基于镜像创建的容器添加卷。<strong>一个卷是可以存在于一个或者多个容器内的特定的目录</strong>, 这个目录可以绕过联合文件系统,并提供如下共享数据或者对数据进行持久化的功能。</p><ul><li>卷可以在容器间共享和重用。</li><li>一个容器可以不是必须和其他容器共享卷 ？</li><li>对卷的修改是立时生效的。</li><li>对卷的修改不会对更新镜像产生影响 ？</li><li>卷会一直存在直到没有任何容器再使用它</li></ul><p>卷功能让我们可以将数据(如源代码)、数据库或者其他内容添加到镜像中而不是将这些内容提交到镜像中,并且允许我们在多个容器间共享这些内容。我们可以利用此功能来测试容器和内部的应用程序代码,管理日志,或者处理容器内部的数据库。</p><pre><code>VOLUME [&quot;/opt/project&quot;]</code></pre><p>这条指令将会为基于此镜像创建的任何容器创建一个名为<code>/opt/project</code>的挂载点。<br>我们也可以通过指定数组的方式指定多个卷</p><pre><code>VOLUME [&quot;/opt/project&quot;, &quot;/data&quot;]</code></pre><blockquote><p>可以在<a href="http://docs.docker.com/userguide/dockervolumes/" target="_blank" rel="noopener">http://docs.docker.com/userguide/dockervolumes/</a>读到更多关于卷的信息</p></blockquote><h4 id="7-ADD"><a class="header-anchor" href="#7-ADD">¶</a>7. ADD</h4><p><code>ADD</code>指令用来将<strong>构建环境</strong>下的文件和目录复制到镜像中。比如,在安装一个应用程序时。ADD指令需要源文件位置和目的文件位置两个参数</p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">ADD software.lic /opt/application/software/lic<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里的<code>ADD</code>指令将会将构建目录下的<code>software.1ic</code>文件复制到镜像中的<code>/opt/ application/software.1ic</code>。指向源文件的位置参数可以是一个URL, 或者构建上下文或环境中文件名或者目录。不能对构建目录或者上下文之外的文件进行<code>ADD</code>操作。<br>在<code>ADD</code>文件时, Docker通过目的地址参数末尾的字符来判断文件源是目录还是文件。<br>如果目标地址以/结尾,那么 Docker就认为源位置指向的是一个目录。如果目的地址以/结尾, 那么Docker就认为源位置指向的是目录。如果目的地址不是以/结尾,那么 Docker就认为源位置指向的是文件。<br>文件源也可以使用URL的格式：</p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">ADD http://wordpress.org/latest.zip /root/wordpress.zip<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最后值得一提的是, <code>ADD</code>在处理本地归档文件(tar archive)时还有一些小魔法。如果将一个归档文件(合法的归档文件包括gzip、bzip2、xz)指定为源文件, Docker会自动将归档文件解开(unpack)</p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">ADD latest.tar.gz /var/www/wordpress/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这条命令会将归档文件<code>latest.tax.gz</code>解开到<code>/var/www/wordpress/</code>目录下Docker解开归档文件的行为和使用带<code>-x</code>选项的<code>tar</code>命令一样:该指令执行后的输出是原目录的目录已经存在的内容加上归档文件中的内容。如果目的位置的目录下已经存在了和归档文件同名的文件或者目录, 那么目的位置中的文件或者目录不会被覆盖。<br>最后,如果目的位置不存在的话, Docker将会为我们创建这个全路径, 包括路径中的任何目录。新创建的文件和目录的模式为0755,并且UID和GID都是0。</p><blockquote><p><code>ADD</code>指令会使得构建缓存变得无效,这一点也非常重要。如果通过<code>ADD</code>指令向镜像添加一个文件或者目录, 那么这将使Dockerfile中的后续指令都不能继续使用之前的构建缓存。</p></blockquote><h4 id="8-COPY"><a class="header-anchor" href="#8-COPY">¶</a>8. COPY</h4><p><code>COPY</code>指令非常类似于<code>ADD</code>,它们根本的不同是<code>COPY</code>只关心在构建上下文中复制本地文件, 而不会去做文件提取(extraction)和解压(decompression)的工作。</p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">COPY conf.d/ /etc/apache2/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这条指令将会把本地<code>conf.d</code>目录中的文件复制到<code>/etc/apache2/</code>目录中。<br>文件源路径必须是一个与当前构建环境相对的文件或者目录, 本地文件都放到和Dockerfi1e同一个目录下。不能复制该目录之外的任何文件,因为构建环境将会上传到Docker守护进程,而复制是在Docker守护进程中进行的。任何位于构建环境之外的东西都是不可用的。<code>COPY</code>指令的目的位置则必须是容器内部的一个绝对路径。<br>任何由该指令创建的文件或者目录的UID和GID都会设置为0。<br>如果源路径是一个目录,那么这个目录将整个被复制到容器中,包括文件系统元数据如果源文件为任何类型的文件,则该文件会随同元数据一起被复制。在这个例子里,源路径以/结尾,所以 Docker会认为它是目录,并将它复制到目的目录中。<br>如果目的位置不存在, Docker将会自动创建所有需要的目录结构, 就像<code>mkdir -p</code>命令那样。</p><h4 id="9-ONBUILD"><a class="header-anchor" href="#9-ONBUILD">¶</a>9. ONBUILD</h4><p><code>ONBUILD</code>指令能为镜像添加触发器(trigger)。当一个镜像被用做其他镜像的基础镜像（也称为父镜像）时(比如你的镜像需要从<strong>某未准备好的位置</strong>添加源代码,或者你需要执行<strong>特定于构建镜像的环境</strong>的构建脚本), 该镜像中的触发器将会在以其为基础镜像的 Dockerfile 被 build 的时候执行。<br>父镜像触发器会在子镜像构建过程中插入新指令, 我们可以认为这些指令是紧跟在子镜像<code>FROM</code>之后指定的。触发器可以是任何构建指令</p><pre><code>ONBUILD ADD . /app/src ONBUILD RUN cd /app/src &amp; make</code></pre><p>上面的代码将会在创建的（父）镜像中加入<code>ONBUILD</code>触发器, <code>ONBUILD</code>指令可以在镜像上运行<code>docker inspect</code>命令来査看</p><pre><code>$ sudo docker inspect 508efa4e4bf8...&quot;OnBuild&quot;: {    &quot;ADD . /app/src&quot;,    &quot;RUN cd /app/src/ &amp;&amp; make&quot;}...</code></pre><p>比如,我们为Apache2镜像构建一个全新的 Dockerfi1e,该镜像名为web_test:</p><pre><code>FROM ubuntu:14.04 MAINTAINER John &quot;xxx@example.com&quot; RUN apt-get update RUN apt-get install -y apache2 ENV APACHE_RUN_USER www-data ENV APACHE_RUN_GROUP www-data ENV APACHE_LOG_DIR /var/log/apache2 ONBUILD ADD . /var/www/ EXPOSE 80 ENTRYPOINT [&quot;/usr/sbin/apache2&quot;] CMD [&quot;-D&quot;, &quot;FOREGROUND&quot;]</code></pre><p>现在我们就来构建该镜像</p><pre><code>$ sudo docker build -t=&quot;web_test&quot;...Step 7: ONBUILD ADD . /var/www/ --&gt; Running in 0e117f6ea4ba --&gt; a79983575b86 Successfully built a79983575b86</code></pre><p>在新构建的镜像中包含一条<code>ONBUILD</code>指令,该指令会使用<code>ADD</code>指令将构建环境所在的目录下的内容全部添加到镜像中的<code>/var/www/</code>目录下。我们可以轻而易举地将这个Dockerfi1e作为一个通用的Web应用程序的模板,可以基于这个模板来构建Web应用程序。<br>我们可以通过构建一个名为<code>webapp</code>的镜像来看看如何使用镜像模板功能。它的Dockerfile如下：</p><pre><code>FROM web_testMAINTAINER john &quot;xxx@example.com&quot;ENV APPLICATION_NAME webappENV ENVIRONMENT development</code></pre><p><code>docker biuld</code>：</p><pre><code>$ sudo docker build -t=&quot;webapp&quot; Step 0: FROM web_test # Executing 1 build triggers Step onbuild-0: ADD . /var/www/ --&gt; 1a018213a59d --&gt; 1a018213a59d Step1: MAINTAINER john &quot;xxx@example.com&quot;  ... ...Successfully built 04829a360d86</code></pre><p>可以清楚地看到,在<code>FROM</code>指令之后, Docker插入了一条<code>ADD</code>指令,这条<code>ADD</code>指令是在<code>ONBUILD</code>触发器中指定的。执行完该<code>ADD</code>指令后, Docker才会继续执行构建文件的后续指令。这种机制使我每次都会将本地源代码添加到镜像,就像上面我们做到的那样, 也支持我为不同的应用程序进行一些特定的配置或者设置构建信息。这时,可以<code>web_test</code>当做一个镜像模板。<br><code>ONBUILD</code>触发器会按照在父镜像中指定的顺序执行,并且只能被继承一次(也就是说只能在子镜像中执行,而不会在孙子镜像中执行)。如果我们再基于<code>webapp</code>构建一个镜像,则新镜像是<code>web_test</code>的孙子镜像,因此在该镜像的构建过程中, <code>ONBUILD</code>触发器是不会被执行的。</p><blockquote><p>这里有好几条指令是不能用在<code>ONBUTLD</code>指令中的,包括<code>FROM</code>、 <code>MAINTAINER</code>和 <code>ONBULLD</code> 本身。之所以这么规定是为了防止在Dockerfile构建过程中产生递归调用的问题。</p></blockquote><h4 id="10-FROM"><a class="header-anchor" href="#10-FROM">¶</a>10. FROM</h4><pre class="line-numbers language-language-shell"><code class="language-language-shell">FROM scratch # 从头制作 base image，使用当前 host os 作为 docker 的 os filesystem 层<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">FROM centos # 使用 base image<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="11-LABEL"><a class="header-anchor" href="#11-LABEL">¶</a>11. LABEL</h4><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 定义元信息#作者LABEL maintainer="john@gmail.com"#版本LABEL version="1.0"#描述LABEL description="This is description"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="12-RUN"><a class="header-anchor" href="#12-RUN">¶</a>12. RUN</h4><p>每一条 RUN 命令都会生成新的一层 image。所以为了避免无用分层，合并多条命令成一行；为了美观，复杂的 RUN 用反斜线换行：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">RUN yum update && yum install -y vim \ # \ 换行。这里一共包含两个yum命令，使用 && 合并到了一个 RUNpython-dev<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="13-EXPOSE"><a class="header-anchor" href="#13-EXPOSE">¶</a>13. EXPOSE</h4><p>指定基于当前镜像运行的容器会暴露的端口。实际上在容器运行的时候这个端口并没有开放，需要使用 <code>-p</code> 参数来进行实际的端口开放和映射，即使在 Dockerfile 中完全没有定义 EXPOSE 也不影响 <code>-p</code> 的端口开放，也就是说 EXPOSE 仅是一个声明、规范的作用。另外，<code>-P</code> 会开放 EXPOSE 指定的所有端口，此时 EXPOSE 才显得有实际意义，另外 EXPOSE 也包含了协议约定，默认不写协议就是 TCP，如果要暴露 TCP 和 UDP ，则需要同时定义：</p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">EXPOSE 80/tcpEXPOSE 80/udp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="t-参数"><a class="header-anchor" href="#t-参数">¶</a>-t 参数</h3><p>该参数可以指定要构建的新镜像的仓库名和名称</p><h2 id="docker-push"><a class="header-anchor" href="#docker-push">¶</a>docker push</h2><p>镜像构建完毕之后，我们也可以将它上传到 Docker Hub （Registry?）上面去进行共享</p><blockquote><p>Docker Hub也提供了对私有仓库的支持,这是一个需要付费的功能,你可以将镜像存储到私有仓库中,这样只有你或者任何与你共享这个私有仓库的人才能访问该镜像。这样你就可以将机密信息或者代码放到私有镜像中,不必担心被公开访问了。</p></blockquote><p>我们可以通过<code>docker push</code>命令将镜像推送到 Docker Hub。</p><ol><li>首先我们尝试推送一个无用户前缀的镜像</li></ol><pre><code>[root@izwz920kp0myp15p982vp4z test]# docker push test_webError response from daemon: You cannot push a &quot;root&quot; repository. Please rename your repository to docker.io/&lt;user&gt;/&lt;repo&gt; (ex: docker.io/707845008/test_web)</code></pre><p>上面的指令中我们推送了一个<code>test_web</code>的镜像，这个镜像没有用户前缀，dockerhub 会认为它被推送到了主仓库，但是这是不被允许的。</p><ol start="2"><li>下面我们推送一个到其他用户前缀的镜像</li></ol><pre><code>[root@izwz920kp0myp15p982vp4z test]# docker push a/test_webThe push refers to a repository [docker.io/a/test_web]d1333a47bb14: Preparinged7f9a0373a2: Preparing842c2d1118bb: Preparing16542a8fc3be: Preparing6597da2e2e52: Preparing977183d4e999: Waitingc8be1b8f4d60: Waitingdenied: requested access to the resource is denied</code></pre><p>上面的指令中我们推送了一个<code>a/test_web</code>的镜像，这个镜像的用户前缀是&quot;a&quot;，docker hub 会根据我们通过<code>docker login</code>登录的用户信息进行权限校验，发现我们还是没有权限。</p><ol start="3"><li>接着我们推送一个自己的用户前缀的镜像</li></ol><pre><code>[root@izwz920kp0myp15p982vp4z test]# docker push 707845008/test_webThe push refers to a repository [docker.io/707845008/test_web]d1333a47bb14: Pusheded7f9a0373a2: Pushed842c2d1118bb: Pushed16542a8fc3be: Pushed6597da2e2e52: Pushed977183d4e999: Pushedc8be1b8f4d60: Pushed... ...</code></pre><p>上面的指令中我们推送了一个&quot;707845008/test_web&quot;的镜像，这个镜像的用户前缀是&quot;707845008&quot;，docker hub 会根据我们通过<code>docker login</code>登录的用户信息进行权限校验，发现我们的登录信息是正确的，然后到我们的用户仓库群下寻找名为&quot;707845008/test_web&quot;的仓库，如果不存在则创建这个仓库。然后校验现在推送的这个镜像的层是否有已经存在于远程仓库中了，如果有则不推送这些层了（镜像这个实体应该就是由层的引用堆叠而成），如果没有则进行推送。（这里没有测试如果存在重复的标签，会怎样，感觉应该就是覆盖，将之前的那个标签指向镜像实体中的层的引用进行覆盖更新即可）。然后将这些镜像保存到仓库中，并打上标签。</p><p>下面这段指令我基于一样的基础镜像不同的 Dockerfile 又构建了一个仓库名一样但是标签不一样的镜像，在推送的时候发现底层的基础层已经存在于远程仓库了，这是上面猜想的来源</p><pre><code>[root@izwz920kp0myp15p982vp4z test1]# docker push 707845008/test_web:otherThe push refers to a repository [docker.io/707845008/test_web]faedecbf345a: Pushed842c2d1118bb: Layer already exists16542a8fc3be: Layer already exists6597da2e2e52: Layer already exists977183d4e999: Layer already existsc8be1b8f4d60: Layer already existsother: digest: sha256:a766d2330ba6ee88da5f70aa5be9f215c9c0a5e7118780a926a58d1f3f6e0c35 size: 1576</code></pre><p>推送之后的 dockerhub 仓库<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221205432.png" alt="1a9c5a86957db5a474446c4086e1874a"></p><h2 id="docker-rmi"><a class="header-anchor" href="#docker-rmi">¶</a>docker rmi</h2><p>如果不再需要一个镜像了,也可以将它删除。可以使用<code>docker rmi</code>命令来删除一个镜像</p><pre><code>[root@izwz920kp0myp15p982vp4z test1]# docker rmi john/web-test:tag_2Untagged: john/web-test:tag_2</code></pre><p>另外还可以指定多个镜像进行删除</p><pre><code>[root@izwz920kp0myp15p982vp4z test1]# docker rmi 707845008/test_web:other 707845008/test-wen:otherUntagged: 707845008/test_web:otherUntagged: 707845008/test_web@sha256:a766d2330ba6ee88da5f70aa5be9f215c9c0a5e7118780a926a58d1f3f6e0c35Untagged: 707845008/test-wen:otherDeleted: sha256:6f48bf776f6b3ef52d7ac06a4f3fa65807e3e9efa7fa11d02516e24ef1d1d83fDeleted: sha256:907964e8f9cde4b56ebf76e811eda45371e7a8a94a73b47dcfe3e93e13503475</code></pre><p>或者,类似于<code>docker rm</code>命令那样来使用<code>docker rmi</code>命令:</p><pre><code>$ sudo docker rmi `docker images -a -q`</code></pre><p>注意，如果不指定 tag，docker 会默认是 latest 进行删除。通过以上的观察可以发现，docker 在删除镜像的时候如果发现当前镜像中的所有层都在被另外还存在的镜像引用是不会删除这些层的，只是把当前镜像这个&quot;壳子&quot;干掉，然后在镜像索引表中干掉这个镜像的索引（标签、id 等）；如果存在没有被其他镜像引用的层则会将这些层也删掉。</p><p>另外，如果一个镜像拥有一个的容器，也是不能被删除的，除非用<code>-f</code>强制删除</p><pre><code>[root@izwz920kp0myp15p982vp4z test1]# docker rmi docker.io/ubuntu:latestError response from daemon: conflict: unable to remove repository reference &quot;docker.io/ubuntu:latest&quot; (must force) - container 47ef1e6c79ba is using its referenced image 4e5021d210f6</code></pre><h3 id="f-参数"><a class="header-anchor" href="#f-参数">¶</a>-f 参数</h3><p>强制删除</p><h2 id="docker-history"><a class="header-anchor" href="#docker-history">¶</a>docker history</h2><p>显示镜像的构建记录</p><pre><code>[root@izwz920kp0myp15p982vp4z test]# docker history cff52e402b5cIMAGE               CREATED             CREATED BY                                      SIZE                COMMENTcff52e402b5c        15 minutes ago      /bin/sh -c #(nop)  EXPOSE 80/tcp                0 Bdef92ee88354        15 minutes ago      /bin/sh -c echo 'Hi, I am in your containe...   27 Bd025c0d41d86        15 minutes ago      /bin/sh -c apt-get install -y nginx             60.2 MB7b961b19d1c3        15 minutes ago      /bin/sh -c apt-get update                       28.2 MB2114db666fdb        15 minutes ago      /bin/sh -c #(nop)  MAINTAINER JOHN &quot;707845...   0 B4e5021d210f6        12 days ago         /bin/sh -c #(nop)  CMD [&quot;/bin/bash&quot;]            0 B&lt;missing&gt;           12 days ago         /bin/sh -c mkdir -p /run/systemd &amp;&amp; echo '...   7 B&lt;missing&gt;           12 days ago         /bin/sh -c set -xe   &amp;&amp; echo '#!/bin/sh' &gt;...   745 B&lt;missing&gt;           12 days ago         /bin/sh -c [ -z &quot;$(apt-get indextargets)&quot; ]     987 kB&lt;missing&gt;           12 days ago         /bin/sh -c #(nop) ADD file:594fa35cf803361...   63.2 MB</code></pre><p>从上面的结果可以看到新构建的镜像的每一层,以及创建这些层的Dockerfi1e指令。</p><h2 id="docker-tag"><a class="header-anchor" href="#docker-tag">¶</a>docker tag</h2><p>给镜像打上新标签：</p><pre><code>[root@izwz920kp0myp15p982vp4z test]# docker tag baa36456c7e6 127.0.0.1:5000/john/test_web:new_tag[root@izwz920kp0myp15p982vp4z test]# docker imagesREPOSITORY                     TAG                 IMAGE ID            CREATED             SIZE127.0.0.1:5000/john/test_web   latest              baa36456c7e6        8 minutes ago       153 MB127.0.0.1:5000/john/test_web   new_tag             baa36456c7e6        8 minutes ago       153 MBjohn/test_web                  latest              baa36456c7e6        8 minutes ago       153 M</code></pre><h1>镜像知识</h1><h2 id="Registry"><a class="header-anchor" href="#Registry">¶</a>Registry</h2><p>镜像从仓库下载下来。镜像保存在仓库中,而仓库存在于Registry中。默认的Registry是由Docker公司运营的公共Registry服务,即Docker Hub。<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221205439.png" alt="5c9234bc71abcbfcac12a146bc16b07d"></p><blockquote><p>Docker Registry的代码是开源的,你也可以运行自己的私有 Registry。</p></blockquote><p>在Docker Hub(或者你自己运营的Registry)中, 镜像是保存在仓库中的。<strong>仓库包括镜像、层以及关于镜像的元数据( metadata)。</strong> 每个镜像仓库都可以存放很多镜像(比如, ubuntu仓库包含了 Ubuntu12.04、12.10、13.04、13.10和14.04的镜像)。</p><p><strong>可以将镜像仓库想象为类似Git仓库的东西，一个镜像可以类比一个应用程序项目的代码，一份&quot;应用程序代码&quot;的不同分支类似一个镜像的不同标签（分支和标签一样决定应用程序和镜像所发布的不同版本），而在 git 的一个分支中又会有不同提交的概念，而在 docker 中会存在镜像的层的概念，镜像由层堆叠而成，和 git 管理的&quot;代码&quot;由一次次提交堆叠而成一样的。同一个镜像仓库中的各个镜像所包含的层可能是一样的，可能一个是另一个的真子集，可能存在部分交集，还可能完全不一样。</strong> 另外在实践中发现层貌似也是一个真实存在的对象，基于相同基础镜像，不同 Dockerfile 构建出来的镜像拥有底层一样的层（唯一标识都是一样的），而在<code>docker push</code>命令被执行的时候，会读取出来镜像中对的层是否已经存在于远程仓库了，如果存在则不会再 push 了，这说明了docker镜像这个对象应该就是一个&quot;空壳&quot;，它准确来说应该是由&quot;层的引用&quot;构成的，它存储的内容应该就是这些&quot;层的引用&quot;，在它被作为容器跑起来的时候才会去加载这些层。</p><p>Docker Hub中有两种类型的仓库:用户仓库(user repository)和顶层仓库(top-level repository)。用户仓库的镜像都是由Docker用户创建的,而顶层仓库则是由Docker内部的人来管理的。<br>用户仓库的命名由<strong>用户名和镜像名</strong>两部分组成,如jamtur01/puppet</p><ul><li>用户名: 如jamtur01。</li><li>仓库名: puppet。</li></ul><p>与之相对,顶层仓库只包含仓库名部分,如ubuntu仓库。顶层仓库由Docker公司和由选定的能提供优质基础镜像的厂商(如Fedora团队提供了fedora镜像)管理,用户可以基于这些基础镜像构建自己的镜像。同时顶层仓库也代表了各厂商和 Docker公司的一种承诺,即顶层仓库中的镜像是架构良好、安全且最新的。</p><blockquote><p>用户贡献的镜像都是由Docker社区用户提供的,这些镜像并没有经过 Docker公司的确认和验证,在使用这些镜像时需要自己承担相应的风险。</p></blockquote><h3 id="Registry自动构建"><a class="header-anchor" href="#Registry自动构建">¶</a>Registry自动构建</h3><p>除了从命令行构建和推送镜像, Docker Hub还允许我们定义自动构建( Automated Builds)。为了使用自动构建,我们只需要将Github或 Bitbucket中含有Dockerfile文件的仓库连接到Docker Hub即可。向这个代码仓库推送代码时,将会触发一次镜像构建活动并创建一个新镜像。在之前该工作机制也被称为可信构建(Trusted Build)。</p><blockquote><p>自动构建同样支持私有 Github和 Bitbucket仓库。</p></blockquote><p>详情参考：<a href="https://docs.docker.com/docker-hub/builds/" target="_blank" rel="noopener">https://docs.docker.com/docker-hub/builds/</a></p><h3 id="运行自己的-Docker-Registry"><a class="header-anchor" href="#运行自己的-Docker-Registry">¶</a>运行自己的 Docker Registry</h3><p>显然,拥有Docker镜像的一个公共的Registry非常有用。但是,有时候我们可能希望构建和存储包含不想被公开的信息或数据的镜像。这时候我们有以下两种选择。</p><ul><li>利用 Docker Hub上的私有仓库。</li><li>在防火墙后面运行你自己的 Registry。</li></ul><p>值得感谢的是, Docker公司的团队开源了他们用于运行 Docker Registry 的代码,这样我们就可以基于此代码在内部运行自己的 Registry。</p><blockquote><p>目前Registry还不支持用户界面,只能以API服务器的方式来运行?</p></blockquote><h4 id="从容器运行-Registry"><a class="header-anchor" href="#从容器运行-Registry">¶</a>从容器运行 Registry</h4><p>以下命令将会启动一个运行 Registry 应用的容器,并绑定到本地宿主机的5000端口。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z ~]# docker run -p 5000:5000 registryUnable to find image 'registry:latest' locallyTrying to pull repository docker.io/library/registry ...latest: Pulling from docker.io/library/registry486039affc0a: Pull completeba51a3b098e6: Pull complete8bb4c43d6c8e: Pull complete6f5f453e5f2d: Pull complete42bc10b72f42: Pull completeDigest: sha256:7d081088e4bfd632a88e3f3bcd9e007ef44a796fddfe3261407a3f9f04abe1e7Status: Downloaded newer image for docker.io/registry:latest<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="测试新-Registry"><a class="header-anchor" href="#测试新-Registry">¶</a>测试新 Registry</h4><p>我们找到想要推送到自己的 Registry 的 image</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z test]# docker imagesREPOSITORY           TAG                 IMAGE ID            CREATED              SIZEjohn/test_web        latest              baa36456c7e6        About a minute ago   153 MB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>使用新的 Registry 给该镜像打上标签，在镜像名前加上主机名和端口前缀：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z test]# docker tag baa36456c7e6 127.0.0.1:5000/john/test_web<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可以看到，原有的镜像被复制出来并打上了一个新的标签</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z test]# docker imagesREPOSITORY                     TAG                 IMAGE ID            CREATED             SIZE127.0.0.1:5000/john/test_web   latest              baa36456c7e6        3 minutes ago       153 MBjohn/test_web                  latest              baa36456c7e6        3 minutes ago       153 MB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>此时对该标签进行推送</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z test]# docker push 127.0.0.1:5000/john/test_webThe push refers to a repository [127.0.0.1:5000/john/test_web]f03217d243c7: Pushed47faf580ebd8: Pushed194c0f1f1060: Pushed16542a8fc3be: Pushed6597da2e2e52: Pushed977183d4e999: Pushedc8be1b8f4d60: Pushedlatest: digest: sha256:6bcf5d0f00b0fc9f6f05b0535cf3e98417f6c74293184c0fc4769bccd1f0c293 size: 1783<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>推送成功！此时我们再基于该镜像启动一个容器：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z test]#[root@izwz920kp0myp15p982vp4z test]# docker run -it 127.0.0.1:5000/john/test_webroot@3ee47d104d22:/#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>成功！</p><blockquote><p>这是在防火墙后面部署自己的Docker Registry的最简单的方式。我们并没有解释如何配置或者管理 Registry。如果想深入了解如何配置认证和管理后端镜像存储方式,以及如何管理 Registry等详细信息,可以在 Docker Registry文档查看完整的配置和部署说明。</p></blockquote><h3 id="其他可选-Registry-服务"><a class="header-anchor" href="#其他可选-Registry-服务">¶</a>其他可选 Registry 服务</h3><p>也有很多其他公司和服务提供定制的 Docker Registry服务。</p><h2 id="标签"><a class="header-anchor" href="#标签">¶</a>标签</h2><p>为了区分同一个仓库中的镜像的不同版本, Docker提供了一种称为标签(tag)的功能。每个镜像在列出来时都带有一个标签,如12.10、12.04、 quantal等。<strong>每个标签对</strong>组成特定镜像的一些镜像层进行标记(比如,标签12.04就是对所有Ubuntu12.04镜像的层的标记)。这种机制使得在同一个仓库中可以存储多个版本的镜像。<br>我们可以通过在仓库名后面加上一个冒号和标签名来指定该仓库中的某一镜像版本。<br>我们还能看到很多镜像版本具有相同的镜像ID，它们被打了很多个标签。<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221205450.png" alt="75660e8811892b65ae73de8269cf65ff"><br><strong>比如,74fe38a11401的镜像被打上了12.04和 precise两个标签,分别代表该 Ubuntu发布版的版本号和代号(code name)。但是它们都是同一个镜像。</strong><br>在构建容器时指定仓库的标签也是一个很好的习惯。这样便可以准确地指定容器来源于哪里。不同标签的镜像会有不同,比如 Ubutnu12.04和14.04就不一样,指定镜像的标签会让我们确切知道自己使用的是 ubuntu:12.04,这样我们就能准确知道我们在千什么。</p>]]></content>
      
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2、安装Docker</title>
      <link href="/2020/12/22/docker/yin-xiang-bi-ji/2-an-zhuang-docker/"/>
      <url>/2020/12/22/docker/yin-xiang-bi-ji/2-an-zhuang-docker/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1>总览</h1><p>Docker的安装既快又简单。目前, Docker已经支持非常多的 <strong>Linux平台</strong>,包括 Ubuntu 和RHEL( Red Hat Enterprise Linux, Red Hat企业版 Linux)。除此之外, Docker还支持 Debian、Centos、 Fedora、 Oracle Linux等衍生系统和相关的发行版。<strong>如果使用虚拟环境</strong>,甚至也可以在OSX和 Microsoft Windows中运行 Docker。下面的安装介绍主要包括：</p><ul><li>在运行 Ubuntu系统的宿主机中安装 Docker</li><li>在运行RHEL或其衍生的 Linux发行版的宿主机中安装 Docker</li><li>在OSX系统中用<strong>Boot2Docker</strong>工具安装 Docker:</li><li>在 Microsoft Windows系统中使用<strong>Boot2Docker</strong>工具安装 Docker</li></ul><blockquote><p><a href="http://boot2docker.io" target="_blank" rel="noopener">Boot2Docker</a>是一个极小的虚拟机,同时提供了一个包装脚本( wrapper scnpt)对该虚拟机进行管理。该虚拟机运行一个守护进程,并在OSX或 Microsoft Windows中提供一个本地的 Docker守护进程。 Docker的客户端工具 docker可以作为这些平台的原生程序安装,并连接到在Boo2 Docker虚拟机中运行的 Docker守护进程。</p></blockquote><h1>安装 docker 的先决条件</h1><p>和安装其他软件一样,安装 Docker也需要一些基本的前提条件。 Docker要求的条件具体如下。</p><ul><li><p>运行64位CPU构架的计算机(目前只能是x8664和amd64),请注意, Docker日前不支持32位CPU。</p></li><li><p>运行 Linux3.8或更高版本内核。一些老版本的2.6.x或其后的内核也能够运行 Docker, 但运行结果会有很大的不同。而且,如果你需要就老版本内核寻求帮助时,通常大家会建议你升级到更高版本的内核。</p></li><li><p>内核必须支持一种适合的存储驱动( storage driver), 例如：</p><ul><li>DeviceManager</li><li>AUFS</li><li>vfs</li><li>btrfs</li></ul><p>默认存储驱动通常是 Device Mapper。</p></li><li><p>内核必须支持并开启 cgroup和命名空间(namespace)功能。</p></li></ul><h1>在 Ubuntu 中安装 Docker</h1><h2 id="1-检查前提条件"><a class="header-anchor" href="#1-检查前提条件">¶</a>1.检查前提条件</h2><h3 id="1-1-内核"><a class="header-anchor" href="#1-1-内核">¶</a>1.1 内核</h3><p>首先,确认已经安装了能满足要求的 Linux内核。可以通过 uname命令来检查内核版本信息</p><pre><code>$ uname -aLinux darknight.example.com 3.8.0-23-generic #34-precisel-ubuntu SMP Wed May 29 21:12:31 UTC 2013 x86_64 X86_64 x86_64 GNU/ Linux</code></pre><p>可以看到,这里安装的是3.8.0x86_64版本的内核。这是 Ubuntu12.04.3及更高版本(包括 Ubuntu13.04 Raring)默认的内核但是,如果我们使用 Ubuntu12.04 Precise较早的发行版,可能是3.2内核。我们也可以轻松地把 Ubuntu2.04升级到最新的内核。例如,本书写作时,3.8版本的内核已经可以用apt-get来安装了:</p><pre><code>$ sudo apt-get update$ sudo apt-get install linux-headers-3.8.0-27-genericlinux-image-3.8.0-27-generic linux-headers-3.8.0-27</code></pre><p>然后，我们就可以更新 Grub 启动加载器来加载新内核：</p><pre><code>sudo update-grub</code></pre><p>完成安装后，需要重启宿主机来启动新的3.8内核：</p><pre><code>sudo reboot</code></pre><p>重启之后，我们可以再次使用<code>uanme -a</code>来确定已经运行了正确版本的内核。</p><h3 id="1-2-检查Device-Mapper"><a class="header-anchor" href="#1-2-检查Device-Mapper">¶</a>1.2 检查Device Mapper</h3><p>这里我们将使用 Device Mapper作为存储驱动。自2.6.9版本的 Linux内核开始已经集成了 Device Mapper,并且提供了一个将块设备映射到高级虚拟设备的方法。 Device Mapper支持“自动精简配置”(thin-provisioning)的概念,可以在一种文件系统中存储多台虚拟设备( Docker镜像中的层)。因此,用 Device Mapper作为 Docker 的存储驱动是再合适不过了。<br>任何 Ubuntu12.04或更高版本的宿主机应该都已经安装了 Device Mapper,可以通过以下代码来确认是否已经安装：</p><pre><code>$ ls -l /sys/class/misc/device-mapperlrwxrwxrwx 1 root root 0 Oct 5 18:50 /sys/class/misc/device-mapper -&gt; ../../devices/virtual/misc/device-mapper</code></pre><p>也可以在/proc/devices文件中检査是否有 device-mapper条目</p><pre><code>$ sudo grep device-mapper /proc/devices</code></pre><p>如果没有出现 device-mapper 的相关信息，我们也可以尝试加载 dm_mode 模块：</p><pre><code>$ sudo modprobe dm_mod</code></pre><p>cgroup和命名空间自2.6版本开始己经集成在Linux内核中了。2.6.38以后的内核对cgroup和命名空间都提供了良好的支持,基本上也没有什么bug。</p><h2 id="2-安装-Docker"><a class="header-anchor" href="#2-安装-Docker">¶</a>2.安装 Docker</h2><p>现在“万事俱备,只欠东风”。我们将使用 Docker团队提供的DEB软件包来安装 Docker 首先,要添加 Docker的APT仓库。</p><pre><code>$ sudo sh -c &quot;echo deb https://get.docker.io/ubuntu docker main &gt; /etc/apt/sources.list.d/docker.list&quot;</code></pre><p>其间,可能会提示我们确认添加仓库并自动将仓库的GPG添加到宿主机中。<br>安装之前，我们首先需要确认已经安装了 curl 命令</p><pre><code>whereis curlcurl: /usr/bin/curl /usr/bin/X11/curl /usr/share/man/man1/curl.1.gz</code></pre><p>如果没有找到 curl 命令，我们需要先安装它</p><pre><code>$ sudo apt-get -y install curl</code></pre><p>接下来，要添加 Docker 仓库的 GPG 密钥</p><pre><code>$ curl -s https://get.docker.io/gpg | sudo apt-key add -</code></pre><p>之后，我们需要更新 APT 源</p><pre><code>$ sudo apt-get update</code></pre><p>现在，我们就可以安装 Docker 软件包了</p><pre><code>$ sudo apt-get install lxc-docker</code></pre><p>执行该命令后，系统会安装 Docker 软件包以及一些必需的软件包。<br>安装完毕，可以使用 docker info 命令来确认 Docker 是否已经正常安装并运行了。</p><h2 id="3-Docker-与-UFW"><a class="header-anchor" href="#3-Docker-与-UFW">¶</a>3.Docker 与 UFW</h2><p>在 Ubuntu 中，如果使用 UFW，即 Uncomplicated Firewall，那么还需要对其做一点儿改动才能让 Docker工作。 Docker使用一个网桥来管理容器中的网络。默认情况下,UFW会丢弃所有转发的数据包(也称分组)。因此,需要在UFW中启用数据包的转发,这样オ能让Docker正常运行。我们只需要对/etc/ default/ufw文件做一些改动即可。我们需要将这个文件中以下代码</p><pre><code>DEFAULT_FORWARD_POLICY=&quot;DROP&quot;</code></pre><p>替换为</p><pre><code>DEFAULT_FORWARD_POLICY=&quot;ACCEPT&quot;</code></pre><p>保存修改内容并重新加载 UFW 即可：</p><pre><code>$ sudo ufw reload</code></pre><h1>在 Red Hat 和 Red Hat 系发行版中安装 Docker</h1><p>在 Red Hat 企业版 Linux（或者 CentOs 或Fedora）中，只有少数几个版本可以安装 Docker，包括：</p><ul><li>RHEL（和 CentOS）6或以上的版本（64位）</li><li>Fedora Core19或者以上的版本（64位）</li><li>Oracle Linux 6 和 Oracle Linux 7，带有 Unbreakable 企业内核发行版3（3.8.13）或者更高版本（64位）</li></ul><blockquote><p>在 Red Hat企业版 Linux7及更高版本中, Docker已经成为系统自带的软件包了,并且, 只有 Red Hat企业版 Linux7是 Red Hat官方支持 Docker的发行版本。</p></blockquote><h2 id="1-检查前提条件-v2"><a class="header-anchor" href="#1-检查前提条件-v2">¶</a>1.检查前提条件</h2><h3 id="1-1-内核-v2"><a class="header-anchor" href="#1-1-内核-v2">¶</a>1.1 内核</h3><p>使用<code>uname</code>命令来确认是否安装了3.8后者更高的内核版本</p><h3 id="1-2-检查-Device-Mapper"><a class="header-anchor" href="#1-2-检查-Device-Mapper">¶</a>1.2 检查 Device Mapper</h3><p>我们这里使用 Device Mapper 作为 Docker 的存储驱动，在 RedHat 企业版 Linux、CentOS6或Fedora Core 19及更高版本宿主机中，应该也都安装了 DeviceMapper，不过还是需要确认以下：</p><pre><code>$ ls 0l /sys/class/misc/device-mapperlrwxrwxrwx 1 root root 0 Oct 5 18:50 /sys/class/misc/device-mapper -&gt; ../../devices/virtual/misc/device-mapper</code></pre><p>同样，也可以在/proc/devices文件中检查是否有 device-mapper 条目：</p><pre><code>$ sudo grep device-mapper /proc/devices</code></pre><p>如果没有检测到 Device Mapper，我们可以试着安装 Device-mapper 软件包：</p><pre><code>$ sudo yum install -y device-mapper</code></pre><p>安装完成后，还需要加载 dm_mod内核模块：</p><pre><code>$ sudo modprobe dm_mod</code></pre><p>模块加载完毕，我们就应该可以找到/sys/class/misc/device-mapper 条目了。</p><h2 id="2-安装-Docker-v2"><a class="header-anchor" href="#2-安装-Docker-v2">¶</a>2.安装 Docker</h2><p>在不同版本的 RedHat 中，安装过程略有不同。在 RHEL6或者 CentOS6中，需要先添加 EPEL 软件包的仓库。而 Fedora中则不需要启用EPEL仓库。在不同的平台和版本中,软件包命名也有细微的差别。</p><h3 id="2-1-在RHEL6和-CentOS6中安装-Docker"><a class="header-anchor" href="#2-1-在RHEL6和-CentOS6中安装-Docker">¶</a>2.1 在RHEL6和 CentOS6中安装 Docker</h3><p>对于 RedHat 企业版 Linux6和 CentOS6，可以使用以下指令的 RPM软件包来安装 EPEL：</p><pre><code>sudo rpm -Uvh http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm</code></pre><p>安装完 EPEL 后，就可以安装 Docker 了</p><pre><code>sudo yum -y install docker-io</code></pre><h3 id="2-2-在-RHEL7-中安装Docker"><a class="header-anchor" href="#2-2-在-RHEL7-中安装Docker">¶</a>2.2 在 RHEL7 中安装Docker</h3><p>略</p><h3 id="2-3-在-Fedora-中安装Docker"><a class="header-anchor" href="#2-3-在-Fedora-中安装Docker">¶</a>2.3 在 Fedora 中安装Docker</h3><p>在不同版本的 Fedora 中，软件包的名称有所不同。在 Fedora 19中，要安装 docker-io 这个软件包：</p><pre><code>$ sudo yum -y install docker-ioo</code></pre><p>在 Fedora20或更高的版本中，软件包的名称已经改为 docker：</p><pre><code>$ sudo yum -y install docker</code></pre><h2 id="3-在-Red-Hat-系发行版中启动-Docker-守护进程"><a class="header-anchor" href="#3-在-Red-Hat-系发行版中启动-Docker-守护进程">¶</a>3.在 Red Hat 系发行版中启动 Docker 守护进程</h2><p>软件包安装完成后就可以启动 Docker 守护进程了。在 RHEL6或CentOS6中：</p><pre><code>$ sudo service docker start</code></pre><p>想要在系统开机时自动启动 Docker服务</p><pre><code>$ sudo service docker enable</code></pre><p>在RHEL7或Fedora中启动 Docker 服务</p><pre><code>$ sudo systemctl start docker</code></pre><p>想要在系统开机自动启动 Docker 服务：</p><pre><code>$ sudo systemctl enable docker</code></pre><p>完成上述工作之后，就可以用 docker info命令来确认 Docker 是否已经正确安装并运行了：</p><pre><code>$ sudo docker infoContainers: 0Image: 0...</code></pre><h1>在 OS X 中安装 Boot2Docker</h1><p>如果使用的是OSX系统,则可以使用 Boot2Docker工具快速上手 Docker, Boot2Docker 是一个极小的虚拟机,Boot2Docker在OSX宿主机上安装了一个原生的命令行工具,并提供了一个 Docker环境。<br>要在 OS X中安装Boot2，也依赖于两个必要的条件：</p><ul><li>VirtualBox</li><li>Docker 客户端</li></ul><h2 id="1-安装"><a class="header-anchor" href="#1-安装">¶</a>1 安装</h2><p>下载最新的 Boot2Docker：</p><pre><code>$ wget https://github.com/boot2docker/osx-installer/release/download/v1.3.0/Boot2Docker-1.3.0.pkg</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221205224.png" alt="aeadebfeeb9f48a7c7d496d936ae0b41"><br>如上图进行安装</p><h2 id="2-启动"><a class="header-anchor" href="#2-启动">¶</a>2 启动</h2><p>安装完之后单击Boot2Docker 图标来初始化并启动 Boot2Docker 虚拟机：<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221205242.png" alt="29842b7f4a5d0806d4fdf498050b4f06"></p><h2 id="3-测试"><a class="header-anchor" href="#3-测试">¶</a>3 测试</h2><p>使用本机的Docker 客户端连接到 Boot2Docker 虚拟机中运行的 Docker 守护进程：</p><pre><code>$ Docker infoContainers: 0Image: 0Driver: aufsRoot Dir: /mnt/sda1/var/lib/docker/aufsDirs: 0...Kernel Version:3.13.3-tinycore64</code></pre><h2 id="4-注意"><a class="header-anchor" href="#4-注意">¶</a>4 注意</h2><blockquote><p>当需要通过网络接口或网络端口连接到某个容器,通常这个地址是 Docker 服务器的 localhost或IP地址。因为Boo2Docker是一个本地的虚拟机,拥有自己的网络接口和IP地址,因此,我们需要连接的是Boo2 Docker的地址,而不是1oca1host或宿主机的IP地址。要想得到Boot2Docker的IP地址,可以查看 DOCKER_HOST环境变量的值。当启动或安装Boot2Docker的时候, 也会弹出信息提示这个变量。<br>此外，你也可以运行 boot2docker ip 命令来查看 Boot2Docker 的 IP 地址：<code>boot2docker ip</code>，获得了 Boot2Docker 的 IP 地址后，就可以连接 localhost 上的容器了。例如，使用 curl 命令时，只需将 localhost 替换成相应的 IP 地址即可。</p></blockquote><h1>在 Windows 中安装 Boot2Docker</h1><p>如果使用的是 Microsoft Windows系统,也可以使用Boot2Docker工具快速上手 Docker。Boot2Docker是一个极小的虚拟机,Boot2Docker在 Windows宿主机上安装了一个原生的命令行工具,并提供了一个 Docker环境。<br>要在 WIndows 中安装 Boot2Docker，也依赖于两个必要的条件：</p><ul><li>VirtualBox</li><li>Docker 客户端</li></ul><h2 id="1-在-Windows-中安装-Boot2Docker"><a class="header-anchor" href="#1-在-Windows-中安装-Boot2Docker">¶</a>1 在 Windows 中安装 Boot2Docker</h2><p>和 osx 一样在 github 上下载相应的安装程序并安装</p><pre><code>$ wget https://github.com/boot2docker/windows-installer/releases/download/v1.3.0/docker-install.exe</code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221205250.png" alt="7666e83c71afd9d0faa6f178105c3321"></p><h2 id="2-启动-v2"><a class="header-anchor" href="#2-启动-v2">¶</a>2 启动</h2><p>点击图标启动<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221205256.png" alt="b4cb01ecefe9a6376b4b6aa0f0727388"></p><h2 id="3-测试-v2"><a class="header-anchor" href="#3-测试-v2">¶</a>3 测试</h2><p>同 osx，略</p><h1>脚本安装</h1><p>我们还有另外一种方法，就是使用远程安装脚本在相应的宿主机上安装 Docker。我们可以从 <a href="http://get.docker.io" target="_blank" rel="noopener">get.docker.io</a> 网站获取这个安装脚本。</p><ol><li>确认 curl 命令</li></ol><pre><code>$ whereis curlcurl: /usr/bin/curl /usr/bin/X11/curl /usr/share/man/man1/curl.1.gz</code></pre><ol start="2"><li>如有需要，安装 curl<br><strong>Ubuntu</strong></li></ol><pre><code>$ sudo apt-get -y install curl</code></pre><p><strong>Fedora</strong></p><pre><code>$ sudo yum -y install curl</code></pre><ol start="3"><li>下载安装脚本并安装 Docker</li></ol><pre><code>$ curl https://get.docker.io/ | sudo sh</code></pre><p>这个脚本会自动安装 Docker 所需的依赖，并且检查当前系统的内核版本是否满足要求，以及是否支持所需的存储驱动，最后会安装 Docker 并启动 Docker 守护进程。</p><h1>二进制安装</h1><p>如果不想用基于软件包的安装方法，我们也可以下载最新的 Docker 可执行程序：</p><pre><code>$ wget http://get.docker.io/builds/Linux/x86_64/docker-latest.git</code></pre><h1>Docker 守护进程</h1><p>安装完 Docker后,我们需要确认 Docker的守护进程是否运行。 Docker以root权限运行它的守护进程,来处理普通用户无法完成的操作(如挂载文件系统)。 docker程序是Docker守护进程的客户端程序,同样也需要以root身份运行。<br>当 Docker软件包安装完毕后,默认会立即启动 Docker守护进程。守护进程监听/var/run/docker.sock这个Unix套接字文件,来获取来自客户端的 Docker请求。如果系统中存在名为 docker的用户组的话, Docker则会将该套接字文件的所有者设置为该用户组。<strong>这样, docker用户组的所有用户都可以直接运行 Docker,而无需再使用sudo 命令了。</strong></p><h2 id="配置-Docker-守护进程"><a class="header-anchor" href="#配置-Docker-守护进程">¶</a>配置 Docker 守护进程</h2><p>以下命令都可以启动 Docker 守护进程</p><pre><code>$ systemctl start docker</code></pre><pre><code>$ dockerd</code></pre><p>但是都是默认绑定到/var/run/docker.sock套接字，即网络接口是默认固定的。通过以下命令可以指定守护进程监听的网络接口</p><pre><code>$ sudo dockerd -H tcp://0.0.0.0:2375</code></pre><p>此时运行客户端就不能是<code>docker info</code>了，需要指定守护程序监听的网络接口：</p><pre><code>$ sudo docker -H tcp://0.0.0.0:2375 info</code></pre><p>或者通过指定环境变量<code>DOCKER_HOST</code> 来实现</p><pre><code>$ export DOCKER_HOST='tcp://0.0.0.0:2375'</code></pre><p>另外，我们还可以指定一个 Unix 套接字路径：</p><pre><code>$ sudo dockerd -H /var/run/docker.sock</code></pre><p>还可以绑定就那个多个网络接口</p><pre><code>$ sudo dockerd -H tcp://0.0.0.0:2375 -H /var/run/docker.sock</code></pre><p>在启动守护进程时,我们还可以通过在命令前指定 <code>DEBUG=1</code> 参数来输出更详细的信息。目前, Docker的日志输出还比较少。在使用了 Upstart的 Ubuntu系统下, Docker守护进程生成的日志输出都保存在<code>/var/1og/upstart/docker.1og</code>文件中</p><pre><code>$ DEBUG=1 dockerd</code></pre><p>要想让这些改动永久生效,需要编辑启动配置项。在Ubuntu中,我们需要编辑<code>/etc/default/docker</code>文件,并修改<code>DOCKER_OPTS</code>变量。<br>在 Fedora和 Red Hat发布版本中,则需要编辑<code>/usr/1ib/systemd/system/docker.service</code>文件,并修改其中的 <code>Execstart</code>配置项。</p><h2 id="检查守护进程是否运行"><a class="header-anchor" href="#检查守护进程是否运行">¶</a>检查守护进程是否运行</h2><p>略</p><h1>升级 Docker</h1><p>略</p><h1>Docker图形用户界面</h1><p>Docker安装之后,也可以用图形用户界面来进行管理。目前,有一些正在开发中的 Docker 用户界面和Web控制台,它们都处于不同的开发阶段,具体如下。</p><ul><li>Shipyard: Shipyard提供了通过管理界面来管理各种Docker资源(包括容器、镜像、宿主机等)的功能。Shipyard是开源的,源代码可以在<a href="https://github.com/ehazlett/shipyard" target="_blank" rel="noopener">https://github.com/ehazlett/shipyard</a> 获得。</li><li>DockerUI: DockerUI是一个可以与 Docker Remote API交互的Web界面。 DockerUI 是基于 Angularjs框架,采用 Javascript 编写的。</li><li>maDocker: maDocker是采用 NodeJS 和 Backbone 编写的一个WebUI,还处于早期开发阶段。</li></ul>]]></content>
      
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>k8s入门概述</title>
      <link href="/2020/12/22/docker/k8s-ru-men-gai-shu/"/>
      <url>/2020/12/22/docker/k8s-ru-men-gai-shu/</url>
      
        <content type="html"><![CDATA[<p>k8s 里面的节点分为 master 和 node 节点，master 提供 api 操作集群。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203114.png" alt="image-20201022152526918"></p><p>Master：</p><ul><li>API Server：和外界交互</li><li>Scheduler：调度</li><li>Controller：控制，如维持 pods 的期望部署数量和实际部署数量的匹配</li><li>etcd：存储数据</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203122.png" alt="image-20201022152624806"></p><p>Node：</p><ul><li>Pod：具有相同 namespace 的容器的集合就是一个 Pod</li><li>Docker：容器技术的实现</li><li>kubelet：Master 节点控制 Node 节点的桥梁</li><li>kube-proxy：网络控制相关、services 负载均衡</li><li>Fluentd：日志采集、存储、查询</li><li>Optional 的插件：DNS、UI etc</li><li>Image Registry：镜像服务</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203130.png" alt="image-20201022152735696"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203137.png" alt="image-20201022153122051"></p><h1>k8s安装</h1><ul><li><p>从0一步一步手动搭建 k8s 集群的<a href="https://github.com/kelseyhightower/kubernetes-the-hard-way" target="_blank" rel="noopener">步骤</a>，最困难，最容易熟悉 k8s</p></li><li><p>快速创建有一个单节点的集群的 <a href="https://github.com/kubernetes/minikube" target="_blank" rel="noopener">minikube 工具</a></p></li><li><p>方便地安装一个多节点的集群的 <a href="https://github.com/kubernetes/kubeadm" target="_blank" rel="noopener">kubeadm 工具</a></p></li><li><p>使用 coreos 公司的 <a href="https://coreos.com/tectonic/docs/latest/" target="_blank" rel="noopener">tectonic</a> 安装，这个软件也是基于 vagrant 和 virtualbox 的，不过现在 coreos 公司被 RedHat 收购了， tectonic 被移植到 <a href="https://www.openshift.com/try" target="_blank" rel="noopener">OpenShift</a> 上面了</p></li><li><p>在云上安装多节点集群的 <a href="https://github.com/kubernetes/kops" target="_blank" rel="noopener">kops 工具</a></p></li><li><p><a href="https://labs.play-with-k8s.com/" target="_blank" rel="noopener">别人提供的资源供web页面操作</a></p></li></ul><h2 id="minikube-安装"><a class="header-anchor" href="#minikube-安装">¶</a>minikube 安装</h2><p><a href="https://kubernetes.io/docs/tasks/tools/" target="_blank" rel="noopener">官网安装工具页面</a>：</p><ol><li><p>依赖一个虚拟化技术，可以使用 virtual box，先安装 <a href="https://www.virtualbox.org/" target="_blank" rel="noopener">virtual box</a></p></li><li><p>先安装 <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" target="_blank" rel="noopener">kubectl</a> ，注意<a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/#enable-kubectl-autocompletion" target="_blank" rel="noopener">页面的最后</a>有介绍 kubectl 命令的自动补全功能，目前只支持 bash shell 和 zsh shell。</p></li><li><p>安装 <a href="https://minikube.sigs.k8s.io/docs/start/" target="_blank" rel="noopener">minikube</a></p><ul><li>minikube 类似 vagrant 和 docker machine，会依赖虚拟化技术创建一个 VM，然后安装一系列的 docker 和 k8s 的软件，在安装过程中会拉取镜像，官方的 minikube 可能会去拉取一些在 google 服务器中的镜像，会遇到网络问题，这是阿里云提供<a href="https://developer.aliyun.com/article/221687" target="_blank" rel="noopener">的解决方案</a> 。</li></ul></li><li><p>使用 minikube 创建一个 k8s 集群</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">minikube start --registry-mirror=https://8awf7z4n.mirror.aliyuncs.com<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>使用 <code>kubectl</code> 查看集群的上下文(context)信息：</p><p>查看集群详细信息：</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\k8s>kubectl config viewapiVersion: v1clusters:- cluster:    certificate-authority: C:\Users\john\.minikube\ca.crt    server: https://192.168.99.100:8443  name: minikubecontexts:- context:    cluster: minikube    user: minikube  name: minikubecurrent-context: minikubekind: Configpreferences: {}users:- name: minikube  user:    client-certificate: C:\Users\john\.minikube\profiles\minikube\client.crt    client-key: C:\Users\john\.minikube\profiles\minikube\client.key<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>列出所有集群</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\k8s>kubectl config get-contextsCURRENT   NAME       CLUSTER    AUTHINFO   NAMESPACE*         minikube   minikube   minikube<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>查看集群状态：</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\k8s>kubectl cluster-infoKubernetes master is running at https://192.168.99.100:8443KubeDNS is running at https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxyTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>获取集群节点简要信息和详细信息：</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\deployment>kubectl get nodeNAME       STATUS   ROLES    AGE   VERSIONminikube   Ready    master   14h   v1.19.2D:\docker\docker\chapter9\labs\deployment>kubectl get node -o wideNAME       STATUS   ROLES    AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE               KERNEL-VERSION   CONTAINER-RUNTIMEminikube   Ready    master   14h   v1.19.2   192.168.99.100   <none>        Buildroot 2019.02.11   4.19.114         docker://19.3.12<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>通过 <code>minikube ssh</code> 进入集群虚拟机，类似 vagrant</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\k8s>minikube ssh                         _             _            _         _ ( )           ( )  ___ ___  (_)  ___  (_)| |/')  _   _ | |_      __/' _ ` _ `\| |/' _ `\| || , <  ( ) ( )| '_`\  /'__`\| ( ) ( ) || || ( ) || || |\`\ | (_) || |_) )(  ___/(_) (_) (_)(_)(_) (_)(_)(_) (_)`\___/'(_,__/'`\____)$ docker versionClient: Docker Engine - Community Version:           19.03.12 API version:       1.40 Go version:        go1.13.10 Git commit:        48a66213fe Built:             Mon Jun 22 15:42:53 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.12  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.10  Git commit:       48a66213fe  Built:            Mon Jun 22 15:49:35 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.2.13  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683$<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="kubeadm-安装"><a class="header-anchor" href="#kubeadm-安装">¶</a>kubeadm 安装</h2><h3 id="vagrabt-创建-VM"><a class="header-anchor" href="#vagrabt-创建-VM">¶</a>vagrabt 创建 VM</h3><p>分别创建一个 master 节点和两个 node 节点，以下是 vagrant 的 <code>.Vagrantfile</code> 文件：</p><pre class="line-numbers language-language-ruby"><code class="language-language-ruby"># -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.require_version ">= 1.6.0"boxes = [    {        :name => "k8s-master",        :eth1 => "192.168.205.120",        :mem => "2048",        :cpu => "2",        :ssh_port => "2213"    },    {        :name => "k8s-node1",        :eth1 => "192.168.205.11",        :mem => "2048",        :cpu => "1",        :ssh_port => "2214"    },    {        :name => "k8s-node2",        :eth1 => "192.168.205.12",        :mem => "2048",        :cpu => "1",        :ssh_port => "2215"    }]Vagrant.configure(2) do |config|  config.vm.box = "centos/7"  boxes.each do |opts|      config.vm.define opts[:name] do |config|        config.vm.hostname = opts[:name]        config.vm.provider "vmware_fusion" do |v|          v.vmx["memsize"] = opts[:mem]          v.vmx["numvcpus"] = opts[:cpu]        end        config.vm.provider "virtualbox" do |v|          v.customize ["modifyvm", :id, "--memory", opts[:mem]]          v.customize ["modifyvm", :id, "--cpus", opts[:cpu]]        end                config.vm.network :forwarded_port, guest: 22, host: opts[:ssh_port]        config.vm.network :private_network, ip: opts[:eth1]      end  end  config.vm.synced_folder "./labs", "/home/vagrant/labs"  config.vm.provision "shell", privileged: true, path: "./setup.sh"end<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>.Vagrantfile</code> 中指定的 <code>setup.sh</code> 文件</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">#/bin/shsudo yum install wget -ysudo mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupsudo wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.reposudo yum makecache# install some toolssudo yum install -y git vim gcc glibc-static telnet bridge-utils brctl bind-utils# install dockercurl -fsSL get.docker.com -o get-docker.shsh get-docker.sh# start docker service# sudo groupadd dockersudo usermod -aG docker vagrantsudo systemctl start dockerrm -rf get-docker.shsudo suecho root| passwd root --stdinsed "/^PasswordAuthentication no/c PasswordAuthentication yes" /etc/ssh/sshd_config > tmp_filemv tmp_file /etc/ssh/sshd_configrm -f tmp_filesystemctl restart sshdsudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json <<-'EOF'{  "registry-mirrors": ["https://8awf7z4n.mirror.aliyuncs.com"]}EOFsudo systemctl daemon-reloadsudo systemctl restart dockersudo bash -c 'cat <<EOF > /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF'sudo setenforce 0sudo yum install -y kubelet kubeadm kubectlcat <<EOF | sudo tee /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsudo sysctl --systemsudo systemctl stop firewalldsudo systemctl disable firewalldsudo swapoff -asudo systemctl enable docker.servicesudo systemctl enable kubelet.service<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行 vagrant 创建：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">vagrant up<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>运行完成后，分别进入三个 VM，使用以下命令查看是否安装完成</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# which kubelet/usr/bin/kubelet[root@k8s-master ~]# which kubeadm/usr/bin/kubeadm[root@k8s-master ~]# which kubectl/usr/bin/kubectl[root@k8s-master ~]# docker versionClient: Docker Engine - Community Version:           19.03.13 API version:       1.40 Go version:        go1.13.15 Git commit:        4484c46d9d Built:             Wed Sep 16 17:03:45 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.13  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       4484c46d9d  Built:            Wed Sep 16 17:02:21 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.3.7  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="kubeadm-初始化集群"><a class="header-anchor" href="#kubeadm-初始化集群">¶</a>kubeadm 初始化集群</h3><p><code>--pod-network-cidr</code> 指定集群创建的 pod 的网段；<code>--apiserver-advertise-addressv</code> 指定集群公告的地址，也就是当前这台主机作为 master 可以被其它节点以及 API 访问到的地址，所以这个地址要选用和其它节点同网段的网络节点的地址；<code>--v=5</code> 指定打印日志的等级；<code>--image-repository</code> 指定拉取镜像的地址，这里指定阿里云的地址，不然默认会拉谷歌的</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubeadm init --pod-network-cidr 172.100.0.0/16 --apiserver-advertise-address 192.168.205.120 --image-repository='registry.cn-hangzhou.aliyuncs.com/google_containers' --v=5I1023 04:32:50.960205     889 initconfiguration.go:103] detected and using CRI socket: /var/run/dockershim.sockI1023 04:32:51.080327     889 version.go:183] fetching Kubernetes version from URL: https://dl.k8s.io/release/stable-1.txtW1023 04:32:52.697343     889 configset.go:348] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io][init] Using Kubernetes version: v1.19.3[preflight] Running pre-flight checksI1023 04:32:52.697935     889 checks.go:577] validating Kubernetes and kubeadm version... ...Your Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user:  mkdir -p $HOME/.kube  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config  sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:  https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.205.120:6443 --token eaxpot.07q5bn1h6etqawca \    --discovery-token-ca-cert-hash sha256:7445ed26891dd725b679b837cd2752563672c12f671a61d23f8f513efd805877<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]#   mkdir -p $HOME/.kube[root@k8s-master ~]#   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config[root@k8s-master ~]#   sudo chown $(id -u):$(id -g) $HOME/.kube/config[root@k8s-master ~]#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>检查 pods</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl get pod --all-namespacesNAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGEkube-system   coredns-6c76c8bb89-c5dcd             0/1     Pending   0          12mkube-system   coredns-6c76c8bb89-n5hqc             0/1     Pending   0          12mkube-system   etcd-k8s-master                      1/1     Running   0          12mkube-system   kube-apiserver-k8s-master            1/1     Running   0          12mkube-system   kube-controller-manager-k8s-master   1/1     Running   0          12mkube-system   kube-proxy-ctz76                     1/1     Running   0          92skube-system   kube-proxy-qbjjx                     1/1     Running   0          12mkube-system   kube-scheduler-k8s-master            1/1     Running   0          12m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>安装网络插件</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="加入-node-节点"><a class="header-anchor" href="#加入-node-节点">¶</a>加入 node 节点</h3><p>在 node 节点上运行以下命令加入集群：</p><ul><li><p>node1</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-node1 ~]# kubeadm join 192.168.205.120:6443 --token eaxpot.07q5bn1h6etqawca \>     --discovery-token-ca-cert-hash sha256:7445ed26891dd725b679b837cd2752563672c12f671a61d23f8f513efd805877[preflight] Running pre-flight checks[WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Starting the kubelet[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...This node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details.Run 'kubectl get nodes' on the control-plane to see this node join the cluster.[root@k8s-node1 ~]#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>node2</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-node2 ~]# kubeadm join 192.168.205.120:6443 --token eaxpot.07q5bn1h6etqawca \>     --discovery-token-ca-cert-hash sha256:7445ed26891dd725b679b837cd2752563672c12f671a61d23f8f513efd805877[preflight] Running pre-flight checks[WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Starting the kubelet[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...This node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details.Run 'kubectl get nodes' on the control-plane to see this node join the cluster.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><p>回到 master 节点查看集群节点状态：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl get nodesNAME         STATUS     ROLES    AGE     VERSIONk8s-master   Ready      master   16m     v1.19.3k8s-node1    Ready      <none>   5m10s   v1.19.3k8s-node2    NotReady   <none>   20s     v1.19.3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="其它参考安装"><a class="header-anchor" href="#其它参考安装">¶</a><a href="https://gist.github.com/islishude/231659cec0305ace090b933ce851994a" target="_blank" rel="noopener">其它参考安装</a></h2><blockquote><p>注意以下命令，需要切换到 root 后运行</p></blockquote><h3 id="安装-docker"><a class="header-anchor" href="#安装-docker">¶</a>安装 docker</h3><p>首先确定已经安装完成 docker，如果没有安装可以使用以下脚本快速安装并配置：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">curl -fsSL https://get.docker.com | sudo sh -s -- --mirror Aliyunsudo usermod -aG docker $USERsudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json <<-'EOF'{  "exec-opts": ["native.cgroupdriver=systemd"],  "log-driver": "json-file",  "log-opts": {    "max-size": "100m"  },  "storage-driver": "overlay2",  "registry-mirrors": ["https://t9ab0rkd.mirror.aliyuncs.com"]}EOFsudo systemctl daemon-reloadsudo systemctl restart docker<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="kubeadm"><a class="header-anchor" href="#kubeadm">¶</a>kubeadm</h3><h4 id="安装-k8s-套件"><a class="header-anchor" href="#安装-k8s-套件">¶</a>安装 k8s 套件</h4><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 添加并信任APT证书curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add -# 添加源地址add-apt-repository "deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main"# 更新源并安装最新版 kubenetessudo apt update && apt install -y kubelet kubeadm kubectl# 添加 completion，最好放入 .bashrc 中source <(kubectl completion bash)source <(kubeadm completion bash)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="关闭-swap"><a class="header-anchor" href="#关闭-swap">¶</a>关闭 swap</h4><p>为了性能考虑，k8s 需要关闭 swap 功能，然后重启主机。</p><p>在 <code>/etc/fstab</code> 中找到带有 <code>swap</code> 的那一行，注释掉。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ vim /etc/fstab# UUID=9224d95f-cd87-4b56-b249-3dc7de4491d3 none            swap    sw              0       0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="启动-master-节点："><a class="header-anchor" href="#启动-master-节点：">¶</a>启动 master 节点：</h4><pre class="line-numbers language-language-shell"><code class="language-language-shell">kubeadm init --image-repository='registry.cn-hangzhou.aliyuncs.com/google_containers'<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>--image-repository</code> 指定控制平面容器镜像地址，这里使用aliyun镜像，而不是默认的 <a href="http://k8s.gcr.io" target="_blank" rel="noopener">k8s.gcr.io</a>，这样就能避免下载失败。</p><p>如果 init 失败，检查是否关闭 swap、 用户是否为 root 以及是否下载好核心组件镜像（可能得网络的问题）、是否为至少 2G 内存，然后运行 <code>kubeadm reset</code> 接着再 <code>kubeadm init</code>。</p><h4 id="配置读取路径"><a class="header-anchor" href="#配置读取路径">¶</a>配置读取路径</h4><pre class="line-numbers language-language-shell"><code class="language-language-shell"># append to .bashrcexport KUBECONFIG=/etc/kubernetes/admin.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="安装网络插件"><a class="header-anchor" href="#安装网络插件">¶</a>安装网络插件</h4><pre class="line-numbers language-language-shell"><code class="language-language-shell">kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="加入-worker"><a class="header-anchor" href="#加入-worker">¶</a>加入 worker</h4><p>worker 节点加入 master，使用 kubeadm init 最后提示的命令在 worker 上运行</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">kubeadm join 192.168.199.117:6443 --token y8l6qv.oj2hxua9szguei23 \--discovery-token-ca-cert-hash sha256:bae71d8fb4a26c5f29a6df2db037e08e581fcb344ff85089a603e3eeb9d6d26f<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>其中 <code>--token</code> 是临时的生成，可以通过下面命令获取</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ kubeadm token listTOKEN                     TTL       EXPIRES                     USAGES                   DESCRIPTION                                                EXTRA GROUPSy8l6qv.oj2hxua9szguei23   23h      2019-09-09T12:04:27+08:00   authentication,signing   The default bootstrap token generated by 'kubeadm init'.   system:bootstrappers:kubeadm:default-node-token<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>而 <code>--discovery-token-ca-cert-hash</code> 指的是 CA 证书的哈希值，那么可以使用这种方式获取：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | sha256sum | awk '{print $1}'3e77f845edf944d76234a6d78dde3e5bae3e50261362b1d8cc8d025ac97136b0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="查看-nodes"><a class="header-anchor" href="#查看-nodes">¶</a>查看 nodes</h4><p>在 master 节点上运行</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">kubectl get nodes<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="minikube"><a class="header-anchor" href="#minikube">¶</a>minikube</h3><h4 id="国内源"><a class="header-anchor" href="#国内源">¶</a>国内源</h4><p>在<a href="https://minikube.sigs.k8s.io/docs/start/" target="_blank" rel="noopener">minikube</a>文档页面，选择操作系统，然后下载 minikube，注意版本号。</p><p>在<a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" target="_blank" rel="noopener">k8s-kubectl</a>页面下载 kubectl 并放在$PATH下，注意版本号。</p><p>下载安装 virtualbox。</p><p>启动命令：</p><pre><code>minikube start \--vm-driver=virtualbox \--image-mirror-country=cn \--registry-mirror='https://t9ab0rkd.mirror.aliyuncs.com' \--image-repository='registry.cn-hangzhou.aliyuncs.com/google_containers' \--iso-url='https://kubernetes.oss-cn-hangzhou.aliyuncs.com/minikube/iso/minikube-v1.5.1.iso'</code></pre><p>–image-mirror-country cn 将缺省利用 <a href="http://registry.cn-hangzhou.aliyuncs.com/google_containers" target="_blank" rel="noopener">registry.cn-hangzhou.aliyuncs.com/google_containers</a> 作为安装Kubernetes的容器镜像仓库， --iso-url= 利用阿里云的镜像地址下载相应的 .iso 文件 --cpus=2: 为minikube虚拟机分配CPU核数 --memory=2000mb: 为minikube虚拟机分配内存数 --kubernetes-version= : minikube 虚拟机将使用的 kubernetes 版本</p><h4 id="官方源"><a class="header-anchor" href="#官方源">¶</a>官方源</h4><pre><code># k8scurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key addapt-add-repository &quot;deb http://apt.kubernetes.io/ kubernetes-xenial main&quot;# dockercurl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;# apt安装apt-get update &amp;&amp; apt-get install docker-ce kubeadmcat &gt; /etc/docker/daemon.json &lt;&lt;EOF{  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],  &quot;log-driver&quot;: &quot;json-file&quot;,  &quot;log-opts&quot;: {    &quot;max-size&quot;: &quot;100m&quot;  },  &quot;storage-driver&quot;: &quot;overlay2&quot;}EOFmkdir -p /etc/systemd/system/docker.service.dsystemctl daemon-reloadsystemctl restart docker</code></pre><h3 id="其它阅读参考"><a class="header-anchor" href="#其它阅读参考">¶</a>其它阅读参考</h3><p><a href="https://juejin.im/post/6844903668269973511" target="_blank" rel="noopener">https://juejin.im/post/6844903668269973511</a></p><p><a href="https://cloud.tencent.com/developer/article/1525487" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1525487</a></p><h2 id="配置-kubectl-操作多个-k8s-集群"><a class="header-anchor" href="#配置-kubectl-操作多个-k8s-集群">¶</a>配置 kubectl 操作多个 k8s 集群</h2><p>参考 <a href="https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/" target="_blank" rel="noopener">官方说明</a> 。</p><p>可以看到 kubectl 主要通过类似以下格式的文件读取 k8s 集群的联系信息的：</p><pre class="line-numbers language-language-yaml"><code class="language-language-yaml">contexts:- context:    cluster: development    namespace: frontend    user: developer  name: dev-frontend- context:    cluster: development    namespace: ramp    user: developer  name: dev-ramp-up- context:    cluster: development    namespace: storage    user: developer  name: dev-storage- context:    cluster: scratch    namespace: default    user: experimenter  name: exp-scratch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p>使用 minikube 和 kubeadm 安装集群之后，分别会在 minikube 所在主机以及 kubeadm 所在主机的当前用户 <code>$HOME</code> 下创建 <code>.kube/config</code> 文件，这个就是默认创建给 kubectl 读取的文件，里面包含了集群的连接信息。也就是说 kubectl 默认是会读取这个路径文件的</p></li><li><p>另外我们可以通过指定环境变量 <code>KUBECONFIG</code> 来修改它的默认行为，将集群配置文件所在目录指定给这个环境变量，如果是多个配置文件，在 linux 和 macos 下用冒号隔开，在 windows 下用分号隔开。</p></li><li><p>同时还可以通过 <code>kubectl config</code> 命令设置的方式生成该配置文件。</p></li></ul><p>在经过以上步骤使得 kubectl 可以读取多个集群信息后，通过 <code>kubectl config use-context &lt;context-name&gt;</code> 即可在多个集群的不同上下文之间进行上下文切换。</p><h1>Node</h1><p>每个 cluster 下面有多个 context ，一个 context 可能会涉及多个 Node，一个 Node 就是一个物理主机或者虚机。kubectl 切换到一个 context 之后，可以查看它涉及的节点：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl get nodeNAME         STATUS     ROLES    AGE   VERSIONk8s-master   Ready      master   9h    v1.19.3k8s-node1    NotReady   <none>   9h    v1.19.3k8s-node2    NotReady   <none>   9h    v1.19.3[root@k8s-master ~]# kubectl get node -o wideNAME         STATUS     ROLES    AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION           CONTAINER-RUNTIMEk8s-master   Ready      master   20h   v1.19.3   10.0.2.15     <none>        CentOS Linux 7 (Core)   3.10.0-1127.el7.x86_64   docker://19.3.13k8s-node1    NotReady   <none>   20h   v1.19.3   10.0.2.15     <none>        CentOS Linux 7 (Core)   3.10.0-1127.el7.x86_64   docker://19.3.13k8s-node2    NotReady   <none>   20h   v1.19.3   10.0.2.15     <none>        CentOS Linux 7 (Core)   3.10.0-1127.el7.x86_64   docker://19.3.13<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过 <code>kubectl get node -o yaml</code> 以 yaml 格式输出更多信息（也支持 json 格式输出这些信息，<code>-o json</code>）：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl get node -o yamlapiVersion: v1items:- apiVersion: v1  kind: Node  metadata:    annotations:      kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock      node.alpha.kubernetes.io/ttl: "0"      volumes.kubernetes.io/controller-managed-attach-detach: "true"    creationTimestamp: "2020-10-23T04:33:49Z"    labels:      beta.kubernetes.io/arch: amd64      beta.kubernetes.io/os: linux      kubernetes.io/arch: amd64      kubernetes.io/hostname: k8s-master      kubernetes.io/os: linux      node-role.kubernetes.io/master: ""    managedFields:    - apiVersion: v1      fieldsType: FieldsV1      fieldsV1:        f:metadata:          f:annotations:            f:kubeadm.alpha.kubernetes.io/cri-socket: {}          f:labels:            f:node-role.kubernetes.io/master: {}      manager: kubeadm      operation: Update      time: "2020-10-23T04:33:52Z"    - apiVersion: v1      fieldsType: FieldsV1      fieldsV1:        f:metadata:          f:annotations:            f:node.alpha.kubernetes.io/ttl: {}          f:labels:            f:beta.kubernetes.io/arch: {}            f:beta.kubernetes.io/os: {}        f:spec:          f:podCIDR: {}          f:podCIDRs:            .: {}            v:"172.100.0.0/24": {}          f:taints: {}      manager: kube-controller-manager      operation: Update      time: "2020-10-23T04:48:39Z"    - apiVersion: v1      fieldsType: FieldsV1      fieldsV1:        f:status:          f:conditions:            k:{"type":"NetworkUnavailable"}:              .: {}              f:lastHeartbeatTime: {}              f:lastTransitionTime: {}              f:message: {}              f:reason: {}              f:status: {}              f:type: {}      manager: kube-utils      operation: Update      time: "2020-10-23T14:12:48Z"    - apiVersion: v1      fieldsType: FieldsV1      fieldsV1:        f:metadata:          f:annotations:            .: {}            f:volumes.kubernetes.io/controller-managed-attach-detach: {}          f:labels:            .: {}            f:kubernetes.io/arch: {}            f:kubernetes.io/hostname: {}            f:kubernetes.io/os: {}        f:status:          f:addresses:            .: {}            k:{"type":"Hostname"}:              .: {}              f:address: {}              f:type: {}            k:{"type":"InternalIP"}:              .: {}              f:address: {}              f:type: {}          f:allocatable:            .: {}            f:cpu: {}            f:ephemeral-storage: {}            f:hugepages-2Mi: {}            f:memory: {}            f:pods: {}          f:capacity:            .: {}            f:cpu: {}            f:ephemeral-storage: {}... ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过 <code>kubectl describe node &lt;node-name&gt;</code> 查看详细信息：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl describe node k8s-masterName:               k8s-masterRoles:              masterLabels:             beta.kubernetes.io/arch=amd64                    beta.kubernetes.io/os=linux                    kubernetes.io/arch=amd64                    kubernetes.io/hostname=k8s-master                    kubernetes.io/os=linux                    node-role.kubernetes.io/master=Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock                    node.alpha.kubernetes.io/ttl: 0                    volumes.kubernetes.io/controller-managed-attach-detach: trueCreationTimestamp:  Fri, 23 Oct 2020 04:33:49 +0000Taints:             node-role.kubernetes.io/master:NoScheduleUnschedulable:      falseLease:  HolderIdentity:  k8s-master  AcquireTime:     <unset>  RenewTime:       Sat, 24 Oct 2020 00:58:28 +0000Conditions:  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message  ----                 ------  -----------------                 ------------------                ------                       -------  NetworkUnavailable   False   Fri, 23 Oct 2020 14:12:48 +0000   Fri, 23 Oct 2020 14:12:48 +0000   WeaveIsUp                    Weave pod has set this  MemoryPressure       False   Sat, 24 Oct 2020 00:55:03 +0000   Fri, 23 Oct 2020 04:33:40 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available  DiskPressure         False   Sat, 24 Oct 2020 00:55:03 +0000   Fri, 23 Oct 2020 04:33:40 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure  PIDPressure          False   Sat, 24 Oct 2020 00:55:03 +0000   Fri, 23 Oct 2020 04:33:40 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available  Ready                True    Sat, 24 Oct 2020 00:55:03 +0000   Fri, 23 Oct 2020 04:48:39 +0000   KubeletReady                 kubelet is posting ready statusAddresses:  InternalIP:  10.0.2.15  Hostname:    k8s-masterCapacity:  cpu:                2  ephemeral-storage:  41921540Ki  hugepages-2Mi:      0  memory:             1881936Ki  pods:               110Allocatable:  cpu:                2  ephemeral-storage:  38634891201  hugepages-2Mi:      0  memory:             1779536Ki  pods:               110System Info:  Machine ID:                 db0b07db41e673489398574c36ad7aa0  System UUID:                DB0B07DB-41E6-7348-9398-574C36AD7AA0  Boot ID:                    814e4cf8-5526-42fd-ae20-1afe15ee387f  Kernel Version:             3.10.0-1127.el7.x86_64  OS Image:                   CentOS Linux 7 (Core)  Operating System:           linux  Architecture:               amd64  Container Runtime Version:  docker://19.3.13  Kubelet Version:            v1.19.3  Kube-Proxy Version:         v1.19.3PodCIDR:                      172.100.0.0/24PodCIDRs:                     172.100.0.0/24Non-terminated Pods:          (8 in total)  Namespace                   Name                                  CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE  ---------                   ----                                  ------------  ----------  ---------------  -------------  ---  kube-system                 coredns-6c76c8bb89-c5dcd              100m (5%)     0 (0%)      70Mi (4%)        170Mi (9%)     20h  kube-system                 coredns-6c76c8bb89-n5hqc              100m (5%)     0 (0%)      70Mi (4%)        170Mi (9%)     20h  kube-system                 etcd-k8s-master                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         20h  kube-system                 kube-apiserver-k8s-master             250m (12%)    0 (0%)      0 (0%)           0 (0%)         20h  kube-system                 kube-controller-manager-k8s-master    200m (10%)    0 (0%)      0 (0%)           0 (0%)         20h  kube-system                 kube-proxy-qbjjx                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         20h  kube-system                 kube-scheduler-k8s-master             100m (5%)     0 (0%)      0 (0%)           0 (0%)         20h  kube-system                 weave-net-k777j                       100m (5%)     0 (0%)      200Mi (11%)      0 (0%)         20hAllocated resources:  (Total limits may be over 100 percent, i.e., overcommitted.)  Resource           Requests     Limits  --------           --------     ------  cpu                850m (42%)   0 (0%)  memory             340Mi (19%)  340Mi (19%)  ephemeral-storage  0 (0%)       0 (0%)  hugepages-2Mi      0 (0%)       0 (0%)Events:              <none>[root@k8s-master ~]# kubectl describe node k8s-masterName:               k8s-masterRoles:              masterLabels:             beta.kubernetes.io/arch=amd64                    beta.kubernetes.io/os=linux                    kubernetes.io/arch=amd64                    kubernetes.io/hostname=k8s-master                    kubernetes.io/os=linux                    node-role.kubernetes.io/master=Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock                    node.alpha.kubernetes.io/ttl: 0                    volumes.kubernetes.io/controller-managed-attach-detach: trueCreationTimestamp:  Fri, 23 Oct 2020 04:33:49 +0000Taints:             node-role.kubernetes.io/master:NoScheduleUnschedulable:      falseLease:  HolderIdentity:  k8s-master  AcquireTime:     <unset>  RenewTime:       Sat, 24 Oct 2020 00:58:28 +0000Conditions:  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message  ----                 ------  -----------------                 ------------------                ------                       -------  NetworkUnavailable   False   Fri, 23 Oct 2020 14:12:48 +0000   Fri, 23 Oct 2020 14:12:48 +0000   WeaveIsUp                    Weave pod has set this  MemoryPressure       False   Sat, 24 Oct 2020 00:55:03 +0000   Fri, 23 Oct 2020 04:33:40 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available  DiskPressure         False   Sat, 24 Oct 2020 00:55:03 +0000   Fri, 23 Oct 2020 04:33:40 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure  PIDPressure          False   Sat, 24 Oct 2020 00:55:03 +0000   Fri, 23 Oct 2020 04:33:40 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available  Ready                True    Sat, 24 Oct 2020 00:55:03 +0000   Fri, 23 Oct 2020 04:48:39 +0000   KubeletReady                 kubelet is posting ready statusAddresses:  InternalIP:  10.0.2.15  Hostname:    k8s-masterCapacity:  cpu:                2  ephemeral-storage:  41921540Ki  hugepages-2Mi:      0  memory:             1881936Ki  pods:               110Allocatable:  cpu:                2  ephemeral-storage:  38634891201  hugepages-2Mi:      0  memory:             1779536Ki  pods:               110System Info:  Machine ID:                 db0b07db41e673489398574c36ad7aa0  System UUID:                DB0B07DB-41E6-7348-9398-574C36AD7AA0  Boot ID:                    814e4cf8-5526-42fd-ae20-1afe15ee387f  Kernel Version:             3.10.0-1127.el7.x86_64  OS Image:                   CentOS Linux 7 (Core)  Operating System:           linux  Architecture:               amd64  Container Runtime Version:  docker://19.3.13  Kubelet Version:            v1.19.3  Kube-Proxy Version:         v1.19.3PodCIDR:                      172.100.0.0/24PodCIDRs:                     172.100.0.0/24Non-terminated Pods:          (8 in total)  Namespace                   Name                                  CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE  ---------                   ----                                  ------------  ----------  ---------------  -------------  ---  kube-system                 coredns-6c76c8bb89-c5dcd              100m (5%)     0 (0%)      70Mi (4%)        170Mi (9%)     20h  kube-system                 coredns-6c76c8bb89-n5hqc              100m (5%)     0 (0%)      70Mi (4%)        170Mi (9%)     20h  kube-system                 etcd-k8s-master                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         20h  kube-system                 kube-apiserver-k8s-master             250m (12%)    0 (0%)      0 (0%)           0 (0%)         20h  kube-system                 kube-controller-manager-k8s-master    200m (10%)    0 (0%)      0 (0%)           0 (0%)         20h  kube-system                 kube-proxy-qbjjx                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         20h  kube-system                 kube-scheduler-k8s-master             100m (5%)     0 (0%)      0 (0%)           0 (0%)         20h  kube-system                 weave-net-k777j                       100m (5%)     0 (0%)      200Mi (11%)      0 (0%)         20hAllocated resources:  (Total limits may be over 100 percent, i.e., overcommitted.)  Resource           Requests     Limits  --------           --------     ------  cpu                850m (42%)   0 (0%)  memory             340Mi (19%)  340Mi (19%)  ephemeral-storage  0 (0%)       0 (0%)  hugepages-2Mi      0 (0%)       0 (0%)Events:              <none><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Labels"><a class="header-anchor" href="#Labels">¶</a>Labels</h3><p>在上面的 <code>describe</code> 命令中可以看到 node 的 Labels 属性：</p><pre><code>Labels:             beta.kubernetes.io/arch=amd64                    beta.kubernetes.io/os=linux                    kubernetes.io/arch=amd64                    kubernetes.io/hostname=k8s-master                    kubernetes.io/os=linux                    node-role.kubernetes.io/master=</code></pre><p>Labels 以键值对的形式存在，可以利用这些 Labels 做过滤条件，<code>kubectl get node --show-labels</code> 可以获取 lables</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl get node --show-labelsNAME         STATUS     ROLES    AGE   VERSION   LABELSk8s-master   Ready      master   20h   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master,kubernetes.io/os=linux,node-role.kubernetes.io/master=k8s-node1    NotReady   <none>   20h   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node1,kubernetes.io/os=linuxk8s-node2    NotReady   <none>   20h   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node2,kubernetes.io/os=linux<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>添加 label、删除 label</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl label node k8s-master.bash_history    .bash_logout     .bash_profile    .bashrc          .cshrc           .kube/           .pki/            .tcshrc          .viminfo         anaconda-ks.cfg  original-ks.cfg[root@k8s-master ~]# kubectl label node k8s-master env=testnode/k8s-master labeled[root@k8s-master ~]# kubectl get node --show-labelsNAME         STATUS     ROLES    AGE   VERSION   LABELSk8s-master   Ready      master   20h   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,env=test,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master,kubernetes.io/os=linux,node-role.kubernetes.io/master=k8s-node1    NotReady   <none>   20h   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node1,kubernetes.io/os=linuxk8s-node2    NotReady   <none>   20h   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node2,kubernetes.io/os=linux[root@k8s-master ~]# kubectl label node k8s-master env-node/k8s-master labeled[root@k8s-master ~]# kubectl get node --show-labelsNAME         STATUS     ROLES    AGE   VERSION   LABELSk8s-master   Ready      master   20h   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master,kubernetes.io/os=linux,node-role.kubernetes.io/master=k8s-node1    NotReady   <none>   20h   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node1,kubernetes.io/os=linuxk8s-node2    NotReady   <none>   20h   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node2,kubernetes.io/os=linux[root@k8s-master ~]#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="node-role"><a class="header-anchor" href="#node-role">¶</a>node-role</h3><p>ROLES 是一个特殊的 label “<a href="http://node-role.kubernetes.io" target="_blank" rel="noopener">node-role.kubernetes.io</a>”。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl get node --show-labelsNAME         STATUS     ROLES    AGE   VERSION   LABELSk8s-master   Ready      master   20h   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master,kubernetes.io/os=linux,node-role.kubernetes.io/master=k8s-node1    NotReady   <none>   20h   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node1,kubernetes.io/os=linuxk8s-node2    NotReady   <none>   20h   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node2,kubernetes.io/os=linux[root@k8s-master ~]# kubectl label node k8s-node1 node-role.kubernetes.io/worker=node/k8s-node1 labeled[root@k8s-master ~]# kubectl label node k8s-node2 node-role.kubernetes.io/worker=node/k8s-node2 labeled[root@k8s-master ~]# kubectl get nodeNAME         STATUS     ROLES    AGE   VERSIONk8s-master   Ready      master   20h   v1.19.3k8s-node1    NotReady   worker   20h   v1.19.3k8s-node2    NotReady   worker   20h   v1.19.3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1>调度的最小单位：Pod</h1><p>一个 Pod 里面一个或者多个 Container，一个 Pod 只有一个 namespace，所有 Container 共享这个 namespace 。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203203.png" alt="image-20201022191526685"></p><h3 id="创建-pod"><a class="header-anchor" href="#创建-pod">¶</a>创建 pod</h3><p>下面是一个 k8s 格式的 yml 文件，通过这个文件可以创建一个资源</p><pre class="line-numbers language-language-yaml"><code class="language-language-yaml">apiVersion: v1kind: Pod # 资源类型是 podmetadata:  name: nginx  labels:    app: nginxspec:  containers: # 可以包含多个容器  - name: nginx # 命名    image: nginx # 镜像    ports: # 容器暴露的端口    - containerPort: 80<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用 <code>kubectl create</code> 命令创建资源，根据 <code>-f</code> 指定的文件里面的指定资源类型按需创建，使用 <code>kubectl get pods</code> 命令查看 pods 的状态，显示正在创建中：</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\pod-basic>kubectl create -f pod_nginx.ymlpod/nginx createdD:\docker\docker\chapter9\labs\pod-basic>kubectl get podsNAME    READY   STATUS              RESTARTS   AGEnginx   0/1     ContainerCreating   0          13s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>过一会儿，创建完成</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\pod-basic>kubectl get podsNAME    READY   STATUS    RESTARTS   AGEnginx   1/1     Running   0          10m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>查看更详细的信息，可以看到名为 nginx 的 pod 的 ip 地址 “172.17.0.2” 和所在的主机节点 “minikube”</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\pod-basic>kubectl get pods -o wideNAME    READY   STATUS    RESTARTS   AGE   IP           NODE       NOMINATED NODE   READINESS GATESnginx   1/1     Running   0          12m   172.17.0.2   minikube   <none>           <none><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="进入容器的两种方式"><a class="header-anchor" href="#进入容器的两种方式">¶</a>进入容器的两种方式</h3><ul><li><p><code>minikube ssh</code> 进入 minikube 主机进行操作：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">D:\docker\docker\chapter9\labs\pod-basic>minikube ssh                         _             _            _         _ ( )           ( )  ___ ___  (_)  ___  (_)| |/')  _   _ | |_      __/' _ ` _ `\| |/' _ `\| || , <  ( ) ( )| '_`\  /'__`\| ( ) ( ) || || ( ) || || |\`\ | (_) || |_) )(  ___/(_) (_) (_)(_)(_) (_)(_)(_) (_)`\___/'(_,__/'`\____)                         _             _            _         _ ( )           ( )  ___ ___  (_)  ___  (_)| |/')  _   _ | |_      __/' _ ` _ `\| |/' _ `\| || , <  ( ) ( )| '_`\  /'__`\| ( ) ( ) || || ( ) || || |\`\ | (_) || |_) )(  ___/(_) (_) (_)(_)(_) (_)(_)(_) (_)`\___/'(_,__/'`\____)$ docker ps | grep nginx # 查看 nginx 容器的 id701409f023de        nginx                  "/docker-entrypoint.…"   7 minutes ago       Up 7 minutes                            k8s_nginx_nginx_default_d94d0dba-f5c4-42a6-ac43-ac58d1f9afe0_0$ docker exec -it 701409f023de sh # 这样就进来了# exit<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过 inspect 查看容器的 ip 得到 “172.17.0.2/16”，正是上面 <code>kubectl get pods -o wide</code> 得到的 ip：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ docker network lsNETWORK ID          NAME                DRIVER              SCOPEf557efad83b5        bridge              bridge              local532631c87d8b        host                host                local66c4b8c8efa3        none                null                local$ docker network inspect f557efad83b5[    {        "Name": "bridge",        "Id": "f557efad83b5947aa44cbe3989e93ded56da77ecddc42e98f3d469dea389c2a0",        "Created": "2020-10-22T09:00:27.247244957Z",        "Scope": "local",        "Driver": "bridge",        "EnableIPv6": false,        "IPAM": {            "Driver": "default",            "Options": null,            "Config": [                {                    "Subnet": "172.17.0.0/16",                    "Gateway": "172.17.0.1"                }            ]        },        "Internal": false,        "Attachable": false,        "Ingress": false,        "ConfigFrom": {            "Network": ""        },        "ConfigOnly": false,        "Containers": {            "03a004aa1e27244812acedddb03dcbc471ff19472a05c53b292897cbaa704963": {                "Name": "k8s_POD_nginx_default_d94d0dba-f5c4-42a6-ac43-ac58d1f9afe0_1",                "EndpointID": "d5a75a4f94133680a249472e9389c7cb92108262ef9b13e4be0ee13c77bf14ec",                "MacAddress": "02:42:ac:11:00:02",                "IPv4Address": "172.17.0.2/16",                "IPv6Address": ""            },            "05839cdb2c6b26ca0865bed8cbbcdff77a2056d6972d25627e3b11b0a13e071e": {                "Name": "k8s_POD_coredns-f9fd979d6-gsjlm_kube-system_c2971377-7640-4c2d-bf5b-bbb3a2c4fa41_2",                "EndpointID": "0a8539bd0e679a9cc7fc1eef47c3c393031a3a042503d75bbce6ce27600e7c9a",                "MacAddress": "02:42:ac:11:00:03",                "IPv4Address": "172.17.0.3/16",                "IPv6Address": ""            }        },        "Options": {            "com.docker.network.bridge.default_bridge": "true",            "com.docker.network.bridge.enable_icc": "true",            "com.docker.network.bridge.enable_ip_masquerade": "true",            "com.docker.network.bridge.host_binding_ipv4": "0.0.0.0",            "com.docker.network.bridge.name": "docker0",            "com.docker.network.driver.mtu": "1500"        },        "Labels": {}    }]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>直接使用 <code>kubectl exec -it</code> 进入容器</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">D:\docker\docker\chapter9\labs\pod-basic>kubectl exec -it nginx -- sh#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>通过 <code>-c=&lt;Container namme&gt;</code> 指定要进入的 pod 的容器，如果不指定，默认进入第一个容器</p></li></ul><h3 id="查看-pod-的更详细信息"><a class="header-anchor" href="#查看-pod-的更详细信息">¶</a>查看 pod 的更详细信息</h3><p>通过 <code>kubectl describe</code> 命令查看</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">D:\docker\docker\chapter9\labs\pod-basic>kubectl describe pods nginxName:         nginxNamespace:    defaultPriority:     0Node:         minikube/192.168.99.100Start Time:   Thu, 22 Oct 2020 19:22:57 +0800Labels:       app=nginxAnnotations:  <none>Status:       RunningIP:           172.17.0.2IPs:  IP:  172.17.0.2Containers:  nginx:    Container ID:   docker://701409f023de62e508b79b1cd95a70e2ce96cc8e4ab084c4cc4f5cc0fe82ca98    Image:          nginx    Image ID:       docker-pullable://nginx@sha256:ed7f815851b5299f616220a63edac69a4cc200e7f536a56e421988da82e44ed8    Port:           80/TCP    Host Port:      0/TCP    State:          Running      Started:      Thu, 22 Oct 2020 19:30:47 +0800    Ready:          True    Restart Count:  0    Environment:    <none>    Mounts:      /var/run/secrets/kubernetes.io/serviceaccount from default-token-fc5qj (ro)Conditions:  Type              Status  Initialized       True  Ready             True  ContainersReady   True  PodScheduled      TrueVolumes:  default-token-fc5qj:    Type:        Secret (a volume populated by a Secret)    SecretName:  default-token-fc5qj    Optional:    falseQoS Class:       BestEffortNode-Selectors:  <none>Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300sEvents:  Type     Reason          Age                From               Message  ----     ------          ----               ----               -------  Normal   Scheduled       24m                default-scheduler  Successfully assigned default/nginx to minikube  Warning  Failed          17m                kubelet, minikube  Failed to pull image "nginx": rpc error: code = Unknown desc = unexpected EOF  Warning  Failed          17m                kubelet, minikube  Error: ErrImagePull  Normal   SandboxChanged  17m                kubelet, minikube  Pod sandbox changed, it will be killed and re-created.  Normal   BackOff         17m (x3 over 17m)  kubelet, minikube  Back-off pulling image "nginx"  Warning  Failed          17m (x3 over 17m)  kubelet, minikube  Error: ImagePullBackOff  Normal   Pulling         17m (x2 over 24m)  kubelet, minikube  Pulling image "nginx"  Normal   Pulled          17m                kubelet, minikube  Successfully pulled image "nginx" in 8.817994182s  Normal   Created         17m                kubelet, minikube  Created container nginx  Normal   Started         17m                kubelet, minikube  Started container nginx<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="端口映射"><a class="header-anchor" href="#端口映射">¶</a>端口映射</h3><p>在 minikube 内部可以根据 nginx 容器的 ip 地址进行访问的</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">D:\docker\docker\chapter9\labs\pod-basic>minikube ssh                         _             _            _         _ ( )           ( )  ___ ___  (_)  ___  (_)| |/')  _   _ | |_      __/' _ ` _ `\| |/' _ `\| || , <  ( ) ( )| '_`\  /'__`\| ( ) ( ) || || ( ) || || |\`\ | (_) || |_) )(  ___/(_) (_) (_)(_)(_) (_)(_)(_) (_)`\___/'(_,__/'`\____)$ ping 172.17.0.2PING 172.17.0.2 (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.242 ms64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.088 ms^C--- 172.17.0.2 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.088/0.165/0.242 ms$ curl 172.17.0.2<!DOCTYPE html><html><head><title>Welcome to nginx!</title><style>    body {        width: 35em;        margin: 0 auto;        font-family: Tahoma, Verdana, Arial, sans-serif;    }</style></head><body><h1>Welcome to nginx!</h1><p>If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.</p><p>For online documentation and support please refer to<a href="http://nginx.org/">nginx.org</a>.<br/>Commercial support is available at<a href="http://nginx.com/">nginx.com</a>.</p><p><em>Thank you for using nginx.</em></p></body></html>$<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面我们要实现在 minikube 外面访问这个容器没，先查看 minikube  的 ip ，kuku 可以在外面访问</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ ip a | grep inet    inet 127.0.0.1/8 scope host lo    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0    inet 192.168.99.100/24 brd 192.168.99.255 scope global dynamic eth1    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0$ exitlogoutssh: exit status 127D:\docker\docker\chapter9\labs\pod-basic>ping 192.168.99.100正在 Ping 192.168.99.100 具有 32 字节的数据:来自 192.168.99.100 的回复: 字节=32 时间<1ms TTL=64来自 192.168.99.100 的回复: 字节=32 时间<1ms TTL=64192.168.99.100 的 Ping 统计信息:    数据包: 已发送 = 2，已接收 = 2，丢失 = 0 (0% 丢失)，往返行程的估计时间(以毫秒为单位):    最短 = 0ms，最长 = 0ms，平均 = 0msControl-C^C<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过 <code>kubectl port-forward &lt;pod-name&gt; &lt;local-port&gt;:&lt;container-port&gt;</code> 命令可以对指定 pod 做端口映射，下面命令将 nginx 的80 端口映射到 <code>kubectl</code> 所在主机(<strong>不是 minikube 主机</strong>)的 8080 端口：</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\pod-basic>kubectl port-forward nginx 8080:80Forwarding from 127.0.0.1:8080 -> 80Forwarding from [::1]:8080 -> 80<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>此时在 <code>kubectl</code> 所在主机访问 “127.0.0.1:8080” 就可以访问到 nginx 了：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203214.png" alt="image-20201022201832158"></p><p>可以看到这种映射方式会导致当前终端阻塞，如果中断阻塞，就会导致映射结束。</p><h3 id="删除-pod"><a class="header-anchor" href="#删除-pod">¶</a>删除 pod</h3><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\pod-basic>kubectl delete -f pod_nginx.ymlpod "nginx" deletedD:\docker\docker\chapter9\labs\pod-basic>kubectl get podsNo resources found in default namespace.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="pod-横向扩展"><a class="header-anchor" href="#pod-横向扩展">¶</a>pod 横向扩展</h3><h4 id="ReplicationController"><a class="header-anchor" href="#ReplicationController">¶</a>ReplicationController</h4><p>以下是一个类型是 ReplicationController 的资源，他会创建 3 个 pods，在 v1 版本的配置文件中，支持扩展 pod 副本的资源类型为 ReplicationController 。</p><pre class="line-numbers language-language-yaml"><code class="language-language-yaml">apiVersion: v1kind: ReplicationController metadata:  name: nginxspec:  replicas: 3  selector:    app: nginx  template:    metadata:      name: nginx      labels:        app: nginx    spec:      containers:      - name: nginx        image: nginx        ports:        - containerPort: 80<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="创建"><a class="header-anchor" href="#创建">¶</a>创建</h5><p>使用 <code>kubectl create</code> 创建一个 ReplicationController 资源，<code>kubectl get rc</code> 获取资源创建情况：</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\replicas-set>kubectl create -f rc_nginx.ymlreplicationcontroller/nginx createdD:\docker\docker\chapter9\labs\replicas-set>kubectl get rcNAME    DESIRED   CURRENT   READY   AGEnginx   3         3         1       12sD:\docker\docker\chapter9\labs\replicas-set>kubectl get podsNAME          READY   STATUS    RESTARTS   AGEnginx-9m8br   1/1     Running   0          26snginx-h97jg   1/1     Running   0          26snginx-ntjcb   1/1     Running   0          26sD:\docker\docker\chapter9\labs\replicas-set>kubectl get rcNAME    DESIRED   CURRENT   READY   AGEnginx   3         3         3       30s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="自愈"><a class="header-anchor" href="#自愈">¶</a>自愈</h5><p>下面尝试删除一个 pod，和 docker swarm 一样具有自动恢复的功能：</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\replicas-set>kubectl delete pods nginx-9m8brpod "nginx-9m8br" deletedD:\docker\docker\chapter9\labs\replicas-set>kubectl get podsNAME          READY   STATUS    RESTARTS   AGEnginx-h97jg   1/1     Running   0          3m18snginx-ntjcb   1/1     Running   0          3m18snginx-schc7   1/1     Running   0          8s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="扩展"><a class="header-anchor" href="#扩展">¶</a>扩展</h5><p>使用 <code>kubectl scale rc</code> 命令可以对 ReplicationController 进行横向扩展</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\replicas-set>kubectl scale rc nginx --replicas=2replicationcontroller/nginx scaledD:\docker\docker\chapter9\labs\replicas-set>kubectl get rcNAME    DESIRED   CURRENT   READY   AGEnginx   2         2         2       6m35sD:\docker\docker\chapter9\labs\replicas-set>kubectl scale rc nginx --replicas=4replicationcontroller/nginx scaledD:\docker\docker\chapter9\labs\replicas-set>kubectl get rcNAME    DESIRED   CURRENT   READY   AGEnginx   4         4         4       6m53s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="删除"><a class="header-anchor" href="#删除">¶</a>删除</h5><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\replicas-set>kubectl delete -f rc_nginx.ymlreplicationcontroller "nginx" deletedD:\docker\docker\chapter9\labs\replicas-set>kubectl get podsNo resources found in default namespace.D:\docker\docker\chapter9\labs\replicas-set>kubectl get rcNo resources found in default namespace.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="ReplicaSet"><a class="header-anchor" href="#ReplicaSet">¶</a>ReplicaSet</h4><p>ReplicaSet 是用来替换 ReplictionController 的，它在 apps/v1 版本配置文件中开始支持，它比 ReplicationController 多了一个 new set-based selector requirement 的功能，以下是它的一个 yml 文件配置：</p><pre class="line-numbers language-language-yaml"><code class="language-language-yaml">apiVersion: apps/v1kind: ReplicaSetmetadata:  name: nginx  labels:    tier: frontendspec:  replicas: 3  selector:    matchLabels:      tier: frontend  template:    metadata:      name: nginx      labels:        tier: frontend    spec:      containers:      - name: nginx        image: nginx        ports:        - containerPort: 80<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="创建-v2"><a class="header-anchor" href="#创建-v2">¶</a>创建</h5><p><code>kubectl create rs</code> 创建 ReplicaSet</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\replicas-set>kubectl create -f rs_nginx.ymlreplicaset.apps/nginx createdD:\docker\docker\chapter9\labs\replicas-set>kubectl get rsNAME    DESIRED   CURRENT   READY   AGEnginx   3         3         3       15sD:\docker\docker\chapter9\labs\replicas-set>kubectl get podsNAME          READY   STATUS    RESTARTS   AGEnginx-5ddz7   1/1     Running   0          21snginx-7gfjk   1/1     Running   0          21snginx-t4k5l   1/1     Running   0          21s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="自愈-v2"><a class="header-anchor" href="#自愈-v2">¶</a>自愈</h5><p>… …</p><h5 id="扩展-v2"><a class="header-anchor" href="#扩展-v2">¶</a>扩展</h5><p><code>kubectl scale rs</code> 横向扩展</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\replicas-set>kubectl scale rs nginx --replicas=2replicaset.apps/nginx scaledD:\docker\docker\chapter9\labs\replicas-set>kubectl get rsNAME    DESIRED   CURRENT   READY   AGEnginx   2         2         2       42s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="删除-v2"><a class="header-anchor" href="#删除-v2">¶</a>删除</h5><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\replicas-set>kubectl delete -f rs_nginx.ymlreplicaset.apps "nginx" deletedD:\docker\docker\chapter9\labs\replicas-set>kubectl get rsNo resources found in default namespace.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Deployment"><a class="header-anchor" href="#Deployment">¶</a>Deployment</h4><p>deployment 是比 replicas set 更抽象的资源，使用它可以创建 replicas set 的同时还可以对 replicas set 进行更新操作，例如镜像更新，端口更新等，类似 docker swarm 的 docker service update 和 docker deploy。下面是它的一个配置文件：</p><pre class="line-numbers language-language-yaml"><code class="language-language-yaml">apiVersion: apps/v1kind: Deploymentmetadata:  name: nginx-deployment  labels:    app: nginxspec:  replicas: 3  selector:    matchLabels:      app: nginx  template:    metadata:      labels:        app: nginx    spec:      containers:      - name: nginx        image: nginx:1.12.2        ports:        - containerPort: 80<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="创建-v3"><a class="header-anchor" href="#创建-v3">¶</a>创建</h5><p><code>kubectl create</code> 指定 deployment 类型的配置文件创建 deployment，使用 <code>kubectl get deployment</code> 获取创建的 deployment 信息：</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\deployment>kubectl create -f deployment_nginx.ymldeployment.apps/nginx-deployment createdD:\docker\docker\chapter9\labs\deployment>kubectl get deploymentNAME               READY   UP-TO-DATE   AVAILABLE   AGEnginx-deployment   0/3     3            0           9sD:\docker\docker\chapter9\labs\deployment>kubectl get deploymentNAME               READY   UP-TO-DATE   AVAILABLE   AGEnginx-deployment   3/3     3            3           23sD:\docker\docker\chapter9\labs\deployment>kubectl get rsNAME                          DESIRED   CURRENT   READY   AGEnginx-deployment-84b8bdb667   3         3         3       32sD:\docker\docker\chapter9\labs\deployment>kubectl get podsNAME                                READY   STATUS    RESTARTS   AGEnginx-deployment-84b8bdb667-tfsfr   1/1     Running   0          39snginx-deployment-84b8bdb667-tr9dm   1/1     Running   0          39snginx-deployment-84b8bdb667-xp8pm   1/1     Running   0          39s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="查看详细信息"><a class="header-anchor" href="#查看详细信息">¶</a>查看详细信息</h5><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\deployment>kubectl get deployment -o wideNAME               READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES         SELECTORnginx-deployment   3/3     3            3           3m36s   nginx        nginx:1.12.2   app=nginx<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h5 id="更新-deployment"><a class="header-anchor" href="#更新-deployment">¶</a>更新 deployment</h5><ul><li><p>使用 <code>kubectl set image deployment</code> 更新镜像</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\deployment>kubectl set image deployment nginx-deployment nginx=nginx:1.13deployment.apps/nginx-deployment image updatedD:\docker\docker\chapter9\labs\deployment>kubectl get deployment -o wideNAME               READY   UP-TO-DATE   AVAILABLE   AGE    CONTAINERS   IMAGES       SELECTORnginx-deployment   3/3     3            3           8m8s   nginx        nginx:1.13   app=nginxD:\docker\docker\chapter9\labs\deployment>kubectl get rsNAME                          DESIRED   CURRENT   READY   AGEnginx-deployment-687d765c64   3         3         3       29snginx-deployment-84b8bdb667   0         0         0       8m18sD:\docker\docker\chapter9\labs\deployment>kubectl get podsNAME                                READY   STATUS    RESTARTS   AGEnginx-deployment-687d765c64-24s72   1/1     Running   0          36snginx-deployment-687d765c64-pzz7w   1/1     Running   0          27snginx-deployment-687d765c64-tm68b   1/1     Running   0          29s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>使用 <code>kubectl apply -f &lt;resource-yml&gt;</code> 指定一个对某个现有资源的配置做了更改的 yml 文件，也会对正在运行的资源进行更新，apply 相当于 create or update。而 create 只会 create ，如果资源已存在，就会报错。</p></li><li><p><code>kubectl edit deployment &lt;deployment-name&gt;</code> 也可以对资源进行更新，它会打开资源的 yaml 文件编辑界面，我们对 yml 文件更新后保存即可。</p></li></ul><h5 id="滚动发布"><a class="header-anchor" href="#滚动发布">¶</a>滚动发布</h5><p>deployment 的更新是滚动的，使用 <code>kubectl describe deployment</code> 可以看到它的策略：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master deployment]# kubectl describe deployment nginx-deployment... ...StrategyType:           RollingUpdateMinReadySeconds:        0RollingUpdateStrategy:  25% max unavailable, 25% max surge... ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="回滚"><a class="header-anchor" href="#回滚">¶</a>回滚</h5><p><code>kubectl rollout history</code> 查看 deployment 的历史记录</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\deployment>kubectl rollout history deployment nginx-deploymentdeployment.apps/nginx-deploymentREVISION  CHANGE-CAUSE1         <none>2         <none><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>查看版本1 和版本 2 的详细：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master deployment]# kubectl rollout history deployment nginx-deployment --revision 1deployment.apps/nginx-deployment with revision #1Pod Template:  Labels:app=nginxpod-template-hash=84b8bdb667  Containers:   nginx:    Image:nginx:1.12.2    Port:80/TCP    Host Port:0/TCP    Environment:<none>    Mounts:<none>  Volumes:<none>[root@k8s-master deployment]# kubectl rollout history deployment nginx-deployment --revision 2deployment.apps/nginx-deployment with revision #2Pod Template:  Labels:app=nginxpod-template-hash=687d765c64  Containers:   nginx:    Image:nginx:1.13    Port:80/TCP    Host Port:0/TCP    Environment:<none>    Mounts:<none>  Volumes:<none><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>kubectl rollout undo</code> 对 deployment 进行回滚；另外加 <code>--to-revision &lt;revision num&gt;</code> 可以回滚到指定版本</p><pre class="line-numbers language-language-powershell"><code class="language-language-powershell">D:\docker\docker\chapter9\labs\deployment>kubectl rollout undo deployment nginx-deploymentdeployment.apps/nginx-deployment rolled backD:\docker\docker\chapter9\labs\deployment>kubectl get deployment -o wideNAME               READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTORnginx-deployment   3/3     3            3           10m   nginx        nginx:1.12.2   app=nginxD:\docker\docker\chapter9\labs\deployment>kubectl rollout history deployment nginx-deploymentdeployment.apps/nginx-deploymentREVISION  CHANGE-CAUSE2         <none>3         <none>D:\docker\docker\chapter9\labs\deployment>kubectl set image deployment nginx-deployment nginx=nginx:1.13deployment.apps/nginx-deployment image updated<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="自愈-v3"><a class="header-anchor" href="#自愈-v3">¶</a>自愈</h5><p>deployment 包装了 ReplicasSet，依赖 ReplicasSet 实现 。</p><h1>Namespace</h1><p>Namespace 用来隔离资源，可以在不同的 Namespace 下同时存在两个同类型同名的资源，不能在一个 Namespace 下存在这种情况。即以 pod 为例，现在的 k8s 资源结构层级为：cluster - context - namespace - pod。</p><p><code>kubectl get namespaces</code> 查看命名空间：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl get namespacesNAME              STATUS   AGEdefault           Active   21hkube-node-lease   Active   21hkube-public       Active   21hkube-system       Active   21h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>获取指定 namespace 下面的 pods；获取所有 namespace 下的资源使用参数 <code>--all-namespaces</code> ：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl get pod --namespace kube-systemNAME                                 READY   STATUS    RESTARTS   AGEcoredns-6c76c8bb89-c5dcd             1/1     Running   1          21hcoredns-6c76c8bb89-n5hqc             1/1     Running   1          21hetcd-k8s-master                      1/1     Running   1          21hkube-apiserver-k8s-master            1/1     Running   1          21hkube-controller-manager-k8s-master   1/1     Running   2          21hkube-proxy-ctz76                     1/1     Running   0          21hkube-proxy-fn2fh                     1/1     Running   0          21hkube-proxy-qbjjx                     1/1     Running   1          21hkube-scheduler-k8s-master            1/1     Running   2          21hweave-net-k777j                      2/2     Running   3          21hweave-net-m88vt                      2/2     Running   0          21hweave-net-w6krt                      2/2     Running   1          21h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>创建 namespace</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl create namespace demonamespace/demo created[root@k8s-master ~]# kubectl get namespacesNAME              STATUS   AGEdefault           Active   21hdemo              Active   3skube-node-lease   Active   21hkube-public       Active   21hkube-system       Active   21h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在创建 pod 的 yml 文件中，在顶级属性 metadata 下的子属性 namespace 指定命名空间：</p><pre class="line-numbers language-language-yaml"><code class="language-language-yaml">kind: Podmetadata:name: nginxnamesapce: demo... ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>删除当前上下文中的命名空间：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl delete namespaces demonamespace "demo" deleted<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="k8s-自带命名空间"><a class="header-anchor" href="#k8s-自带命名空间">¶</a>k8s 自带命名空间</h3><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl get nsNAME              STATUS   AGEdefault           Active   27hkube-node-lease   Active   27hkube-public       Active   27hkube-system       Active   27h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中 kube-system 中运行着 kubernetes 提供的服务的 pod ，如 etcd、controller、apiserver等等，其中还有一个提供 DNS 服务 的 service ：kube-dns。</p><h4 id="内置-DNS-服务"><a class="header-anchor" href="#内置-DNS-服务">¶</a>内置 DNS 服务</h4><p>如下就是内置 DNS 服务的信息，它的 ip 地址是 10.96.0.10，kubernetes 通过在每个容器内的 <code>/etc/resolv.conf</code> 文件中增加这个 ip 地址为 DNS 服务器地址，从而实现每个容器进行 DNS 查询的时候就会访问这个 ip 。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl get services -n kube-system -o wideNAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE   SELECTORkube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   27h   k8s-app=kube-dns<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h1>Context</h1><p><strong>default 是所有上下文中默认的缺省命名空间，创建上下文的时候如果没有指定 namespace ，后续创建资源的时候如果没有创建自定义的命名空间或者创建资源没有指定命名空间，新创建的资源就会位于这个命名空间下面</strong> :</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl config get-contextsCURRENT   NAME                          CLUSTER      AUTHINFO           NAMESPACE*         kubernetes-admin@kubernetes   kubernetes   kubernetes-admin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>另外我们可以创建自己的上下文并指定该上下文的默认命名空间，如下所示，在 demo 上下文中创建资源没有指定命名空间，就会放到 demo 命名空间中：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl config set-context demo --user=john --cluster=kubernetes --namespace=demoContext "demo" created.[root@k8s-master ~]# kubectl config get-contextsCURRENT   NAME                          CLUSTER      AUTHINFO           NAMESPACE          demo                          kubernetes   john               demo*         kubernetes-admin@kubernetes   kubernetes   kubernetes-admin[root@k8s-master ~]# kubectl config viewapiVersion: v1clusters:- cluster:    certificate-authority-data: DATA+OMITTED    server: https://192.168.205.120:6443  name: kubernetescontexts:- context:    cluster: kubernetes    namespace: demo    user: john  name: demo- context:    cluster: kubernetes    user: kubernetes-admin  name: kubernetes-admin@kubernetescurrent-context: kubernetes-admin@kuberneteskind: Configpreferences: {}users:- name: kubernetes-admin  user:    client-certificate-data: REDACTED    client-key-data: REDACTED<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>删除上下文：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@k8s-master ~]# kubectl config delete-context demodeleted context demo from /root/.kube/config<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h1>Service</h1><p>反向代理、负载均衡。</p><h3 id="Selector、Label"><a class="header-anchor" href="#Selector、Label">¶</a>Selector、Label</h3><p>Service 使用 Selector 组件获取 pods 的标签并根据 Selector 的条件标签进行流量定向。</p><h3 id="Service-Type"><a class="header-anchor" href="#Service-Type">¶</a>Service Type</h3><h4 id="ClusterIP"><a class="header-anchor" href="#ClusterIP">¶</a>ClusterIP</h4><p>k8s 内部服务暴露</p><h4 id="NodePort"><a class="header-anchor" href="#NodePort">¶</a>NodePort</h4><p>k8s 服务暴露给外部</p><h4 id="LoadBalancer"><a class="header-anchor" href="#LoadBalancer">¶</a>LoadBalancer</h4><p>暴露服务到公网（只监听公网ip，NodePort 监听内网 ip？）</p><h3 id="网络转发模式"><a class="header-anchor" href="#网络转发模式">¶</a>网络转发模式</h3><ul><li><p>用户空间代理模式：路由信息存储在 kube-proxy 中，转发逻辑需要切换到 kube-proxy 用户态然后再切回内核态</p></li><li><p>iptables：每一个 pod 一条 netfilter(iptables 接口操作的内核程序) 规则，负载均衡由转发表实现，负载均衡算法较简单，且一个 pod 一条规则在大规模 k8s 集群下会导致规则过多，频繁更新 linux 内核的 netfilter。</p></li><li><p>IPVS：一个 service 一条 netfilter 规则，这条规则会将流量转发到 LVS，由 LVS 实现负载均衡，性能更高，算法更多。</p></li></ul><h3 id="蓝绿发布"><a class="header-anchor" href="#蓝绿发布">¶</a>蓝绿发布</h3><p>先发布新版本 pod，与旧版本 pod 并存，修改 Service Selector Label 指向新版本，待新版本稳定后删除旧版本；如果新版本出现问题，则改回旧版本。</p><h1>k8s ingress</h1><p>本质上也是一种 service，相当于微服务网关，可以实现流量路由(根据域名、路径、端口等路由到不同 pod)、安全认证、日志监控、流量治理等功能。k8s 的 ingress 和网络一样也是提供了一个标准，有不同的实现，流行的是 nginx-ingress。</p><h1>ConfigMap</h1><p>通过发布一个 ConfigMap 对象，然后在其它对象如 Pod、Service 等中引用这个 ConfigMap 对象。</p><ul><li>通过环境变量的形式注入配置到容器：<code>envFrom</code> 属性的 <code>configMapRef</code> 子属性</li><li>挂载一个 volume 到容器，并将配置以文件的形式放到 volume 中</li></ul><h3 id="变更传播"><a class="header-anchor" href="#变更传播">¶</a>变更传播</h3><p>更新一个已经发布的 ConfigMap，并不会将更新传播到正在运行的之前引用了该 ConfigMap 的 Pod 中。需要以下做法：</p><ul><li>重启 pod</li><li>修改被更新的 ConfigMap 的名称，或者创建一个新的配置文件填入新的内容和名称，然后修改引用了该 ConfigMap 的资源中的 ConfigMap 名称，重新发布该资源，利用滚动更新的机制相较上面直接重启的方式更平滑</li></ul><h1>Secret</h1><p>Secret 和 ConfigMap 一样也是一个键值对的配置存储对象，也是有环境变量注入和 volume 挂载的方式进行使用。区别是使用 <code>kubectl describe</code> 的时候 ConfigMap 会显示配置信息，Secret 不会显示。不过使用 <code>kubectl get secret &lt;secret-name&gt; -o yaml</code> 的时候就会显示了，包括配置值的 base64 编码，如果在 yml 文件中填写的是明文，那么也会显示明文信息。而且 base64 也是不安全的，很容器解码。</p><h1>volume</h1><p>k8s 的 volume 有多种类型，hostPath 表示本地文件。在 <code>containers</code> 的子属性 <code>volumeMounts</code> 的子属性 <code>name</code> 引用 <code>containers</code> 的兄弟属性 <code>volumes</code> 的子属性 <code>name</code> 即可对 pod 的路径进行 volume 挂载。挂载的本地文件路径需要是共享的。</p><h1>PV、PVC</h1><p>将在 <code>volumes</code> 中定义的具体 volume 类型进行解耦，改成引用一个 PVC 对象，而 PVC 对象定义 yml 中引用一个 PV。PVC 表示一个申请动作，PV 中定义了具体的 volume 类型和持久化路径。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">kubectl get pvkubectl get pvc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h1>resources</h1><p><code>containers</code> 的子属性 <code>resources</code> 进行设置。</p><h3 id="request"><a class="header-anchor" href="#request">¶</a>request</h3><p>最小需求，如果 k8s 中的资源不能满足，pod 发布就会 pending（如果一个 deployment 发布多个 pod，则会先发布满足资源的 pod，剩下的如果资源不足就 pending），直到资源满足才会启动。</p><h3 id="limit"><a class="header-anchor" href="#limit">¶</a>limit</h3><p>最大可使用量。如果 pod 在运行过程中内存申请超过了 limit，会被 OOM kil 然后重启（CrashLoopBackOff），重启达到一定次数还不能成功就停止；CPU 资源则会被硬性限制。</p><h3 id="三种设置"><a class="header-anchor" href="#三种设置">¶</a>三种设置</h3><ol><li>Guaranteed：request=limit，只有内存使用超出 limit 才会被kill</li><li>Burstable：request &lt; limit，在 k8s 集群资源不足的时候可能会 kill</li><li>Best Effor：两个值都不设置，在 k8s 资源不足的时候会被 kiil</li></ol><h1>查看资源情况</h1><h2 id="metrics-server"><a class="header-anchor" href="#metrics-server">¶</a>metrics-server</h2><p>需要安装，安装之后通过 <code>kubectl top</code> 命令可以查看各维度、资源的 metrics。</p><h2 id="kubernetes-dashboard"><a class="header-anchor" href="#kubernetes-dashboard">¶</a>kubernetes-dashboard</h2><p>也需要安装，安装之后有一个图形化界面可以查看各指标信息。</p><h1>k8s Java pod 内存限制</h1><p>需要开启容器识别，这样 k8s 的 resource request/limit 才能生效，然后设置 JVM 相应的内存参数。</p><h1>k8s 就绪和存活探针</h1><p>防止在 pod 实际上不可用的情况下向它发送流量发生错误。</p><ul><li><p>就绪探针：在 pod 启动时期检测是否就绪，就绪才会发送流量。</p></li><li><p>存活探针：在 pod 运行时期检测，如果没有存活则会 kill 掉 pod 重启。</p></li></ul><blockquote><p>另外在容器依赖的情况下应该也有用到</p></blockquote><h1>helm/charts</h1><p>k8s 插件、安装包管理。</p>]]></content>
      
      
      <categories>
          
          <category> k8s </category>
          
      </categories>
      
      
        <tags>
            
            <tag> k8s </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker概述</title>
      <link href="/2020/12/22/docker/docker-gai-shu/"/>
      <url>/2020/12/22/docker/docker-gai-shu/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203409.png" alt="什么是docker"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203414.png" alt="docker能干什么"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203420.png" alt="持续集成架构"></p><h1>docker 安装</h1><h3 id="自主安装"><a class="header-anchor" href="#自主安装">¶</a>自主安装</h3><p><a href="https://docs.docker.com/get-docker/" target="_blank" rel="noopener">docker安装</a></p><p>VM工具：virtualbox</p><p>VM自动构建工具：<a href="https://www.vagrantup.com/" target="_blank" rel="noopener">Vagrant</a></p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 创建一个文件夹，这个文件夹就是一个 VM 的家，每一个VM一个家目录，家目录下有一个配置文件vagrant --helpvagrant versionvagrant init centos/7 # 初始化一个centos7的配置文件vagrant up # 基于当前目录中的配置文件进行安装VMvagrant ssh # 进入刚创建的虚拟机里面vagrant status # 查看VM运行状态vagrant halt # 停止刚创建的虚机vargrant destroy # 删除刚创建的虚机<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>一般想安装某个版本的VM直接google可以找到已经写好的配置文件，例如可以安转 CentOS 7，直接 google “vagrant centos7”，一般第一个网页就是 “<a href="https://app.vagrantup.com/" target="_blank" rel="noopener">https://app.vagrantup.com/</a>” 的URL，点进去就可以得到相关的信息：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203428.png" alt="image-20201017150151057"></p></blockquote><h3 id="docker-machine"><a class="header-anchor" href="#docker-machine">¶</a>docker machine</h3><p>mac 和 windows 安装之后自带了 docker machine，他是一个自动管理 docker 自身安装的工具，同时像阿里云，微软云等厂商都基于 docker machine 提供了自动创建一台带有 docker 云主机的功能，搜索 “docker machine aliyun” 相关即可。</p><h3 id="docker-playground"><a class="header-anchor" href="#docker-playground">¶</a>docker playground</h3><p>有一个组织在维护的很多已经装了 docker 的云主机，用户在 web 上可以临时地申请一台通过 web 终端连接使用。</p><h1>vagrant问题</h1><h3 id="无法切换到-root-用户"><a class="header-anchor" href="#无法切换到-root-用户">¶</a>无法切换到 root 用户</h3><pre class="line-numbers language-language-shell"><code class="language-language-shell">sudo su # vagrant默认没有设置root用户密码，使用这个命令可以切换到root用户然后修改root密码passwd root<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="无法远程-ssh"><a class="header-anchor" href="#无法远程-ssh">¶</a>无法远程 ssh</h3><p>遇到报错</p><pre><code>ssh failed Permission denied (publickey,gssapi-keyex,gssapi-with-mic).</code></pre><p>配置 <code>/etc/ssh/sshd_config</code></p><pre class="line-numbers language-language-shell"><code class="language-language-shell">PasswordAuthentication yes<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后 <code>service sshd restart</code></p><h3 id="mount-目录失败"><a class="header-anchor" href="#mount-目录失败">¶</a>mount 目录失败</h3><p>配置<code>config.vm.synced_folder &quot;labs&quot;, &quot;/home/vagrant/labs&quot;</code>报以下错误：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">mount: unknown filesystem type 'vboxsf'<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>解决方案：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">vagrant plugin install vagrant-vbguestvagrant destroy && vagrant up<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="guest-additions-问题"><a class="header-anchor" href="#guest-additions-问题">¶</a>guest additions 问题</h3><p>因为下载的 centos box 里面没有 virtualbox guest additions，需要下载一个携带该软件的 box ：<a href="https://app.vagrantup.com/geerlingguy/boxes/centos7/versions/1.2.24" target="_blank" rel="noopener">https://app.vagrantup.com/geerlingguy/boxes/centos7/versions/1.2.24</a></p><h1>安装 docker 的问题</h1><h3 id="解决官网yum安装docker慢"><a class="header-anchor" href="#解决官网yum安装docker慢">¶</a>解决官网yum安装docker慢</h3><p>替换</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ sudo yum-config-manager \    --add-repo \    https://download.docker.com/linux/centos/docker-ce.repo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>为</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="宿主机和容器突然都不能联网"><a class="header-anchor" href="#宿主机和容器突然都不能联网">¶</a>宿主机和容器突然都不能联网</h3><p>发现是 DNS 服务有问题，无法解析域名，ip可以 ping 通。修改 <code>/etc/resolv.conf</code> 文件，把以下插入到最前面：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">nameserver 223.5.5.5nameserver 223.6.6.6<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h1>Docker 架构</h1><p>Docker 提供了一个开发、打包、运行 app 的平台，把 app 和底层 infrastructure 隔离开来。其中 Docker Engine 就是核心组件。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203439.png" alt="image-20201018104953048"></p><h3 id="Docker-Engine"><a class="header-anchor" href="#Docker-Engine">¶</a>Docker Engine</h3><p>Docker Engine 为 C/S 架构，分为三部分：</p><ul><li>后台进程(dockerd)</li><li>REST API Server</li><li>CLI 接口(docker)，通过 REST API Server 和 dockerd 通信</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203445.png" alt="image-20201018105154795"></p><h3 id="Docker-总体架构图"><a class="header-anchor" href="#Docker-总体架构图">¶</a>Docker 总体架构图</h3><p>一个 Client 连接到一个安装了 Dockerd 的 DOCKER_HOST 主机上进行相关操作，如拉取镜像，运行容器等。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203451.png" alt="image-20201018105405189"></p><h3 id="底层技术支持"><a class="header-anchor" href="#底层技术支持">¶</a>底层技术支持</h3><ul><li><p>Namespaces：做隔离 pid、net、ipc、mnt、uts</p></li><li><p>Control groups：做资源限制</p></li><li><p>Union file systems：Container 和 image 的分层</p></li></ul><h3 id="Docker-Image"><a class="header-anchor" href="#Docker-Image">¶</a>Docker Image</h3><ul><li>文件和 meta data 的集合</li><li>分层的，并且每一层都可以添加改变删除文件，称为一个新的image</li><li>不同的image可以共享相同的基础layer</li><li>Image 本身是 read-only 的</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203459.png" alt="image-20201018143658992"></p><h3 id="Docker-Container"><a class="header-anchor" href="#Docker-Container">¶</a>Docker Container</h3><ul><li>通过 Image 创建（copy）</li><li>在 Image layer 之上建立一个 container layer（可读写）</li><li>类比面向对象：类和实例</li><li>Image 负责 app 的存储和分发，Container 负责运行 app</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203505.png" alt="image-20201018144042167"></p><h1>Docker 网络</h1><h3 id="Linux-网络命令空间-network-namespace"><a class="header-anchor" href="#Linux-网络命令空间-network-namespace">¶</a>Linux 网络命令空间(network namespace)</h3><h4 id="查看-docker-容器的网络接口"><a class="header-anchor" href="#查看-docker-容器的网络接口">¶</a>查看 docker 容器的网络接口</h4><p>先创建两个容器，test1和test2：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker run -d --name test1 busybox /bin/sh -c "while true;do sleep 3600; done"Unable to find image 'busybox:latest' locallylatest: Pulling from library/busybox9758c28807f2: Already existsDigest: sha256:a9286defaba7b3a519d585ba0e37d0b2cbee74ebfe590960b0b1d6a5e97d1e1dStatus: Downloaded newer image for busybox:latest040676f4f47f3fb22bc657099e017a884cc79b045cc67ba1732c3681042568b8[root@docker-node1 ~]# docker run -d --name test2 busybox /bin/sh -c "while true;do sleep 3600; done"2c38e69e55e481683c79eceda32f033e5c34e028581f203189671fdf32ace443<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>进入容器 test1，执行 <code>ip a</code> 查看网络接口情况，可以看到回环端口和一个名为 <code>eth0@if6</code>的端口。序号分别为1和5：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker exec -it test1 /bin/sh/ # ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever5: eth0@if6: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0       valid_lft forever preferred_lft forever<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>进入容器 test2，执行 <code>ip a</code> 查看网络接口情况，可以看到回环端口和一个名为 <code>eth0@if8</code>的端口。序号分别为1和7：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">/ # exit[root@docker-node1 ~]# docker exec -it test2 /bin/sh/ # ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever7: eth0@if8: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0       valid_lft forever preferred_lft forever<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>两个容器的 <code>eth</code> 端口网段是一样的，可以相互 <code>ping</code> 通</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">/ # ping 172.17.0.2PING 172.17.0.2 (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.141 ms64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.685 ms^C--- 172.17.0.2 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.141/0.413/0.685 ms/ # exit[root@docker-node1 ~]#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>退出后在宿主机执行 <code>ip a</code> 查看网络端口，发现看不到两个容器中的 <code>eth</code> 端口 5 和 7。同时看到 docker0 端口的网段和两个容器是一样的：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host       valid_lft forever preferred_lft forever2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic eth0       valid_lft 81204sec preferred_lft 81204sec    inet6 fe80::5054:ff:fe4d:77d3/64 scope link       valid_lft forever preferred_lft forever3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 08:00:27:e6:45:bc brd ff:ff:ff:ff:ff:ff    inet 192.168.205.10/24 brd 192.168.205.255 scope global noprefixroute eth1       valid_lft forever preferred_lft forever    inet6 fe80::a00:27ff:fee6:45bc/64 scope link       valid_lft forever preferred_lft forever4: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default    link/ether 02:42:25:db:49:63 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0       valid_lft forever preferred_lft forever    inet6 fe80::42:25ff:fedb:4963/64 scope link       valid_lft forever preferred_lft forever6: veth2aaf7ce@if5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default    link/ether ea:87:9c:ff:2b:ae brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet6 fe80::e887:9cff:feff:2bae/64 scope link       valid_lft forever preferred_lft forever8: vethf1db1bd@if7: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default    link/ether 62:b7:11:da:66:56 brd ff:ff:ff:ff:ff:ff link-netnsid 1    inet6 fe80::60b7:11ff:feda:6656/64 scope link       valid_lft forever preferred_lft forever<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="使用-linux-命令操作网络命名空间"><a class="header-anchor" href="#使用-linux-命令操作网络命名空间">¶</a>使用 linux 命令操作网络命名空间</h4><p>添加、查看、删除网络命名空间</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# ip netns add test1[root@docker-node1 ~]# ip netns add test2[root@docker-node1 ~]# ip netns add test3[root@docker-node1 ~]# ip netns listtest3test2test1[root@docker-node1 ~]# ip netns delete test3[root@docker-node1 ~]# ip netns listtest2test1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>查看 test1 命名空间下的网络接口，发现只有一个回环接口，而且状态是 <code>DOWN</code> 的，也没有 ip 地址：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# ip netns exec test1 ip a1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>查看 test1 命名空间下的 link</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# ip netns exec test1 ip link1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>查看宿主机下的 link</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# ip link1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000    link/ether 08:00:27:e6:45:bc brd ff:ff:ff:ff:ff:ff4: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default    link/ether 02:42:25:db:49:63 brd ff:ff:ff:ff:ff:ff6: veth2aaf7ce@if5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default    link/ether ea:87:9c:ff:2b:ae brd ff:ff:ff:ff:ff:ff link-netnsid 08: vethf1db1bd@if7: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default    link/ether 62:b7:11:da:66:56 brd ff:ff:ff:ff:ff:ff link-netnsid 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203512.png" alt="image-20201019152312515"></p><p>添加一对 <code>Veth</code> 设备，<code>veth-test1</code> 和 <code>veth-test2</code>，它们的序号为 12 和 13，都有MAC地址，分别为<code>3e:c1:1a:1d:37:3c</code>和<code>2a:d1:1d:4b:9f:6c</code>，状态<code>state</code>都是<code>DOWN</code>。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# ip link add veth-test1 type veth peer name veth-test2[root@docker-node1 ~]# ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host       valid_lft forever preferred_lft forever2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic eth0       valid_lft 76155sec preferred_lft 76155sec    inet6 fe80::5054:ff:fe4d:77d3/64 scope link       valid_lft forever preferred_lft forever3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 08:00:27:e6:45:bc brd ff:ff:ff:ff:ff:ff    inet 192.168.205.10/24 brd 192.168.205.255 scope global noprefixroute eth1       valid_lft forever preferred_lft forever    inet6 fe80::a00:27ff:fee6:45bc/64 scope link       valid_lft forever preferred_lft forever4: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default    link/ether 02:42:25:db:49:63 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0       valid_lft forever preferred_lft forever    inet6 fe80::42:25ff:fedb:4963/64 scope link       valid_lft forever preferred_lft forever6: veth2aaf7ce@if5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default    link/ether ea:87:9c:ff:2b:ae brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet6 fe80::e887:9cff:feff:2bae/64 scope link       valid_lft forever preferred_lft forever8: vethf1db1bd@if7: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default    link/ether 62:b7:11:da:66:56 brd ff:ff:ff:ff:ff:ff link-netnsid 1    inet6 fe80::60b7:11ff:feda:6656/64 scope link       valid_lft forever preferred_lft forever12: veth-test2@veth-test1: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000    link/ether 3e:c1:1a:1d:37:3c brd ff:ff:ff:ff:ff:ff13: veth-test1@veth-test2: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000    link/ether 2a:d1:1d:4b:9f:6c brd ff:ff:ff:ff:ff:ff<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>把这对 <code>Veth</code> 设备的两端分别添加到命名空间 test1 和 test2 中，可以看到两个命名空间中分别多了一条link，而宿主机中的12和13号设备看不到了。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# ip link set veth-test1 netns test1[root@docker-node1 ~]# ip netns exec test1 ip link1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:0013: veth-test1@if12: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000    link/ether 2a:d1:1d:4b:9f:6c brd ff:ff:ff:ff:ff:ff link-netnsid 0[root@docker-node1 ~]# ip link set veth-test2 netns test2[root@docker-node1 ~]# ip netns exec test2 ip link1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:0012: veth-test2@if13: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000    link/ether 3e:c1:1a:1d:37:3c brd ff:ff:ff:ff:ff:ff link-netnsid 0[root@docker-node1 ~]# ip link1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000    link/ether 08:00:27:e6:45:bc brd ff:ff:ff:ff:ff:ff4: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default    link/ether 02:42:25:db:49:63 brd ff:ff:ff:ff:ff:ff6: veth2aaf7ce@if5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default    link/ether ea:87:9c:ff:2b:ae brd ff:ff:ff:ff:ff:ff link-netnsid 08: vethf1db1bd@if7: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default    link/ether 62:b7:11:da:66:56 brd ff:ff:ff:ff:ff:ff link-netnsid 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>给两个 <code>Veth</code> 设备分别添加 ip 地址</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# ip netns exec test1 ip addr add 192.168.1.1/24 dev veth-test1[root@docker-node1 ~]# ip netns exec test2 ip addr add 192.168.1.2/24 dev veth-test2[root@docker-node1 ~]# ip netns exec test1 ip a1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:0013: veth-test1@if12: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000    link/ether 2a:d1:1d:4b:9f:6c brd ff:ff:ff:ff:ff:ff link-netnsid 1    inet 192.168.1.1/24 scope global veth-test1       valid_lft forever preferred_lft forever[root@docker-node1 ~]# ip netns exec test2 ip a1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:0012: veth-test2@if13: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000    link/ether 3e:c1:1a:1d:37:3c brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet 192.168.1.2/24 scope global veth-test2       valid_lft forever preferred_lft forever<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>启用两个 <code>Veth</code> 设备：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# ip netns exec test1 ip link set dev veth-test1 up[root@docker-node1 ~]# ip netns exec test2 ip link set dev veth-test2 up[root@docker-node1 ~]# ip netns exec test1 ip a1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:0013: veth-test1@if12: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000    link/ether 2a:d1:1d:4b:9f:6c brd ff:ff:ff:ff:ff:ff link-netnsid 1    inet 192.168.1.1/24 scope global veth-test1       valid_lft forever preferred_lft forever    inet6 fe80::28d1:1dff:fe4b:9f6c/64 scope link       valid_lft forever preferred_lft forever[root@docker-node1 ~]# ip netns exec test2 ip a1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:0012: veth-test2@if13: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000    link/ether 3e:c1:1a:1d:37:3c brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet 192.168.1.2/24 scope global veth-test2       valid_lft forever preferred_lft forever    inet6 fe80::3cc1:1aff:fe1d:373c/64 scope link       valid_lft forever preferred_lft forever<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 test1 命名空间中 ping test2 的ip 地址，是连通的：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# ip netns exec test1 ping 192.168.1.2PING 192.168.1.2 (192.168.1.2) 56(84) bytes of data.64 bytes from 192.168.1.2: icmp_seq=1 ttl=64 time=0.065 ms64 bytes from 192.168.1.2: icmp_seq=2 ttl=64 time=0.058 ms^C--- 192.168.1.2 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 999msrtt min/avg/max/mdev = 0.058/0.061/0.065/0.008 ms[root@docker-node1 ~]#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="容器互通和连接公网"><a class="header-anchor" href="#容器互通和连接公网">¶</a>容器互通和连接公网</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203519.png" alt="image-20201019155447457"></p><p>查看 docker 网络情况，有名为 bridge、host、none 的网络，DRIVER 分别为 bridge、host、null</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker network lsNETWORK ID          NAME                DRIVER              SCOPEc89adfd37eb3        bridge              bridge              localdac2514ae55c        host                host                local10ac2277dbd2        none                null                local<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>目前有一个 docker 容器在运行</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker ps -aCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES040676f4f47f        busybox             "/bin/sh -c 'while t…"   2 hours ago         Up 2 hours                              test1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>然后我们通过 <code>inspect</code> 命令查看上面的 bridge 网络，可以发现在 Containers 条目中，包含了上面列举的唯一的容器，也就是说这个容器的网络是连接在 bridge 上面的。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker network inspect c89adfd37eb3[    {        "Name": "bridge",        "Id": "c89adfd37eb397f31279e63c4eae8c28d01fe85019d32f6244be3af53e3daad6",        "Created": "2020-10-19T05:56:27.683543536Z",        "Scope": "local",        "Driver": "bridge",        "EnableIPv6": false,        "IPAM": {            "Driver": "default",            "Options": null,            "Config": [                {                    "Subnet": "172.17.0.0/16",                    "Gateway": "172.17.0.1"                }            ]        },        "Internal": false,        "Attachable": false,        "Ingress": false,        "ConfigFrom": {            "Network": ""        },        "ConfigOnly": false,        "Containers": {            "040676f4f47f3fb22bc657099e017a884cc79b045cc67ba1732c3681042568b8": {                "Name": "test1",                "EndpointID": "690b3d311fd769eae58091cfd94c6f9575a84720143a76d73d9bb6c268175442",                "MacAddress": "02:42:ac:11:00:02",                "IPv4Address": "172.17.0.2/16",                "IPv6Address": ""            }        },        "Options": {            "com.docker.network.bridge.default_bridge": "true",            "com.docker.network.bridge.enable_icc": "true",            "com.docker.network.bridge.enable_ip_masquerade": "true",            "com.docker.network.bridge.host_binding_ipv4": "0.0.0.0",            "com.docker.network.bridge.name": "docker0",            "com.docker.network.driver.mtu": "1500"        },        "Labels": {}    }]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>再次在宿主机上查询网络接口，可以看到 4 号设备名为 <code>docker0</code>，6 号设备名为 <code>veth2aaf7ce@if5</code>，其实 <code>docker0</code> 就是一个 bridge 设备，而 <code>veth2aaf7ce@if5</code> 是一个 <code>Veth</code> 设备，一对 <code>Veth</code> 是通过连接到同一个 <code>bridge</code> 上实现互通的（类比现实世界中两条主机的物理接口通过网线连接到同一个路由器或者交换机），所以可以推测，该 <code>Veth</code> 设备的另一端就是位于 test1 容器的 network namespace 中的 <code>eth0@if6</code>。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host       valid_lft forever preferred_lft forever2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic eth0       valid_lft 74159sec preferred_lft 74159sec    inet6 fe80::5054:ff:fe4d:77d3/64 scope link       valid_lft forever preferred_lft forever3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 08:00:27:e6:45:bc brd ff:ff:ff:ff:ff:ff    inet 192.168.205.10/24 brd 192.168.205.255 scope global noprefixroute eth1       valid_lft forever preferred_lft forever    inet6 fe80::a00:27ff:fee6:45bc/64 scope link       valid_lft forever preferred_lft forever4: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default    link/ether 02:42:25:db:49:63 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0       valid_lft forever preferred_lft forever    inet6 fe80::42:25ff:fedb:4963/64 scope link       valid_lft forever preferred_lft forever6: veth2aaf7ce@if5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default    link/ether ea:87:9c:ff:2b:ae brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet6 fe80::e887:9cff:feff:2bae/64 scope link       valid_lft forever preferred_lft forever       [root@docker-node1 ~]# docker exec test1 ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever5: eth0@if6: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0       valid_lft forever preferred_lft forever<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过 <code>brctl</code> 工具证实 <code>veth2aaf7ce@if5</code> 是连接在 <code>docker0</code> 上的：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# yum install bridge-utils[root@docker-node1 ~]# brctl showbridge namebridge idSTP enabledinterfacesdocker08000.024225db4963noveth2aaf7ce<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>再增加一个容器的时候，可以看到 <code>docker network inspect bridge</code> 的 Containers 条目多了一个容器信息， <code>ip a</code> 也多了一个 <code>Veth</code> 设备 <code>veth3811212@if14</code>，<code>brctl show</code> 也看到了 bridge 多了一个端口。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker run -d --name test2 busybox /bin/sh -c "while true;do sleep 3600; done"97c2b77265324f16be66f5ae02eaed3c8175ebc78acc9d5e0e7c3ea0f3d271bd[root@docker-node1 ~]# docker network inspect bridge[    {        "Name": "bridge",        "Id": "c89adfd37eb397f31279e63c4eae8c28d01fe85019d32f6244be3af53e3daad6",        "Created": "2020-10-19T05:56:27.683543536Z",        "Scope": "local",        "Driver": "bridge",        "EnableIPv6": false,        "IPAM": {            "Driver": "default",            "Options": null,            "Config": [                {                    "Subnet": "172.17.0.0/16",                    "Gateway": "172.17.0.1"                }            ]        },        "Internal": false,        "Attachable": false,        "Ingress": false,        "ConfigFrom": {            "Network": ""        },        "ConfigOnly": false,        "Containers": {            "040676f4f47f3fb22bc657099e017a884cc79b045cc67ba1732c3681042568b8": {                "Name": "test1",                "EndpointID": "690b3d311fd769eae58091cfd94c6f9575a84720143a76d73d9bb6c268175442",                "MacAddress": "02:42:ac:11:00:02",                "IPv4Address": "172.17.0.2/16",                "IPv6Address": ""            },            "97c2b77265324f16be66f5ae02eaed3c8175ebc78acc9d5e0e7c3ea0f3d271bd": {                "Name": "test2",                "EndpointID": "3a755087b8b7ea5bbdcd807dcf7230e37fcfdef91e70cbebdfecf0a2e8086354",                "MacAddress": "02:42:ac:11:00:03",                "IPv4Address": "172.17.0.3/16",                "IPv6Address": ""            }        },        "Options": {            "com.docker.network.bridge.default_bridge": "true",            "com.docker.network.bridge.enable_icc": "true",            "com.docker.network.bridge.enable_ip_masquerade": "true",            "com.docker.network.bridge.host_binding_ipv4": "0.0.0.0",            "com.docker.network.bridge.name": "docker0",            "com.docker.network.driver.mtu": "1500"        },        "Labels": {}    }][root@docker-node1 ~]# ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host       valid_lft forever preferred_lft forever2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic eth0       valid_lft 73701sec preferred_lft 73701sec    inet6 fe80::5054:ff:fe4d:77d3/64 scope link       valid_lft forever preferred_lft forever3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 08:00:27:e6:45:bc brd ff:ff:ff:ff:ff:ff    inet 192.168.205.10/24 brd 192.168.205.255 scope global noprefixroute eth1       valid_lft forever preferred_lft forever    inet6 fe80::a00:27ff:fee6:45bc/64 scope link       valid_lft forever preferred_lft forever4: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default    link/ether 02:42:25:db:49:63 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0       valid_lft forever preferred_lft forever    inet6 fe80::42:25ff:fedb:4963/64 scope link       valid_lft forever preferred_lft forever6: veth2aaf7ce@if5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default    link/ether ea:87:9c:ff:2b:ae brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet6 fe80::e887:9cff:feff:2bae/64 scope link       valid_lft forever preferred_lft forever15: veth3811212@if14: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default    link/ether ae:bf:e2:b8:d5:af brd ff:ff:ff:ff:ff:ff link-netnsid 1    inet6 fe80::acbf:e2ff:feb8:d5af/64 scope link       valid_lft forever preferred_lft forever[root@docker-node1 ~]# brctl showbridge namebridge idSTP enabledinterfacesdocker08000.024225db4963noveth2aaf7ceveth3811212<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="–link-和自定义-bridge-网络"><a class="header-anchor" href="#–link-和自定义-bridge-网络">¶</a>–link 和自定义 bridge 网络</h4><h5 id="–link"><a class="header-anchor" href="#–link">¶</a>–link</h5><p>运行两个容器，test2 link 到 test1 上</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker run -d --name test1 busybox /bin/sh -c "while true;do sleep 3600;done"401c4b231a5dbe1ea66e44152b08b15aab088fb1551ccdb447658b8b61cb9892[root@docker-node1 ~]# docker run -d --name test2 --link test1:alias  busybox /bin/sh -c "while true;do sleep 3600;done"7c531b6d6cde4bc5578c73867a3667acdc09a2ae49583f69a1a528b5246b1a4f<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>查看 ip 地址</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker exec test1 ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever30: eth0@if31: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0       valid_lft forever preferred_lft forever[root@docker-node1 ~]# docker exec test2 ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever32: eth0@if33: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0       valid_lft forever preferred_lft forever<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 test1 上可以 ping 通 test2 的ip，但是不能 ping 它的名称：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker exec -it test1 /bin/sh/ # ping 172.17.0.3PING 172.17.0.3 (172.17.0.3): 56 data bytes64 bytes from 172.17.0.3: seq=0 ttl=64 time=0.217 ms64 bytes from 172.17.0.3: seq=1 ttl=64 time=0.084 ms^C--- 172.17.0.3 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.084/0.150/0.217 ms/ # ping test2ping: bad address 'test2'/ # exit<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 test2 上可以 ping 通 test1 的名称和 link 指定的别名 “alias”</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker exec -it test2 /bin/sh/ # ping test1PING test1 (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.075 ms^C--- test1 ping statistics ---1 packets transmitted, 1 packets received, 0% packet lossround-trip min/avg/max = 0.075/0.075/0.075 ms/ #/ # ping aliasPING alias (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.108 ms^C--- alias ping statistics ---1 packets transmitted, 1 packets received, 0% packet lossround-trip min/avg/max = 0.108/0.108/0.108 ms/ # exit[root@docker-node1 ~]#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其实就是在 test2 中加入了关于 test1 的 DNS 信息到 test2 的本地中，方便 ip 不固定的时候进行访问。</p><h5 id="自定义-bridge-网络"><a class="header-anchor" href="#自定义-bridge-网络">¶</a>自定义 bridge 网络</h5><p>通过 <code>docker network create</code> 创建一个 driver 是 bridge 的网络，也就是 bridge 类型的网络设备，名称为 my-bridge。通过 <code>brctl show</code> 可以看到当前没有任何 <code>Veth</code> 接口连接到该设备</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker network create -d bridge my-bridged3699cfbd400293e08c6c5a4d2da2f6d7226981b875d092bafd6f7d455f38921[root@docker-node1 ~]# docker network listNETWORK ID          NAME                DRIVER              SCOPEc89adfd37eb3        bridge              bridge              localdac2514ae55c        host                host                locald3699cfbd400        my-bridge           bridge              local10ac2277dbd2        none                null                local[root@docker-node1 ~]# brctl showbridge namebridge idSTP enabledinterfacesbr-d3699cfbd4008000.0242432c6ca4nodocker08000.024225db4963noveth6ad4611vethddc0a25<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过 <code>--network</code> 参数指定自建网络运行容器，此时自建 bridge 网络上多了一个接口 <code>veth151f6f7</code>，inspect network 上也出现了新运行的容器信息，ip 是一个和之前默认运行的两个容器网段不一样的 172.18 网段。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker run -d --name test3 --network my-bridge busybox /bin/sh -c "while true;do sleep 3600;done"b2e3e66cad7dc1d07fa1e85961cc8bab7c74c76b3a41ec405faf437f051c2fc5[root@docker-node1 ~]# brctl showbridge namebridge idSTP enabledinterfacesbr-d3699cfbd4008000.0242432c6ca4noveth151f6f7docker08000.024225db4963noveth6ad4611vethddc0a25[root@docker-node1 ~]# docker network inspect my-bridge[    {        "Name": "my-bridge",        "Id": "d3699cfbd400293e08c6c5a4d2da2f6d7226981b875d092bafd6f7d455f38921",        "Created": "2020-10-19T08:48:42.200451913Z",        "Scope": "local",        "Driver": "bridge",        "EnableIPv6": false,        "IPAM": {            "Driver": "default",            "Options": {},            "Config": [                {                    "Subnet": "172.18.0.0/16",                    "Gateway": "172.18.0.1"                }            ]        },        "Internal": false,        "Attachable": false,        "Ingress": false,        "ConfigFrom": {            "Network": ""        },        "ConfigOnly": false,        "Containers": {            "b2e3e66cad7dc1d07fa1e85961cc8bab7c74c76b3a41ec405faf437f051c2fc5": {                "Name": "test3",                "EndpointID": "9cf330bc93faf46fa0d869eeffc8bf549b37397c8f231ec323dd0a5bba826ead",                "MacAddress": "02:42:ac:12:00:02",                "IPv4Address": "172.18.0.2/16",                "IPv6Address": ""            }        },        "Options": {},        "Labels": {}    }]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过 <code>docker network connect</code> 命令将已有容器连接到新增的网络中，如下例子将 test2 容器也连接到了 my-bridge 中，此时 test2 既在 bridge 网络中也在 my-bridge 中。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker network connect my-bridge test2[root@docker-node1 ~]# docker network inspect my-bridge[    {        "Name": "my-bridge",        "Id": "d3699cfbd400293e08c6c5a4d2da2f6d7226981b875d092bafd6f7d455f38921",        "Created": "2020-10-19T08:48:42.200451913Z",        "Scope": "local",        "Driver": "bridge",        "EnableIPv6": false,        "IPAM": {            "Driver": "default",            "Options": {},            "Config": [                {                    "Subnet": "172.18.0.0/16",                    "Gateway": "172.18.0.1"                }            ]        },        "Internal": false,        "Attachable": false,        "Ingress": false,        "ConfigFrom": {            "Network": ""        },        "ConfigOnly": false,        "Containers": {            "7c531b6d6cde4bc5578c73867a3667acdc09a2ae49583f69a1a528b5246b1a4f": {                "Name": "test2",                "EndpointID": "1351f55488ce2c3bedbb77c17e0bf41a22c22c16fb0724564d3a2e93f20af38e",                "MacAddress": "02:42:ac:12:00:03",                "IPv4Address": "172.18.0.3/16",                "IPv6Address": ""            },            "b2e3e66cad7dc1d07fa1e85961cc8bab7c74c76b3a41ec405faf437f051c2fc5": {                "Name": "test3",                "EndpointID": "9cf330bc93faf46fa0d869eeffc8bf549b37397c8f231ec323dd0a5bba826ead",                "MacAddress": "02:42:ac:12:00:02",                "IPv4Address": "172.18.0.2/16",                "IPv6Address": ""            }        },        "Options": {},        "Labels": {}    }]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>此时没有使用 <code>--link</code> 参数连接 test2 和 test3，但是在 test3 中直接 ping test2 也是可以 ping 通的。这是因为连接到自定义 bridge 中所有容器都是可以通过容器名称 ping 通的，而在默认 bridge 中就不行。即 test2 也可以 ping 通 test3，test3 无法 ping 通 test1 。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker exec -it test3 /bin/sh/ # ping test2PING test2 (172.18.0.3): 56 data bytes64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.083 ms^C--- test2 ping statistics ---1 packets transmitted, 1 packets received, 0% packet lossround-trip min/avg/max = 0.083/0.083/0.083 ms/ # exit<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="host-和-none-网络"><a class="header-anchor" href="#host-和-none-网络">¶</a>host 和 none 网络</h4><p>指定 <code>--network</code> 为 none 的容器只有回环端口，不会创建其它端口，所以只能通过 <code>docker exec</code> 的方式进入容器内部访问容器，无法在宿主机内或者外通过网络端口进行访问。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 ~]# docker run -d --name test1 --network none busybox /bin/sh -c "while true; do sleep 60; done"ac33d31a6b32e04e6927cb1d91b21cb6acf83e6df850d404d7845f25249c60c0[root@docker-node1 ~]# docker network inspect none[    {        "Name": "none",        "Id": "10ac2277dbd296323001001da2dae51ddee8a8ee8ce4fe76580d83b9bbd6387b",        "Created": "2020-10-19T04:37:58.595608046Z",        "Scope": "local",        "Driver": "null",        "EnableIPv6": false,        "IPAM": {            "Driver": "default",            "Options": null,            "Config": []        },        "Internal": false,        "Attachable": false,        "Ingress": false,        "ConfigFrom": {            "Network": ""        },        "ConfigOnly": false,        "Containers": {            "ac33d31a6b32e04e6927cb1d91b21cb6acf83e6df850d404d7845f25249c60c0": {                "Name": "test1",                "EndpointID": "10851450939da6cf590a81b36255c2b83bd6c93577a10e1d6993cd1659d5c675",                "MacAddress": "",                "IPv4Address": "",                "IPv6Address": ""            }        },        "Options": {},        "Labels": {}    }][root@docker-node1 ~]# docker exec test1 ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>host 网络的容器和宿主机在同一 network namespace，使用同一套网络接口，所以 host 网络的容器很容易产生端口冲突，例如起了两个 host 网络的 nginx 容器的时候，默认端口都是 80 ，此时就冲突了。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 flask-redis]# docker run -d --name test2 --network host busybox /bin/sh -c "while true; do sleep 60; done"4ce2ee17282361b97498ae84276e452561257536fc2b6972bdb7bc1095a23778[root@docker-node1 flask-redis]# docker inspect host[    {        "Name": "host",        "Id": "dac2514ae55c0933a9528db1cc07f0dfe1999f0ad9b9a5d284b3b96d1f67fcd2",        "Created": "2020-10-19T04:37:58.605734163Z",        "Scope": "local",        "Driver": "host",        "EnableIPv6": false,        "IPAM": {            "Driver": "default",            "Options": null,            "Config": []        },        "Internal": false,        "Attachable": false,        "Ingress": false,        "ConfigFrom": {            "Network": ""        },        "ConfigOnly": false,        "Containers": {            "4ce2ee17282361b97498ae84276e452561257536fc2b6972bdb7bc1095a23778": {                "Name": "test2",                "EndpointID": "28181afba7b0a479c9820f034c15e52ed47e4459aa3b410aa1955ef225eb2b9c",                "MacAddress": "",                "IPv4Address": "",                "IPv6Address": ""            }        },        "Options": {},        "Labels": {}    }][root@docker-node1 flask-redis]# docker exec test2 ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host       valid_lft forever preferred_lft forever2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast qlen 1000    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0       valid_lft 66842sec preferred_lft 66842sec    inet6 fe80::5054:ff:fe4d:77d3/64 scope link       valid_lft forever preferred_lft forever3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast qlen 1000    link/ether 08:00:27:e6:45:bc brd ff:ff:ff:ff:ff:ff    inet 192.168.205.10/24 brd 192.168.205.255 scope global eth1       valid_lft forever preferred_lft forever    inet6 fe80::a00:27ff:fee6:45bc/64 scope link       valid_lft forever preferred_lft forever4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue    link/ether 02:42:25:db:49:63 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0       valid_lft forever preferred_lft forever    inet6 fe80::42:25ff:fedb:4963/64 scope link       valid_lft forever preferred_lft forever34: br-d3699cfbd400: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue    link/ether 02:42:43:2c:6c:a4 brd ff:ff:ff:ff:ff:ff    inet 172.18.0.1/16 brd 172.18.255.255 scope global br-d3699cfbd400       valid_lft forever preferred_lft forever    inet6 fe80::42:43ff:fe2c:6ca4/64 scope link       valid_lft forever preferred_lft forever[root@docker-node1 flask-redis]# ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host       valid_lft forever preferred_lft forever2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic eth0       valid_lft 66841sec preferred_lft 66841sec    inet6 fe80::5054:ff:fe4d:77d3/64 scope link       valid_lft forever preferred_lft forever3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 08:00:27:e6:45:bc brd ff:ff:ff:ff:ff:ff    inet 192.168.205.10/24 brd 192.168.205.255 scope global noprefixroute eth1       valid_lft forever preferred_lft forever    inet6 fe80::a00:27ff:fee6:45bc/64 scope link       valid_lft forever preferred_lft forever4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default    link/ether 02:42:25:db:49:63 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0       valid_lft forever preferred_lft forever    inet6 fe80::42:25ff:fedb:4963/64 scope link       valid_lft forever preferred_lft forever34: br-d3699cfbd400: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default    link/ether 02:42:43:2c:6c:a4 brd ff:ff:ff:ff:ff:ff    inet 172.18.0.1/16 brd 172.18.255.255 scope global br-d3699cfbd400       valid_lft forever preferred_lft forever    inet6 fe80::42:43ff:fe2c:6ca4/64 scope link       valid_lft forever preferred_lft forever<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="overlay：多机通信网络"><a class="header-anchor" href="#overlay：多机通信网络">¶</a>overlay：多机通信网络</h4><p>如下所示，现在在同一个宿主机上有一个 python 的 flask web 程序和 redis 容器，此时它们是可以通信的，网络类型是 bridge。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203530.png" alt="image-20201019175752528"></p><p>但是如果这两个容器分别位于不同的宿主机上，应该如何通信呢？如下所示，两个容器被分隔在不同的宿主机当前，假设当前宿主机的 local 域就是一个最大的内网域，那么它们发出的报文在当前宿主机的网络栈解析后发现目标地址是一个 local 域的内网地址，还不在当前主机路由表中，此时就会拒绝访问。</p><p>这种情况(跨网络的不同内网主机通信)一般是通过隧道的方式进行通信的，即将最原始的数据包封装到一个数据包中，从 192.168.205.10 发送到 192.168.205.11，接收方对数据包解析后得到真正的网络四要素进行处理，处理完后，再对响应报文进行封装回传… …原始数据包称为 underlay，封装后的数据包称为 overlay。docker 基于这种方案实现了多级网络通信。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203537.png" alt="image-20201019180427290"></p><h5 id="配置-overlay-网络："><a class="header-anchor" href="#配置-overlay-网络：">¶</a>配置 overlay 网络：</h5><h5 id="1-下载-etcd-并启动"><a class="header-anchor" href="#1-下载-etcd-并启动">¶</a>1&gt;下载 etcd 并启动</h5><p>docker engine 内部基于 overlay 的实现了分布式网络，使用了分布式存储 etcd 来存储分布式网络中的节点(容器)信息，所以我们要在各个宿主机上安装 etcd 并启动：</p><p>在 docker-node1 宿主机上安装 etcd 并启动：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 /]# wget https://github.com/etcd-io/etcd/releases/download/v3.3.25/etcd-v3.3.25-linux-amd64.tar.gz[root@docker-node1 /]# tar -zxf etcd-v3.3.25-linux-amd64.tar.gz[root@docker-node1 /]# cd etcd-v3.3.25-linux-amd64[root@docker-node1 etcd-v3.3.25-linux-amd64]# nohup ./etcd --name docker-node1 --initial-advertise-peer-urls http://192.168.205.10:2380 \> --listen-peer-urls http://192.168.205.10:2380 \> --listen-client-urls http://192.168.205.10:2379,http://127.0.0.1:2379 \> --advertise-client-urls http://192.168.205.10:2379 \> --initial-cluster-token etcd-cluster \> --initial-cluster docker-node1=http://192.168.205.10:2380,docker-node2=http://192.168.205.11:2380 \> --initial-cluster-state new&[1] 32761[root@docker-node1 etcd-v3.3.25-linux-amd64]# nohup: ignoring input and appending output to 'nohup.out'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 docker-node2 宿主机上安装 etcd 并启动：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 /]# wget https://github.com/etcd-io/etcd/releases/download/v3.3.25/etcd-v3.3.25-linux-amd64.tar.gz[root@docker-node1 /]# tar -zxf etcd-v3.3.25-linux-amd64.tar.gz[root@docker-node1 /]# cd etcd-v3.3.25-linux-amd64[root@docker-node2 etcd-v3.3.25-linux-amd64]# nohup ./etcd --name docker-node2 --initial-advertise-peer-urls http://192.168.205.11:2380 \> --listen-peer-urls http://192.168.205.11:2380 \> --listen-client-urls http://192.168.205.11:2379,http://127.0.0.1:2379 \> --advertise-client-urls http://192.168.205.11:2379 \> --initial-cluster-token etcd-cluster \> --initial-cluster docker-node1=http://192.168.205.10:2380,docker-node2=http://192.168.205.11:2380 \> --initial-cluster-state new&[1] 29667[root@docker-node2 etcd-v3.3.25-linux-amd64]# nohup: ignoring input and appending output to 'nohup.out'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 docker-node1 宿主机上查看 etcd 分布式存储健康状态：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 etcd-v3.3.25-linux-amd64]# ./etcdctl cluster-healthmember 21eca106efe4caee is healthy: got healthy result from http://192.168.205.10:2379member 8614974c83d1cc6d is healthy: got healthy result from http://192.168.205.11:2379cluster is healthy<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在 docker-node2 宿主机上查看 etcd 分布式存储健康状态：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node2 etcd-v3.3.25-linux-amd64]# ./etcdctl cluster-healthmember 21eca106efe4caee is healthy: got healthy result from http://192.168.205.10:2379member 8614974c83d1cc6d is healthy: got healthy result from http://192.168.205.11:2379cluster is healthy<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h5 id="2-重新启动-dockerd"><a class="header-anchor" href="#2-重新启动-dockerd">¶</a>2&gt;重新启动 dockerd</h5><p>etcd 安装好后，重启 dockerd 引擎连接 etcd：</p><p>docker-node1主机重启：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 etcd-v3.3.25-linux-amd64]# systemctl stop docker[root@docker-node1 etcd-v3.3.25-linux-amd64]# /usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --cluster-store=etcd://192.168.205.10:2379 --cluster-advertise=192.168.205.10:2375&<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>docker-node2主机重启：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node2 etcd-v3.3.25-linux-amd64]# systemctl stop docker[root@docker-node2 etcd-v3.3.25-linux-amd64]# /usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --cluster-store=etcd://192.168.205.11:2379 --cluster-advertise=192.168.205.11:2375&<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="3-创建-overlay-网络"><a class="header-anchor" href="#3-创建-overlay-网络">¶</a>3&gt;创建 overlay 网络</h5><p>在其中一台宿主机上创建一个名为 demo 的 overlay 类型的网络：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 etcd-v3.3.25-linux-amd64]# docker network lsNETWORK ID          NAME                DRIVER              SCOPE0209d911ddf0        bridge              bridge              local093639f6808b        host                host                local917d8e6230b0        none                null                local[root@docker-node1 etcd-v3.3.25-linux-amd64]# sudo docker network create -d overlay demo042b9fe688167f5263372dffddaff7cf1712bbf68e2bf5e276af0470707d02bd[root@docker-node1 etcd-v3.3.25-linux-amd64]# docker network lsNETWORK ID          NAME                DRIVER              SCOPE0209d911ddf0        bridge              bridge              local042b9fe68816        demo                overlay             global093639f6808b        host                host                local917d8e6230b0        none                null                local<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在另一台宿主机上也能查到这个网络的信息，可以知道两个安装了 etcd 的宿主机的信息是同步的：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node2 etcd-v3.3.25-linux-amd64]# docker network lsNETWORK ID          NAME                DRIVER              SCOPE7929f7d4a27a        bridge              bridge              local042b9fe68816        demo                overlay             global58598d4dd274        host                host                local5db4751f8c47        none                null                local[root@docker-node2 etcd-v3.3.25-linux-amd64]# docker inspect demo[    {        "Name": "demo",        "Id": "042b9fe688167f5263372dffddaff7cf1712bbf68e2bf5e276af0470707d02bd",        "Created": "2020-10-20T06:19:30.581789942Z",        "Scope": "global",        "Driver": "overlay",        "EnableIPv6": false,        "IPAM": {            "Driver": "default",            "Options": {},            "Config": [                {                    "Subnet": "10.0.0.0/24",                    "Gateway": "10.0.0.1"                }            ]        },        "Internal": false,        "Attachable": false,        "Ingress": false,        "ConfigFrom": {            "Network": ""        },        "ConfigOnly": false,        "Containers": {},        "Options": {},        "Labels": {}    }]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>而同步信息就是基于 etcd 来实现的，可以直接通过 <code>etcdctl</code> 工具查看具体存储的内容：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node2 etcd-v3.3.25-linux-amd64]# ./etcdctl ls /docker/nodes/docker/nodes/192.168.205.10:2375/docker/nodes/192.168.205.11:2375[root@docker-node2 etcd-v3.3.25-linux-amd64]# ./etcdctl ls /docker/network/v1.0/network/docker/network/v1.0/network/042b9fe688167f5263372dffddaff7cf1712bbf68e2bf5e276af0470707d02bd<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 node1 宿主机 run 一个 demo overlay 网络的名为 test1 的容器：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node1 etcd-v3.3.25-linux-amd64]# docker run -d --name test1 --network demo busybox /bin/sh -c "while true;do sleep 60;done"83bf9479fbabce2fa3297fbe469749cefec0ff6586dc5ac919ddebcab5bc96a3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>此时再在 node2 宿主机上 run 一个同网络同名的容器会报已存在：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node2 etcd-v3.3.25-linux-amd64]# docker run -d --name test1 --network demo busybox /bin/sh -c "while true;do sleep 60;done"docker: Error response from daemon: endpoint with name test1 already exists in network demo.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后 run 一个 demo overlay 网络的名为 test2 的容器，查看 demo 中包含了 test1 和 test2 的两个容器节点，ip 分别为 10.0.0.2 和 10.0.0.3</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node2 etcd-v3.3.25-linux-amd64]# docker run -d --name test2 --network demo busybox /bin/sh -c "while true;do sleep 60;done"7749fd634491a1bf7636cb693466b40bf04ea3559cd00784e898ffa24fac32ed[root@docker-node2 etcd-v3.3.25-linux-amd64]# docker inspect demo[    {        "Name": "demo",        "Id": "042b9fe688167f5263372dffddaff7cf1712bbf68e2bf5e276af0470707d02bd",        "Created": "2020-10-20T06:19:30.581789942Z",        "Scope": "global",        "Driver": "overlay",        "EnableIPv6": false,        "IPAM": {            "Driver": "default",            "Options": {},            "Config": [                {                    "Subnet": "10.0.0.0/24",                    "Gateway": "10.0.0.1"                }            ]        },        "Internal": false,        "Attachable": false,        "Ingress": false,        "ConfigFrom": {            "Network": ""        },        "ConfigOnly": false,        "Containers": {            "7749fd634491a1bf7636cb693466b40bf04ea3559cd00784e898ffa24fac32ed": {                "Name": "test2",                "EndpointID": "a61eb9838177fbedee02ad926480ac565bf4c43b29a2e8c56aa8de4bd9c1ebf1",                "MacAddress": "02:42:0a:00:00:03",                "IPv4Address": "10.0.0.3/24",                "IPv6Address": ""            },            "ep-2fc584506d058dd7d41dac1dcda9dd153abe8ff799a1e51edc9ec791e9ac757d": {                "Name": "test1",                "EndpointID": "2fc584506d058dd7d41dac1dcda9dd153abe8ff799a1e51edc9ec791e9ac757d",                "MacAddress": "02:42:0a:00:00:02",                "IPv4Address": "10.0.0.2/24",                "IPv6Address": ""            }        },        "Options": {},        "Labels": {}    }]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这时候两个容器就可以互通了：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node2 etcd-v3.3.25-linux-amd64]# docker exec test2 ping test1PING test1 (10.0.0.2): 56 data bytes64 bytes from 10.0.0.2: seq=0 ttl=64 time=0.860 ms64 bytes from 10.0.0.2: seq=1 ttl=64 time=1.102 ms<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>另外，我们再以 test2 容器为例，可以看到它的网络接口不只一个 10.0.0.3，还有一个 172.18.0.2，而 node2 宿主机的 docker 网络也增加了一个名为 docker_gwbridge 的 bridge 网络，通过 <code>ip a</code> 可以看到在宿主机上 docker_gwbridge 网桥的 ip 地址，而 15 号 <code>vethf2fc083@if14</code> 设备就是和 test2 的 14 号设备 <code>eth1@if15</code> 是一对 Veth。即在创建一个 overlay 网络的容器的时候，每个容器都创建了两个 Veth 设备，一个连接到宿主机的单独创建的网桥上，和宿主机进行通信，一个连接到他自己创建的一个虚拟设备上 。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-node2 etcd-v3.3.25-linux-amd64]# docker exec test2 ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever11: eth0@if12: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1450 qdisc noqueue    link/ether 02:42:0a:00:00:03 brd ff:ff:ff:ff:ff:ff    inet 10.0.0.3/24 brd 10.0.0.255 scope global eth0       valid_lft forever preferred_lft forever14: eth1@if15: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue    link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff    inet 172.18.0.2/16 brd 172.18.255.255 scope global eth1       valid_lft forever preferred_lft forever[root@docker-node2 etcd-v3.3.25-linux-amd64]# docker network lsNETWORK ID          NAME                DRIVER              SCOPE7929f7d4a27a        bridge              bridge              local042b9fe68816        demo                overlay             globalf780bd743e0a        docker_gwbridge     bridge              local58598d4dd274        host                host                local5db4751f8c47        none                null                local[root@docker-node2 etcd-v3.3.25-linux-amd64]# ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host       valid_lft forever preferred_lft forever2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic eth0       valid_lft 75314sec preferred_lft 75314sec    inet6 fe80::5054:ff:fe4d:77d3/64 scope link       valid_lft forever preferred_lft forever3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 08:00:27:45:8b:91 brd ff:ff:ff:ff:ff:ff    inet 192.168.205.11/24 brd 192.168.205.255 scope global noprefixroute eth1       valid_lft forever preferred_lft forever    inet6 fe80::a00:27ff:fe45:8b91/64 scope link       valid_lft forever preferred_lft forever4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default    link/ether 02:42:57:e6:8b:12 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0       valid_lft forever preferred_lft forever    inet6 fe80::42:57ff:fee6:8b12/64 scope link       valid_lft forever preferred_lft forever13: docker_gwbridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default    link/ether 02:42:2b:b0:6c:74 brd ff:ff:ff:ff:ff:ff    inet 172.18.0.1/16 brd 172.18.255.255 scope global docker_gwbridge       valid_lft forever preferred_lft forever    inet6 fe80::42:2bff:feb0:6c74/64 scope link       valid_lft forever preferred_lft forever15: vethf2fc083@if14: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker_gwbridge state UP group default    link/ether 62:e4:1c:73:ba:0a brd ff:ff:ff:ff:ff:ff link-netnsid 1    inet6 fe80::60e4:1cff:fe73:ba0a/64 scope link       valid_lft forever preferred_lft forever<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1>Docker 持久化存储</h1><p>写入容器的读写层的数据在容器删除后就没有了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203555.png" alt="image-20201018144042167"></p><p>通过一个特殊的方式将宿主机的一块磁盘 mount 到容器上，实现数据持久化</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203600.png" alt="image-20201020144507540"></p><h3 id="Docker-持久化数据方案"><a class="header-anchor" href="#Docker-持久化数据方案">¶</a>Docker 持久化数据方案</h3><ul><li><p>基于本地文件的 Volume。可以在执行 Docker create 或 Docker run 时，通过 <code>-v</code> 参数将主机的目录作为容器的数据卷。这部分功能便是基于本地文件系统的 volume 管理。</p><ul><li><p>Data Mounting：受管理的 data Volume，由 docker 后台自动创建，mount 到宿主机的随机路径</p><p>以 MySQL 官方提供的 Dockerfile 为例，以 VOLUME 指令指定了 <code>/var/lib/mysql</code> 为容器的 volume，指的是容器中的 <code>/var/lib/mysql</code> 路径会 mount 到宿主机中的一个路径。我们先 run 一个 MySQL 容器：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-host ~]# sudo docker run -d --name mysql1 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysqlUnable to find image 'mysql:latest' locallylatest: Pulling from library/mysqlbb79b6b2107f: Pull complete49e22f6fb9f7: Pull complete842b1255668c: Pull complete9f48d1f43000: Pull completec693f0615bce: Pull complete8a621b9dbed2: Pull complete0807d32aef13: Pull complete9eb4355ba450: Pull complete6879faad3b6c: Pull complete164ef92f3887: Pull complete6e4a6e666228: Pull completed45dea7731ad: Pull completeDigest: sha256:86b7c83e24c824163927db1016d5ab153a9a04358951be8b236171286e3289a4Status: Downloaded newer image for mysql:latest27e7c2dc9827d3dc485a97e36b71384abea77e634fc424f08b43865f52c989e3[root@docker-host ~]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                 NAMES27e7c2dc9827        mysql               "docker-entrypoint.s…"   12 seconds ago      Up 11 seconds       3306/tcp, 33060/tcp   mysql1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>查看 docker 的 volume 可以看到没有通过 <code>-v</code> 参数指定 volume 的时候，volume 的名称是一个随机 ID，每创建一个 mysql 容器就会新增一个 volume，此时我们停止删除容器后 volume 还在；通过 <code>docker volume inspect</code> 可以查看 volume mount 到了宿主机的哪一个路径；通过 <code>docker volume rm</code> 删除 volume：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-host ~]# docker volume lsDRIVER              VOLUME NAMElocal               d8d22755a81cef64966748478352b3fc807f013f90d44ced2b586bc3850007ed[root@docker-host ~]# docker volume inspect d8d22755a81cef64966748478352b3fc807f013f90d44ced2b586bc3850007ed[    {        "CreatedAt": "2020-10-20T07:26:05Z",        "Driver": "local",        "Labels": null,        "Mountpoint": "/var/lib/docker/volumes/d8d22755a81cef64966748478352b3fc807f013f90d44ced2b586bc3850007ed/_data",        "Name": "d8d22755a81cef64966748478352b3fc807f013f90d44ced2b586bc3850007ed",        "Options": null,        "Scope": "local"    }][root@docker-host ~]# sudo docker run -d --name mysql2 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql6550c8cdc4206c561107afd628b9b107fc88ea5aa562ef40fd7e86d25febc160[root@docker-host ~]# docker volume lsDRIVER              VOLUME NAMElocal               d8d22755a81cef64966748478352b3fc807f013f90d44ced2b586bc3850007edlocal               fec2daa7b61f5eef6ccc130fb76191374d65c18844d547afd384a69e7868b368[root@docker-host ~]# docker volume inspect fec2daa7b61f5eef6ccc130fb76191374d65c18844d547afd384a69e7868b368[    {        "CreatedAt": "2020-10-20T07:27:24Z",        "Driver": "local",        "Labels": null,        "Mountpoint": "/var/lib/docker/volumes/fec2daa7b61f5eef6ccc130fb76191374d65c18844d547afd384a69e7868b368/_data",        "Name": "fec2daa7b61f5eef6ccc130fb76191374d65c18844d547afd384a69e7868b368",        "Options": null,        "Scope": "local"    }][root@docker-host ~]#  docker stop mysql1 mysql2mysql1mysql2[root@docker-host ~]# docker rm mysql1 mysql2mysql1mysql2[root@docker-host ~]# docker volume lsDRIVER              VOLUME NAMElocal               d8d22755a81cef64966748478352b3fc807f013f90d44ced2b586bc3850007edlocal               fec2daa7b61f5eef6ccc130fb76191374d65c18844d547afd384a69e7868b368[root@docker-host ~]# docker volume rm d8d22755a81cef64966748478352b3fc807f013f90d44ced2b586bc3850007ed fec2daa7b61f5eef6ccc130fb76191374d65c18844d547afd384a69e7868b368d8d22755a81cef64966748478352b3fc807f013f90d44ced2b586bc3850007edfec2daa7b61f5eef6ccc130fb76191374d65c18844d547afd384a69e7868b368<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们通过 <code>-v</code> 参数指定 volume 的名称为 mysql，此时就可以实现 volume 的复用，删除 mysql1 容器后，新运行的 mysql2 可以基于 mysql1 的volume 继续运行，数据不会丢失，例如我们在 mysql1 中创建的数据库 docker 可以在 mysql2 中看到：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-host ~]# docker run -d -v mysql:/var/lib/mysql --name mysql1 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql0b02325ec880a7c37dfb482e12279bd4a9ef36d52622489cb024d7972cee12ee[root@docker-host ~]# docker volume lsDRIVER              VOLUME NAMElocal               mysql[root@docker-host ~]# docker exec -it mysql1 /bin/sh# exit[root@docker-host ~]# clear[root@docker-host ~]# docker exec -it mysql1 /bin/bashroot@0b02325ec880:/# mysql -urootWelcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 8Server version: 8.0.21 MySQL Community Server - GPLCopyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql> show databases;+--------------------+| Database           |+--------------------+| information_schema || mysql              || performance_schema || sys                |+--------------------+4 rows in set (0.02 sec)mysql> create database docker;Query OK, 1 row affected (0.01 sec)mysql> exitByeroot@0b02325ec880:/# exitexit[root@docker-host ~]# docker rm -f mysql1mysql1[root@docker-host ~]# docker volume lsDRIVER              VOLUME NAMElocal               mysql[root@docker-host ~]# docker run -d -v mysql:/var/lib/mysql --name mysql2 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql1c2ae7fc37ce41e8f40ac8e46c1926ad8a22fa79c92d42b953c147e1e4606aae[root@docker-host ~]# docker exec -it mysql2 /bin/bashroot@1c2ae7fc37ce:/# mysql -urootWelcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 8Server version: 8.0.21 MySQL Community Server - GPLCopyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql> show databases;+--------------------+| Database           |+--------------------+| docker             || information_schema || mysql              || performance_schema || sys                |+--------------------+5 rows in set (0.01 sec)mysql> exitBye<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>Bind Mouting：绑定挂载的 Volume，具体挂载位置可以由用户指定，即 mount 到用户指定路径。<code>-v</code> 参数有三个字段，字段之间由&quot;:&quot;冒号分隔</p><ul><li>第一个字段表示 mount 到宿主机中的路径，如果以&quot;/&quot;斜杠开头，则表示绝对路径，此时就是 Bind Mouting 模式，宿主机中的 mount 路径由用户指定；如果不以斜杠开头或者省略为空，此时表示相对路径，如果省略没写，docker就会生成一个随机的ID作为该相对路径，此时就是上面介绍的 Data Mounting 模式。记相对路径为<code>${related_path}</code>，此时会 Mount 到宿主机的 <code>var/lib/docker/volumes/${related_path}</code> 上，并以 <code>${related_path}</code> 作为该 volume 的命名。</li><li>第二个字段表示容器中要 mount 的路径</li><li>第三个字段表示容器中该路径的操作权限，如只读</li></ul><p>Data Mounting 主要是容器中要产生数据，为了保证数据不随着容器删除而丢失使用的；Bind Mounting 则是宿主机也会产生数据，例如源代码等，方便直接在宿主机中进行修改。</p></li></ul></li><li><p>基于 plugin 的 Volume，支持第三方的存储方案，比如 NAS，aws。</p></li></ul><h1>Docker Compose</h1><ul><li>Docker Compose 是一个工具</li><li>这个工具可以通过一个 yml 文件定义多容器的 docker 应用</li><li>通过一条命令就可以根据 yml 文件的定义去创建或者管理这多个容器\</li><li>version2 格式的文件只能通过 docker-compose 部署在一个主机；version3 格式的文件可以通过 docker stack 命令通过 swarm 架构部署多机网络</li></ul><p>yml 文件默认名字 <code>docker-compose.yml</code>，可以改。它有三大关键概念：</p><ul><li><p>Services</p><ul><li><p>一个 service 代表一个 container，这个 container 可以用从 dockerhub 的 image 来创建，或者从本地的 Dockerfile build 出来的 image 来创建</p></li><li><p>Service 的启动类似 docker run，我们可以给其指定 network 和 volume，所以可以给 service 指定 network 和 volume 的引用</p></li><li><p>例子：</p><ul><li><p>下面是一个名为 db 的 service，image 表示从 docker hub 拉取镜像</p><pre><code>services:db:image: postgres:9.4volume:- &quot;db-data:/var/lib/postgresql/data&quot; # 引用一个名为 db-data 的 volumenetworks:- back-tier # 引用一个名为 back-tier 的network</code></pre><p>类似</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">docker run -d --network back-tier -v db-data:/var/lib/postgresql/data postgres:9.4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>services 包含一个 worker 的service，build 指定 Dockerfile 所在目录，表示要自己 build 镜像，不去 docker hub 拉取。另外，还有一个 links，表示的就是 <code>--link</code> 参数</p><pre><code>services:worker:build: ./workerlinks:- db- redis    networks:    - back-tier</code></pre></li></ul></li></ul></li><li><p>Networks</p><pre><code>volumes:db-data:</code></pre><p>类似</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">docker volume create db-data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>Volumes</p><pre><code>networks:front-tier:driver: bridgeback-tier:driver: bridge</code></pre><p>类似</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">docker network create -d bridge front-tierdocker network create -d bridge back-tier<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><h3 id="整体例子"><a class="header-anchor" href="#整体例子">¶</a>整体例子</h3><p>下面是一个启动 wordpress 博客服务的 docker compose yml 文件</p><pre><code>version: '3' # 指定 version 3 的 docker compose 格式services:  wordpress:    image: wordpress    ports: # 指定端口映射，-p 参数      - 8080:80    environment: # 设置环境变量 -e 参数      WORDPRESS_DB_HOST: mysql      WORDPRESS_DB_PASSWORD: root    networks: # 引用网络      - my-bridge  mysql:    image: mysql    environment:      MYSQL_ROOT_PASSWORD: root      MYSQL_DATABASE: wordpress    volumes:      - mysql-data:/var/lib/mysql    networks:      - my-bridgevolumes:  mysql-data:networks:  my-bridge:    driver: bridge # 网络类型</code></pre><p>它的作用类似于以下 docker 命令，不过它们的网络构建方式不一样，docker compose 文件里面使用了自定义 bridge 网络，下面的 docker 命令使用了 <code>--link</code>：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-host docker-nginx]# docker run -d --name mysql -v mysql-data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=wordpress mysql4a37f84fe3e870df8e3959c00f118ca6b858f7aa820b56fb3e9410add47240e3[root@docker-host docker-nginx]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                 NAMES4a37f84fe3e8        mysql               "docker-entrypoint.s…"   8 seconds ago       Up 7 seconds        3306/tcp, 33060/tcp   mysql[root@docker-host docker-nginx]# docker run -d -e WORDPRESS_DB_HOST=mysql:3306 --link mysql -p 8080:80 wordpress1eb7f0c302c76ff38e645f48c0ab8633d16ccb839bd6c0095a72b75f957c4411[root@docker-host docker-nginx]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                  NAMES1eb7f0c302c7        wordpress           "docker-entrypoint.s…"   4 seconds ago       Up 4 seconds        0.0.0.0:8080->80/tcp   confident_chaplygin4a37f84fe3e8        mysql               "docker-entrypoint.s…"   5 minutes ago       Up 5 minutes        3306/tcp, 33060/tcp    mysql<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="命令"><a class="header-anchor" href="#命令">¶</a>命令</h3><p>需要注意的是 docker compose 指定必须基于一个 yml 文件执行，也就是说如果没有通过 <code>-f</code> 指定 yml 文件，就必须 <code>cd</code> 到 yml 文件所在目录执行 <code>docker-compose</code> 命令；另外 <code>docker-compose</code> 创建的容器的名称是会拼接一定前缀保证唯一的，所以使用 <code>docker-compose</code> 直接对 yml 文件中定义的名称进行操作是可以的，但是使用 <code>docker</code> 的命令就不行了，此时需要完全名称。</p><ul><li><p><code>docker-compose up</code> 执行该 yml 文件</p><ul><li><code>-d</code> 后台运行，不输出日志到终端</li><li><code>--scale &lt;service-name&gt;=&lt;run-num-of-container&gt;</code> 来运行指定数量的指定 service 容器，相当于水平扩展，需要注意该 service 的 yml 定义中是否硬编码绑定到了宿主机中的同一端口，会产生冲突。<code>docker-compose</code> 的 <code>scale</code> 只能在单机上做水平扩展。</li></ul></li><li><p><code>docker-compose ps</code> 列出指定容器状态</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@docker-host wordpress]# docker-compose ps        Name                       Command               State          Ports-------------------------------------------------------------------------------------wordpress_mysql_1       docker-entrypoint.sh mysqld      Up      3306/tcp, 33060/tcpwordpress_wordpress_1   docker-entrypoint.sh apach ...   Up      0.0.0.0:8080->80/tcp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><code>docker-compose stop</code> 停止</p></li><li><p><code>docker-compose down</code> 停止并删除容器、网络、volume等，不删除 image</p></li><li><p><code>docker-compose start</code> 启动</p></li><li><p><code>docker-compose images</code> 列举出 yml 文件中容器用到的 images</p></li><li><p><code>docker-compose exec</code> 和 docker 的 exec 基本一致</p></li><li><p><code>docker-compose build</code> 拉取和 build services 需要的镜像；当镜像更新的时候也要使用这个命令然后再 <code>docker-compose up</code>。</p></li></ul><h1>Docker Swarm</h1><p>在单机情况下使用<code>Docker run</code>和<code>Docker-compose</code>：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203616.png" alt="image-20201021094647857"></p><p>此时会遇到以下问题：</p><ul><li>如何管理这么容器？</li><li>怎么能方便地横向扩展？</li><li>如果容器down了，怎么能自动恢复？</li><li>如何去更新容器而不影响业务？</li><li>如何去监控追踪这些容器？</li><li>怎么去调度容器的创建？</li><li>如何保护隐私数据？</li></ul><h3 id="SWARM-模式"><a class="header-anchor" href="#SWARM-模式">¶</a>SWARM 模式</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203621.png" alt="image-20201021094741226"></p><h4 id="架构图"><a class="header-anchor" href="#架构图">¶</a>架构图</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203631.png" alt="image-20201021094932725"></p><ul><li>Manager 节点至少有两个，内置分布式存储数据库，通过 Raft 协议同步数据，不会出现脑裂。</li><li>Worker 节点是实际工作节点，通过 Gossip Work 同步数据。</li></ul><h4 id="service-和-replica"><a class="header-anchor" href="#service-和-replica">¶</a>service 和 replica</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203637.png" alt="image-20201021095239081"></p><p>一个服务可以创建多个副本进行水平横向扩展，根据实际资源调度到不同的 Worker 节点中运行。</p><h4 id="执行流程"><a class="header-anchor" href="#执行流程">¶</a>执行流程</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203646.png" alt="image-20201021095423706"></p><h3 id="使用"><a class="header-anchor" href="#使用">¶</a>使用</h3><h4 id="命令-v2"><a class="header-anchor" href="#命令-v2">¶</a>命令</h4><p><code>docker</code></p><ul><li><code>swam</code>：操作 swarm 集群<ul><li><code>init</code>：初始化一个 swam 集群，当前节点称为一个 manager 节点<ul><li><code>--advertise-addr &lt;addr_string&gt;</code>：向别的 swam 节点公告自己的地址，以这个地址为自己的沟通方式</li></ul></li><li><code>join</code>：当前节点作为 worker 节点加入一个 swam 集群<ul><li><code>--token &lt;token_string&gt;</code>：指定要加入集群的 token</li></ul></li></ul></li><li><code>node</code>：查看 swam 集群信息<ul><li><code>ls</code>：查看 swarm 集群中的所有节点，只能在 manager 节点运行</li></ul></li><li><code>service</code>：service 相关操作<ul><li><code>create</code>：创建一个 service，不一定运行在本地，根据实际调度</li><li><code>ls</code>：查看所有 services 的概览信息</li><li><code>ps &lt;container-name-or-id&gt;</code>：查看指定 service 的详细信息，包括运行在哪个节点</li><li><code>scale &lt;service-name&gt;=&lt;replicas-num&gt; [&lt;service-name&gt;=&lt;replicas-num&gt;...]</code>：可以对多个服务进行横向扩展，指定它们的副本数量，默认副本数量就是 1，即不会扩展。<code>scale</code> 可以自动恢复。</li><li><code>rm &lt;service-name&gt; [&lt;service-name&gt;...]</code>：删除指定 service。</li></ul></li></ul><h4 id="创建一个3个节点的集群"><a class="header-anchor" href="#创建一个3个节点的集群">¶</a>创建一个3个节点的集群</h4><p>在 swarm-manager 主机上初始化一个 swarm 集群</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker swarm init --advertise-addr=192.168.205.10Swarm initialized: current node (16le9my05jir8fjagatlcxx2c) is now a manager.To add a worker to this swarm, run the following command:    docker swarm join --token SWMTKN-1-5ftx7ja9b2c20rhkheu2dnms06j4t646rkiwjbkcns1hhwa4rk-6l0kapgwbsea66pih6cvxmu3k 192.168.205.10:2377To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>分别在 swarm-worker1 和 swarm-worker2 上作为 worker 节点加入到集群</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-worker1 ~]# docker swarm join --token SWMTKN-1-5ftx7ja9b2c20rhkheu2dnms06j4t646rkiwjbkcns1hhwa4rk-6l0kapgwbsea66pih6cvxmu3k 192.168.205.10:2377This node joined a swarm as a worker.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-worker2 ~]# docker swarm join --token SWMTKN-1-5ftx7ja9b2c20rhkheu2dnms06j4t646rkiwjbkcns1hhwa4rk-6l0kapgwbsea66pih6cvxmu3k 192.168.205.10:2377This node joined a swarm as a worker.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>回到 swarm-manager 主机上查看集群节点</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker node lsID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION16le9my05jir8fjagatlcxx2c *   swarm-manager       Ready               Active              Leader              19.03.13p9026oe5ws78l7vpoj2b342q0     swarm-worker1       Ready               Active                                  19.03.133zilh3e4keprghwftsv3g7doi     swarm-worker2       Ready               Active                                  19.03.13<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="在-manager-上创建-service"><a class="header-anchor" href="#在-manager-上创建-service">¶</a>在 manager 上创建 service</h4><p>通过<code>docker service create</code>创建一个 service，通过 <code>docker service ps</code> 命令看到这个 service 运行在当前 manager 节点上，通过 <code>docker ps</code> 看到创建的容器名称并不是我们指定的 service 名称，而是做了一些拼接保证唯一。<code>docker service ls</code>可以看到这个节点的模式是可扩展的，副本只有一份，也就是还没有扩展。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker service create --name demo busybox sh -c "while true;do sleep 60;done" vtfjx1iw3mdfwdwakqs5jyxepoverall progress: 1 out of 1 tasks1/1: running   [==================================================>]verify: Service converged[root@swarm-manager ~]#  docker service lsID                  NAME                MODE                REPLICAS            IMAGE               PORTSvtfjx1iw3mdf        demo                replicated          1/1                 busybox:latest[root@swarm-manager ~]# docker service ps demoID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE                ERROR               PORTS9oaa1o7f0fb5        demo.1              busybox:latest      swarm-manager       Running             Running about a minute ago[root@swarm-manager ~]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES050d6438f24d        busybox:latest      "sh -c 'while true;d…"   2 minutes ago       Up 2 minutes                            demo.1.9oaa1o7f0fb5l1mjmovv6fxyd<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="动态横向扩展"><a class="header-anchor" href="#动态横向扩展">¶</a>动态横向扩展</h4><p>上面已经运行了一个 service，再次通过 <code>docker service scale</code> 命令指定副本数量为5，即再扩展4个service。<code>docker service ls</code>的 <code>REPLICAS</code> 的分子表示 ready 的副本数量，分母表示 <code>scale</code> 指令指定的副本数量：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker service scale demo=5demo scaled to 5overall progress: 5 out of 5 tasks1/5: running   [==================================================>]2/5: running   [==================================================>]3/5: running   [==================================================>]4/5: running   [==================================================>]5/5: running   [==================================================>]verify: Service converged[root@swarm-manager ~]# docker service lsID                  NAME                MODE                REPLICAS            IMAGE               PORTSvtfjx1iw3mdf        demo                replicated          5/5                 busybox:latest[root@swarm-manager ~]# docker service ps demoID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS9oaa1o7f0fb5        demo.1              busybox:latest      swarm-manager       Running             Running 10 minutes agokfevbmud5rlo        demo.2              busybox:latest      swarm-worker2       Running             Running 2 minutes ago0c9ol7s99ajw        demo.3              busybox:latest      swarm-worker2       Running             Running 2 minutes agoid6r217b847s        demo.4              busybox:latest      swarm-manager       Running             Running 2 minutes agoz3nk7cethkao        demo.5              busybox:latest      swarm-worker1       Running             Running 2 minutes ago<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="自动恢复"><a class="header-anchor" href="#自动恢复">¶</a>自动恢复</h4><p>先在随意一个节点删除一个 service：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-worker2 ~]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES9c21a650f557        busybox:latest      "sh -c 'while true;d…"   5 minutes ago       Up 5 minutes                            demo.3.0c9ol7s99ajwc80uz224lwew84938879da7fe        busybox:latest      "sh -c 'while true;d…"   5 minutes ago       Up 5 minutes                            demo.2.kfevbmud5rlotwmn7xmdk1q2a[root@swarm-worker2 ~]# docker rm -f 4938879da7fe4938879da7fe<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到 REPLICAS 的 ready 数量减 1：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker service lsID                  NAME                MODE                REPLICAS            IMAGE               PORTSvtfjx1iw3mdf        demo                replicated          4/5                 busybox:latest<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>再次查看的时候，发现恢复成 5 了</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker service lsID                  NAME                MODE                REPLICAS            IMAGE               PORTSvtfjx1iw3mdf        demo                replicated          5/5                 busybox:latest<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="swarm-模式的多机网络"><a class="header-anchor" href="#swarm-模式的多机网络">¶</a>swarm 模式的多机网络</h4><p>先使用 <code>docker network create</code> 创建一个 overlay 网络</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker network create -d overlay demo88eid380la4nk4cbm4j6fg7ji[root@swarm-manager ~]# docker network lsNETWORK ID          NAME                DRIVER              SCOPE73fb8708e978        bridge              bridge              local88eid380la4n        demo                overlay             swarm7c337a10f364        docker_gwbridge     bridge              local7e166669d3c0        host                host                localid0v0fnkkaz6        ingress             overlay             swarm1f203646282a        none                null                local<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>此时在其它节点上还没能看到这个网络：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-worker2 ~]# docker network lsNETWORK ID          NAME                DRIVER              SCOPEfa22d819b3a6        bridge              bridge              local1852f7d5af51        docker_gwbridge     bridge              localbebcfcafd9b1        host                host                localid0v0fnkkaz6        ingress             overlay             swarmc47aacb76a84        none                null                local<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 manager 上启动 mysql service 和 wordpress service，其中可以看到 wordpress service 被分配到了 worker2 主机上：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker service create --name mysql --env MYSQL_ROOT_PASSWORD=root --env MYSQL_DATABASE=wordpress --network demo --mount type=volume,source=mysql,destination=/var/lib/mysql mysql[root@swarm-manager ~]# docker service create --name mysql --env MYSQL_ROOT_PASSWORD=root --env MYSQL_DATABASE=wordpress --network demo --mount type=volume,source=mysql,destination=/var/lib/mysql mysql9iq09p6da4vbmeu1mvdmzrl2noverall progress: 1 out of 1 tasks1/1: running   [==================================================>]verify: Service converged[root@swarm-manager ~]# docker service lsID                  NAME                MODE                REPLICAS            IMAGE               PORTS9iq09p6da4vb        mysql               replicated          1/1                 mysql:latest[root@swarm-manager ~]# docker service create --name wordpress -p 80:80 --env WORDPRESS_DB_PASSWORD=root --env WORDPRESS_DB_HOST=mysql --network demo wordpresslm7s3n6oaw47nt46ge13mt5g3overall progress: 1 out of 1 tasks1/1: running   [==================================================>]verify: Service converged[root@swarm-manager ~]# docker service lsID                  NAME                MODE                REPLICAS            IMAGE               PORTS9iq09p6da4vb        mysql               replicated          1/1                 mysql:latestlm7s3n6oaw47        wordpress           replicated          1/1                 wordpress:latest    *:80->80/tcp[root@swarm-manager ~]# docker service ps wordpressID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE                ERROR               PORTSb5n9cnap232j        wordpress.1         wordpress:latest    swarm-worker2       Running             Running about a minute ago<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>此时到 worker2 节点上查看网络已经可以看到 demo overlay 网络：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-worker2 ~]# docker network lsNETWORK ID          NAME                DRIVER              SCOPEfa22d819b3a6        bridge              bridge              local88eid380la4n        demo                overlay             swarm1852f7d5af51        docker_gwbridge     bridge              localbebcfcafd9b1        host                host                localid0v0fnkkaz6        ingress             overlay             swarmc47aacb76a84        none                null                local<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>所以在 swarm 模式下实现多机通信网络已经不需要额外的分布式存储 etcd 来实现了。此外，wordpress 容器运行在 worker2 节点上，但是实际上三个节点的 ip 地址都能访问：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203656.png" alt="image-20201021112330794"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203701.png" alt="image-20201021112446081"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203708.png" alt="image-20201021112501116"></p><h4 id="网络说明"><a class="header-anchor" href="#网络说明">¶</a>网络说明</h4><p>无论是 docker-compose 还是 docker swarm 创建的 service 都能通过 service 名称进行通信，这是在 Docker Engine 内部实现了一个 DNS 服务，service name 直接指向的是 service 所在 overlay 网络的虚拟 ip 地址，这个虚拟地址后面再指向容器实际的 ip 地址，因为容器的实际 ip 地址是会变化的：</p><ul><li>service down 掉重启可能会调度到不同的 host 上了，此时 ip 地址变化</li><li>直接被调度到不同 host 上，ip 地址变化</li><li>scale 多个副本进行水平扩展，此时一个 service 其实有多个实际 ip 地址</li></ul><p>而 service 的 ip 不会变。service 的虚拟 ip 地址和容器的实际 ip 地址是通过 LVS 实现映射和负载均衡的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203713.png" alt="image-20201021113415018"></p><h5 id="示例说明"><a class="header-anchor" href="#示例说明">¶</a>示例说明</h5><p>先启动一个 whoami 的服务，这个服务会在 8000 端口运行，当访问它的时候会返回主机名。然后再起一个名为 client 的 busybox 的服务，后续会在 busybox 里面尝试 ping whoami 服务。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker service create --name whoami -p 8000:8000 --network demo -d jwilder/whoamij0d5g1wbfckk2jdtqb3fnt00g[root@swarm-manager ~]# docker service lsID                  NAME                MODE                REPLICAS            IMAGE                   PORTSj0d5g1wbfckk        whoami              replicated          1/1                 jwilder/whoami:latest   *:8000->8000/tcp[root@swarm-manager ~]# docker service ps whoamiID                  NAME                IMAGE                   NODE                DESIRED STATE       CURRENT STATE           ERROR               PORTSireyqp5j9gj3        whoami.1            jwilder/whoami:latest   swarm-worker1       Running             Running 3 minutes ago[root@swarm-manager ~]# curl 127.0.0.1:8000I'm 7d6a8c51c9d5[root@swarm-manager ~]# docker service create --name client -d --network demo busybox sh -c "while true;do sleep 60;done"ss6z96qypr8ezsubmy51jgeej[root@swarm-manager ~]# docker service lsID                  NAME                MODE                REPLICAS            IMAGE                   PORTSss6z96qypr8e        client              replicated          1/1                 busybox:latestj0d5g1wbfckk        whoami              replicated          1/1                 jwilder/whoami:latest   *:8000->8000/tcp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>docker service ps</code> 查看到 busybox 服务是在本机运行的，直接进行 busybox 服务 ping whoami 服务，得到返回 ip 地址是 10.0.1.13：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker service ps clientID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTSwe6rr1uirf0t        client.1            busybox:latest      swarm-manager       Running             Running 24 seconds ago[root@swarm-manager ~]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS               NAMES01f1dc5f93d0        busybox:latest      "sh -c 'while true;d…"   About a minute ago   Up About a minute                       client.1.we6rr1uirf0tbin4dr4ftt7fk[root@swarm-manager ~]# docker exec -it 01f1dc5f93d0 sh/ # ping whoamiPING whoami (10.0.1.13): 56 data bytes64 bytes from 10.0.1.13: seq=0 ttl=64 time=0.339 ms64 bytes from 10.0.1.13: seq=1 ttl=64 time=0.189 ms64 bytes from 10.0.1.13: seq=2 ttl=64 time=0.187 ms^C--- whoami ping statistics ---3 packets transmitted, 3 packets received, 0% packet lossround-trip min/avg/max = 0.187/0.238/0.339 ms/ #<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当我们横向扩展 whoami 服务为两个容器之后，新的容器被调度在 worker2 节点，再次进入 busybox ping whoami 发现 ip 还是 10.0.0.13，也就是说服务扩展后它的 ip 没有变化：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker service scale whoami=2whoami scaled to 2overall progress: 2 out of 2 tasks1/2: running   [==================================================>]2/2: running   [==================================================>]verify: Service converged[root@swarm-manager ~]# docker service ps whoamiID                  NAME                IMAGE                   NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTSireyqp5j9gj3        whoami.1            jwilder/whoami:latest   swarm-worker1       Running             Running 2 hours agoz0prnv2sbzwz        whoami.2            jwilder/whoami:latest   swarm-worker2       Running             Running 24 seconds ago[root@swarm-manager ~]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES01f1dc5f93d0        busybox:latest      "sh -c 'while true;d…"   2 hours ago         Up 2 hours                              client.1.we6rr1uirf0tbin4dr4ftt7fk[root@swarm-manager ~]# docker exec -it 01f1dc5f93d0 sh/ # ping whoamiPING whoami (10.0.1.13): 56 data bytes64 bytes from 10.0.1.13: seq=0 ttl=64 time=0.121 ms64 bytes from 10.0.1.13: seq=1 ttl=64 time=0.124 ms^C--- whoami ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.121/0.122/0.124 ms/ # exit[root@swarm-manager ~]#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 worker1 节点中查看服务 whoami 的第一个容器，发现它没有上面 ping 返回的 10.0.0.13 ip：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-worker1 ~]# docker psCONTAINER ID        IMAGE                   COMMAND             CREATED             STATUS              PORTS               NAMES7d6a8c51c9d5        jwilder/whoami:latest   "/app/http"         2 hours ago         Up 2 hours          8000/tcp            whoami.1.ireyqp5j9gj3cu6sx61fbmie1[root@swarm-worker1 ~]# docker exec 7d6a8c51c9d5 ip a | grep 10.0.0.13[root@swarm-worker1 ~]# docker exec 7d6a8c51c9d5 ip a | grep inet    inet 127.0.0.1/8 scope host lo    inet 10.0.0.11/24 brd 10.0.0.255 scope global eth1    inet 172.18.0.3/16 brd 172.18.255.255 scope global eth2    inet 10.0.1.14/24 brd 10.0.1.255 scope global eth0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>woker2 中的新的容器也没有：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-worker2 ~]# docker exec 1ed0b9d6310d ip a | grep 10.0.0.13[root@swarm-worker2 ~]# docker exec 1ed0b9d6310d ip a | grep inet    inet 127.0.0.1/8 scope host lo    inet 10.0.0.12/24 brd 10.0.0.255 scope global eth1    inet 172.18.0.3/16 brd 172.18.255.255 scope global eth2    inet 10.0.1.19/24 brd 10.0.1.255 scope global eth0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>重新进入 busybox ，使用 <code>nslookup</code> 工具进行 DNS 查找 “whoami”，发现返回的 DNS Server 地址是 127.0.0.11:53，这个就是 docker engine 内部实现的 DNS 服务；另外，当我们查找 “tasks.whoami” 的时候，发现返回了两个 ip 地址，这两个 ip 地址就是我们上面在 work1 和 work2 中分别查询到的容器的实际 ip 之一：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES01f1dc5f93d0        busybox:latest      "sh -c 'while true;d…"   2 hours ago         Up 2 hours                              client.1.we6rr1uirf0tbin4dr4ftt7fk[root@swarm-manager ~]# docker exec -it 01f1dc5f93d0 sh/ # nslookup -type=a whoamiServer:127.0.0.11Address:127.0.0.11:53Non-authoritative answer:Name:whoamiAddress: 10.0.1.13/ # nslookup -type=a tasks.whoamiServer:127.0.0.11Address:127.0.0.11:53Non-authoritative answer:Name:tasks.whoamiAddress: 10.0.1.19Name:tasks.whoamiAddress: 10.0.1.14/ # exit<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>再扩展一个容器的时候，此时容器数量为3：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker service scale whoami=3whoami scaled to 3overall progress: 3 out of 3 tasks1/3: running   [==================================================>]2/3: running   [==================================================>]3/3: running   [==================================================>]verify: Service converged[root@swarm-manager ~]# docker service ps whoamiID                  NAME                IMAGE                   NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTSireyqp5j9gj3        whoami.1            jwilder/whoami:latest   swarm-worker1       Running             Running 2 hours agoz0prnv2sbzwz        whoami.2            jwilder/whoami:latest   swarm-worker2       Running             Running 27 minutes agoo6qod1li5v2t        whoami.3            jwilder/whoami:latest   swarm-manager       Running             Running 23 seconds ago[root@swarm-manager ~]# docker exec ee75ad6b35b8 ip a | grep inet    inet 127.0.0.1/8 scope host lo    inet 10.0.0.13/24 brd 10.0.0.255 scope global eth1    inet 172.18.0.4/16 brd 172.18.255.255 scope global eth2    inet 10.0.1.21/24 brd 10.0.1.255 scope global eth0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后重新进入 busybox 使用 nslookup 查看 “tasks.whoami”，查找了该容器的 ip 地址 10.0.1.21：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker exec -it 01f1dc5f93d0 sh/ # nslookup -type=a tasks.whoamiServer:127.0.0.11Address:127.0.0.11:53Non-authoritative answer:Name:tasks.whoamiAddress: 10.0.1.19Name:tasks.whoamiAddress: 10.0.1.21Name:tasks.whoamiAddress: 10.0.1.14<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后分别调用三次 whoami 服务，发现三次返回的主机名都不一样，所以这三次服务执行分别是三个不同的容器执行的，这就是由 LVS 负载均衡实现的：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">/ # wget whoami:8000 -O - -qI'm ee75ad6b35b8/ # wget whoami:8000 -O - -qI'm 1ed0b9d6310d/ # wget whoami:8000 -O - -qI'm 7d6a8c51c9d5<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="Routing-Mesh-的两种体现"><a class="header-anchor" href="#Routing-Mesh-的两种体现">¶</a>Routing Mesh 的两种体现</h5><p>通过上面例子可以看出 docker-compose 和 docker swarm 的 overlay 网络和之前通过 etcd 实现的 overlay 网络（VXLAN tuunel）是不一样的，前者是 docker engine 内部实现的。</p><ul><li><p>Internal：Container 和 Container 之间的访问通过 overlay 网络的 VIP（虚拟IP）进行，如果一个服务有做横向扩展，会实现负载均衡：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203725.png" alt="image-20201021142353794"></p><ul><li><p>DNS + VIP + iptables + LVS</p><p>client 容器发起一个请求先走内部的 DNS 解析得到 VIP 后走 iptables 和 IPVS (LVS)根据要访问的服务和端口负载均衡到其中一个容器上：<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203731.png" alt="image-20201021142449489"></p></li></ul></li><li><p>Ingress：如果服务有绑定接口，则此服务可以通过任意 swarm 节点的相应接口访问（就是上面提到的 wordpress 只有一个容器但是在三个节点上都可以访问的情况）</p><ul><li>外部访问的负载均衡</li><li>服务端口被暴露到各个 swarm 节点</li><li>内部通过 IPVS 进行负载均衡</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203746.png" alt="image-20201021144423361"></p></li></ul><h5 id="Ingress-Network-的示例说明"><a class="header-anchor" href="#Ingress-Network-的示例说明">¶</a>Ingress Network 的示例说明</h5><p>查看当前 swarm 中存在的 whoami 服务的容器</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker service ps whoamiID                  NAME                IMAGE                   NODE                DESIRED STATE       CURRENT STATE               ERROR               PORTSireyqp5j9gj3        whoami.1            jwilder/whoami:latest   swarm-worker1       Running             Running 3 hours agoz0prnv2sbzwz        whoami.2            jwilder/whoami:latest   swarm-worker2       Running             Running about an hour ago[root@swarm-manager ~]# curl 127.0.0.1:8000I'm 1ed0b9d6310d[root@swarm-manager ~]# curl 127.0.0.1:8000I'm 7d6a8c51c9d5<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到 iptables nat 端口映射规则表中最后有一条 DOCKER-INGRESS 规则链，其中有一条 DNAT 转发规则，将访问 tcp、8000端口的数据包转发到 172.18.0.2:8000 这个接口；</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# iptables -nL -t natChain PREROUTING (policy ACCEPT)target     prot opt source               destinationDOCKER-INGRESS  all  --  0.0.0.0/0            0.0.0.0/0            ADDRTYPE match dst-type LOCALDOCKER     all  --  0.0.0.0/0            0.0.0.0/0            ADDRTYPE match dst-type LOCALChain INPUT (policy ACCEPT)target     prot opt source               destinationChain OUTPUT (policy ACCEPT)target     prot opt source               destinationDOCKER-INGRESS  all  --  0.0.0.0/0            0.0.0.0/0            ADDRTYPE match dst-type LOCALDOCKER     all  --  0.0.0.0/0           !127.0.0.0/8          ADDRTYPE match dst-type LOCALChain POSTROUTING (policy ACCEPT)target     prot opt source               destinationMASQUERADE  all  --  0.0.0.0/0            0.0.0.0/0            ADDRTYPE match src-type LOCALMASQUERADE  all  --  172.18.0.0/16        0.0.0.0/0MASQUERADE  all  --  172.17.0.0/16        0.0.0.0/0Chain DOCKER (2 references)target     prot opt source               destinationRETURN     all  --  0.0.0.0/0            0.0.0.0/0RETURN     all  --  0.0.0.0/0            0.0.0.0/0Chain DOCKER-INGRESS (2 references)target     prot opt source               destinationDNAT       tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:8000 to:172.18.0.2:8000RETURN     all  --  0.0.0.0/0            0.0.0.0/0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>查看宿主机的所有接口，发现有一个名为 docker_gwbridge 的网桥，它的 ip 地址是 172.18.0.1/16，可以看出它和 172.18.0.2 是在同一个网段的，大体上可以猜到上面的 nat 转发是转发到了连接在这个网桥上的其中一端 Veth 设备：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host       valid_lft forever preferred_lft forever2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 52:54:00:4d:77:d3 brd ff:ff:ff:ff:ff:ff    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic eth0       valid_lft 70039sec preferred_lft 70039sec    inet6 fe80::5054:ff:fe4d:77d3/64 scope link       valid_lft forever preferred_lft forever3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 08:00:27:25:ee:82 brd ff:ff:ff:ff:ff:ff    inet 192.168.205.10/24 brd 192.168.205.255 scope global noprefixroute eth1       valid_lft forever preferred_lft forever    inet6 fe80::a00:27ff:fe25:ee82/64 scope link       valid_lft forever preferred_lft forever4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default    link/ether 02:42:78:26:0a:2f brd ff:ff:ff:ff:ff:ff    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0       valid_lft forever preferred_lft forever    inet6 fe80::42:78ff:fe26:a2f/64 scope link       valid_lft forever preferred_lft forever9: docker_gwbridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default    link/ether 02:42:fe:ab:b0:37 brd ff:ff:ff:ff:ff:ff    inet 172.18.0.1/16 brd 172.18.255.255 scope global docker_gwbridge       valid_lft forever preferred_lft forever    inet6 fe80::42:feff:feab:b037/64 scope link       valid_lft forever preferred_lft forever11: veth599d221@if10: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker_gwbridge state UP group default    link/ether 9a:8d:28:87:2f:e1 brd ff:ff:ff:ff:ff:ff link-netnsid 1    inet6 fe80::988d:28ff:fe87:2fe1/64 scope link       valid_lft forever preferred_lft forever29: veth752a46e@if28: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker_gwbridge state UP group default    link/ether 02:5d:7d:bc:31:6a brd ff:ff:ff:ff:ff:ff link-netnsid 4    inet6 fe80::5d:7dff:febc:316a/64 scope link       valid_lft forever preferred_lft forever<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用 <code>brctl show</code> 可以看到这个网桥有两个接口连接着设备 veth599d221 和 veth752a46e，使用 <code>docker network inspect</code> docker_gwbridge 这个网络，可以看到在 Containers 项中存在一个 ingress-sbox 条目，它的 ip 就是上面的转发目标 ip 178.18.0.2。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# brctl showbridge namebridge idSTP enabledinterfacesdocker08000.024278260a2fnodocker_gwbridge8000.0242feabb037noveth599d221veth752a46e[root@swarm-manager ~]# docker network inspect docker_gwbridge[    {        "Name": "docker_gwbridge",        "Id": "7c337a10f364ac490d2a6051f5f1b8bf1be7217297d2a14bb974f4dfd2e4a528",        "Created": "2020-10-21T02:43:59.755068648Z",        "Scope": "local",        "Driver": "bridge",        "EnableIPv6": false,        "IPAM": {            "Driver": "default",            "Options": null,            "Config": [                {                    "Subnet": "172.18.0.0/16",                    "Gateway": "172.18.0.1"                }            ]        },        "Internal": false,        "Attachable": false,        "Ingress": false,        "ConfigFrom": {            "Network": ""        },        "ConfigOnly": false,        "Containers": {            "01f1dc5f93d034606e520ccbf4a0ad7e585cfa82a70dfa4ed27a772e9eb168a3": {                "Name": "gateway_5c7efcd6a1e4",                "EndpointID": "7f7180b2f9692ebf71845be2de23cf64b40c2b7fb3c540021c6b56fa4b80a168",                "MacAddress": "02:42:ac:12:00:03",                "IPv4Address": "172.18.0.3/16",                "IPv6Address": ""            },            "ingress-sbox": {                "Name": "gateway_ingress-sbox",                "EndpointID": "0a3e5055c325cfe6c73525dc041764dc456e4efd253fbf171fd69a2c5ba86c9d",                "MacAddress": "02:42:ac:12:00:02",                "IPv4Address": "172.18.0.2/16",                "IPv6Address": ""            }        },        "Options": {            "com.docker.network.bridge.enable_icc": "false",            "com.docker.network.bridge.enable_ip_masquerade": "true",            "com.docker.network.bridge.name": "docker_gwbridge"        },        "Labels": {}    }]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>一个 Container 就有一个属于它的 network 命名空间，直接进入它的命名空间进行查看。通过 <code>ip a</code> 可以看到 172.18.0.2 就是这个命名空间里面的 <code>eth0@if11</code> 设备的 ip 地址；然后再查看这个命名空间的 iptables 的 mangle 规则表里面的 PREROUTING 规则链有一条 MARK 规则，将所有访问 8000 端口 TCP 协议的数据包的标识位设置为 0x104，这个动作就是和 LVS 联合实现负载均衡的。最后通过 <code>ipvsdm</code> 工具可以看到 <code>FWM 260 rr</code> 就是将标识位为 260 的数据包转发到 10.0.0.11 或者 10.0.0.12 地址，260 刚好就是 0x104。10.0.0.11 和 10.0.0.12 就是 whoami 两个容器的实际 ip 地址了。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# yum install ipvsadm -y # 先安装 LVS 的管理工具[root@swarm-manager ~]ls /var/run/docker/netns1-88eid380la  1-id0v0fnkka  5c7efcd6a1e4  ingress_sbox  lb_88eid380l[root@swarm-manager ~]# nsenter --net=/var/run/docker/netns/ingress_sbox[root@swarm-manager ~]# ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever7: eth0@if8: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default    link/ether 02:42:0a:00:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet 10.0.0.2/24 brd 10.0.0.255 scope global eth0       valid_lft forever preferred_lft forever    inet 10.0.0.10/32 brd 10.0.0.10 scope global eth0       valid_lft forever preferred_lft forever10: eth1@if11: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default    link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 1    inet 172.18.0.2/16 brd 172.18.255.255 scope global eth1       valid_lft forever preferred_lft forever[root@swarm-manager ~]# iptables -nL -t mangleChain PREROUTING (policy ACCEPT)target     prot opt source               destinationMARK       tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:8000 MARK set 0x104Chain INPUT (policy ACCEPT)target     prot opt source               destinationMARK       all  --  0.0.0.0/0            10.0.0.10            MARK set 0x104Chain FORWARD (policy ACCEPT)target     prot opt source               destinationChain OUTPUT (policy ACCEPT)target     prot opt source               destinationChain POSTROUTING (policy ACCEPT)target     prot opt source               destination[root@swarm-manager ~]# ipvsadm -lIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags  -> RemoteAddress:Port           Forward Weight ActiveConn InActConnFWM  260 rr  -> 10.0.0.11:0                  Masq    1      0          0  -> 10.0.0.12:0                  Masq    1      0          0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="Ingress-Network-数据包走向详情"><a class="header-anchor" href="#Ingress-Network-数据包走向详情">¶</a>Ingress Network 数据包走向详情</h5><ol><li>在本机的任何接口访问 8000 端口会被 NAT 转发到 ingress_sbox network namespace 中的一个接口</li><li>ingress_sbox 中存在一条 mangle 路由规则对 8000 端口的数据包设置一些标识位，LVS 根据该标识位负载均衡到服务的其中一个容器实际地址</li><li>得到的实际容器 ip 地址再发到 Ingress Network，由它对数据报文进行封装形成 overlay 报文，发送到该实际容器所在主机的网络端口，overlay 报文传播路线即为 vxlan tunnel</li><li>容器所在主机收到 overlay 报文之后，根据网络四元组的目的端口将报文传给 Ingress Network 处理，再经过一系列的 NAT 转发到实际容器… …</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203802.png" alt="image-20201021155012294"></p><h4 id="使用-Docker-Compose-文件进行部署"><a class="header-anchor" href="#使用-Docker-Compose-文件进行部署">¶</a>使用 Docker Compose 文件进行部署</h4><p>上面提到的都是直接使用命令行参数配置的方式进行 swarm 部署，而对于 Docker Compose File 的 version 3 格式中加入了一个 deploy 指令（需要注意的是，此时在 docker compose 文件中的 build 指令并不能用了，只能通过 image 从 registry 拉取镜像），可以直接在文件中定义 swarm 集群信息，然后一键式部署，详情可以参考<a href="https://docs.docker.com/compose/compose-file/#deploy" target="_blank" rel="noopener">官网</a>，下面是一个示例，解释了 deploy 指令的部分子指令：</p><ul><li><code>endpoint_mode</code><ul><li>“vip”：使用 VIP+LVS 负载均衡实现overlay，也就是上面提到的方式，这个值是默认值</li><li>“dnsrr”：不是 VIP，直接使用容器的实际 ip 地址在内部进行轮询实现负载均衡</li></ul></li><li><code>labbels</code>：key-value的描述信息</li><li><code>MODE</code>：<ul><li>“global”：当前 service 在整个 swarm 集群中只有一个副本容器</li><li>“replicated”：当前 service 可以扩展多个副本</li></ul></li><li><code>PLACEMENT</code>：主要限制一些限制条件和一些喜好<ul><li><code>constraints</code>：限制条件<ul><li><code>node.role</code><ul><li>“manager”：限制当前 service 的容器只能部署到 manager 节点</li><li>…</li></ul></li><li>…</li></ul></li><li><code>preference</code>：喜好<ul><li>…</li></ul></li></ul></li><li><code>REPLICAS</code>：副本数量</li><li><code>RESOURCES</code>：设置资源<ul><li><code>limits</code>：限制当前 service 容器最多可以使用这么多<ul><li><code>cpus</code>：‘0.50’</li><li><code>memory</code>：50M</li></ul></li><li><code>reservations</code>：最少要预留这么多给当前 service 容器<ul><li><code>cpus</code>：‘0.25’</li><li><code>memory</code>：20M</li></ul></li></ul></li><li><code>RESTART_POLICY</code>：设置重启策略<ul><li><code>condition</code>：重启条件<ul><li>“on=failure”</li><li>…</li></ul></li><li><code>delay</code>：条件满足后延迟多久开始重启</li><li><code>max_attempts</code>：最大尝试重启次数</li><li><code>window</code>：重启完成后容器持续运行多久可以认为它是重启成功了</li></ul></li><li><code>UPDATE_CONFIG</code>：当 service 有更新的时候设置更新策略<ul><li><code>parallelism</code>：设置更新的时候可以同时更新的副本数量</li><li><code>delay</code>：设置前一个副本更新完成后，下个副本要间隔多少时间才能开始更新</li><li><code>order</code>：更新执行顺序<ul><li>“stop-first”：先停止老版本的容器，然后再启动新版本容器</li><li>“start-first”：先启动新版本容器，再停止老版本容器</li></ul></li></ul></li></ul><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">version: "3.8"services:  wordpress:...    deploy:      mode: replicated      replicas: 2      endpoint_mode: viplabbels:com.example.description: "This label will appear on all containers for the web service"placement:        constraints:          - "node.role==manager"          - "engine.labels.operatingsystem==ubuntu 18.04"        preferences:          - spread: node.labels.zone      resources:        limits:          cpus: '0.50'          memory: 50M        reservations:          cpus: '0.25'          memory: 20M      restart_policy:        condition: on-failure        delay: 5s        max_attempts: 3        window: 120s      update_config:        parallelism: 2        delay: 10s        order: stop-first<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="命令-v3"><a class="header-anchor" href="#命令-v3">¶</a>命令</h5><p><code>docker stack</code></p><ul><li><code>deploy</code>：部署一个 stack 或者更新一个 stack，stack 就是一个 swarm 集群<ul><li><code>[options] &lt;stack-name&gt; [flags]</code> ：设置选项并指定 stack 名称</li><li><code>--compose-file=&lt;path-of-compose-file&gt;</code>：指定 docker compose yml 文件路径</li></ul></li><li><code>ls</code>：列出所有 stack</li><li><code>ps</code>：列出指定 stack 的信息</li><li><code>rm</code>：删除一个或者多个 stack（包括所有服务和网络、volume）</li><li><code>services</code>：列出指定 stack 中的服务</li></ul><h5 id="Docker-Compose-File-示例"><a class="header-anchor" href="#Docker-Compose-File-示例">¶</a>Docker Compose File 示例</h5><h6 id="wordpress"><a class="header-anchor" href="#wordpress">¶</a>wordpress</h6><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">version: '3'services:  web:    image: wordpress    ports:      - 8080:80    environment:      WORDPRESS_DB_HOST: mysql      WORDPRESS_DB_PASSWORD: root    networks:      - my-network    depends_on:      - mysql    deploy:      mode: replicated      replicas: 3      restart_policy:        condition: on-failure        delay: 5s        max_attempts: 3      update_config:        parallelism: 1        delay: 10s  mysql:    image: mysql    environment:      MYSQL_ROOT_PASSWORD: root      MYSQL_DATABASE: wordpress    volumes:      - mysql-data:/var/lib/mysql    networks:      - my-network    deploy:      mode: global      placement:        constraints:          - node.role == managervolumes:  mysql-data:networks:  my-network:    driver: overlay<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h6 id="投票系统"><a class="header-anchor" href="#投票系统">¶</a>投票系统</h6><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">version: "3"services:  redis: # 投票直接写入的是redis    image: redis:alpine    ports:      - "6379"    networks:      - frontend    deploy:      replicas: 2      update_config:        parallelism: 2        delay: 10s      restart_policy:        condition: on-failure  db: # 投票数据持久化数据库    image: postgres:9.4    volumes:      - db-data:/var/lib/postgresql/data    networks:      - backend    deploy:      placement:        constraints: [node.role == manager]  vote: # 前端投票 web 系统    image: dockersamples/examplevotingapp_vote:before    ports:      - 5000:80    networks:      - frontend    depends_on:      - redis    deploy:      replicas: 2      update_config:        parallelism: 2      restart_policy:        condition: on-failure  result: # 后端从 redis 持久化数据到 db 的程序    image: dockersamples/examplevotingapp_result:before    ports:      - 5001:80    networks:      - backend    depends_on:      - db    deploy:      replicas: 1      update_config:        parallelism: 2        delay: 10s      restart_policy:        condition: on-failure  worker:    image: dockersamples/examplevotingapp_worker    networks:      - frontend      - backend    deploy:      mode: replicated      replicas: 1      labels: [APP=VOTING]      restart_policy:        condition: on-failure        delay: 10s        max_attempts: 3        window: 120s      placement:        constraints: [node.role == manager]  visualizer: # docker容器可视化，查看 docker swarm 内容器分布情况    image: dockersamples/visualizer:stable    ports:      - "8080:8080"    stop_grace_period: 1m30s    volumes:      - "/var/run/docker.sock:/var/run/docker.sock"    deploy:      placement:        constraints: [node.role == manager]networks:  frontend:  backend:volumes:  db-data:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="更新服务"><a class="header-anchor" href="#更新服务">¶</a>更新服务</h4><p>更新服务命令为 <code>docker service update</code> ，通过指定参数更新指定内容，如 <code>--publish-add &lt;port&gt;</code> 添加开放端口、<code>--publish-rm &lt;port&gt;</code>移除开放端口、<code>--secret-add &lt;secret&gt;</code> 添加 secret、<code>--secret-rm &lt;list&gt;</code> 删除 secret、<code>--image &lt;image&gt;</code> 更新 image</p><p>假设现在有一个 web service 在运行，这个 web 服务是 1.0 版本的，访问之后会返回 <code>hello docker, version 1.0</code>，我们要更新成 2.0 版本的image，相应的会返回 “2.0”</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker service create --name web --publish 8080:5000 --network demo xiaopeng163/python-flask-demo:1.0zxg8ik8g07h1smge2t9mip1sloverall progress: 1 out of 1 tasks1/1: running   [==================================================>]verify: Service converged[root@swarm-manager ~]# docker service ps webID                  NAME                IMAGE                               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTSrme8jr4himvz        web.1               xiaopeng163/python-flask-demo:1.0   swarm-manager       Running             Running 46 seconds ago[root@swarm-manager ~]# curl 127.0.0.1:8080hello docker, version 1.0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们在更新 service 的时候必须保证 service 有多个副本，这样才能实现不停服务的更新。<code>docker service update</code> 默认会一个个容器地进行更新，更新后会看到有两个 down 的旧版本的容器，两个 up 的新版本的容器：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker service scale web=2web scaled to 2overall progress: 2 out of 2 tasks1/2: running   [==================================================>]2/2: running   [==================================================>]verify: Service converged[root@swarm-manager ~]# docker service ps webID                  NAME                IMAGE                               NODE                DESIRED STATE       CURRENT STATE                ERROR               PORTSrme8jr4himvz        web.1               xiaopeng163/python-flask-demo:1.0   swarm-manager       Running             Running about a minute agoh4dsfenjxcop        web.2               xiaopeng163/python-flask-demo:1.0   swarm-worker1       Running             Running 15 seconds ago[root@swarm-manager ~]# docker service update --image xiaopeng163/python-flask-demo:2.0 webweboverall progress: 2 out of 2 tasks1/2: running   [==================================================>]2/2: running   [==================================================>]verify: Service converged[root@swarm-manager labs]# docker service ps webID                  NAME                IMAGE                               NODE                DESIRED STATE       CURRENT STATE                 ERROR               PORTSfy51bio3ptmo        web.1               xiaopeng163/python-flask-demo:2.0   swarm-worker2       Running             Running about a minute agorme8jr4himvz         \_ web.1           xiaopeng163/python-flask-demo:1.0   swarm-manager       Shutdown            Shutdown about a minute agoxhmljyshutbd        web.2               xiaopeng163/python-flask-demo:2.0   swarm-worker1       Running             Running about a minute agoh4dsfenjxcop         \_ web.2           xiaopeng163/python-flask-demo:1.0   swarm-worker1       Shutdown            Shutdown about a minute ago<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在另外一个 shell session 循环 curl service，会发现没有出现访问失败，平滑地更新了：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager labs]# while true; do curl 127.0.0.1:8080; sleep 1; donehello docker, version 1.0hello docker, version 1.0hello docker, version 1.0hello docker, version 1.0hello docker, version 1.0hello docker, version 1.0hello docker, version 1.0hello docker, version 1.0hello docker, version 2.0hello docker, version 2.0hello docker, version 2.0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以下是更新发布端口的例子</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager ~]# docker service update --publish-rm 8080:5000 --publish-add 8088:5000 webweboverall progress: 2 out of 2 tasks1/2: running   [==================================================>]2/2: running   [==================================================>]verify: Service converged<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果是对使用了 docker compose file 的 swarm services 更新，直接修改 yml 文件中要更新的内容，然后调用 <code>docker stack deploy  --compose-file=&lt;docker-compose-file&gt; &lt;要更新的stack name&gt;</code> 即可，docker 会自动检查文件中变化了的部分进行更新，而 compose 文件中同时也可以对更新的策略进行配置。</p><h1>Docker Secret</h1><ul><li>用户名密码</li><li>SSH Key</li><li>TLS认证</li><li>任何不想让别人看到的数据</li></ul><p>以上都是 secret 数据，在 docker 中也提供了一套管理 secret 数据的机制：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203828.png" alt="image-20201021174613996"></p><p>如果是 docker swarm ，会将 secret 数据存储在内部的 raft 协议的分布式数据库中，对外提供一个唯一标识进行引用；如果是单机 docker，就是存储在 docker engine 中，存储形式是加密的。</p><h3 id="命令-v4"><a class="header-anchor" href="#命令-v4">¶</a>命令</h3><p><code>docker secrets</code></p><ul><li><code>create</code>：创建一个 secret</li><li><code>inspect</code>：查询详细信息</li><li><code>ls</code>：列出所有 secret</li><li><code>rm</code>：删除一个或者多个 secret</li></ul><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@swarm-manager example-vote-app]# cat > password << EOF> admin123> EOF[root@swarm-manager example-vote-app]# cat passwordadmin123[root@swarm-manager example-vote-app]# docker secret create my-passwd passwordsyswr8jsddpueg6soadrz7tdm[root@swarm-manager example-vote-app]# echo 'adminadmin' | docker secret create my-passwd2 -spwrwxzc0cfa507r1to43tqyl[root@swarm-manager example-vote-app]# docker secret lsID                          NAME                DRIVER              CREATED              UPDATEDsyswr8jsddpueg6soadrz7tdm   my-passwd                               About a minute ago   About a minute agospwrwxzc0cfa507r1to43tqyl   my-passwd2                              18 seconds ago       18 seconds ago[root@swarm-manager example-vote-app]# docker secret rm my-passwd2my-passwd2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>docker service create</code>命令有一个 <code>--secret</code> 参数可以引用 secret 的唯一标识，容器引用了 secret 并创建之后，引用的 secret 保存在 <code>/run/secrets/&lt;secret-name&gt;</code> 文件中，是明文的形式，以下是在启动 mysql service 的时候设置 MySQL root 用户密码（环境变量<code>MYSQL_ROOT_PASSWORD_FILE=/run/secrets/my-passwd</code>）的示例：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">#### manager[root@swarm-manager example-vote-app]# docker service create --name db --secret my-passwd -e MYSQL_ROOT_PASSWORD_FILE=/run/secrets/my-passwd mysql6ggy76hw51c9xlbf54lpzz9leoverall progress: 1 out of 1 tasks1/1: running   [==================================================>]verify: Service converged[root@swarm-manager example-vote-app]# docker service ps dbID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTShrcnzoyfmo1k        db.1                mysql:latest        swarm-worker2       Running             Running 17 seconds ago#### woker2[root@swarm-worker2 ~]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                 NAMES5e516b193c10        mysql:latest        "docker-entrypoint.s…"   42 seconds ago      Up 41 seconds       3306/tcp, 33060/tcp   db.1.hrcnzoyfmo1kmabchxlfhx5ux[root@swarm-worker2 ~]# docker exec -it 5e516b193c10 sh# cat /run/secrets/my-passwdadmin123# mysql -uroot -padmin123mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 9Server version: 8.0.22 MySQL Community Server - GPLCopyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="在-compose-file-中使用"><a class="header-anchor" href="#在-compose-file-中使用">¶</a>在 compose file 中使用</h3><ol><li>在 <code>services</code> 下定义的 service 中的 <code>secrets</code> 指令直接引用已经创建的 secret</li><li>直接使用顶级 <code>secrets</code> 指令创建一个 secret 后再引用</li></ol><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">version: '3'services:  web:    image: wordpress    ports:      - 8080:80    secrets: # 引用 secret      - my-pw    environment:      WORDPRESS_DB_HOST: mysql      WORDPRESS_DB_PASSWORD_FILE: /run/secrets/my-pw    networks:      - my-network    depends_on:      - mysql    deploy:      mode: replicated      replicas: 3      restart_policy:        condition: on-failure        delay: 5s        max_attempts: 3      update_config:        parallelism: 1        delay: 10s  mysql:    image: mysql    secrets:      - my-pw    environment:      MYSQL_ROOT_PASSWORD_FILE: /run/secrets/my-pw      MYSQL_DATABASE: wordpress    volumes:      - mysql-data:/var/lib/mysql    networks:      - my-network    deploy:      mode: global      placement:        constraints:          - node.role == managervolumes:  mysql-data:networks:  my-network:    driver: overlay# secrets: # 直接创建再引用#   my-pw:#    file: ./password<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1>Docker Cloud</h1><p>CaaS，Container as a Service，基于 PaaS 提供容器的管理、编排、部署的托管服务。主要模块：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203840.png" alt="image-20201021094251033"></p><h3 id="两种模式"><a class="header-anchor" href="#两种模式">¶</a>两种模式</h3><ul><li>Standard 模式：一个 Node 就是一个 Docker Host</li><li>Swarm 模式：多个 Node 组成的 Swarm Cluster</li></ul><p>现在 Docker Cloud 好像已经关闭了，在 Docker Hub 上面找到了自动构建的功能，先将Github 账号 授权给 Docker Hub 账号访问</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203848.png" alt="image-20201022081536158"></p><p>创建一个有 Dockerfile 文件进行构建打包工作的源代码仓库</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203855.png" alt="image-20201022081744344"></p><p>在 DockerHub 中创建一个组织</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203914.png" alt="image-20201022081830728"></p><p>在组织下创建一个仓库</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203922.png" alt="image-20201022082135065"></p><p>填写仓库信息</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203928.png" alt="image-20201022082244421"></p><p>点击build，发现在组织下还要关联一次 Github，点击</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203936.png" alt="image-20201022082420994"></p><p>连接 Github 后再次点击</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203942.png" alt="image-20201022082524944"></p><p>填写 Build 信息，重要的是 BUILD RULES，默认有一条 build 规则，只要在 master 分支上有代码更新（包括push、merge、github 的 pull request 等等）都会自动 build，点击保存并build，会自动触发一次build</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203950.png" alt="image-20201022082652434"></p><p>build 完成</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221203958.png" alt="image-20201022083608095"></p><p>另外还可以增加其它 build 触发规则，如增加一个 tag 规则，此时在 release 一个新的 tag 的时候就会触发一次 build</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221204005.png" alt="image-20201022083949263"></p><p>发布一个新 tag</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221204011.png" alt="image-20201022084435252"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221204017.png" alt="image-20201022084513523"></p><p>看到触发了 build，build tag 就是刚刚 release 的1.1.2</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221204023.png" alt="image-20201022084834032"></p><p>build 完成后在 Tags 标签页可以看到新发布的 tag</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221204030.png" alt="image-20201022085859526"></p><p>原本除了自动构建还有自动部署的功能，有个 “Launch Service” 按钮在下图圈中的 “Public View” 的位置，现在没有了，不知道是不是很和 Docker Cloud 一起停掉了，还是付费用户才有。这个自动部署可以按照一定规则（例如build 了新的镜像）进行自动发布运行引用</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221204035.png" alt="image-20201022090637620"></p><h1>Docker EE</h1><h3 id="Mirantis"><a class="header-anchor" href="#Mirantis">¶</a>Mirantis</h3><p>Docker 企业版已经被一家名为 MIRANTIS 的公司收购了。Docker EE 就是基于 Docker、Docker-Compose、Docker Swarm 等提供了一个 UI 界面还有一些额外的功能（如监控），主要主键是 <a href="https://docs.mirantis.com/docker-enterprise/v3.0/dockeree-products/ucp.html#" target="_blank" rel="noopener">UDP</a> (容器和本地镜像管理)和 <a href="https://docs.mirantis.com/docker-enterprise/v3.0/dockeree-products/dtr.html" target="_blank" rel="noopener">DTR</a> (registry管理，这个 registy 是trusted 的，意思是安全的，可信赖的，因为它内部有一个安全数据库，收集了很多标准安全规范，可以对上传的 images 进行安全扫描并显示 images 的哪一层为什么不安全)。</p><p>这里是 <a href="https://www.mirantis.com/software/docker/docker-enterprise-container-cloud/download/" target="_blank" rel="noopener">Docker EE 部署脚本和证书下载页面</a>  和 <a href="https://docs.mirantis.com/de-container-cloud/latest/deployment-guide/deploy-bm-mgmt/bm-mgmt-overview.html" target="_blank" rel="noopener">安装指导</a> 。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221204042.png" alt="image-20201022093034054"></p><h3 id="阿里云"><a class="header-anchor" href="#阿里云">¶</a><a href="https://cs.console.aliyun.com/index2#/k8s/cluster/list" target="_blank" rel="noopener">阿里云</a></h3><p>阿里云也提供了 docker swarm 和 k8s 的容器服务，所谓 docker swarm 的容器服务就类似 docker ee 版本，就是提供了界面操作，不过 docker swarm 已经停止技术支持。</p><p>另外原本在阿里云的云市场里面也有 docker ee 的下载和安装到 ecs 的服务的，现在也没有了，估计和上面提到的 Mirantis 的收购有关。</p>]]></content>
      
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3、Docker容器</title>
      <link href="/2020/12/22/docker/yin-xiang-bi-ji/3-docker-rong-qi/"/>
      <url>/2020/12/22/docker/yin-xiang-bi-ji/3-docker-rong-qi/</url>
      
        <content type="html"><![CDATA[<hr><p>title: 3、Docker容器<br>top: true<br>cover: false<br>toc: true<br>mathjax: true<br>date:<br>password:<br>summary: 3、Docker容器<br>tags:</p><ul><li>docker<br>categories:</li><li>docker</li></ul><hr><p>[TOC]</p><h1>帮助</h1><p>官方文档列出了完整的 Docker 命令列表，也可以使用 <code>docker help</code> 获取这些命令。此外，还可以使用 Docker 的 man 页（man docker）。另外，对于二级命令，这些操作同样适用：<code>docker help run</code>、<code>man docker-run</code>、<code>docker run --help</code></p><h1>命令</h1><h2 id="docker-run"><a class="header-anchor" href="#docker-run">¶</a>docker run</h2><p><code>docker run</code>命令提供了 Docker 容器的创建到启动的功能：</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker run -it ubuntu /bin/bashUnable to find image 'ubuntu:latest' locallyTrying to pull repository docker.io/library/ubuntu ...latest: Pulling from docker.io/library/ubuntu5bed26d33875: Pull completef11b29a9c730: Pull complete930bda195c84: Pull complete78bf9a5ad49e: Pull completeDigest: sha256:bec5a2727be7fff3d308193cfde3491f8fba1a2ba392b7546b43a051853a341dStatus: Downloaded newer image for docker.io/ubuntu:latestroot@6e73587e0ffe:/#</code></pre><p>下面我们来解析上面这条命令</p><pre><code>$ docker run -it ubuntu /bin/bash</code></pre><h3 id="i-t-参数"><a class="header-anchor" href="#i-t-参数">¶</a>-i -t 参数</h3><p>首先,我们告诉 Docker执行 docker run命令,并指定了-i和-t两个命令行参数。 <strong>-i标志保证容器中STDIN是开启的,尽管我们并没有附着到容器中。持久的标准输入是交互式shel的“半边天”,-t标志则是另外“半边天”,它告诉Docker为要创建的容器分配一个伪tty终端</strong> 。这样,新创建的容器才能提供一个交互式 shell若要在命令行下创建一个我们能与之进行交互的容器,而不是一个运行后台服务的容器,则这两个参数己经是最基本的参数了</p><h3 id="指定容器的基础镜像"><a class="header-anchor" href="#指定容器的基础镜像">¶</a>指定容器的基础镜像</h3><p>接下来,我们告诉Docker基于什么镜像来创建容器,示例中使用的是 <code>ubuntu</code>镜像。<code>ubuntu</code>镜像是一个常备镜像,也可以称为“基础”(base)镜像,它由 Docker公司提供, 保存在Docker Hub Registry上。<br>你可以用ubuntu基础镜像(以及类似的fedora、 debian、 centos等镜像)为基础,在你选择的操作系统上构建自己的镜像。这里,我们基于此基础镜像启动了一个容器, 并且没有对容器进行任何改动。</p><h3 id="容器创建流程"><a class="header-anchor" href="#容器创建流程">¶</a>容器创建流程</h3><p>那么,在这一切的背后又都发生了什么呢?首先Docker会检査本地是否存在 <code>ubuntu</code> 镜像,如果本地还没有该镜像的话,那么 Docker就会连接官方维护的 Docker Hub Registry 查看 Docker Hub中是否有该镜像。Docker一旦找到该镜像,就会下载该镜像并将其保存到本地宿主机中。<br>随后,Docker<strong>在文件系统内部</strong>用这个镜像创建了一个新容器。该容器拥有自己的网络、IP地址,以及一个用来和宿主机进行通信的桥接网络接口。</p><h3 id="指定容器创建后执行的命令"><a class="header-anchor" href="#指定容器创建后执行的命令">¶</a>指定容器创建后执行的命令</h3><p>最后,我们告诉Docker在新容器中要运行什么命令,在本例中我们在容器中运行/bin/bash命令启动了一个 Bash shell 当容器创建完毕之后, Docker就会执行容器中的/bin/bash命令,这时我们就可以看到容器内的shell了：</p><pre><code>root@6e73587e0ffe:/#</code></pre><h3 id="–name-参数"><a class="header-anchor" href="#–name-参数">¶</a>–name 参数</h3><p>我们在创建容器的时候可以使用<code>--name</code>参数指定容器的名称而不使用 Docker 为我们随机生成的名称：</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker run --name the_container_of_john -it ubuntu /bin/bashroot@9b69de862ea9:/#</code></pre><p>上述命令将会创建一个名为<code>the_container_of_john</code>的容器。一个合法的容器名称只能包含以下字符:小写字母a<sub>z、大写字母A</sub>Z、数字0-9、下划线、圆点、横线(如果用正则表达式来表示这些符号,就是(a-zA-z0-9_.-])。<br>在很多Docker命令中,我们都可以用容器的名称来替代容器ID,后面我们将会看到。容器名称有助于分辨容器,当构建容器和应用程序之间的逻辑连接时,容器的名称也有助于从逻辑上理解连接关系。具体的名称(如web、db)比容器ID和随机容器名好记多了。我推荐大家都使用容器名称,以更加方便地管理容器。<br>容器的命名必须是唯一的。如果我们试图创建两个名称相同的容器,则命令将会失败。<br>如果要使用的容器名称己经存在,可以先用<code>docker rm</code>命令删除已有的同名容器后,再来创建新的容器。</p><h3 id="d-参数运行守护式容器"><a class="header-anchor" href="#d-参数运行守护式容器">¶</a>-d 参数运行守护式容器</h3><p><code>docker run</code>在默认下创建的容器是交互式运行的(Interactive container),我们也可以创建长期运行的容器。守护式容器(demonized container)没有交互式会话,非常适合运行应用程序和服务。大多数时候我们都需要以守护式来运行我们的容器。下面我们就来启动一个守护式容器</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker run --name daemon_container -d ubuntu /bin/sh -c &quot;while true;do echo hello world;sleep 1;done&quot;e9436bfe00334d3ac0883621fa6ae92f679839fc82a0c76c315cf97dab513258</code></pre><p>我们在上面的<code>docker run</code>命令使用了<code>-d</code>参数，因此 Docker 会将容器放到后台运行；另外我们还在容器里运行的命令使用了一个<code>while</code>循环，该循环会一直打印 hello workd，直到容器或者其进程停止运行。上面的命令执行之后会发现 docker 并不会将主机的控制台附着到新的 shell 会话上，而是仅仅返回了一个容器 id，通过 <code>docker ps</code> 命令我们可以找到刚刚创建的容器在运行</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker ps -aCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                       PORTS               NAMESe9436bfe0033        ubuntu              &quot;/bin/sh -c 'while...&quot;   3 minutes ago       Up 3 minutes                                     daemon_container</code></pre><ul><li>此时我们可以通过<code>docker logs</code>命令获取容器的打印的日志</li><li>另外还可以通过<code>docker top</code>查看容器内部运行的进程</li><li>使用<code>docker exec</code>还可以在容器内运行进程</li><li>使用<code>docker stop</code>停止容器</li></ul><h3 id="–restart-参数"><a class="header-anchor" href="#–restart-参数">¶</a>–restart 参数</h3><p>如果由于某种错误而导致容器停止运行,我们还可以通过<code>--restart</code>标志,让Docker自动重新启动该容器。<code>--restart</code>标志会检査容器的退出代码,并据此来决定是否要重启容器。默认的行为是Docker不会重启容器。</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker run --restart always --name daemon_always -d ubuntu /bin/sh -c &quot;while true;echo hello world;sleep 1;done&quot;37101230a80ebf66f1def575f2d5094ea3161bcde5a3002c4e7c22c8bb9d9a7c</code></pre><p>在本例中, <code>--restart</code>标志被设置为a1ways。无论容器的退出代码是什么, Docker都会自动重启该容器。除了a1ways,我们还可以将这个标志设为on-fai1ure,这样,只有当容器的退出代码为非0值的时候,才会自动重启。另外,on-failure还接受一个可选的重启次数参数：</p><pre><code>--restart=on-failure:5</code></pre><h3 id="p-参数"><a class="header-anchor" href="#p-参数">¶</a>-p 参数</h3><p>该标志用来控制Docker在运行时应该公开哪些网络端口给外部(宿主机)。</p><h4 id="1-指定容器对外暴露的端口"><a class="header-anchor" href="#1-指定容器对外暴露的端口">¶</a>1. 指定容器对外暴露的端口</h4><pre><code>[root@izwz920kp0myp15p982vp4z test]# docker run -d -p 80 --name web_test john/test_web nginx -g &quot;daemon off;&quot;6b564a193037976f219bd76a6ef94f27a7daa48103d1bd0d01846a3e8c37de2c</code></pre><p>运行一个容器时, 如果该容器被指定要向外暴露一个端口，则Docker可以通过两种方法来在宿主机上分配端口:</p><ul><li>Docker可以在宿主机上随机选择一个位于49153~6553的一个比较大的端口号来映射到容器中的80端口上。</li><li>可以根据用户的指定（可以通过<code>-p</code>指定）Docker宿主机中指定一个具体的端口号来映射到容器中的80端口上。</li></ul><p>上面的命令明显是第一种方式，因为我们并没有指定宿主机中的映射端口，我们使用<code>docker ps</code>命令来看一下容器的端口分配情况：</p><pre><code>[root@izwz920kp0myp15p982vp4z test]# docker ps -lCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                   NAMES6b564a193037        john/test_web       &quot;nginx -g 'daemon ...&quot;   6 minutes ago       Up 6 minutes        0.0.0.0:32768-&gt;80/tcp   web_test</code></pre><p>可以看到容器中的80端口被映射到了宿主机的32768端口上。另外我们还可以通过<code>docker port</code>或者<code>docker inspect</code>来查看容器的端口映射情况</p><h4 id="2-指定容器暴露的端口的同时并指定映射关系"><a class="header-anchor" href="#2-指定容器暴露的端口的同时并指定映射关系">¶</a>2. 指定容器暴露的端口的同时并指定映射关系</h4><pre><code>-p 80:80</code></pre><p>上面的命令会将容器内的80端口绑定到本地宿主机的80端口上。（肯定不推荐啦）</p><pre><code>-p 127.0.0.1:80:80</code></pre><p>上面的参数将容器的80端口绑定到了一个&quot;ip:port&quot;对应的网络接口上，即还能指定 ip</p><pre><code>-p 127.0.0.1::80</code></pre><p>上面仅仅指定了 ip，所以 docker 还是取随机接口进行映射</p><pre><code>-p 127.0.0.1::80/udp</code></pre><p>上面还指定了协议</p><blockquote><p>可以从<a href="http://docs.docker.com/userguide/dockerlinks/#network-port-mapping-refresher" target="_blank" rel="noopener">http://docs.docker.com/userguide/dockerlinks/#network-port-mapping-refresher</a>获得更多关于端口重定向的信息。</p></blockquote><h3 id="P-参数"><a class="header-anchor" href="#P-参数">¶</a>-P 参数</h3><p>大 P 参数会将容器中程序绑定的容器端口随机映射到宿主机的一个端口进行开放，并将用来构建该镜像的 Dockerfile 文件中 <code>EXPOSE</code> 指令指定的其他端口也一并公开。</p><h3 id="–entrypoint、-w-参数"><a class="header-anchor" href="#–entrypoint、-w-参数">¶</a>–entrypoint、-w 参数</h3><p><code>--entrypoint</code>覆盖构建镜像的时候 Dockerfile 中<code>ENTRYPOINT</code>指令指定的命令<br><code>-w</code>覆盖构建镜像的时候 Dockerfile 中<code>WORDIR</code>指令指定的命令</p><h3 id="e-参数"><a class="header-anchor" href="#e-参数">¶</a>-e 参数</h3><p>传递环境变量:</p><pre><code>$ sudo docker run -ti -e &quot;WEB_PORT=8080&quot; ubuntu env HOME=/ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin: /bin HOSTNAME=792b171c5e9f TERM=xterm WEB_PORT=8080</code></pre><p>我们可以看到,在容器中<code>WEB_PORT</code>环境变量被设为了8080。</p><h3 id="u-参数"><a class="header-anchor" href="#u-参数">¶</a>-u 参数</h3><p>指定容器以什么用户去执行，可以指定用户、用户 id、用户组、用户组 id、或者两两组合，和 Dockerfile 中的<code>USER</code>指令一致，不过当前参数会覆盖 Dockerfile 中可能设置了的<code>USER</code>指令</p><h3 id="v-参数"><a class="header-anchor" href="#v-参数">¶</a>-v 参数</h3><p><code>-v</code> 选项允许我们将宿主机的目录作为卷，挂载到容器里。卷在 Docker里非常重要,也很有用。卷是在一个或者多个容器内被选定的目录, 可以绕过<strong>分层的</strong>联合文件系统(Union File System), 为Docker提供持久数据或者共享数据。这意味着对卷的修改会直接生效, 并绕过镜像。<strong>当提交或者创建镜像（其实是层）时, 卷中的内容不被包含在镜像里（其实是层）。</strong></p><blockquote><p>卷可以在容器间共享。即便容器停止,卷里的内容依旧存在。</p></blockquote><p>当我们遇到以下场景的时候都可以用到卷：</p><ul><li>希望同时对代码做开发和测试</li><li>代码改动很频繁，不想在开发过程中重构镜像</li><li>希望在多个容器间共享代码</li><li>… …</li></ul><p>参数<code>-v</code>指定了卷的源目录(本地宿主机的目录)和容器里的目的目录, 这两个目录通过<code>:</code>来分隔。如果目的目录不存在, Docker会自动创建一个。也可以通过在目的目录后面加上<code>rw</code>(read&amp;write)或者<code>ro</code>(read-only)。来指定目的目录的读写状态。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">docker run -d -p 80 --name website -v $PWD/website:/var/www/html/website:ro 707845008/nginx nginx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>以上命令将<code>$PWD/website</code>(<code>$PWD</code>会被用来执行<code>echo $PWD</code>，和<code>pwd</code>命令得到的结果一样，然后拼接上<code>/website</code>)挂载到容器的<code>/var/www/html/website</code>目录，并且<code>:ro</code>使得目的目录<code>/var/www/html/website</code>变成只读状态。</p><h3 id="–link"><a class="header-anchor" href="#–link">¶</a>–link</h3><p>该选项可以把一个或者多个 Docker容器连接起来,让其互相通信。<br>先启动一个 redis 容器，注意到，我们启动的时候并没有对外暴露这个容器的任何接口</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z ~]# docker run -d --name redis 707845008/redisb223886418744665e39431346e49533f88d6105feb070658ef4d5aaa4354fa41<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>现在我们启动一个要连接该 redis 的 web 程序</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z ~]# docker run -p 4567 --name webapp --link redis:db -it -v $PWD/webapp:/opt/webapp 707845008/sinatra /bin/bashroot@55e0a4c82d37:/#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>可以看到我们使用了一个<code>--link</code>参数，<code>--1ink</code> 标志创建了两个容器间的父子连接。这个标志需要两个参数:一个是要连接的容器名字,另一个是连接后容器的别名。这个例子中, 我们把新容器连接到redis容器,并使用<code>db</code>作为别名。别名让我们可以访问公开的信息, 而无须关注底层容器的名字。连接让父容器有能力访问子容器,并且把子容器的一些连接细节分享给父容器, 这些细节有助于配置应用程序并使用这个连接。<br>连接也能得到一些安全上的好处。注意到启动 Redis容器时,并没有使用<code>-p</code>标志公开Redis的端口。因为不需要这么做。通过把容器连接在一起,可以让父容器直接访问任意子容器的公开端口(比如,父容器 webapp可以连接到子容器 redis的6379端口)。更妙的是,只有使用<code>--1ink</code>标志连接到这个容器的容器才能连接到这个端口。容器的端口不需要对本地宿主机公开,现在我们己经拥有一个非常安全的模型。通过这个安全模型,就可以限制容器化应用程序的被攻击面,减少应用暴露的网络。</p><p>也可以把多个容器连接在一起。比如,如果想让这个Redis实例服务于多个Web应用程序可以把每个Web应用程序的容器和同一个 redis容器连接在一起</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ docker run -p 4567 --name webapp2 --link redis:db ... ...$ docker run -p 4567 --name webapp3 --link redis:db ... ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><blockquote><p>被连接的容器必须运行在同一个Docker宿主机上。不同Docker宿主机上运行的容器无法连接？</p></blockquote><p>接下来我们再看一下连接了 Redis 容器的 webapp 容器内部的 <strong>hosts 文件和环境变量</strong>有什么变化：</p><h4 id="1-hosts-文件"><a class="header-anchor" href="#1-hosts-文件">¶</a>1. hosts 文件</h4><pre class="line-numbers language-language-shell"><code class="language-language-shell">root@55e0a4c82d37:/# cat /etc/hosts127.0.0.1localhost::1localhost ip6-localhost ip6-loopback... ...172.17.0.2db b22388641874 redis172.17.0.355e0a4c82d37<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里可以看到一些有用的项。第一项是由该连接指令创建的,它是 redis容器的IP地址和从该连接的别名衍生的主机名db。第二项是容器自己的IP地址和主机名(主机名是容器ID 的一部分)。我们如果 <code>ping</code> 一下 db 和 redis，是可以 ping 通的：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">root@55e0a4c82d37:/# ping redisPING db (172.17.0.2) 56(84) bytes of data.64 bytes from db (172.17.0.2): icmp_seq=1 ttl=64 time=0.113 ms64 bytes from db (172.17.0.2): icmp_seq=2 ttl=64 time=0.079 ms... ...root@55e0a4c82d37:/# ping dbPING db (172.17.0.2) 56(84) bytes of data.64 bytes from db (172.17.0.2): icmp_seq=1 ttl=64 time=0.062 ms64 bytes from db (172.17.0.2): icmp_seq=2 ttl=64 time=0.072 ms... ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>如果被连接容器重启了，连接容器 hosts 文件中的 ip 地址就会更新成被连接容器重启之后获得的 ip 地址。</p></blockquote><h4 id="2-环境变量"><a class="header-anchor" href="#2-环境变量">¶</a>2. 环境变量</h4><pre class="line-numbers language-language-shell"><code class="language-language-shell">root@55e0a4c82d37:/# envHOSTNAME=55e0a4c82d37DB_NAME=/webapp/dbDB_PORT=tcp://172.17.0.2:6379DB_PORT_6379_TCP=tcp://172.17.0.2:6379DB_PORT_6379_TCP_PROTO=tcpDB_PORT_6379_TCP_ADDR=172.17.0.2DB_PORT_6379_TCP_PORT=6379... ...PWD=/SHLVL=1HOME=/rootREFRESEHED_AT=2020-04-03LESSOPEN=| /usr/bin/lesspipe %sLESSCLOSE=/usr/bin/lesspipe %s %s_=/usr/bin/env<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到不少环境变量,其中一些以DB开头。 Docker在连接 webapp和 redis容器时,自动创建了这些以DB开头的环境变量。以DB开头是因为DB是创建连接时使用的别名。<br>这些自动创建的环境变量包含以下信息</p><ul><li>子容器的名字。</li><li>子容器里运行的服务所使用的协议、IP和端口号。</li><li>容器里由Docker设置的环境变量的值。</li></ul><p>此时用户可以使用这些连接信息来让容器内的应用程序使用相同的方法与别的容器进行连接,而不用关心被连接的容器的具体细节。</p><h3 id="h、–hostname-参数"><a class="header-anchor" href="#h、–hostname-参数">¶</a>-h、–hostname 参数</h3><p>该选项可以为容器设定主机名</p><h3 id="–dns、–dns-search-参数"><a class="header-anchor" href="#–dns、–dns-search-参数">¶</a>–dns、–dns-search 参数</h3><p>该参数可以为容器单独配置 DNS。你可以设置本地DNS解析的路径和搜索城。在<a href="https://docs.docker.com/articles/networking/" target="_blank" rel="noopener">https://docs.docker.com/articles/networking/</a>上可以找到更详细的配置信息。如果没有这两个标志, Docker会根据宿主机的信息来配置DNS解析。可以在<code>/etc/resolv.conf</code>文件中查看DNS解析的配置情況。</p><h3 id="–memory-参数"><a class="header-anchor" href="#–memory-参数">¶</a>–memory 参数</h3><p>限制容器可以使用的内存资源</p><h3 id="–cpu-shares"><a class="header-anchor" href="#–cpu-shares">¶</a>–cpu-shares</h3><p>限制容器的可使用 CPU 相对权重，例如有一个容器设置 <code>--cpu-shares 10</code>，另一个容器设置 <code>--cpu-shares 5</code>，此时两个容器启动，现在宿主机上有两个容器运行，它们的 CPU 权重比是 10 比 5，也就是 2 比 1，那么第一个容器的 CPU 时间片占比就是总的 2/3，另一个是 1/3 。</p><h2 id="docker-port"><a class="header-anchor" href="#docker-port">¶</a>docker port</h2><p>该指令可以查看容器的端口映射情况，例如下面例子是查看容器<code>web_test</code>中80端口映射到宿主机的端口是哪个，这里是32768</p><pre><code>[root@izwz920kp0myp15p982vp4z test]# docker port web_test 800.0.0.0:32768</code></pre><h2 id="docker-stop"><a class="header-anchor" href="#docker-stop">¶</a>docker stop</h2><p>该命令可以停止一个容器（特比是守护式容器）</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker stop daemon_containerdaemon_container</code></pre><p>当然，我们也可以通过容器 id 进行停止。<br>此时我们通过<code>docker ps</code>命令即可查看当前容器的状态：</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker ps -n 1CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                       PORTS               NAMESe9436bfe0033        ubuntu              &quot;/bin/sh -c 'while...&quot;   55 minutes ago      Exited (137) 2 minutes ago                       daemon_container</code></pre><blockquote><p><code>docker stop</code>命令会向 docker 容器进程发送 <code>SIGTERM</code> 信号。如果你想快速停止某个容器，也可以用<code>docker kill</code>命令来向容器进程发送<code>SIGKILL</code>信号。</p></blockquote><h2 id="docker-kill"><a class="header-anchor" href="#docker-kill">¶</a>docker kill</h2><h2 id="docker-exec"><a class="header-anchor" href="#docker-exec">¶</a>docker exec</h2><p>在 Docker1.3之后,我们也可以通过<code>docker exec</code>命令在容器内部额外启动新进程。可以在容器内运行的进程有两种类型:后台任务和交互式任务。后台任务在容器内运行且没有交互需求,而交互式任务则保持在前台运行。<br>该命令默认是启动一个前台运行的交互式任务，下面我们可以在 daemon_container 容器中启动一个诸如打开 shell 的交互式任务：</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker exec -it daemon_container /bin/bashroot@e9436bfe0033:/#</code></pre><p>和<code>docker run</code>交互式容器一样，这里的<code>-t</code>和<code>-i</code>参数为我们执行的进程创建了 TTY 并捕捉了 STDIN。命令的后面我们分别指定了容器的名字和要执行的命令，此时这条<code>docker exec</code>指令就会在容器内创建一个新的 bash 会话，有了这个会话，我们就可以在该容器中运行其他命令了。</p><h3 id="d参数"><a class="header-anchor" href="#d参数">¶</a>-d参数</h3><p><code>-d</code>参数可以在容器内部启动一个后台任务：</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker exec -d daemon_container touch /etc/new_config_file</code></pre><p>以上指令在&quot;daemon_container&quot;容器内部创建了一个空文本</p><h2 id="docker-top"><a class="header-anchor" href="#docker-top">¶</a>docker top</h2><p>该命令可以看到容器内的所有进程、运行的进程的用户及进程 ID：</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker top daemon_containerUID                 PID                 PPID                C                   STIME               TTY                 TIME                CMDroot                16420               16371               0                   13:32               ?                   00:00:00            /bin/sh -c while true;do echo hello world;sleep 1;doneroot                18103               16420               0                   13:58               ?                   00:00:00            sleep 1</code></pre><h2 id="docker-logs"><a class="header-anchor" href="#docker-logs">¶</a>docker logs</h2><p>该命令可以打印容器正在打印输出的日志</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker logs daemon_containerhello worldhello worldhello worldhello worldhello worldhello worldhello world...</code></pre><p>Docker 会输出最后几条日志项并返回。</p><h3 id="f-参数"><a class="header-anchor" href="#f-参数">¶</a>-f 参数</h3><p>该参数可以来监控 Docker 的日志，和 <code>tail -f</code> 命令非常相似:</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker logs -f daemon_containerhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello world...</code></pre><p><code>ctrl+c</code>即可退出日志追踪</p><h3 id="–tail-参数"><a class="header-anchor" href="#–tail-参数">¶</a>–tail 参数</h3><p>该参数获取日志的最后 x 行内容，如下命令获取最后10行内容。</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker logs --tail 10 daemon_containerhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello world</code></pre><p><code>--tail</code> 加上 <code>-f</code> 即可进行组合使用，例如以下例子就是监控后三行日志并打印输出</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker logs -f --tail 3 daemon_containerhello worldhello worldhello worldhello world...</code></pre><h3 id="t-参数"><a class="header-anchor" href="#t-参数">¶</a>-t 参数</h3><p>该参数会打印时间戳<br><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221205355.png" alt="cd5db3c16964450b12e46688e6d1d245"></p><h2 id="docker-start"><a class="header-anchor" href="#docker-start">¶</a>docker start</h2><p><code>the_container_of_john</code>容器已经停止了，我们可以使用<code>docker start</code>命令重新启动已经停止的容器（ <strong>注意，容器启动之后会再执行创建容器的时候指定的那个命令，如上例就是&quot;/bin/bash&quot;</strong> ）</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker start the_container_of_johnthe_container_of_john</code></pre><p>此时<code>docker ps</code>即可看到这个启动的容器了</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES9b69de862ea9        ubuntu              &quot;/bin/bash&quot;         About an hour ago   Up 2 minutes                            the_container_of_john</code></pre><h2 id="docker-restart"><a class="header-anchor" href="#docker-restart">¶</a>docker restart</h2><p><code>docker restart</code>命令也可以重启容器</p><h2 id="docker-attach"><a class="header-anchor" href="#docker-attach">¶</a>docker attach</h2><p>Docker容器在创建的时候指定了<code>-it</code>参数并且停止之后又开启的时候，虽然如上例该 Docker 容器内部照样执行了&quot;/bin/bash&quot;，但是我们的 ssh 终端并没有立即附着到该容器，此时我们可以使用<code>docker attach</code>重启附着到该容器</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker attach the_container_of_johnroot@9b69de862ea9:/#</code></pre><p>可以看到，我们又进入到了容器的<a href="https://baike.baidu.com/item/bash/6367661?fr=aladdin" target="_blank" rel="noopener">bash</a>会话界面，当然，指定容器的 id 也是可以的。</p><h2 id="docker-ps"><a class="header-anchor" href="#docker-ps">¶</a>docker ps</h2><p>默认情况下，当执行<code>docker ps</code>命令时，<strong>只能看到正在运行的容器</strong>。</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</code></pre><p>可以看到，当前没有正在运行的容器</p><h3 id="a-all-参数"><a class="header-anchor" href="#a-all-参数">¶</a>-a (all)参数</h3><p><code>-a</code> 参数可以查看所有的容器的列表</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker ps -aCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                        PORTS               NAMES6e73587e0ffe        ubuntu              &quot;/bin/bash&quot;         53 minutes ago      Exited (127) 32 seconds ago                       determined_davinci</code></pre><h3 id="l-last-参数"><a class="header-anchor" href="#l-last-参数">¶</a>-l (last)参数</h3><p><code>-l</code> 参数会列出最后一次运行的容器，包括正在运行和已经停止的。</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker ps -lCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                       PORTS               NAMES6e73587e0ffe        ubuntu              &quot;/bin/bash&quot;         56 minutes ago      Exited (127) 4 minutes ago                       determined_davinci</code></pre><h3 id="n-参数"><a class="header-anchor" href="#n-参数">¶</a>-n 参数</h3><p>该参数会显示最后 x 个容器，不论这些容器正在运行还是已经停止：</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker ps -n 3CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                           PORTS               NAMESe9436bfe0033        ubuntu              &quot;/bin/sh -c 'while...&quot;   57 minutes ago      Exited (137) 5 minutes ago                           daemon_container9b69de862ea9        ubuntu              &quot;/bin/bash&quot;              4 hours ago         Exited (127) About an hour ago                       the_container_of_john6e73587e0ffe        ubuntu              &quot;/bin/bash&quot;              5 hours ago         Exited (127) 4 hours ago                             determined_davinci</code></pre><h3 id="q-参数"><a class="header-anchor" href="#q-参数">¶</a>-q 参数</h3><p>只返回 docker 容器的 id</p><h3 id="命令输出参数列表"><a class="header-anchor" href="#命令输出参数列表">¶</a>命令输出参数列表</h3><p>从该命令的输出结果中我们可以看到关于这个容器的很多有用信息:短 UUID、用于创建该容器的镜像、容器最后执行的命令、创建时间以及容器的退出状态。</p><h2 id="docker-inspect"><a class="header-anchor" href="#docker-inspect">¶</a>docker inspect</h2><p>除了通过<code>docker ps</code> 命令获取容器的信息，我们还可以使用<code>docker inspect</code>来获取更多的容器信息（<strong>注意：该命令也可以用来获取镜像的详细信息</strong>）：</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker inspect daemon_container[    {        &quot;Id&quot;: &quot;e9436bfe00334d3ac0883621fa6ae92f679839fc82a0c76c315cf97dab513258&quot;,        &quot;Created&quot;: &quot;2020-04-02T05:32:46.739740589Z&quot;,        &quot;Path&quot;: &quot;/bin/sh&quot;,        &quot;Args&quot;: [            &quot;-c&quot;,            &quot;while true;do echo hello world;sleep 1;done&quot;        ],        &quot;State&quot;: {            &quot;Status&quot;: &quot;exited&quot;,            &quot;Running&quot;: false,            &quot;Paused&quot;: false,            &quot;Restarting&quot;: false,            &quot;OOMKilled&quot;: false,            &quot;Dead&quot;: false,            &quot;Pid&quot;: 0,            &quot;ExitCode&quot;: 137,            &quot;Error&quot;: &quot;&quot;,            &quot;StartedAt&quot;: &quot;2020-04-02T05:32:46.963093293Z&quot;,            ... ...</code></pre><p><code>docker inspect</code>命令会对容器进行详细的检查，然后返回其配置信息，包括名称、命令、网络配置以及很多有用的数据。</p><h3 id="f、–format-参数"><a class="header-anchor" href="#f、–format-参数">¶</a>-f、–format 参数</h3><p>我们也可以用<code>-f</code>或者<code>--format</code>参数来查看其中的一些项目，例如下面这条命令会返回容器的运行状态</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker inspect -f '{{.State.Running}}' daemon_containerfalse</code></pre><p>此外，我们还能获取 IP 地址：</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker inspect -f '{{.NetworkSettings.IPAddress}}' the_container_of_john172.17.0.2</code></pre><p>我们还可以同时指定多个容器，并显示每个容器的输出结果：</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker inspect -f &quot;{{.Name}} {{.State.Running}}&quot; the_container_of_john daemon_container/the_container_of_john true/daemon_container false</code></pre><blockquote><p><code>--format</code> 或者 <code>-f</code> 标志远非表面看上去那么简单。该标志实际上支持完整的Go语言模板。用它进行查询时,可以充分利用Go语言模板的优势。</p></blockquote><h2 id="docker-rm"><a class="header-anchor" href="#docker-rm">¶</a>docker rm</h2><p>如果容器已经不再使用,可以使用<code>docker rm</code>命令来删除它们：</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# docker rm daemon_containerdaemon_container</code></pre><p>目前，还没有办法一次删除所有容器，不过可以通过以下小技巧来删除全部容器：</p><pre><code>docker rm `docker ps -a -q`</code></pre><p>上面的<code>docker ps</code>命令会列出所有的全部容器，<code>-a</code>表示列出所有容器，<code>-q</code>表示只需要返回容器的 id 而不会返回容器的其他信息。这样我们就得到了容器 id 的列表，并作为参数传给了<code>docker rm</code>命令，从而达到删除所有容器的目的。</p><h1>容器知识</h1><p>下面我们基于上面创建的容器来研究以下这个容器：</p><h2 id="容器内部结构"><a class="header-anchor" href="#容器内部结构">¶</a>容器内部结构</h2><h3 id="hostname"><a class="header-anchor" href="#hostname">¶</a>hostname</h3><pre><code>root@6e73587e0ffe:/# hostname6e73587e0ffe</code></pre><p>可以看到，容器的主机名就是该容器的短 id</p><h3 id="hosts-文件"><a class="header-anchor" href="#hosts-文件">¶</a>hosts 文件</h3><pre><code>root@6e73587e0ffe:/# cat /etc/hosts127.0.0.1localhost::1localhost ip6-localhost ip6-loopbackfe00::0ip6-localnetff00::0ip6-mcastprefixff02::1ip6-allnodesff02::2ip6-allrouters172.17.0.26e73587e0ffe</code></pre><p>Docker 已在 hosts 文件中为该容器的 IP 地址添加了一条主机配置项<code>172.17.0.26e73587e0ffe</code></p><h3 id="安装软件"><a class="header-anchor" href="#安装软件">¶</a>安装软件</h3><p>当我们想查看容器的网卡情况的时候，发现没有 ifconfig 命令，此时通过以下命令进行安装：</p><pre><code>root@6e73587e0ffe:/# apt-get update &amp;&amp; apt-get install net-toolsHit:1 http://archive.ubuntu.com/ubuntu bionic InReleaseHit:2 http://security.ubuntu.com/ubuntu bionic-security InReleaseHit:3 http://archive.ubuntu.com/ubuntu bionic-updates InReleaseHit:4 http://archive.ubuntu.com/ubuntu bionic-backports InReleaseReading package lists... DoneReading package lists... DoneBuilding dependency treeReading state information... DoneThe following NEW packages will be installed:  net-tools0 upgraded, 1 newly installed, 0 to remove and 12 not upgraded.Need to get 194 kB of archives.After this operation, 803 kB of additional disk space will be used.Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 net-tools amd64 1.60+git20161116.90da8a0-1ubuntu1 [194 kB]Fetched 194 kB in 2s (129 kB/s)debconf: delaying package configuration, since apt-utils is not installedSelecting previously unselected package net-tools.(Reading database ... 4046 files and directories currently installed.)Preparing to unpack .../net-tools_1.60+git20161116.90da8a0-1ubuntu1_amd64.deb ...Unpacking net-tools (1.60+git20161116.90da8a0-1ubuntu1) ...Setting up net-tools (1.60+git20161116.90da8a0-1ubuntu1) ...</code></pre><h3 id="查看网卡情况"><a class="header-anchor" href="#查看网卡情况">¶</a>查看网卡情况</h3><pre><code>root@6e73587e0ffe:/# ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 172.17.0.2  netmask 255.255.0.0  broadcast 0.0.0.0        inet6 fe80::42:acff:fe11:2  prefixlen 64  scopeid 0x20&lt;link&gt;        ether 02:42:ac:11:00:02  txqueuelen 0  (Ethernet)        RX packets 3564  bytes 18160753 (18.1 MB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 3088  bytes 209488 (209.4 KB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 1  (Local Loopback)        RX packets 0  bytes 0 (0.0 B)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 0  bytes 0 (0.0 B)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</code></pre><p>我们可以看到,这里有10的环回接口,还有IP为172.17.0.2的标准eth0网络接口,和普通宿主机是完全一样的。</p><h3 id="查看容器中的进程"><a class="header-anchor" href="#查看容器中的进程">¶</a>查看容器中的进程</h3><pre><code>root@6e73587e0ffe:/# ps -auxUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDroot         1  0.0  0.0  18496  2028 ?        Ss   01:02   0:00 /bin/bashroot       486  0.0  0.0  34392  1460 ?        R+   01:46   0:00 ps -aux</code></pre><h3 id="退出容器"><a class="header-anchor" href="#退出容器">¶</a>退出容器</h3><p>你可以继续在容器中做任何自己想做的事情。当所有工作都结束时,输入exit,就可以返回到Ubuntu宿主机的命令行提示符了。</p><pre><code>root@6e73587e0ffe:/# exitexit[root@izwz920kp0myp15p982vp4z ~]#</code></pre><p>这个容器现在怎样了?容器现在已经停止运行了!<strong>只有在指定的/bin/bash命令处于运行状态的时候,我们容器也才会相应地处于运行状态。一旦退出容器,/bin/bash命令也就结束了，这时容器也随之停止了运行。</strong><br>但容器仍然是存在的，我们可以用<code>docker ps -a</code>命令查看当前系统中容器的列表。</p><h2 id="容器本身的知识"><a class="header-anchor" href="#容器本身的知识">¶</a>容器本身的知识</h2><h3 id="唯一标识"><a class="header-anchor" href="#唯一标识">¶</a>唯一标识</h3><p>有三种方式可以指代唯一容器:短UID(如6e73587e0ffe)、长UUID(如6e73587e0ffee03c9438c729345e54db9d20cfa2ac1fc3494b6eb60872e74778)或者名称(如determined_davinci)。<br>如果我们在创建容器的时候没有指定容器的名称，Docker 会为我们创建的每一个容器自动生成一个随机的名称。例如我们上面创建的容器就被命名为<code>determined_davinci</code>。</p><h3 id="容器目录"><a class="header-anchor" href="#容器目录">¶</a>容器目录</h3><p><code>/var/lib/docker</code>目录存放着 Docker 镜像、容器以及容器的配置。所有容器都保存在<code>/var/lib/docker/containers</code>目录下。我们可以通过浏览这些目录来深入了解 docker 的工作原理。</p><h3 id="在容器中运行Docker"><a class="header-anchor" href="#在容器中运行Docker">¶</a>在容器中运行Docker</h3><p>可以在<a href="https://github.com/jpetazzo/dind" target="_blank" rel="noopener">https://github.com/jpetazzo/dind</a>读到更多关于在Docker中运行Docker的细节。</p><h2 id="容器网络"><a class="header-anchor" href="#容器网络">¶</a>容器网络</h2><p>在安装 Docker 时,会创建一个新的网络接口,名字是<code>docker0</code>。每个 Docker容器都会在这个接口上分配一个IP地址。来看看目前 Docker宿主机上这个网络接口的信息:</p><pre><code>[root@izwz920kp0myp15p982vp4z redis]# ifconfigdocker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 172.17.0.1  netmask 255.255.0.0  broadcast 0.0.0.0        ether 02:42:c5:a1:6e:4a  txqueuelen 0  (Ethernet)        RX packets 255449  bytes 16639041 (15.8 MiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 275461  bytes 939889264 (896.3 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 172.18.93.184  netmask 255.255.240.0  broadcast 172.18.95.255        ether 00:16:3e:12:76:f9  txqueuelen 1000  (Ethernet)        RX packets 10182467  bytes 2530603025 (2.3 GiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 8922551  bytes 8099089849 (7.5 GiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        loop  txqueuelen 1  (Local Loopback)        RX packets 9472  bytes 73899790 (70.4 MiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 9472  bytes 73899790 (70.4 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0veth74b3a7f: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        ether 2a:05:a6:c1:f7:36  txqueuelen 0  (Ethernet)        RX packets 14  bytes 1339 (1.3 KiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 34  bytes 2697 (2.6 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0vethbacb313: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        ether 2a:54:63:85:14:df  txqueuelen 0  (Ethernet)        RX packets 49  bytes 10915 (10.6 KiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 71  bytes 5328 (5.2 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</code></pre><p><code>docker0</code>接口有符合<code>RFC1918</code>的私有IP地址,范围是172.16~172.30。接口本身的地址172.17.0.1是这个Docker网络的网关地址,也是所有Docker容器的网关地址。</p><blockquote><p>Docker会默认使用172.17.x,x作为子网地址,除非已经有别人占用了这个子网。如果这个子网被占用了, Docker会在172.16~172.30这个范国内尝试创建子网。</p></blockquote><p>接口<code>docker0</code>是一个虚拟的以太网桥,用于连接容器和本地宿主网络。如果进一步查看Docker宿主机的其他网络接口,会发现一系列名字以&quot;veth&quot;开头的接口：</p><pre><code>... ...veth74b3a7f: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500... ...vethbacb313: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500... ...</code></pre><p>Docker每创建一个容器就会创建一组互联的网络接口。这组接口就像管道的两端(就是说,从一端发送的数据会在另一端接收到)。这组接口其中一端作为容器里的<code>eth0</code>接口, 而另一端统一命名为类似 <code>vethexxxx</code> 这种名字, 作为宿主机的一个端口。你可以把<code>veth</code>接口认为是虚拟网线的一端。这个虚拟网线一端插在名为<code>docker0</code>的网桥上, 另一端插到容器里。把每个<code>veth</code>接口绑定到<code>docker0</code>网桥, 这样Docker就创建了一个虚拟子网,这个子网由宿主机和所有的Docker容器共享。<br>进入容器里面,看看这个子网管道的另一端:</p><pre><code>root@317e82905350:/# ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 172.17.0.4  netmask 255.255.0.0  broadcast 0.0.0.0        inet6 fe80::42:acff:fe11:4  prefixlen 64  scopeid 0x20&lt;link&gt;        ether 02:42:ac:11:00:04  txqueuelen 0  (Ethernet)        RX packets 8161  bytes 18462877 (18.4 MB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 7878  bytes 674670 (674.6 KB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 1  (Local Loopback)        RX packets 0  bytes 0 (0.0 B)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 0  bytes 0 (0.0 B)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</code></pre><p>可以看到，Docker 给容器分配了 IP 地址172.17.0.4作为宿主接口的另一端，这样就能够让宿主网络和容器互相通信了。<br>让我们从容器内跟踪对外通信的路由,看看是如何建立连接的</p><pre><code>root@317e82905350:/# traceroute baidu.comtraceroute to baidu.com (39.156.69.79), 30 hops max, 60 byte packets 1  172.17.0.1 (172.17.0.1)  0.027 ms  0.010 ms  0.008 ms 2  * * * 3  11.220.36.1 (11.220.36.1)  7.016 ms 11.220.37.1 (11.220.37.1)  7.733 ms 11.220.36.65 (11.220.36.65)  7.698 ms 4  * * * 5  11.217.38.202 (11.217.38.202)  0.425 ms 11.217.38.250 (11.217.38.250)  0.389 ms 11.217.38.218 (11.217.38.218)  0.364 ms 6  42.120.253.9 (42.120.253.9)  1.123 ms 117.49.35.198 (117.49.35.198)  1.267 ms 116.251.117.158 (116.251.117.158)  1.212 ms 7  42.120.242.229 (42.120.242.229)  2.024 ms 117.49.38.34 (117.49.38.34)  2.471 ms 117.49.38.30 (117.49.38.30)  2.167 ms ... ...</code></pre><p>可以看到，容器地址后的下一跳就是宿主网络上<code>docker0</code>接口的网关 IP 172.17.0.1。</p><p>不过 Docker网络还有另一个部分配置才能允许建立连接: 防火墙规则和NAT配置。这些配置允许 Docker在宿主网络和容器间路由。现在来査看一下宿主机上的 Iptables NAT 配置：</p><pre><code>[root@izwz920kp0myp15p982vp4z ~]# sudo iptables -t nat -L -nChain PREROUTING (policy ACCEPT)target     prot opt source               destinationDOCKER     all  --  0.0.0.0/0            0.0.0.0/0            ADDRTYPE match dst-type LOCALChain INPUT (policy ACCEPT)target     prot opt source               destinationChain OUTPUT (policy ACCEPT)target     prot opt source               destinationDOCKER     all  --  0.0.0.0/0           !127.0.0.0/8          ADDRTYPE match dst-type LOCALChain POSTROUTING (policy ACCEPT)target     prot opt source               destinationMASQUERADE  all  --  172.17.0.0/16        0.0.0.0/0MASQUERADE  tcp  --  172.17.0.2           172.17.0.2           tcp dpt:4567MASQUERADE  tcp  --  172.17.0.3           172.17.0.3           tcp dpt:6379Chain DOCKER (2 references)target     prot opt source               destinationRETURN     all  --  0.0.0.0/0            0.0.0.0/0DNAT       tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:32770 to:172.17.0.2:4567DNAT       tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:32771 to:172.17.0.3:6379</code></pre><p>这里有几个值得注意的 Iptables 规则。首先,我们注意到,容器默认是无法访问的。从宿主网络与容器通信时, 必须明确指定打开的端口。下面我们以DNAT(即目标NAT)这个规则为例, 这个规则把容器里的访问路由到 Docker宿主机的32770端口</p><blockquote><p>关于更多的 Docker 的高级网络配置，可以参考:<a href="https://docs.docker.com/articles/networking" target="_blank" rel="noopener">https://docs.docker.com/articles/networking</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTML简述序言</title>
      <link href="/2020/12/22/web-qian-duan/h5/html/"/>
      <url>/2020/12/22/web-qian-duan/h5/html/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1>HTML简述序言</h1><h2 id="HTML基础"><a class="header-anchor" href="#HTML基础">¶</a>HTML基础</h2><h3 id="1-软件开发架构"><a class="header-anchor" href="#1-软件开发架构">¶</a>1. 软件开发架构</h3><ul><li>C/S架构：分客户端和服务端，即可以在客户端处理请求，也可以在服务端处理。</li><li>B/S架构：分浏览器和服务器，只是在服务端处理请求，浏览器只是显示数据。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222001403.png" alt="Image"></p><h3 id="2-HTML基础"><a class="header-anchor" href="#2-HTML基础">¶</a>2. HTML基础</h3><h4 id="1-HTTP协议"><a class="header-anchor" href="#1-HTTP协议">¶</a>1&gt;HTTP协议</h4><p>Hyper Text Transfer Protocol 超文本传输协议，我们写的HTML网页运行在HTTP协议上。HTML遵守W3C规范。</p><h4 id="2-W3C"><a class="header-anchor" href="#2-W3C">¶</a>2&gt;W3C</h4><p>万维网联盟，一个非盈利性组织。万维网俩能创建于1994年，是Web技术领域最具权威和影响力的国际中性技术标准机构。到目前为止，W3C已发布了200多项影响深远的Web技术标准及实施指南。</p><h4 id="3-HTML"><a class="header-anchor" href="#3-HTML">¶</a>3&gt;HTML</h4><p>Hyper Text Markup Language超文本标记语言。浏览器是网页的载体，所有浏览器按照 HTML 标准进行开发，目的是解析 HTML 标准下的语义按照规则展示网页内容。HTML 标准由 W3C (World Wide Web Consortium）组织（非盈利）制定。</p><ul><li>超文本：不同于普通文本，可以描述图片，音频，视频，链接等非字符串对象。</li><li>标记语言：这是一种运行在浏览器上的语言，由各种标记组成，不同于Java，没有逻辑控制。</li></ul><h4 id="4-HTML5"><a class="header-anchor" href="#4-HTML5">¶</a>4&gt;HTML5</h4><p>HTML5 不再代表HTML网页编程语言标准，而是围绕着HTML这个东西以及它周边的一系列网页相关技术的总称，既包含了HTML+CSS的网页制作，也包含了javascript这门编程语言的相关开发。H5 是它的简称。WEB 前端是它的别称。</p><h4 id="5-XML和HTML的区别"><a class="header-anchor" href="#5-XML和HTML的区别">¶</a>5&gt;XML和HTML的区别</h4><p>个人理解：XML中的标签默认为字符串对象，只能处理字符串对象。</p><p>HMTL中的标签都是对应的一个类的对象，具有其具体的功能。我们可以认为HTML就是一份XML，这份XML的约束已经好了，例如根标签只能是<code>&lt;html&gt;</code>，<code>&lt;html&gt;</code>下面可以是<code>&lt;head&gt;</code>，之后是…然后这些标签都是对应了一个JavaBean（包括html标签），这个类具有一定的功能，例如html就是一个用来实现超文本展示的对象，head是用来展示网页的title…</p><p>HTML的格式源自XML导入了HTML的约束，HTML的约束文件编写参考JavaBean内的成员变量，这些用来实现展示数据或者布局的JavaBean响应人们的需求而诞生。版本越高的HTML自然实现了更高级的JavaBean，自然就能实现展示更高级的数据。</p><table><thead><tr><th></th><th><strong>XML</strong></th><th><strong>HTML</strong></th></tr></thead><tbody><tr><td><strong>名字</strong></td><td>eXtensible Markup Language</td><td>Hyper Text Markup Language</td></tr><tr><td><strong>扩展性</strong></td><td>标签由用户自己写的<code>&lt;name&gt;</code>潘金莲<code>&lt;/name&gt;</code></td><td>不能扩展的，所有的标签都是固定，功能也是固定的。由w3c制定，如：<code>&lt;br/&gt;</code>换行</td></tr><tr><td><strong>大小写敏感性</strong></td><td>敏感<code>&lt;abc&gt;</code>与<code>&lt;ABC&gt;</code>两个不同标签</td><td>不敏感<code>&lt;br/&gt;</code>或<code>&lt;BR/&gt;</code>功能是一样，建议使用小写</td></tr><tr><td><strong>功能</strong></td><td>用于软件的配置，数据的存储</td><td>用于表示层，把数据显示给用户</td></tr></tbody></table><h3 id="3-HTML版本"><a class="header-anchor" href="#3-HTML版本">¶</a>3. HTML版本</h3><ul><li>HTML4用于电脑上比较多</li><li>HTML5主要用于移动端</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222001412.png" alt="FD027DE9-70AA-491A-9101-36AC4D23F3EF"></p><h3 id="4-HTML开发工具"><a class="header-anchor" href="#4-HTML开发工具">¶</a>4. HTML开发工具</h3><ul><li>Microsoft FrontPage 前端页面：微软的产品，目前已经淘汰。</li><li>Adobe Dreamweaver 织梦者：用于网页设计人员与代码编程人员。</li><li>HBuilder 用于网页开发工具，国产。提示功能强大。</li></ul><h3 id="5-HBuilder"><a class="header-anchor" href="#5-HBuilder">¶</a>5. HBuilder</h3><p>HBuilder是DCloud（数字天堂）推出的一款支持HTML5的Web开发IDE。HBuilder的编写用到了Java、C、Web和Ruby。HBuilder本身主体是由Java编写。它基于Eclipse，所以顺其自然地兼容了Eclipse的插件。数字天堂公司是HTML5联盟成员，在前端方面非常具有权威的。</p><ol><li><p>安装：直接解压就可以使用,双击运行如下文件：（注意第一次使用会让你登录，可以选择暂不登录）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201127115856.png" alt="39A39497-B322-4953-969A-EDACCAE11189-6449536"></p><p>进入开发环境的页面效果</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201222001419.png" alt="C8B09C20-7912-460D-AB68-F23EAF3F1E93"></p></li><li><p>使用：</p><ol><li><p>确定工作空间</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201127120042.png" alt="542A211D-E105-445E-8848-D3A133E372C4"></p></li><li><p>新建工程项目（web项目）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201127120205.png" alt="FE728A90-82BA-4FF8-830F-CF7EEC4F4EE8-6449693"></p></li><li><p>填写项目名字</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201127120323.png" alt="F721B444-2883-426A-B25A-6CFCC9F37809"></p></li><li><p>选择项目day28鼠标右键新建html网页，选择html4.01模板，开始写代码</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201127120605.png" alt="D37FF914-7383-4BA3-8F25-7E215777F62C"></p></li><li><p>编写文件名，勾选html4.01模板</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201127120635.png" alt="B3273635-FE0F-46FF-B414-3970ABC2B621"></p></li><li><p>编写代码</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201127120656.png" alt="854E728C-CCB3-4131-9173-D91079DA6120"></p></li><li><p>效果</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201127122843.png" alt="94E8757B-1144-4E8F-BF9A-AE1BC8FF5F3A"></p></li></ol></li></ol>]]></content>
      
      
      <categories>
          
          <category> web前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> html </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vue 学习资料</title>
      <link href="/2020/12/22/web-qian-duan/vue-xue-xi-zi-liao/"/>
      <url>/2020/12/22/web-qian-duan/vue-xue-xi-zi-liao/</url>
      
        <content type="html"><![CDATA[<p><a href="https://cn.vuejs.org/v2/guide/" target="_blank" rel="noopener">基本功能</a></p><p><a href="https://cli.vuejs.org/zh/" target="_blank" rel="noopener">CLI 脚手架工具</a></p><p><a href="https://router.vuejs.org/zh/guide/#javascript" target="_blank" rel="noopener">路由</a></p><blockquote><p>利用 bom 的 location 或者 history 配合 window.onhashchange 或者 window.onpopstate</p></blockquote><p><a href="https://vuex.vuejs.org/zh/" target="_blank" rel="noopener">vuex：状态管理/存储层</a></p><p><a href="https://github.com/robinvdvleuten/vuex-persistedstate" target="_blank" rel="noopener">vuex-persistedstate：非官方支持的持久化的状态管理</a></p><p><a href="https://github.com/vuejs/awesome-vue" target="_blank" rel="noopener">awesomevue项目</a></p><p><a href="https://element.eleme.cn/#/zh-CN/component/installation" target="_blank" rel="noopener">element UI：饿了么开源 PC 端 vue 组件库</a></p><p><a href="https://youzan.github.io/vant/#/zh-CN/" target="_blank" rel="noopener">vant UI: 有赞开源移动端 vue 组件库</a></p>]]></content>
      
      
      <categories>
          
          <category> web前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> vue </tag>
            
            <tag> 学习资料 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Eureka的自我保护机制</title>
      <link href="/2020/12/22/springcloud/eureka-de-zi-wo-bao-hu-ji-zhi/"/>
      <url>/2020/12/22/springcloud/eureka-de-zi-wo-bao-hu-ji-zhi/</url>
      
        <content type="html"><![CDATA[<h1>自我保护机制介绍</h1><p>当检测到同时有大量已注册客户端因为非正常断开连接然后准备从注册列表剔除，Eureka 服务器就会进入自我保护模式(self-presevation mode)。这是为了保证大规模网络中断事件不会导致 eureka 的注册时间被抹掉并传播到所有客户端(消费者)。</p><p>eureka 中已注册客户端被剔除方式：</p><ol><li>对于 eureka 的协议，客户端停止注册的正常流程应该使执行一个明确的动作。例如：在 java 客户端中的 <code>shutdown</code> 方法。</li><li>另外，如果 eureka server 在连续 3 个 heartbeat 周期时间单位内没有收到一个客户端的心跳包，就会认为这个客户端&quot;不明确的中断了&quot;，将会在后台的剔除任务中从注册列表剔除这个客户端。</li></ol><p>自我保护模式针对的使第二种断开方式，当有超过 15% 已注册客户端处于这种状态的时候，自我保护模式将会被开启。自我保护模式开启后，将会停止所有客户端剔除工作，直到以下任一条件满足为止：</p><ul><li>eureka server 检测到恢复心跳的客户端超过了期望阈值</li><li>自我保护模式被关闭</li></ul><p>自我保护模式在默认情况下使开启的，默认开启自我保护模式的阈值是当前注册客户端数量的 15%。</p><h1>个人理解</h1><p>和大多数注册中心(服务发现)一样，消费者从注册中心获取服务提供方联系信息，直接对生产者发起远程调用(k8s 的服务发现不是)。如果存在&quot;少量&quot;服务方不明确地不可达的时候，通常来说，注册中心同步这个消息到消费者不会出现大问题。</p><p>相对的，如果使短时间内大量服务不可达的时候，这个消息如果同步到消费者，那么这个微服务构建的分布式系统将明确的进入不可响应状态。但是同时出现大量生产者 crash 的情况是较低概率的，一般是网络问题导致，即生产者到注册中心之间的链路出现了问题，但是消费者到生产者的链路可能是没问题的，所以 eureka 在这方面采用保守做法，保留自己的注册信息从而使得消费者中已经同步的生产信息不被删除。</p><h1>相关服务端配置</h1><ul><li><code>eureka.renewalPercentThreshold</code>：指定触发自我保护模式的阈值（多少已注册客户端非正常断开），范围是 [0.0, 1.0]。</li><li><code>eureka.enableSelfPreservation</code>：是否开启自我保护模式，true开启、false关闭</li><li><code>eureka.server.eviction-interval-timer-in-ms</code>：客户端剔除时间窗口，个人理解是一个断开连接的客户端最迟要在&quot;确定断开的时间点&quot;之后该时间间隔内从注册中心剔除。单位 ms 。</li></ul><h1>相关客户端配置</h1><ul><li><code>eureka.client.lease-renewal-interval-in-seconds</code>：客户端向服务端续约的时间间隔(发送心跳包)。单位 s。</li><li><code>eureka.client.lease-expiration-duration-in-seconds</code>：告诉服务端发送的租约(心跳包)过期时间。单位 s。（检测是否需要启动自我保护机制的时间单位）</li></ul><h1>参考阅读</h1><ul><li><a href="https://github.com/Netflix/eureka/wiki/Server-Self-Preservation-Mode" target="_blank" rel="noopener">官方介绍</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> springcloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> eureka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nodejs 入门</title>
      <link href="/2020/12/22/web-qian-duan/nodejs/nodejs-ru-men/"/>
      <url>/2020/12/22/web-qian-duan/nodejs/nodejs-ru-men/</url>
      
        <content type="html"><![CDATA[<h1>简介与安装</h1><h2 id="什么是-Node-js"><a class="header-anchor" href="#什么是-Node-js">¶</a>什么是 Node.js</h2><ul><li><p>Node.js 是一个基于 Chrome V8 引擎的 JavaScript <strong>运行环境</strong>。</p></li><li><p>Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型，使其轻量又高效。</p></li><li><p>Node.js 的包管理器 npm，是全球最大的开源库生态系统。</p></li></ul><p>Node.js 可以解析JS代码（没有浏览器安全级别的限制）提供很多系统级别的API，如：</p><ul><li><p>文件的读写</p></li><li><p>进程的管理</p></li><li><p>网络通信</p></li><li><p>……</p></li></ul><h2 id="准备-Node-js"><a class="header-anchor" href="#准备-Node-js">¶</a>准备 Node.js</h2><p>使用 nvm 可以在本地安装并维护<strong>多个</strong>Node.js的版本</p><p>1、项目地址：</p><p><a href="https://github.com/creationix/nvm/blob/master/README.md" target="_blank" rel="noopener">https</a><a href="https://github.com/creationix/nvm/blob/master/README.md" target="_blank" rel="noopener">://</a><a href="https://github.com/creationix/nvm/blob/master/README.md" target="_blank" rel="noopener">github.com/creationix/nvm/blob/master/README.md</a></p><p>2、配置加速镜像：</p><p>export NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node</p><h2 id="命令行中的体验"><a class="header-anchor" href="#命令行中的体验">¶</a>命令行中的体验</h2><pre class="line-numbers language-language-shell"><code class="language-language-shell">$ node 进入命令行<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol><li><p>在浏览器和node命令行中运行代码</p><pre class="line-numbers language-language-js"><code class="language-language-js">function add(x, y){  console.log(x+y);}add(3, 4)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>在浏览器和node命令行里调用 window, process 两个对象</p></li></ol><blockquote><p>nodejs可以调用操作系统内核 api（io、进程等）；浏览器中可以调用浏览器内核 api（bom、dom）</p></blockquote><h2 id="执行-js-文件"><a class="header-anchor" href="#执行-js-文件">¶</a>执行 .js 文件</h2><ol><li><p>编写 index.js 文件</p><pre class="line-numbers language-language-js"><code class="language-language-js">console.log('hello');function add(x,y) { console.log(x+y);}add(6,7);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><code>node index.js</code> 执行代码（省略 <code>.js</code> 后缀也可以）</p></li></ol><h2 id="一些工具"><a class="header-anchor" href="#一些工具">¶</a>一些工具</h2><ul><li><p>npm：包管理器</p></li><li><p>cnpm：使用国内镜像</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">sudo npm install -g cnpm --registry=https://registry.npm.taobao.org<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>gulp：文件管理、css预编译等</p></li><li><p>@vue/cli：vue 官方脚手架工具</p></li><li><p>nodemon：可以实时监听脚本的变化以及自动执行</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">cnpm install -g nodemonnodemon xxx.js<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><h2 id="使用不同版本的-Node-js"><a class="header-anchor" href="#使用不同版本的-Node-js">¶</a>使用不同版本的 Node.js</h2><p>查看有哪些版本：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">nvm ls<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过以下两个命令都可以查看正在使用的版本</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 1nvm run node –version# 2npm -v<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>以某个版本运行某个脚本文件：</p><ul><li><p>方式一</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 直接通过 nvm run 命令执行脚本nvm run v6.11.2 script.js<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>方式二</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 在当前目录创建一个.nvmrc 版本文件, 文件内容为某个版本，如：8.4.0。然后执行以下命令nvm use# 再执行具体的脚本node script.js<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h1>Node.js 特性</h1><h2 id="CommonJS规范-http-www-commonjs-org"><a class="header-anchor" href="#CommonJS规范-http-www-commonjs-org">¶</a>[CommonJS规范](<a href="http://www.commonjs.org" target="_blank" rel="noopener">http://www.commonjs.org</a></h2><p>)</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201212211734.png" alt></p><h2 id="Node-js-模块"><a class="header-anchor" href="#Node-js-模块">¶</a>Node.js 模块</h2><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201212212107.png" alt></p><h2 id="package-json"><a class="header-anchor" href="#package-json">¶</a>package.json</h2><p>在当前项目目录(ECMAScript工程)下创建一个 <code>package.json</code> 文件记录工程的信息以及其依赖的模块，由 npm 或者 yarn 等工具读取管理。使用命令即可在当前目录下创建一个该文件，即初始化一个工程：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">npm init<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-language-json"><code class="language-language-json">{  "name": "nodejs-day1-1",  "version": "1.0.0",  "description": "",  "main": "index.js",  "dependencies": {    // commonjs版本约定有三位，分别是 major、minor、patch    // ^ 表示 major 固定，取最新版本；~ 表示 major 和 minor 固定，取最新版本；* 表示取最新版本    "underscore": "^1.8.3"  },// 开发环境的依赖。    "devDependencies": {    "cheerio": "^0.22.0",    "gulp": "*"  },  // scripts 模块定义一些自定义 npm 命令。如下面生成的命令为 npm test、npm start；分别将它们的 value 作为命令执行。  "scripts": {    "test": "echo \"Error: no test specified\" && exit 1",    "start": "node server.js"  },  "author": "",  "license": "ISC"} <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="安装模块"><a class="header-anchor" href="#安装模块">¶</a>安装模块</h2><p>当使用 <code>-g</code> 的时候表示在全局安装模块</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 在全局安装 request 模块npm install request -g<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>没有 <code>-g</code> 的时候表示在当前工程中创建一个模块，默认认为在当前目录下存在一个 <code>package.json</code> 文件：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">npm install request --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>--save</code> 表示将这个模块记录到当前项目的 package.json 的依赖项中：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># package.json 的 dependencies 中记录了 request 模块{  "name": "hello",  "version": "1.0.0",  "description": "",  "main": "index.js",  "scripts": {    "test": "echo \"Error: no test specified\" && exit 1"  },  "author": "",  "license": "ISC",  "dependencies": {    "request": "^2.81.0"  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当在当前工程安装完成依赖模块之后，会在工程目录下生成一个 <code>node_modules</code> 目录，里面就是安装的依赖包</p><h2 id="模块定义、导出和导入"><a class="header-anchor" href="#模块定义、导出和导入">¶</a>模块定义、导出和导入</h2><h3 id="commonjs"><a class="header-anchor" href="#commonjs">¶</a>commonjs</h3><p>导出模块为 hello 函数为一个名为 hello 的模块</p><pre class="line-numbers language-language-js"><code class="language-language-js">const hello = () => {  console.log('hello ~');}//module.exports 是写死的语法，相当于一个模块集合对象，下面的 require 得到的就是这个对象，通过 .模块名 获取具体的模块module.exports.hello = hello<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>导入自己定义的模块，使用 <code>./</code> 表示这个模块是在当前自己项目中定义的，避免如扫描内置模块或者第三方模块</p><pre class="line-numbers language-language-js"><code class="language-language-js">// require 中指定模块所在的 js 文件路径const greeting = require('./src/greeting.js')greeting.hello()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模块化参考阅读"><a class="header-anchor" href="#模块化参考阅读">¶</a>模块化参考阅读</h3><p><a href="https://medium.com/computed-comparisons/commonjs-vs-amd-vs-requirejs-vs-es6-modules-2e814b114a0b" target="_blank" rel="noopener">commonjs、amd、requirejs、es6模块</a></p><p><a href="https://2ality.com/2014/09/es6-modules-final.html" target="_blank" rel="noopener">ECMAScript 6 modules: the final syntax</a></p><h2 id="npm-的一些命令"><a class="header-anchor" href="#npm-的一些命令">¶</a>npm 的一些命令</h2><pre class="line-numbers language-language-shell"><code class="language-language-shell"># -g、--global 表示全局。不加就是当前项目npm list # 查看安装包列表npm info <package name> # 查看具体包的所有版本及其它详细信息npm init # 初始化工程包管理文件配置信息npm install # 按照当前目录的 package.json 文件依赖进行安装npm install <package name>@<version> # 安装具体版本的包npm install <package> --save # 安装模块并添加到配置文件依赖项 npm uninstall <pacakge> --save-dev # 卸载模块并将其在配置文件的开发依赖项中删除npm outdated # 显示安装的包的版本、配置文件中依赖的可以下载的最新版本、最新版本npm cache clean # 清除 npm 包管理缓存<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1><a href="http://nodejs.cn/api/" target="_blank" rel="noopener">Node.js 内置常用模块</a></h1><h2 id="URL"><a class="header-anchor" href="#URL">¶</a>URL</h2><p>对一个字符串安装 URL 格式解析成一个 json 对象</p><pre class="line-numbers language-language-js"><code class="language-language-js">// 第一个参数传入的就是 URL 字符串// 第二个参数是一个boolean值，表示是否将 query 串也解析成一个json对象，否则原封不同就是一个字符串('&'分隔)// 第三个参数也是一个boolean值，表示在协议未确定的情况下是否推测解析出 host 和 porturl.parse(urlString[, parseQueryString[, slashesDenoteHost]])// 将上面的返回值，即一个 json 对象转成一个 url 字符串url.format(urlObject)// 拼接 URL 字符串，from 一般是一个 host、to 一般是一个 pathurl.resolve(from, to)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="querystring"><a class="header-anchor" href="#querystring">¶</a>querystring</h2><pre class="line-numbers language-language-js"><code class="language-language-js">// 将一个对象转成一个字符串，默认按照 http URL 中的 query 串的格式进行转换// 第一个参数就是要转换的 json 对象// 第二个参数是每一个属性键值对之间的分隔符// 第三个参数是每一对属性键值之间的分隔符querystring.stringify(obj[, sep[, eq[, options]]])// 和上面的方法相反querystring.parse(str[, sep[, eq[, options]]])// 对传入字符串进行 URL 编码querystring.escape(str)// 对传入字符串进行 URL 解码querystring.unescape(str)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="http、https"><a class="header-anchor" href="#http、https">¶</a><a href="http://nodejs.cn/api/http.html" target="_blank" rel="noopener">http、https</a></h2><p>小爬虫实现：</p><pre class="line-numbers language-language-js"><code class="language-language-js">var http = require('http')var https = require('https')var cheerio = require('cheerio')var url = 'https://www.lagou.com/'function filterMenu(html) {  var $ = cheerio.load(html)  var menu = $('.menu_main')  var menuData = []  menu.each(function(index, value){    var menuTitle = $(value).find('h2').text()    var menuLists = $(value).find('a')    var menuList = []    menuLists.each(function(index, value){      menuList.push($(value).text())    })    menuData.push({      menuTitle: menuTitle,      menuList: menuList    })  })  return menuData;}function printMenu(menu) {  menu.forEach(function(value){    console.log(value.menuTitle + '\n')    value.menuList.forEach(function(value){      console.log(value)    })  })}https.get(url, function(res){  var html = ''  res.on('data', function(data){    html += data  })  res.on('end', function(){    var result = filterMenu(html)    printMenu(result)  })  res.on('error', function(err){    console.log(err)  })})<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="事件监听处理机制"><a class="header-anchor" href="#事件监听处理机制">¶</a>事件监听处理机制</h2><pre class="line-numbers language-language-js"><code class="language-language-js">// 引入事件机制模块const EventEmitter = require('events')// 实现自己的类继承事件机制类class Player extends EventEmitter {}// 新建事件机制对象var player = new Player()//on 方法表示发布某个事件监听及其处理器，且一直监听；once 方法表示只监听处理一次该事件//第一个参数是事件名称，第二个参数是事件处理函数player.once('play', (track) => {  console.log(`正在播放:《${track}》`)})//emit 方法表示触发某个事件//第一个参数是事件名称，第二个参数是事件本身player.emit('play', '精绝古城')player.emit('play', '黄皮子坟')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="File-System"><a class="header-anchor" href="#File-System">¶</a>File System</h2><ul><li>得到文件与目录的信息：stat</li><li>创建一个目录：mkdir</li><li>创建文件并写入内容：writeFile,appendFile</li><li>读取文件的内容：readFile</li><li>列出目录的东西：readdir</li><li>重命名目录或文件：rename</li><li>删除目录与文件：rmdir,unlink</li></ul><h2 id="Stream"><a class="header-anchor" href="#Stream">¶</a>Stream</h2><ul><li>读取文件流</li><li>可读流的事件</li><li>可写的文件流</li><li>pipe链式使用</li><li>pipe</li></ul><h2 id="网络"><a class="header-anchor" href="#网络">¶</a>网络</h2><h3 id="net-模块-socket-编程"><a class="header-anchor" href="#net-模块-socket-编程">¶</a>net 模块 socket 编程</h3><p>SocketServer.js：</p><pre class="line-numbers language-language-js"><code class="language-language-js">var net = require('net')var chatServer = net.createServer(),    clientMap = new Object()var i = 0 //连接名称的流水号chatServer.on('connection', function (client) {  console.log('客户端有人连接~')  client.name = ++i  clientMap[client.name] = client  // 对客户端发送消息的监听  client.on('data', function (data) {    console.log('客户端传来：' + data)    broadcast(data, client)  })  // 数据错误事件处理  client.on('error', function (e) {    console.log('client error' + e);    client.end()  })  // 客户端关闭事件  client.on('close', function (data) {    delete clientMap[client.name]    console.log(client.name + '下线了');    broadcast(client.name + '下线了', client)  })})// 消息广播function broadcast(message, client) {  for (var key in clientMap) {    clientMap[key].write(client.name + 'say:' + message + '\n')  }}chatServer.listen(9000)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>SocketClient.js：</p><pre class="line-numbers language-language-js"><code class="language-language-js">var net = require('net')var port = 9000var host = '127.0.0.1'var client = new net.Socket()client.setEncoding = 'UTF-8'// 连接服务器client.connect(port, host, function () {  client.write('您好')})client.on('data', function (data) {  console.log('服务端传来：' + data);  say()})client.on('error', function (err) {  console.log('error' + err);})client.on('close', function () {  console.log('connection closeed');})const readline = require('readline')const r1 = readline.createInterface({  input: process.stdin,  output: process.stdout})function say() {  r1.question('请输入：', (inputStr) => {    if (inputStr != 'bye') {      client.write(inputStr + '\n')    } else {      client.distroy() //关闭连接      r1.close()    }  })}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="浏览器原生支持-WebSocket"><a class="header-anchor" href="#浏览器原生支持-WebSocket">¶</a>浏览器原生支持 WebSocket</h3><p>WsServer.js</p><pre class="line-numbers language-language-js"><code class="language-language-js">var WebSocketServer = require('ws').Server,    wss = new WebSocketServer({port: 9000})var clientMap = new Object()var i = 0wss.on('connection', function (ws) {  console.log(ws + '上线')  ws.name = ++i  clientMap[ws.name] = ws  ws.on('message', function (message) {    broadcast(message, ws)  })  ws.on('close', function () {    // global.gc() //调用内存回收    console.log('离开');  })})function broadcast(msg, ws) {  for (var key in clientMap) {    clientMap[key].send(ws.name + '说: ' + msg)  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>WsClient.js，被聊天框页面用 script 标签引入，可以看到 WebSocket 对象是浏览器内置对象，不用导入：</p><pre class="line-numbers language-language-js"><code class="language-language-js">var ws = new WebSocket('ws://127.0.0.1:9000/')ws.onopen = function () {  ws.send('大家好')}ws.onmessage = function (event) {  var chatroot = document.querySelector('#chatroom')  chatroom.innerHTML += '<br/>' + event.data}ws.onclose = function () {  alert('Closed')}ws.onerror = function (err) {  alert('Error:' + err)}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>聊天框页面：</p><pre class="line-numbers language-language-html"><code class="language-language-html"><!DOCTYPE html><html lang="en"><head>  <meta charset="UTF-8">  <meta name="viewport" content="width=device-width, initial-scale=1.0">  <meta http-equiv="X-UA-Compatible" content="ie=edge">  <title>ws client</title></head><body>  <h1>WebSocket</h1>  <div id="chatroom" style="width:400px;height:300px;overflow:auto;border:1px solid blue"></div>  <input type="text" name="sayinput" id="sayinput" value="">  <input type="button" name="send" id="sendbutton" value="发送">  <script src="WsClient.js" charset="utf-8"></script>  <script type="text/javascript">    function send() {      ws.send(sayinput.value)      sayinput.value = ''    }    document.onkeyup = function (event) {      if (event.keycode == 13) {        send()      }    }    sendbutton.onclick = function () {      send()    }  </script></body></html><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="兼容性好的-socketio"><a class="header-anchor" href="#兼容性好的-socketio">¶</a>兼容性好的 <a href="https://socket.io/" target="_blank" rel="noopener">socketio</a></h3><p>上面的 WebSocket 实现需要兼容 html5 的浏览器才可行。Socket io 则兼容一切浏览器。</p><h1>第三方模块</h1><h2 id="Async"><a class="header-anchor" href="#Async">¶</a><a href="https://www.npmjs.com/package/async" target="_blank" rel="noopener">Async</a></h2><p>示例：</p><pre class="line-numbers language-language-js"><code class="language-language-js">var async = require('async')console.time('test')// 串行无关联：series 方法// 两个参数，第一个参数是一个函数数组，数组里面的函数将会被串行调用。第二个参数是一个回调函数，将会在函数数组里面的函数都调用完成后被调用async.series([  function (callback) {    setTimeout(function(){      callback(null, 'one')    }, 2000)  },  function (callback) {    setTimeout(function(){      callback(null, 'two')    }, 5000)  }], function(err, results){  console.log(results)  console.timeEnd('test')})async.series({  one: function (callback) {    setTimeout(function(){      callback(null, '1')    }, 1000)  },  two: function (callback) {    setTimeout(function(){      callback(null, '2')    }, 2000)  }}, function(err, results){  console.log(results)  console.timeEnd('test')})// 并行无关联：parallel 方法// 两个参数，第一个参数是一个函数数组，数组里面的函数将会被异步调用。第二个参数是一个回调函数，将会在函数数组里面的函数都调用完成后被调用async.parallel([  function (callback) {    setTimeout(function(){      callback(null, 'one')    }, 2000)  },  function (callback) {    setTimeout(function(){      callback(null, 'two')    }, 5000)  }], function(err, results){  console.log(results)  console.timeEnd('test')})// 串行有关联：waterfall 方法// 两个参数// 第一个参数是一个函数数组，数组里面的函数将会被串行调用，且前一个函数的参数 callback 就是下一个函数的引用，依次形成过滤器/责任链模式。// 第二个参数是一个回调函数，将会在函数数组里面的函数都调用完成后被调用async.waterfall([  function (callback) {    callback(null, 'one', 'two')  },  function (arr1, arr2, callback) {    callback(null, arr1, arr2, 'three')  },  function (arr1, arr2, arr3, callback) {    callback(null, [arr1, arr2, arr3, 'done'])  }], function(err, results){  console.log(results)})<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Express"><a class="header-anchor" href="#Express">¶</a><a href="http://expressjs.com/" target="_blank" rel="noopener">Express</a></h2><p>一个 Web 开发脚手架工具。 使用它可以生成一个格式化的工程项目，里面包含了一些已经写好的结构化代码，以及一个依赖了固定功能的 Web 开发模块的 package.json 文件。基于这个工程就可以快速开发一个 Web 项目。</p><h3 id="EJS-简介"><a class="header-anchor" href="#EJS-简介">¶</a>EJS 简介</h3><p>EJS 是 Express 中依赖的一个模板引擎语言。</p><p>EJS是一个简单高效的模板语言，通过数据和模板，可以生成HTML标记文本。可以说EJS是一个JavaScript库，EJS可以同时运行在客户端和服务器端，客户端安装直接引入文件即可，服务器端用npm包安装。</p><h4 id="EJS-的特点"><a class="header-anchor" href="#EJS-的特点">¶</a>EJS 的特点</h4><ul><li><p>快速编译和渲染</p></li><li><p>简单的模板标签</p></li><li><p>自定义标记分隔符</p></li><li><p>支持文本包含</p></li><li><p>支持浏览器端和服务器端</p></li><li><p>模板静态缓存</p></li><li><p>支持express视图系统</p></li></ul><h4 id="EJS-的成员函数"><a class="header-anchor" href="#EJS-的成员函数">¶</a>EJS 的成员函数</h4><p>Render(str,data,[option]):直接渲染字符串并生成html</p><ul><li>str：需要解析的字符串模板</li><li>data：数据</li><li>option：配置选项</li></ul><h4 id="EJS-的常用标签"><a class="header-anchor" href="#EJS-的常用标签">¶</a>EJS 的常用标签</h4><ul><li><code>&lt;% %&gt;</code>流程控制标签</li><li><code>&lt;%= %&gt;</code>输出标签（原文输出HTML标签）</li><li><code>&lt;%- %&gt;</code>输出标签（HTML会被浏览器解析）</li><li><code>&lt;%# %&gt;</code>注释标签</li><li>% 对标记进行转义</li></ul><h2 id="Mocha"><a class="header-anchor" href="#Mocha">¶</a>Mocha</h2><p>Mocha（发音&quot;摩卡&quot;）诞生于2011年，是现在最流行的JavaScript测试框架之一，在浏览器和Node环境都可以使用。所谓&quot;测试框架&quot;，就是运行测试的工具。通过它，可以为JavaScript应用添加测试，从而保证代码的质量。</p><h2 id="chai"><a class="header-anchor" href="#chai">¶</a>chai</h2><p>assert/断言库。</p><ul><li>should风格的断言</li><li>expect风格的断言</li></ul>]]></content>
      
      
      <categories>
          
          <category> web前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nodejs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《redis设计与实践》读书笔记</title>
      <link href="/2020/12/22/redis/redis-she-ji-yu-shi-jian/gai-lan/"/>
      <url>/2020/12/22/redis/redis-she-ji-yu-shi-jian/gai-lan/</url>
      
        <content type="html"><![CDATA[<h1>普通数据结构</h1><h2 id="SDS-Simple-Dynamic-String"><a class="header-anchor" href="#SDS-Simple-Dynamic-String">¶</a>SDS(Simple Dynamic String)</h2><h3 id="结构体"><a class="header-anchor" href="#结构体">¶</a>结构体</h3><pre class="line-numbers language-language-c"><code class="language-language-c">struct sdshdr {int len;int free;char buf[];}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="和C字符串区别"><a class="header-anchor" href="#和C字符串区别">¶</a>和C字符串区别</h3><h4 id="常数复杂度获取字符串长度"><a class="header-anchor" href="#常数复杂度获取字符串长度">¶</a>常数复杂度获取字符串长度</h4><h4 id="杜绝缓冲区溢出"><a class="header-anchor" href="#杜绝缓冲区溢出">¶</a>杜绝缓冲区溢出</h4><h4 id="减少修改字符串的时候需要重新分配内存的次数"><a class="header-anchor" href="#减少修改字符串的时候需要重新分配内存的次数">¶</a>减少修改字符串的时候需要重新分配内存的次数</h4><h4 id="二进制安全"><a class="header-anchor" href="#二进制安全">¶</a>二进制安全</h4><h4 id="兼容部分C字符串的函数"><a class="header-anchor" href="#兼容部分C字符串的函数">¶</a>兼容部分C字符串的函数</h4><h2 id="链表"><a class="header-anchor" href="#链表">¶</a>链表</h2><h3 id="结构体-v2"><a class="header-anchor" href="#结构体-v2">¶</a>结构体</h3><pre class="line-numbers language-language-c"><code class="language-language-c">typedef struct listNode {struct listNode *prev;struct listNode *next;void *value;}listNode;typedef struct list {  listNode *head;  listNode *tail;  unsigned long len;  //操作函数指针  void *(*dup)(void *ptr);  void *(free)(void *ptr);  int (*match)(void *ptr, void *key);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="特点"><a class="header-anchor" href="#特点">¶</a>特点</h3><h4 id="双向链表"><a class="header-anchor" href="#双向链表">¶</a>双向链表</h4><h4 id="无环"><a class="header-anchor" href="#无环">¶</a>无环</h4><h4 id="同时持有头尾节点指针"><a class="header-anchor" href="#同时持有头尾节点指针">¶</a>同时持有头尾节点指针</h4><h4 id="保存链表长度"><a class="header-anchor" href="#保存链表长度">¶</a>保存链表长度</h4><h4 id="多态"><a class="header-anchor" href="#多态">¶</a>多态</h4><h2 id="字典"><a class="header-anchor" href="#字典">¶</a>字典</h2><h3 id="结构体-v3"><a class="header-anchor" href="#结构体-v3">¶</a>结构体</h3><pre class="line-numbers language-language-c"><code class="language-language-c">typedef struct dictht {  dictEntry **table;  unsigned long size;  unsigned long sizemask;  unsigned long used;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p>table属性是一个数组，数组中的每个元素都是一个指向 dict.h/dictEntry 结构的指针，每个 dictEntry 结构的指针。</p></li><li><p>每个 dictEntry 结构保存着一个键值对。</p></li><li><p>size 属性记录了 table 大小。used 记录了 table 目前已有节点(键值对)数量。</p></li><li><p>sizemask 属性的值总是等于 size-1，这个属性和哈希值一起决定一个键应该被放到 table 数组的哪个索引上(和hashmap中算法类似)。</p></li></ul><pre class="line-numbers language-language-c"><code class="language-language-c">typedef struct dictEntry {  void *key;union {    void *val;    unit64_tu64;    int64_ts64;  } v;  struct dictEntry *next;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>key属性保存着键值对中的键</li><li>而v属性则保存着键值对中的值,其中键值对的值可以是一个指针,或者是一个uint64_t整数,又或者是一个int64_t整数。</li><li>next属性是指向另一个哈希表节点的指针,这个指针可以将多个哈希值相同的键值对连接在一次,以此来解决键冲突( collision)的问题。</li></ul><pre><code>typedef struct dict {dictType *type;void *privdata;}</code></pre><h3 id="主要使用"><a class="header-anchor" href="#主要使用">¶</a>主要使用</h3><h4 id="redis数据库本身"><a class="header-anchor" href="#redis数据库本身">¶</a>redis数据库本身</h4><h4 id="hash键"><a class="header-anchor" href="#hash键">¶</a>hash键</h4>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis设计与实践 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql学习笔记：基础架构</title>
      <link href="/2020/12/22/mysql/ji-chu-jia-gou-ji-suo-yin-ji-suo-ji-shi-wu-shi-xian-ji-ri-zhi/"/>
      <url>/2020/12/22/mysql/ji-chu-jia-gou-ji-suo-yin-ji-suo-ji-shi-wu-shi-xian-ji-ri-zhi/</url>
      
        <content type="html"><![CDATA[<h1>一、基础架构:一条SQL查询语句是如何执行的</h1><p>下面以以下SQL为例，分析其在MySQL中是如何执行的。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from T where ID=10；<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="MySQL基础架构示意图"><a class="header-anchor" href="#MySQL基础架构示意图">¶</a>MySQL基础架构示意图</h2><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131500.png" alt="MySQL的逻辑架构图"></p><p>大体来说，MySQL 可以分为 <strong>Server 层</strong>和<strong>存储引擎</strong>层两部分。</p><ul><li><p>Server 层</p><p>Server 层包括<strong>连接器、查询缓存、分析器、优化器、执行器</strong>等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</p></li><li><p>存储引擎层</p><p>存储引擎层<strong>负责数据的存储和提取</strong>。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。</p><p>也就是说，你执行 create table 建表的时候，如果不指定引擎类型，默认使用的就是 InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在 <code>create table</code> 语句中使用 <code>engine=memory</code>, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同。</p></li></ul><h2 id="连接器"><a class="header-anchor" href="#连接器">¶</a>连接器</h2><p>第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql -h$ip -P$port -u$user -p<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在 -p 后面写在命令行中，但这样可能会导致你的密码泄露。如果你连的是生产服务器，强烈建议你不要这么做。</p><p>连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。</p><ul><li><p>如果用户名或密码不对，你就会收到一个&quot;Access denied for user&quot;的错误，然后客户端程序结束执行。</p></li><li><p>如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。这就意味着，<strong>一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置</strong>。</p></li></ul><h3 id="连接状态和超时"><a class="header-anchor" href="#连接状态和超时">¶</a>连接状态和超时</h3><p>连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 <code>show processlist</code> 命令中看到它。文本中这个图是 <code>show processlist</code> 的结果，其中的 <code>Command</code> 列显示为“Sleep”的就表示现在系统里面有一个空闲连接。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> show processlist;+-------+------+---------------------+----------+---------+------+----------+------------------+| Id    | User | Host                | db       | Command | Time | State    | Info             |+-------+------+---------------------+----------+---------+------+----------+------------------+| 16036 | root | 120.24.80.237:45346 | flowable | Sleep   |  590 |          | NULL             || 16037 | root | 120.24.80.237:45350 | flowable | Sleep   |  566 |          | NULL             |... ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 <code>wait_timeout</code> 控制的，单位是秒，默认值是 8 小时。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> show variables like  "wait_timeout";+---------------+-------+| Variable_name | Value |+---------------+-------+| wait_timeout  | 28800 |+---------------+-------+1 row in set (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： <code>Lost connection to MySQL server during query</code>。这时候如果你要继续，就需要重连，然后再执行请求了。</p><h3 id="建立连接和维持连接的消耗"><a class="header-anchor" href="#建立连接和维持连接的消耗">¶</a>建立连接和维持连接的消耗</h3><p>数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。</p><p>但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。</p><p>怎么解决这个问题呢？你可以考虑以下两种方案。</p><ol><li>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li><li>如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 <code>mysql_reset_connection</code> 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li></ol><h2 id="查询缓存"><a class="header-anchor" href="#查询缓存">¶</a>查询缓存</h2><p>连接建立完成后，就可以执行select语句了。执行逻辑就会来到第二步：查询缓存。</p><p>MySQL 拿到一个查询请求后：</p><ul><li><p>会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 <code>key-value</code> 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。</p></li><li><p>如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。</p></li></ul><h3 id="不建议使用缓存"><a class="header-anchor" href="#不建议使用缓存">¶</a>不建议使用缓存</h3><p>但是大多数情况下不建议使用查询缓存，为什么呢？因为查询缓存往往弊大于利。**查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。**因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。<strong>除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。</strong></p><p>好在 MySQL 也提供了这种“按需使用”的方式。可以将参数 <code>query_cache_type</code> 设置成 <code>DEMAND</code>，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select SQL_CACHE * from T where ID=10；<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>需要注意的是，<strong>MySQL 8.0 版本直接将查询缓存的整块功能删掉了</strong>，也就是说 8.0 开始彻底没有这个功能了。</p><h2 id="分析器"><a class="header-anchor" href="#分析器">¶</a>分析器</h2><p>如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。</p><p>分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。MySQL 从你输入的&quot;select&quot;这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。</p><p>做完了这些识别以后，结果就是生成一颗语法树，然后根据这颗树来做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法，如要<strong>查询的字段或者条件字段在表中是否存在</strong>、各子句顺序是不是有误等。如果你的语句不对，就会收到<code>You have an error in your SQL syntax</code>的错误提醒，比如下面这个语句 select 少打了开头的字母“s”。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> elect * from t where ID=1;ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'elect * from t where ID=1' at line 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="优化器"><a class="header-anchor" href="#优化器">¶</a>优化器</h2><p>经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>join是inner join的缩写 using(ID) 是 on <a href="http://t1.id" target="_blank" rel="noopener">t1.id</a> == t2.id的简写 因为联表on条件是两张表中同一个字段，可以简写为using(字段名)</p></blockquote><ul><li>既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。</li><li>也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。</li></ul><p>这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而<strong>优化器的作用就是决定选择使用哪一个方案</strong>。</p><p>优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。</p><h2 id="执行器"><a class="header-anchor" href="#执行器">¶</a>执行器</h2><p>MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。</p><p>开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from T where ID=10;ERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果有权限，就打开表继续执行。打开表的时候，<strong>执行器就会根据表的引擎定义，去使用这个引擎提供的接口</strong>。</p><p>比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：</p><ol><li>调用 InnoDB 引擎接口取这个表的<u>第一行</u><sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；</li><li>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。</li><li>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。</li></ol><p>至此，这个语句就执行完成了。</p><p>对于有索引的表，执行的逻辑也差不多。<strong>第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口</strong>，这些接口都是引擎中已经定义好的。</p><p>在数据库的慢查询日志中看到一个 <code>rows_examined</code> 的字段，表示这个语句执行过程中<strong>扫描了多少行</strong>。这个值就是在<strong>执行器</strong>每次调用引擎获取数据行的时候进行<strong>累加</strong>的(执行器累加)。</p><p>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此<strong>引擎扫描行数跟 <code>rows_examined</code> 并不是完全相同的</strong>。</p><h1>二、日志系统:一条sql更新语句是如何执行的</h1><p>MySQL 可以恢复到半个月内任意一秒的状态，这是怎样做到的呢？还是从一个表的一条更新语句说起，下面是这个表的创建语句，这个表有一个主键 ID 和一个整型字段 c：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> create table T(ID int primary key, c int);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果要将 ID=2 这一行的值加 1，SQL 语句就会这么写：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> update T set c=c+1 where ID=2;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查询语句的那一套流程，更新语句也是同样会走一遍。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131525.png" alt="MySQL的逻辑架构图"></p><p>你执行语句前要先连接数据库，这是连接器的工作。</p><p><strong>在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空</strong>。这也就是我们一般不建议使用查询缓存的原因。</p><p>接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。</p><p>与查询流程不一样的是，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志）<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>。</p><h2 id="重要的日志模块：redo-log"><a class="header-anchor" href="#重要的日志模块：redo-log">¶</a>重要的日志模块：redo log</h2><p>写磁盘的操作相对是成本比较高昂的操作，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者引进了 MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>，再写磁盘。</p><p>具体来说，当有一条记录需要更新的时候：</p><ol><li><p>InnoDB 引擎就会先把记录写到 redo log 里面。</p><blockquote><p>将更新数据页的改动写入redo中记录，这样就可以不用直接同步数据库刷磁盘，减少了写入磁盘IO动作，下次等空闲、内存不足、redo满了时就会 ”刷脏“。</p></blockquote></li><li><p>并更新内存，这个时候更新就算完成了。</p><blockquote><p>这个动作是将当前更新内容更新到内存中，如果更新内容在内存中不存在就会涉及到先读入内存，在更新的操作。后面引入了change buffer时，你会发现存在与不存在内存都不用读磁盘，用change buffer解决，减少了读磁盘IO的操作，提高了性能</p></blockquote></li><li><p>同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。</p><blockquote><p>这个动作叫 ”刷脏“，其实就是将第二步写在内存(buffer)中的数据页更新到位于磁盘中的数据文件，并移动 redo log 的 checkpoint 。</p><p>刷脏时机：</p><ol><li>后台线程定期会刷脏页</li><li>清理LRU链表时会顺带刷脏页</li><li>redoLog写满会强制刷</li><li>数据库关闭时会将所有脏页刷回磁盘</li><li>脏页数量过多（默认占缓冲池75%）时，会强制刷</li></ol></blockquote></li></ol><p>InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131538.png" alt="redolog"></p><p>write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把<strong>记录更新到数据文件</strong><sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>。</p><p>从 write pos 开始到 checkpoint 之间还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下<sup class="footnote-ref"><a href="#fn4" id="fnref4:1">[4:1]</a></sup>。</p><p><strong>有了 redo log ，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失（宕机重启的时候，反过来从 checkpoint 开始到 write pos 之间的位置就是还没刷盘的日志，直接拿这段日志出来重放操作，即可恢复宕机前 buffer pool 中的数据页），这个能力称为 crash-safe。</strong></p><h3 id="redo-log-buffer"><a class="header-anchor" href="#redo-log-buffer">¶</a>redo log buffer</h3><p>在一个事务的更新过程中，涉及多个操作，redo log 是要写很多次的，所以在更新过程的 redo log 写入都是先写入到一块内存空间的，它就是 redo log buffer，在事务提交的时候才真正把日志写到 redo log 文件（文件名是 ib_logfile+数字）(当然，这还要取决于<code>innodb_flush_log_at_trx_commit</code>变量如何配置，如果是1才会在commit的时候进行fsync) 。</p><p>这样在减少磁盘访问的同时也保证在 commit 之前没有将 redo log 写入同步到 redo log 文件，减少因为回滚带来的 redo log 补偿操作。另外需要注意的是，如果 redo log buffer 写满或者紧张的时候，也还是会提前写入到 redo log 文件中的，所以我们需要尽量避免长事务。</p><h2 id="重要的日志模块：binlog"><a class="header-anchor" href="#重要的日志模块：binlog">¶</a>重要的日志模块：binlog</h2><p>MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。 redo log 是 <strong>InnoDB 引擎</strong>特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。</p><h3 id="使用-binlog-恢复数据操作"><a class="header-anchor" href="#使用-binlog-恢复数据操作">¶</a>使用 binlog 恢复数据操作</h3><p>binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。</p><p>当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：</p><ul><li><p>首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；</p></li><li><p>然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。</p></li></ul><p>这样你的<strong>临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去</strong>。</p><p>好了，说完了数据恢复过程，我们回来说说，为什么日志需要“两阶段提交”。这里不妨用反证法来进行解释。由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。</p><h2 id="为什么会有两份日志呢？"><a class="header-anchor" href="#为什么会有两份日志呢？">¶</a>为什么会有两份日志呢？</h2><p>因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，<strong>binlog 日志只能用于归档</strong>，即记录用户操作的信息，<strong>它没有 crash-safe 能力。</strong></p><p>而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 直接使用了自己原有的一套支持崩溃恢复和支持事务的日志系统——也就是 <strong>redo log 来实现 crash-safe 能力</strong>。</p><h3 id="crash-safe"><a class="header-anchor" href="#crash-safe">¶</a>crash-safe</h3><p>首先什么是 crash-safe，我们更新的数据它并不是立刻就写到它最终要去的数据文件中的。出于性能方面的考虑：</p><ol><li>它会先写到 redo log 中，而对于 redo log 本身来说，根据用户的配置不同<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup><sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>：<ul><li>它可能 write 到redo log中就可以了，在特定场景下才会将buffer中的数据同步到磁盘文件中；</li><li>或者每次都直接写到磁盘文件中，但是因为 redo log 是顺序IO，非更新数据文件中涉及的随机 IO，所以效率较高。</li></ul></li><li>然后在内存中更新对应的数据页，就完成了一次数据的更新，之后的数据读取都可以直接读取内存中的数据页。之后在特定的场景再将内存中的数据页同步到磁盘文件中。</li></ol><p>所以如果此时 MySQL 发生了 crash，那么在内存中还未同步到磁盘数据文件的数据页将会丢失。在之后重启 MySQL 的时候，MySQL 则会读取 redo log 对这部分数据进行恢复，主要还是上面提到的两个指针，write_pos 和 check_point ，位于 write_pos 之后 、check_point 之前的数据(改动)都是没有同步到数据文件中的，所以 MySQL 可以根据这区间的日志恢复 crash 之前在内存中丢失的数据页。（注意：这里假设采取的是每次写 redo log 都是直接写到磁盘，如果是写到内存，那么在 crash 之前如果 redo log 的 file system cache 没有落盘，对应的数据页页在内存中没有同步到数据文件，那么这部分数据就丢失了）。</p><p>上面讲的就是 carsh-safe ，它指的是 MySQL 对于自身已经提交的事务( commit )给予的持久化保证，不会说明明已经 commit 一个更新了，因为你 MySQL 自身的一些性能优化就会导致我数据库重启之后这个更新又不见了。</p><blockquote><p>另外，这个和我们误删数据或者代码 bug 产生脏数据的时候拿 binlog 来恢复数据是不一样的，这个是我们的业务问题，前者是 MySQL 给我们的持久化语义保证。</p></blockquote><h3 id="redo-log和binlog的不同"><a class="header-anchor" href="#redo-log和binlog的不同">¶</a>redo log和binlog的不同</h3><p>从上面对于 MySQL 的 crash-safe 过程和 binlog 没有关系，单独使用 redo log 即完成了。那为什么还要 binlog 呢？去掉它不行吗？主要从这两种日志的不同点进行分析，有以下三点不同：</p><ol><li><p>redo log 是 InnoDB 引擎特有的；</p><p><strong>binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。</strong></p></li><li><p><strong>redo log 是物理日志</strong>，记录的是“在某个数据页上做了什么修改”，不是记录数据页“更新之后的状态”，使用的格式是 InnoDB 独有的格式，所以它支持数据页级别的恢复；</p><p><strong>binlog 是逻辑日志</strong>，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。逻辑日志可以给别的数据库，别的引擎使用。binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。binlog 的记录相对 redo log 来说是比较&quot;粗&quot;的，所以它无法实现 cras-safe。</p></li><li><p>redo log 是循环写的，空间固定会用完，它记录的信息不会持久保存；</p><p>binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。<strong>binlog的“归档”这个功能，redolog是不具备的。</strong></p></li><li><p>MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，<strong>MySQL 系统高可用的基础，就是 binlog 复制</strong>。还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的 binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。总之，由于现在包括 MySQL 高可用在内的很多系统机制都依赖于 binlog，所以“鸠占鹊巢”redo log 还做不到。</p></li></ol><p>所以我们基于现有的实现只能保存两份日志，而两份日志都会记录了数据的状态，所以此时就要解决这两份日志的一致性问题，不能让它们对于某一份数据出现不同的记录。如果它们不一致会出现什么样的后果呢？假设在一次数据库重启之后，redo log 中记录的某个数据值为 1，但是因为一致性问题，binlog 中的值是 0 ，此时 MySQL 自身是<strong>按照 redo log 在重启的时候恢复数据的</strong>。而在此一段时间后我们因为某些业务问题需要读取 binlog 进行数据还原，此时还原出来的数据 0 将会和重启之后的数据库中的数据 1 不一样。</p><ul><li>有可能是 binlog 先写了，redo log 还没写就 crash 了，此时我们根据 binlog 还原出来的 0 值对于重启之后的数据库来说相当于多了一个更新操作</li><li>有可能是 redo log 先写了，binlog 还没写就 crash 了，此时我们根据 binlog 还原出来的 0 值就相当于少了一个操作</li></ul><blockquote><p>当然，用户可以选择配置关闭 binlog 的功能，这样就相当于不要 binlog 了，也没有需要同步两份日志一说了。</p></blockquote><h3 id="保证两份日志一致"><a class="header-anchor" href="#保证两份日志一致">¶</a>保证两份日志一致</h3><p>基于上面过程，MySQL 必须保证两份 log 一致，MySQL 本身是基于 redo log 实现事务等功能等，一条数据更新的 redo log 写完成就意味着它的更新操作完成了，所以应该先保证 redo log 记录成功(物理更新)再进行 binlog 的记录(业务操作逻辑记录)，然后返回执行成功的结果给用户。而两份日志都有着自己的格式，都以某种格式记录着一个完整的事务（<strong>statement 格式的 binlog，最后会有 COMMIT；row 格式的 binlog，最后会有一个 XID event 。另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。</strong>），使得 MySQL 可以分析它们的完整性。所以 MySQL 每次重启根据 redo log 恢复那些还没同步到数据文件的内存页数据的时候，可以拿到其中每一条事务的事务ID(XID)到 binlog 中按照 binlog 格式查找该 XID 是否存在以及事务是否完整而得知该事务是否有效（用户提交一个事务的完成标识就是 MySQL 完成了该事务在 binlog 中的写入），无效的事务无需恢复并删除即可，同时修复 binlog 。</p><p>以上描述的是发生 crash 、重启之后如何保证两份日志一致，即以 binlog 事务是否完整为准进行数据恢复并修复同步修复两份日志。这个做法有个很明显的问题就是，需要对 redo log 中需要恢复的每一个事务都要到 binlog 中找到对应的事务并按其格式对其进行分析该事务是否完整，这是一个比较耗时的过程。所以做出以下改动：在 binlog 写完一个事务之后，对 redo log 中该事务中一个特定标识位置为一个特定的标识，表示 binlog 对于这个事务已经完成写入了，即事务已提交。这样重启之后就不用对每一个事务都需要到 binlog 中检查了，只需要那些没有被置为提交状态的事务进行检查即可（准确来说应该是准备状态的事务）。</p><blockquote><p>在 MySQL 运行过程中是否会发生不一致呢？不会，因为无论是因为系统错误(如磁盘错误等)还是用户主动回滚，MySQL 都会有对应的逻辑对两份日志进行相应的更新。只要 MySQL 还在运行中，它就会对两份日志进行同步。</p></blockquote><p>参考下面的数据更新执行过程例子参考日志的写入过程。</p><h4 id="数据更新执行过程"><a class="header-anchor" href="#数据更新执行过程">¶</a>数据更新执行过程</h4><p>先来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。</p><ol><li>执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li><li>执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</li><li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，<strong>此时 redo log 处于 prepare 状态</strong>。然后告知执行器执行完成了，随时可以提交事务。</li><li>执行器生成这个操作的 binlog，并把 binlog 写入磁盘。</li><li>执行器调用引擎的提交事务接口(返回用户提交事务完成)，引擎把刚刚写入的 <strong>redo log 改成提交（commit）状态</strong>，更新完成。</li></ol><p>以下是 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131549.png" alt="update 语句执行流程"></p><p>最后三步看上去有点“绕”，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是&quot;两阶段提交&quot;。即将&quot;两个事务&quot;<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>的所有的重操作放在 prepare 阶段去做，最后由一个 commit 操作来同一提交两个事务的完成状态。结合上面讲到的内容，MySQL 在重启的时候会检查 redo log 中的事务，所有位于 write_pos 之后、check point 之前的事务如果是 commit 状态的，将其恢复到内存数据页中或者同步到数据文件(这些都是还没同步到数据文件中的事务)；如果是 prepare 状态的，说明这个事务可能写了 binlog ，但是没有提交，去 binlog 中查找这个事务，如果事务存在且完整，则恢复这个事务并重新 commit 这个事务，否则删除这个事务并修复 binlog。</p><blockquote><p>commit 动作(对 redo log 中的事务标识为提交状态)不能在完成 redo log 事务写入后就进行(即违反两阶段提交，每一个事务完成后都直接提交)，因为 binlog 是有可能写入失败的，这时候将会导致重启的时候 redo log 读到一个 commit 状态的事务立即对其恢复，但是实际上他写入 binlog 的时候失败了，返回给用户也是失败返回。此时将产生了日志不一致，呈现给用户的也是逻辑物理不一致的状态。此时 redo log 中的 commit 标识位将会起到本末倒置的作用，完全无法识别一个事务是否完成了(完整写入了binlog)，还是要对于每个事务都到 binlog 中检查完整性。</p></blockquote><blockquote><p>除此之外，和分布式事务比较类似的点就是降低风险可能性。</p><p>在分布式事务中，涉及多个子事务的一致性问题，如果一个子事务已经提交了，此时另外一个子事务失败了，我们需要对已经提交的子事务进行补偿(此时的分布式事务是一个最终一致性/弱一致性)，补偿有时候是一个不是那么容易做的工作。所以我们希望通过将这种情况的可能性降到最低，以达到几乎可以忽略的情况，这样我们可以对补偿的动作进行特殊处理（或者说不处理，通过业务方案解决）。此时我们将操作比较重、耗时较长、容易出错的业务处理过程和操作简单、耗时极短、不易出错的提交动作分开，前者为 prepare 阶段，后者为 commit 阶段。所有完成 prepare 阶段的子事务发出 commit 请求，事务管理器收齐所有子事务的请求之后进入 commit 阶段，下发 commit 到各个子事务进行提交；而一旦有一个子事务无法完成 prepare ，事务管理器下发 rollback ，此时各子事务直接调用本地存储器提供的 rollback 回滚即可，而无需自己写大量的补偿逻辑。此时我们将&quot;在其它子事务提交之后另一个子事务执行/提交失败&quot;的可能性由某个事务的整个执行、提交周期降低到了事务的简单的提交周期。大大降低了需要补偿的可能性。</p><p>回到 MySQL 自身，现在我们先不讲上面提到的两阶段 commit 给 MySQL 面对 crash 重启之后带来的好处。考虑在 MySQL 运行过程中如果使用立即提交的方式进行两份日志的维护，那么在 redo log 提交之后，如果 binlog 写失败了，此时就需要回滚 redo log 的提交，可能不仅仅是修改 redo log 中的标识位那么简单了，如果 redo log 发生了 check point 前推(MySQL 按需将已经 commit 的事务同步到磁盘数据文件，释放 redo log 空间)，即对应的数据已经写入数据文件了，则需要同时补偿恢复内穿+磁盘中对应的数据页。而如果采用两阶段提交，此时就将失败的可能性从整个写 binlog 的区间降到了一个简单的修改 redo log 的 commit 标识期间，这几乎是可以忽略的。</p></blockquote><h2 id="binlog-的写入机制"><a class="header-anchor" href="#binlog-的写入机制">¶</a>binlog 的写入机制</h2><p>其实，binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。</p><p>系统给 binlog cache 分配了一片内存，每个线程一个，参数 <code>binlog_cache_size</code> 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。</p><p>事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131603.png" alt="binlog 写盘状态"></p><p>可以看到，每个线程有自己 binlog cache，但是共用同一份 binlog 文件。</p><ul><li>图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。</li><li>图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。</li></ul><p>write 和 fsync 的时机，是由参数 <code>sync_binlog</code> 控制的：</p><ol><li><code>sync_binlog</code>=0 的时候，表示每次提交事务都只 write，不 fsync；</li><li><code>sync_binlog</code>=1 的时候，表示每次提交事务都会执行 fsync；</li><li><code>sync_binlog=N</code>(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。</li></ol><p>因此，在出现 IO 瓶颈的场景里，将 <code>sync_binlog</code> 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。但是，将 <code>sync_binlog</code> 设置为 N，对应的风险是：如果<strong>主机</strong>发生异常重启(是主机重启，而不是 MySQL 重启，如果是 MySQL crash 重启，无论<code>sync_binlog</code>如何设置，已提交事务的 binlog 都 write 到了文件系统的 page cache 了)，会丢失最近 N 个事务的 binlog 日志。</p><h2 id="redo-log-的写入机制"><a class="header-anchor" href="#redo-log-的写入机制">¶</a>redo log 的写入机制</h2><p>事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。redo log buffer 里面的内容，不是每次生成后都要直接持久化到磁盘的。如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。那么，另外一个问题是，<strong>事务还没提交的时候，redo log buffer 中的部分日志有没有可能被持久化到磁盘呢</strong>？答案是，确实会有。这个问题，要从 redo log 可能存在的三种状态说起。这三种状态，对应的就是图中的三个颜色块。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131612.png" alt="MySQL redo log 存储状态"></p><p>这三种状态分别是：</p><ol><li>存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分；</li><li>写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分；</li><li>持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。</li></ol><p>日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了。为了控制 redo log 的写入策略，InnoDB 提供了 <code>innodb_flush_log_at_trx_commit</code> 参数，它有三种可能取值：</p><ol><li>设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;</li><li>设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；</li><li>设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。</li></ol><blockquote><p>需要注意的是，被动触发持久化的 redo log 中包含的事务如果没有被用户主动提交，是不会有 prepare 状态的。也就是说 redo log 的 prepare 的准备是为了提交事务，只有用户执行了提交事务语句才会将该事务的 redo log 置为 prepare 状态。</p></blockquote><h3 id="未提交事务-redo-log-持久化情况"><a class="header-anchor" href="#未提交事务-redo-log-持久化情况">¶</a>未提交事务 redo log 持久化情况</h3><ol><li>InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。注意，事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。</li><li>redo log buffer 占用的空间即将达到 <code>innodb_log_buffer_size</code> 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。</li><li>并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 <code>innodb_flush_log_at_trx_commit</code> 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。</li></ol><p>以上情况都是因为对于每一个事务，它们都是共享的一个 redo log buffer，写入过程可能是交叉写入的，那么对于该 buffer 的每一次 fsync 固然就是将 buffer 中的所有内容持久化到磁盘上该 buffer 对应的文件了，所以此时只要存在 buffer 中的数据都会被持久化，不管是否完整事务（为什么 binlog cache 是每线程一份，redo log buffer 是全局共享，个人认为是因为前者是逻辑日志，后者是物理日志）。</p><p>两阶段提交时序上 redo log 先 prepare， 再写 binlog，最后再把 redo log commit。如果把 <code>innodb_flush_log_at_trx_commit</code> 设置成 1，那么 redo log 在 prepare 阶段就要持久化 fsync 一次(实际上会在 binlog cache write 之后、fsync 之前发生，参考下面的组提交介绍)，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的。每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。</p><h2 id="组提交"><a class="header-anchor" href="#组提交">¶</a>组提交</h2><p>通常我们说 MySQL 的“双 1”配置，指的就是 <code>sync_binlog</code> 和 <code>innodb_flush_log_at_trx_commit</code> 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。这时候，可能有一个疑问，这意味着从 MySQL 看到的 TPS 是每秒两万的话，每秒就会写四万次磁盘。但是，用工具测试出来，磁盘能力也就两万左右，怎么能实现两万的 TPS？解释这个问题，就要用到组提交（group commit）机制了。</p><p>这里，需要先介绍日志逻辑序列号（log sequence number，LSN）的概念。LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。如图所示，是三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131622.png" alt="redo log 组提交"></p><p>从图中可以看到，</p><ol><li>trx1 是第一个到达的，会被选为这组的 leader；</li><li>等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；</li><li>trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；</li><li>这时候 trx2 和 trx3 就可以直接返回了。</li></ol><blockquote><p>其实就是上面提到的并发事务的时候，一个事务的提交会导致其它事务的 log 一起从 redo log buffer 进行持久化，只不过这里的&quot;其它事务&quot; trx2 和 trx3 都是已经提交的事务</p></blockquote><p>所以，一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。</p><p>为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间。以下是两阶段提交的简图：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131633.png" alt="两阶段提交"></p><p>但实际上，写 binlog 是分成两步的：</p><ol><li>先把 binlog 从 binlog cache 中 write 到磁盘上的 binlog 文件；</li><li>调用 fsync 持久化。</li></ol><p>MySQL 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1 之后。也就是说，上面的图变成了这样：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131641.png" alt="两阶段提交细化"></p><p>这么一来，binlog 也可以组提交了。在执行第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。不过通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果那么好。</p><p>如果你想提升 binlog 组提交的效果，可以通过设置 <code>binlog_group_commit_sync_delay</code> 和 <code>binlog_group_commit_sync_no_delay_count</code> 来实现。</p><ol><li><code>binlog_group_commit_sync_delay</code> 参数，表示延迟多少微秒后才调用 fsync;</li><li><code>binlog_group_commit_sync_no_delay_count</code> 参数，表示累积多少次以后才调用 fsync。</li></ol><p>这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。也就是说，当 <code>binlog_group_commit_sync_delay</code> 设置为 0 的时候，<code>binlog_group_commit_sync_no_delay_count</code> 也无效了。</p><h2 id="小结"><a class="header-anchor" href="#小结">¶</a>小结</h2><h3 id="WAL-带来的好处"><a class="header-anchor" href="#WAL-带来的好处">¶</a>WAL 带来的好处</h3><p>WAL 机制主要得益于两个方面：</p><ol><li>redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；</li><li>组提交机制，可以大幅度降低磁盘的 IOPS 消耗。</li></ol><h3 id="总结日志写入流程"><a class="header-anchor" href="#总结日志写入流程">¶</a>总结日志写入流程</h3><ol><li>用户开启事务并执行相关语句</li><li>写 redo log buffer</li><li>写 binlog cache</li><li>用户提交事务</li><li>根据参数 <code>innodb_flush_log_at_trx_commit</code> 决定实际操作<ul><li>0：不做操作(留给后台每秒一次将 redo log buffer write and fsync 到文件)</li><li>1 和 2：将 redo log buffer write 到 redo log 文件</li></ul></li><li>将 binlog cache 进行执行 write 写入文件</li><li>如果 <code>innodb_flush_log_at_trx_commit</code> 为1：<ul><li>是：fsync redo log</li><li>否：什么也不做<ul><li>后台线程每秒也会触发一次将 redo log buffer write and fsync redo log 文件</li><li>redo log buffer 过载也会触发 write and fsync 到 redo log 文件</li><li>其它事务触发 redo log buffer write and fsync 到 redo log 文件</li></ul></li></ul></li><li>根据参数 <code>sync_binlog</code> 决定实际操作：<ul><li>0：不做操作</li><li>N(N &gt;= 1)：提交事务累积次数是否到达 N<ul><li>是：根据参数 <code>binlog_group_commit_sync_delay</code>、<code>binlog_group_commit_sync_no_delay_count</code>决定是否要立刻执行 fsync:<ul><li>是：立刻</li><li>否：延迟</li></ul></li><li>否：不做操作</li></ul></li></ul></li><li>write commit redo log buffer</li><li>返回用户界面事务提交成功</li></ol><h3 id="针对-MySQL-写入日志相关的优化"><a class="header-anchor" href="#针对-MySQL-写入日志相关的优化">¶</a>针对 MySQL 写入日志相关的优化</h3><p>如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？针对这个问题，可以考虑以下三种方法：</p><ol><li>设置 <code>binlog_group_commit_sync_delay</code> 和 <code>binlog_group_commit_sync_no_delay_count</code> 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险（因为这两个参数是延迟了用户提交事务时的返回，提高了事务失败的风险，但是没有丢失数据的风险）<ul><li>如果是从库设置了 <code>binlog_group_commit_sync_delay</code> 和 <code>binlog_group_commit_sync_no_delay_count</code> ，会导致一直延迟的情况。在主库设置这两个参数，是为了减少 binlog 的写盘压力。备库这么设置，尤其在“快要追上”的时候，就反而会受这两个参数的拖累。</li></ul></li><li>将 <code>sync_binlog</code> 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。</li><li>将 <code>innodb_flush_log_at_trx_commit</code> 设置为 2。这样做的风险是，主机掉电的时候会丢数据。</li></ol><p>不建议你把 <code>innodb_flush_log_at_trx_commit</code> 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。</p><h4 id="把线上生产库设置成“非双-1”场景"><a class="header-anchor" href="#把线上生产库设置成“非双-1”场景">¶</a>把线上生产库设置成“非双 1”场景</h4><ol><li>业务高峰期。一般如果有预知的高峰期，DBA 会有预案，把主库设置成“非双 1”。</li><li>备库延迟，为了让备库尽快赶上主库。</li><li>用备份恢复主库的副本，应用 binlog 的过程，这个跟上一种场景类似。</li><li>批量导入数据的时候。</li></ol><p>一般情况下，把生产库改成“非双 1”配置，是设置 <code>innodb_flush_logs_at_trx_commit</code>=2、<code>sync_binlog</code>=1000。</p><h3 id="MySQL-的-crash-safe-保证"><a class="header-anchor" href="#MySQL-的-crash-safe-保证">¶</a>MySQL 的 crash-safe 保证</h3><p>如果 binlog 写完盘以后发生 crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是 bug？</p><p>回答：不是。你可以设想一下更极端的情况，整个事务都提交成功了，redo log commit 完成了，备库也收到 binlog 并执行了。但是主库和客户端网络断开了，导致事务成功的包返回不回去，这时候客户端也会收到“网络断开”的异常。这种也只能算是事务成功的，不能认为是 bug。</p><p>实际上数据库的 crash-safe 保证的是：</p><ol><li>如果客户端收到事务成功的消息，事务就一定持久化了；</li><li>如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；</li><li>如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。</li></ol><h2 id="如果update的新值和旧值一致-MySQL-如何处理"><a class="header-anchor" href="#如果update的新值和旧值一致-MySQL-如何处理">¶</a>如果<code>update</code>的新值和旧值一致 MySQL 如何处理</h2><p>创建一个简单的表 t，并插入一行，然后对这一行做修改。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> CREATE TABLE `t` (`id` int(11) NOT NULL primary key auto_increment,`a` int(11) DEFAULT NULL) ENGINE=InnoDB;insert into t values(1,2);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这时候，表 t 里有唯一的一行数据 (1,2)。假设，执行：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> update t set a=2 where id=1;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131651.png" alt="update旧值与新值一致"></p><p>结果显示，匹配 (rows matched) 了一行，修改 (Changed) 了 0 行。</p><p>仅从现象上看，MySQL 内部在处理这个命令的时候，可以有以下三种选择：</p><ol><li>更新都是先读后写的，MySQL Server 层读出数据，发现 a 的值本来就是 2，不更新，直接返回，执行结束；</li><li>MySQL Server 调用了 InnoDB 引擎提供的“修改为 (1,2)”这个接口，但是引擎发现值与原来相同，不更新，直接返回；</li><li>InnoDB 认真执行了“把这个值修改成 (1,2)&quot;这个操作，该加锁的加锁，该更新的更新。</li></ol><h3 id="验证"><a class="header-anchor" href="#验证">¶</a>验证</h3><ol><li><p>第一个选项</p><p>从加锁角度验证：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131658.png" alt="锁验证方式"></p><p>session B 的 update 语句被 blocked (行锁)了，加锁这个动作是 InnoDB 才能做的，所以排除选项 1。</p></li><li><p>第二个选项和第三个选项统一验证</p><p>从一致性读角度验证：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131703.png" alt="可见性验证方式"></p><p>可以看到 session A 在执行 update 之后，它再执行 select 就可以看到 session B 的更新了。而 session A 的第二个 select 语句是一致性读（快照读)，其实它不是看到了 session B 的更新了，是看到了它自己的更新。实际上它照常执行了更新操作，生成了事务 ID 为它的事务 ID 的数据版本，该版本中的数据基于当前读取到了 B 的更新，所以不是2，而是修改后的3 。之后 session A 的一致性读就可以读到了这个数据。如果 session A 没有执行更新操作，它是不能看见&quot; session B 的更新&quot;的。</p></li></ol><p>综上，MySQL 采取的是第三种方式，但是需要说明的是，这是因为当前验证是建立在<code>binllog_format=statement</code>下进行的，且<code>update</code>语句的条件是<code>id=1</code>，否则可能结果就不是这样了，详情看下面。</p><h3 id="其它情况"><a class="header-anchor" href="#其它情况">¶</a>其它情况</h3><h4 id="update语句的set-子句和where子句的值一致"><a class="header-anchor" href="#update语句的set-子句和where子句的值一致">¶</a><code>update</code>语句的<code>set</code> 子句和<code>where</code>子句的值一致</h4><p>查看以下示例，发现 session A 中查询得到的结果和上面的验证不一样了，它得到的还是（1,2）。这是因为此时<code>update</code>语句的<code>where</code>子句中的条件变成了<code>id=1 and a=3</code>，这条语句会调用 InnoDB 的当前读，可以读到 session B 的更新（此时如果有一个 session C 在 session A 的<code>update</code> 语句之后尝试执行 <code>update</code> 会在 session A 提交之前阻塞，所以证明了调用了当前读并加了锁），但是由于 Server 层是可以根据 <code>set</code> 中只对 a 进行设置为3，且<code>where</code>子句中存在一个必要条件是 <code>a=3</code>，所以从语法分析上就可以直到它不会做任何更新，此时 Server 层将不会再调用 <code>InnoDB</code> 的更新操作进行更新。所以后面的一致性读就还是读到了 session B 的版本，但是这个版本的事务 ID 对于 session A 来说是不可见的，所以往回退找到了 (1,2)。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131711.png" alt="可见性验证方式--对照"></p><h4 id="binlog-format-row"><a class="header-anchor" href="#binlog-format-row">¶</a><code>binlog_format=row</code></h4><ul><li><p>如果是 <code>binlog_format=row</code> 并且 <code>binlog_row_image=FULL</code> 的时候，由于 MySQL 需要在 binlog 里面记录所有的字段，所以即使更新语句是<code>update t set a=3 where id=1</code>也要把所有字段值都读出来，此时可以判断<code>a</code>的值是否相等，发现相等之后就不再更新了。因此在这时候，<code>select * from t where id=1</code>，结果就是“返回 (1,2)”而不是(1,3)。</p></li><li><p>如果是 <code>binlog_format=row</code> 并且 <code>binlog_row_image=NOBLOB</code> 的时候，会读出除 blob 外的所有字段，在上面这个例子里，session A 的第二次<code>select</code>还是“返回 (1,2)”。</p></li><li><p>如果是 <code>binlog_format=row</code> 并且<code>binlog-row-image=minimal</code></p><blockquote><p>此时 binlog 日志的前镜像只记录唯一识别列，即主键所和唯一索引列；后镜像只记录修改列。节省不少磁盘空间，节省一定的io，但是由于前镜像不记录修改列，只在后镜像记录修改列，如果数据出现误操作，必然不能通过 flashback 或 binlog2SQL 等快速闪回工具恢复数据，因此不能通过 binlog 生成反向 SQL 了。</p><ul><li>节省磁盘空间：高</li><li>数据安全性：低</li></ul></blockquote><p>此时 Server 层将不会调用 InnoDB 查询 <code>a</code> 字段值，所以就无法判断 <code>a</code> 值更新前后是否相等，则还是调用 InnoDB 进行更新。故 session A 的第二次<code>select</code>“返回 (1,3)”。</p></li></ul><h4 id="表中有自动获取当前时间的timestamp字段"><a class="header-anchor" href="#表中有自动获取当前时间的timestamp字段">¶</a>表中有自动获取当前时间的<code>timestamp</code>字段</h4><p>给表<code>t</code>增加一个自动获取当前时间的<code>timestamp</code>字段：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">alter table t add column uptime timestamp null default current_timestamp on update current_timestamp;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此时发现和验证中同样是在 session A 中执行 <code>update t set a = 3 where id = 1</code>之后，第二次 <code>select</code> 一致性读却还是读到了（1,2）。则是因为如果表中有 <code>timestamp</code> 字段而且设置了自动更新的话，那么更新“别的字段”的时候，MySQL 会读入所有涉及的字段，这样通过判断，就会发现不需要修改。此时一致性读就不能读到 session B 的&quot;不一致更新版本&quot;了。</p><h2 id="如何判断全备周期"><a class="header-anchor" href="#如何判断全备周期">¶</a>如何判断全备周期</h2><p>在一天一备的模式里，最坏情况下需要应用一天的 binlog。比如，你每天 0 点做一次全量备份，而要恢复出一个到昨天晚上 23 点的备份。一周一备最坏情况就要应用一周的 binlog 了。系统的对应指标就是 RTO（恢复目标时间），根据这个指标需要来确定要选择怎样的全备周期，全备越频繁，周期越短，恢复时间越快，但是消耗更多的存储空间。</p><h2 id="评论区的一个SQL执行过程记录"><a class="header-anchor" href="#评论区的一个SQL执行过程记录">¶</a>评论区的一个SQL执行过程记录</h2><p>1.首先客户端通过tcp/ip发送一条sql语句到server层的SQL interface<br>2.SQL interface接到该请求后，先对该条语句进行解析，验证权限是否匹配<br>3.验证通过以后，分析器会对该语句分析,是否语法有错误等<br>4.接下来是优化器器生成相应的执行计划，选择最优的执行计划<br>5.之后会是执行器根据执行计划执行这条语句。在这一步会去open table,如果该table上有MDL，则等待。<br>如果没有，则加在该表上加短暂的MDL(S)(如果opend_table太大,表明open_table_cache太小。需要不停的去打开frm文件)</p><p>6.进入到引擎层，首先会去innodb_buffer_pool里的data dictionary(元数据信息)得到表信息<br>7.通过元数据信息,去lock info里查出是否会有相关的锁信息，并把这条update语句需要的<br>锁信息写入到lock info里(锁这里还有待补充)<br>8.然后涉及到的老数据通过快照的方式存储到innodb_buffer_pool里的undo page里,并且记录undo log修改的redo<br>(如果data page里有就直接载入到undo page里，如果没有，则需要去磁盘里取出相应page的数据，载入到undo page里)<br>9.在innodb_buffer_pool的data page做update操作。并把操作的物理数据页修改记录到redo log buffer里<br>由于update这个事务会涉及到多个页面的修改，所以redo log buffer里会记录多条页面的修改信息。<br>因为group commit的原因，这次事务所产生的redo log buffer可能会跟随其它事务一同flush并且sync到磁盘上<br>10.同时修改的信息，会按照event的格式,记录到binlog_cache中。(这里注意binlog_cache_size是transaction级别的,不是session级别的参数,<br>一旦commit之后，dump线程会从binlog_cache里把event主动发送给slave的I/O线程)<br>11.之后把这条sql,需要在二级索引上做的修改，写入到change buffer page，等到下次有其他sql需要读取该二级索引时，再去与二级索引做merge<br>(随机I/O变为顺序I/O,但是由于现在的磁盘都是SSD,所以对于寻址来说,随机I/O和顺序I/O差距不大)<br>12.此时update语句已经完成，需要commit或者rollback。这里讨论commit的情况，并且双1<br>13.commit操作，由于存储引擎层与server层之间采用的是内部XA(保证两个事务的一致性,这里主要保证redo log和binlog的原子性),<br>所以提交分为prepare阶段与commit阶段<br>14.prepare阶段,将事务的xid写入，将binlog_cache里的进行flush以及sync操作(大事务的话这步非常耗时)<br>15.commit阶段，由于之前该事务产生的redo log已经sync到磁盘了。所以这步只是在redo log里标记commit<br>16.当binlog和redo log都已经落盘以后，如果触发了刷新脏页的操作，先把该脏页复制到doublewrite buffer里，把doublewrite buffer里的刷新到共享表空间，然后才是通过page cleaner线程把脏页写入到磁盘中</p><h1>三、事务隔离</h1><p>简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。</p><p>提到事务，你肯定会想到 ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），本节讲的是 I，也就是“隔离性”。</p><p>当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。</p><p>在谈隔离级别之前，首先要知道，隔离得越严实，效率就会越低。因此很多时候，要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）：</p><ul><li><p>读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。</p></li><li><p>读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。</p></li><li><p>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。启动时其它未提交的事务不可见，同时本事务启动之后才提交的其它事务对本事务也不可见。</p></li><li><p>串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</p></li></ul><h2 id="一个理解隔离级别的例子"><a class="header-anchor" href="#一个理解隔离级别的例子">¶</a>一个理解隔离级别的例子</h2><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> create table T(c int) engine=InnoDB;insert into T(c) values(1);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131721.png" alt="事务隔离级别例子"></p><ul><li><p>若隔离级别是“读未提交”， 则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2。</p></li><li><p>若隔离级别是“读提交”，则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。</p></li><li><p>若隔离级别是“可重复读”，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。</p></li><li><p>若隔离级别是“串行化”，则在事务 B 执行“将 1 改成 2”的时候，会被锁住(写锁被读锁阻塞)。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。</p></li></ul><p>在实现上，数据库里面会创建一个(MVCC)视图，访问的时候以视图的逻辑结果为准。</p><ul><li>在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图，所以 RR 隔离级别下，整个事务期间对于其它事务的视图都是不变的。</li><li>在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的，所以 RC 隔离级别下，只要在本事务内每条语句执行之前提交的事务对于本事务来说都会被加入到新的视图中，是可见的。</li><li>“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念。</li><li>而“串行化”隔离级别下直接用加锁的方式来避免并行访问。</li></ul><h2 id="根据不同情况选择隔离级别"><a class="header-anchor" href="#根据不同情况选择隔离级别">¶</a>根据不同情况选择隔离级别</h2><p>Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，一定要记得将 MySQL 的隔离级别设置为“读提交”。配置的方式是，将启动参数 <code>transaction-isolation</code> 的值设置成 <code>READ-COMMITTED</code>。你可以用 <code>show variables</code> 来查看当前的值。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> show variables like "transaction_isolation";+-----------------------+-----------------+| Variable_name         | Value           |+-----------------------+-----------------+| transaction_isolation | REPEATABLE-READ |+-----------------------+-----------------+1 row in set (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>要根据自己的业务情况来定。一个需要“可重复读”隔离级别的数据校对逻辑的案例：</p><p>假设你在管理一个个人银行账户表。一个表存了账户余额，一个表存了账单明细。到了月底你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。</p><h2 id="事务隔离的实现"><a class="header-anchor" href="#事务隔离的实现">¶</a>事务隔离的实现</h2><p>在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>里面就会有类似下面的记录。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131730.png" alt="undolog"></p><p>当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到(<strong>说明每个 read-view 并不是真的将数据复制为一个副本，而是在回滚段中建立一个标识或者直接使用事务id进行匹配</strong>)。</p><p>同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。</p><h2 id="回滚段的删除策略及长事务带来的影响"><a class="header-anchor" href="#回滚段的删除策略及长事务带来的影响">¶</a>回滚段的删除策略及长事务带来的影响<sup class="footnote-ref"><a href="#fn8" id="fnref8:1">[8:1]</a></sup></h2><p>回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。什么时候才不需要了呢？<strong>就是当系统里没有比这个回滚日志更早的 read view 的时候：</strong></p><ul><li><p>undo log 可以删除的大前提是产生该 undo log 的事务本身已经完成了(提交或者回滚)，否则该事务需要维护回滚段供用户随时回滚。以下情形都是基于已经完成的事务的 undo log 为准。</p></li><li><p>如果数据库中当前没有 read view 存在，则所有 undo log 都可以删除，只保留聚簇索引中的数据即可。</p></li><li><p>如果存在 read  view，取所有 read view 的所属事务 ID 中的最小值，对于一个存在多条 undo log 的数据行来说，以小于等于前面取到的最小 read view 所属事务 ID 的最大 undo log 所属事务 ID 为临界点，所属事务 ID 小于这个临界点的 undo log 可以删除；</p></li></ul><p>基于此，建议尽量不要使用长事务(迟迟没有 commit 或者 rollback)。</p><ul><li><p>长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。</p><p>在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。会出现数据只有 20GB，而回滚段有 200GB 的情况。最终只好为了清理回滚段，重建整个库。</p></li><li><p>除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。</p></li></ul><h2 id="如何避免长事务对业务的影响"><a class="header-anchor" href="#如何避免长事务对业务的影响">¶</a>如何避免长事务对业务的影响</h2><p>这个问题，我们可以从应用开发端和数据库端来看。</p><p>首先，从应用开发端来看：</p><ul><li><strong>确认是否使用了 <code>set autocommit=0</code></strong>。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。</li><li><strong>确认是否有不必要的只读事务</strong>。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。</li><li>业务连接数据库的时候，根据业务本身的预估，通过 <code>SET MAX_EXECUTION_TIME</code> 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间（如果不能全库设置global，就根据情况来对某个表进行单独设置，或者在应用层代码中拦截，通过插件的方式根据业务条件来对每一个session进行分别设置）。</li></ul><p>其次，从数据库端来看：</p><ul><li>监控 <code>information_schema.Innodb_trx</code> 表，设置长事务阈值，超过就报警 / 或者 kill；</li><li>Percona 的 pt-kill 这个工具不错，推荐使用；</li><li>在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；</li><li>如果使用的是 MySQL 5.6 或者更新版本，把 <code>innodb_undo_tablespaces</code> 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。</li></ul><h2 id="事务的启动方式"><a class="header-anchor" href="#事务的启动方式">¶</a>事务的启动方式</h2><p>其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。MySQL 的事务启动方式有以下几种：</p><ol><li>显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。</li><li>set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。</li><li>没有任何显示启动，默认就是 autocommit=1，此时每一条 SQL 语句的执行都是一个事务的开启和提交。</li></ol><p>有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。因此，我会建议你总是使用 set autocommit=1, 通过显式语句的方式来启动事务。</p><p>但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果有这个顾虑，建议使用 commit work and chain 语法。</p><p>在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1>四、索引</h1><h2 id="不同索引模式"><a class="header-anchor" href="#不同索引模式">¶</a>不同索引模式</h2><p>索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，有三种常见、也比较简单的数据结构，它们分别是<strong>哈希表、有序数组和搜索树</strong>。</p><p>下面主要从使用的角度，简单分析一下这三种模型的区别。</p><h3 id="哈希表"><a class="header-anchor" href="#哈希表">¶</a>哈希表</h3><p>哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的键即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。</p><p>不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。</p><p>假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131740.png" alt="hash索引示意"></p><p>图中，User2 和 User4 根据身份证号算出来的值都是 N，但没关系，后面还跟了一个链表。假设，这时候你要查 ID_card_n2 对应的名字是什么，处理步骤就是：首先，将 ID_card_n2 通过哈希函数算出 N；然后，按顺序遍历，找到 User2。</p><p>需要注意的是，图中四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是**，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。**你可以设想下，如果你现在要找身份证号在[ID_card_X, ID_card_Y]这个区间的所有用户，就必须全部扫描一遍了。</p><p>所以，哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。</p><h3 id="有序数组"><a class="header-anchor" href="#有序数组">¶</a>有序数组</h3><p><strong>而有序数组在等值查询和范围查询场景中的性能就都非常优秀</strong>。还是上面这个根据身份证号查名字的例子，如果我们使用有序数组来实现的话，示意图如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131752.png" alt="有序数组索引示意"></p><p>这里我们假设身份证号没有重复，这个数组就是按照身份证号递增的顺序保存的。这时候如果你要查 ID_card_n2 对应的名字，用<strong>二分法</strong>就可以快速得到，这个时间复杂度是 O(log(N))。</p><p>同时很显然，<strong>这个索引结构支持范围查询</strong>。你要查身份证号在[ID_card_X, ID_card_Y]区间的 User，可以先用二分法找到 ID_card_X（如果不存在 ID_card_X，就找到大于 ID_card_X 的第一个 User），然后向右遍历，直到查到第一个大于 ID_card_Y 的身份证号，退出循环。</p><p>如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，<strong>你往中间插入一个记录就必须得挪动后面所有的记录，成本太高</strong>（O(N)）<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>。</p><p>所以，<strong>有序数组索引只适用于静态存储引擎</strong>，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。</p><h3 id="搜索树"><a class="header-anchor" href="#搜索树">¶</a>搜索树</h3><h4 id="二叉搜索树的时间复杂度"><a class="header-anchor" href="#二叉搜索树的时间复杂度">¶</a>二叉搜索树的时间复杂度</h4><p>二叉搜索树也是课本里的经典数据结构了。还是上面根据身份证号查名字的例子，如果我们用二叉搜索树来实现的话，示意图如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131800.png" alt="二叉搜索树索引示意"></p><p>二叉搜索树的特点是：父节点左子树所有结点的值小于父节点的值，右子树所有结点的值大于父节点的值。这样如果你要查 ID_card_n2 的话，按照图中的搜索顺序就是按照 UserA -&gt; UserC -&gt; UserF -&gt; User2 这个路径得到。这个时间复杂度是 O(log(N))。</p><p>当然为了维持 O(log(N)) 的查询复杂度，你就需要<strong>保持这棵树是平衡二叉树</strong>。为了做这个保证，更新的时间复杂度也是 O(log(N))。</p><h4 id="二叉平衡搜索树在面对磁盘访问的不适应性"><a class="header-anchor" href="#二叉平衡搜索树在面对磁盘访问的不适应性">¶</a>二叉平衡搜索树在面对磁盘访问的不适应性</h4><p>树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。</p><p>你可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块(<strong>这里是以B+树为背景进行描述的，B+树只有叶子节点会存放数据，所以每一次访问数据都必须经历从根节点到叶子节点的访问过程，每个节点单独存储在一个数据块中，所以就可能会访问树高个数据块</strong>)。在机械硬盘时代，从<strong>磁盘随机读</strong>一个数据块<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。</p><h4 id="平衡二叉树、B树、B-树、B-树"><a class="header-anchor" href="#平衡二叉树、B树、B-树、B-树">¶</a>平衡二叉树、B树、B+树、B*树</h4><h5 id="1-平衡二叉树"><a class="header-anchor" href="#1-平衡二叉树">¶</a>1&gt;平衡二叉树</h5><h6 id="概念"><a class="header-anchor" href="#概念">¶</a>概念</h6><p>平衡二叉树是基于二分法的策略提高数据的查找速度的二叉树的数据结构；</p><h6 id="特点"><a class="header-anchor" href="#特点">¶</a>特点</h6><p>平衡二叉树是采用二分法思维把数据按规则组装成一个树形结构的数据，用这个树形结构的数据减少无关数据的检索，大大的提升了数据检索的速度；平衡二叉树的数据结构组装过程有以下规则：</p><ol><li>非叶子节点只能允许最多两个子节点存在。</li><li>每一个非叶子节点数据分布规则为左边的子节点小当前节点的值，右边的子节点大于当前节点的值(这里值是基于自己的算法规则而定的，比如hash值)；</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131810.jpg" alt="平衡二叉树1"></p><p>平衡树的层级结构：因为平衡二叉树查询性能和树的层级（h高度）成反比，h值越小查询越快、为了保证树的结构左右两端数据大致平衡降低二叉树的查询难度一般会采用一种算法机制实现节点数据结构的平衡，实现了这种算法的有比如<a href="https://link.zhihu.com/?target=http%3A//baike.baidu.com/item/Treap" target="_blank" rel="noopener">Treap</a>、红黑树，使用平衡二叉树能保证数据的左右两边的节点层级相差不会大于1.，通过这样避免树形结构由于删除增加变成线性链表影响查询效率，保证数据平衡的情况下查找数据的速度近于二分法查找；</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131816.jpg" alt="平衡二叉树2"></p><h6 id="总结平衡二叉树特点"><a class="header-anchor" href="#总结平衡二叉树特点">¶</a>总结平衡二叉树特点</h6><ol><li>非叶子节点最多拥有两个子节点；</li><li>非叶子节值大于左边子节点、小于右边子节点；</li><li>树的左右两边的层级数相差不会大于1;</li><li>没有值相等重复的节点;</li></ol><h5 id="2-B树-B-tree"><a class="header-anchor" href="#2-B树-B-tree">¶</a>2&gt;B树(B-tree)</h5><p>注意:之前有看到有很多文章把B树和B-tree理解成了两种不同类别的树，其实这两个是同一种树;</p><h6 id="概念-v2"><a class="header-anchor" href="#概念-v2">¶</a>概念</h6><p>B树和平衡二叉树稍有不同的是B树属于多叉树又名平衡多路查找树（查找路径不只两个），数据库索引技术里大量使用者B树和B+树的数据结构，让我们来看看他有什么特点;</p><h6 id="规则"><a class="header-anchor" href="#规则">¶</a>规则</h6><ol><li>排序方式：所有节点关键字是按递增次序排列，并遵循左小右大原则；</li><li>子节点数：非叶节点的子节点数&gt;1，且&lt;=M ，且M&gt;=2，空树除外（注：M阶代表一个树节点最多有多少个查找路径，M=M路,当M=2则是2叉树,M=3则是3叉）；</li><li>关键字数：枝节点的关键字数量大于等于ceil(m/2)-1个且小于等于M-1个（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2);</li><li>所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子;</li></ol><p>最后我们用一个图和一个实际的例子来理解B树（这里为了理解方便我就直接用实际字母的大小来排列C&gt;B&gt;A）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131823.jpg" alt="B树"></p><h6 id="B树的查询流程："><a class="header-anchor" href="#B树的查询流程：">¶</a>B树的查询流程：</h6><p>如上图要从上图中找到E字母，查找流程如下</p><ol><li>获取根节点的关键字进行比较，当前根节点关键字为M，E&lt;M（26个字母顺序），所以往找到指向左边的子节点（二分法规则，左小右大，左边放小于当前节点值的子节点、右边放大于当前节点值的子节点）；</li><li>拿到关键字D和G，D&lt;E&lt;G 所以直接找到D和G中间的节点；</li><li>拿到E和F，因为E=E 所以直接返回关键字和指针信息（如果树结构里面没有包含所要查找的节点则返回null）；</li></ol><h6 id="B树的插入节点流程"><a class="header-anchor" href="#B树的插入节点流程">¶</a>B树的插入节点流程</h6><p>定义一个5阶树（平衡5路查找树;），现在我们要把3、8、31、11、23、29、50、28 这些数字构建出一个5阶树出来;</p><p>遵循规则：</p><ul><li>节点拆分规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须&lt;=5-1（这里关键字数&gt;4就要进行节点拆分）；</li><li>排序规则：满足节点本身比左边节点大，比右边节点小的排序规则;</li></ul><p>流程：</p><ol><li><p>插入 3、8、31、11</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131830.jpg" alt="B树插入1"></p></li><li><p>再插入23、29</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131836.png" alt="B树插入2"></p></li><li><p>再插入50、28<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131842.png" alt="B树插入3"></p></li></ol><h6 id="B树节点的删除"><a class="header-anchor" href="#B树节点的删除">¶</a>B树节点的删除</h6><p>规则</p><ol><li>节点合并规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须大于等于ceil（5/2）（这里关键字数&lt;2就要进行节点合并）；</li><li>满足节点本身比左边节点大，比右边节点小的排序规则;</li><li>关键字数小于二时先从子节点取，子节点没有符合条件时就向向父节点取，取中间值往父节点放；</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131849.png" alt="B树删除"></p><p>特点</p><p>B树相对于平衡二叉树的不同是，每个节点包含的关键字增多了，特别是在B树应用到数据库中的时候，数据库充分利用了磁盘块的原理（磁盘数据存储是采用块的形式存储的，每个块的大小为4K，每次IO进行数据读取时，同一个磁盘块的数据可以一次性读取出来）把节点大小限制和充分使用在磁盘快大小范围；把树的节点关键字增多后树的层级比原来的二叉树少了，减少数据查找的次数和复杂度;</p><h5 id="3-B-树"><a class="header-anchor" href="#3-B-树">¶</a>3&gt;B+树</h5><h6 id="概念-v3"><a class="header-anchor" href="#概念-v3">¶</a>概念</h6><p>B+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。为什么说B+树查找的效率要比B树更高、更稳定；我们先看看两者的区别</p><h6 id="规则-v2"><a class="header-anchor" href="#规则-v2">¶</a>规则</h6><ol><li>B+跟B树不同B+树的<strong>非叶子</strong>节点不保存关键字记录的指针，只进行数据索引，这样使得B+树每个<strong>非叶子</strong>节点所能保存的关键字大大增加；</li><li>B+树<strong>叶子</strong>节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样；</li><li>B+树叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针。</li><li>非叶子节点的子节点数=关键字数（来源百度百科）（根据各种资料 这里有两种算法的实现方式，另一种为非叶节点的关键字数=子节点数-1（来源维基百科)，虽然他们数据排列结构不一样，但其原理还是一样的Mysql 的B+树是用第一种方式实现）;</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131855.jpg" alt="B+树"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131900.jpg" alt="B+树1"></p><h6 id="特点-v2"><a class="header-anchor" href="#特点-v2">¶</a>特点</h6><ol><li>B+<strong>树的层级更少</strong>：相较于B树B+每个<strong>非叶子</strong>节点存储的关键字数更多，树的层级更少所以查询数据更快；</li><li>B+<strong>树查询速度更稳定</strong>：B+所有关键字数据地址都存在<strong>叶子</strong>节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;</li><li>B+<strong>树天然具备排序功能：<strong>B+树所有的</strong>叶子</strong>节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。</li><li>B+<strong>树全节点遍历更快：<strong>B+树遍历整棵树只需要遍历所有的</strong>叶子</strong>节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。</li></ol><p><strong>B树</strong>相对于<strong>B+树</strong>的优点是，如果经常访问的数据离根节点很近，而<strong>B树</strong>的<strong>非叶子</strong>节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比<strong>B+树</strong>快。</p><h5 id="4-B-树"><a class="header-anchor" href="#4-B-树">¶</a>4&gt;B*树</h5><h6 id="规则-v3"><a class="header-anchor" href="#规则-v3">¶</a>规则</h6><p>B*树是B+树的变种，相对于B+树他们的不同之处如下：</p><ol><li>首先是关键字个数限制问题，B+树初始化的关键字初始化个数是 <code>cei(m/2)</code>，b*树的初始化个数为（<code>cei(2/3*m)</code>）</li><li>B+树节点满时就会分裂，而B*树节点满时会检查兄弟节点是否满（因为每个节点都有指向兄弟的指针），如果兄弟节点未满则向兄弟节点转移关键字，如果兄弟节点已满，则从当前节点和兄弟节点各拿出1/3的数据创建一个新的节点出来；</li></ol><h6 id="特点-v3"><a class="header-anchor" href="#特点-v3">¶</a>特点</h6><p>在B+树的基础上因其初始化的容量变大，使得节点空间使用率更高，而又存有兄弟节点的指针，可以向兄弟节点转移关键字的特性使得B*树额分解次数变得更少；</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131907.jpg" alt="B*树"></p><h5 id="5-总结"><a class="header-anchor" href="#5-总结">¶</a>5&gt;总结</h5><h6 id="1、相同思想和策略"><a class="header-anchor" href="#1、相同思想和策略">¶</a>1、相同思想和策略</h6><p>从平衡二叉树、B树、B+树、B*树总体来看它们的贯彻的思想是相同的，都是采用二分法和数据平衡策略来提升查找数据的速度；</p><h6 id="2、不同的方式的磁盘空间利用"><a class="header-anchor" href="#2、不同的方式的磁盘空间利用">¶</a>2、不同的方式的磁盘空间利用</h6><p>不同点是他们一个一个在演变的过程中通过IO从磁盘读取数据的原理进行一步步的演变，每一次演变都是为了让节点的空间更合理的运用起来，从而使树的层级减少达到快速查找数据的目的；</p><blockquote><p>补充概念：</p><p>附（二分法查找）：<a href="https://zhuanlan.zhihu.com/p/27597160" target="_blank" rel="noopener">二分法查找原理 - 知乎专栏</a></p><p>附（B、B+、B*树）：<a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/v_JULY_v/article/details/6530142/" target="_blank" rel="noopener">从B树、B+树、B*树谈到R 树</a></p><p>附（B、B+、B*树）：<a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/endlu/article/details/51720299" target="_blank" rel="noopener">end’s coding life</a></p><p>附：<a href="https://link.zhihu.com/?target=https%3A//www.cnblogs.com/nullzx/p/8729425.html" target="_blank" rel="noopener">B树和B+树的插入、删除图文详解 - nullzx - 博客园</a></p></blockquote><h4 id="N叉树及InnoDB索引模型初识"><a class="header-anchor" href="#N叉树及InnoDB索引模型初识">¶</a>N叉树及InnoDB索引模型初识</h4><p>为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup> 。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块(即page)的大小。</p><blockquote><p>在MySQL中如何调整“N叉树”的N值？</p><ol><li>通过改变key值来调整<br>N叉树中<strong>非叶子节点 page</strong> 存放的是索引信息，索引包含Key和Point指针。Point指针固定为6个字节<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>，假如Key为10个字节，那么单个索引就是16个字节。如果B+树中页大小为16K，那么一个页就可以存储1024个索引，此时N就等于1024。我们通过改变Key的大小，就可以改变N的值。Key 越小，一个 Page 能够存放的索引信息就越多，此时子节点数量 N 就越大。</li><li>改变页的大小<br><strong>页越大，一页存放的索引就越多，N就越大</strong>。而通常认为key的值是固定的，就是4或者8，即 int或者bigint，所以主要还是page大小来决定 N 叉树的节点数量。</li></ol><p>通过让N值变大，就可以降低同等数据量下树的高度，降低磁盘IO次数。</p></blockquote><p>以 InnoDB 的一个长整数字段索引为例，<strong>这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个Page，这已经 17 亿了</strong>。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了<sup class="footnote-ref"><a href="#fn11" id="fnref11:1">[11:1]</a></sup>。</p><blockquote><p>索引字段为长整型，长度为8个字节，加上记录子节点的指针6B，此时一个非叶子节点的page中的数据单元大小为14B。取默认的 page 大小 16 KB，即一个非叶子节点中可以存储 16 * 1024 / 14 ≈ 1200 个索引信息。</p><p>树高为4，根节点对应一个 page ，存储1200 个索引信息，即第二层可以有1200个page，此时第三层则会有 1200 * 1200 个page，那么第四层再乘 1200 即为 1200 的3次方个page，即第四层叶子节点可以有 1200 的3次方个page可以存储数据。</p></blockquote><p>N 叉树由于在读写上的性能优点，以及<strong>适配磁盘的访问模式</strong>，已经被广泛应用在数据库引擎中了。MySQL 中使用的就是 B+ 树。<strong>B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。</strong></p><blockquote><p>相反，类似红黑树的平衡二叉树适合面对内存访问的场景，因为内存访问更快。</p><p>平衡二叉树每个节点都是一个最小的数据单元，直接经过一次判断对比即可知道该节点是否是要找的数据，或者在它的左子节点还是右子节点，非常高效。而B+树每一次都需要到达叶子节点，即每次访问的层次是固定的，另外其每一个节点都不是最小的数据单元，而是由最小数据单元构成的有序数组，需要对该节点进行查找(二分查找)，才能匹配到对应的数据单元或者指向下一层的指针。</p><p>但是问题还是因为树高的原因可能会访问很多层才能找到对应的节点。此时如果是访问内存，相对于磁盘来说它是非常迅速的(除了主存本身的访问较快，还可以利用多级缓存)。</p></blockquote><h3 id="小结-v2"><a class="header-anchor" href="#小结-v2">¶</a>小结</h3><p>不管是哈希还是有序数组，或者 N 叉树，它们都是不断迭代、不断优化的产物或者解决方案。数据库技术发展到今天，<strong>跳表、LSM 树</strong>等数据结构也被用于引擎设计中。</p><p>心里要有个概念，数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。</p><h2 id="InnoDB的索引模型"><a class="header-anchor" href="#InnoDB的索引模型">¶</a>InnoDB的索引模型</h2><p>在 MySQL 中，<strong>索引是在存储引擎层实现的</strong>，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。由于 InnoDB 存储引擎在 MySQL 数据库中使用最为广泛，下面以 InnoDB 为例，分析一下其中的索引模型。</p><p>在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为<strong>索引组织表</strong>。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。</p><p><strong>每一个索引在 InnoDB 里面对应一棵 B+ 树。</strong></p><p>假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。这个表的建表语句是：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> create table T(id int primary key, k int not null, name varchar(16),index (k))engine=InnoDB;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="聚簇索引-主键-和二级索引-非主键"><a class="header-anchor" href="#聚簇索引-主键-和二级索引-非主键">¶</a>聚簇索引(主键)和二级索引(非主键)</h3><p>表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131916.png" alt="InnoDB 的索引组织结构"></p><p>B+树的高度可以为2或者更多，它的每一个节点都是一个数据页(page)，每个数据页中包含着多个最小数据单元。而数据单元的类型随着它是否是叶子节点或者主键索引而不同。</p><ul><li><p>非叶子节点中存储的最小数据单元是&quot;我们认为的索引&quot;：它由两部分组成，一个是key，一个是指向其子节点的指针 point。其含义为point指向的子节点中包含的所有&quot;数据行&quot;的当前索引字段的值都小于 key。而非叶子节点 page 中存储的最小数据单元是有序的，指的就是按照 key 从小到大进行排序。</p></li><li><p>而叶子节点中存储的最小数据单元，又根据当前索引类型为主键索引和非主键索引的不同而有所不同：</p><ul><li><p><strong>主键索引的叶子节点存的是整行数据(数据页page指的就是聚簇索引的叶子节点，它本身是一个有序数组，里面存储着多行数据)</strong>。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。即整个表数据都是存储在索引中的，索引就是所谓的表。</p><blockquote><p>注意，即使在建表的时候没有指明某个字段为主键，InnoDB也会有一个默认的主键<code>rowid</code>。如果在后续重新指定一个字段为主键字段，将会重建整张表并构建新的聚簇索引。</p></blockquote></li><li><p><strong>非主键索引的叶子节点内容是主键的值</strong>。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。</p></li></ul></li></ul><h3 id="基于主键索引和普通索引的查询有什么区别"><a class="header-anchor" href="#基于主键索引和普通索引的查询有什么区别">¶</a>基于主键索引和普通索引的查询有什么区别</h3><ul><li><p>如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树(聚簇索引本身就是和表数据联合存放在一起的)；</p></li><li><p>如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。</p><blockquote><p>如果语句是 select k from T where k = 5，因为查询的字段 k 的值仅在该索引中即可获得，所以无需回表。如果对于为什么都 k=5 了还仅查询该字段，有什么意义的疑问，这种查询可以被理解为查询有多少行这样的数据，MySQL 还是返回对应命中的行数的，有时候就是有这样的业务需求，不仅仅是要求得命中了多少行，例如某些拼接字符串的场景。</p><p>另外例如查询语句 select k from T where k = 5 and c = 10 ，其中 k 和 c 是联合索引，也会发生索引覆盖，无需回表。</p></blockquote></li></ul><p>也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。</p><h3 id="索引维护可能遇到的页分裂和解决方案"><a class="header-anchor" href="#索引维护可能遇到的页分裂和解决方案">¶</a>索引维护可能遇到的页分裂和解决方案</h3><p>B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，<strong>如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录</strong>。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。</p><p>而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法：</p><ol><li>先查看当前页的前后页是否满了，如果没满就会先将要插入的数据放在前后两个页上</li><li>否则<strong>需要申请一个新的数据页，然后挪动部分数据过去</strong></li></ol><p><strong>以上过程都会将保存了当前页的部分数据的其它数据页的指针保存在当前数据页中形成一个链表串连(其它数据页里面应该有分割符吧…)。这个过程称为页分裂</strong>。在这种情况下，性能自然会受影响（首先是这个过程就需要额外的消耗，其次在读取该页数据的时候，还要遍历链表根据指针进行迭代寻址将逻辑上该页的所有数据读取出来）。</p><p>除了性能外，后者页分裂操作还影响数据页的利用率。<strong>原本放在一个页的数据，现在新申请了一个数据页分别存在两个页中</strong>，整体空间利用率降低大约 50%(之后这两个页如果删除数据，就会出现两个数据页不满的情况，此时体现了利用率低)。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。</p><h4 id="使用自增主键以及使用业务字段作为主键对比"><a class="header-anchor" href="#使用自增主键以及使用业务字段作为主键对比">¶</a>使用自增主键以及使用业务字段作为主键对比</h4><p>基于上面的索引维护过程说明，我们来讨论一个案例：</p><blockquote><p>你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。</p></blockquote><ol><li><p>性能</p><ul><li>自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： <code>NOT NULL PRIMARY KEY AUTO_INCREMENT</code>。插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。也就是说，自增主键的插入数据模式，<strong>正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作(因为是自增)，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。</strong></li><li>而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。</li></ul></li><li><p>存储</p><p>除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？</p><p>由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点中一行数据的占用约 20 个字节(包含身份证的18个字节以及当前字段的值约2个字节，这个2个字节应该是平均得出的)，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。</p><p><strong>显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。</strong></p></li></ol><p>所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：</p><ul><li>只有一个索引；</li><li>该索引必须是唯一索引。</li></ul><p>你一定看出来了，这就是典型的 KV 场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。</p><blockquote><p>在分布式环境下的雪花算法生成的分布式 ID 不是递增的，但是是增长的趋势，所以用它来作为主键是没问题的，在插入的时候也是顺序插入，所以插入不会造成主键页分裂，和自增 ID 性能差不多。</p></blockquote><h3 id="重建索引的理由以及方式"><a class="header-anchor" href="#重建索引的理由以及方式">¶</a>重建索引的理由以及方式</h3><p>对于上面例子中的 InnoDB 表 T，如果要重建索引 k，两个 SQL 语句可以这么写：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">alter table T drop index k;alter table T add index(k);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果你要重建主键索引，也可以这么写：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">alter table T drop primary key;alter table T add primary key(id);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>上面通过两个 alter 语句重建索引 k，以及通过两个 alter 语句重建主键索引是否合理？</p><p>首先为什么要重建索引：索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。</p><p>重建索引 k 的做法是合理的，可以达到省空间的目的；但是，重建主键的过程不合理。<strong>不论是删除主键还是创建主键，都会将整个表重建</strong>。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句用这个语句代替 ： <code>alter table T engine=InnoDB</code>。</p><h4 id="评论区回答"><a class="header-anchor" href="#评论区回答">¶</a>评论区回答</h4><ol><li><p>直接删掉主键索引是不好的，它会使得所有的二级索引都失效，并且会用ROWID来作主键索引；</p></li><li><p>看到mysql官方文档写了三种措施，第一个是整个数据库迁移，先dump出来再重建表（这个一般只适合离线的业务来做）；第二个是用空的alter操作，比如<code>ALTER TABLE t1 ENGINE = InnoDB;</code>这样子就会原地重建表结构；第三个是用repaire table，不过这个是由存储引擎决定支不支持的（InnoDB就不行）。</p></li></ol><h4 id="用户案例"><a class="header-anchor" href="#用户案例">¶</a>用户案例</h4><p>线上的一个表，记录日志用的，会定期删除过早之前的数据.。最后这个表实际内容的大小才10G，而他的索引却有30G。在阿里云控制面板上看就是占了40G空间，这可花的是真金白银啊。后来了解到是 InnoDB 这种引擎导致的，虽然删除了表的部分记录，但是它的索引还在，并未释放，当时没有开启<code>innodb_file_per_table</code>选项（以前 MySQL 数据库是没有默认开启<code>innodb_file_per_table</code>选项的，但现在的新版本已经一个默认配置了），导致所有的表(数据和索引)都存储在了一个文件中。导致上述的<code>alter table T engine=InnoDB</code>无法进行磁盘碎片整理（即修复因为删除数据或者页分裂导致的索引数据页空洞）（没有开启一个表一个索引文件，所有索引都揉再一个文件里面了，很难整理），即使是使用了<code>optimize table</code>都无法释放空间。只能是重新建表并重建索引。</p><blockquote><p>另外，对于记录日志的表最好是分区表（按照时间序列建表按批次归档数据），历史数据清理可以直接drop分区。</p></blockquote><h1>五、索引优化</h1><h2 id="MySQL-Server和InnoDB的查询配合"><a class="header-anchor" href="#MySQL-Server和InnoDB的查询配合">¶</a>MySQL Server和InnoDB的查询配合</h2><p>在下面这个表 T 中，如果执行 <code>select * from T where k between 3 and 5</code>，需要执行几次树的搜索操作，会扫描多少行？</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> create table T (ID int primary key,k int NOT NULL DEFAULT 0, s varchar(16) NOT NULL DEFAULT '',index k(k))engine=InnoDB;insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131928.png" alt="range查询扫描行数"></p><p>现在，我们一起来看看这条 SQL 查询语句的执行流程：</p><ol><li>在 k 索引树上找到 k=3 的记录，取得 ID = 300；</li><li>再到 ID 索引树查到 ID=300 对应的 R3；</li><li>在 k 索引树取下一个值 k=5，取得 ID=500；</li><li>再回到 ID 索引树查到 ID=500 对应的 R4；</li><li>在 k 索引树取下一个值 k=6，不满足条件，循环结束。</li></ol><p><strong>在引擎内部使用覆盖索引在索引 k 上其实读了三个记录</strong>，R3~R5（对应的索引 k 上的记录项，读取了k=6的项发现不满足，没有回表其数据），<strong>但是对于 MySQL 的 Server 层来说，它就是找引擎拿到了两条记录，因此 MySQL 认为扫描行数是 2(行扫描指的是Server层对InnoDB返回的数据进行扫描，InnoDB根据索引将存储的数据返回到Server层，无索引的条件只能由Server层执行器自己来扫描并过滤不匹配的行)</strong>。(<strong>从扫描字眼以及这里的描述看起来对于数据page中有序数组的查询方式是遍历而不是二分？还是说有一定的策略的？</strong>)</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> explain select * from T where k between 3 and 5;+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                 |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+|  1 | SIMPLE      | T     | NULL       | range | k             | k    | 4       | NULL |    2 |   100.00 | Using index condition |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+1 row in set, 1 warning (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="覆盖索引"><a class="header-anchor" href="#覆盖索引">¶</a>覆盖索引</h2><p>在以上过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了 k 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4）。在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？</p><p>如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引(查询的字段只有主键或者和条件字段构成联合索引的时候触发)。<strong>由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。</strong></p><p>基于上面覆盖索引的说明，我们来讨论一个问题：在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `tuser` (  `id` int(11) NOT NULL,  `id_card` varchar(32) DEFAULT NULL,  `name` varchar(32) DEFAULT NULL,  `age` int(11) DEFAULT NULL,  `ismale` tinyint(1) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `id_card` (`id_card`),  KEY `name_age` (`name`,`age`)) ENGINE=InnoDB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们知道，身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？</p><p>如果现在有一个高频请求，要根据市民的身份证号查询他的姓名，这个联合索引就有意义了。<strong>它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录</strong>，减少语句的执行时间。当然，索引字段的维护总是有代价的。</p><p>因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作。</p><h2 id="最左前缀原则"><a class="header-anchor" href="#最左前缀原则">¶</a>最左前缀原则</h2><p>基于上面提到的覆盖索引，建表语句可以改成：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `tuser` (  `id` int(11) NOT NULL,  `id_card` varchar(32) DEFAULT NULL,  `name` varchar(32) DEFAULT NULL,  `age` int(11) DEFAULT NULL,  `ismale` tinyint(1) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `id_card_name` (`id_card`, `name`), -- 针对频繁的根据身份证查姓名的需求建立联合索引  KEY `name_age` (`name`,`age`)) ENGINE=InnoDB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但是这样也会产生新的问题，如果为每一种查询都设计一个索引，索引是不是太多了。如果现在要按照市民的身份证号去查他的家庭地址呢？虽然这个查询需求在业务中出现的概率不高，但总不能让它走全表扫描吧？反过来说，单独为一个不频繁的请求再创建一个（身份证）的单独索引 或者（身份证号，地址）的联合索引又感觉有点浪费。应该怎么做呢？</p><p>其实无需怎么做，因为 B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。所以前面定义的<code>id_card_name</code>索引它对于单独使用身份证进行查询还是其它字段还是有效的，不会全表扫描，只不过会回表去查询其它字段。</p><p>下面后面的（name，age）这个联合索引来分析最左前缀匹配过程。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131937.jpg" alt="最左前缀匹配"></p><p>可以看到，索引项是按照索引定义里面出现的字段顺序排序的。</p><ul><li>当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。</li><li>如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是&quot;where name like ‘张 %’&quot;。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。</li></ul><p>可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。<strong>这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。</strong></p><h3 id="联合索引如何安排索引字段顺序"><a class="header-anchor" href="#联合索引如何安排索引字段顺序">¶</a>联合索引如何安排索引字段顺序</h3><p>那么基于上面对最左前缀索引的说明，在建立联合索引的时候，如何安排索引内的字段顺序。这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的（作为查询条件比较频繁的字段排在前面）。</p><p>那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，建议创建一个（name,age) 的联合索引和一个 (age) 的单字段索引：</p><blockquote><ul><li>多个字段同时作为查询条件出现</li><li>或者部分作为查询条件、部分作为查询字段出现</li><li>同时又经常只有一个字段作为查询条件出现</li></ul><p>以上情况频率比较均匀的情况下，对这些字段建立联合(利用索引下推和索引覆盖分别满足前两个操作)的同时对长度较小的字段重新建立索引(使得后一个操作无法进行前缀匹配利用联合索引的时候走单独索引，避免全表扫描，同时相较对大字段重复建立索引来说降低了索引空间的占用)。</p></blockquote><h2 id="索引下推"><a class="header-anchor" href="#索引下推">¶</a>索引下推</h2><p>还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from tuser where name like '张%' and age=10 and ismale=1;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>根据前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。然后对索引匹配的数据行进行判断其他条件是否满足：</p><ul><li><p>在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131944.jpg" alt="无索引下推执行流程"></p><p>图中去掉了 age 的值，标识这个过程 InnoDB 并不会去看 age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。</p></li><li><p>而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131950.jpg" alt="索引下推执行流程"></p><p>InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在该例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。</p></li></ul><p>注意，以上的所说 MySQL 5.6 前后差异指的是模糊查询(使用<code>LIKE</code>关键字)有所差异。在 5.6 之前，对于模糊查询，InnoDB 存储引擎给出的接口只能传入&quot;搜索关键字&quot;，无法传入其它匹配条件(即无法进行 index condition pushdown)；在 5.6 之后，增加了入参，从而可以实现模糊查询下的索引条件下推，让 InnoDB 自身在使用字符串前缀匹配到该字符串字段所在的联合索引中的page之后使用这些下推的索引条件对其它索引字段对匹配到的数据行进行过滤。（对于非模糊查询，5.6 之前应该就有这个逻辑，不然联合索引意义何在）</p><blockquote><p>当使用了索引下推的时候，使用 explain 输出的 extra 列会显示&quot;Using index condition&quot;，而不是&quot;using index&quot;。</p></blockquote><h2 id="多主键索引"><a class="header-anchor" href="#多主键索引">¶</a>多主键索引</h2><h3 id="问题"><a class="header-anchor" href="#问题">¶</a>问题</h3><p>实际上主键索引也是可以使用多个字段的。</p><p>DBA 小吕在入职新公司的时候，就发现自己接手维护的库里面，有这么一个表，表结构定义类似这样的：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `geek` (  `a` int(11) NOT NULL,  `b` int(11) NOT NULL,  `c` int(11) NOT NULL,  `d` int(11) NOT NULL,  PRIMARY KEY (`a`,`b`),  KEY `c` (`c`),  KEY `ca` (`c`,`a`),  KEY `cb` (`c`,`b`)) ENGINE=InnoDB;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>公司的同事告诉他说，由于历史原因，这个表需要 a、b 做联合主键，这个小吕理解了。但是，既然主键包含了 a、b 这两个字段，那意味着单独在字段 c 上创建一个索引，就已经包含了三个字段了呀，为什么要创建“ca”“cb”这两个索引？同事告诉他，是因为他们的业务里面有这样的两种语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from geek where c=N order by a limit 1;select * from geek where c=N order by b limit 1;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>为了这两个查询模式，这两个索引是否都是必须的？为什么呢？</p><h3 id="答案"><a class="header-anchor" href="#答案">¶</a>答案</h3><p>InnoDB 会把主键字段放到索引定义字段后面，同时去重，类似联合索引。</p><ul><li>对于联合主键索引（a,b），在聚簇索引的叶子节点page的有序数组中，数据行就是先按照 a 进行排序，a 相同的情况下再按照 b 进行排序的。</li><li>对于索引（c），InnoDB 会把主键字段（a,b）加到后面，成为（c,a,b），此时该二级索引的叶子节点page中的有序数组将按照c 进行排序，然后才是 c 、b。</li><li>对于索引（c,a），InnoDB 还是会把主键字段（a,b）加到后面并去重，成为（c,a,b），此时和索引（c）重复了。所以这个索引是可以去掉的。</li><li>对于索引（c,b），拼接主键字段并去重后得到（c,b,a），此时将先按照 c 排序，然后是 b ，最后是 a。</li></ul><p>所以，索引（c,a）是可以去掉的。</p><h2 id="关于explain中的Extra"><a class="header-anchor" href="#关于explain中的Extra">¶</a><a href="https://dev.mysql.com/doc/refman/5.7/en/explain-output.html#explain-extra-information" target="_blank" rel="noopener">关于<code>explain</code>中的<code>Extra</code></a></h2><ul><li>Using filesort：本次查询语句中有order by，且排序依照的字段不在本次使用的索引中，不能自然有序。需要进行额外的排序工作。</li><li>Using index：使用了覆盖索引——即本次查询所需的所有信息字段都可以从利用的索引上取得。无需回表，额外去主索引上去数据。 The column information is retrieved from the table using only information in the index tree without having to do an additional seek to read the actual row. This strategy can be used when the query uses only columns that are part of a single index.</li><li>Using index condition： 使用了索引下推技术ICP。（虽然本次查询所需的数据，不能从利用的索引上完全取得，还是需要回表去主索引获取。但在回表前，充分利用索引中的字段，根据where条件进行过滤。提前排除了不符合查询条件的列。这样就减少了回表的次数，提高了效率。） Tables are read by accessing index tuples and testing them first to determine whether to read full table rows. In this way, index information is used to defer (“push down”) reading full table rows unless it is necessary. See Section 8.2.1.5, “Index Condition Pushdown Optimization”.</li><li>Using where：表示本次查询，Server 层要对从存储层返回的结果进行筛选过滤。</li><li>Using temporary：表示会使用到临时表</li><li>Using MRR：使用了 MRR 优化</li></ul><h1>六、MySQL中的锁</h1><p>根据加锁的范围，MySQL 里面的锁大致可以分成<strong>全局锁、表级锁和行锁<sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup>三类</strong>。</p><h2 id="全局锁"><a class="header-anchor" href="#全局锁">¶</a>全局锁</h2><p>顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 <code>Flush tables with read lock</code> <sup class="footnote-ref"><a href="#fn14" id="fnref14">[14]</a></sup> (FTWRL)。当你需要让<strong>整个库处于只读状态</strong>的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：</p><ul><li>数据更新语句（数据的增删改）</li><li>数据定义语句（包括建表、修改表结构等）</li><li>更新类事务的提交语句</li></ul><p>全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。以前有一种做法，是通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。</p><h3 id="为什么备份数据库要加全局锁"><a class="header-anchor" href="#为什么备份数据库要加全局锁">¶</a>为什么备份数据库要加全局锁</h3><p>但是让整库都只读，听上去就很危险：</p><ul><li><p>如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；</p></li><li><p>如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。</p></li></ul><p>看来加全局锁不太好。但是细想一下，备份为什么要加锁呢？我们来看一下不加锁会有什么问题。</p><p>假设你现在要维护“极客时间”的购买系统，关注的是用户账户余额表和用户课程表。现在发起一个逻辑备份。假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。如果时间顺序上是先备份账户余额表 (u_account)，然后用户购买，然后备份用户课程表 (u_course)，会怎么样呢？</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221131959.png" alt="业务和备份状态图"></p><p>可以看到，这个备份结果里，用户 A 的数据状态是“账户余额没扣，但是用户课程表里面已经多了一门课”。如果后面用这个备份来恢复数据的话，用户 A 就发现，自己赚了。作为用户可别觉得这样可真好啊，你可以试想一下：如果备份表的顺序反过来，先备份用户课程表再备份账户余额表，又可能会出现什么结果？也就是说，<strong>不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的(其实就是备份的数据是不完整的)</strong>。</p><h3 id="除了全局锁外保持视图一致的方法-mysqldump"><a class="header-anchor" href="#除了全局锁外保持视图一致的方法-mysqldump">¶</a>除了全局锁外保持视图一致的方法:mysqldump</h3><p>在可重复读隔离级别下开启一个事务，是可以保持一个全局不变的事务视图的。</p><p>官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数<code>–single-transaction</code> 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。</p><h4 id="有了mysqldump为什么还要全局锁"><a class="header-anchor" href="#有了mysqldump为什么还要全局锁">¶</a>有了mysqldump为什么还要全局锁</h4><p>有了这个功能，为什么还需要 FTWRL 呢？一致性读是好，<strong>但前提是引擎要支持这个隔离级别</strong>。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了，这里谈到的<strong>全局锁是 Server 层实现</strong>的，所以<strong>它们不依赖于底层存储引擎</strong>。</p><p>所以，<code>single-transaction</code> 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。</p><h3 id="为什么不通过设置readonly来实现数据库不可写"><a class="header-anchor" href="#为什么不通过设置readonly来实现数据库不可写">¶</a>为什么不通过设置<code>readonly</code>来实现数据库不可写</h3><p>既然要全库只读，为什么不使用 <code>set global readonly=true</code> 的方式呢？确实 readonly 方式也可以让全库进入只读状态，但还是会建议用 FTWRL 方式，主要有两个原因：</p><ul><li><p>一是，在有些系统中，<strong>readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库</strong>。因此，修改 global 变量的方式影响面更大，我不建议你使用。</p></li><li><p>二是，在异常处理机制上有差异。<strong>如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁</strong>，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。</p></li></ul><h2 id="表级锁"><a class="header-anchor" href="#表级锁">¶</a>表级锁</h2><p>业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。但是，即使没有被全局锁住，加字段也不是就能一帆风顺的，因为你还会碰到表级锁。</p><p>MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。</p><h3 id="表锁"><a class="header-anchor" href="#表锁">¶</a>表锁</h3><p>表锁的语法是 <code>lock tables … read/write</code>。与 FTWRL 类似，可以用 <code>unlock tables</code> 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。</p><p>举个例子, 如果在某个线程 A 中执行 <code>lock tables t1 read, t2 write;</code> 这个语句，则其他线程写<code> t1</code>、读写<code> t2</code> 的语句都会被阻塞。同时，线程 A 在执行 <code>unlock tables</code> 之前，也只能执行读 <code>t1</code>、读写 <code>t2</code> 的操作。<strong>连写 <code>t1</code> 都不允许，自然也不能访问其他表</strong>。</p><blockquote><p>在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 <strong>InnoDB 这种支持行锁的引擎</strong>，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。</p></blockquote><h3 id="MDL（metadata-lock"><a class="header-anchor" href="#MDL（metadata-lock">¶</a>MDL（metadata lock)</h3><p>另一类表级的锁是 MDL（metadata lock)。<strong>MDL 不需要显式使用</strong>，在访问一个表的时候会被自动加上。<strong>MDL 的作用是，保证读写数据前后表的结构是一致的</strong>。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。因此，在 MySQL 5.5 版本中引入了 MDL，<strong>当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁</strong>：</p><ul><li><p>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</p></li><li><p>读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。</p></li><li><p>MDL 有一个同步队列，如果在某一刻有一个线程在获取写锁，写锁进入同步队列，后面所有 MDL 都会被该写锁阻塞，可以看出写锁是有一个相对高优先级的，这应该是防止写锁饿死，因为读锁的获取是非常频繁的，如果锁的获取是随机不公平的，将可能导致写锁一直获取不到锁。</p><p>另外，因为通常获取 MDL 之后执行的 DDL 是要消耗较长时间的 (需要扫描全表) ，如果它获取写锁之后一直不释放，就会一直阻塞其它读锁导致此期间该表无法读写数据。所以在 5.6 之后加入了 “online DDL”：</p><ol><li>申请 MDL 写锁：和第三步形成互斥保证同一时间只有一个线程对一个表执行 DDL。</li><li>DDL 执行准备：这里可以写入一些准备数据，第1步加写锁也保证了安全</li><li>降级成 MDL 读锁：准备完成之后可以降级乘读锁，同时读锁保持阻塞其它 DDL 申请写锁（阻塞其它线程执行第一步，也就是不允许其它线程对当前表执行 DDL）。</li><li>DDL 核心执行（耗时较长）：申请新空间在新空间上执行DDL</li><li>升级成 MDL 写锁：第4步 DDL 执行完之后，需要升级为 MDL 写锁提交修改。</li><li>DDL 最终提交</li><li>释放 MDL 锁</li></ol><p>其中第4步真正执行 DDL 的步骤不会阻塞后面其它线程对于该表 MDL 的获取，体现了 “onliine”。</p></li><li><p>MDL 的释放是随着事务的释放才释放的，所以如果手动开启了事务执行 DDL 或者 DML，一定要手动事务，否则将会一直阻塞后面的 DDL/DML 或者 DDL（这一点也是长事务的一个负担）。而自动提交事务则会自动释放 MDL 。</p></li></ul><h4 id="MDL-带来的阻塞问题"><a class="header-anchor" href="#MDL-带来的阻塞问题">¶</a>MDL 带来的阻塞问题</h4><p>虽然 MDL 锁是系统默认会加的，但却是不能忽略的一个机制。比如下面这个例子，经常有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。<strong>给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据</strong>。在对大表操作的时候，肯定要特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。</p><p>下面是一个操作序列，假设表 t 是一个小表。其中绿色表示成功拿到 MDL，黄色是释放 MDL，红色表示取 MDL 被阻塞。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132010.png" alt="mysqlmdl"></p><ol><li>session C 在尝试修改执行 DDL 修改表结构，在第一步获取写锁的时候，因为前面有两个获取 MDL 读锁的 session 是手动开启事务，且还没有提交事务，所以将一直阻塞。因为有一个写锁在队列中阻塞，所以后面的 session D 的获取读锁动作也会被阻塞。此时 session C 和 D 的用户界面将一直 hang 住。</li><li>后续 session A 和 B 都释放了读锁，此时 session C 成功获取到写锁，并进入第二阶段，为执行 DDL 做准备，此时后续 session C 的获取读锁动作将会被持续阻塞。</li><li>直到 session C 第二阶段完成，将写锁降级乘读锁，进入第四阶段，online 执行 DDL， 此时 session D 获取到读锁，执行查询语句返回用户界面，等待用户提交事务。</li><li>sessino C 第四阶段完成后，申请写锁，准备提交 DDL 修改，但是因为 session D 没有释放读锁，所以持续阻塞，用户界面持续 hang 住。与此同时，有一个 session E 准备修改表数据，申请读锁，将会因为 session C 的申请写锁阻塞而阻塞。</li><li>session D 提交事务释放读锁，session C 顺利拿到写锁提交 DDL 修改后自动释放事务并释放写锁，session E 拿到读锁，执行表数据修改 DML 。</li></ol><p>如果对 session D 稍作修改，将<code>begin</code>手动开启、<code>commit</code>手动提交事务都去掉，此时它的查询操作将会在获取到读锁之后执行完查询语句返回用户界面即自动释放读锁。此时 session C 就不会因为 session D 没有提交事务而被 hang 住了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132018.png" alt="mysqlmdl1"></p><p>基于以上分析，online DDL 在第一步获取写锁的时候是会被前面的读锁事务被阻塞的，所以<strong>如果该事务是一个长事务，迟迟不释放该读锁，此时获取写锁请求将一直阻塞。如果只有自己被阻塞还没什么关系，但是之后所有要对表的增删改查操作都需要先申请 MDL 读锁，这些新申请 MDL 读锁的请求也会被阻塞，等于这个表现在完全不可读写了。如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满</strong>。</p><h4 id="如何解决-MDL-的潜在问题"><a class="header-anchor" href="#如何解决-MDL-的潜在问题">¶</a>如何解决 MDL 的潜在问题</h4><ol><li><p>首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 <code>information_schema</code> 库的 <code>innodb_trx</code> 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。</p></li><li><p>但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？这时候 kill 可能未必管用，因为新的请求马上就来了。</p><ul><li><p>比较理想的机制是，在 <code>alter table</code> 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 <code>DDL NOWAIT/WAIT N</code> 这个语法。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">ALTER TABLE tbl_name NOWAIT add column ...ALTER TABLE tbl_name WAIT N add column ... <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>另外，对于非开源 mysql ，可以通过在准备执行 DDL 的 session 中执行 <code>set lock_wait_timeout = &lt;N&gt;</code> 设置获取锁最大等待时间 N 秒，N 秒无法申请写锁将取消申请，此时将不会阻塞后面读写了。</p></li></ul></li></ol><h4 id="参考阅读"><a class="header-anchor" href="#参考阅读">¶</a>参考阅读</h4><blockquote><p><a href="https://blog.csdn.net/finalkof1983/article/details/88063328" target="_blank" rel="noopener">CSDN: MySQL锁系列之MDL元数据锁之一</a></p><p><a href="https://blog.csdn.net/finalkof1983/article/details/88119884" target="_blank" rel="noopener">CSDN: MySQL锁系列之MDL元数据锁之二</a></p><p><a href="https://blog.csdn.net/finalkof1983/article/details/88247329" target="_blank" rel="noopener">CSDN: MySQL锁系列之MDL元数据锁之三</a></p></blockquote><h3 id="小结-v3"><a class="header-anchor" href="#小结-v3">¶</a>小结</h3><p>全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，建议选择使用<code>–single-transaction</code> 参数，对应用会更友好。</p><p>表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果发现应用程序里有 <code>lock tables</code> 这样的语句，需要追查一下，比较可能的情况是：要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；要么是引擎升级了，但是代码还没升级，将 <code>lock tables</code> 和 <code>unlock tables</code> 改成 <code>begin</code> 和 <code>commit</code>，问题就解决了。</p><h3 id="在备库做备份时遇到主库DDL"><a class="header-anchor" href="#在备库做备份时遇到主库DDL">¶</a>在备库做备份时遇到主库DDL</h3><p>备份一般都会在备库上执行，你在用<code>–single-transaction</code> 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？假设这个 DDL 是针对表 t1 的，以下是 <code>mysqldump</code> 命令的内部流程示例：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；/* other tables */Q3:SAVEPOINT sp;/* 时刻 1 */Q4:show create table `t1`;/* 时刻 2 */Q5:SELECT * FROM `t1`;/* 时刻 3 */Q6:ROLLBACK TO SAVEPOINT sp;/* 时刻 4 *//* other tables */<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在备份开始的时候，为了确保 RR（可重复读）隔离级别，再设置一次 RR 隔离级别 (Q1)；启动事务，这里用 <code>WITH CONSISTENT SNAPSHOT</code> 确保这个语句执行完就可以得到一个一致性视图（Q2)；设置一个保存点，这个很重要（Q3）；<code>show create</code> 是为了拿到表结构 (Q4)，然后正式导数据 （Q5），回滚到 SAVEPOINT sp，在这里的作用是释放 t1 的 MDL 锁 （Q6）。</p><p>DDL 从主库传过来的时间按照效果不同，分为4个时刻。题目设定为小表，假定到达后，如果开始执行，则很快能够执行完成。</p><ol><li>如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。</li><li>如果在“时刻 2”到达，则表结构被改过，Q5 执行的时候，报 <code>Table definition has changed, please retry transaction</code>，现象：mysqldump 终止；</li><li>如果在“时刻 2”和“时刻 3”之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。</li><li>从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 前的表结构。</li></ol><h4 id="评论区的一个描述"><a class="header-anchor" href="#评论区的一个描述">¶</a>评论区的一个描述</h4><p>备库用不同的备份命令会有不同的情况：</p><ul><li><p>如果备库采用的备份选项为 <code>--single-transaction --dump-slave=(1or2)</code> 时：</p><p>会在备份文件中记录主库备份时点的binlog偏移量，并且关停备库的sql_running进程，备份完成后再开启。此时主库对表的DDL操作传输到备库的relay日志中，但由于备份的sql_running进行处于停止状态，所以并不会运用数据库中，对备库的备份无影响，所有的DDL操作都等待备份完成后再进行。</p></li><li><p>如果备份采用的备份选项是 <code>--single-transaction --master-data=(1or2)</code>时：</p><p>会在备份文件中记录备库备份时的binlog偏移量，这个时候需要分三种情况进行讨论：</p><ol><li>主库中对表的DDL操作传输到备库时，备库的备份已完成对该表的备份<br>此时对备份数据没有影响</li><li>主库中对表的DDL操作传输到备库时，备库的备份还未对该表进行备份<br>那么当备份到该表时，备份会报错，例如表定义已改变或者表不存在等</li><li>主库中对表的DDL操作传输到备库时，备库的备份正在对该表进行备份<br>此刻DDL语句会被阻塞，处于等待获取MDL写锁的状态。</li></ol></li></ul><h2 id="行锁"><a class="header-anchor" href="#行锁">¶</a>行锁</h2><p>MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁（更新操作先加 MDL 读锁互斥 DDL 操作，然后显式声明表锁互斥针其它线程对该表的 DML 操作），对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，<strong>相对于表锁，粒度更细，提高了并发效率</strong>，这也是 MyISAM 被 InnoDB 替代的重要原因之一。</p><p>顾名思义，行锁就是针对数据表中行记录的锁。这很好理解，比如<strong>事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新</strong>。</p><h3 id="两阶段锁"><a class="header-anchor" href="#两阶段锁">¶</a>两阶段锁</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132028.jpg" alt="两阶段锁"></p><p>以上图中事务 B 会被 事务 A 阻塞，直到事务 A commit 之后，事务 B 才能执行。</p><p>在 InnoDB 事务中，<strong>行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等待事务结束时才释放</strong>。这个就是两阶段锁协议。</p><p>根据两阶段锁协议，如果事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。此时每个事务对并发越频繁的锁的占有时间会越短，相对较少锁冲突带来的阻塞、并发效率低下、死锁等问题。</p><h4 id="例子"><a class="header-anchor" href="#例子">¶</a>例子</h4><p>假设要实现一个电影票在线交易业务，顾客 A 要在影院 B 购买电影票。我们简化一点，这个业务需要涉及到以下操作：</p><ol><li>从顾客 A 账户余额中扣除电影票价；</li><li>给影院 B 的账户余额增加这张电影票价；</li><li>记录一条交易日志。</li></ol><p>也就是说，要完成这个交易，我们需要 update 两条记录，并 insert 一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。实际上这三个操作产生的锁的频率是不一样的：</p><ul><li>因为可能存在很多个顾客都在买影院 B 的票，它的账户余额变化频率应该是最高的</li><li>顾客 A 可能同时在买不同影院的票或者在买其它东西，他的账户余额虽然存在变化，但是频率远不及电影院高</li><li>剩下的就是交易日志表了，这是一条 insert 操作，它也是会加行锁的，但是因为这是一张日志表，通常都是插入操作，很少有更新，所以它的锁冲突基本没有。</li></ul><p>所以应该按照&quot;3-&gt;1-&gt;2&quot;的方式执行，此时锁冲突频率尽可能降到最低，最大程度减少了事务之间的等待，提高了并发效率。</p><h3 id="死锁"><a class="header-anchor" href="#死锁">¶</a>死锁</h3><p>虽然上面经过设计减少锁冲突频率，但是如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，<strong>并发量一上来</strong>，发现 MySQL 挂了。登上服务器一看**，CPU 消耗接近 100%，但整个数据库每秒就执行不到 100 个事务**，此时可能就是发生死锁了。</p><p>当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132035.jpg" alt="死锁"></p><p>事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。</p><h3 id="死锁解决方法"><a class="header-anchor" href="#死锁解决方法">¶</a>死锁解决方法</h3><p>当出现死锁以后，有两种策略：</p><ul><li>一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 <code>innodb_lock_wait_timeout</code> 来设置。</li><li>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 <code>innodb_deadlock_detect</code> 设置为 <code>on</code>，表示开启这个逻辑。</li></ul><h4 id="利用锁等待超时参数解死锁的弊端"><a class="header-anchor" href="#利用锁等待超时参数解死锁的弊端">¶</a>利用锁等待超时参数解死锁的弊端</h4><p>在 InnoDB 中，<code>innodb_lock_wait_timeout</code> 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。</p><h4 id="利用死锁检测"><a class="header-anchor" href="#利用死锁检测">¶</a>利用死锁检测</h4><p>所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 <code>innodb_deadlock_detect</code> 的默认值本身就是 <code>on</code>。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。</p><h5 id="热点行对于死锁检测的负担"><a class="header-anchor" href="#热点行对于死锁检测的负担">¶</a>热点行对于死锁检测的负担</h5><p>每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，对于单个线程来说一个时间复杂度是 O(n) 的操作，而对于并发的所有线程来说是一个接近O(n^2)的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。</p><h6 id="什么情况下会发生死锁检测"><a class="header-anchor" href="#什么情况下会发生死锁检测">¶</a>什么情况下会发生死锁检测</h6><ol><li><p>首先是要开启了死锁检测，默认是开启的</p></li><li><p>当前事务要加锁的行已经存在了锁，才会进行死锁检测</p></li><li><p>一致性读不会加锁(MVCC，如果是串行隔离级别读也会加锁)，就不需要进行死锁检测</p></li><li><p>死锁检测并不是说要扫描所有事务，基于第2点：当前事务A发现它要申请的锁已经有事务B申请了，此时它就要检测事务B是否有要申请并且在等待的锁，如果有就检查该锁被哪个事务持有了，再检查该事务是否有等待的锁，以此类推，就是一个查找链表上是否存在环的问题，不在这个依赖链表上的事务不会被扫描。</p><p><strong>从这一点也可以看出，死锁检测是从每一个新提交的事务本身开始扫描检测的</strong>（因为从逻辑上来说，已经存在的事务都不应该存在死锁，因为存在也会被检测到并回滚了，只有新加进来的事务可能会导致死锁的产生）。</p></li></ol><h5 id="解决热点行更新导致的性能问题"><a class="header-anchor" href="#解决热点行更新导致的性能问题">¶</a>解决热点行更新导致的性能问题</h5><ul><li><p>一种头痛医头的方法，就是<strong>如果你能确保这个业务一定不会出现死锁（其实可以理解为在业务上保证同一事务中的DML肯定不会出现循环取锁；或者保证取锁有序，即写执行数据库DML的时候要注意保证它们涉及的锁都是按照同一顺序取的，但是涉及到相对复杂的场景就很难做到了）</strong>，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误：</p><ul><li>毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的（死锁检测相对较快，直接回滚解开死锁重试）。</li><li>而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的（等待过程的时间被白白消耗）。</li></ul></li><li><p>**另一个思路是控制并发度。**根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。</p><p>因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了（<strong>利用 MQ 削峰和 Redis 减轻数据库压力</strong>）。</p><p>如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。</p></li></ul><h3 id="如何删除表里面的前-10000-行数据"><a class="header-anchor" href="#如何删除表里面的前-10000-行数据">¶</a>如何删除表里面的前 10000 行数据</h3><ul><li><p>第一种，直接执行 <code>delete from T limit 10000;</code></p><p>事务相对较长，则占用锁的时间较长，会导致其他客户端等待资源时间较长</p></li><li><p>第二种，在一个连接中循环执行 20 次 <code>delete from T limit 500;</code></p><p>串行化执行，将相对长的事务分成多次相对短的事务，则每次事务占用锁的时间相对较短，其他客户端在等待相应资源的时间也较短。这样的操作，同时也意味着将资源分片使用（每次执行使用不同片段的资源），可以提高并发性（和其它连接）。</p></li><li><p>第三种，在 20 个连接中同时执行 <code>delete from T limit 500</code>。</p><p>人为自己制造锁竞争，加剧并发量</p></li><li><p>第四种，先查询前 10000 行的主键出来，根据主键分成 20 批，在 20 个连接中同时执行。</p><p>规避第三种方法带来的锁竞争问题，同时又能利用并发执行带来的好处。</p></li></ul><h2 id="next-key-lock"><a class="header-anchor" href="#next-key-lock">¶</a>next-key lock</h2><h3 id="先导：例子"><a class="header-anchor" href="#先导：例子">¶</a>先导：例子</h3><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t` (  `id` int(11) NOT NULL,  `c` int(11) DEFAULT NULL,  `d` int(11) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个表除了主键 id 外，还有一个索引 c，初始化语句在表中插入了 6 行数据。基于这个表结构，下列语句序列是怎么加锁的呢？加的锁又是什么时候释放呢？</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">begin;select * from t where d=5 for update; -- 字段 d 没有索引commit;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>基于上面的行锁介绍比较好理解的是，这个语句会命中 d=5 的这一行，对应的主键 id=5，因此在 select 语句执行完成后，id=5 这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行 commit 语句的时候释放。由于字段 d 上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的 5 行记录上，会不会被加锁呢？接下来没有特殊说明的部分，都是设定在可重复读隔离级别下。</p><h3 id="幻读是什么？"><a class="header-anchor" href="#幻读是什么？">¶</a>幻读是什么？</h3><p>下面分析一下，如果只在主键索引的 id=5 这一行加锁，而其他行的不加锁的话，会怎么样。下面先来看一下这个场景（注意：这是假设的 MySQL 不加锁的一个场景）：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132046.png" alt="假设只在 id=5 这一行加行锁"></p><p>可以看到，session A 里执行了三次查询，分别是 Q1、Q2 和 Q3。它们的 SQL 语句相同，都是 select * from t where d=5 for update。这个语句的意思你应该很清楚了，查所有 d=5 的行，而且使用的是当前读，并且加上写锁。现在，我们来看一下这三条 SQL 语句，分别会返回什么结果。</p><ol><li>Q1 只返回 id=5 这一行；</li><li>在 T2 时刻，session B 把 id=0 这一行的 d 值改成了 5，因此 T3 时刻 Q2 查出来的是 id=0 和 id=5 这两行；</li><li>在 T4 时刻，session C 又插入一行（1,1,5），因此 T5 时刻 Q3 查出来的是 id=0、id=1 和 id=5 的这三行。</li></ol><p>其中，Q3 读到 id=1 这一行的现象，被称为“幻读”。也就是说，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。这里需要对“幻读”做一个说明：</p><ol><li><p>在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。</p><blockquote><p>对于不可重复读(RC)隔离级别，快照读会看到别的事务插入的数据，但这是 RC 的版本视图特性，不能算为幻读。</p></blockquote></li><li><p>上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。</p></li></ol><blockquote><p>此外，幻读是因为 RR 隔离级别下出现下面介绍的问题(bug)的原因。对于 RC 隔离界级别来说，没有这样的问题。所以，可以认为幻读是 RR 隔离级别下才有的一个问题。</p></blockquote><p>因为这三个查询都是加了 for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B 和 sessionC 的两条语句，执行后就会提交，所以 Q2 和 Q3 就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。但是，这是不是真的没问题呢？不，这里还真就有问题。</p><h3 id="幻读有什么问题？"><a class="header-anchor" href="#幻读有什么问题？">¶</a>幻读有什么问题？</h3><h4 id="破坏了加锁语义"><a class="header-anchor" href="#破坏了加锁语义">¶</a>破坏了加锁语义</h4><p>首先是语义上的。session A 在 T1 时刻就声明了，“我要把所有 d=5 的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。在例子中 session B 和 session C 里面分别加一条 SQL 语句，再看看会出现什么现象。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132052.png" alt="假设只在 id=5 这一行加行锁--语义被破坏"></p><p>session B 的第二条语句 <code>update t set c=5 where id=0</code>，语义是“我把 id=0、d=5 这一行的 c 值，改成了 5”。由于在 T1 时刻，session A 还只是给 id=5 这一行加了行锁， 并没有给 id=0 这行加上锁。因此，session B 在 T2 时刻，是可以执行这两条 update 语句的。这样，就<strong>破坏了 session A 里 Q1 语句要锁住所有 d=5 的行的加锁声明</strong>。session C 也是一样的道理，对 id=1 这一行的修改，也是破坏了 Q1 的加锁声明。</p><h4 id="破坏数据一致性"><a class="header-anchor" href="#破坏数据一致性">¶</a>破坏数据一致性</h4><p>其次，是数据一致性的问题。我们知道，锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。为了说明这个问题，再给 session A 在 T1 时刻再加一个更新语句，即：<code>update t set d=100 where d=5</code>。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132100.png" alt="假设只在 id=5 这一行加行锁--数据一致性问题"></p><p>update 的加锁语义和 <code>select …for update</code> 是一致的，所以这时候加上这条 update 语句也很合理。session A 声明说“要给 d=5 的语句加上锁”，就是为了要更新数据，新加的这条 update 语句就是把它认为加上了锁的这一行的 d 值修改成了 100。以下是执行过程分析：</p><ol><li>经过 T1 时刻，id=5 这一行变成 (5,5,100)，当然这个结果最终是在 T6 时刻正式提交的 ;</li><li>经过 T2 时刻，id=0 这一行变成 (0,5,5);</li><li>经过 T4 时刻，表里面多了一行 (1,5,5);</li><li>其他行跟这个执行序列无关，保持不变。</li></ol><p>这样看，这些数据也没啥问题，但是我们再来看看这时候 binlog 里面的内容。</p><ol><li>T2 时刻，session B 事务提交，写入了两条语句；</li><li>T4 时刻，session C 事务提交，写入了两条语句；</li><li>T6 时刻，session A 事务提交，写入了 <code>update t set d=100 where d=5</code> 这条语句。</li></ol><p>统一放到一起的话，就是这样的：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">update t set d=5 where id=0; /*(0,0,5)*/update t set c=5 where id=0; /*(0,5,5)*/insert into t values(1,1,5); /*(1,1,5)*/update t set c=5 where id=1; /*(1,5,5)*/update t set d=100 where d=5;/*所有d=5的行，d改成100*/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个语句序列，不论是拿到备库去执行，还是以后用 binlog 来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100) 和 (5,5,100)。也就是说，id=0 和 id=1 这两行和上面主库执行得到的 (0,5,5)、(1,5,5)，发生了数据不一致。这个问题很严重，是不行的。</p><h5 id="解决其它事务更新带来的不一致性问题"><a class="header-anchor" href="#解决其它事务更新带来的不一致性问题">¶</a>解决其它事务更新带来的不一致性问题</h5><p>我们分析一下可以知道，这是我们假设 <code>select * from t where d=5 for update</code> 这条语句只给 d=5 这一行，也就是 id=5 的这一行加锁”导致的。所以我们认为，上面的设定不合理，要改。那怎么改呢？我们把扫描主键索引的过程中碰到的行，也都加上写锁，再来看看执行效果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132106.png" alt="假设扫描到的行都被加上了行锁"></p><p>由于 session A 把所有的行都加了写锁，所以 session B 在执行第一个 update 语句的时候就被锁住了。需要等到 T6 时刻 session A 提交以后，session B 才能继续执行。这样对于 id=0 这一行，在数据库里的最终结果还是 (0,5,5)。在 binlog 里面，执行序列是这样的：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">insert into t values(1,1,5); /*(1,1,5)*/update t set c=5 where id=1; /*(1,5,5)*/update t set d=100 where d=5;/*所有d=5的行，d改成100*/update t set d=5 where id=0; /*(0,0,5)*/update t set c=5 where id=0; /*(0,5,5)*/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，按照日志顺序执行，id=0 这一行的最终结果也是 (0,5,5)。所以，id=0 这一行的问题解决了。</p><blockquote><p>到这里，可以看到 MySQL 针对条件子句 <code>where</code> 中无索引字段的更新直接残暴地对主键索引中所有行加锁（当然，如果 <code>order by</code> 子句中如果有满足条件的索引字段，就会在该字段中对所有行加锁），因为要被更新的行无法根据某个有序索引紧密地排列在一起从而可以进行简单地锁定，而是散乱地散步在各个索引中，所以只能对所有行加锁。</p></blockquote><p>但同时你也可以看到，id=1 这一行，在数据库里面的结果是 (1,5,5)，而根据 binlog 的执行结果是 (1,5,100)，也就是说幻读的问题还是没有解决。为什么我们已经这么“凶残”地，把所有的记录都上了锁，还是阻止不了 id=1 这一行的插入和更新呢？原因很简单。在 T3 时刻，我们给所有行加锁的时候，id=1 这一行还不存在，不存在也就加不上锁。也就是说，即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻读”会被单独拿出来解决的原因。</p><h5 id="解决幻读"><a class="header-anchor" href="#解决幻读">¶</a>解决幻读</h5><p>产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。顾名思义，间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132113.png" alt="表t主键索引上的行锁和间隙锁"></p><p>这样，当执行 <code>select * from t where d=5 for update</code> 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。所以，<strong>数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体</strong>。</p><h6 id="行锁和间隙锁的锁语义不同"><a class="header-anchor" href="#行锁和间隙锁的锁语义不同">¶</a>行锁和间隙锁的锁语义不同</h6><p>但是间隙锁跟我们之前碰到过的锁都不太一样。比如行锁，分成读锁和写锁。下图就是这两种类型行锁的冲突关系。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132118.png" alt="两种行锁间的冲突关系"></p><p>也就是说，跟行锁有冲突关系的是“另外一个行锁”。但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作(其实插入会申请插入意向锁，是它发生了冲突)。间隙锁之间都不存在冲突关系。这句话不太好理解，我给你举个例子：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132123.png" alt="间隙锁之间不互锁"></p><p>这里 session B 并不会被堵住。因为表 t 里并没有 c=7 这个记录，因此 session A 加的是间隙锁 (5,10)。而 session B 也是在这个间隙加的间隙锁。它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。</p><blockquote><p>以上的理解是，行锁的后续动作就是需要同步的临界代码区，所有相应操作的线程进入临界代码区之前需要加锁来保证后续临界代码的原子性，加锁动作的互斥关系由锁关系决定，互斥会导致加锁失败的线程阻塞；而对于间隙锁，它是专门针对 <code>insert</code> 和加行锁的互斥性而被创造出来的，在已有的行锁(锁的是一行，重要成员变量就一个，要锁定的行)的数据结构及语义无法满足该需求的情况下，只能创建一个间隙锁出来(锁的是一个区间，成员变量也是只有一个，间隙结束行，但时候由于间隙锁本身的特性，SQL 执行线程发现是间隙锁，就会根据它的间隙结束行找到间隙起始行，所以实际上它的成员变量应该有两个，只不过间隙起始行没有静态地存储下来，而是由执行线程自己动态计算的)，在加行锁之前，加间隙锁，然后 <code>insert</code> 动作要加 <code>insert intention lock</code> 插入意向锁，这个锁是会和间隙锁冲突的。</p></blockquote><h6 id="next-key-lock-v2"><a class="header-anchor" href="#next-key-lock-v2">¶</a>next-key lock</h6><p>间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 <code>select * from t for update</code> 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 <code>(-∞,0]</code>、<code>(0,5]</code>、<code>(5,10]</code>、<code>(10,15]</code>、<code>(15,20]</code>、<code>(20, 25]</code>、<code>(25, +supremum]</code>。</p><blockquote><p>备注：如果没有特别说明，把间隙锁记为开区间，把 next-key lock 记为前开后闭区间。</p></blockquote><p>这个 supremum 从哪儿来的呢？这是因为 +∞是开区间。实现上，InnoDB 给每个索引加了一个不存在的最大值 supremum，这样才符合我们前面说的“都是前开后闭区间”。</p><p>间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。有以下业务场景，任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据，代码如下：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据，代码如下：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">begin;select * from t where id=N for update;/*如果行不存在*/insert into t values(N,N,N);/*如果行存在*/update t set d=N set id=N;commit;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>这个不是 <code>insert … on duplicate key update</code> 就能解决吗？但其实在有多个唯一键的时候，这个方法是不能满足这个需求的。</p></blockquote><p>这个逻辑一旦有并发，就会碰到死锁。这个逻辑每次操作前用 <code>for update</code> 锁起来，已经是最严格的模式了，怎么还会有死锁呢？这里，用两个 session 来模拟并发，并假设 N=9。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132129.png" alt="间隙锁导致的死锁"></p><p>其实都不需要用到后面的 update 语句，就已经形成死锁了。我们按语句执行顺序来分析一下：</p><ol><li>session A 执行 <code>select … for update</code> 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10);</li><li>session B 执行 <code>select … for update</code> 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；</li><li>session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；</li><li>session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。</li></ol><p>至此，两个 session 进入互相等待状态，形成死锁。当然，InnoDB 的死锁检测马上就发现了这对死锁关系，让 session A 的 insert 语句报错返回了。<strong>间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。</strong></p><blockquote><p><code>innodb_locks_unsafe_for_binlog</code>设置为1标识不加 <code>gap lock</code>，已经要被废弃了，8.0就没有了，所以不建议设置。如果真要去掉 gap lock，可以考虑改用下面讲的 RC 隔离级别+binlog_format=row</p></blockquote><h3 id="读提交隔离模式"><a class="header-anchor" href="#读提交隔离模式">¶</a>读提交隔离模式</h3><p>以上分析的问题都是在可重复读隔离级别下的，<strong>间隙锁是在可重复读隔离级别下才会生效的。所以，如果把隔离级别设置为读提交的话，就没有间隙锁了</strong>。但同时，要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。这，也是现在不少公司使用的配置组合。</p><p>但是这个配置到底合不合理呢？关于这个问题本身的答案是，如果读提交隔离级别够用，也就是说，业务不需要可重复读的保证，这样考虑到读提交下操作数据的锁范围更小（没有间隙锁），这个选择是合理的。比如说，大家都用读提交，可是逻辑备份的时候，mysqldump 为什么要把备份线程设置成可重复读呢？然后，在备份期间，备份线程用的是可重复读，而业务线程用的是读提交。同时存在两种事务隔离级别，会不会有问题？进一步地，这两个不同的隔离级别现象有什么不一样的，关于我们的业务，“用读提交就够了”这个结论是怎么得到的？如果业务开发和运维团队这些问题都没有弄清楚，那么“没问题”这个结论，本身就是有问题的。</p><h2 id="加锁逻辑分析"><a class="header-anchor" href="#加锁逻辑分析">¶</a>加锁逻辑分析</h2><p>首先说明一下，这些加锁规则以下前提说明：MySQL 后面的版本可能会改变加锁策略，所以这个规则只限于截止到 5.x 系列 &lt;=5.7.24，8.0 系列 &lt;=8.0.13。</p><p>因为间隙锁在可重复读隔离级别下才有效，所以本篇文章接下来的描述，若没有特殊说明，默认是可重复读隔离级别。加锁规则包含了两个“原则”、两个“优化”和一个“bug”。</p><ol><li>原则 1：加锁的基本单位是 next-key lock。next-key lock 是前开后闭区间。</li><li>原则 2：查找过程中访问到的对象(某个字段的某行数据)才会加锁。</li><li>优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li><li>优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。</li><li>一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li></ol><h3 id="先导：例子-v2"><a class="header-anchor" href="#先导：例子-v2">¶</a>先导：例子</h3><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t` (  `id` int(11) NOT NULL,  `c` int(11) DEFAULT NULL,  `d` int(11) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="案例一：等值查询间隙锁"><a class="header-anchor" href="#案例一：等值查询间隙锁">¶</a>案例一：等值查询间隙锁</h3><p>第一个例子是关于等值条件操作间隙：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132139.png" alt="等值查询的间隙锁"></p><p>由于表 t 中没有 id=7 的记录，所以用我们上面提到的加锁规则判断一下的话：</p><ol><li>根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 <code>(5,10]</code>；</li><li>同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 <code>(5,10)</code>。</li></ol><p>所以，session B 要往这个间隙里面插入 id=8 的记录会被锁住，但是 session C 修改 id=10 这行是可以的。</p><h3 id="案例二：非唯一索引等值锁"><a class="header-anchor" href="#案例二：非唯一索引等值锁">¶</a>案例二：非唯一索引等值锁</h3><p>第二个例子是关于覆盖索引上的锁：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132146.png" alt="只加在非唯一索引上的锁"></p><p>看到这个例子，是不是有一种“该锁的不锁，不该锁的乱锁”的感觉？来分析一下吧。这里 session A 要给索引 c 上 c=5 的这一行加上读锁。</p><ol><li>根据原则 1，加锁单位是 next-key lock，因此会给 <code>(0,5]</code>加上 next-key lock。</li><li>要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 <code>(5,10]</code>加 next-key lock。</li><li>但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 <code>(5,10)</code>。</li><li>根据原则 2 ，只有访问到的对象(某个字段的某行)才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。</li></ol><p>但 session C 要插入一个 (7,7,7) 的记录，就会被 session A 的间隙锁 (5,10) 锁住。<strong>需要注意，在这个例子中，lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁</strong>。</p><p>这个例子说明，锁是加在索引上的；同时，它给我们的指导是，如果你要用 <code>lock in share mode</code> 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，<strong>在查询字段中加入索引中不存在的字段</strong>。比如，将 session A 的查询语句改成 <code>select d from t where c=5 lock in share mode</code> 。</p><h3 id="案例三：主键索引范围锁"><a class="header-anchor" href="#案例三：主键索引范围锁">¶</a>案例三：主键索引范围锁</h3><p>第三个例子是关于范围查询的。举例之前，你可以先思考一下这个问题：对于我们这个表 t，下面这两条查询语句，加锁范围相同吗？</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from t where id=10 for update;mysql> select * from t where id>=10 and id<11 for update;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>你可能会想，id 定义为 <code>int</code> 类型，这两个语句就是等价的吧？其实，它们并不完全等价。在逻辑上，这两条查语句肯定是等价的，但是它们的加锁规则不太一样。现在，我们就让 session A 执行第二个查询语句，来看看加锁效果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132153.png" alt="主键索引上范围查询的锁"></p><p>现在我们就用前面提到的加锁规则，来分析一下 session A 会加什么锁呢？</p><ol><li>开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock<code>(5,10]</code>。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。</li><li>范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock<code>(10,15]</code>。</li></ol><p>所以，session A 这时候锁的范围就是主键索引上，行锁 id=10 和 next-key lock<code>(10,15]</code>。这样，session B 和 session C 的结果你就能理解了。这里你需要注意一点，首次 session A 定位查找 id=10 的行的时候，是当做等值查询来判断的，而向右扫描到 id=15 的时候，用的是范围查询判断。</p><h3 id="案例四：非唯一索引范围锁"><a class="header-anchor" href="#案例四：非唯一索引范围锁">¶</a>案例四：非唯一索引范围锁</h3><p>接下来，我们再看两个范围查询加锁的例子，可以对照着案例三来看。需要注意的是，与案例三不同的是，案例四中查询语句的 where 部分用的是字段 c。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132200.png" alt="非唯一索引范围锁"></p><p>这次 session A 用字段 c 来判断，加锁规则跟案例三唯一的不同是：在第一次用 c=10 定位记录的时候，索引 c 上加了 <code>(5,10]</code>这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 <code>(5,10]</code> 和 <code>(10,15]</code> 这两个 next-key lock。</p><p>所以从结果上来看，sesson B 要插入（8,8,8) 的这个 insert 语句时就被堵住了。这里需要扫描到 c=15 才停止扫描，是合理的，因为 InnoDB 要扫到 c=15，才知道不需要继续往后找了。</p><h3 id="案例五：唯一索引范围锁-bug"><a class="header-anchor" href="#案例五：唯一索引范围锁-bug">¶</a>案例五：唯一索引范围锁 bug</h3><p>前面的四个案例，我们已经用到了加锁规则中的两个原则和两个优化，接下来再看一个关于加锁规则中 bug 的案例。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132207.png" alt="唯一索引范围锁的 bug"></p><p>session A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 <code>(10,15]</code>这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了。但是实现上，InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于这是个范围扫描，因此索引 id 上的 <code>(15,20]</code> 这个 next-key lock 也会被锁上。</p><p>所以，session B 要更新 id=20 这一行，是会被锁住的。同样地，session C 要插入 id=16 的一行，也会被锁住。</p><blockquote><p>丁大：照理说，这里锁住 id=20 这一行的行为，其实是没有必要的。因为扫描到 id=15，就可以确定不用往后再找了。但实现上还是这么做了，因此我认为这是个 bug。我也曾找社区的专家讨论过，官方 bug 系统上也有提到，但是并未被 verified。所以，认为这是 bug 这个事儿，也只能算我的一家之言，如果你有其他见解的话，也欢迎你提出来。</p></blockquote><h3 id="案例六：非唯一索引上存在-等值-的例子"><a class="header-anchor" href="#案例六：非唯一索引上存在-等值-的例子">¶</a>案例六：非唯一索引上存在&quot;等值&quot;的例子</h3><p>接下来的例子，是为了更好地说明“间隙”这个概念。这里，给表 t 插入一条新记录。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> insert into t values(30,10,30);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>新插入的这一行 c=10，也就是说现在表里有两个 c=10 的行。那么，这时候索引 c 上的间隙是什么状态了呢？要知道，由于非唯一索引上包含主键的值，所以是不可能存在“相同”的两行的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132213.png" alt="非唯一索引等值的例子"></p><p>可以看到，虽然有两个 c=10，但是它们的主键值 id 是不同的（分别是 10 和 30），因此这两个 c=10 的记录之间，也是有间隙的。图中画出了索引 c 上的主键 id。为了跟间隙锁的开区间形式进行区别，用 <code>(c=10,id=30)</code> 这样的形式来表示索引上的一行。</p><p>现在，我们来看一下案例六。</p><p>这次我们用 <code>delete</code> 语句来验证。注意，<code>delete</code> 语句加锁的逻辑，其实跟 <code>select ... for update</code> 是类似的，也就是在文章开始总结的两个“原则”、两个“优化”和一个“bug”。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132220.png" alt="delete 示例"></p><p>这时，session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里加的是 <code>(c=5,id=5)</code> 到 <code>(c=10,id=10)</code> 这个 next-key lock。然后，session A 向右查找，直到碰到 <code>(c=15,id=15)</code> 这一行，循环才结束。根据优化 2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 <code>(c=10,id=10)</code> 到 <code>(c=15,id=15)</code> 的间隙锁。也就是说，这个 <code>delete</code> 语句在索引 c 上的加锁范围，就是下图中蓝色区域覆盖的部分。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132225.png" alt="delete 加锁效果示例"></p><p>这个蓝色区域左右两边都是虚线，表示开区间，即 <code>(c=5,id=5)</code> 和 <code>(c=15,id=15)</code> 这两行上都没有锁。</p><h3 id="案例七：limit-语句加锁"><a class="header-anchor" href="#案例七：limit-语句加锁">¶</a>案例七：limit 语句加锁</h3><p>例子 6 也有一个对照案例，场景如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132231.png" alt="limit 语句加锁"></p><p>这个例子里，session A 的 <code>delete</code> 语句加了 limit 2。你知道表 t 里 c=10 的记录其实只有两条，因此加不加 limit 2，删除的效果都是一样的，但是加锁的效果却不同。可以看到，session B 的 <code>insert</code> 语句执行通过了，跟案例六的结果不同。这是因为，案例七里的 <code>delete</code> 语句明确加了 limit 2 的限制，因此在遍历到 <code>(c=10, id=30)</code> 这一行之后，满足条件的语句已经有两条，循环就结束了。因此，索引 c 上的加锁范围就变成了从 <code>(c=5,id=5)</code> 到 <code>(c=10,id=30)</code> 这个前开后闭区间，如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132237.png" alt="带 limit 2 的加锁效果"></p><p>可以看到，<code>(c=10,id=30)</code> 之后的这个间隙并没有在加锁范围里，因此 insert 语句插入 c=12 是可以执行成功的。</p><p>这个例子对我们实践的指导意义就是，<strong>在删除数据的时候尽量加 limit。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围</strong>。</p><h3 id="案例八：一个死锁的例子"><a class="header-anchor" href="#案例八：一个死锁的例子">¶</a>案例八：一个死锁的例子</h3><p>前面的例子中，我们在分析的时候，是按照 next-key lock 的逻辑来分析的，因为这样分析比较方便。最后我们再看一个案例，目的是说明：next-key lock 实际上是间隙锁和行锁加起来的结果。你一定会疑惑，这个概念不是一开始就说了吗？不要着急，我们先来看下面这个例子：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132245.png" alt="案例八的操作序列"></p><p>现在，我们按时间顺序来分析一下为什么是这样的结果。</p><ol><li>session A 启动事务后执行查询语句加 <code>lock in share mode</code>，在索引 c 上加了 next-key lock<code>(5,10]</code> 和间隙锁 <code>(10,15)</code>；</li><li>session B 的 <code>update</code> 语句也要在索引 c 上加 next-key lock<code>(5,10]</code> ，进入锁等待；</li><li>然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。</li></ol><p>你可能会问，session B 的 next-key lock 不是还没申请成功吗？其实是这样的，session B 的“加 next-key lock<code>(5,10]</code> ”操作，实际上分成了两步，先是加 <code>(5,10)</code> 的间隙锁，加锁成功；然后加 c=10 的行锁，这时候才被锁住的。也就是说，我们在分析加锁规则的时候可以用 next-key lock 来分析。但是要知道，<strong>具体执行的时候，是要分成间隙锁和行锁两段来执行的</strong>。</p><h3 id="案例九：索引倒序加锁"><a class="header-anchor" href="#案例九：索引倒序加锁">¶</a>案例九：索引倒序加锁</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132252.png" alt="事务进入锁等待状态"></p><p>实际上，这里 session B 和 session C 的 insert 语句都会进入锁等待状态。你可以试着分析一下，出现这种情况的原因是什么？在可重复读级别下，因为是按照索引 c 倒序，c 上面索引且 <code>where</code> 子句有条件筛选，所以该 SQL 会直接走 c 索引树避免排序。但是是反向搜索的(从大到小)：</p><ol><li>由于是 order by c desc，第一个要定位的是索引 c 上“最右边的”c=20 的行，所以会加上间隙锁 <code>(20,25)</code> 和 next-key lock <code>(15,20]</code>。</li><li>在索引 c 上向左遍历，要扫描到 c=10 才停下来，所以 next-key lock 会加到 <code>(5,10]</code>，这正是阻塞 session B 的 insert 语句的原因。</li><li>在扫描过程中，c=20、c=15、c=10 这三行都存在值，由于是 select *，所以会在主键 id 上加三个行锁。</li></ol><p>因此，session A 的 select 语句锁的范围就是：</p><ol><li>索引 c 上 (5, 25)；</li><li>主键索引上 id=15、20 两个行锁。</li></ol><h3 id="案例十：不等号条件里地等值查询"><a class="header-anchor" href="#案例十：不等号条件里地等值查询">¶</a>案例十：不等号条件里地等值查询</h3><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">begin;select * from t where id>9 and id<12 order by id desc for update;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这个语句的加锁范围是主键索引上的 <code>(0,5]</code>、<code>(5,10]</code>和 <code>(10, 15)</code>。也就是说，id=15 这一行，并没有被加上行锁。加锁单位是 next-key lock，都是前开后闭区间，但是这里用到了优化 2，即索引上的等值查询，向右遍历的时候 id=15 不满足条件，所以 next-key lock 退化为了间隙锁 <code>(10, 15)</code>。</p><ol><li>首先这个查询语句的语义是 <code>order by id desc</code>，要拿到满足条件的所有行，优化器必须先找到“第一个 id&lt;12 的值”。</li><li>这个过程是通过索引树的搜索过程得到的，在引擎内部，其实是要找到 id=12 的这个值，只是最终没找到，但找到了 <code>(10,15)</code> 这个间隙。</li><li>然后向左遍历，在遍历过程中，就不是等值查询了，会扫描到 id=5 这一行，所以会加一个 next-key lock <code>(0,5]</code>。</li></ol><p>也就是说，在执行过程中，无论查询 SQL 是通过大于小于号的范围查询还是等于号的等值查询，在 MySQL 内部通过树搜索的方式定位记录的时候，用的都是“等值查询”的方法，前者是等值查询范围边界，后者就是等值查询用户要查询的值。</p><h3 id="案例十一、等值查询的过程及死锁发生与检查"><a class="header-anchor" href="#案例十一、等值查询的过程及死锁发生与检查">¶</a>案例十一、等值查询的过程及死锁发生与检查</h3><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">begin;select id from t where c in(5,20,10) lock in share mode;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这条查询语句里用的是 in，我们先来看这条语句的 explain 结果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132302.png" alt="in 语句的 explain 结果"></p><p>可以看到，这条 in 语句使用了索引 c 并且 rows=3，说明这三个值都是通过 B+ 树搜索定位的。在查找 c=5 的时候，先锁住了 <code>(0,5]</code>。但是因为 c 不是唯一索引，为了确认还有没有别的记录 c=5，就要向右遍历，找到 c=10 才确认没有了，这个过程满足优化 2，所以加了间隙锁 <code>(5,10)</code>。同样的，执行 c=10 这个逻辑的时候，加锁的范围是 <code>(5,10]</code> 和 (10,15)；执行 c=20 这个逻辑的时候，加锁的范围是 <code>(15,20]</code> 和 <code>(20,25)</code>。通过这个分析，我们可以知道，这条语句在索引 c 上加的三个记录锁的顺序是：先加 c=5 的记录锁，再加 c=10 的记录锁，最后加 c=20 的记录锁。</p><h4 id="死锁-v2"><a class="header-anchor" href="#死锁-v2">¶</a>死锁</h4><p>如果同时有另外一个语句，是这么写的：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select id from t where c in(5,20,10) order by c desc for update;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>间隙锁是不互锁的，但是这两条语句都会在索引 c 上的 c=5、10、20 这三行记录上加记录锁。这里你需要注意一下，由于语句里面是 <code>order by c desc</code>， 这三个记录锁的加锁顺序，是先锁 c=20，然后 c=10，最后是 c=5。也就是说，这两条语句要加锁相同的资源，但是加锁顺序相反。当这两条语句并发执行的时候，就可能出现死锁。</p><h4 id="怎么看死锁？"><a class="header-anchor" href="#怎么看死锁？">¶</a>怎么看死锁？</h4><p>下图是在出现死锁后，执行 <code>show engine innodb status</code> 命令得到的部分输出。这个命令会输出很多信息，有一节 <code>LATESTDETECTED DEADLOCK</code>，就是记录的最后一次死锁信息。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132308.png" alt="死锁现场"></p><p>我们来看看这图中的几个关键信息。</p><ol><li>这个结果分成三部分：<ul><li>(1) TRANSACTION，是第一个事务的信息；</li><li>(2) TRANSACTION，是第二个事务的信息；</li><li>WE ROLL BACK TRANSACTION (1)，是最终的处理结果，表示回滚了第一个事务。</li></ul></li><li>第一个事务的信息中：<ul><li>WAITING FOR THIS LOCK TO BE GRANTED，表示的是这个事务在等待的锁信息；<ul><li><code>index c of table test.t</code>，说明在等的是表 t 的索引 c 上面的锁；</li><li>lock mode S waiting 表示这个语句要自己加一个读锁，当前的状态是等待中；<ul><li>lock_mode X waiting表示next-key lock；</li><li>lock_mode X locks rec but not gap是只有行锁；</li><li>locks gap before rec，就是只有间隙锁；</li></ul></li><li>Record lock 说明这是一个记录锁；</li><li>n_fields 2 表示这个记录是两列，也就是字段 c 和主键字段 id；</li><li>0: len 4; hex 0000000a; asc ;; 是第一个字段，也就是 c。值是十六进制 a，也就是 10；</li><li>1: len 4; hex 0000000a; asc ;; 是第二个字段，也就是主键 id，值也是 10；</li><li>这两行里面的 asc 表示的是，接下来要打印出值里面的“可打印字符”，但 10 不是可打印字符，因此就显示空格。</li></ul></li><li>第一个事务信息就只显示出了等锁的状态，在等待 <code>(c=10,id=10)</code> 这一行的锁。</li><li>既然出现死锁了，就表示这个事务也占有别的锁，但是没有显示出来。别着急，我们从第二个事务的信息中推导出来。</li></ul></li><li>第二个事务显示的信息要多一些：<ul><li>“HOLDS THE LOCK(S)”用来显示这个事务持有哪些锁；</li><li><code>index c of table test.t</code> 表示锁是在表 t 的索引 c 上；</li><li>hex 0000000a 和 hex 00000014 表示这个事务持有 c=10 和 c=20 这两个记录锁；</li><li>WAITING FOR THIS LOCK TO BE GRANTED，表示在等 (c=5,id=5) 这个记录锁。</li></ul></li></ol><p>从上面这些信息中，我们就知道：</p><ol><li>“lock in share mode”的这条语句，持有 c=5 的记录锁，在等 c=10 的锁；</li><li>“for update”这个语句，持有 c=20 和 c=10 的记录锁，在等 c=5 的记录锁。</li></ol><p>因此导致了死锁。这里，我们可以得到两个结论：</p><ol><li>由于锁是一个个加的，要避免死锁，对同一组资源，要按照尽量相同的顺序访问；</li><li>在发生死锁的时刻，for update 这条语句占有的资源更多，回滚成本更大，所以 InnoDB 选择了回滚成本更小的 lock in share mode 语句，来回滚。</li></ol><h3 id="案例十二、delete-导致锁范围变化以及查看锁等待"><a class="header-anchor" href="#案例十二、delete-导致锁范围变化以及查看锁等待">¶</a>案例十二、<code>delete</code> 导致锁范围变化以及查看锁等待</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132315.png" alt="delete 导致间隙变化"></p><p>可以看到，由于 session A 并没有锁住 c=10 这个记录，所以 session B 删除 id=10 这一行是可以的。但是之后，session B 再想 insert id=10 这一行回去就不行了。现在我们一起看一下此时 <code>show engine innodb status</code> 的结果，看看能不能给我们一些提示。锁信息是在这个命令输出结果的 TRANSACTIONS 这一节。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132321.png" alt="锁等待信息"></p><p>我们来看几个关键信息。</p><ol><li><code>index PRIMARY of table test.t</code> ，表示这个语句被锁住是因为表 t 主键上的某个锁。</li><li>lock_mode X locks gap before rec insert intention waiting 这里有几个信息：<ul><li>insert intention 表示当前线程准备插入一个记录，这是一个插入意向锁。为了便于理解，你可以认为它就是这个插入动作本身。</li><li>gap before rec 表示这是一个间隙锁，而不是记录锁。</li></ul></li><li>那么这个 gap 是在哪个记录之前的呢？接下来的 0~4 这 5 行的内容就是这个记录的信息。</li><li>n_fields 5 也表示了，这一个记录有 5 列：<ul><li>0: len 4; hex 0000000f; asc ;; 第一列是主键 id 字段，十六进制 f 就是 id=15。所以，这时我们就知道了，这个间隙就是 id=15 之前的，因为 id=10 已经不存在了，它表示的就是 <code>(5,15)</code>。</li><li>1: len 6; hex 000000000513; asc ;; 第二列是长度为 6 字节的事务 id，表示最后修改这一行的是 trx id 为 1299 的事务。</li><li>2: len 7; hex b0000001250134; asc % 4;; 第三列长度为 7 字节的回滚段信息。可以看到，这里的 acs 后面有显示内容 (% 和 4)，这是因为刚好这个字节是可打印字符。</li><li>后面两列是 c 和 d 的值，都是 15。</li></ul></li></ol><p>因此，可以得出由于 <code>delete</code> 操作把 id=10 这一行删掉了，原来的两个间隙 <code>(5,10)</code>、<code>(10,15)</code>变成了一个 <code>(5,15)</code>。</p><p>说到这里，可以联合起来再思考一下这两个现象之间的关联：</p><ol><li>session A 执行完 select 语句后，什么都没做，但它加锁的范围突然“变大”了；</li><li>当我们执行 <code>select * from t where c&gt;=15 and c&lt;=20 order by c desc lock in share mode;</code> 向左扫描到 c=10 的时候，要把 <code>(5, 10]</code>锁起来。</li></ol><p>也就是说，所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的（在这里看起来，间隙锁貌似又不像是拥有左边界和右边界两个属性，其实就是只有一个属性，就是右边界，左边界相当于是一个虚的概念，由 SQL 执行线程在其扫描索引树的过程自己根据存在的间隙锁的右边界计算出来）。</p><blockquote><p>即使是空表也是有间隙的，因为每个索引都会计算出一个最大值 supremum 作为右边界。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132328.png" alt="复现空表的 next-key lock"></p><p>session A 这个查询语句加锁的范围就是 next-key lock (-∞, supremum]。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132334.png" alt="show engine innodb status 部分结果"></p></blockquote><h3 id="案例十三、update导致锁范围变化"><a class="header-anchor" href="#案例十三、update导致锁范围变化">¶</a>案例十三、<code>update</code>导致锁范围变化</h3><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132339.png" alt="update 的例子"></p><p>session A 的加锁范围是索引 c 上的 <code>(5,10]</code>、<code>(10,15]</code>、<code>(15,20]</code>、<code>(20,25]</code>和 <code>(25,supremum]</code>。</p><blockquote><p>注意：根据 c&gt;5 查到的第一个记录是 c=10，因此不会加 <code>(0,5]</code>这个 next-key lock。</p></blockquote><p>之后 session B 的第一个 update 语句，要把 c=5 改成 c=1，可以理解为两步：</p><ol><li>插入 (c=1, id=5) 这个记录；</li><li>删除 (c=5, id=5) 这个记录。</li></ol><p>索引 c 上 (5,10) 间隙是由这个间隙右边的记录，也就是 c=10 定义的。所以通过这个操作，session A 的加锁范围变成了下图所示的样子：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132347.png" alt="session B 修改后， session A 的加锁范围"></p><p>好，接下来 session B 要执行 <code>update t set c = 5 where c = 1</code> 这个语句了，一样地可以拆成两步：</p><ol><li>插入 (c=5, id=5) 这个记录；</li><li>删除 (c=1, id=5) 这个记录。</li></ol><p>第一步试图在已经加了间隙锁的 <code>(1,10)</code> 中插入数据，所以就被堵住了。</p><h2 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h2><p>上面的所有案例都是在可重复读隔离级别 (repeatable-read) 下验证的。同时，可重复读隔离级别遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的时候才释放的。</p><p>其实加锁动作是随着原本的行扫描动作而发生的，行扫描有两种方式，一种是逐行扫描(也就是我们常说的全表扫描)，另一种是根据索引树同层节点的有序性进行树搜索。所以：</p><ul><li>如果 <code>where</code> 条件子句中的条件字段都没有索引，那么检索方式就是在主键索引进行全表扫描，此时扫描的每一行都会被按照以上案例逻辑进行加锁，这样的逻辑是对的，因为此时已经无法保证条件子句中的条件字段在索引中是有序的了，匹配条件的数据行无规则散落在各个 page，无法按照某个规律加锁来减小锁的粒度，所以只能全表加锁，即在逐行扫描全表的过程中对每一行加锁。</li><li><code>insert</code> 操作会对 <code>insert</code> 成功之后的该行加行锁、<code>update</code> 和 <code>delete</code> 都会被加 next-key lock 。<code>update</code> 对于二级索引来说可以算是先删除后插入。</li><li><code>where</code> 条件子句中所有的条件字段以及 <code>set</code> 子句中等号<code>=</code>右边的字段都是要读取的字段，即这些字段都会被扫描。如果 <code>where</code> 子句中所有条件字段都没有索引，就会变成主键索引全表扫描，如果存在 <code>order</code> 子句且排序字段存在索引，在满足一定条件下，会扫描该字段的索引，那么无论是扫描哪个索引都会在其上对扫描地每一行加锁；如果有索引就会选择一个最优索引进行索引树检索和加锁、如果该字段不是主键字段，而加的行锁是 X 锁，会相应地对主键索引中该行加 X 行锁，<code>lock in share mode</code> 就不会这样；</li></ul><p>在案例八中，可以清楚地知道 next-key lock 实际上是由间隙锁加行锁实现的。如果切换到读提交隔离级别 (read-committed) 的话，就好理解了，过程中去掉间隙锁的部分，也就是只剩下行锁的部分。其实读提交隔离级别在外键场景下还是有间隙锁，相对比较复杂。<strong>另外，在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交</strong>。也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因。</p><h1>七、MVCC 隔离性和锁的原理</h1><p>如果是可重复读隔离级别，事务 T 启动的时候会创建一个视图 read-view，之后事务 T 执行期间，即使有其他事务修改了数据，事务 T 看到的仍然跟在启动时看到的一样。也就是说，一个在可重复读隔离级别下执行的事务，好像与世无争，不受外界影响；但是一个事务要更新一行，如果刚好有另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。问题是，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？肯定是要读到该数据的最新值，不然锁的意义何在，但是这又和前面的隔离性<strong>貌似</strong>产生了矛盾，所以要看下 MySQL 的 MVCC 下隔离性到底是如何实现的，它提供的语义是怎样的。</p><h2 id="先导：一个并发更新示例"><a class="header-anchor" href="#先导：一个并发更新示例">¶</a>先导：一个并发更新示例</h2><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> CREATE TABLE `t` (  `id` int(11) NOT NULL,  `k` int(11) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(id, k) values(1,1),(2,2);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132356.png" alt="事务A、B、C的执行流程"></p><p>这里，我们需要注意的是事务的启动时机。</p><p><code>begin</code>/<code>start transaction</code> 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 <code>start transaction with consistent snapshot</code> 这个命令。</p><blockquote><p>使用<code>begin</code>，一致性视图是在执行第一个快照读语句时创建的；</p><p>使用<code>start transaction</code>，一致性视图是在执行 <code>start transaction with consistent snapshot</code> 时创建的。</p></blockquote><p>事务 C 没有显式地使用 <code>begin</code>/<code>commit</code>，表示这个 <code>update</code> 语句本身就是一个事务，语句完成的时候会自动提交。事务 B 在更新了行之后查询 ; 事务 A 在一个只读事务中查询，并且时间顺序上是在事务 B 的查询之后。</p><p>以上执行结果事务 B 查到的 k 值是 3，而事务 A 查到的 k 值是1。</p><h2 id="快照在-MVCC-里是怎么工作的"><a class="header-anchor" href="#快照在-MVCC-里是怎么工作的">¶</a>快照在 MVCC 里是怎么工作的</h2><p>在 MySQL 里，有两个&quot;视图&quot;的概念：</p><ul><li>一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 <code>create view …</code> ，而它的查询方法与表一样。</li><li>另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。<strong>它没有独立的物理结构</strong>，作用是事务执行期间用来定义“我能看到什么数据”。</li></ul><p>在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，<strong>这个快照是基于整库的</strong>。如果一个库有 100G，实际上，并不需要拷贝一份这 100G 的数据作为副本，所以呼应了这个视图是<strong>没有独立的物理结构的</strong>。</p><h3 id="版本-的数据结构"><a class="header-anchor" href="#版本-的数据结构">¶</a>&quot;版本&quot;的数据结构</h3><p>InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的（<strong>只读事务分配的是随机ID</strong>，因为只读事务不会产生新的数据版本，不会被加入到按照事务 ID 排序工作的read view中）。<strong>而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本(每个事务会申请空间基于 read view 中待更新行的当前版本拷贝一份副本到该空间中进行修改，当然这个事务后续可以是待提交、提交、回滚等状态的，而一个提交状态的事务产生的数据版本才会被 read view 采纳)</strong>，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 <code>row trx_id</code>。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 <code>row trx_id</code>。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132406.png" alt="行状态变更图"></p><p>图中虚线框里是同一行数据的 4 个版本，当前最新版本是 V4，k 的值是 22，它是被 transaction id 为 25 的事务更新的，因此它的 <code>row trx_id</code> 也是 25。所谓 undo log 就是图中的三个虚线剪头 U1、U2、U3 , <strong>它们是代表着一个实际的数据结构，而 V1、V2、V3 并不是物理上真实存在的</strong>，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 的时候，就是通过 V4 依次执行 U3、U2 算出来（所以在聚簇索引中存储的都是最新版本的数据，在查询的时候根据下面的隔离性算法进行实际的版本计算）。undo Log 记录了每个对应版本对应行数据的值。 undo Log 中分为两种类型:</p><ol><li>INSERT_UNDO（INSERT操作），记录插入的唯一键值；</li><li>UPDATE_UNDO（包含UPDATE及DELETE操作），记录修改的唯一键值以及old column记录。</li></ol><h3 id="基于-多版本-数据结构实现隔离性的算法"><a class="header-anchor" href="#基于-多版本-数据结构实现隔离性的算法">¶</a>基于&quot;多版本&quot;数据结构实现隔离性的算法</h3><p>以下来分析 InnoDB 定义那个“100G”的快照的算法。</p><p>按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。因此，一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。当然，如果“上一个版本”也不可见，那就得继续往前找。还有，如果是这个事务自己更新的数据，它自己还是要认的。</p><p>在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132414.png" alt="数据版本可见性规则"></p><p>这个视图数组把所有的 <code>row trx_id</code> 分成了几种不同的情况，这不同的情况就决定了 <code>row</code> 的可见性：</p><ol><li><p>如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</p></li><li><p>如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；</p></li><li><p>如果落在黄色部分，那就包括两种情况</p><ol><li><p>若 <code>row trx_id</code> 在数组中，表示这个版本是由还没提交的事务生成的，不可见；</p></li><li><p>若 <code>row trx_id</code> 不在数组中，表示这个版本是已经提交了的事务生成的，可见。</p><blockquote><p>为什么存在落在黄色部分但是不在数组中的 <code>row trx_id</code>呢？黄色部分就是 read view 数组，即当前事务创建之初已经创建但是未提交的其它数组，但是其实可能存在一些事务也已经创建了并且提交了的。这些事务或许是晚启动的，只不过是一个短事务，比一些早启动的长事务还要早提交了。</p></blockquote></li></ol></li></ol><blockquote><p>对于一个事务视图来说，某个数据版本的可见性还可以这样定义：</p><p>除了自己的更新总是可见以外，有三种情况：</p><ul><li><p>版本未提交，不可见；</p></li><li><p>版本已提交，但是是在视图创建后提交的，不可见；</p></li><li><p>版本已提交，而且是在视图创建前提交的，可见。</p></li></ul></blockquote><p>系统里面随后发生的更新，就跟这个事务看到的内容无关了。因为之后的更新，生成的版本一定属于上面的 2 或者 3.1 的情况，而对它来说，这些新的数据版本是不存在的，所以这个事务的快照，就是“静态”的了。</p><p>所以 MySQL 在一个事务中进行一致性查询的时候，当查询到某行数据，就会从它的最新数据的 <code>row trx_id</code> 开始匹配，如果匹配结果一直不可见就<strong>一直沿着 undo log 往前计算旧版本(旧版本不一定比新版本的事务 ID 小，例如提到的晚创建但是早提交的短事务)</strong>，直到匹配为止，在 <a href="##%E5%9B%9E%E6%BB%9A%E6%AE%B5%E7%9A%84%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E5%8F%8A%E9%95%BF%E4%BA%8B%E5%8A%A1%E5%B8%A6%E6%9D%A5%E7%9A%84%E5%BD%B1%E5%93%8D%5B%5E3.1%5D">关于回滚段的删除策略</a> 中提到，当数据库中不存在比 undo log 更早的 read view 的时候就可以删除该 undo log 了，就是和 read view 的创建特性有关。</p><p>InnoDB 利用了以上“多版本”数据结构和算法，实现了“秒级创建快照”的能力，其实创建快照的动作以及消耗延迟均摊到了事务中各个实际操作上，而不是在创建事务之初就拷贝一份副本。</p><h2 id="结合先导例子和-MVCC-实现分析一致性读"><a class="header-anchor" href="#结合先导例子和-MVCC-实现分析一致性读">¶</a>结合先导例子和 MVCC 实现分析一致性读</h2><p>这里，我们不妨做如下假设：</p><ol><li>事务 A 开始前，系统里面只有一个活跃事务 ID 是 99；</li><li>事务 A、B、C 的版本号分别是 100、101、102，且当前系统里只有这四个事务；</li><li>三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。</li></ol><p>这样，事务 A 的视图数组就是[99,100], 事务 B 的视图数组是[99,100,101], 事务 C 的视图数组是[99,100,101,102]。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132421.png" alt="事务 A 查询数据逻辑图"></p><p>从图中可以看到，第一个有效更新是事务 C，把数据从 (1,1) 改成了 (1,2)。这时候，这个数据的最新版本的 <code>row trx_id</code> 是 102，而 90 这个版本已经成为了历史版本。第二个有效更新是事务 B，把数据从 (1,2) 改成了 (1,3)。这时候，这个数据的最新版本（即 <code>row trx_id</code>）是 101，而 102 又成为了历史版本。当事务 A 查询的时候，其实事务 B 还没有提交，但是事务 B 生成的 (1,3) 这个版本已经变成当前(最新)版本了。但这个版本对事务 A 必须是不可见的，否则就变成脏读了。</p><p>好，现在事务 A 要来读数据了，它的视图数组是[99,100]。当然了，读数据都是从当前(最新)版本读起的。所以，事务 A 查询语句的读数据流程是这样的：</p><ul><li>找到 (1,3) 的时候，判断出 <code>row trx_id</code>=101，比高水位大，处于红色区域，不可见；</li><li>接着，找到上一个历史版本，一看 <code>row trx_id</code>=102，比高水位大，处于红色区域，不可见；</li><li>再往前找，终于找到了（1,1)，它的 <code>row trx_id</code>=90，比低水位小，处于绿色区域，可见。</li></ul><p>这样执行下来，虽然期间这一行数据被修改过，但是事务 A 不论在什么时候查询，看到这行数据的结果都是一致的，所以我们<strong>称之为一致性读</strong>。</p><blockquote><p>另外，我们还能用另外一种语言来描述它们的可见性：</p><p>事务 A 的查询语句的视图数组是在事务 A 启动的时候生成的，这时候：</p><ul><li>(1,3) 还没提交，属于情况 1，不可见；</li><li>(1,2) 虽然提交了，但是是在视图数组创建之后提交的，属于情况 2，不可见；</li><li>(1,1) 是在视图数组创建之前提交的，可见。</li></ul></blockquote><h2 id="结合先导例子和-MVCC-实现以及行锁分析更新逻辑"><a class="header-anchor" href="#结合先导例子和-MVCC-实现以及行锁分析更新逻辑">¶</a>结合先导例子和 MVCC 实现以及行锁分析更新逻辑</h2><p>以上一致性读的分析过程中，<strong>事务 B 的 update 语句，如果按照一致性读，结果是不对的</strong>，因为它读到的是最新版本的数据，而该数据不在事务 B 的 read view 中。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132429.png" alt="事务 B 更新逻辑图"></p><p>上图中，事务 B 的视图数组是先生成的，之后事务 C 才提交，不是应该看不见 (1,2) 吗，怎么能算出 (1,3) 来？确实如此，<strong>如果事务 B 在更新之前查询一次数据，这个查询返回的 k 的值确实是 1</strong>。<strong>但是，当它要去更新数据的时候，就不能再在历史版本上更新了，否则事务 C 的更新就丢失了（这就是 MySQL 给出的 MVCC 语义，读是一致性读，但是更新要基于最新版本数据进行更新）</strong>。因此，事务 B 此时的 <code>set k=k+1</code> 是在（1,2）的基础上进行的操作。</p><p>所以，这里就用到了这样一条规则：<strong>更新数据(指的就是某一句 update 语句，而不是 select 语句)都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）</strong>。因此，在更新的时候，当前读拿到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，同时新版本的 row trx_id 是 101。所以，在事务 B 在更新完毕之后执行到查询语句，一看自己的版本号是 101，最新数据的版本号也是 101，是自己的更新，可以直接使用，所以查询得到的 k 的值是 3。</p><blockquote><p>所有更新语句如果需要读取数据再更新，例如<code>update t set k = k+1</code>，会在第一步读取数据的时候就会加上 X 锁。相当于下面的<code>select ... for update</code>。</p></blockquote><p>其实，除了 <code>update</code> 语句外，<code>select</code> 语句如果加锁，也是当前读。所以，如果把事务 A 的查询语句 <code>select * from t where id=1</code> 修改一下，加上 <code>lock in share mode</code> 或 <code>for update</code>，也都可以读到版本号是 101 的数据，返回的 k 的值是 3。下面这两个 select 语句，就是分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select k from t where id=1 lock in share mode;mysql> select k from t where id=1 for update;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>再往前一步，假设事务 C 不是马上提交的，而是变成了下面的事务 C’，会怎么样呢？</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132437.png" alt="事务 A、B、C'的执行流程"></p><p>事务 C’的不同是，更新后并没有马上提交，在它提交前，事务 B 的更新语句先发起了。前面说过了，虽然事务 C’还没提交，但是 (1,2) 这个版本也已经生成了，并且是当前的最新版本。那么，事务 B 的更新语句会怎么处理呢？</p><p>这时候，“两阶段锁协议”就要上场了。事务 C’没提交，也就是说 (1,2) 这个版本上的写锁还没释放。而事务 B 是当前读，必须要读最新版本，而且必须加锁，因此就被阻塞了，必须等到事务 C’释放这个锁，才能完成它的加锁进行当前读。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132444.png" alt="事务 B 更新逻辑图（配合事务 C'）"></p><h2 id="总结：事务的可重复读能力"><a class="header-anchor" href="#总结：事务的可重复读能力">¶</a>总结：事务的可重复读能力</h2><p>可重复读的核心就是一致性读（consistent read）；</p><ul><li>默认的 <code>select</code> 语句执行的就是<strong>一致性读</strong>，基于 read view + 多版本数据，不加锁。</li><li>而 <code>update</code> 语句中涉及的读操作都是<strong>当前读</strong>，加 X 锁（<code>update</code> 本身就要加 X 锁）。</li><li>在 <code>select</code> 语句后面加 <code>lock in share mode</code> 或者 <code>for update</code> 都是当前读，前者加 S 锁，后者加 X 锁。</li><li>锁都是锁在最新版本数据。</li></ul><p>所以即使是 MVCC 下：</p><ul><li>如果当前事务需要对某行数据做更新操作，但是已经存在其它事务对该行进行了当前读或者更新操作且未提交，当前事务就需要进入锁等待。</li><li>如果当前事务需要对某行数据做当前读操作，但是已经存在其它事务对该行进行了更新操作且未提交，当前事务也需要进入锁等待。</li></ul><h2 id="读已提交的分析"><a class="header-anchor" href="#读已提交的分析">¶</a>读已提交的分析</h2><p>读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：</p><ul><li>在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；</li><li>在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。</li></ul><p><strong>所以它们的区别主要就是在一致性读，对于当前读、加锁、更新逻辑它们是完全一致。</strong></p><p>下面分析在读提交隔离级别下，事务 A 和事务 B 的查询语句查到的 k，分别应该是多少呢？</p><blockquote><p>这里需要说明一下，“start transaction with consistent snapshot; ”的意思是从这个语句开始，创建一个持续整个事务的一致性快照。所以，在读提交隔离级别下，这个用法就没意义了，等效于普通的 begin。</p></blockquote><p>下面是读提交时的状态图，可以看到这两个查询语句的创建视图数组的时机发生了变化，就是图中的 read view 框。（注意：这里，我们用的还是事务 C 的逻辑直接提交，而不是事务 C’）</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132452.jpg" alt="读提交隔离级别下的事务状态图"></p><p>这时，事务 A 的查询语句的视图数组是在执行这个语句的时候创建的，时序上 (1,2)、(1,3) 的生成时间都在创建这个视图数组的时刻之前。但是，在这个时刻：</p><ul><li>(1,3) 还没提交，属于情况 1，不可见；</li><li>(1,2) 提交了，属于情况 3，可见。</li></ul><p>所以，这时候事务 A 查询语句返回的是 k=2。显然地，事务 B 查询结果 k=3。</p><h2 id="表结构没有MVCC"><a class="header-anchor" href="#表结构没有MVCC">¶</a>表结构没有MVCC</h2><p>表结构目前没有多版本控制，都是通过 MDL 控制的，即使是一个 RR 事务在表被删除之前启动了，如果这个事务没有产生读写表操作，那么另一个事务删除表就不会被 MDL 阻塞，删除表之后(即使是还没提交)，前一个事务就看到表被删除了，而不是和启动事务时一致，表还存在（<strong>此外 DDL 含有一个隐式提交事务，所以即使专门手动开启了一个事务，执行一个 DDL 不手动提交，MySQL 都会对这个 DDL 进行提交，保证其它事务立马能看到这个修改</strong>）。</p><blockquote><p>据说 MySQL 目前有这方面支持的打算，可能在不久的未来就支持了。</p></blockquote><h2 id="为何条件匹配却无法更新数据"><a class="header-anchor" href="#为何条件匹配却无法更新数据">¶</a>为何条件匹配却无法更新数据</h2><p>下面的表结构和初始化语句作为试验环境，事务隔离级别是可重复读。现在，我要把所有“字段 c 和 id 值相等的行”的 c 值清零，但是却发现了一个“诡异”的、改不掉的情况。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> CREATE TABLE `t` (  `id` int(11) NOT NULL,  `c` int(11) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(id, c) values(1,1),(2,2),(3,3),(4,4);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> begin;Query OK, 0 rows affected (0.00 sec)mysql> select * from t;+----+------+| id | c    |+----+------+|  1 |    1 ||  2 |    2 ||  3 |    3 ||  4 |    4 |+----+------+4 rows in set (0.00 sec)mysql> update t set c = 0 where id=c;Query OK, 0 rows affected (11.41 sec)Rows matched: 0  Changed: 0  Warnings: 0mysql> select * from t;+----+------+| id | c    |+----+------+|  1 |    1 ||  2 |    2 ||  3 |    3 ||  4 |    4 |+----+------+4 rows in set (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这是因为：</p><ol><li><p>在 RR 隔离级别下，<code>begin</code> 手动开启事务之后，第一个 <code>select</code> 触发了事务创建。</p></li><li><p>此时存在另外一个事务先执行了 <code>update t set c = 0 where id=c;</code> 操作并提交事务。</p></li><li><p>然后当前事务再执行 <code>update t set c = 0 where id=c;</code> 的时候，是基于当前读获取到了另一个已经提交事务(如果该事务没有提交当前语句会被阻塞)的更新，所以条件已经不匹配了，故更新行数为0。</p></li><li><p>最后当前事务再次执行 <code>select</code> 的时候，此时是一致性读，还是保持的创建事务之初的 read view。所以读取到的还是老版本数据，出现了无法更新的诡异现象。</p></li></ol><p>这种情形多数出现在业务层面使用乐观锁控制并发的场景下，例如使用一个专门的版本控制字段<code>version</code>放在更新语句后面，如：<code>where condition = xxx and version = xxx</code>，然后根据执行之后返回的<code>affected rows</code>与预期是否一致判断更新是否执行成功，这样就可以实现一个乐观控制了。</p><p>至于执行失败之后是要轮询重试；还是在一开始就在事务中对所有影响到更新操作计算的查询使用当前读加 S 锁，还是要看具体情况。前者不断起事务训轮重试，如果并发量高，负担高；后者对参与更新操作条件计算的查询都加 S 锁会阻塞其它对于查询行的更新，具体要看写操作频繁与否以及要加 S 锁的查询多不多。</p><h2 id="MVCC下写丢失的一个例子"><a class="header-anchor" href="#MVCC下写丢失的一个例子">¶</a>MVCC下写丢失的一个例子</h2><h3 id="问题-v2"><a class="header-anchor" href="#问题-v2">¶</a>问题</h3><p>业务上有这样的需求，A、B 两个用户，如果互相关注，则成为好友。设计上是有两张表，一个是 <code>like</code> 表，一个是 <code>friend</code> 表，<code>like</code> 表有 <code>user_id</code>、<code>liker_id</code> 两个字段，我设置为复合唯一索引即 <code>uk_user_id_liker_id</code>。语句执行逻辑是这样的：</p><p>以 A 关注 B 为例：</p><p>第一步，先查询对方有没有关注自己（B 有没有关注 A）<code>select * from like where user_id = B and liker_id = A;</code></p><ul><li>如果有，则成为好友<code>insert into friend;</code></li><li>没有，则只是单向关注关系<code>insert into like;</code></li><li>但是如果 A、B 同时关注对方，会出现不会成为好友的情况。因为上面第 1 步，双方都没关注对方。第 1 步即使使用了排他锁也不行，因为记录不存在，行锁无法生效。请问这种情况，在 MySQL 锁层面有没有办法处理？（实际上之前都是在应用层代码加锁或者CAS保证的）</li></ul><p>以下是表结构：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `like` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `user_id` int(11) NOT NULL,  `liker_id` int(11) NOT NULL,  PRIMARY KEY (`id`),  UNIQUE KEY `uk_user_id_liker_id` (`user_id`,`liker_id`)) ENGINE=InnoDB;CREATE TABLE `friend` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `friend_1_id` int(11) NOT NULL,  `friend_2_id` int(11) NOT NULL,  UNIQUE KEY `uk_friend` (`friend_1_id`,`friend_2_id`),  PRIMARY KEY (`id`)) ENGINE=InnoDB;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在并发场景下，同时有两个人，设置为关注对方，就可能导致无法成功加为朋友关系：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132509.png" alt="并发逻辑操作顺序"></p><p>由于一开始 A 和 B 之间没有关注关系，所以两个事务里面的 select 语句查出来的结果都是空。因此，session 1 的逻辑就是“既然 B 没有关注 A，那就只插入一个单向关注关系”。session 2 也同样是这个逻辑。这个结果对业务来说就是 bug 了。因为在业务设定里面，这两个逻辑都执行完成以后，是应该在 friend 表里面插入一行记录的。</p><h3 id="方案"><a class="header-anchor" href="#方案">¶</a>方案</h3><p>首先，要给“like”表增加一个字段，比如叫作 <code>relation_ship</code>，并设为整型，取值 1、2、3。</p><ul><li>值是 1 的时候，表示 user_id 关注 liker_id;</li><li>值是 2 的时候，表示 liker_id 关注 user_id;</li><li>值是 3 的时候，表示互相关注。</li></ul><p>然后，当 A 关注 B 的时候，应用代码里面，比较 A 和 B 的大小</p><ul><li><p>如果 A &lt; B</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> begin; /*启动事务*/insert into `like`(user_id, liker_id, relation_ship) values(A, B, 1) on duplicate key update relation_ship=relation_ship | 1;select relation_ship from `like` where user_id=A and liker_id=B;/*代码中判断返回的 relation_ship，  如果是1，事务结束，执行 commit  如果是3，则执行下面这两个语句：  */insert ignore into friend(friend_1_id, friend_2_id) values(A,B);commit;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>如果 A &gt; B</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> begin; /*启动事务*/insert into `like`(user_id, liker_id, relation_ship) values(B, A, 2) on duplicate key update relation_ship=relation_ship | 2;select relation_ship from `like` where user_id=B and liker_id=A;/*代码中判断返回的 relation_ship，  如果是2，事务结束，执行 commit  如果是3，则执行下面这两个语句：*/insert ignore into friend(friend_1_id, friend_2_id) values(B,A);commit;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><p>这个设计里，让<code>like</code>表里的数据保证 <code>user_id</code> &lt; <code>liker_id</code>，这样不论是 A 关注 B，还是 B 关注 A，在操作<code>like</code>表的时候，如果反向的关系已经存在，就会出现行锁冲突。然后，<code>insert … on duplicate</code> 语句，确保了在事务内部，执行了这个 SQL 语句后，就强行占住了这个行锁，之后的 <code>select</code> 判断 <code>relation_ship</code> 这个逻辑时就确保了是在行锁保护下的读操作。</p><p>操作符 “|” 是按位或，连同最后一句 insert 语句里的 ignore，是为了保证重复调用时的幂等性。这样，即使在双方“同时”执行关注操作，最终数据库里的结果，也是 <code>like</code> 表里面有一条关于 A 和 B 的记录，而且 <code>relation_ship</code> 的值是 3， 并且 <code>friend</code> 表里面也有了 A 和 B 的这条记录。</p><blockquote><p>这里的按位或操作很巧妙，1|2 == 2|1 == 3|1 == 3|2 == 3、1|1 == 1、2|2 == 2</p></blockquote><blockquote><ol><li><code>insert ... on duplicate key update</code>语法：对于表中的所有唯一索引(包含主键索引)来说，如果当前插入行和表中某行重复了，则执行后面的更新语句：<ul><li>单行插入用法：<code>INSERT INTO t1 (a,b,c) VALUES (1,2,3)  ON DUPLICATE KEY UPDATE c=c+1;</code></li><li>多行插入用法：<code>INSERT INTO t1 (a,b,c) VALUES (1,2,3),(4,5,6) ON DUPLICATE KEY UPDATE c=VALUES(c);</code></li></ul></li><li><code>insert ignore</code>语法：对于表中的所有唯一索引(包含主键索引)来说，如果当前插入行和表中某行重复了则不执行该 <code>insert</code>，不会报错。<ul><li><code>insert into</code> 检查条件一样，不一样的是出现重复则会报错</li><li><code>replace into</code> 检查条件也一样，不一样的是出现重复会覆盖(删除原有插入当前)、不存在则<code>insert into</code>。</li></ul></li></ol></blockquote><p>这里使用两个唯一索引，不是说不建议使用吗？不建议使用指的是在“业务开发保证不会插入重复记录”的情况下，着重要解决性能问题的时候，才建议尽量使用普通索引。而像这个例子里，按照这个设计，业务根本就是保证“我一定会插入重复数据，数据库一定要要有唯一性约束”，这时就没啥好说的了，唯一索引建起来吧。</p><h1>八、普通索引和唯一索引</h1><ol><li><p>如果确定某个数据列只包含彼此各不相同的值，在为这个数据列创建索引的时候，就应该用关键字<code>UNIQUE</code>把它定义为一个唯一索引， MySQL 会在有新纪录插入数据表时，自动检查新纪录的这个字段的值是否已经在某个记录的这个字段里出现过了。如果是，MySQL 将拒绝插入那条新纪录。也就是说，唯一索引可以保证数据记录的唯一性。</p></li><li><p>此外，对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。而对于普通索引来说，查找到满足条件的第一个记录后，需要查找下一个记录，直到碰到第一个不满足条件的记录。</p></li></ol><p>事实上，在许多场合，人们创建唯一索引的目的往往不是为了提高访问速度，而只是为了避免数据出现重复。</p><p>假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号。如果市民系统需要按照身份证号查姓名，就会执行类似这样的 SQL 语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select name from cuser where id_card = 'xxxxxxxyyyyyyzzzzz';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>所以，一定会考虑在 <code>id_card</code> 字段上建索引。由于身份证号字段比较大，建议把身份证号当做主键，那么现在有两个选择，要么给 <code>id_card</code> 字段创建唯一索引，要么创建一个普通索引。如果业务代码已经保证了不会写入重复的身份证号，那么这两个选择逻辑上都是正确的。此时再从性能的角度考虑，选择唯一索引还是普通索引呢？选择的依据是什么呢？</p><h2 id="先导：示例"><a class="header-anchor" href="#先导：示例">¶</a>先导：示例</h2><p>假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。这个表的建表语句是：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> create table T(id int primary key, k int not null, name varchar(16),index (k))engine=InnoDB;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132519.png" alt="InnoDB 的索引组织结构"></p><p>接下来，从这两种索引对查询语句和更新语句的性能影响来进行分析。</p><h2 id="查询过程-几乎无差异"><a class="header-anchor" href="#查询过程-几乎无差异">¶</a>查询过程:几乎无差异</h2><p>假设，执行查询的语句是 <code>select id from T where k=5</code>。这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。</p><ul><li><p>对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。</p></li><li><p>对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。</p></li></ul><p>那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。因为引擎是按页读写的，所以说，当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。当然，如果 k=5 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。但是，我们之前计算过，对于整型字段，一个数据页可以放近千个 key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。</p><h2 id="更新过程"><a class="header-anchor" href="#更新过程">¶</a>更新过程</h2><p>为了说明普通索引和唯一索引对更新语句性能的影响这个问题，需要先介绍一下 change buffer。</p><h3 id="change-buffer"><a class="header-anchor" href="#change-buffer">¶</a>change buffer</h3><p>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后才真正将 change buffer 中与这个页有关的操作进行执行并得到最新结果，这个过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。</p><blockquote><p>需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上的 ibdata 文件(表共享空间)中，对应的内部系统表名为<code>SYS_IBUF_TABLE</code>，在做 merge 操作的时候应该就会持久化到 ibdata。</p></blockquote><p>显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率（change buffer 虽然和 page 一样也占用 buffer pool，但是它是有效内存占用，即仅保存实际要操作的某行数据的信息，而如果把 page 加载到内存中进行实际更新，此时 page 中其它不需要更新的数据就算是无效数据，内存利用率不高）。</p><h3 id="什么条件下可以使用-change-buffer"><a class="header-anchor" href="#什么条件下可以使用-change-buffer">¶</a>什么条件下可以使用 change buffer</h3><p>对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这<strong>必须要将数据页读入内存才能判断</strong>。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。</p><p>另外，MySQL 中锁是一个单独存在的数据结构，一个锁记录包含了它要锁的对象，所以如果一个修改操作在锁记录中发现了它要修改的页，此时 change buffer 也会被定义为不能用（实际上连该页都不能修改了）。</p><blockquote><p>对于用户来说，更新表数据操作就是通过 insert、update、delete 等语句对表数据进行修改，而对于 InnoDB 来说，实际上都是在修改索引，即聚簇索引或者二级索引：</p><ul><li>insert 语句和 delete 语句会修改当前表的聚簇索引和所有二级索引</li><li>update 语句会修改 update 子句中包含的聚簇索引和二级索引</li></ul><p>而修改索引就要先将索引从磁盘加载内存进行修改，change buffer 就是延迟实际修改动作从而延迟读取数据页（磁盘随机读IO）的手段，但是对于一些唯一索引（包含主键索引）的修改和条件子句中包含的索引(字段)，都无法应用 change buffer。</p><ol><li><p>对于 insert 和 update 子句，对于主键索引或者唯一索引的插入或者修改无法应用 change buffer ，因为要查询 insert 或者 update 的主键值是否已经存在，就必须读取主键索引或者唯一索引进行验证。</p><p>但是只要表中包含普通索引，insert 语句就必然也会修改普通索引树，此时对于普通索引树的修改也是可以应用 change buffer 的。</p></li><li><p>对于 update、delete 语句的 where 条件子句中包含的索引字段的修改也无法应用 change buffer。</p><ul><li><code>update T set a = 1, b = 2, c = 3 where a = 3</code>：a 是普通索引、b 是唯一索引、c 是普通索引，此时 a、b 都无法应用 change buffer，c 可以应用</li><li><code>delete from T where c = 3;</code>：此时 c 不能应用 change buffer，a、b 的修改都可以应用，虽然 b 是唯一索引，但是这是删除操作，无须验证是否唯一，在下次涉及索引 b 的插入和修改的时候就会加载对应的 page 到内存，此时会 merge 当前删除（或者后台定期 merge、数据库 shutdown），再进行索引值的唯一验证。</li></ul></li><li><p>delete 语句除了条件子句中包含的索引字段，剩余的表中定义的索引树的修改，都可以应用 change buffer。</p></li></ol></blockquote><p>change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 <code>innodb_change_buffer_max_size</code> 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。</p><h3 id="修改索引的过程"><a class="header-anchor" href="#修改索引的过程">¶</a>修改索引的过程</h3><p>一起来看看如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。</p><ol><li><p>第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下：</p><ul><li>对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；</li><li>对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。</li></ul><p>这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。但这不是我们关注的重点。</p></li><li><p>第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下：</p><ul><li>对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；</li><li>对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。</li></ul><p>将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问（因为延迟了实际修改索引树的操作，所以在写入change buffer到真正触发数据所在页的 change buffer merge 之前的这段时间，可能在该页上发生了多次写操作，产生了很多 buffer ，此时触发该页 merge 的时候，原本需要发生很多次的随机磁盘访问降低到了仅需以此），所以对更新性能的提升是会很明显的。</p><blockquote><p>某个业务的库内存命中率突然从 99% 降低到了 75% (更新操作立即加载内存页导致利用率低)，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，发现这个业务有大量插入数据的操作，而在前一天其中的某个普通索引改成了唯一索引。</p></blockquote></li></ol><h3 id="change-buffer-的使用场景"><a class="header-anchor" href="#change-buffer-的使用场景">¶</a>change buffer 的使用场景</h3><p>因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。</p><p>因此，<strong>对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好</strong>。这种业务模型常见的就是账单类、日志类的系统。</p><p>反过来，<strong>假设一个业务的更新模式是写入之后马上会做查询</strong>，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。</p><h2 id="索引选择和实践"><a class="header-anchor" href="#索引选择和实践">¶</a>索引选择和实践</h2><p>通索引和唯一索引应该怎么选择。其实，这两类索引<strong>在查询能力上是没差别的</strong>，主要考虑的是对更新性能的影响。所以，建议尽量选择普通索引。</p><p>如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。在实际使用中，会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。</p><p>特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。</p><h2 id="change-buffer-和-redo-log"><a class="header-anchor" href="#change-buffer-和-redo-log">¶</a>change buffer 和 redo log</h2><p>WAL 提升性能的核心机制，也是尽量减少随机读写，这两个概念确实容易混淆。所以，这里把它们放到了同一个流程里来说明，便于区分这两个概念。</p><p>现在，我们要在表上执行这个插入语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> insert into t(id,k) values(id1,k1),(id2,k2);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里，我们假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。如图 2 所示是带 change buffer 的更新状态图。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132530.png" alt="带 change buffer 的更新过程"></p><p>分析这条更新语句，会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。</p><p>这条更新语句做了如下的操作（按照图中的数字顺序）：</p><ol><li><p>Page 1 在内存中，直接更新内存；</p></li><li><p>Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息</p></li><li><p>将上述两个动作记入 redo log 中（图中 3 和 4）。</p><blockquote><p>注意：</p><ul><li><p>change buffer 中针对 page 2 的操作可能不只一条，发生 merge 之前每一次针对 page 的修改都会增加一条新的记录到 change buffer 中。在 merge 的时候会按顺序一条条执行这些日志，得到最新版的数据页。</p></li><li><p>对于 change buffer 的 redo log 记录仅仅是记录&quot;修改了 change buffer 的行为&quot;，只有在发生 merge 的时候，才会记录&quot;修改了 page 的行为&quot;。且 merge 动作仅会将数据页加载到内存并将 change buffer 中对于该页的操作进行执行并记录相应的 redo log 就完成了，它不包含刷脏的过程，即将内存中得到的最新数据页同步到磁盘数据文件中（刷脏也无需记录 redo log）。</p></li></ul></blockquote></li></ol><p>做完上面这些，事务就可以完成了。所以，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。同时，图中的两个虚线箭头（左边是持久化 change buffer、右边是定时刷内存中的脏页），是后台操作，不影响更新的响应时间。</p><p>那在这之后的读请求，要怎么处理呢？比如，我们现在要执行 <code>select * from t where k in (k1, k2)</code>。如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，图中就没画出这两部分。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132538.png" alt="change buffer 的读过程"></p><ol><li>读 Page 1 的时候，直接从内存返回。WAL 之后如果读数据，不一定要读盘，不一定要从 redo log 里面把数据更新以后才可以返回（刷脏）。可以看一下图中的这个状态，虽然磁盘(指的是磁盘上的数据文件，此时还没有经历刷脏操作)上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。</li><li>要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后执行 change buffer 里面记录的针对 page 2 的操作日志，生成一个正确的版本并返回结果。可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。</li></ol><p>所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，<strong>redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗</strong>。</p><h2 id="change-buffer-与宕机"><a class="header-anchor" href="#change-buffer-与宕机">¶</a>change buffer 与宕机</h2><p>change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 merge 过程，就等于是数据丢失了。会不会出现这种情况呢？</p><ul><li>如果断电之前该修改操作提交成功，说明已经成功写入 redo log，此时重启后 redo log 将是 commit 状态。如果 redo log 的落盘策略（是每次写都落盘，调用fsync；还是定时刷内存到磁盘）是每次都写磁盘，那么将不会丢失，操作过程已经被持久化，可以恢复。</li><li>如果断电之前该操作没有提示提交成功，可能成功写入 redo log 也可能没有，以下以 redo log 和 binlog 都是每次写磁盘的策略进行分析：<ul><li>如果 redo log 中已经成功写入，但是不是 commit 状态，此时检查到 binlog 的写入是不完整的，此时会发生回滚，这部分数据丢失。</li><li>如果 redo log 中已经写入，但是不是 commit 状态，此时检查 binlog 发现写入完整，自动 commit，此时可以从 redo log 进行恢复。</li></ul></li></ul><h1>九、MySQL为什么有时候会选错索引</h1><p>MySQL 中一张表其实是可以支持多个索引的。但是，写 SQL 语句的时候，并没有主动指定使用哪个索引。也就是说，使用哪个索引是由 MySQL 来确定的。可能会碰到这种情况，一条本来可以执行得很快的语句，却由于 MySQL 选错了索引，而导致执行速度变得很慢。</p><h2 id="先导：例子-v3"><a class="header-anchor" href="#先导：例子-v3">¶</a>先导：例子</h2><p>先建一个简单的表，表里有 a、b 两个字段，并分别建上索引：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t` (  `id` int(11) AUTO_INCREMENT NOT NULL,  `a` int(11) DEFAULT NULL,  `b` int(11) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `a` (`a`),  KEY `b` (`b`)) ENGINE=InnoDB;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>往表 t 中插入 10 万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到 (100000,100000,100000)。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">delimiter ;;create procedure idata()begin  declare i int;  set i=1;  while(i<=100000)do    insert into t(a, b) values(i, i);    set i=i+1;  end while;end;;delimiter ;call idata();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>接下来，分析一条 SQL 语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from t where a between 10000 and 20000;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这条查询语句的执行符合预期，key 这个字段值是’a’，表示优化器选择了索引 a。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> explain select * from t where a between 10000 and 20000;+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+-----------------------+| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows  | filtered | Extra                 |+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+-----------------------+|  1 | SIMPLE      | t     | NULL       | range | a             | a    | 5       | NULL | 10001 |   100.00 | Using index condition |+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+-----------------------+1 row in set, 1 warning (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在已经准备好的包含了 10 万行数据的表上，再做如下操作。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132547.png" alt="session A 和 session B 的执行流程"></p><p>session A 开启了一个事务。随后，session B 把数据都删除后，又调用了 <code>idata</code> 这个存储过程，插入了 10 万行数据。</p><p>这时候，session B 的查询语句 <code>select * from t where a between 10000 and 20000;</code> 就不会再选择索引 a 了（原因参考 <a href="####%E4%BC%98%E5%8C%96%E5%99%A8%E7%9A%84%E9%A2%84%E4%BC%B0%E6%89%AB%E6%8F%8F%E8%A1%8C">优化器的预估扫描行</a>），可以看到，下面的执行计划中使用了全表扫描。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> explain select * from t where a between 10000 and 20000;+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows   | filtered | Extra       |+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+-------------+|  1 | SIMPLE      | t     | NULL       | ALL  | a             | NULL | NULL    | NULL | 100015 |    37.11 | Using where |+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+-------------+1 row in set, 1 warning (0.13 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以通过慢查询日志（slow log）来查看一下具体的执行情况。作为对照，增加一次语句执行使用 <code>force index(a)</code> 来让优化器强制使用索引 a。</p><p>下面的三条 SQL 语句，就是这个实验过程。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">set long_query_time=0;select * from t where a between 10000 and 20000; /*Q1*/select * from t force index(a) where a between 10000 and 20000;/*Q2*/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>第一句，是将慢查询日志的阈值设置为 0，表示这个线程接下来的语句都会被记录入慢查询日志中；</p><p>第二句，Q1 是 session B 原来的查询；</p><p>第三句，Q2 是加了 force index(a) 来和 session B 原来的查询语句执行情况对比。</p><p>这三条 SQL 语句执行完成后的慢查询日志：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132554.png" alt="slow log 结果"></p><p>可以看到：</p><ul><li>Q1 扫描了 10 万行，显然是走了全表扫描，执行时间是 40 毫秒。</li><li>Q2 扫描了 10001 行，执行了 21 毫秒。</li></ul><p>也就是说，我们在没有使用 force index 的时候，MySQL 用错了索引（走主键索引逐行扫描，其实就是全表扫描了，相当于没用索引），导致了更长的执行时间。这个例子对应的是我们平常不断地删除历史数据和新增数据的场景。这时，MySQL 竟然会选错索引，是不是有点奇怪呢？</p><h2 id="优化器的逻辑"><a class="header-anchor" href="#优化器的逻辑">¶</a>优化器的逻辑</h2><p>选择索引是优化器的工作。而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少（这里指的是存储引擎的扫描行），消耗的 CPU 资源越少。</p><p>当然，<strong>扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素</strong>进行综合判断。当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。</p><h3 id="扫描行数判断"><a class="header-anchor" href="#扫描行数判断">¶</a>扫描行数判断</h3><p>MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。</p><h4 id="基数"><a class="header-anchor" href="#基数">¶</a>基数</h4><p>这个统计信息包含了<strong>索引的“区分度”</strong>。<strong>一个索引上不同的值越多(对于某个索引来说，不同的值越多，相同的值就越少了，越容易定位到某行数据)，这个索引的区分度就越好</strong>。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。</p><p>我们可以使用 <code>show index</code> 方法，看到一个索引的基数。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132601.png" alt="表 t 的 show index 结果"></p><p>虽然这个表的每一行的三个字段值都是一样的，但是在统计信息中，这三个索引的基数值并不同，而且其实都不准确。</p><h5 id="如何计算基数"><a class="header-anchor" href="#如何计算基数">¶</a>如何计算基数</h5><p>那么，MySQL 是怎样得到索引的基数的呢？通过采样统计的方式。为什么要采样统计呢？因为要对表的每一行进行记录统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。采样统计的时候，<strong>InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数</strong>。而数据表是会持续更新的，索引统计信息也不会固定不变。所以，<strong>当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计</strong>。</p><p>在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 <code>innodb_stats_persistent</code> 的值来选择：</p><ul><li><p>设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。</p></li><li><p>设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。</p></li></ul><p>由于是采样统计，所以不管 N 是 20 还是 8，这个基数都是很容易不准的。</p><blockquote><p>即基数 cardinality 就是预估出来的某个索引上的不同值的数量。这个数量对于<strong>最终预估扫描行</strong>也是有贡献的，假如有一个用户表，表中有一个性别字段，表中有100W数据，那么此时该字段的基数相较其它字段将会非常低，此时相对来说如果使用这个索引进行检索那么需要扫描的行数就可能越多，因为区分度太低。以如下 SQL 为例：</p><p><code>select * from tuser where gender = 1 and unique_id = 1000</code></p><p>这个 SQL 的条件子句中包含了两个字段 <code>gender</code> 和 <code>unique_id</code> ，前者有一个二级索引，后者有一个唯一索引。</p><ul><li>此时表中包含 100W 数据</li><li><code>gender</code> 只有 1 和 0 两种取值</li><li>基数计算中的 N 值取8</li><li>注意索引中的 page 是按照索引字段值排序的，所以此时 <code>gender</code> 取到的每一个 page 中很大概率都是同一个值 1 或者 0。当然，page 的取样应该是分布较散的，所以我们这里还是假设 8 个 page 中 <code>gender</code> 可以取到一样的 1 和 0。</li><li><code>unique_id</code> 的 page 中的值肯定都不一样了</li></ul><p>那么取 8 个 page ，<code>gender</code> 的不同值都是 2 ，乘以 8 得到 16 ；而 <code>unique_id</code> 因为每个值都不一样，要算一下一个 page 中可以有多少行数据，MySQL page 默认 16 KB，假设 <code>unique_id</code> 为 <code>int</code> 占 4 个字节，主键长度也是 4 个字节，此时一个 page 可以有 16 * 1024 / (4+4) = 2048 行，所以 <code>unique_id</code> 的基数为 2048 * 8 = 16384 。差别很多，如果仅以基数作为参考，那么肯定是选择后者了。</p><p>那么实际的索引检索过程中是不是真的基数越小检索效果越差呢？这是相对来说的，因为这个 SQL 中还有 <code>unique_id</code> 字段作为条件了，假设现在我们就是要用 <code>gender</code> 进行检索：</p><ol><li><p>首先我们计算 <code>gender</code> 的树高。 <code>gender</code> 索引的叶子节点中数据单元大小（即一行数据所占大小）为 <code>gender</code> 字段长度+主键索引字段长度，假设 <code>gender</code> 字段长度为 1 B，主键长度为 4 B，此时一个数据单元就是 5 B。默认 mysql page 16 KB，所以每一个 page 中可以有约 3276 行。仅一个根节点是肯定装不下的。现在按照树高为 2 进行计算。</p><p>非叶子节点中的一个数据单元大小 = <code>gender</code>字段长度 + 子节点指针长度 6B，就是 7 B，索引树根节点可以存储 16 * 1024 / 7 ≈ 2340 个单元，即第二层可以有 2340 个节点。此时 2340 * 16 * 1024 / 5 ≈ 7667712 ，700 多万行数据，仅2层树高就可以存储超过 100W 行数据。</p></li><li><p>虽然树高只有 2 层，但是因为这个索引树的区分度非常低，需要从第二层的最左节点一直扫描到中间节点，需要访问磁盘 50 W 次（忽略其它优化，这里按照一个数据块访问一次磁盘计算），然后这 50 W条记录都要回表到主键索引查询数据返回到 Server 层，Server 层拿到这 50 W条数据之后还要对 <code>unique_id</code> 条件进行过滤。</p></li></ol><p>对比直接用 <code>unqiue_id</code> ，它的树高肯定也是 2 层就可以了，所以它直接可以在根节点二分得到对应的第二层节点位置，然后再在第二层叶子节点进行一次二分定位到该行位置，因为是唯一索引，所以直接回表主键索引查询该行数据返回 Server 层即可（即使它不是唯一索引，最多也就是定位到该行后看下一行是不是一样的值，但是因为它拥有极高基数也就是所有值都是唯一的，所以肯定不想等，直接返回）。Server 层仅拿到一条数据，然后再对 <code>gender</code> 字段进行匹配，看这条数据是否正确，正确就返回用户界面，否则返回空。</p><p>由此看出两者差距还是挺大的，所以对于基数非常低的字段建立索引是比较尴尬的。</p></blockquote><h5 id="当前例子的基数不会影响优化器判断"><a class="header-anchor" href="#当前例子的基数不会影响优化器判断">¶</a>当前例子的基数不会影响优化器判断</h5><p>从前面图中也可以看到索引统计中的基数（cardinality 列）虽然不够精确，但大体上还是差不多的（<strong>因为三个字段 a、b、c 都是每行唯一的，基数理论上就是一样的</strong>），选错索引一定还有别的原因。其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。</p><blockquote><p>个人感觉这里的预估扫描行是预估的存储引擎返回给 Server 的行数，如果索引的基数非常高，并且执行计划类型是 <code>eq</code> 而不是 <code>range</code> （<code>all</code>就是不用索引全表逐行扫描了），此时 rows 可能是 1 。</p><p>如果是 <code>range</code> 或者 <code>all</code> 查询，所以 rows 应该是基数的补数的正相关函数，正相关函数的常数应该和 <code>rannge</code> 查询或者 <code>all</code> 的区间行数正相关。</p></blockquote><h4 id="优化器的预估扫描行"><a class="header-anchor" href="#优化器的预估扫描行">¶</a>优化器的预估扫描行</h4><p>看看优化器预估的，这两个语句的预估扫描行数是多少。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132610.png" alt="意外的 explain 结果"></p><p>rows 这个字段表示的是预计扫描行数。其中：</p><ul><li>Q1 的结果还是符合预期的，rows 的值是 104620（因为 Q1 <code>select * from t where a between 10000 and 20000;</code> 是全表扫描，本身表中确实是有这么多数据，而在主键索引中匹配 a 字段确实就是要逐行扫描每一条数据，因为该字段是无序的，所以 10W 行左右没错）；</li><li>但是 Q2 的 rows 值是 37116，偏差就大了：在一开始没有做删除再插入全部 10W 行数据的时候执行计划显示的是 10001，但是现在却变成了 3W，Q1 的执行计划显示的全表扫描是正常的（即在删除再插入 10W 行数据前后全表扫描执行计划是一致的，都是 10W，逻辑上也讲的通），所以判断就是<strong>因为这个偏差误导了优化器的判断</strong>。</li></ul><p>这里产生了两个问题：</p><ol><li>为什么 Q2 有偏差</li><li>为什么 Q2 的预估扫描行是 3W 优化器却选择了 10 W执行</li></ol><p>我们分开来看：</p><h5 id="1-为什么-Q2-有偏差"><a class="header-anchor" href="#1-为什么-Q2-有偏差">¶</a>1.为什么 Q2 有偏差</h5><h6 id="MySQL-是如何删除数据的"><a class="header-anchor" href="#MySQL-是如何删除数据的">¶</a>MySQL 是如何删除数据的</h6><p>首先来看一下 MySQL 是如何删除数据的。MySQL 对于数据并不是立刻删除的：</p><ol><li>每一次删除数据都立即执行并写磁盘，消耗较大</li><li>出于并发访问效率的考虑 MySQL 实现了 MVCC，在 RC 和 RR 模式下基于一个事务一定的一致性视图保证。</li></ol><p>所以综合起来不会每次都立即删除数据，以下是删除数据的步骤：</p><ol><li><p>删除数据都是在一个事务中进行的，会申请一个事务 ID</p></li><li><p>所有要删除的行都会在聚簇索引和二级索引中生成一个新的版本，该版本的 row trx_id 是当前事务 ID，然后将该行标记为<code>deleted</code>，并将删除前的版本记录为一个 undo log 数据结构赋值到当前版本中进行记录（这些操作有可能会先保存在 change buffer 中，延迟到需要的时候再真正操作 page）。</p><blockquote><p>注意：为什么要标记为 <code>deleted</code> 不直接删除，因为：</p><ol><li>所有的读数据动作都是直接在索引中开始读取，索引中的数据都是最新版本，根据最新版本沿着 undo log 一直往前计算，如果直接删除了，删除数据前已经开启的其它事务重新来读取这行数据的时候，发现找不到了，一致性无法保证。所以这个标记为 <code>deleted</code> 的索引行是为了那些已经存在的 read view 保持 undo log。</li><li>MySQL 对所有使用 <code>delete</code> 语句删除的数据都不会真正的删除，它们只会被打标为删除，当 page 中被打标的数据行的所有 undo log 都已经删除，那么它就会被标记为可复用，后续新插入的数据行和可复用的数据行的前后也保持有序的情况下，就会复用这个&quot;槽&quot;(或者说空洞)。如果一个页上的所有数据行都被删除并且是可复用的，那么这个页都是可复用的了，此时该数据页将可以被随意复用。</li><li>另外，上面提到表文件本身永久不会减少，同时通过优化表等行为可以重建表，此时这些已经可以是重用的空洞就会被消除，但是也是一个全新的文件了（即是另外一个磁盘空间了，只不过文件名一样，替换了原本空洞过多的文件）。</li></ol><p>那什么时候会将一条被打标删除的数据标记为可复用呢？这条 undo log 删除的时候。那这条 undo log 什么时候删除呢？<a href="##%E5%9B%9E%E6%BB%9A%E6%AE%B5%E7%9A%84%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E5%8F%8A%E9%95%BF%E4%BA%8B%E5%8A%A1%E5%B8%A6%E6%9D%A5%E7%9A%84%E5%BD%B1%E5%93%8D%5B%5E3.1%5D">关于回滚段的删除策略</a>有提到，当这条数据被标记为<code>deleted</code>前所有已经存在的 read view 都不存在了，就可以删除了，那由谁来删除、怎么删除呢？</p><p>后台会有 purge 线程在定期删除那些可以删除的 undo log 并清理已经删除的数据，以下是关于 purge 线程的一些参数：</p><ul><li><p><code>innodb_purge_batch_size</code>：用来设置每次purge操作需要清理的undo log page的数量。默认300，表示每次清理300个page，支持动态修改。设置的越大，表示每次回收的页也就越多，可供重用的undo page也就越多，就能减少磁盘存储空间与分配的开销。不过该参数设置得太大，则每次需要purge处理更多的undo page，从而导致CPU和磁盘IO过于集中于对undo log的处理，使性能下降。普通用户不建议调整这个参数。</p></li><li><p><code>innodb_purge_threads</code>：当有很多的表进行DML操作时候， 增大 <code>innodb_purge_threads</code> 能提高purge的效率(清理掉MVCC机制导致的老旧数据)。现在的MySQL版本中。purge线程已经从master线程中独立出来,使用单独的线程提高了可伸缩性。从MySQL5.7.8开始，这个参数默认是4，最大可以设置为32.（老版本里面这个值默认是1）</p></li><li><p><code>innodb_max_purge_lag</code>：当InnoDB存储引擎的压力非常大时，并不能高效地进行purge操作。那么history list(undo log page数量)的长度会变得越来越长。<code>innodb_max_purge_lag</code> 就是控制history list的长度，若长度大于该值，就会延缓DML的操作。该值默认为0，表示不做任何限制。(不建议修改这个参数值!! )</p></li><li><p><code>innodb_max_purge_lag_delay</code>：表示当上面<code>innodb_max_purge_lag</code>的delay超时时间太大，超过这个参数时，将delay设置为该参数值，防止purge线程操作缓慢导致其他SQL线程长期处于等待状态。默认为0，一般不用修改。</p></li></ul></blockquote></li><li><p>此后如果在删除数据前已经开启的其它事务再来查询删除行的时候，发现最新版本事务 ID 太大，所以沿着 undo log 查找到删除前的版本，其视图保持一致；而在本次删除事务提交之后才开启的事务来查询删除行的时候，发现索引中该行被标记为 <code>deleted</code> ，而该版本事务 ID 满足在一致性视图，所以读取该行为已删除，即不返回这行给用户。</p></li></ol><h6 id="Q2-的偏差"><a class="header-anchor" href="#Q2-的偏差">¶</a>Q2 的偏差</h6><ol><li><p>在 RR 模式下，当 Session A 开启了一个一致性视图，假设其事务 ID 为 Ta。</p></li><li><p>然后在 Session B 中删除表 t 中的 10W 行数据，此时需要保证 Session A的一致性视图。对于删除的每一行数据（所有聚簇索引和二级索引）新增一个版本，<code>row trx_id</code> 指向 Session B 的事务 ID ，并将这些数据标记为删除状态，然后将老版本生成 undo log 链接到索引的当前最新<code>deleted</code>版本中。</p><blockquote><p>对于所有这 10W 行数据，a，b 都没有唯一索引，条件子句中也没有指明任何字段，所以对于 a，b 索引的修改都可以先写入 change buffer （或者可能 MySQL 计算到删除数据量比较大，可能会放弃 change buffer，直接加载 page 进行操作）</p></blockquote></li><li><p>继续在 Session B 中调用存储过程重新插入 10W 行，需要注意的是，前面的例子中使用的是主键自增 ID。所以主键索引中会有 20W 个最新版本(10W <code>deleted</code> 的，10W 当前新增的)。而 a，b 索引中是要存储主键索引的，此时重新插入的 10W 行的主键和已经 <code>deleted</code> 的 10W 行的主键已经不一样了，所以在 a，b 索引中，每一个值都会有两份最新版本的数据。一份是 <code>deleted</code>的行，持有旧的主键ID；一份是新插入的行，持久最新取到的自增ID。</p><p>此时如果在 Session B 中继续查询 <code>select * from t where a between 10000 and 20000;</code> 的执行计划，在计算索引 a 的预估计扫描行 <code>rows</code> 的时候会索引中已经 <code>deleted</code> 的数据和刚刚新增的 10W 行数据都纳入计算。所以得到了 37116 的错误的更大的值。（这也是为什么表为非自增的时候，无法复现的原因，因为 <code>deleted</code> 的行）</p><blockquote><p>此时 Session A 还没有提交，故标记为<code>deleted</code>的 undo log 还不能被删除，所以虽然说10w 行数据被标记为删除了，但是如果它不能彻底地从索引中移除（重建表），那么它就还是在该索引中的，所以利用索引a进行检索的时候，必然会检索到这些删除的索引，然后再检查它是否是标记为<code>delete</code>的，版本事务是否符合当前查询事务的视图等，这个是一个有效的计算来的。</p><p>所以优化器在抽样检查加载的 page 中的数据行计算预估计扫描行的<code>rows</code>的时候，就应该将标记为<code>deleted</code>但是未真正删除和已经重新插入的版本都作为计算因子。所以此时 Session B 再次查询<code>select * from t where a between 10000 and 20000;</code>语句对于索引 a 的执行计划时，最终计算出 37116 的数量，反馈给了查询用户扫描行预估过多的情况(因为在用户视角里面，之前的 10 W行删除了)。而此时优化器发现使用二级索引比主键索引要扫描的 1/3 行还要多，所以它选择了主键索引全表扫描的计划，并返回给用户。所以看到的是全表扫描的 10W 行左右，使用<code>explain select * from t force index(a) where a between 10000 and 20000;</code> 可以看到优化器计算索引 a 的预估计<code>rows</code>值。</p></blockquote><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t` (  `id` int(11) AUTO_INCREMENT NOT NULL,  `a` int(11) DEFAULT NULL,  `b` int(11) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `a` (`a`),  KEY `b` (`b`)) ENGINE=InnoDB;delimiter ;;create procedure idata()begin  declare i int;  set i=1;  while(i<=100000)do    insert into t(a, b) values(i, i);    set i=i+1;  end while;end;;delimiter ;call idata();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>另外还需要注意的是，执行计划给出的主键全表扫描是 100015 行，约10W 行，怎么主键的计算就正确了呢？它不是也保留了<code>deleted</code>的 undo log 吗？这是因为对于主键索引和二级索引的<code>rows</code>计算是不一样的。它直接计算表的行数的，优化器直接用的 <code>show table status</code> 中表的 <code>rows</code>字段值。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> show table status;+-------+--------+---------+------------+--------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------+----------+----------------+---------+| Name  | Engine | Version | Row_format | Rows   | Avg_row_length | Data_length | Max_data_length | Index_length | Data_free | Auto_increment | Create_time         | Update_time         | Check_time | Collation   | Checksum | Create_options | Comment |+-------+--------+---------+------------+--------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------+----------+----------------+---------+| T     | InnoDB |      10 | Dynamic    |      6 |           2730 |       16384 |               0 |        16384 |         0 |           NULL | 2020-10-02 08:59:24 | NULL                | NULL       | utf8mb4_bin |     NULL |                |         || t     | InnoDB |      10 | Dynamic    | 100015 |             68 |     6832128 |               0 |     11567104 |   4194304 |         200001 | 2020-10-03 15:13:04 | 2020-10-03 15:13:49 | NULL       | utf8mb4_bin |     NULL |                |         || tuser | InnoDB |      10 | Dynamic    |      0 |              0 |       16384 |               0 |        32768 |         0 |           NULL | 2020-10-02 09:37:17 | NULL                | NULL       | utf8mb4_bin |     NULL |                |         |+-------+--------+---------+------------+--------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+-------------+----------+----------------+---------+3 rows in set (0.03 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><blockquote><p>以下两种情况不会导致优化器预估扫描行错误：</p><p>1&gt;主键非自增</p><p>上面的 Q2 的索引 a 预估计扫描行从 10001 偏差到 3W 多行只有表是自增的情况下才能复现，如果是非自增的话，优化器对于 <code>select * from t where a between 10000 and 20000;</code> 的执行计划计算算出的 a 索引的预估扫描行是正确的 10001 行。所以它不会选择全表扫描的执行计划，<code>explain select * from t where a between 10000 and 20000;</code> 的结果就是选择了索引 a ，预估扫描行是 10001，而无需 <code>force index(a)</code>。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t` (`id` int(11)NOT NULL,`a` int(11) DEFAULT NULL,`b` int(11) DEFAULT NULL,PRIMARY KEY (`id`),KEY `a` (`a`),KEY `b` (`b`)) ENGINE=InnoDB;delimiter ;;create procedure idata()begindeclare i int;set i=1;while(i<=100000)do insert into t values(i, i, i); set i=i+1;end while;end;;delimiter ;call idata();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里和自增主键的区别就是全表删除之后第二次重新插入的主键还都是一样的。当第二次重新插入的主键还是一样的时候，重新插入的每一行数据都会根据（a，id）的值在 a 索引树中找到自己的位置，此时就会定位到已经<code>deleted</code>的那份版本的位置，所以将会发生覆盖，<code>deleted</code>的版本会变成新插入版本的 undo log。此时索引树中只剩下新插入的 10W 数据了，此时查询<code>select * from t where a between 10000 and 20000;</code> 的执行计划，就会得到正常的 10001。</p><p>2&gt;没有开启Session A</p><p>此时在 Session B 删除数据的时候，被打标为<code>deleted</code>的 10W 行数据即可被置为可复用。因为全部数据都是可复用的，说明所有页都是可复用的，页是可以随意复用的，不用管前后行是否有序，所以后续再新插入 10W 行数据的时候，无论是否主键自增的情况，索引 a 中的数据还是原本的10W 行，不会发生翻倍，此时查询<code>select * from t where a between 10000 and 20000;</code> 的执行计划，也会得到正常的 10001。</p></blockquote><h5 id="2-为什么选择全表扫描"><a class="header-anchor" href="#2-为什么选择全表扫描">¶</a>2.为什么选择全表扫描</h5><p>因为优化器的计算是这样的：</p><ul><li>如果使用索引 a，每次从索引 a 上拿到一个值，<strong>都要回到主键索引上查出整行数据</strong>（回表），这个代价优化器也要算进去的。</li><li>而如果选择扫描 10 万行，是<strong>直接在主键索引上扫描的</strong>，没有额外的代价。</li><li>所以在优化器看来，使用了一个二级索引之后还需要 1/3 的预估行扫描，就会选择全表扫描。</li></ul><p>优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。使用普通索引需要把回表的代价算进去，在前面 <a href="##%E5%85%88%E5%AF%BC%EF%BC%9A%E4%BE%8B%E5%AD%90">一开始</a> 执行 explain 的时候，也考虑了这个策略的代价 ，但选择是对的。也就是说，这个策略并没有问题。所以冤有头债有主，MySQL 选错索引，这件事儿还得归咎到没能准确地判断出使用索引 a 时的扫描行数。</p><h5 id="解决"><a class="header-anchor" href="#解决">¶</a>解决</h5><p>既然是统计信息不对，那就修正。<code>analyze table t</code> 命令，可以用来重新统计索引信息。我们来看一下执行效果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132623.png" alt="analyze table t 命令恢复的 explain 结果"></p><p>这回对了（没有<code>analyze</code>之前执行计划选择的是全表扫描，<code>analyze</code>之后索引 a 的预估扫描行降到了 10001，选择了走索引 a）。所以在实践中，如果你发现 <code>explain</code> 的结果预估的 <code>rows</code> 值跟实际情况差距比较大，可以采用这个方法来处理。</p><h3 id="排序的影响"><a class="header-anchor" href="#排序的影响">¶</a>排序的影响</h3><p>其实，如果只是索引统计不准确，通过 <code>analyze</code> 命令可以解决很多问题，前面说了，优化器可不止是看扫描行数。依然是基于这个表 t，我们看看另外一个语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>从条件上看，这个查询没有符合条件的记录，因此会返回空集合。</p><ul><li>如果使用索引 a 进行查询，那么就是扫描索引 a 的前 1000 个值，然后取到对应的 id，再到主键索引上去查出每一行，然后根据字段 b 来过滤。显然这样需要扫描 1000 行。</li><li>如果使用索引 b 进行查询，那么就是扫描索引 b 的最后 50001 个值，与上面的执行过程相同，也是需要回到主键索引上取值再判断，所以需要扫描 50001 行。</li></ul><p>所以你一定会想，如果使用索引 a 的话，执行速度明显会快很多。那么，下面我们就来看看到底是不是这么一回事儿。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> explain select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132629.png" alt="使用 explain 方法查看执行计划 2"></p><p>可以看到，返回结果中 key 字段显示，这次优化器选择了索引 b，而 rows 字段显示需要扫描的行数是 50198。从这个结果中，可以得到两个结论：</p><ul><li><p>扫描行数的估计值依然不准确()；</p></li><li><p>这个例子里 MySQL 又选错了索引。</p></li></ul><p>其实优化器选择使用索引 b，是因为它认为使用<strong>索引 b 可以避免排序</strong>（b 本身是索引，已经是有序的了，如果选择索引 b 的话，存储引擎根据索引 b 检索出来的数据就是有序的，Server 层筛选数据的时候不需要再做排序，只需要遍历），所以即使扫描行数多，也判定为代价更小。</p><p>如果我们使用 <code>force index</code> 强行选择索引 a：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132635.png" alt="使用不同索引的语句执行耗时"></p><p>可以看到，原本语句需要执行 2.23 秒，而当你使用 force index(a) 的时候，只用了 0.05 秒，比优化器的选择快了 40 多倍。</p><h4 id="索引选择异常和处理"><a class="header-anchor" href="#索引选择异常和处理">¶</a>索引选择异常和处理</h4><p>其实大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况：原本可以执行得很快的 SQL 语句，执行速度却比你预期的慢很多，你应该怎么办呢？</p><h5 id="force-index-强制使用正确索引"><a class="header-anchor" href="#force-index-强制使用正确索引">¶</a>force index 强制使用正确索引</h5><p>一种方法是，像我们第一个例子一样，采用 force index 强行选择一个索引。MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。</p><h6 id="force-index-的弊端"><a class="header-anchor" href="#force-index-的弊端">¶</a>force index 的弊端</h6><p>不过很多程序员不喜欢使用 force index，一来这么写不优美，二来如果索引改了名字，这个语句也得改，显得很麻烦。而且如果以后迁移到别的数据库的话，这个语法还可能会不兼容。但其实使用 force index 最主要的问题还是变更的及时性。因为选错索引的情况还是比较少出现的，所以开发的时候通常不会先写上 force index。而是等到线上出现问题的时候，你才会再去修改 SQL 语句、加上 force index。但是修改之后还要测试和发布，对于生产系统来说，这个过程不够敏捷。</p><h5 id="修改-SQL-引导数据库选择正确索引"><a class="header-anchor" href="#修改-SQL-引导数据库选择正确索引">¶</a>修改 SQL 引导数据库选择正确索引</h5><p>基于 force index 的弊端，数据库的问题最好还是在数据库内部来解决。那么，在数据库里面该怎样解决呢？既然优化器放弃了使用索引 a，说明 a 还不够合适，所以第二种方法就是，我们可以考虑修改语句，引导 MySQL 使用我们期望的索引。比如，在这个例子里，显然把<code>order by b limit 1</code> 改<code> order by b,a limit 1</code> ，语义的逻辑是相同的。我们来看看改之后的效果：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132641.png" alt="order by b,a limit 1 执行结果"></p><p><code>order by b,a</code> 这种写法，要求按照 <code>b,a</code> 排序，就意味着无论使用 a 还是 b 索引都是需要排序的，因为即使使用了 b 索引，b是有序的，但是它不是和 a 的联合索引，所以 b 索引中不包含 a 字段，最终返回给 Server 层还是要对 a 排序。因此，扫描行数成了影响决策的主要条件，于是此时优化器选了只需要扫描 1000 行的索引 a。</p><p>当然，这种修改并不是通用的优化手段，只是刚好在这个语句里面有 limit 1，因此如果有满足条件的记录， <code>order by b limit 1</code> 和 <code>order by b,a limit 1</code> 都会返回 b 是最小的那一行，逻辑上一致，才可以这么做。</p><p>如果觉得修改语义这件事儿不太好，这里还有一种改法：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from  (select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 100)alias limit 1;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行效果：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132646.png" alt="改写 SQL 的 explain"></p><p>在这个例子里，我们用 limit 100 让优化器意识到，使用 b 索引代价是很高的。其实是我们根据数据特征诱导了一下优化器，也不具备通用性。</p><h5 id="删除误用的索引"><a class="header-anchor" href="#删除误用的索引">¶</a>删除误用的索引</h5><p>第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。</p><p>不过，在这个例子中，没有找到通过新增索引来改变优化器行为的方法。这种情况其实比较少，尤其是经过 DBA 索引优化过的库，再碰到这个 bug，找到一个更合适的索引一般比较难（当然前提是有一个好的DBA）。</p><h2 id="关于Like的索引问题"><a class="header-anchor" href="#关于Like的索引问题">¶</a>关于Like的索引问题</h2><p>一张表两个字段 <code>id</code>,<code> name</code>。<code>id</code> 主键，<code>uname</code>普通索引：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">SELECT * FROM tuser WHERE name LIKE 'j'SELECT * FROM tuser WHERE name LIKE 'j%'-- 执行计划+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                    |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+|  1 | SIMPLE      | tuser | NULL       | index | name          | name | 1022    | NULL |    1 |   100.00 | Using where; Using index |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+SELECT id FROM tuser WHERE name LIKE 'j'SELECT id FROM tuser WHERE name LIKE 'j%'-- 执行计划+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                    |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+|  1 | SIMPLE      | tuser | NULL       | index | name          | name | 1022    | NULL |    1 |   100.00 | Using where; Using index |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+SELECT * FROM tuser WHERE name LIKE '%j'SELECT * FROM tuser WHERE name LIKE '%j%'-- 执行计划：表中只要 ID 和 name 两个字段，直接在 name 中全表扫描+索引覆盖+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                    |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+|  1 | SIMPLE      | tuser | NULL       | index | NULL          | name | 1022    | NULL |    1 |   100.00 | Using where; Using index |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>添加一个age字段：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">SELECT * FROM tuser WHERE name LIKE 'j'SELECT * FROM tuser WHERE name LIKE 'j%'SELECT age FROM tuser WHERE name LIKE 'j'SELECT age FROM tuser WHERE name LIKE 'j%'-- 执行计划：由 using index 变成了 using index condition+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                 |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+|  1 | SIMPLE      | tuser | NULL       | range | name          | name | 1022    | NULL |    1 |   100.00 | Using index condition |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+SELECT id FROM tuser WHERE name LIKE 'j'SELECT id FROM tuser WHERE name LIKE 'j%'-- 执行计划+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                    |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+|  1 | SIMPLE      | tuser | NULL       | index | name          | name | 1022    | NULL |    1 |   100.00 | Using where; Using index |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+SELECT * FROM tuser WHERE name LIKE '%j'SELECT * FROM tuser WHERE name LIKE '%j%'SELECT age FROM tuser WHERE name LIKE '%j'SELECT age FROM tuser WHERE name LIKE '%j%'-- 执行计划：不使用索引+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra       |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+|  1 | SIMPLE      | tuser | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    1 |   100.00 | Using where |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>建立 <code>uname</code>，<code>age</code> 的联合索引：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">SELECT * FROM tuser WHERE name LIKE 'j'SELECT * FROM tuser WHERE name LIKE 'j%'SELECT age FROM tuser WHERE name LIKE 'j'SELECT age FROM tuser WHERE name LIKE 'j%'-- 执行计划：又变成了 using index，使用的是联合索引+----+-------------+-------+------------+-------+--------------------+---------------+---------+------+------+----------+--------------------------+| id | select_type | table | partitions | type  | possible_keys      | key           | key_len | ref  | rows | filtered | Extra                    |+----+-------------+-------+------------+-------+--------------------+---------------+---------+------+------+----------+--------------------------+|  1 | SIMPLE      | tuser | NULL       | index | name,idx_namme_age | idx_namme_age | 1027    | NULL |    1 |   100.00 | Using where; Using index |+----+-------------+-------+------------+-------+--------------------+---------------+---------+------+------+----------+--------------------------+SELECT id FROM tuser WHERE name LIKE 'j'SELECT id FROM tuser WHERE name LIKE 'j%'SELECT name FROM tuser WHERE name LIKE 'j'SELECT name FROM tuser WHERE name LIKE '%j'-- 执行计划：使用的是name索引+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                    |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+|  1 | SIMPLE      | tuser | NULL       | index | name          | name | 1022    | NULL |    1 |   100.00 | Using where; Using index |+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+SELECT * FROM tuser WHERE name LIKE 'j'SELECT age FROM tuser WHERE name LIKE 'j%'SELECT * FROM tuser WHERE name LIKE '%j'SELECT * FROM tuser WHERE name LIKE '%j%'SELECT age FROM tuser WHERE name LIKE '%j'SELECT age FROM tuser WHERE name LIKE '%j%'-- 执行计划：不使用索引-- 执行计划：使用的是name、age联合索引+----+-------------+-------+------------+-------+--------------------+---------------+---------+------+------+----------+--------------------------+| id | select_type | table | partitions | type  | possible_keys      | key           | key_len | ref  | rows | filtered | Extra                    |+----+-------------+-------+------------+-------+--------------------+---------------+---------+------+------+----------+--------------------------+|  1 | SIMPLE      | tuser | NULL       | index | name,idx_namme_age | idx_namme_age | 1027    | NULL |    1 |   100.00 | Using where; Using index |+----+-------------+-------+------------+-------+--------------------+---------------+---------+------+------+----------+--------------------------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1>十、慢查询日志</h1><h2 id="慢查询日志概念"><a class="header-anchor" href="#慢查询日志概念">¶</a>慢查询日志概念</h2><p>MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过 <code>long_query_time</code> 值的SQL，则会被记录到慢查询日志中。<code>long_query_time</code> 的默认值为10，意思是运行 10s 以上的语句。默认情况下，<strong>MySQL 数据库并不启动慢查询日志</strong>，需要我们手动来设置这个参数，当然，<strong>如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响</strong>。<strong>慢查询日志支持将日志记录写入文件，也支持将日志记录写入数据库表</strong>。</p><h2 id="慢查询日志相关参数"><a class="header-anchor" href="#慢查询日志相关参数">¶</a>慢查询日志相关参数</h2><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>slow_query_log</td><td>是否开启慢查询日志，1表示开启，0表示关闭</td></tr><tr><td>log_slow_queries</td><td>旧版（5.6以下版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件<code>host_name-slow.log</code></td></tr><tr><td>slow_query_log_file</td><td>新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件<code>host_name-slow.log</code></td></tr><tr><td>long_query_time</td><td>慢查询阈值，当查询时间多于设定的阈值时，记录日志。</td></tr><tr><td>log_queries_not_using_indexes</td><td>未使用索引的查询也被记录到慢查询日志中（可选项）。</td></tr><tr><td>log_output</td><td>日志存储方式。<code>log_output='FILE'</code> 表示将日志存入文件，默认值是<code>FILE</code>。<code>log_output='TABLE'</code> 表示将日志存入数据库，这样日志信息就会被写入到 <code>mysql.slow_log</code> 表中。MySQL数据库支持同时两种日志存储方式，配置的时候以逗号隔开即可，如：<code>log_output='FILE,TABLE'</code>。日志记录到系统的专用日志表中，要比记录到文件耗费更多的系统资源，因此对于需要启用慢查询日志，又需要能够获得更高的系统性能，那么建议优先记录到文件。</td></tr><tr><td>log_slow_admin_statements</td><td>表示是否将慢管理语句例如 <code>ANALYZE TABLE</code> 和 <code>ALTER TABLE</code> 等记入慢查询日志</td></tr><tr><td><code>show global status like '%Slow_queries%'</code></td><td>查询记录了多少条慢查询</td></tr><tr><td>log_slow_slave_statements</td><td>默认情况下，副本从服务器不会记录复制主服务器的 SQL 到慢日志。通过激活这个系统变量，使得那些在从服务器上执行超过 <code>long_query_time</code> 秒的 SQL 被记录。这个变量在 5.7.1 版本中加入，设置这个变量不会立马生效。这个变量值会应用在随后的 START SLAVE 的 statement 中。</td></tr></tbody></table><h2 id="慢查询日志配置"><a class="header-anchor" href="#慢查询日志配置">¶</a>慢查询日志配置</h2><p>默认情况下slow_query_log的值为OFF，表示慢查询日志是禁用的，可以通过设置 <code>slow_query_log</code> 的值来开启，如下所示：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> show variables like '%slow_query_log%';+---------------------+-------------------------------------------------+| Variable_name       | Value                                           |+---------------------+-------------------------------------------------+| slow_query_log      | OFF                                             || slow_query_log_file | /var/lib/mysql/izwz920kp0myp15p982vp4z-slow.log |+---------------------+-------------------------------------------------+2 rows in set (0.01 sec)mysql> set global slow_query_log=1;Query OK, 0 rows affected (0.04 sec)mysql> show variables like '%slow_query_log%';+---------------------+-------------------------------------------------+| Variable_name       | Value                                           |+---------------------+-------------------------------------------------+| slow_query_log      | ON                                              || slow_query_log_file | /var/lib/mysql/izwz920kp0myp15p982vp4z-slow.log |+---------------------+-------------------------------------------------+2 rows in set (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>使用<code>set global slow_query_log=1</code>开启了慢查询日志只对当前数据库生效，如果MySQL重启后则会失效。如果要永久生效，就必须修改配置文件 <code>my.cnf</code>（其它系统变量也是如此）。</p></blockquote><p>那么开启了慢查询日志后，什么样的SQL才会记录到慢查询日志里面呢？ 这个是由参数 <code>long_query_time</code> 控制，默认情况下 <code>long_query_time</code> 的值为10秒，可以使用命令修改，也可以在 <code>my.cnf</code> 参数里面修改。关于运行时间正好等于 <code>long_query_time</code> 的情况，并不会被记录下来。也就是说，在 MySQL 源码里是判断大于 <code>long_query_time</code> ，而非大于等于。从 MySQL 5.1 开始， <code>long_query_time</code> 开始以微秒精度记录SQL语句运行时间，之前仅到秒的精度。如果记录到表里面，只会记录整数部分，不会记录微秒部分。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> show variables like '%long_query_time%';+-----------------+-----------+| Variable_name   | Value     |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+1 row in set (0.00 sec)mysql> set global long_query_time=1;Query OK, 0 rows affected (0.00 sec)mysql> show global variables like 'long_query_time';+-----------------+----------+| Variable_name   | Value    |+-----------------+----------+| long_query_time | 1.000000 |+-----------------+----------+1 row in set (0.00 sec)mysql> show variables like 'long_query_time';+-----------------+-----------+| Variable_name   | Value     |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+1 row in set (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个参数很奇怪，<code>set global</code> 之后使用 <code>show variables</code> 无法查询到修改后的变量值，使用 <code>show global variables</code> 才可以。退出当前会话重连之后使用 <code>show variables</code> 才能看到：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> show variables like 'long_query_time';+-----------------+----------+| Variable_name   | Value    |+-----------------+----------+| long_query_time | 1.000000 |+-----------------+----------+1 row in set (0.01 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但是上面的 <code>slow_log_query</code> 参数又是可以立刻看到的。</p><h2 id="查看慢查询"><a class="header-anchor" href="#查看慢查询">¶</a>查看慢查询</h2><p>在MySQL里面执行下面SQL语句</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select sleep(2);+----------+| sleep(2) |+----------+|        0 |+----------+1 row in set (2.04 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后我们去检查对应的慢查询日志，就会发现类似下面这样的信息。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z /]# more /var/lib/mysql/izwz920kp0myp15p982vp4z-slow.log/usr/sbin/mysqld, Version: 5.7.30-log (MySQL Community Server (GPL)). started with:Tcp port: 3306  Unix socket: /var/lib/mysql/mysql.sockTime                 Id Command    Argumentset global slow_query_log_file='/var/lib/mysql/izwz920kp0myp15p982vp4z-slow.log';# Time: 2020-10-03T00:57:21.183639Z# User@Host: root[root] @ localhost []  Id:   410# Query_time: 2.000210  Lock_time: 0.000000 Rows_sent: 1  Rows_examined: 0SET timestamp=1601686641;select sleep(2);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="日志分析工具mysqldumpslow"><a class="header-anchor" href="#日志分析工具mysqldumpslow">¶</a>日志分析工具mysqldumpslow</h2><p>在生产环境中，如果要手工分析日志，查找、分析SQL，显然是个体力活，MySQL提供了日志分析工具mysqldumpslow</p><p>查看mysqldumpslow的帮助信息：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">[root@izwz920kp0myp15p982vp4z ~]# mysqldumpslow --helpUsage: mysqldumpslow [ OPTS... ] [ LOGS... ]Parse and summarize the MySQL slow query log. Options are  --verbose    verbose  --debug      debug  --help       write this text to standard output  -v           verbose  -d           debug  -s ORDER     what to sort by (al, at, ar, c, l, r, t), 'at' is default                al: average lock time                ar: average rows sent                at: average query time                 c: count                 l: lock time                 r: rows sent                 t: query time  -r           reverse the sort order (largest last instead of first)  -t NUM       just show the top n queries  -a           don't abstract all numbers to N and strings to 'S'  -n NUM       abstract numbers with at least n digits within names  -g PATTERN   grep: only consider stmts that include this string  -h HOSTNAME  hostname of db server for *-slow.log filename (can be wildcard),               default is '*', i.e. match all  -i NAME      name of server instance (if using mysql.server startup script)  -l           don't subtract lock time from total time<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p><code>-s</code> 是表示按照何种方式排序：</p><ul><li>c：访问计数</li><li>l：锁定时间</li><li>r：返回记录</li><li>t：查询时间</li><li>al：平均锁定时间</li><li>ar：平均返回记录数</li><li>at：平均查询时间</li></ul></li><li><p><code>-t</code>：是top n的意思，即为返回前面多少条的数据；</p></li><li><p><code>-g</code>： 后边可以写一个正则匹配模式，大小写不敏感的；</p></li></ul><p>示例：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"># 得到返回记录集最多的10个SQL。mysqldumpslow -s r -t 10 /database/mysql/mysql06_slow.log# 得到访问次数最多的10个SQLmysqldumpslow -s c -t 10 /database/mysql/mysql06_slow.log# 得到按照时间排序的前10条里面含有左连接的查询语句。mysqldumpslow -s t -t 10 -g “left join” /database/mysql/mysql06_slow.log# 另外建议在使用这些命令时结合 | 和more 使用 ，否则有可能出现刷屏的情况。mysqldumpslow -s r -t 20 /mysqldata/mysql/mysql06-slow.log | more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1>十一、给字符串字段加索引</h1><p>假设，有一个支持邮箱登录的系统，用户表是这么定义的：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> create table SUser(ID bigint unsigned primary key,email varchar(64), ... )engine=innodb; <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select f1, f2 from SUser where email='xxx';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果 email 这个字段上没有索引，那么这个语句就只能做全表扫描。同时，MySQL 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。</p><h2 id="前缀索引"><a class="header-anchor" href="#前缀索引">¶</a>前缀索引</h2><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> alter table SUser add index index1(email);-- 或mysql> alter table SUser add index index2(email(6));<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>第一个语句创建的 index1 索引里面，包含了每个记录的整个字符串；而第二个语句创建的 index2 索引里面，对于每个记录都是只取前 6 个字节，这就是前缀索引。<strong>注意，只要在定义索引的时候对一个字段使用了括号进行长度定义，无论长度是否大于等于该字段的长度，都会被定义为前缀索引，这会对覆盖索引产生影响</strong>。以下是两种索引结构图：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132702.jpg" alt="email 索引结构"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132709.jpg" alt="email(6) 索引结构"></p><h2 id="前缀索引的优势"><a class="header-anchor" href="#前缀索引的优势">¶</a>前缀索引的优势</h2><p>从图中可以看到，由于 email(6) 这个索引结构中每个邮箱字段都只取前 6 个字节（即：zhangs），所以<strong>占用的空间会更小</strong>，这就是使用前缀索引的优势。</p><h2 id="前缀索引的劣势"><a class="header-anchor" href="#前缀索引的劣势">¶</a>前缀索引的劣势</h2><h3 id="增加回表扫描行数"><a class="header-anchor" href="#增加回表扫描行数">¶</a>增加回表扫描行数</h3><p>但，这同时带来的损失是，<strong>可能会增加额外的记录扫描次数</strong>。接下来，再看看下面这个语句，在这两个索引定义下分别是怎么执行的。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select id,name,email from SUser where email='zhangssxyz@xxx.com';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li><p>如果使用的是 index1（即 email 整个字符串的索引结构），执行顺序是这样的：</p><ol><li>从 index1 索引树找到满足索引值是’zhangssxyz@xxx.com’的这条记录，取得 ID2 的值；</li><li>到主键上查到主键值是 ID2 的行，判断 email 的值是正确的，将这行记录加入结果集；</li><li>取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足 email='zhangssxyz@xxx.com’的条件了，循环结束。</li></ol><p>这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。</p></li><li><p>如果使用的是 index2（即 email(6) 索引结构），执行顺序是这样的：</p><ol><li>从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 ID1；</li><li>到主键上查到主键值是 ID1 的行，判断出 email 的值不是’zhangssxyz@xxx.com’，这行记录丢弃；</li><li>取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 ID2，再到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集；</li><li>重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束。</li></ol><p>在这个过程中，要回主键索引取 4 次数据，也就是扫描了 4 行。</p></li></ul><h3 id="前缀索引对覆盖索引的影响"><a class="header-anchor" href="#前缀索引对覆盖索引的影响">¶</a>前缀索引对覆盖索引的影响</h3><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select id,email from SUser where email='zhangssxyz@xxx.com';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个语句只要求返回 id 和 email 字段。所以，如果使用 index1（即 email 整个字符串的索引结构）的话，可以利用覆盖索引，从 index1 查到结果后直接就返回了，不需要回到 ID 索引再去查一次。</p><p>而如果使用 index2（即 email(6) 索引结构）的话，就不得不回到 ID 索引再去判断 email 字段的值。<strong>即使你将 index2 的定义修改为 email(18) 的前缀索引，这时候虽然 index2 已经包含了所有的信息，但 InnoDB 还是要回到 id 索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息</strong>。</p><p>也就是说，<strong>使用前缀索引就用不上覆盖索引对查询性能的优化了</strong>，这也是你在选择是否使用前缀索引时需要考虑的一个因素。</p><h2 id="如何给长字符串定义好索引"><a class="header-anchor" href="#如何给长字符串定义好索引">¶</a>如何给长字符串定义好索引</h2><h3 id="定义前缀索引并指定一个好长度"><a class="header-anchor" href="#定义前缀索引并指定一个好长度">¶</a>定义前缀索引并指定一个好长度</h3><p>前面回表扫描行数的例子提到使用前缀索引后，可能会<strong>导致查询语句读数据的次数变多</strong>。但是，对于该查询语句来说，如果定义的 index2 不是 email(6) 而是 email(7），也就是说取 email 字段的前 7 个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到 ID2，只扫描一行就结束了。<strong>也就是说使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。</strong></p><p>当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。</p><ol><li><p>首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select count(distinct email) as L from SUser;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>然后，依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select   count(distinct left(email,4)）as L4,  count(distinct left(email,5)）as L5,  count(distinct left(email,6)）as L6,  count(distinct left(email,7)）as L7,from SUser;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6。</p></li></ol><h3 id="其他方式"><a class="header-anchor" href="#其他方式">¶</a>其他方式</h3><p>对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时，我们要怎么办呢？比如，我们国家的身份证号，一共 18 位，其中前 6 位是地址码，所以同一个县的人的身份证号前 6 位一般会是相同的。假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为 6 的前缀索引的话，这个索引的区分度就非常低了。</p><p>按照我们前面说的方法，可能你需要创建长度为 12 以上的前缀索引，才能够满足区分度要求。但是，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。答案是，有的。</p><h4 id="1-字符串倒叙加前缀索引"><a class="header-anchor" href="#1-字符串倒叙加前缀索引">¶</a>1.字符串倒叙加前缀索引</h4><p>如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select field_list from t where id_card = reverse('input_id_card_string');<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>由于身份证号的最后 6 位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了足够的区分度。当然了，实践中你不要忘记使用 count(distinct) 方法去做个验证。</p><h4 id="2-添加一个字符串的hash字段并在hash字段上加索引"><a class="header-anchor" href="#2-添加一个字符串的hash字段并在hash字段上加索引">¶</a>2.添加一个字符串的hash字段并在hash字段上加索引</h4><p>可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> alter table t add id_card_crc int unsigned, add index(id_card_crc);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同(这个判断会在 hash 索引回表后在主键索引中进行判断，不会因为没有索引触发全表扫描)。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这样，索引的长度变成了 4 个字节，比原来小了很多。</p><h4 id="两者异同"><a class="header-anchor" href="#两者异同">¶</a>两者异同</h4><p>首先，它们的相同点是，<strong>都不支持范围查询</strong>。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在[ID_X, ID_Y]的所有市民了。同样地，hash 字段的方式也只能支持等值查询。</p><p>它们的区别，主要体现在以下三个方面：</p><ol><li>从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。</li><li>在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。</li><li>从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。</li></ol><h3 id="拆分字段"><a class="header-anchor" href="#拆分字段">¶</a>拆分字段</h3><p>如果这个字段和身份证一样是有区间的，且可以直到某个区间的区分度较高，可以将这个字段按照各区间的区分度不同拆分成多个字段，为区分度高的部分字段建立索引，也可以在保证存储空间占用小但是又能减少回表次数。</p><h2 id="问题：如何设计一个同一格式字符串字段的索引"><a class="header-anchor" href="#问题：如何设计一个同一格式字符串字段的索引">¶</a>问题：如何设计一个同一格式字符串字段的索引</h2><p>如果你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号 @gmail.com&quot;, 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。系统登录的时候都需要学生输入登录名和密码，验证正确后才能继续使用系统。就只考虑登录验证这个行为的话，你会怎么设计这个登录名的索引呢？</p><ol><li>根据业务量预估，一个学校每年预估2万新生，50年才100万记录，能节省多少空间，直接全字段索引。省去了开发转换及局限性风险</li><li>数据量上来后这里遇到瓶颈，就将&quot;@gmail.com&quot;去掉，单独将学号设计为一个 bigint 8个字节单独作为索引。</li><li>利用bitmap对学号进行压缩，假设一个学生的学号是 ‘20200517’，这是一个长度为 8 的字符串，以ascii 编码为例，这个字符串需要占据 8 个字节的空间。但是，你发现，这个字符串里面所有的内容都是数字，而一个数字有 10 种可能，也就是说，这个长度的学号最多有 10 ^ 8 种可能性，也就是一亿种可能性。在计算机中，使用 32 位二进制数就可以表示 2 ^ 32 种可能性，这个数字是远远大于一亿的，所以也就是说，你完全可以用 4 字节的内存存下这个学号的所有信息（所以你完全可以使用 int 进行存储）。所以，学号只有 一亿 种可能性，可将它转化成 2^32 进制进行存储。当然，只是最粗略的方法，可以设计一种方法，将这种受限的字符串压缩，这样就能减少存储空间的利用了。但是不建议这样做，这种操作可以将信息压缩到极致（实际上极值情况就和哈希有点像了），但是设计这种方法可能会增加复杂性，在数据规模没有达到极其庞大的底部，它带来的收益其实是有限的。</li></ol><h1>十二、MySQL 刷脏：数据库抖一下</h1><p>平时的工作中，不知道你有没有遇到过这样的场景，一条 SQL 语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。看上去，这就像是数据库“抖”了一下。</p><p>MySQL 在写入数据的时候利用了 WAL 优化，先写 redo log 并更新内存中的 page 就返回了。此时该页在内存中和磁盘中的数据是不一致的。<strong>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。</strong></p><p>所以平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。</p><h2 id="刷脏-flush-时机"><a class="header-anchor" href="#刷脏-flush-时机">¶</a>刷脏(flush)时机</h2><ol><li><p>InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132720.jpg" alt="redo log 状态图"></p><p>checkpoint 可不是随便往前修改一下位置就可以的。比如图中，把 checkpoint 位置从 CP 推进到 CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都 flush 到磁盘上。之后，图中从 write pos 到 CP’之间就是可以再写入的 redo log 的区域。</p></li><li><p>系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。那为什么不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿 redo log 出来恢复不就行了？这里其实是从性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：</p><ul><li>一种是内存里存在，内存里就肯定是正确的结果，直接返回；</li><li>另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。这样的效率最高。</li></ul></li><li><p>MySQL 认为系统“空闲”的时候。即使不空闲，也要见缝插针地找时间，只要有机会就刷一点“脏页”。</p></li><li><p>MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。</p></li></ol><h2 id="4种刷脏时机对性能的影响"><a class="header-anchor" href="#4种刷脏时机对性能的影响">¶</a>4种刷脏时机对性能的影响</h2><p>其中，第三种情况是属于 MySQL 空闲时的操作，这时系统没什么压力，而第四种场景是数据库本来就要关闭了。这两种情况下，你不会太关注“性能”问题。所以这里，我们主要来分析一下前两种场景下的性能问题。</p><ul><li><p>第一种是“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0。</p></li><li><p>第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：</p><ul><li>第一种是，还没有使用的；</li><li>第二种是，使用了并且是干净页；</li><li>第三种是，使用了并且是脏页。</li></ul><p>InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。<strong>这时候只能把最久不使用（LRU）的数据页从内存中淘汰掉</strong>：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。</p><blockquote><p>这里保有疑问，脏页的&quot;是否为脏&quot;的逻辑是由 redo log 中每行日志的序列号也就是 LSN (Log Sequence Number)实现的：</p><ul><li>Checkpoint 对象会记录 LSN，则小于该 LSN 的都是已经刷了的脏页。</li><li>而 buffer pool 中的 page 的头部中也会记录 LSN，表示修改当前 page 的最后操作在 redo log 中的 LSN。所以正常来说 page 的 LSN 如果小于 checkpoint 的 LSN，那么它肯定是 flush 了的。所以它是干净页。（如果系统宕机重启后还是会根据 redo log 重放 buffer pool 中的 page，LSN 也重新写入）</li></ul><p>对于脏页，除了 buffer pool 满了加载新脏页需要根据 LRU 淘汰脏页的其它三种情况，其实都可以理解为正常推进 checkpoint 的过程，所以可以保证 LSN 的有序推进，即 LSN 大于 checkpoint 中 LSN 的 page 肯定是脏页。但是这里 LRU 淘汰的脏页就不一样了，根据惯性语义最久不使用应该包含读，所以此时要淘汰的可能就不是 buffer pool 中 LSN 最小、checkpoint LSN + 1 的脏页了，那这里就有问题，此时要怎么处理呢？</p><ul><li>将小于该 LSN 的脏页也一起 flush 了？</li><li>还是有一个专门的地方记录大于 checkpoint 但是已经刷了的脏页？</li><li>还是说就不管这种情况，直接 flush 后就把该页淘汰，反正已经刷盘到数据文件了，数据不会丢失，就是后面 checkpoint 推进到当前 LSN 的时候会发生重复 flush？</li><li>还是说其实并不是按照最久不使用的淘汰策略的，而是最早被修改的脏页？</li></ul></blockquote></li></ul><p>所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：</p><ol><li>一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；</li><li>日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。</li></ol><p>所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。</p><h2 id="InnoDB-刷脏页的控制策略"><a class="header-anchor" href="#InnoDB-刷脏页的控制策略">¶</a>InnoDB 刷脏页的控制策略</h2><h3 id="告诉-InnoDB-主机的-IO-能力"><a class="header-anchor" href="#告诉-InnoDB-主机的-IO-能力">¶</a>告诉 InnoDB 主机的 IO 能力</h3><p>首先，你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快（另外，不只刷脏，应该也会和其它操作引发的磁盘 IO 有关）。这就要用到 <code>innodb_io_capacity</code> 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 <code>IOPS</code>。磁盘的 <code>IOPS</code> 可以通过 <code>fio</code> 这个工具来测试，下面的语句是用来测试磁盘随机读写的命令：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell"> fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>MySQL 5.7 默认值是 200，用上面命令查看了主要能力不是 IO 的 ecs 的 IOPS 在 950 左右。</p></blockquote><p>其实，因为没能正确地设置 <code>innodb_io_capacity</code> 参数，而导致的性能问题也比比皆是。之前，存在一个案例，一个数据库的性能有问题，说 <strong>MySQL 的写入速度很慢，TPS 很低，但是数据库主机的 IO 压力并不大</strong>。经过一番排查，发现罪魁祸首就是这个参数的设置出了问题。他的主机磁盘用的是 SSD，但是 <code>innodb_io_capacity</code> 的值设置的是 <code>300</code>。于是，InnoDB 认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。</p><p>虽然现在已经定义了“全力刷脏页”的行为，但平时总不能一直是全力刷吧？<strong>毕竟磁盘能力不能只用来刷脏页，还需要服务用户请求</strong>。所以接下来，还要配置 InnoDB 控制引擎按照“全力”的百分比来刷脏页。</p><h3 id="InnoDB-如何利用主机-IO-能力进行刷脏"><a class="header-anchor" href="#InnoDB-如何利用主机-IO-能力进行刷脏">¶</a>InnoDB 如何利用主机 IO 能力进行刷脏</h3><p>如果刷太慢，会出现什么情况？首先是内存脏页太多，其次是 redo log 写满。所以，InnoDB 的刷盘速度就是要参考这两个因素：<strong>一个是脏页比例，一个是 redo log 写盘速度</strong>。</p><p>InnoDB 会根据这两个因素先单独算出两个数字：</p><ul><li><p>参数 <code>innodb_max_dirty_pages_pct</code> 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字，计算这个数字的伪代码类似这样：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">F1(M){  if M>=innodb_max_dirty_pages_pct then      return 100;  return 100*M/innodb_max_dirty_pages_pct;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>脏页比例 M 是通过以下两个变量计算出来的：</p><ul><li><code>Innodb_buffer_pool_pages_dirty</code> ：buffer pool 中脏页数量</li><li><code>Innodb_buffer_pool_pages_total</code> ：buffer pool 中总页数。（举个例子，buffer pool size 是 16G 的时候，page 默认 16 K，缓存池就可以存储 100W 个 page）</li></ul><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';select @a/@b;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。F2(N) 算法比较复杂，你只要知道 N 越大，算出来的值越大就好了。</p></li></ul><p>然后，根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132730.png" alt="InnoDB 刷脏页速度策略"></p><p>所以，无论是查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了更新语句，都可能是造成从业务端感知到 MySQL“抖”了一下的原因。要尽量避免这种情况，你就要合理地设置 <code>innodb_io_capacity</code> 的值，并<strong>且平时要多关注脏页比例，不要让它经常接近 75%</strong>。</p><h3 id="InnoDB-脏页连坐策略"><a class="header-anchor" href="#InnoDB-脏页连坐策略">¶</a>InnoDB 脏页连坐策略</h3><p>一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。</p><p>在 InnoDB 中，<code>innodb_flush_neighbors</code> 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机 IO。机械硬盘的随机 IOPS 一般只有几百，相同的逻辑操作减少随机 IO 就意味着系统性能的大幅度提升。而如果使用的是 SSD 这类 IOPS 比较高的设备的话，我就建议你把 <code>innodb_flush_neighbors</code> 的值设置成 0。因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。在 MySQL 8.0 中，<code>innodb_flush_neighbors</code> 参数的默认值已经是 0 了。</p><h2 id="redo-log-设置过小导致频繁刷脏"><a class="header-anchor" href="#redo-log-设置过小导致频繁刷脏">¶</a>redo log 设置过小导致频繁刷脏</h2><p>一个内存配置为 128GB、<code>innodb_io_capacity</code> 设置为 20000 的大规格实例，正常会建议将 redo log 设置成 4 个 1GB 的文件。但如果你在配置的时候不慎将 redo log 设置成了 1 个 100M 的文件，会发生什么情况呢？</p><p>每次事务提交都要写 redo log，如果设置太小，很快就会被写满，也就是下面这个图的状态，这个“环”将很快被写满，write pos 一直追着 CP。这时候系统不得不停止所有更新，去推进 checkpoint。这时，你看到的现象就是磁盘压力很小，但是数据库出现间歇性的性能下跌。</p><blockquote><p>redo log 建议大小：如果是现在常见的几个 TB 的磁盘的话，就不要太小气了，直接将 redo log 设置为 4 个文件、每个文件 1GB 吧。</p></blockquote><h1>十三、页空洞：为什么表数据删掉一半，表文件大小不变</h1><p>是针对 MySQL 中应用最广泛的 InnoDB 引擎展开讨论。一个 InnoDB 表包含两部分，即：表结构定义和数据。在 MySQL 8.0 版本以前，表结构是存在以<code>.frm</code> 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结构定义放在系统数据表中了。因为表结构定义占用的空间很小，所以我们今天主要讨论的是<strong>表数据</strong>。</p><h2 id="开启innodb-file-per-table参数"><a class="header-anchor" href="#开启innodb-file-per-table参数">¶</a>开启<code>innodb_file_per_table</code>参数</h2><p><strong>表数据（就是索引）既可以存在共享表空间里，也可以是单独的文件</strong>。这个行为是由参数 <code>innodb_file_per_table</code> 控制的：</p><ul><li>这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；</li><li>这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 <code>.ibd</code> 为后缀的文件中。</li></ul><p>从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。</p><p>建议不论使用 MySQL 的哪个版本，都将这个值设置为 ON。</p><ul><li>因为，一个表单独存储为一个文件更容易管理，而且在<strong>你不需要这个表的时候，通过 <code>drop table</code> 命令，系统就会直接删除这个文件(drop table 直接将文件删除了。truncate = drop + create 文件)</strong>。</li><li><strong>而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。</strong></li></ul><p>所以，将 <code>innodb_file_per_table</code> 设置为 ON，是推荐做法，接下来的讨论都是基于这个设置展开的。</p><h2 id="页空洞问题"><a class="header-anchor" href="#页空洞问题">¶</a>页空洞问题</h2><p>我们在<strong>删除整个表的时候，可以使用 <code>drop table</code> 命令回收表空间。但是，我们遇到的更多的删除数据的场景是删除某些行</strong>，这时就遇到问题了：表中的数据被删除了，但是表空间却没有被回收。</p><h3 id="MySQL-的数据删除造成空洞"><a class="header-anchor" href="#MySQL-的数据删除造成空洞">¶</a>MySQL 的数据删除造成空洞</h3><p>参考 [前面关于优化器预估扫描行的逻辑中提到的](######MySQL 是如何删除数据的) ，删除数据不会真正把数据删除，而是将其标记为删除，而如果没有其它一致性视图在引用删除前数据，它就会被标记为可复用（以下讨论都建立再没有其它事务的前提下，所以删除即可复用）。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132739.png" alt="B+ 树索引示意图"></p><p>假设，我们要删掉 R4 这个记录，InnoDB 引擎只会把 R4 这个记录标记为删除。如果之后要再插<strong>入一个 ID 在 300 和 600 之间的记录</strong>时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。</p><p>InnoDB 的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，整个数据页就可以被复用了。但是，数据页的复用跟记录的复用是不同的。记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。<strong>但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了</strong>。而当整个页都是可复用的时候，会从 B+ 树里面摘掉，可以复用到任何位置。以上图为例，如果将数据页 page A 上的所有记录删除以后，page A 会被标记为可复用。这时候如果要插入一条 ID=50 的记录需要使用新页的时候，page A 是可以被复用的。</p><p><strong>如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用</strong>。</p><p>进一步地，如果我们用 delete 命令把整个表的数据删除呢？结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。 delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。</p><h3 id="插入更新数据也可能造成空洞"><a class="header-anchor" href="#插入更新数据也可能造成空洞">¶</a>插入更新数据也可能造成空洞</h3><p>实际上，不止是删除数据会造成空洞，插入数据也会。如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但<strong>如果数据是随机插入的，就可能造成索引的数据页分裂</strong>。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132746.png" alt="插入数据导致页分裂"></p><p>由于 page A 满了，再插入一个 ID 是 550 的数据时，就不得不再申请一个新的页面 page B 来保存数据了。页分裂完成后，page A 的末尾就留下了空洞（注意：实际上，可能不止 1 个记录的位置是空洞）。</p><p>另外，<strong>更新索引上的值，可以理解为删除一个旧的值，再插入一个新值（对于主键索引来说，更新操作不会删除再插入；但是二级索引就需要了，它要保持有序，所以要将该二级索引字段旧值所在页的行删除，然后将新值插入到所在页的行）</strong>。不难理解，这也是会造成空洞的。</p><h2 id="重建表"><a class="header-anchor" href="#重建表">¶</a>重建表</h2><p>经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。而重建表，就可以达到这样的目的。可以使用 <code>alter table A engine=InnoDB</code> 命令来重建表。</p><h3 id="MySQL-5-5-版本及之前"><a class="header-anchor" href="#MySQL-5-5-版本及之前">¶</a>MySQL 5.5 版本及之前</h3><p>新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。显然地，表 B 的主键索引更紧凑，数据页的利用率也更高。把表 B 作为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，交换表A、B的名字，删除旧表。从效果上看，就起到了收缩表 A 空间的作用。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132756.png" alt="重建表锁表 DDL"></p><p>显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失。因此，<strong>在整个 DDL （指的就是<code>alter table A engine=InnoDB</code>）过程中，表 A 被锁定，无法修改也无法读写。也就是说，这个 DDL 不是 Online 的</strong>。</p><h3 id="MySQL-5-6-版本及之后"><a class="header-anchor" href="#MySQL-5-6-版本及之后">¶</a>MySQL 5.6 版本及之后</h3><p>在 MySQL 5.6 版本开始引入了 Online DDL（[这里也有提到 online ddl](###MDL（metadata lock))），指的是执行特定 DDL 的过程中，允许对表进行读写数据。其中 <code>alter table A engine=InnoDB</code> 这条 DDL 也支持了 Online DDL。为了保证 “Onilne” 重建该表的过程可以写入数据且不丢失，需要对重建表流程做优化：</p><ol><li>建立一个临时文件，扫描表 A 主键的所有数据页；</li><li>用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；</li><li>生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；</li><li>临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；</li><li>用临时文件替换表 A 的数据文件。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132804.png" alt="Online DDL"></p><p>可以看到，不同之处在于，由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。对于一个大表来说，Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对业务来说，就可以认为是 Online 的。</p><h4 id="Online-和-inplace"><a class="header-anchor" href="#Online-和-inplace">¶</a>Online 和 inplace</h4><p>说到 Online，要再澄清一下它和另一个跟 DDL 有关的、容易混淆的概念 inplace 的区别。</p><p>5.5及5.6重建表的两个操作中，前者把表 A 中的数据导出来的存放位置叫作 tmp_table。这是一个临时表，是在 server 层创建的。后者根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，整个过程对它来说是透明的，所以是一个“原地”操作，这就是“inplace”名称的来源（<code>alter table A engine=InnoDB</code>语句也说明了引擎是 InnoDB，而该工作完全是 InnoDB 内部完成，即 <code>InnoDB inplace</code>）。</p><p>所以 <code>inplace</code> 也是要占用额外空间的，它和平常的数据结构算法中提到的原地算法不一样。</p><p>我们重建表的这个语句 <code>alter table t engine=InnoDB</code>，其实隐含的意思是：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">alter table t engine=innodb,ALGORITHM=inplace;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>即指定由 <code>InnoDB</code> 自己来完成这项工作。跟 inplace 对应的就是拷贝表的方式了，用法是：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">alter table t engine=innodb,ALGORITHM=copy;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>当你使用 <code>ALGORITHM=copy</code> 的时候，表示的是强制拷贝表，表示执行 5.5 之前的那个临时表复制流程。</p><p>需要注意的是，这里重建表的 DDL 虽然 inplace 是 online 的，但是不代表所有 inplace 的 DDL 都是可以 online 的。比如，如果要给 InnoDB 表的一个字段加全文索引，写法是：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">alter table t add FULLTEXT(field_name);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个 DDL 没有指定 <code>ALGORITHM</code>，所以默认也是 <code>inplace</code> 的，但是它会阻塞增删改操作，是不支持 Online 的。</p><h5 id="Online-和-inplace-的联系"><a class="header-anchor" href="#Online-和-inplace-的联系">¶</a>Online 和 inplace 的联系</h5><p>如果说这两个逻辑之间的关系是什么的话，可以概括为：</p><ol><li>DDL 过程如果是 Online 的，就一定是 inplace 的；</li><li>反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。</li></ol><h3 id="重建表需谨慎"><a class="header-anchor" href="#重建表需谨慎">¶</a>重建表需谨慎</h3><p>需要补充说明的是，上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。因此，如果是线上服务，要很小心地控制操作时间。如果想要比较安全的操作的话，推荐你使用 GitHub 开源的 gh-ost 来做。</p><h3 id="optimize-table、analyze-table和alter-table区别"><a class="header-anchor" href="#optimize-table、analyze-table和alter-table区别">¶</a><code>optimize table</code>、<code>analyze table</code>和<code>alter table</code>区别</h3><ul><li>从 MySQL 5.6 版本开始，<code>alter table t engine = InnoDB</code> 就是上面提到的 Online 流程；</li><li><code>analyze table t</code> 其实不是重建表，只是对表的索引信息做重新(正确)统计，没有修改数据，这个过程中加了 MDL 读锁；</li><li><code>optimize table t</code> 等于前两者操作之和。</li></ul><h2 id="收缩表空间却适得其反？"><a class="header-anchor" href="#收缩表空间却适得其反？">¶</a>收缩表空间却适得其反？</h2><p>假设现在有人碰到了一个“想要收缩表空间，结果适得其反”的情况，看上去是这样的：</p><ol><li>一个表 t 文件大小为 1TB；</li><li>对这个表执行 <code>alter table t engine=InnoDB;</code></li><li>发现执行完成后，空间不仅没变小，还稍微大了一点儿，比如变成了 1.01TB。</li></ol><p>如果这个表，本身就已经没有空洞的了，比如说刚刚做过一次重建表操作。所以没能整出多少剩余空间。</p><ul><li>在 DDL online 重新收缩的过程中，如果刚好有外部的 DML 在执行，这期间可能会引入一些新的空洞。</li><li>另外，在重建表的时候，InnoDB 不会把整张表占满，每个页留了 1/16 给后续的更新用。也就是说，其实重建表之后不是“最”紧凑的。</li></ul><blockquote><p><code>INFORMATION_SCHEMA.INNODB_BUFFER_PAGE</code> 这里面可以看到每个page的尺寸,如果离16KB很近,那就说明基本满了，基本没空洞。做个统计就行了。</p></blockquote><h1>十四、<code>count(*)</code></h1><h2 id="count-的实现方式"><a class="header-anchor" href="#count-的实现方式">¶</a><code>count(*)</code> 的实现方式</h2><p>在不同的 MySQL 引擎中，<code>count(*)</code> 有不同的实现方式。</p><ul><li><p>MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 <code>count(*)</code> 的时候会直接返回这个数，效率很高；</p></li><li><p>而 InnoDB 引擎就麻烦了，它执行 <code>count(*)</code> 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。当表中记录数越来越多的时候，计算一个表的总行数会越来越慢的原因。</p></li></ul><blockquote><p>这里需要注意的是，这里讨论的是没有过滤条件的 count(*)，如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的。</p></blockquote><h2 id="InnoDB-实现"><a class="header-anchor" href="#InnoDB-实现">¶</a>InnoDB 实现</h2><p>那为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于 <code>count(*)</code> 请求来说，InnoDB 只好把数据一行一行地读出依次判断（从当前版本一直沿着 undo log 寻找匹配 read view 的版本），可见的行才能够用于计算“基于这个查询”的表的总行数。</p><h2 id="InnoDB的优化"><a class="header-anchor" href="#InnoDB的优化">¶</a>InnoDB的优化</h2><p>当然，现在这个看上去笨笨的 MySQL，在执行 <code>count(*)</code> 操作的时候还是做了优化的。</p><p>InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 <code>count(*)</code> 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，<strong>MySQL 优化器会找到最小的那棵树来遍历</strong>。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。</p><h2 id="show-table-status-的table-rows和-explain对于全表扫描的预估扫描行"><a class="header-anchor" href="#show-table-status-的table-rows和-explain对于全表扫描的预估扫描行">¶</a><code>show table status</code> 的<code>table_rows</code>和 <code>explain</code>对于全表扫描的预估扫描行</h2><p>如果你用过 <code>show table status</code> 命令的话，就会发现这个命令的输出结果里面也有一个 <code>TABLE_ROWS</code> 用于显示这个表当前有多少行，这个命令执行挺快的，但是它不能代替 <code>count(*)</code> 。<code>explain</code> 中对于全表扫描的预估扫描行也是取的这个值。实际上，<code>TABLE_ROWS</code> 就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到 40% 到 50%。所以，<code>show table status</code> 命令显示的行数也不能直接使用。</p><h2 id="如何解决经常查询表行数的需求"><a class="header-anchor" href="#如何解决经常查询表行数的需求">¶</a>如何解决经常查询表行数的需求</h2><p>如果现在有一个页面<strong>经常</strong>要显示交易系统的操作记录总数，到底应该怎么办呢？答案是，我们只能自己计数，需要自己找一个地方，把操作记录表的行数存起来。</p><h3 id="用缓存系统保存计数"><a class="header-anchor" href="#用缓存系统保存计数">¶</a>用缓存系统保存计数</h3><p>用 Redis 存储缓存是最容易想到的做法，但是有以下要注意的：</p><ol><li><p>要保证持久性，缓存系统如果宕机或者重启后如何恢复。当然可以利用 Redis 本身的持久化机制实现，但问题是可能在宕机期间又有新数据写入了。所以需要到数据库里面单独执行一次 <code>count(*)</code> 获取真实的行数，再把这个值写回到 Redis 里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。</p></li><li><p>将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的。这是因为，在并发系统里面，同时使用 Redis 和 MySQL 两个中间件，它们之间终究不是同一个系统，数据库的新增数据行操作和 Redis 的计数操作不能保证原子性，所以很容易会出现不一致性读的问题，这就涉及到分布式事务的问题了。</p></li></ol><h3 id="在数据库保存计数"><a class="header-anchor" href="#在数据库保存计数">¶</a>在数据库保存计数</h3><p>其实就是利用 MySQL InnoDB 支持事务的特性，专门建一个表或者一个字段来存储行数，将新增数据行和计数加1的动作放在一个事务中进行，另外读取计数以及读取数据行也放在一个事务里面实现一致性读。</p><p>另外，需要注意的是，出于并发性能的考虑，<strong>在新增数据行的事务中，要先执行新增数据行，再更新计数，因为前者并发度较低，后者并发读较高，这样可以尽量降低行锁阻塞事务的概率</strong>。</p><h2 id="不同的-count-用法"><a class="header-anchor" href="#不同的-count-用法">¶</a>不同的 count 用法</h2><p><code>count(*)</code>、<code>count(主键 id)</code>、<code>count(字段)</code> 和 <code>count(1)</code> 等不同用法的性能，有哪些差别?</p><p>首先要弄清楚 <code>count()</code> 的语义。<code>count()</code> 是一个聚合函数，对于返回的结果集，一行行地判断，如果 <code>count</code> 函数的参数不是 <code>NULL</code>，累计值就加 1，否则不加。最后返回累计值。</p><p>所以，<code>count(*)</code>、<code>count(主键 id)</code> 和 <code>count(1)</code> 都表示返回<strong>满足条件</strong>的结果集的总行数；而 <code>count(字段）</code>，则表示返回<strong>满足条件的数据行里面</strong>，参数“字段”不为 <code>NULL</code> 的总个数。</p><p>至于分析性能差别的时候，可以记住这么几个原则：</p><ol><li>server 层要什么就给什么；</li><li>InnoDB 只给必要的值；</li><li>现在的优化器只优化了 <code>count(*)</code> 的语义为“取行数”，其他“显而易见”的优化并没有做。</li></ol><p>这是什么意思呢？接下来，我们就一个个地来看看。</p><p>对于 <code>count(主键 id)</code> 来说，InnoDB 引擎会遍历整张表，当然，它也做了优化，如果存在更小的二级索引，也会去检索该索引树而不是检索主键索引，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，因为可以知道这是一个主键，是不可能为空的，就直接按行累加。</p><p>对于 <code>count(1)</code> 来说，InnoDB 引擎遍历整张表，但不取值(Server层不会要值)。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。单看这两个用法的差别的话，你能对比出来，<code>count(1)</code> 执行得要比 <code>count(主键 id)</code> 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。</p><p>对于 <code>count(字段)</code> 来说：如果这个“字段”是定义为 <code>not null</code> 的话，一行行地从记录里面读出这个字段，根据 <code>not null</code> 约束可以直到该字段不能为 null，直接按行累加；如果这个“字段”定义允许为 <code>null</code>，那么执行的时候，知道有可能是 <code>null</code>，还要把值取出来再判断一下，不是 <code>null</code> 才累加。也就是前面的第一条原则，server 层要什么字段，InnoDB 就返回什么字段。</p><p>但是 <code>count(*)</code> 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。<code>count(*)</code> 的语义就是对所有的行进行计数，肯定不是 <code>null</code>，按行累加。看到这里，你一定会说，优化器就不能自己判断一下吗，主键 id 肯定非空啊，为什么不能按照 <code>count(*)</code> 来处理，多么简单的优化啊。当然，MySQL 专门针对这个语句进行优化，也不是不可以。但是这种需要专门优化的情况太多了，而且 MySQL 已经优化过 <code>count(*)</code> 了，你直接使用这种用法就可以了。</p><p>所以结论是：按照效率排序的话，<code>count(字段)</code>&lt;<code>count(主键 id)</code>&lt;<code>count(1)</code>≈<code>count(*)</code>，所以建议尽量使用 <code>count(*)</code></p><h1>十五、<code>order by</code></h1><h2 id="先导：例子-v4"><a class="header-anchor" href="#先导：例子-v4">¶</a>先导：例子</h2><p>在开发应用的时候，一定会经常碰到需要根据指定的字段排序来显示结果的需求。还是以我们前面举例用过的市民表为例，假设你要查询城市是“杭州”的所有人名字，并且按照姓名排序返回前 1000 个人的姓名、年龄。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t` (  `id` int(11) NOT NULL,  `city` varchar(16) NOT NULL,  `name` varchar(16) NOT NULL,  `age` int(11) NOT NULL,  `addr` varchar(128) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `city` (`city`)) ENGINE=InnoDB;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这时，SQL 语句可以这么写：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select city,name,age from t where city='杭州' order by name limit 1000  ;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下面来分析 MySQL 是如何执行 <code>order by</code> 的。</p><h2 id="全字段排序"><a class="header-anchor" href="#全字段排序">¶</a>全字段排序</h2><p>为避免全表扫描，我们需要在 city 字段加上索引。在 city 字段上创建索引之后，我们用 <code>explain</code> 命令来看看这个语句的执行情况。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> explain select city,name,age from t where city='杭州' order by name limit 1000;+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+---------------------------------------+| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref   | rows | filtered | Extra                                 |+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+---------------------------------------+|  1 | SIMPLE      | t     | NULL       | ref  | city          | city | 66      | const | 4000 |   100.00 | Using index condition; Using filesort |+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+---------------------------------------+1 row in set, 1 warning (0.14 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer，排序过程是在 Server 层进行的，申请的 sort_buffer 在排序完成后即归还系统。</p><h3 id="全字段排序流程"><a class="header-anchor" href="#全字段排序流程">¶</a>全字段排序流程</h3><p>为了说明这个 SQL 查询语句的执行过程，我们先来看一下 city 这个索引的示意图。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132818.png" alt="city 字段的索引示意图"></p><p>从图中可以看到，满足 city='杭州’条件的行，是从 ID_X 到 ID_(X+N) 的这些记录。通常情况下，这个语句执行流程如下所示 ：</p><ol><li>初始化 sort_buffer，确定放入 name、city、age 这三个字段；</li><li>从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；</li><li>到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；</li><li>从索引 city 取下一个记录的主键 id；</li><li>重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；</li><li>对 sort_buffer 中的数据按照字段 name 做快速排序；</li><li>按照排序结果取前 1000 行返回给客户端。</li></ol><p>暂且把这个排序过程，称为全字段排序，执行流程的示意图如下所示</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132825.jpg" alt="全字段排序"></p><h3 id="外部排序"><a class="header-anchor" href="#外部排序">¶</a>外部排序</h3><p>图中“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 <code>sort_buffer_size</code>。<code>sort_buffer_size</code>，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 <code>sort_buffer_size</code>，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。</p><h3 id="查看是否外部排序以及其它排序指标"><a class="header-anchor" href="#查看是否外部排序以及其它排序指标">¶</a>查看是否外部排序以及其它排序指标</h3><p>可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">/* 打开optimizer_trace，只对本线程有效 */SET optimizer_trace='enabled=on'; /* @a保存Innodb_rows_read的初始值 */select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';/* 执行语句 */select city, name,age from t where city='杭州' order by name limit 1000; /* 查看 OPTIMIZER_TRACE 输出 */SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G/* @b保存Innodb_rows_read的当前值 */select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';/* 计算Innodb_rows_read差值 */select @b-@a;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个方法是通过查看 <code>OPTIMIZER_TRACE</code> 的结果来确认的，可以从 <code>number_of_tmp_files</code> 中看到是否使用了临时文件。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132833.png" alt="全排序的 OPTIMIZER_TRACE 部分结果"></p><ul><li><p><code>number_of_tmp_files</code> 表示的是，排序过程中使用的临时文件数。为什么需要 12 个文件？内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，MySQL 将需要排序的数据分成 12 份，每一份单独排序后存在这些临时文件中。然后把这 12 个有序文件再合并成一个有序的大文件。如果 <code>sort_buffer_size</code> 超过了需要排序的数据量的大小，number_of_tmp_files 就是 0，表示排序可以直接在内存中完成；否则就需要放在临时文件中排序。<code>sort_buffer_size</code> 越小，需要分成的份数越多，<code>number_of_tmp_files</code> 的值就越大。</p></li><li><p>示例表<code>t</code>中有 4000 条满足 city='杭州’的记录，所以可以看到 <code>examined_rows</code>=4000，表示参与排序的行数是 4000 行。</p></li><li><p><code>sort_mode</code> 里面的 <code>packed_additional_fields</code> 的意思是，将所有查询要返回的字段都打包参与到了排序中，且排序过程对字符串做了“紧凑”处理。即使 <code>name</code> 字段的定义是 varchar(16)，在排序过程中还是要按照实际长度来分配空间的。</p></li><li><p>同时，最后一个查询语句 <code>select @b-@a</code> 的返回结果是 4000，表示整个执行过程只扫描了 4000 行</p></li></ul><blockquote><p>这里需要注意的是，为了避免对结论造成干扰，把 <code>internal_tmp_disk_storage_engine</code> 设置成 MyISAM。否则，<code>select @b-@a</code>的结果会显示为 4001。这是因为查询 <code>OPTIMIZER_TRACE</code> 这个表时，需要用到临时表，而 <code>internal_tmp_disk_storage_engine</code> 的默认值是 InnoDB。如果使用的是 InnoDB 引擎的话，把数据从临时表取出来的时候，会让 <code>Innodb_rows_read</code> 的值加 1。</p></blockquote><h2 id="rowid-排序"><a class="header-anchor" href="#rowid-排序">¶</a>rowid 排序</h2><p>在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的<strong>行数很少</strong>，要分成很多个临时文件，排序的性能会很差。</p><p>MySQL 通过参数 <code>max_length_for_sort_data</code> 来控制排序时单行数据可以接受的最大长度，如果在进行全字段排序的时候所有字段的长度加起来超过了这个阈值，就会采用 <strong>row id 排序</strong>的方式。</p><p><code>city</code>、<code>name</code>、<code>age</code> 这三个字段的定义总长度是 36，把 <code>max_length_for_sort_data</code> 设置为 16，我们再来看看计算过程有什么改变。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">SET max_length_for_sort_data = 16;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="row-id-排序流程"><a class="header-anchor" href="#row-id-排序流程">¶</a>row id 排序流程</h3><p>放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就变成如下所示的样子：</p><ol><li>初始化 sort_buffer，确定放入两个字段，即 name 和 id；</li><li>从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；</li><li>到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；</li><li>从索引 city 取下一个记录的主键 id；</li><li>重复步骤 3、4 直到不满足 city='杭州’条件为止，也就是图中的 ID_Y；</li><li>对 sort_buffer 中的数据按照字段 name 进行排序；</li><li>遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。</li></ol><p>这个执行流程的示意图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132840.jpg" alt="rowid 排序"></p><p>对比全字段排序流程图会发现，rowid 排序多访问了一次表 <code>t</code> 的主键索引，就是步骤 7。</p><blockquote><p>需要说明的是，最后的“结果集”是一个逻辑概念，实际上 MySQL 服务端从排序后的 sort_buffer 中依次取出 id，然后到原表查到 <code>city</code>、<code>name</code> 和 <code>age</code> 这三个字段的结果，不需要在服务端再耗费内存存储结果，是直接返回给客户端的（直接从主键索引内存页拷贝到网络IO缓存）。</p></blockquote><h3 id="查看是否外部排序以及其它排序指标-v2"><a class="header-anchor" href="#查看是否外部排序以及其它排序指标-v2">¶</a>查看是否外部排序以及其它排序指标</h3><p>图中的 <code>examined_rows</code> 的值还是 4000，表示用于排序的数据是 4000 行。但是 <code>select @b-@a</code> 这个语句的值变成 5000 了。因为这时候除了排序过程外，在排序完成后，还要根据 id 去原表取值。由于语句是 limit 1000，因此会多读 1000 行。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132847.png" alt="rowid 排序的 OPTIMIZER_TRACE 部分输出"></p><p>从 <code>OPTIMIZER_TRACE</code> 的结果中，还能看到另外两个信息也变了。</p><ul><li><code>sort_mode</code> 变成了 ，表示参与排序的只有 <code>name</code> 和 <code>id</code> 这两个字段。</li><li><code>number_of_tmp_files</code> 变成 10 了，是因为这时候参与排序的行数虽然仍然是 4000 行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。</li></ul><h2 id="全字段排序-VS-rowid-排序"><a class="header-anchor" href="#全字段排序-VS-rowid-排序">¶</a>全字段排序 VS rowid 排序</h2><p>如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。这也就体现了 MySQL 的一个设计思想：<strong>如果内存够，就要多利用内存，尽量减少磁盘访问</strong>。</p><blockquote><p>使用全字段排序会面临临时文件过多，也有磁盘访问的压力；使用 rowid 排序则有索引访问的压力。需要对比。但是，如果排序内存完全够全字段排序，那必然是使用全字段排序优先。</p></blockquote><p>对于 <strong>InnoDB 表来说，rowid 排序会要求回表多造成磁盘读(由于 InnoDB 是索引组织表且存储在磁盘中)</strong>，因此不会被优先选择。</p><h2 id="不用-order-by-也可以排序"><a class="header-anchor" href="#不用-order-by-也可以排序">¶</a>不用 <code>order by</code> 也可以排序</h2><p>所以 MySQL 做排序是一个成本比较高的操作。那么你会问，是不是所有的 <code>order by</code> 都需要排序操作呢？如果不排序就能得到正确的结果，那对系统的消耗会小很多，语句的执行时间也会变得更短。其实，并不是所有的 <code>order by</code> 语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。如果能够保证从 <code>city</code> 这个索引上取出来的行，天然就是按照 <code>name</code> 递增排序的话，就可以不用再排序。</p><p>可以在这个市民表上创建一个 city 和 name 的联合索引，对应的 SQL 语句是：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">alter table t add index city_user(city, name);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>作为与 city 索引的对比，我们来看看这个索引的示意图。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132854.png" alt="city 和 name 联合索引示意图"></p><p>在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足 city='杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是杭州，name 的值就一定是有序的。这样整个查询过程的流程就变成了：</p><ol><li>从索引 (city,name) 找到第一个满足 city='杭州’条件的主键 id；</li><li>到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；</li><li>从索引 (city,name) 取下一个记录主键 id；</li><li>重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132902.jpg" alt="引入 (city,name) 联合索引后，查询语句的执行计划"></p><p>可以看到，这个查询过程不需要临时表，也不需要排序。接下来，我们用 <code>explain</code> 的结果来印证一下。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> explain select city,name,age from t where city='杭州' order by name limit 1000  ;+----+-------------+-------+------------+------+----------------+-----------+---------+-------+------+----------+-----------------------+| id | select_type | table | partitions | type | possible_keys  | key       | key_len | ref   | rows | filtered | Extra                 |+----+-------------+-------+------------+------+----------------+-----------+---------+-------+------+----------+-----------------------+|  1 | SIMPLE      | t     | NULL       | ref  | city,city_user | city_user | 66      | const | 4000 |   100.00 | Using index condition |+----+-------------+-------+------------+------+----------------+-----------+---------+-------+------+----------+-----------------------+1 row in set, 1 warning (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从图中可以看到，Extra 字段中没有 Using filesort 了，也就是不需要排序了。而且由于 (city,name) 这个联合索引本身有序，所以这个查询也不用把 4000 行全都读一遍，只要找到满足条件的前 1000 条记录就可以退出了。也就是说，在我们这个例子里，只需要扫描 1000 次。</p><h3 id="对该-SQL-执行的进一步优化"><a class="header-anchor" href="#对该-SQL-执行的进一步优化">¶</a>对该 SQL 执行的进一步优化</h3><p>按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程。针对这个查询，我们可以创建一个 <code>city</code>、<code>name</code> 和 <code>age</code> 的联合索引，对应的 SQL 语句就是：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">alter table t add index city_user_age(city, name, age);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这时，对于 <code>city</code> 字段的值相同的行来说，还是按照 <code>name</code> 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了：</p><ol><li>从索引 (city,name,age) 找到第一个满足 city='杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；</li><li>从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；</li><li>重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132908.jpg" alt="引入 (city,name,age) 联合索引后，查询语句的执行流程"></p><p>再来看看 <code>explain</code> 的结果：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> explain select city,name,age from t where city='杭州' order by name limit 1000  ;+----+-------------+-------+------------+------+------------------------------+--------------+---------+-------+------+----------+--------------------------+| id | select_type | table | partitions | type | possible_keys                | key          | key_len | ref   | rows | filtered | Extra                    |+----+-------------+-------+------------+------+------------------------------+--------------+---------+-------+------+----------+--------------------------+|  1 | SIMPLE      | t     | NULL       | ref  | city,city_user,city_user_age | city_user_age| 66      | const | 4000 |   100.00 | Using where; Using index |+----+-------------+-------+------------+------+------------------------------+--------------+---------+-------+------+----------+--------------------------+1 row in set, 1 warning (0.03 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，Extra 字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。</p><h2 id="单纯给-order-by-字段加索引是否可以加速"><a class="header-anchor" href="#单纯给-order-by-字段加索引是否可以加速">¶</a>单纯给 <code>order by</code> 字段加索引是否可以加速</h2><p>上面的例子中，<code>select</code> SQL 是有条件子句 <code>where</code> 的，且 <code>where</code> 中的条件字段 <code>city</code> 本身就有了索引，所以该查询语句必然会去检索这个二级索引，然后再回表检索，此时我们给 <code>order by</code> 字段与 <code>city</code> 字段建立联合索引，才能避免排序。但是如果 SQL 本身就没有 <code>where</code> 子句，或者说 <code>where</code> 子句中的字段不能加索引，此时单独对 <code>order by</code> 字段建立索引，是否可以避免排序起到加速的效果呢？看下面例子：</p><p>有个页面，需要按数据插入时间 <code>create_time</code> 倒序来查看一张记录表的信息 ，因为除了分页的参数 ， 没有其他 where 的条件 ，所以除了主键外没有其他索引 。这时候给 <code>create_time</code> 创建索引， 查询会利用这个二级索引增快吗？</p><ol><li><p>无 <code>where</code> 条件，只有 <code>order by create_time</code>，<strong>即便 <code>create_time</code> 上有索引，也不会使用到</strong>。因为优化器认为走二级索引再去回表成本比直接全表扫描出来进行排序成本更高</p><blockquote><p>个人认为也是的，先遍历一遍二级索引树得到主键值然后一遍遍回表检索，此时每一遍都要从主键索引树根到叶子节点的检索过程，更糟糕的是如果相对主键索引顺序较散乱还可能导致主键索引中的一个 page 要从磁盘加载多次才能访问完它里面的所有数据行；</p><p>如果是全表扫描，直接将叶子节点一个个加载出来就行了。</p><p>相对来说，时间复杂度应该是前者更高的。</p></blockquote></li><li><p>无 <code>where</code> 条件，但是 <code>order by create_time limit m</code>，如果 m 值较小，是可以走索引的。</p><ul><li>此时 m 值较小，需要回表的动作就不多，相对来说，此时排序的成本又上去了，走全表扫描是要对全表进行排序的，所以优化器此时会选择走二级索引，这时候就可以利用这个二级索引避免排序了</li><li>即使没有二级索引，MySQL 针对 <code>order by limit</code> 也做了优化，采用堆排序。</li></ul></li><li><p>如果查询子句 <code>select</code> 中要查询的字段只有 <code>create_time</code>，或者说和 <code>create_time</code> 都在一个联合索引以内，那么因为覆盖索引的原因有无 <code>limit</code> 都可以走这个二级索引，因此优化器认为此时是无需回表的，这时候也可以利用这个二级索引避免排序了。但是在此例中不成立，<code>select</code> 中要查询的字段肯定不只有 <code>create_time</code>。</p></li></ol><p>总的来说，如果分析出来 SQL <strong>需要回表且回表行数过多，优化器就不会走二级索引，而是主键索引全表扫描</strong>，这个不只对 <code>order by</code> 字段有效，对于 <code>where</code> 字段同样有效。</p><h2 id="在联合索引上使用了范围查询导致不能避免排序"><a class="header-anchor" href="#在联合索引上使用了范围查询导致不能避免排序">¶</a>在联合索引上使用了范围查询导致不能避免排序</h2><p>假设你的表里面已经有了 city_name(city, name) 这个联合索引，然后你要查杭州和苏州两个城市中所有的市民的姓名，并且按名字排序，显示前 100 条记录。如果 SQL 查询语句是这么写的 ：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from t where city in ('杭州',"苏州") order by name limit 100;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>那么，这个语句执行的时候会有排序过程吗，为什么？如果业务端代码由你来开发，需要实现一个在数据库端不需要排序的方案，你会怎么实现呢？进一步地，如果有分页需求，要显示第 101 页，也就是说语句最后要改成 “limit 10000,100”， 你的实现方法又会是什么呢？</p><p>虽然有 (city,name) 联合索引，对于单个 city 内部，name 是递增的。但是由于这条 SQL 语句不是要单独地查一个 city 的值，而是同时查了&quot;杭州&quot;和&quot; 苏州 &quot;两个城市，因此所有满足条件的 name 就不是递增的了。也就是说，这条 SQL 语句需要排序。</p><p>那怎么避免排序呢？</p><p>这里，我们要用到 (city,name) 联合索引的特性，把这一条语句拆成两条语句，执行流程如下：</p><ol><li>执行 <code>select * from t where city=“杭州” order by name limit 100;</code> 这个语句是不需要排序的，客户端用一个长度为 100 的内存数组 A 保存结果。</li><li>执行 <code>select * from t where city=“苏州” order by name limit 100;</code> 用相同的方法，假设结果被存进了内存数组 B。</li><li>现在 A 和 B 是两个有序数组，然后你可以用归并排序的思想，得到 name 最小的前 100 值，就是我们需要的结果了。</li></ol><p>如果把这条 SQL 语句里“limit 100”改成“limit 10000,100”的话，处理方式其实也差不多，即：要把上面的两条语句改成写：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from t where city="杭州" order by name limit 10100; select * from t where city="苏州" order by name limit 10100;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这时候数据量较大，可以同时起两个连接一行行读结果，用归并排序算法拿到这两个结果集里，按顺序取第 10001~10100 的 name 值，就是需要的结果了。当然这个方案有一个明显的损失，就是从数据库返回给客户端的数据量变大了。所以，如果数据的单行比较大的话，可以考虑把这两条 SQL 语句改成下面这种写法：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select id, name from t where city="杭州" order by name limit 10100; select id, name from t where city="苏州" order by name limit 10100;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后，再用归并排序的方法取得按 name 顺序第 10001~10100 的 name、id 的值，然后拿着这 100 个 id 到数据库中去查出所有记录。</p><p>上面这些方法，需要你根据性能需求和开发的复杂度做出权衡。</p><h2 id="MySQL-类型后面的括号"><a class="header-anchor" href="#MySQL-类型后面的括号">¶</a>MySQL 类型后面的括号</h2><p><code>bigint</code> 和 <code>int</code> 后面圆括号括住一个数字不会对可以存储的内容的大小产生影响。以 <code>bigint</code> 为例，<code>bigint(1)</code> 和 <code>bigint(19)</code> 都能存储 2^64-1 范围内的值。<code>int </code>是2^32-1。括号里面的值目前是被客户端用来对该字段的内容显示的时候进行截取的长度，例如<code>bigint(1)</code> 只显示 1 位数字。</p><h1>十六、随机排序和临时表</h1><p>一个英语学习 App 首页有一个随机显示单词的功能，也就是根据每个用户的级别有一个单词表，然后这个用户每次访问首页的时候，都会随机滚动显示三个单词。但是随着单词表变大，选单词这个逻辑变得越来越慢，甚至影响到了首页的打开速度。现在，如果让你来设计这个 SQL 语句，你会怎么写呢？</p><p>为了便于理解，对这个例子进行了简化：去掉每个级别的用户都有一个对应的单词表这个逻辑，直接就是从一个单词表中随机选出三个单词。这个表的建表语句和初始数据的命令如下：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> CREATE TABLE `words` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `word` varchar(64) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB;delimiter ;;create procedure idata()begin  declare i int;  set i=0;  while i<10000 do    insert into words(word) values(concat(char(97+(i div 1000)), char(97+(i % 1000 div 100)), char(97+(i % 100 div 10)), char(97+(i % 10))));    set i=i+1;  end while;end;;delimiter ;call idata();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为了便于量化说明，我在这个表里面插入了 10000 行记录。接下来，一起看看要随机选择 3 个单词，有什么方法实现，存在什么问题以及如何改进。</p><h2 id="order-by-rand"><a class="header-anchor" href="#order-by-rand">¶</a><code>order by rand()</code></h2><p>首先会想到用 <code>order by rand()</code> 来实现这个逻辑。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select word from words order by rand() limit 3;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p><code>select</code> 对于每行数据调用一次 <code>rand()</code> 函数获得一个随机值，根据随机值排序，取前三行的 <code>word</code> 字段进行返回。</p></blockquote><h3 id="内存临时表"><a class="header-anchor" href="#内存临时表">¶</a>内存临时表</h3><p>查看 <code>explain</code> 执行计划：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> explain select word from words order by rand() limit 3;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------+| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                           |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------+|  1 | SIMPLE      | words | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 9980 |   100.00 | Using temporary; Using filesort |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------+1 row in set, 1 warning (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Extra 字段显示 Using temporary，表示的是需要使用临时表；Using filesort，表示的是需要执行排序操作。因此这个 Extra 的意思就是，需要建立临时表，并且需要对建立的临时表上排序。</p><h4 id="rowid-排序策略"><a class="header-anchor" href="#rowid-排序策略">¶</a>rowid 排序策略</h4><p>MySQL 的排序策略有两种：全字段排序和 row id 排序。</p><ul><li>对于 <strong>InnoDB 表</strong>来说，执行全字段排序会减少磁盘访问，因此会被优先选择。</li><li>对于<strong>内存表</strong>，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。所以针对内存表优化器没有了磁盘访问的顾虑。那么此时它会优先考虑的，就是<strong>用于排序的行越小越好</strong>了，所以，MySQL 这时就会选择 rowid 排序。</li></ul><h4 id="执行流程"><a class="header-anchor" href="#执行流程">¶</a>执行流程</h4><p>理解了排序策略选择的逻辑，再来看看语句的执行流程。同时，通过这个例子，尝试分析一下语句的扫描行数（实际扫描行数，不是执行计划里面的预估计扫描行数）。</p><p>这条语句的执行流程是这样的：</p><ol><li>创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。</li><li>并且，这个表没有建索引。从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，<strong>扫描行数是 10000</strong>。</li><li>现在临时表有 10000 行数据了，接下来要在这个没有索引的内存临时表上，按照字段 R 排序。</li><li>初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型(存储随机函数值的字段 R)，另一个是整型(存储 memory 表中行的唯一标识)。</li><li>从内存临时表中一行一行地取出 R 值和位置信息<sup class="footnote-ref"><a href="#fn15" id="fnref15">[15]</a></sup>，分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，<strong>此时扫描行数增加 10000，变成了 20000</strong>。</li><li>在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。</li><li>排序完成后，取出前三个结果的位置信息<sup class="footnote-ref"><a href="#fn15" id="fnref15:1">[15:1]</a></sup>，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，<strong>总扫描行数变成了 20003。</strong></li></ol><p>过慢查询日志（slow log）来验证一下我们分析得到的扫描行数是否正确。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql"># Query_time: 0.900376  Lock_time: 0.000347 Rows_sent: 3 Rows_examined: 20003SET timestamp=1541402277;select word from words order by rand() limit 3;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>其中，Rows_examined：20003 就表示这个语句执行过程中扫描了 20003 行，也就验证了分析得出的结论。</p><p>完整的排序执行流程图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132919.png" alt="随机排序完整流程图1"></p><h3 id="磁盘临时表"><a class="header-anchor" href="#磁盘临时表">¶</a>磁盘临时表</h3><p>那么，是不是所有的临时表都是内存表呢？其实不是的。<code>tmp_table_size</code> 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 <code>tmp_table_size</code>，那么内存临时表就会转成磁盘临时表。磁盘临时表使用的引擎默认是 InnoDB，是由参数 <code>internal_tmp_disk_storage_engine</code> 控制的。当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。</p><p>为了复现这个过程，把 <code>tmp_table_size</code> 设置成 1024，把 <code>sort_buffer_size</code> 设置成 32768, 把 <code>max_length_for_sort_data</code> 设置成 16。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">set tmp_table_size=1024;set sort_buffer_size=32768;set max_length_for_sort_data=16;/* 打开 optimizer_trace，只对本线程有效 */SET optimizer_trace='enabled=on'; /* 执行语句 */select word from words order by rand() limit 3;/* 查看 OPTIMIZER_TRACE 输出 */SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132928.png" alt="OPTIMIZER_TRACE 部分结果"></p><p>然后，看一下这次 OPTIMIZER_TRACE 的结果。因为将 <code>max_length_for_sort_data</code> 设置成 16，小于 word 字段的长度定义，所以我们看到 <code>sort_mode</code> 里面显示的是 rowid 排序，这个是符合预期的，参与排序的是随机值 R 字段和 rowid 字段组成的行。</p><h4 id="排序算法：堆排序-VS-快速排序"><a class="header-anchor" href="#排序算法：堆排序-VS-快速排序">¶</a>排序算法：堆排序 VS 快速排序</h4><p>对于上面的 OPTIMIZER_TRACE 的结果。R 字段存放的随机值就 8 个字节，rowid 是 6 个字节（如果一个 InnoDB 表中没有主键或者主键删掉了，就会默认生成一个 6 个字节的 row id 字段作为主键），数据总行数是 10000，这样算出来就有 140000 字节，超过了 <code>sort_buffer_size</code> 定义的 32768 字节了。但是，<code>number_of_tmp_files</code> 的值居然是 0，难道不需要用临时文件吗？</p><p>这个 SQL 语句的排序确实没有用到临时文件，采用是 MySQL 5.6 版本引入的一个新的排序算法，即：优先队列排序算法。接下来，我们就看看为什么没有使用临时文件的算法，也就是归并排序算法，而是采用了<strong>优先队列排序算法（其实就是堆排序）</strong>。</p><p>其实，我们现在的 SQL 语句，只需要取 R 值最小的 3 个 rowid。但是，如果使用**归并排序算法(其实是快排，快排比堆排序更占空间)**的话，虽然最终也能得到前 3 个值，但是这个算法结束后，已经将 10000 行数据都排好序了。也就是说，后面的 9997 行也是有序的了。但，我们的查询并不需要这些数据是有序的。所以，想一下就明白了，这浪费了非常多的计算量。</p><p>而优先队列排序算法，就可以精确地只得到三个最小值，执行流程如下：</p><ol><li>对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；</li><li>取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；</li><li>重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132936.png" alt="优先队列排序算法示例"></p><p>上图是模拟 6 个 (R,rowid) 行，通过优先队列排序算法找到最小的三个 R 值的行的过程。整个排序过程中，为了最快地拿到当前堆的最大值，总是保持最大值在堆顶，因此这是一个最大堆。前面的 OPTIMIZER_TRACE 结果中，<code>filesort_priority_queue_optimization</code> 这个部分的 <code>chosen=true</code>，就表示使用了优先队列排序算法，这个过程不需要临时文件，因此对应的 <code>number_of_tmp_files</code> 是 0。</p><blockquote><p>总结：这里之所以会用到优先队列算法，是因为</p><ul><li>MySQL 识别到了 limit 3 的需求，直到最终只需要 3 行最小数据，而不是需要全表数据都返回</li><li>定义的 <code>sort_buffer_size</code> 完全可以满足 3 行数据堆排序过程的内存占用；否则需要分批进行归并排序，对堆排序做归并较复杂且成本也较高，将会转成快排+归并。</li></ul><p>所以除了这里的临时表，我们自己定义的表在使用 <code>order by</code> 的时候也可以利用这两点：</p><ul><li>如果可以，尽量 <code>limit</code> 一个较小的数量</li><li>将 <code>sort_buffer_size</code> 尽量设置大一点</li></ul></blockquote><h3 id="小结-v4"><a class="header-anchor" href="#小结-v4">¶</a>小结</h3><p>总之，不论是使用哪种类型的临时表，<code>order by rand()</code> 这种写法都会让计算过程非常复杂，需要大量的扫描行数，因此排序过程的资源消耗也会很大。</p><h2 id="其它随机排序方法"><a class="header-anchor" href="#其它随机排序方法">¶</a>其它随机排序方法</h2><h3 id="随机算法-1"><a class="header-anchor" href="#随机算法-1">¶</a>随机算法 1</h3><p>先把问题简化一下，如果只随机选择 1 个 word 值，可以怎么做呢？思路上是这样的：</p><ol><li>取得这个表的主键 id 的最大值 M 和最小值 N;</li><li>用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N;</li><li>取不小于 X 的第一个 ID 的行。</li></ol><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select max(id),min(id) into @M,@N from t ;set @X= floor((@M-@N+1)*rand() + @N);select * from t where id >= @X limit 1;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li><p>优点</p><p>这个方法效率很高，因为取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的 select 也可以用索引快速定位，可以认为就只扫描了 3 行。</p></li><li><p>缺点</p><p>但实际上，这个算法本身并不严格满足题目的随机要求，因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。比如你有 4 个 id，分别是 1、2、4、5，如果按照上面的方法，那么取到 id=4 的这一行的概率是取得其他行概率的两倍。如果这四行的 id 分别是 1、2、40000、40001 呢？这个算法基本就能当 bug 来看待了。</p></li></ul><h3 id="随机算法-2"><a class="header-anchor" href="#随机算法-2">¶</a>随机算法 2</h3><p><code>rand()</code> 函数返回的是一个小数，直接乘以表行数并取整就可以得到一个比较随机的 id：</p><ol><li>取得整个表的行数，并记为 C。</li><li>取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。</li><li>再用 limit Y,1 取得一行。</li></ol><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select count(*) into @C from t;set @Y = floor(@C * rand());set @sql = concat("select * from t limit ", @Y, ",1");prepare stmt from @sql;execute stmt;DEALLOCATE prepare stmt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>MySQL 处理 limit Y,1 的做法就是按顺序一个一个地读出来，丢掉前 Y 个，然后把下一个记录作为返回结果，因此这一步需要扫描 Y+1 行。再加上，第一步扫描的 C 行，<strong>总共需要扫描 C+Y+1 行，执行代价比随机算法 1 的代价要高</strong>。当然，随机算法 2 跟直接 <code>order by rand()</code> 比起来，执行代价还是小很多的。(为什么都得到一个 id 了，还要 limit 呢？因为大于最小 id、小于最大 id 不一定是一个有效 id，首先你要保证 id 是自增的，而且没有删除过数据)</p><blockquote><p><code>order by rand()</code>：</p><ol><li>要构建临时表</li><li>构建完成后还需要按照 <code>rand()</code>字段排序</li><li>如果使用的是快排需要对全表排序；优先队列排序还快一点</li></ol><p>随机算法2：直接根据有序的主键索引扫描到 <code>limit</code> 行即可。</p></blockquote><h3 id="随机算法-3"><a class="header-anchor" href="#随机算法-3">¶</a>随机算法 3</h3><p>如果我们按照随机算法 2 的思路，要随机取 3 个 word 值呢？</p><ol><li>取得整个表的行数，记为 C；</li><li>根据相同的随机方法得到 Y1、Y2、Y3；</li><li>再执行三个 limit Y, 1 语句得到三行数据。</li></ol><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select count(*) into @C from t;set @Y1 = floor(@C * rand());set @Y2 = floor(@C * rand());set @Y3 = floor(@C * rand());select * from t limit @Y1，1； //在应用代码里面取Y1、Y2、Y3值，拼出SQL后执行select * from t limit @Y2，1；select * from t limit @Y3，1；<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="随机算法-4"><a class="header-anchor" href="#随机算法-4">¶</a>随机算法 4</h3><p>上面的随机算法 3 的总扫描行数是 C+(Y1+1)+(Y2+1)+(Y3+1)，实际上它还是可以继续优化，来进一步减少扫描行数的。取 Y1、Y2 和 Y3 里面最大的一个数，记为 M，最小的一个数记为 N，然后执行下面这条 SQL 语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from t limit N, M-N+1;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>再加上取整个表总行数的 C 行，这个方案的扫描行数总共只需要 C+M+1 行。</p><h1>十七、&quot;有索引但是很慢&quot;的场景示例</h1><h2 id="案例一：条件字段函数操作"><a class="header-anchor" href="#案例一：条件字段函数操作">¶</a>案例一：条件字段函数操作</h2><p>假设现在维护了一个交易系统，其中交易记录表 tradelog 包含交易流水号（tradeid）、交易员 id（operator）、交易时间（t_modified）等字段。为了便于描述，我们先忽略其他字段。这个表的建表语句如下：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> CREATE TABLE `tradelog` (  `id` int(11) NOT NULL,  `tradeid` varchar(32) DEFAULT NULL,  `operator` int(11) DEFAULT NULL,  `t_modified` datetime DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `tradeid` (`tradeid`),  KEY `t_modified` (`t_modified`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>假设，现在已经记录了从 2016 年初到 2018 年底的所有数据，运营部门有一个需求是，要统计发生在所有年份中 7 月份的交易记录总数。这个逻辑看上去并不复杂，你的 SQL 语句可能会这么写：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select count(*) from tradelog where month(t_modified)=7;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>由于 t_modified 字段上有索引，于是你就很放心地在生产库中执行了这条语句，但却发现执行了特别久，才返回了结果。如果你问 DBA 同事为什么会出现这样的情况，他大概会告诉你：如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定。为什么条件是 <code>where t_modified='2018-7-1’</code>的时候可以用上索引，而改成 <code>where month(t_modified)=7</code> 的时候就不行了？</p><p>下面是这个 <code>t_modified</code> 索引的示意图。方框上面的数字就是 <code>month()</code> 函数对应的值。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132950.png" alt="t_modified 索引示意图"></p><p>如果 SQL 语句条件用的是 <code>where t_modified='2018-7-1’</code>的话，引擎就会按照上面绿色箭头的路线，快速定位到 <code>t_modified='2018-7-1’</code>需要的结果。实际上，B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性。但是，如果计算 <code>month()</code> 函数的话，会发现本来有序的索引变成了无序的了，也就是说，<strong>涉及对索引字段进行函数计算的操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能</strong>。需要注意的是，优化器并不是要放弃使用这个索引。<strong>在这个例子里，放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引 <code>t_modified</code>，优化器对比索引大小后发现，索引 <code>t_modified</code> 更小，遍历这个索引比遍历主键索引来得更快。因此最终还是会选择索引 <code>t_modified</code></strong>。</p><p>使用 <code>explain</code> 命令，查看一下这条 SQL 语句的执行计划：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221132958.png" alt="explain 结果"></p><p>key=&quot;t_modified&quot;表示的是，使用了 <code>t_modified</code> 这个索引；我在测试表数据中插入了 10 万行数据，<strong>rows=100335，说明这条语句扫描了整个索引的所有值</strong>；Extra 字段的 Using index，表示的是使用了覆盖索引（使用了索引不一定是使用了索引树搜索功能）。</p><p>也就是说，由于在 <code>t_modified</code> 字段加了 <code>month()</code> 函数操作，导致了全索引扫描。为了能够用上索引的快速定位能力，我们就要把 SQL 语句改成基于字段本身的范围查询。按照下面这个写法，优化器就能按照我们预期的，用上 <code>t_modified</code> 索引的快速定位能力了。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select count(*) from tradelog where    -> (t_modified >= '2016-7-1' and t_modified<'2016-8-1') or    -> (t_modified >= '2017-7-1' and t_modified<'2017-8-1') or     -> (t_modified >= '2018-7-1' and t_modified<'2018-8-1');<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>当然，如果系统上线时间更早，或者后面又插入了之后年份的数据的话，就需要再把其他年份补齐。</p><p>优化器在对索引字段进行函数计算的问题上确实有“偷懒”行为，<strong>即使是对于不改变有序性的函数，也不会考虑使用索引</strong>。比如，对于 <code>select * from tradelog where id + 1 = 10000</code> 这个 SQL 语句，这个加 1 操作并不会改变有序性，但是 MySQL 优化器还是不能用 id 索引快速定位到 9999 这一行。所以，需要你在写 SQL 语句的时候，手动改写成 <code>where id = 10000 -1</code> 才可以。</p><h2 id="案例二：隐式类型转换"><a class="header-anchor" href="#案例二：隐式类型转换">¶</a>案例二：隐式类型转换</h2><p>一起看一下这条 SQL 语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from tradelog where tradeid=110717;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>交易编号 <code>tradeid</code> 这个字段上，本来就有索引，但是 <code>explain</code> 的结果却显示，这条语句需要走全表扫描。你可能也发现了，<code>tradeid</code> 的字段类型是 <code>varchar(32)</code>，而输入的参数却是整型，所以需要做类型转换。</p><p>那么，现在这里就有两个问题：</p><ol><li>数据类型转换的规则是什么？</li><li>为什么有数据类型转换，就需要走全索引扫描？</li></ol><p>看 <code>select “10” &gt; 9</code> 的结果：</p><ol><li>如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是 1；</li><li>如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是 0。</li></ol><p>验证结果：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select '10' > 9;+----------+| '10' > 9 |+----------+|        1 |+----------+1 row in set (0.09 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由于 <code>select “10” &gt; 9</code> 返回的是 1，所以就能确认 MySQL 里的转换规则了：在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。</p><blockquote><p>另外：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select 'a'=0 && '中'=0;+------------------+| 'a'=0 && '中'=0  |+------------------+|                1 |+------------------+1 row in set, 2 warnings (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由上可以知道，对于不能转成数字的字符，都会被转成数字0 。</p></blockquote><p>所以此时这个全表扫描的语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from tradelog where tradeid=110717;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>就相当于：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from tradelog where  CAST(tradid AS signed int) = 110717;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>也就是说，这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。</p><blockquote><p>以下语句中 id 的类型是 <code>int</code>，但是不会导致全表扫描，因为类型转换是字符串转成 <code>int</code>，所以此时类型转换发生在右边，并不会对索引字段做任何处理，所以可以走索引树搜索功能。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from tradelog where id="83126";<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></blockquote><h2 id="案例三：隐式字符编码转换"><a class="header-anchor" href="#案例三：隐式字符编码转换">¶</a>案例三：隐式字符编码转换</h2><p>假设系统里还有另外一个表 <code>trade_detail</code>，用于记录交易的操作细节。为了便于量化分析和复现，我往交易日志表 <code>tradelog</code> 和交易详情表 <code>trade_detail</code> 这两个表里插入一些数据。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> CREATE TABLE `trade_detail` (  `id` int(11) NOT NULL,  `tradeid` varchar(32) DEFAULT NULL,  `trade_step` int(11) DEFAULT NULL, /*操作步骤*/  `step_info` varchar(32) DEFAULT NULL, /*步骤信息*/  PRIMARY KEY (`id`),  KEY `tradeid` (`tradeid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into tradelog values(1, 'aaaaaaaa', 1000, now());insert into tradelog values(2, 'aaaaaaab', 1000, now());insert into tradelog values(3, 'aaaaaaac', 1000, now());insert into trade_detail values(1, 'aaaaaaaa', 1, 'add');insert into trade_detail values(2, 'aaaaaaaa', 2, 'update');insert into trade_detail values(3, 'aaaaaaaa', 3, 'commit');insert into trade_detail values(4, 'aaaaaaab', 1, 'add');insert into trade_detail values(5, 'aaaaaaab', 2, 'update');insert into trade_detail values(6, 'aaaaaaab', 3, 'update again');insert into trade_detail values(7, 'aaaaaaab', 4, 'commit');insert into trade_detail values(8, 'aaaaaaac', 1, 'add');insert into trade_detail values(9, 'aaaaaaac', 2, 'update');insert into trade_detail values(10, 'aaaaaaac', 3, 'update again');insert into trade_detail values(11, 'aaaaaaac', 4, 'commit');<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这时候，如果要查询 id=2 的交易的所有操作步骤信息，SQL 语句可以这么写：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /*语句Q1*/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>explain</code>：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> explain select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /*语句Q1*/+----+-------------+-------+------------+-------+-----------------+---------+---------+-------+------+----------+-------------+| id | select_type | table | partitions | type  | possible_keys   | key     | key_len | ref   | rows | filtered | Extra       |+----+-------------+-------+------------+-------+-----------------+---------+---------+-------+------+----------+-------------+|  1 | SIMPLE      | l     | NULL       | const | PRIMARY,tradeid | PRIMARY | 4       | const |    1 |   100.00 | NULL        ||  1 | SIMPLE      | d     | NULL       | ALL   | NULL            | NULL    | NULL    | NULL  |   11 |   100.00 | Using where |+----+-------------+-------+------------+-------+-----------------+---------+---------+-------+------+----------+-------------+2 rows in set, 1 warning (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>一起来看下这个结果：</p><ol><li>第一行显示优化器会先在交易记录表 <code>tradelog</code> 上查到 <code>id</code>=2 的行，这个步骤用上了主键索引，<code>rows</code>=1 表示只扫描一行；</li><li>第二行 <code>key</code>=NULL，表示没有用上交易详情表 <code>trade_detail</code> 上的 <code>tradeid</code> 索引，进行了全表扫描。</li></ol><p>在这个执行计划里，是从 <code>tradelog</code> 表中取 <code>tradeid</code> 字段，再去 <code>trade_detail</code> 表里查询匹配字段。<strong>因此，我们把 <code>tradelog</code> 称为驱动表，把 <code>trade_detail</code> 称为被驱动表，把 <code>tradeid</code> 称为关联字段</strong>。</p><p>接下来，我们看下这个 <code>explain</code> 结果表示的执行流程：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133008.png" alt="语句 Q1 的执行过程"></p><p>图中：</p><ol><li>第 1 步，是根据 <code>id</code> 在 <code>tradelog</code> 表里找到 L2 这一行；</li><li>第 2 步，是从 <code>L2</code> 中取出 <code>tradeid</code> 字段的值；</li><li>第 3 步，是根据 <code>tradeid</code> 值到 <code>trade_detail</code> 表中查找条件匹配的行。<code>explain</code> 的结果里面第二行的 <code>key</code>=NULL 表示的就是，这个过程是通过遍历主键索引的方式，一个一个地判断 <code>tradeid</code> 的值是否匹配。</li></ol><p>进行到这里，会发现第 3 步不符合预期。因为表 <code>trade_detail</code> 里 <code>tradeid</code> 字段上是有索引的，我们本来是希望通过使用 <code>tradeid</code> 索引能够快速定位到等值的行。但，这里并没有。如果去问 DBA 同学，他们可能会说，因为这两个表的字符集不同，一个是 <code>utf8</code>，一个是 <code>utf8mb4</code>，所以做表连接查询的时候用不上关联字段的索引。</p><p>如果单独把第3步改成 SQL 语句的话，那就是：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from trade_detail where tradeid=$L2.tradeid.value; <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中，<code>$L2.tradeid.value</code> 的字符集是 <code>utf8mb4</code>。参照前面例子，字符集 <code>utf8mb4</code> 是 <code>utf8</code> 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 <code>utf8</code> 字符串转成 <code>utf8mb4</code> 字符集（向上转型/宽化转换），再做比较。因此， 在执行上面这个语句的时候，需要将被驱动数据表里的字段一个个地转换成 <code>utf8mb4</code>，再跟 <code>L2</code> 做比较。也就是说，实际上这个语句等同于下面这个写法：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from trade_detail  where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>CONVERT()</code> 函数，在这里的意思是把输入的字符串转成 <code>utf8mb4</code> 字符集。**这就再次触发了我们上面说到的原则：对索引字段做函数操作，优化器会放弃走树搜索功能。**所以字符集不同只是条件之一，<strong>连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因</strong>。</p><h3 id="同样是隐式字符编码转换却走了索引树搜索"><a class="header-anchor" href="#同样是隐式字符编码转换却走了索引树搜索">¶</a>同样是隐式字符编码转换却走了索引树搜索</h3><p>作为对比验证，现在有另外一个需求，“查找 <code>trade_detail</code> 表里 <code>id</code>=4 的操作，对应的操作者是谁”，再来看下这个语句和它的执行计划。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql>select l.operator from tradelog l , trade_detail d where d.tradeid=l.tradeid and d.id=4;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行计划：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> explain select l.operator from tradelog l , trade_detail d where d.tradeid=l.tradeid and d.id=4;+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtered | Extra |+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+|  1 | SIMPLE      | d     | NULL       | const | PRIMARY       | PRIMARY | 4       | const |    1 |   100.00 | NULL  ||  1 | SIMPLE      | l     | NULL       | ref   | tradeid       | tradeid | 131     | const |    1 |   100.00 | NULL  |+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+2 rows in set, 1 warning (0.03 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个语句里 <code>trade_detail</code> 表成了驱动表，但是 <code>explain</code> 结果的第二行显示，这次的查询操作用上了被驱动表 <code>tradelog</code> 里的索引 (<code>tradeid</code>)，扫描行数是 1。</p><p>这也是两个 <code>tradeid</code> 字段的 <code>join</code> 操作，为什么这次能用上被驱动表的 <code>tradeid</code> 索引呢？</p><ol><li><p>假设驱动表 <code>trade_detail</code> 里 <code>id</code>=4 的行记为 R4，那么在连接的时候，被驱动表 <code>tradelog</code> 上执行的就是类似这样的 SQL 语句</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select operator from tradelog  where traideid =$R4.tradeid.value; <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>这时候 <code>$R4.tradeid.value</code> 的字符集是 <code>utf8</code>, 按照字符集转换规则，要转成 <code>utf8mb4</code>，所以这个过程就被改写成：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select operator from tradelog  where traideid =CONVERT($R4.tradeid.value USING utf8mb4); <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里的 <code>CONVERT</code> 函数是加在输入参数上的，这样就可以用上被驱动表的 <code>traideid</code> 索引。</p></li></ol><h3 id="优化前面的语句"><a class="header-anchor" href="#优化前面的语句">¶</a>优化前面的语句</h3><p>理解了原理以后，就可以用来指导操作了。如果要优化语句</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>的执行过程，有两种做法：</p><ul><li><p>比较常见的优化方法是，把 <code>trade_detail</code> 表上的 <code>tradeid</code> 字段的字符集也改成 <code>utf8mb4</code>，这样就没有字符集转换的问题了。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">alter table trade_detail modify tradeid varchar(32) CHARACTER SET utf8mb4 default null;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>如果能够修改字段的字符集的话，是最好不过了。但如果数据量比较大， 或者业务上暂时不能做这个 DDL 的话，那就只能采用修改 SQL 语句的方法了。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行计划：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> explain select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2;+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtered | Extra |+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+|  1 | SIMPLE      | l     | NULL       | const | PRIMARY       | PRIMARY | 4       | const |    1 |   100.00 | NULL  ||  1 | SIMPLE      | d     | NULL       | ref   | tradeid       | tradeid | 99      | const |    4 |   100.00 | NULL  |+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+2 rows in set, 1 warning (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里，主动把 <code>l.tradeid</code> 转成 <code>utf8</code>，就避免了被驱动表上的字符编码转换，从 <code>explain</code> 结果可以看到，这次索引走对了。</p></li></ul><h2 id="案例四：隐式截断字段"><a class="header-anchor" href="#案例四：隐式截断字段">¶</a>案例四：隐式截断字段</h2><p>表结构如下：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> CREATE TABLE `table_a` (  `id` int(11) NOT NULL,  `b` varchar(10) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `b` (`b`)) ENGINE=InnoDB;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>假设现在表里面，有 100 万行数据，其中有 10 万行数据的 b 的值是’1234567890’， 假设现在执行语句是这么写的:</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from table_a where b='1234567890abcd';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最理想的情况是，MySQL 看到字段 b 定义的是 <code>varchar(10)</code>，那肯定返回空呀。可惜，MySQL 并没有这么做。那要不，就是把’1234567890abcd’拿到索引里面去做匹配，肯定也没能够快速判断出索引树 b 上并没有这个值，也很快就能返回空结果。</p><p>相对以上处理方式来说，MySQL 对于这条 SQL 语句的执行很慢，流程是这样的：</p><ol><li>在传给引擎执行的时候，做了字符截断。因为引擎里面这个行只定义了长度是 10，所以只截了前 10 个字节，就是’1234567890’进去做匹配；</li><li>这样满足条件的数据有 10 万行；因为是 <code>select *</code>， 所以要做 10 万次回表；</li><li>但是每次回表以后查出整行，到 server 层一判断，b 的值都不是’1234567890abcd’;</li><li>返回结果是空。</li></ol><p>以上流程不只说明了字符串超长的处理方式，还说明了在做函数处理的时候，有可能从存储引擎查回数据到 Server 层之后还要对所有数据做一次判断，因为穿给存储引擎的条件是做了特殊处理的，返回来的不一定就是最终要返回给用户的正确的数据。</p><h2 id="MySQL-在连表的时候的优化"><a class="header-anchor" href="#MySQL-在连表的时候的优化">¶</a>MySQL 在连表的时候的优化</h2><p>上面案例三提到了连表的场景，在 MySQL 进行连表操作的时候，驱动表的选择至关重要。而 MySQL 在决定驱动表的时候是做了优化的，该逻辑不会受到连表 <code>on</code> 子句中连表字段顺序、<code>where</code> 子句中连表字段顺序、<code>from</code> 子句中参与连表的表名书写顺序所影响。</p><h3 id="例1"><a class="header-anchor" href="#例1">¶</a>例1</h3><p>类似案例三中的 SQL ：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可以看到 <code>tradelog</code> 和 <code>trade_detail</code> 发生了连表，连表字段写在了 <code>where</code> 子句中，而 <code>trade_detail</code> 的字段放在了前面，但是从执行计划可以看出，驱动表是 <code>tradelog</code>。</p><ul><li>这是因为 <code>where</code> 子句中存在另外一个条件 <code>l.id=2</code>，这个条件是对表 <code>tradelog</code> 的筛选条件，它是 <code>tradelog</code> 的主键索引，如果 MySQL 选择了 <code>tradelog</code> 作为驱动表，就可以先利用这个条件走 <code>tradelog</code> 的主键索引，此时就可以经过较短的时间（O(log(M))）即可得到 <code>tradelog</code> 中对应的一行数据，然后取出该行数据的 <code>tradeid</code> 字段值，然后再到表 <code>trade_detail</code> 上走一次索引树搜索即可（O(log(N))）。</li><li>但是如果选择了 <code>trade_detail</code> 作为驱动表，那么由于 <code>where</code> 子句中没有 <code>trade_detail</code> 的筛选条件，此时就需要走 <code>trade_id</code> 的索引全表扫描，然后对于得到的每一行数据的 <code>trade_id</code> 值，到 <code>tradelog</code> 的 <code>trade_id</code> 索引树中进行搜索，然后再根据得到的 <code>id</code> 值进行筛选，此时相较于使用 <code>tradelog</code> 作为驱动表的 “O(log(N)) + O(log(M))”，当前选择需要 “O(N) + N * O(log(M))”。</li></ul><p>综上，前者的时间复杂度相对是低很多的，所以 MySQL 会选择前者。</p><h3 id="例2"><a class="header-anchor" href="#例2">¶</a>例2</h3><p>上面的例子中是因为 <code>where</code> 子句中存在某个参与连表的表的某个索引字段的筛选条件，MySQL 优化器决定使用它作为驱动表，那么如果是 <code>where</code> 子句中只有连表条件，没有其它筛选条件呢？如下：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因为两个表在 <code>where</code> 子句中没有筛选条件，只有连接条件，所以驱动表肯定会扫描全表，所以时间复杂度是O(N)；然后连接条件可以相当于被驱动表的筛选条件了，此时时间复杂度为 N * log(M)。所以总的时间复杂度为 O(N) + N * log(M)，此时 N 为驱动表的行数，M 为被驱动表的行数，显然当 N &gt; M 的时候，时间复杂度相对是大于当 M &gt; N 的时候的（可以画函数曲线看看），也就是说大表作为驱动表的时候效率相对较低。所以 MySQL 在针对这种情况的时候，会使用小表驱动大表。</p><h1>十八、只查一行的语句也很慢的场景</h1><p>一般情况下，如果说查询性能优化，首先会想到一些复杂的语句，想到查询需要返回大量的数据。但有些情况下，“查一行”，也会执行得特别慢。需要说明的是，如果 MySQL 数据库本身就有很大的压力，导致数据库服务器 CPU 占用率很高或 ioutil（IO 利用率）很高，这种情况下所有语句的执行都有可能变慢，不属于讨论范围。</p><p>为了便于描述，构造一个表，基于这个表来说明今天的问题。这个表有两个字段 id 和 c，并且在里面插入了 10 万行记录。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> CREATE TABLE `t` (  `id` int(11) NOT NULL,  `c` int(11) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB;delimiter ;;create procedure idata()begin  declare i int;  set i=1;  while(i<=100000) do    insert into t values(i,i);    set i=i+1;  end while;end;;delimiter ;call idata();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="第一类：查询长时间不返回"><a class="header-anchor" href="#第一类：查询长时间不返回">¶</a>第一类：查询长时间不返回</h2><p>在表 t 执行下面的 SQL 语句：</p><pre class="line-numbers language-language-mysq"><code class="language-language-mysq">mysql> select * from t where id=1;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查询结果长时间不返回。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133023.png" alt="查询长时间不返回"></p><p>一般碰到这种情况的话，大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 <code>show processlist</code> 命令，看看当前语句处于什么状态。然后再针对每种状态，去分析它们产生的原因、如何复现，以及如何处理。</p><h3 id="等-MDL-锁"><a class="header-anchor" href="#等-MDL-锁">¶</a>等 MDL 锁</h3><p>如图所示，就是使用 <code>show processlist</code> 命令查看 Waiting for table metadata lock 的示意图。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133028.png" alt="Waiting for table metadata lock 状态示意图"></p><p>出现这个状态表示的是，<strong>现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了</strong>。</p><p>在 MySQL 5.7 版本下复现这个场景，也很容易。如下图所示给出了简单的复现步骤。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133032.png" alt="MySQL 5.7 中 Waiting for table metadata lock 的复现步骤"></p><p>session A 通过 <code>lock table</code> 命令持有表 t 的 MDL 写锁，而 session B 的查询需要获取 MDL 读锁。所以，session B 进入等待状态。</p><h4 id="解决-v2"><a class="header-anchor" href="#解决-v2">¶</a>解决</h4><p>这类问题的处理方式，就是找到谁持有 MDL 写锁，然后把它 kill 掉。但是，由于在 <code>show processlist</code> 的结果里面，session A 的 Command 列是“Sleep”，导致查找起来很不方便。不过有了 <code>performance_schema</code> 和 <code>sys</code> 系统库以后，就方便多了。（MySQL 启动时需要设置 <code>performance_schema=on</code>，相比于设置为 off 会有 10% 左右的性能损失)。通过查询 <code>sys.schema_table_lock_waits</code> 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。</p><blockquote><p>执行</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from performance_schema.setup_instruments where name='wait/lock/metadata/sql/mdl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>看一下<code>ENABLED</code>和<code>TIMED</code>是不是都是YES，只有两个都是YES的时候才能执行文章中说的操作。 具体可以参考官方文档： <a href="https://dev.mysql.com/doc/refman/5.7/en/sys-schema-table-lock-waits.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/sys-schema-table-lock-waits.html</a> 和 <a href="https://dev.mysql.com/doc/refman/5.7/en/metadata-locks-table.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/metadata-locks-table.html</a> 。</p><p>如果都匹配，直接手动更新：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">UPDATE performance_schema.setup_instruments SET ENABLED = 'YES', TIMED = 'YES' where name='wait/lock/metadata/sql/mdl';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></blockquote><h3 id="等-flush"><a class="header-anchor" href="#等-flush">¶</a>等 flush</h3><p>接下来举另外一种查询被堵住的情况。在表 t 上，执行下面的 SQL 语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from information_schema.processlist where id=1;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133039.png" alt="Waiting for table flush 状态示意图"></p><p>查出来这个线程的状态是 Waiting for table flush。这个状态表示的是，现在有一个线程正要对表 t 做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">flush tables t with read lock;flush tables with read lock;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>这两个 flush 语句，如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。</p><p>复现步骤：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133045.png" alt="Waiting for table flush 的复现步骤"></p><p>在 session A 中，故意每行都调用一次 sleep(1)，这样这个语句默认要执行 10 万秒，在这期间表 t 一直是被 session A“打开”着。然后，session B 的 <code>flush tables t</code> 命令再要去关闭表 t，就需要等 session A 的查询结束。这样，session C 要再次查询的话，就会被 flush 命令堵住了。</p><p>下图是这个复现步骤的 <code>show processlist</code> 结果。这个例子的排查也很简单，看到这个 <code>show processlist</code> 的结果，直接找到源头 kill 掉。</p><h3 id="等行锁"><a class="header-anchor" href="#等行锁">¶</a>等行锁</h3><p>现在，经过了表级锁的考验， select 语句终于来到引擎里了。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from t where id=1 lock in share mode; <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>由于访问 id=1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住。复现步骤和现场如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133051.png" alt="行锁复现"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133057.png" alt="行锁 show processlist 现场"></p><p>显然，session A 启动了事务，占有写锁，还不提交，是导致 session B 被堵住的原因。这个问题并不难分析，但问题是怎么查出是谁占着这个写锁。如果用的是 MySQL 5.7 版本，可以通过 <code>sys.innodb_lock_waits</code> 表查到。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from t sys.innodb_lock_waits where locked_table='`test`.`t`'\G<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133104.png" alt="通过 sys.innodb_lock_waits 查行锁"></p><p>可以看到，这个信息很全，4 号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是 <code>KILL QUERY 4</code> 或 <code>KILL 4</code>。不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止 4 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁。<strong>实际上，<code>KILL 4</code> 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。</strong></p><h2 id="第二类：查询慢"><a class="header-anchor" href="#第二类：查询慢">¶</a>第二类：查询慢</h2><p>经过了重重封“锁”，再来看看一些查询慢的例子。</p><h3 id="字段没加索引导致全表扫描"><a class="header-anchor" href="#字段没加索引导致全表扫描">¶</a>字段没加索引导致全表扫描</h3><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from t where c=50000 limit 1;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>由于字段 c 上没有索引，这个语句只能走 id 主键顺序扫描，因此需要实际扫描 5 万行。作为确认，可以看一下慢查询日志。注意，这里为了把所有语句记录到 slow log 里，在连接后先执行了 <code>set long_query_time=0</code>，将慢查询日志的时间阈值设置为 0。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133111.png" alt="全表扫描 5 万行的 slow log"></p><p><code>Rows_examined</code> 显示扫描了 50000 行。你可能会说，不是很慢呀，11.5 毫秒就返回了，我们线上一般都配置超过 1 秒才算慢查询。但你要记住：坏查询不一定是慢查询。这个例子里面只有 10 万行记录，数据量大起来的话，执行时间就线性涨上去了。</p><h3 id="版本落后太多只查扫描也很慢"><a class="header-anchor" href="#版本落后太多只查扫描也很慢">¶</a>版本落后太多只查扫描也很慢</h3><p>扫描行数多，所以执行慢，这个很好理解。但是接下来，我们再看一个只扫描一行，但是执行很慢的语句。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from t where id=1；<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>slow log：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133118.png" alt="扫描一行却执行得很慢"></p><p>虽然扫描行数是 1，但执行时间却长达 800 毫秒。</p><p>如果把这个 slow log 的截图再往下拉一点，你可以看到下一个语句，<code>select * from t where id=1 lock in share mode</code>，执行时扫描行数也是 1 行，执行时间是 0.2 毫秒。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133124.png" alt="加上 lock in share mode 的 slow log"></p><p>两个语句的输出结果：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133130.png" alt="两个语句的输出结果"></p><p>第一个语句的查询结果里 c=1，带 <code>lock in share mode</code> 的语句返回的是 c=1000001 。</p><p>下面是复现步骤：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134610.png" alt="复现步骤"></p><p>session B 更新完 100 万次，生成了 100 万个回滚日志 (undo log)。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133136.png" alt="id=1 的数据状态"></p><p>带 <code>lock in share mode</code> 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；而 <code>select * from t where id=1</code> 这个语句，是一致性读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回。注意，undo log 里记录的其实是“把 2 改成 1”，“把 3 改成 2”这样的操作逻辑，画成减 1 的目的是方便看图。</p><h1>十九、饮鸩止渴提高性能地方法</h1><h2 id="短连接风暴"><a class="header-anchor" href="#短连接风暴">¶</a>短连接风暴</h2><p>正常的短连接模式就是连接到数据库后，执行很少的 SQL 语句就断开，下次需要的时候再重连。如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。MySQL 建立连接的过程，成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限。在数据库压力比较小的时候，这些额外的成本并不明显。</p><p>但是，短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。<code>max_connections</code> 参数，用来控制一个 MySQL 实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。对于被拒绝连接的请求来说，从业务角度看就是数据库不可用。在机器负载比较高的时候，处理现有请求的时间变长，每个连接保持的时间也更长。这时，再有新建连接的话，就可能会超过 <code>max_connections</code> 的限制。</p><p>碰到这种情况时，一个比较自然的想法，就是调高 <code>max_connections</code> 的值。但这样做是有风险的。因为设计 <code>max_connections</code> 这个参数的目的是想保护 MySQL，如果我们把它改得太大，让更多的连接都可以进来，那么系统的负载可能会进一步加大，大量的资源耗费在权限验证等逻辑上，结果可能是适得其反，已经连接的线程拿不到 CPU 资源去执行业务的 SQL 请求。那么这种情况下，还有没有别的建议呢？这里还有两种方法，但要注意，这些方法都是有损的。</p><h3 id="第一种方法：杀连接"><a class="header-anchor" href="#第一种方法：杀连接">¶</a>第一种方法：杀连接</h3><p>先处理掉那些占着连接但是不工作的线程。<code>max_connections</code> 的计算，不是看谁在 running，是只要连着就占用一个计数位置。对于那些不需要保持的连接，我们可以通过 kill connection 主动踢掉。这个行为跟事先设置 <code>wait_timeout</code> 的效果是一样的。设置 <code>wait_timeout</code> 参数表示的是，一个线程空闲 <code>wait_timeout</code> 这么多秒之后，就会被 MySQL 直接断开连接。但是需要注意，在 show processlist 的结果里，踢掉显示为 sleep 的线程，可能是有损的。我们来看下面这个例子。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133146.png" alt="sleep 线程的两种状态"></p><p>在上面这个例子里，如果断开 session A 的连接，因为这时候 session A 还没有提交，所以 MySQL 只能按照回滚事务来处理；而断开 session B 的连接，就没什么大影响。所以，如果按照优先级来说，你应该优先断开像 session B 这样的事务外空闲的连接。</p><p>但是，怎么判断哪些是事务外空闲的呢？session C 在 T 时刻之后的 30 秒执行 show processlist，看到的结果是这样的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133151.png" alt="sleep 线程的两种状态，show processlist 结果"></p><p>图中 id=4 和 id=5 的两个会话都是 Sleep 状态。而要看事务具体状态的话，可以查 <code>information_schema</code> 库的 <code>innodb_trx</code> 表。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133156.png" alt="从 information_schema.innodb_trx 查询事务状态"></p><p>这个结果里，<code>trx_mysql_thread_id</code>=4，表示 id=4 的线程还处在事务中。因此，如果是连接数过多，你可以优先断开事务外空闲太久的连接；如果这样还不够，再考虑断开事务内空闲太久的连接。从服务端断开连接使用的是 kill connection + id 的命令， 一个客户端处于 sleep 状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。</p><p>从数据库端主动断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，<strong>而是直接用这个已经不能用的句柄重试查询</strong>。这会导致从应用端看上去，“MySQL 一直没恢复”。所以，在做业务开发的时候，遇到这种情况就要重新建立连接了。</p><h3 id="第二种方法：减少连接过程的消耗"><a class="header-anchor" href="#第二种方法：减少连接过程的消耗">¶</a>第二种方法：减少连接过程的消耗</h3><p>有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。跳过权限验证的方法是：重启数据库，并使用 <code>–skip-grant-tables</code> 参数启动。这样，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。但是，这种方法特别符合标题里说的“饮鸩止渴”，风险极高，是特别不建议使用的方案。尤其你的库外网可访问的话，就更不能这么做了。在 MySQL 8.0 版本里，如果启用 <code>–skip-grant-tables</code> 参数，MySQL 会默认把 <code>--skip-networking</code> 参数打开，表示这时候数据库只能被本地的客户端连接。可见，MySQL 官方对 <code>skip-grant-tables</code> 这个参数的安全问题也很重视。</p><h2 id="慢查询性能问题"><a class="header-anchor" href="#慢查询性能问题">¶</a>慢查询性能问题</h2><p>除了短连接数暴增可能会带来性能问题外，实际上，我们在线上碰到更多的是查询或者更新语句导致的性能问题。其中，查询问题比较典型的有两类，一类是由新出现的慢查询导致的，一类是由 QPS（每秒查询数）突增导致的。</p><p>在 MySQL 中，会引发性能问题的慢查询，大体有以下三种可能：</p><ol><li>索引没有设计好；</li><li>SQL 语句没写好；</li><li>MySQL 选错了索引。</li></ol><h3 id="索引没有设计好"><a class="header-anchor" href="#索引没有设计好">¶</a>索引没有设计好</h3><p>这种场景一般就是通过紧急创建索引来解决。MySQL 5.6 版本以后，创建索引都支持 Online DDL 了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行 <code>alter table</code> 语句。比较理想的是能够在备库先执行。假设现在的服务是一主一备，主库 A、备库 B，这个方案的大致流程是这样的：</p><ol><li>在备库 B 上执行 <code>set sql_log_bin=off</code>，也就是不写 binlog，然后执行 <code>alter table</code> 语句加上索引；</li><li>执行主备切换；</li><li>这时候主库是 B，备库是 A。在 A 上执行 <code>set sql_log_bin=off</code>，然后执行 alter table 语句加上索引。</li></ol><p>这是一个“古老”的 DDL 方案。平时在做变更的时候，你应该考虑类似 gh-ost 这样的方案，更加稳妥。但是在需要紧急处理时，上面这个方案的效率是最高的。</p><h3 id="SQL-语句没写好"><a class="header-anchor" href="#SQL-语句没写好">¶</a>SQL 语句没写好</h3><p>这时，我们可以通过改写 SQL 语句来处理。MySQL 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。比如，语句被错误地写成了 <code>select * from t where id + 1 = 10000</code>，你可以通过下面的方式，增加一个语句改写规则。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");call query_rewrite.flush_rewrite_rules();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这里，call query_rewrite.flush_rewrite_rules() 这个存储过程，是让插入的新规则生效，也就是我们说的“查询重写”。可以用图 4 中的方法来确认改写规则是否生效。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133206.png" alt="查询重写效果"></p><h3 id="MySQL-选错了索引"><a class="header-anchor" href="#MySQL-选错了索引">¶</a>MySQL 选错了索引</h3><p>这时候，应急方案就是给这个语句加上 <code>force index</code>。同样地，使用查询重写功能，给原来的语句加上 <code>force index</code>，也可以解决这个问题。上面讨论的由慢查询导致性能问题的三种可能情况，实际上出现最多的是前两种，即：索引没设计好和语句没写好。而这两种情况，恰恰是完全可以避免的。比如，通过下面这个过程，我们就可以预先发现问题。</p><ol><li>上线前，在测试环境，把慢查询日志（slow log）打开，并且把 <code>long_query_time</code> 设置成 0，确保每个语句都会被记录入慢查询日志；</li><li>在测试表里插入模拟线上的数据，做一遍回归测试；</li><li>观察慢查询日志里每类语句的输出，特别留意 <code>Rows_examined</code> 字段是否与预期一致。</li></ol><p>不要吝啬这段花在上线前的“额外”时间，因为这会帮你省下很多故障复盘的时间。如果新增的 SQL 语句不多，手动跑一下就可以。而如果是新项目的话，或者是修改了原有项目的 表结构设计，全量回归测试都是必要的。这时候，你需要工具帮你检查所有的 SQL 语句的返回结果。比如，你可以使用开源工具 <a href="https://www.percona.com/doc/percona-toolkit/3.0/pt-query-digest.html" target="_blank" rel="noopener">pt-query-digest</a>。</p><h2 id="QPS-突增问题"><a class="header-anchor" href="#QPS-突增问题">¶</a>QPS 突增问题</h2><p>有时候由于业务突然出现高峰，或者应用程序 bug，导致某个语句的 QPS 突然暴涨，也可能导致 MySQL 压力过大，影响服务。当然，最理想的情况是让业务把这个功能下掉，服务自然就会恢复。而下掉一个功能，如果从数据库端处理的话，对应于不同的背景，有不同的方法可用。这里展开说明一下。</p><ol><li>一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。</li><li>如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。</li><li>如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成&quot;select 1&quot;返回。</li></ol><p>当然，这个操作的风险很高，需要你特别细致。它可能存在两个副作用：</p><ol><li>如果别的功能里面也用到了这个 SQL 语句模板，会有误伤；</li><li>很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1 的结果返回的话，可能会导致后面的业务逻辑一起失败。</li></ol><p>所以，方案 3 是用于止血的，跟前面提到的去掉权限验证一样，应该是你所有选项里优先级最低的一个方案。同时你会发现，其实方案 1 和 2 都要依赖于规范的运维体系：虚拟化、白名单机制、业务账号分离。由此可见，更多的准备，往往意味着更稳定的系统。</p><h1>二十、关于 kill</h1><p>在 MySQL 中有两个 kill 命令：一个是 kill query + 线程 id，表示终止这个线程中正在执行的语句；一个是 kill connection + 线程 id，这里 connection 可缺省，表示断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的。</p><p>在使用 MySQL 的时候，可能会遇到这样的现象：使用了 kill 命令，却没能断开这个连接。再执行 <code>show processlist</code> 命令，看到这条语句的 Command 列显示的是 Killed。显示为 Killed 是什么意思，不是应该直接在 <code>show processlist</code> 的结果里看不到这个线程了吗？</p><p>其实大多数情况下，kill query/connection 命令是有效的。比如，执行一个查询的过程中，发现执行时间太久，要放弃继续查询，这时我们就可以用 kill query 命令，终止这条查询语句。还有一种情况是，语句处于锁等待的时候，直接使用 kill 命令也是有效的。我们一起来看下这个例子：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133214.png" alt="kill query 成功的例子"></p><p>可以看到，session C 执行 kill query 以后，session B 几乎同时就提示了语句被中断。这，就是我们预期的结果。</p><h2 id="收到-kill-以后，线程做什么？"><a class="header-anchor" href="#收到-kill-以后，线程做什么？">¶</a>收到 kill 以后，线程做什么？</h2><p>上面的 session B 是直接终止掉线程，什么都不管就直接退出吗？显然，这是不行的。例如当对一个表做增删改查操作时，会在表上加 MDL 读锁。所以，session B 虽然处于 blocked 状态，但还是拿着一个 MDL 读锁的。如果线程被 kill 的时候，就直接终止，那之后这个 MDL 读锁就没机会被释放了。这样看来，kill 并不是马上停止的意思，而是告诉执行线程说，这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了”。</p><p>其实，这跟 Linux 的 kill 命令类似，<code>kill -N pid</code> 并不是让进程直接停止，而是给进程发一个信号，然后进程处理这个信号，进入终止逻辑。只是对于 MySQL 的 kill 命令来说，不需要传信号量参数，就只有“停止”这个命令。</p><p>实现上，当用户执行 kill query thread_id_B 时，MySQL 里处理 kill 命令的线程做了两件事：</p><ol><li>把 session B 的运行状态改成 THD::KILL_QUERY(将变量 killed 赋值为 THD::KILL_QUERY)；</li><li>给 session B 的执行线程发一个信号。</li></ol><p>为什么要发信号呢？因为像上图中的例子里面，session B 处于锁等待状态，如果只是把 session B 的线程状态设置 THD::KILL_QUERY，线程 B 并不知道这个状态变化，还是会继续等待。发一个信号的目的，就是让 session B 退出等待(操作系统的信号处理，线程注册自己感兴趣的信号量然后挂起，如果操作系统收到这些信号，就会激活该挂起的现成)，来处理这个 THD::KILL_QUERY 状态。</p><p>上面的分析中，隐含了这么三层意思：</p><ol><li>一个语句执行过程中有多处“埋点”，在这些“埋点”的地方判断线程状态，如果发现线程状态是 THD::KILL_QUERY，才开始进入语句终止逻辑；</li><li>如果处于等待状态，必须是一个可以被唤醒的等待，否则根本不会执行到“埋点”处；</li><li>语句从开始进入终止逻辑，到终止逻辑完全完成，是有一个过程的。</li></ol><p>所以 kill 掉 MySQL 现成不是说停就停的。</p><h2 id="kill-不掉的例子"><a class="header-anchor" href="#kill-不掉的例子">¶</a>kill 不掉的例子</h2><h3 id="1-被-kill-的线程无法执行到-埋点"><a class="header-anchor" href="#1-被-kill-的线程无法执行到-埋点">¶</a>1&gt;被 kill 的线程无法执行到&quot;埋点&quot;</h3><p>首先，执行 <code>set global innodb_thread_concurrency=2</code>，将 InnoDB 的并发线程上限数设置为 2；然后，执行下面的序列：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133221.png" alt="kill query 无效的例子"></p><p>可以看到：</p><ol><li>sesssion C 执行的时候被堵住了；</li><li>但是 session D 执行的 kill query C 命令却没什么效果，</li><li>直到 session E 执行了 kill connection 命令，才断开了 session C 的连接，提示“Lost connection to MySQL server during query”，</li><li>但是这时候，如果在 session E 中执行 show processlist，你就能看到下面这个图。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133228.png" alt="kill connection 之后的效果"></p><p>这时候，id=12 这个线程的 Commnad 列显示的是 Killed。也就是说，客户端虽然断开了连接，但实际上服务端上这条语句还在执行过程中。为什么在执行 kill query 命令时，这条语句不像第一个例子的 update 语句一样退出呢？</p><ol><li>在实现上，等行锁时，使用的是 <code>pthread_cond_timedwait</code> 函数，这个等待状态可以被唤醒。但是，在这个例子里，12 号线程的等待逻辑是这样的：每 10 毫秒判断一下是否可以进入 InnoDB 执行，如果不行，就调用 <code>nanosleep</code> 函数进入 sleep 状态。也就是说，虽然 12 号线程的状态已经被设置成了 KILL_QUERY，但是在这个等待进入 InnoDB 的循环过程中，并没有去判断线程的状态，因此根本不会进入终止逻辑阶段。</li><li>而当 session E 执行 kill connection 命令时，是这么做的：<ul><li>把 12 号线程状态设置为 KILL_CONNECTION；</li><li>关掉 12 号线程的网络连接。因为有这个操作，所以你会看到，这时候 session C 收到了断开连接的提示（服务端断开网络连接），但是线程还是继续执行的，只不过该线程的网络连接的相关资源都被回收了。</li></ul></li></ol><p>那为什么执行 <code>show processlist</code> 的时候，会看到 Command 列显示为 killed 呢？其实，这就是因为在执行 <code>show processlist</code> 的时候，有一个特别的逻辑：</p><pre><code>如果一个线程的状态是KILL_CONNECTION，就把Command列显示成Killed。</code></pre><p>所以其实，即使是客户端退出(发出该 SQL 的客户端连接已经被断开)了，这个线程的状态仍然是在等待中。那这个线程什么时候会退出呢？答案是，只有等到满足进入 InnoDB 的条件后，session C 的查询语句继续执行，然后才有可能判断到线程状态已经变成了 KILL_QUERY 或者 KILL_CONNECTION，再进入终止逻辑阶段。</p><h4 id="无法-kill-的原因总结"><a class="header-anchor" href="#无法-kill-的原因总结">¶</a>无法 kill 的原因总结</h4><p><strong>这个例子是 kill 无效的第一类情况，即：线程没有执行到判断线程状态的逻辑。跟这种情况相同的，还有由于 IO 压力过大，读写 IO 的函数一直无法返回，导致不能及时判断线程的状态</strong>。</p><h3 id="2-终止逻辑耗时较长"><a class="header-anchor" href="#2-终止逻辑耗时较长">¶</a>2&gt;终止逻辑耗时较长</h3><p>另一类情况是，终止逻辑耗时较长。这时候，从 <code>show processlist</code> 结果上看也是 Command=Killed，需要等到终止逻辑完成，语句才算真正完成。这类情况，比较常见的场景有以下几种：</p><ol><li>超大事务执行期间被 kill。这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长。</li><li>大查询回滚。如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临时文件可能需要等待 IO 资源，导致耗时较长。</li><li>DDL 命令执行到最后阶段，如果被 kill，需要删除中间过程的临时文件，也可能受 IO 资源影响耗时较久。</li></ol><h4 id="Ctrl-C-误解"><a class="header-anchor" href="#Ctrl-C-误解">¶</a>Ctrl+C 误解</h4><p>如果直接在客户端通过 Ctrl+C 命令，是不是就可以直接终止线程呢？答案是，不可以。这里有一个误解，其实在客户端的操作只能操作到客户端的线程，客户端和服务端只能通过网络交互，是不可能直接操作服务端线程的。而由于 MySQL 是停等协议，所以这个线程执行的语句还没有返回的时候，再往这个连接里面继续发命令也是没有用的。实际上，执行 Ctrl+C 的时候，是 MySQL 客户端另外启动一个连接，然后发送一个 kill query 命令。所以，你可别以为在客户端执行完 Ctrl+C 就万事大吉了。因为，要 kill 掉一个线程，还涉及到后端的很多操作。</p><h4 id="另外两个关于客户端的误解"><a class="header-anchor" href="#另外两个关于客户端的误解">¶</a>另外两个关于客户端的误解</h4><p>在实际使用中，我也经常会碰到一些同学对客户端的使用有误解。接下来，我们就来看看两个最常见的误解。</p><h5 id="表很多连接慢"><a class="header-anchor" href="#表很多连接慢">¶</a>表很多连接慢</h5><p>第一个误解是：如果库里面的表特别多，连接就会很慢。有些线上的库，会包含很多表（我见过最多的一个库里有 6 万个表）。这时候，你就会发现，每次用客户端连接都会卡在下面这个界面上。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133236.png" alt="连接等待"></p><p>而如果 db1 这个库里表很少的话，连接起来就会很快，可以很快进入输入命令的状态。因此，有同学会认为是表的数目影响了连接性能。</p><p>其实每个客户端在和服务端建立连接的时候，需要做的事情就是 TCP 握手、用户校验、获取权限。但这几个操作，显然跟库里面表的个数无关。但实际上，正如图中的文字提示所说的，<strong>当使用默认参数连接的时候，MySQL 客户端会提供一个本地库名和表名补全的功能</strong>。为了实现这个功能，客户端在连接成功后，需要多做一些操作：</p><ol><li>执行 <code>show databases</code>；</li><li>切到 <code>db1</code> 库，执行 <code>show tables</code>；</li><li>把这两个命令的结果用于构建一个本地的哈希表。</li></ol><p>在这些操作中，最花时间的就是第三步在本地构建哈希表的操作。所以，当一个库中的表个数非常多的时候，这一步就会花比较长的时间。也就是说，<strong>我们感知到的连接过程慢，其实并不是连接慢，也不是服务端慢，而是客户端慢</strong>。</p><p>图中的提示也说了，如果在连接命令中加上 <code>-A</code>，就可以关掉这个自动补全的功能，然后客户端就可以快速返回了。这里自动补全的效果就是，你在输入库名或者表名的时候，输入前缀，可以使用 Tab 键自动补全表名或者显示提示。实际使用中，如果你自动补全功能用得并不多，建议你每次使用的时候都默认加 <code>-A</code>。</p><h5 id="客户端连接-–quick-参数"><a class="header-anchor" href="#客户端连接-–quick-参数">¶</a>客户端连接 <code>–quick</code> 参数</h5><p>其实上图提示里面没有说，除了加 <code>-A</code> 以外，加<code>–quick</code>(或者简写为 <code>-q</code>) 参数，也可以跳过这个阶段。但是，这个<code>–quick</code> 是一个更容易引起误会的参数，也是关于客户端常见的一个误解。</p><p>看到这个参数，是不是觉得这应该是一个让服务端加速的参数？但实际上恰恰相反，设置了这个参数可能会降低服务端的性能。为什么这么说呢？MySQL 客户端发送请求后，接收服务端返回结果的方式有两种：</p><ol><li>一种是本地缓存，也就是在本地开一片内存，先把结果存起来。如果你用 API 开发，对应的就是 <code>mysql_store_result</code> 方法。</li><li>另一种是不缓存，读一个处理一个。如果你用 API 开发，对应的就是 <code>mysql_use_result</code> 方法。</li></ol><p>MySQL 客户端默认采用第一种方式，而如果加上<code>–quick</code> 参数，就会使用第二种不缓存的方式。采用不缓存的方式时，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端变慢。既然这样，为什么要给这个参数取名叫作 <code>quick</code> 呢？这是因为使用这个参数可以达到以下三点效果：</p><ul><li>第一点，就是前面提到的，跳过表名自动补全功能。</li><li>第二点，<code>mysql_store_result</code> 需要申请本地内存来缓存查询结果，如果查询结果太大，会耗费较多的本地内存，可能会影响客户端本地机器的性能；</li><li>第三点，是不会把执行命令记录到本地的命令历史文件。</li></ul><p>所以 <code>–quick</code> 参数的意思，是让客户端变得更快。</p><h2 id="如何处理-kill-不掉的问题"><a class="header-anchor" href="#如何处理-kill-不掉的问题">¶</a>如何处理 kill 不掉的问题</h2><p>这些“kill 不掉”的情况，其实是因为发送 kill 命令的客户端，并没有强行停止目标线程的执行，而只是设置了个状态，并唤醒对应的线程。而被 kill 的线程，需要执行到判断状态的“埋点”，才会开始进入终止逻辑阶段。并且，终止逻辑本身也是需要耗费时间的。所以，如果发现一个线程处于 Killed 状态，可以做的事情就是，通过影响系统环境，让这个 Killed 状态尽快结束。比如，如果是第一个例子里 InnoDB 并发度的问题，你就可以临时调大 <code>innodb_thread_concurrency</code> 的值，或者停掉别的线程，让出位子给这个线程执行。而如果是回滚逻辑由于受到 IO 资源限制执行得比较慢，就通过减少系统压力让它加速。做完这些操作后，其实你已经没有办法再对它做什么了，只能等待流程自己完成。</p><p>如果碰到一个被 killed 的事务一直处于回滚状态，是应该直接把 MySQL 进程强行重启，还是应该让它自己执行完成呢？为什么呢？</p><p>因为重启之后该做的回滚动作还是不能少的，所以从恢复速度的角度来说，应该让它自己结束。当然，如果这个语句可能会占用别的锁，或者由于占用 IO 资源过多，从而影响到了别的语句执行的话，就需要先做主备切换，切到新主库提供服务。切换之后别的线程都断开了连接，自动停止执行。接下来还是等它自己执行完成。这个操作属于前面说到的，减少系统压力，加速终止逻辑。</p><h1>二十一、一次性查询很多数据会不会把数据库内存打爆</h1><p>主机内存只有 100G，现在要对一个 200G 的大表做全表扫描，会不会把数据库主机的内存用光了？这个问题确实值得担心，被系统 OOM（out of memory）可不是闹着玩的。但是，反过来想想，逻辑备份的时候，可不就是做整库扫描吗？如果这样就会把内存吃光，逻辑备份不是早就挂了？所以说，对大表做全表扫描，看来应该是没问题的。但是，这个流程到底是怎么样的呢？</p><h2 id="全表扫描对-server-层的影响"><a class="header-anchor" href="#全表扫描对-server-层的影响">¶</a>全表扫描对 server 层的影响</h2><p>假设，我们现在要对一个 200G 的 InnoDB 表 db1. t，执行一个全表扫描。当然，你要把扫描结果保存在客户端，会使用类似这样的命令：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql -h$host -P$port -u$user -p$pwd -e "select * from db1.t" > $target_file<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>InnoDB 的数据是保存在主键索引上的，所以全表扫描实际上是直接扫描表 t 的主键索引。这条查询语句由于没有其他的判断条件，所以查到的每一行都可以直接放到结果集里面，然后返回给客户端。</p><p>那么，这个“结果集”存在哪里呢？实际上，服务端并不需要保存一个完整的结果集。取数据和发数据的流程是这样的：</p><ol><li>获取一行，写到 net_buffer 中。这块内存的大小是由参数 <code>net_buffer_length</code> 定义的（针对每个客户端连接都会有两个缓冲区，一个是连接缓冲一个是结果集缓冲，net_buffer_length 指定这个缓冲区的初始值，max_allowed_packet 是这个缓冲区可以达到的最大值，缓冲区随着需要扩容。结果集缓冲在每次 statement 执行之后会恢复为初始值即 net_buffer_length。net_buffer_length 默认是 16k，最小值 1K，最大值1M）。</li><li>重复获取行，直到 net_buffer 写满，调用网络接口发出去(socket send buffer)。</li><li>如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。</li><li>如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。</li></ol><p>这个过程对应的流程图如下所示。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133247.jpg" alt="查询结果发送流程"></p><p>从这个流程中，你可以看到：</p><ol><li>一个查询在发送过程中，占用的 MySQL 内部的内存最大就是 net_buffer_length 这么大，并不会达到 200G；</li><li>socket send buffer 也不可能达到 200G（默认定义 <code>/proc/sys/net/core/wmem_default</code>），</li></ol><p>如果 socket send buffer 被写满，就会暂停读数据的流程。也就是说，MySQL 是“边读边发的”，这个概念很重要。这就意味着，如果客户端接收得慢，会导致 MySQL 服务端由于结果发不出去，这个事务的执行时间变长。比如下面这个状态，就是故意让客户端不去读 socket receive buffer 中的内容，然后在服务端 <code>show processlist</code> 看到的结果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133253.png" alt="服务端发送阻塞"></p><p><strong>如果看到 State 的值一直处于“Sending to client”，就表示服务器端的网络栈写满了</strong>。如果客户端使用<code>–quick</code> 参数，会使用 <code>mysql_use_result</code> 方法。这个方法是读一行处理一行。你可以想象一下，假设有一个业务的逻辑比较复杂，每读一行数据以后要处理的逻辑如果很慢，就会导致客户端要过很久才会去取下一行数据，可能就会出现如上图所示的这种情况。</p><ul><li><p>因此，对于业务开发来说，<strong>正常的线上业务，如果一个查询的返回结果不会很多的话，都建议你使用 <code>mysql_store_result</code> 这个接口，直接把查询结果保存到本地内存</strong>。当然前提是查询返回结果不多，否则可能会因为执行了一个大查询导致客户端占用内存上几十G的情况都有，这种情况下就需要改用 <code>mysql_use_result</code> 接口了。</p><blockquote><p>MySQL JDBC中的fetchSize()方法，不做分页通过一次大查询然后客户端流式读取来批量查询数据，这个内部原理就是使用了<code>mysql_use_result</code>接口读一行处理一行的接口。</p><ul><li>一次性取的好处是，对服务端只全表，只扫描一遍；坏处是可能会出现大事务。</li><li>一般更常见的做法还是调用 <code>mysql_store_result</code> 接口分批取，每一批拿到最大的一个id（主键值），下一批查询的时候用 <code>where Id &gt; N</code> 这种写法。</li></ul></blockquote></li><li><p>另一方面，对于 DBA 来说，如果在自己负责维护的 MySQL 里看到很多个线程都处于“Sending to client”这个状态，就意味着要让业务开发同学优化查询结果，并评估这么多的返回结果是否合理。而如果要快速减少处于这个状态的线程的话，将 net_buffer_length 参数设置为一个更大的值是一个可选方案（对于执行器来说，写进 net_buffer 的数据都算是执行完成了，不算到 sending data，即 sending data 指的是从存储引擎加载数据发送到 net buffer）。</p></li></ul><h3 id="Sending-to-data-状态"><a class="header-anchor" href="#Sending-to-data-状态">¶</a>Sending to data 状态</h3><p>与“Sending to client”长相很类似的一个状态是“Sending data”，这是一个经常被误会的问题。有同学问我说，在自己维护的实例上看到很多查询语句的状态是“Sending data”，但查看网络也没什么问题啊，为什么 Sending data 要这么久？实际上，一个查询语句的状态变化是这样的（注意：这里略去了其他无关的状态）：</p><ol><li>MySQL 查询语句进入执行阶段后，首先把状态设置成“Sending data”；</li><li>然后，发送执行结果的列相关的信息（meta data) 给客户端；</li><li>再继续执行语句的流程；</li><li>执行完成后，把状态设置成空字符串。</li></ol><p>也就是说，“Sending data”并不一定是指“正在发送数据”，而可能是处于执行器过程中的任意阶段。比如，可以构造一个锁等待的场景，就能看到 Sending data 状态。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133300.png" alt="读全表被锁"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133306.png" alt="Sending data 状态"></p><p>可以看到，session B 明显是在等锁，状态显示为 Sending data。也就是说，仅当一个线程处于“等待客户端接收结果”的状态，才会显示&quot;Sending to client&quot;；而如果显示成“Sending data”，它的意思只是“正在执行”。</p><p>综上，查询的结果是分段发给客户端的，因此扫描全表，查询返回大量的数据，并不会把内存打爆。在 server 层的处理逻辑我们都清楚了，在 InnoDB 引擎里面又是怎么处理的呢？ 扫描全表会不会对引擎系统造成影响呢？</p><h2 id="全表扫描对-InnoDB-的影响"><a class="header-anchor" href="#全表扫描对-InnoDB-的影响">¶</a>全表扫描对 InnoDB 的影响</h2><p>基于 WAL 机制， InnoDB 内存的一个作用，是保存更新的结果，再配合 redo log，就避免了随机写盘。内存的数据页是在 Buffer Pool (BP) 中管理的，在 WAL 里 Buffer Pool 起到了加速更新的作用。而实际上，Buffer Pool 还有一个更重要的作用，就是加速查询。</p><p>由于有 WAL 机制，当事务提交的时候，磁盘上的数据页是旧的，那如果这时候马上有一个查询要来读这个数据页，是不是要马上把 redo log 应用到数据页呢？答案是不需要。因为这时候内存数据页的结果是最新的，直接读内存页就可以了。你看，这时候查询根本不需要读磁盘，直接从内存拿结果，速度是很快的。所以说，Buffer Pool 还有加速查询的作用。而 Buffer Pool 对查询的加速效果，依赖于一个重要的指标，即：<strong>内存命中率</strong>。</p><p>可以在 <code>show engine innodb status</code> 结果中，查看一个系统当前的 BP 命中率。一般情况下，一个稳定服务的线上系统，要保证响应时间符合要求的话，内存命中率要在 99% 以上。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133315.png" alt="show engine innodb status 显示内存命中率"></p><p>如果所有查询需要的数据页都能够直接从内存得到，那是最好的，对应的命中率就是 100%。但，这在实际生产上是很难做到的。</p><p><strong>InnoDB Buffer Pool 的大小是由参数 <code>innodb_buffer_pool_size</code> 确定的</strong>，一般建议设置成可用物理内存的 60%~80%。</p><h3 id="InnoDB-内存池管理算法"><a class="header-anchor" href="#InnoDB-内存池管理算法">¶</a>InnoDB 内存池管理算法</h3><p>在大约十年前，单机的数据量是上百个 G，而物理内存是几个 G；现在虽然很多服务器都能有 128G 甚至更高的内存，但是单机的数据量却达到了 T 级别。所以，innodb_buffer_pool_size 小于磁盘的数据量是很常见的。如果一个 Buffer Pool 满了，而又要从磁盘读入一个数据页，那肯定是要淘汰一个旧数据页的。InnoDB 内存管理用的是最近最少使用 (Least Recently Used, LRU) 算法，这个算法的核心就是淘汰最久未使用的数据。</p><h4 id="普通的-LRU-算法"><a class="header-anchor" href="#普通的-LRU-算法">¶</a>普通的 LRU 算法</h4><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133322.jpg" alt="基本 LRU 算法"></p><p>InnoDB 管理 Buffer Pool 的 LRU 算法，是用链表来实现的。</p><ol><li>在上图的状态 1 里，链表头部是 P1，表示 P1 是最近刚刚被访问过的数据页；假设内存里只能放下这么多数据页；</li><li>这时候有一个读请求访问 P3，因此变成状态 2，P3 被移到最前面；</li><li>状态 3 表示，这次访问的数据页是不存在于链表中的，所以需要在 Buffer Pool 中新申请一个数据页 Px，加到链表头部。但是由于内存已经满了，不能申请新的内存。于是，会清空链表末尾 Pm 这个数据页的内存，存入 Px 的内容，然后放到链表头部。</li><li>从效果上看，就是最久没有被访问的数据页 Pm，被淘汰了。</li></ol><p>这个算法乍一看上去没什么问题，但是如果考虑到要做一个全表扫描，会不会有问题呢？假设按照这个算法，我们要扫描一个 200G 的表，而这个表是一个历史数据表，平时没有业务访问它。那么，按照这个算法扫描的话，就会把当前的 Buffer Pool 里的数据全部淘汰掉，存入扫描过程中访问到的数据页的内容。也就是说 Buffer Pool 里面主要放的是这个历史数据表的数据。对于一个正在做业务服务的库，这可不妙。你会看到，Buffer Pool 的内存命中率急剧下降，磁盘压力增加，SQL 语句响应变慢。</p><h4 id="InnoDB-的-LRU-算法"><a class="header-anchor" href="#InnoDB-的-LRU-算法">¶</a>InnoDB 的 LRU 算法</h4><p>所以，InnoDB 不能直接使用这个 LRU 算法。实际上，InnoDB 对 LRU 算法做了改进。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133331.png" alt="改进的 LRU 算法"></p><p>在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域。图中 LRU_old 指向的就是 old 区域的第一个位置，是整个链表的 5/8 处。也就是说，靠近链表头部的 5/8 是 young 区域，靠近链表尾部的 3/8 是 old 区域。改进后的 LRU 算法执行流程变成了下面这样：</p><ol><li><p>上图中状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态 2。</p></li><li><p>之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 Px，是放在 LRU_old 处。</p></li><li><p>处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：</p><ul><li>若这个数据页在 LRU 链表中存在的时间超过了 1 秒(最后一次被访问时间-第一次被访问时间)，就把它移动到链表头部(此时 young 区最后的数据页就会被挤到 old 了)；</li><li>如果这个数据页在 LRU 链表中存在的时间短于 1 秒(最后一次被访问时间-第一次被访问时间)，位置保持不变。1 秒这个时间，是由参数 <code>innodb_old_blocks_time</code> 控制的。其默认值是 1000，单位毫秒。</li></ul><blockquote><p>即每个数据页至少要在 old 段停留一秒，一秒之后还没被淘汰且还被访问到就会进入 young</p></blockquote></li></ol><blockquote><ul><li><p>和 JVM 的 young、old 不一样，JVM 的设计思想是大多对象朝生夕灭，所以它的 young/old 指的就是字面意思，一个对象存活长短，无论一个对象被访问地频繁与否，只要它的指针一直 GC Root 可达，就会越来越old，而越 old 的对象越难被淘汰；</p></li><li><p>这里 InnoDB 的 young/old 指的是对象的活跃度、新鲜度，一个对象如果越久没有被访问就越 old，而越 old 就越容易被淘汰，刚好相反。</p></li></ul></blockquote><p>这个策略，就是为了处理类似全表扫描的操作量身定制的。还是以刚刚的扫描 200G 的历史数据表为例，我们看看改进后的 LRU 算法的操作逻辑：</p><ol><li>扫描过程中，需要新插入的数据页，都被放到 old 区域 ;</li><li>一个数据页里面有多条记录，这个数据页会被多次访问到，但由于是顺序扫描，这个数据页第一次被访问和最后一次被访问的时间间隔不会超过 1 秒，因此还是会被保留在 old 区域；</li><li>再继续扫描后续的数据，之前的这个数据页之后也不会再被访问到，于是始终没有机会移到链表头部（也就是 young 区域），很快就会被淘汰出去。</li></ol><p>可以看到，这个策略最大的收益，就是在扫描这个大表的过程中，虽然也用到了 Buffer Pool，但是对 young 区域完全没有影响，从而保证了 Buffer Pool 响应正常业务的查询命中率。</p><h2 id="总结-v2"><a class="header-anchor" href="#总结-v2">¶</a>总结</h2><p>由于 MySQL 采用的是边算边发的逻辑，因此对于数据量很大的查询结果来说，不会在 server 端保存完整的结果集。所以，如果客户端读结果不及时，会堵住 MySQL 的查询过程，但是不会把内存打爆。而对于 InnoDB 引擎内部，由于有淘汰策略，大查询也不会导致内存暴涨。并且，由于 InnoDB 对 LRU 算法做了改进，冷数据的全表扫描，对 Buffer Pool 的影响也能做到可控。当然，全表扫描还是比较耗费 IO 资源的，所以业务高峰期还是不能直接在线上主库执行全表扫描的。</p><p>如果客户端由于压力过大，迟迟不能接收数据，对服务端的内存占用影响或许不大，但是更严重的是造成了“长事务”。至于长事务的影响，就要结合锁、MVCC 分析了。如果前面的语句有更新，意味着它们在占用着行锁，会导致别的语句更新被锁住；当然读的事务也有问题，就是会导致 undo log 不能被回收，导致回滚段空间膨胀。</p><p>另外一般我们说“MySQL挂掉”，其实大多数情况下就是响应慢了：</p><ul><li>如果说重启的话， 有一种是InnoDB 读 io迟迟不返回，会自己重启；</li><li>还有是 <code>innodb_buffer_pool_size</code> 设置太大，再加上server层使用的内存，是可能导致内存超过系统上限被 OOM。<strong>我们说一个大查询不会打爆，但是如果很多并发查询，还是可能的</strong>。</li></ul><h1>二十二、join</h1><p>在实际生产中，关于 join 语句使用的问题，一般会集中在以下两类：</p><ol><li>我们 DBA 不让使用 join，使用 join 有什么问题呢？</li><li>如果有两个大小不同的表做 join，应该用哪个表做驱动表呢？</li></ol><h2 id="先导：例子-v5"><a class="header-anchor" href="#先导：例子-v5">¶</a>先导：例子</h2><p>为了便于量化分析，创建两个表 t1 和 t2 来说明。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t2` (  `id` int(11) NOT NULL,  `a` int(11) DEFAULT NULL,  `b` int(11) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `a` (`a`)) ENGINE=InnoDB;drop procedure idata;delimiter ;;create procedure idata()begin  declare i int;  set i=1;  while(i<=1000)do    insert into t2 values(i, i, i);    set i=i+1;  end while;end;;delimiter ;call idata();create table t1 like t2;insert into t1 (select * from t2 where id<=100)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，这两个表都有一个主键索引 id 和一个索引 a，字段 b 上无索引。存储过程 <code>idata()</code> 往表 t2 里插入了 1000 行数据，在表 t1 里插入的是 100 行数据。</p><h2 id="Index-Nested-Loop-Join"><a class="header-anchor" href="#Index-Nested-Loop-Join">¶</a>Index Nested-Loop Join</h2><p>如果直接使用 join 语句，MySQL 优化器可能会选择表 t1 或 t2 作为驱动表，这样会影响我们分析 SQL 语句的执行过程。所以，为了便于分析执行过程中的性能问题，改用 <code>straight_join</code> 让 MySQL 使用固定的连接方式执行查询，这样优化器只会按照我们指定的方式去 join。在这个语句里，t1 是驱动表，t2 是被驱动表。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from t1 straight_join t2 on (t1.a=t2.a);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133342.png" alt="使用索引字段 join 的 explain 结果"></p><p>可以看到，在这条语句里，被驱动表 t2 的字段 a 上有索引，join 过程用上了这个索引，因此这个语句的执行流程是这样的：</p><ol><li>从表 t1 中读入一行数据 R；</li><li>从数据行 R 中，取出 a 字段到表 t2 里去查找；</li><li>取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；</li><li>重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。</li></ol><p>这个过程是先遍历表 t1，然后根据从表 t1 中取出的每行数据中的 a 值，去表 t2 中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称 NLJ。</p><p>它对应的流程图如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133349.jpg" alt="Index Nested-Loop Join 算法的执行流程"></p><p>在这个流程里：</p><ol><li>对驱动表 t1 做了全表扫描，这个过程需要扫描 100 行；</li><li>而对于每一行 R，根据 a 字段去表 t2 查找，走的是树搜索过程。由于我们构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描 100 行；</li><li>所以，整个执行流程，总扫描行数是 200。</li></ol><h3 id="能不能使用-join"><a class="header-anchor" href="#能不能使用-join">¶</a>能不能使用 join?</h3><p>假设不使用 join，那我们就只能用单表查询。我们看看上面这条语句的需求，用单表查询怎么实现。</p><ol><li>执行 <code>select * from t1</code>，查出表 t1 的所有数据，这里有 100 行；</li><li>循环遍历这 100 行数据：<ul><li>从每一行 R 取出字段 a 的值 <code>$R.a</code>；</li><li>执行 <code>select * from t2 where a=$R.a;</code></li><li>把返回的结果和 R 构成结果集的一行。</li></ul></li></ol><p>可以看到，在这个查询过程，也是扫描了 200 行，但是总共执行了 101 条语句，比直接 join 多了 100 次交互。除此之外，客户端还要自己拼接 SQL 语句和结果。显然，这么做还不如直接 join 好。</p><h3 id="怎么选择驱动表？"><a class="header-anchor" href="#怎么选择驱动表？">¶</a>怎么选择驱动表？</h3><p>在这个 join 语句执行过程中，驱动表是走全表扫描，而被驱动表是走树搜索。假设被驱动表的行数是 <code>M</code>。每次在被驱动表查一行数据，要先搜索索引 a，再搜索主键索引。每次搜索一棵树近似复杂度是以 2 为底的 <code>M</code> 的对数，记为 <code>log2M</code>，所以在被驱动表上查一行的时间复杂度是 <code>2*log2M</code>。假设驱动表的行数是 N，执行过程就要扫描驱动表 N 行，然后对于每一行，到被驱动表上匹配一次。因此整个执行过程，近似复杂度是 <code>N + N*2*log2M</code>。</p><p>显然，N 对扫描行数的影响更大，因此应该让小表来做驱动表。</p><blockquote><p>如果你没觉得这个影响有那么“显然”， 可以这么理解：N 扩大 1000 倍的话，扫描行数就会扩大 1000 倍；而 M 扩大 1000 倍，扫描行数扩大不到 10 倍。</p></blockquote><h3 id="小结-v5"><a class="header-anchor" href="#小结-v5">¶</a>小结</h3><p>通过上面的分析我们得到了两个结论：使用 join 语句，性能比强行拆成多个单表执行 SQL 语句的性能要好；如果使用 join 语句的话，需要让小表做驱动表。但是，你需要注意，这个结论的前提是“<strong>可以使用被驱动表的索引</strong>”。接下来，我们再看看被驱动表用不上索引的情况。</p><h2 id="Simple-Nested-Loop-Join"><a class="header-anchor" href="#Simple-Nested-Loop-Join">¶</a>Simple Nested-Loop Join</h2><p>现在，我们把 SQL 语句改成这样：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from t1 straight_join t2 on (t1.a=t2.b);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>由于表 t2 的字段 b 上没有索引，因此再用上图的执行流程时，<strong>每次到 t2 去匹配的时候，就要做一次全表扫描</strong>。你可以先设想一下这个问题，继续使用上图的算法，是不是可以得到正确的结果呢？如果只看结果的话，这个算法是正确的，而且这个算法也有一个名字，叫做“Simple Nested-Loop Join”。</p><p>但是，这样算来，这个 SQL 请求就要扫描表 t2 多达 100 次，总共扫描 100*1000=10 万行。这还只是两个小表，如果 t1 和 t2 都是 10 万行的表（当然了，这也还是属于小表的范围），就要扫描 100 亿行，这个算法看上去太“笨重”了。当然，MySQL 也没有使用这个 Simple Nested-Loop Join 算法，而是使用了另一个叫作“Block Nested-Loop Join”的算法，简称 BNL。</p><h2 id="Block-Nested-Loop-Join"><a class="header-anchor" href="#Block-Nested-Loop-Join">¶</a>Block Nested-Loop Join</h2><p>这时候，被驱动表上没有可用的索引，算法的流程是这样的：</p><ol><li>把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；</li><li>扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。</li></ol><p>这个过程的流程图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133359.jpg" alt="Block Nested-Loop Join 算法的执行流程"></p><p>对应地，这条 SQL 语句的 explain 结果如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133407.png" alt="不使用索引字段 join 的 explain 结果"></p><p>可以看到，在这个过程中，对表 t1 和 t2 都做了一次全表扫描，因此总的扫描行数是 1100。由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做 100 次判断，总共需要在内存中做的判断次数是：100*1000=10 万次。</p><p>前面我们说过，如果使用 Simple Nested-Loop Join 算法进行查询，扫描行数也是 10 万行。因此，从时间复杂度上来说，这两个算法是一样的。但是，Block Nested-Loop Join 算法的这 10 万次判断是内存操作，速度上会快很多，性能也更好。</p><h4 id="如何选择驱动表"><a class="header-anchor" href="#如何选择驱动表">¶</a>如何选择驱动表</h4><p>接下来，我们来看一下，在这种情况下，应该选择哪个表做驱动表。</p><h5 id="join-buffer-size-足够大：完全可以容纳两个表"><a class="header-anchor" href="#join-buffer-size-足够大：完全可以容纳两个表">¶</a><code>join_buffer_size</code> 足够大：完全可以容纳两个表</h5><p>假设小表的行数是 N，大表的行数是 M，那么在这个算法里：</p><ol><li>两个表都做一次全表扫描，所以总的扫描行数是 M+N；</li><li>内存中的判断次数是 M*N。</li></ol><p>可以看到，调换这两个算式中的 M 和 N 没差别，因此这时候选择大表还是小表做驱动表，执行耗时是一样的。</p><p><code>join_buffer_size</code> 不够大：只能容纳一个表或者两个都不行</p><p>这个例子里表 t1 才 100 行，要是表 t1 是一个大表，join_buffer 放不下怎么办呢？join_buffer 的大小是由参数 <code>join_buffer_size</code> 设定的，默认值是 256k。如果放不下表 t1 的所有数据话，策略很简单，就是分段放。我把 <code>join_buffer_size</code> 改成 1200，再执行：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from t1 straight_join t2 on (t1.a=t2.b);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行过程就变成了：</p><ol><li>扫描表 t1，顺序读取数据行放入 join_buffer 中，放完第 88 行 join_buffer 满了，继续第 2 步；</li><li>扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回；</li><li>清空 join_buffer；</li><li>继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步。</li></ol><p>执行流程图也就变成这样：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133413.jpg" alt="Block Nested-Loop Join--两段"></p><p>图中的步骤 4 和 5，表示清空 join_buffer 再复用。这个流程才体现出了这个算法名字中“Block”的由来，表示“分块去 join”。可以看到，这时候由于表 t1 被分成了两次放入 join_buffer 中，导致表 t2 会被扫描两次。虽然分成两次放入 join_buffer，但是判断等值条件的次数还是不变的，依然是 (88+12)*1000=10 万次。</p><p>我们再来看下，在这种情况下驱动表的选择问题。假设，驱动表的数据行数是 <code>N</code>，需要分 <code>K</code> 段才能完成算法流程，被驱动表的数据行数是 <code>M</code>。注意，这里的 <code>K</code> 不是常数，<code>N</code> 越大 <code>K</code> 就会越大，因此把 <code>K</code> 表示为<code>λ*N</code>，显然 <code>λ</code> 的取值范围是 <code>(0,1)</code>。所以，在这个算法的执行过程中：扫描行数是 <code>N+λ*N*M</code>；内存判断 <code>N*M</code> 次。</p><p>显然，内存判断次数是不受选择哪个表作为驱动表影响的。而考虑到扫描行数，在 <code>M</code> 和 <code>N</code> 大小确定的情况下，<code>N</code> 小一些，整个算式的结果会更小。所以结论是，<strong>应该让小表当驱动表</strong>。</p><p>当然，你会发现，在 <code>N+λ*N*M</code> 这个式子里，<code>λ</code> 才是影响扫描行数的关键因素，这个值越小越好。刚刚我们说了 <code>N</code> 越大，分段数 <code>K</code> 越大。那么，<code>N</code> 固定的时候，什么参数会影响 <code>K</code> 的大小呢？（也就是 <code>λ</code> 的大小）答案是 <code>join_buffer_size</code>。<code>join_buffer_size</code> 越大，一次可以放入的行越多，分成的段数也就越少，对被驱动表的全表扫描次数就越少。这就是为什么，你可能会看到一些建议告诉你，如果你的 join 语句很慢，就把 <code>join_buffer_size</code> 改大。</p><h2 id="总结-v3"><a class="header-anchor" href="#总结-v3">¶</a>总结</h2><p>理解了 MySQL 执行 join 的两种算法，现在我们再来看开头的两个问题。</p><h3 id="能不能使用-join-语句？"><a class="header-anchor" href="#能不能使用-join-语句？">¶</a>能不能使用 join 语句？</h3><ol><li><p>如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的；</p></li><li><p>如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。尤其是在大表上的 join 操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用。</p></li></ol><p>所以你在判断要不要使用 join 语句时，就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样。</p><h3 id="如果要使用-join，应该选择大表做驱动表还是选择小表做驱动表？"><a class="header-anchor" href="#如果要使用-join，应该选择大表做驱动表还是选择小表做驱动表？">¶</a>如果要使用 join，应该选择大表做驱动表还是选择小表做驱动表？</h3><ol><li>如果是 Index Nested-Loop Join 算法，应该选择小表做驱动表；</li><li>如果是 Block Nested-Loop Join 算法：在 <code>join_buffer_size</code> 足够大的时候，是一样的；在 <code>join_buffer_size</code> 不够大的时候（这种情况更常见），应该选择小表做驱动表。</li></ol><p>所以，这个问题的结论就是，总是应该使用小表做驱动表。当然了，这里我需要说明下，什么叫作“小表”。我们前面的例子是没有加条件的。如果在语句的 <code>where</code> 条件加上 <code>t2.id&lt;=50</code> 这个限定条件，再来看下这两条语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from t1 straight_join t2 on (t1.b=t2.b) where t2.id<=50;select * from t2 straight_join t1 on (t1.b=t2.b) where t2.id<=50;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意，为了让两条语句的被驱动表都用不上索引，所以 join 字段都使用了没有索引的字段 b。但如果是用第二个语句的话，<code>join_buffer</code> 只需要放入 t2 的前 50 行，显然是更好的。所以这里，“t2 的前 50 行”是那个相对小的表，也就是“小表”。</p><p>我们再来看另外一组例子：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select t1.b,t2.* from  t1  straight_join t2 on (t1.b=t2.b) where t2.id<=100;select t1.b,t2.* from  t2  straight_join t1 on (t1.b=t2.b) where t2.id<=100;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这个例子里，表 t1 和 t2 都是只有 100 行参加 join。但是，这两条语句每次查询放入 <code>join_buffer</code> 中的数据是不一样的：</p><ul><li>表 t1 只查字段 b，因此如果把 t1 放到 <code>join_buffer</code> 中，则 <code>join_buffer</code> 中只需要放入 b 的值；</li><li>表 t2 需要查所有的字段，因此如果把表 t2 放到 join_buffer 中的话，就需要放入三个字段 id、a 和 b。</li></ul><p>这里，我们应该选择表 t1 作为驱动表。也就是说在这个例子里，“只需要一列参与 join 的表 t1”是那个相对小的表。</p><p>所以，更准确地说，<strong>在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表</strong>。</p><h2 id="join-优化"><a class="header-anchor" href="#join-优化">¶</a>join 优化</h2><p>使用 NLJ 算法的时候，其实效果还是不错的，比通过应用层拆分成多个语句然后再拼接查询结果更方便，而且性能也不会差。但是，BNL 算法在大表 join 的时候性能就差多了，比较次数等于两个表参与 join 的行数的乘积，很消耗 CPU 资源。当然了，这两个算法都还有继续优化的空间。</p><p>为了便于分析，创建两个表 t1、t2 来展开。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create table t1(id int primary key, a int, b int, index(a));create table t2 like t1;drop procedure idata;delimiter ;;create procedure idata()begin  declare i int;  set i=1;  while(i<=1000)do    insert into t1 values(i, 1001-i, i);    set i=i+1;  end while;    set i=1;  while(i<=1000000)do    insert into t2 values(i, i, i);    set i=i+1;  end while;end;;delimiter ;call idata();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为了便于后面量化说明，在表 t1 里，插入了 1000 行数据，每一行的 a=1001-id 的值。也就是说，表 t1 中字段 a 是逆序的。同时，在表 t2 中插入了 100 万行数据。</p><h3 id="Multi-Range-Read-优化"><a class="header-anchor" href="#Multi-Range-Read-优化">¶</a>Multi-Range Read 优化</h3><p>在介绍 join 语句的优化方案之前，需要先介绍一个知识点，即：Multi-Range Read 优化 (MRR)。这个优化的主要目的是尽量使用顺序读盘。回表是指，InnoDB 在普通索引 a 上查到主键 id 的值后，再根据一个个主键 id 的值到主键索引上去查整行数据的过程。那么回表过程是一行行地查数据，还是批量地查数据？我们先来看看这个问题。假设，执行这个语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from t1 where a>=1 and a<=100;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>主键索引是一棵 B+ 树，在这棵树上，每次只能根据一个主键 id 查到一行数据。因此，回表肯定是一行行搜索主键索引的，基本流程如图所示。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133424.png" alt="基本回表流程"></p><p>如果随着 a 的值递增顺序查询的话，id 的值就变成随机的，那么就会出现随机访问，性能相对较差。虽然“按行查”这个机制不能改，但是调整查询的顺序，还是能够加速的。因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能（<strong>降低磁盘随机读带来的寻道及旋转延迟耗时、以及在内存紧张的情况下充分提高内存页的命中率</strong>）。</p><p>这就是 MRR 优化的设计思路。此时，语句的执行流程变成了这样：</p><ol><li>根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;</li><li>将 read_rnd_buffer 中的 id 进行递增排序；</li><li>排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。</li></ol><p>这里，read_rnd_buffer 的大小是由 <code>read_rnd_buffer_size</code> 参数控制的。如果步骤 1 中，read_rnd_buffer 放满了，就会先执行完步骤 2 和 3，然后清空 read_rnd_buffer。之后继续找索引 a 的下个记录，并继续循环。</p><blockquote><p>另外需要说明的是，如果你想要稳定地使用 MRR 优化的话，需要设置<code>set optimizer_switch=&quot;mrr_cost_based=off&quot;</code>。（官方文档的说法，是现在的优化器策略，判断消耗的时候，会更倾向于不使用 MRR，把 mrr_cost_based 设置为 off，就是固定使用 MRR 了。）</p></blockquote><p>下面两幅图就是使用了 MRR 优化后的执行流程和 explain 结果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133431.jpg" alt="MRR 执行流程"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133440.png" alt="MRR 执行流程的 explain 结果"></p><p>从 explain 结果中，我们可以看到 Extra 字段多了 Using MRR，表示的是用上了 MRR 优化。而且，由于我们在 read_rnd_buffer 中按照 id 做了排序，所以最后得到的结果集也是按照主键 id 递增顺序的，也就是与前面未使用 MRR 的结果集中行的顺序相反。</p><h4 id="小结-v6"><a class="header-anchor" href="#小结-v6">¶</a>小结</h4><p>MRR 能够提升性能的核心在于，这条查询语句<strong>在索引 a 上做的是一个范围查询</strong>（也就是说，这是一个多值查询），可以得到足够多的主键 id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。</p><h5 id="不要使用-MMR-的场景"><a class="header-anchor" href="#不要使用-MMR-的场景">¶</a>不要使用 MMR 的场景</h5><p><code>select * from t1 where a&gt;=1 and a&lt;=100 order by a;</code> 语句，a是索引列，此时就不要使用 MMR 了，因为查询出来的数据就是要按照 a 排序的，且存在索引 a ，不使用 MMR 的情况下查询出来的数据就是有序的。如果还要使用 MMR，就会在查询出结果后增加额外排序，且 MMR 又带来了 read_rnd_buffer 的消耗和排序 id 的消耗，得不偿失。</p><h3 id="Batched-Key-Access"><a class="header-anchor" href="#Batched-Key-Access">¶</a>Batched Key Access</h3><p>理解了 MRR 性能提升的原理，我们就能理解 MySQL 在 5.6 版本后开始引入的 Batched Key Access(BKA) 算法了。<strong>这个 BKA 算法，其实就是对 NLJ 算法的优化</strong>。</p><p>再来看看 NLJ 算法的流程图：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133448.jpg" alt="Index Nested-Loop Join 流程图"></p><p>NLJ 算法执行的逻辑是：从驱动表 t1，一行行地取出 a 的值，再到被驱动表 t2 去做 join。也就是说，对于表 t2 来说，每次都是匹配一个值。这时，MRR 的优势就用不上了。</p><p>那怎么才能一次性地多传些值给表 t2 呢？方法就是，从表 t1 里一次性地多拿些行出来，一起传给表 t2。既然如此，我们就把表 t1 的数据取出来一部分，先放到一个临时内存。这个临时内存不是别人，就是 join_buffer。join_buffer 在 BNL 算法里的作用，是暂存驱动表的数据。但是在 NLJ 算法里并没有用。那么，我们刚好就可以复用 join_buffer 到 BKA 算法中。</p><p>下图是上面的 NLJ 算法优化后的 BKA 算法的流程。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133456.png" alt="Batched Key Access 流程"></p><p>图中，在 join_buffer 中放入的数据是 P1~P100，表示的是只会取查询需要的字段。当然，如果 join buffer 放不下 P1~P100 的所有数据，就会把这 100 行数据分成多段执行上图的流程。</p><p>那么，这个 BKA 算法到底要怎么启用呢？如果要使用 BKA 优化算法的话，你需要在执行 SQL 语句之前，先设置</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中，前两个参数的作用是要启用 MRR。这么做的原因是，BKA 算法的优化要依赖于 MRR。</p><h3 id="BNL-算法的性能问题"><a class="header-anchor" href="#BNL-算法的性能问题">¶</a>BNL 算法的性能问题</h3><p>说完了 NLJ 算法的优化，我们再来看 BNL 算法的优化。</p><p>在使用 Block Nested-Loop Join(BNL) 算法时，可能会对被驱动表做多次扫描。如果这个被驱动表是一个大的冷数据表，除了会导致 IO 压力大以外，还会对系统有什么影响呢？</p><p>由于 InnoDB 对 Bufffer Pool 的 LRU 算法做了优化，即：第一次从磁盘读入内存的数据页，会先放在 old 区域，且在一秒之内都只能存在 old 区域，如果此期间有其它数据页插入到 old 区或者 young 区，该数据页就会一直被往后推直到被提出 LRU 队列；如果能够坚持到一秒之后还没被提出且再被访问到的时候，就会移动到队首进入 young 区。</p><p>此时我们针对 BNL 的被驱动表是一个较小的表和一个较大的表分别进行分析（较大较小是和 old 区的相对概念，整个表都能存在 old 区就是较小表；否则较大表），在此之前，我们假设被驱动表是一个冷表且驱动表不能完全装入 join_buffer，需要分批，则被驱动表需要多次扫描，这是最差的情况：</p><ul><li><p>被驱动表是较小表：</p><p>这种情况下，被驱动表数据量小于整个 buffer pool 的 3/8，能够完全放入 old 区域。如果一个使用 BNL 算法的 join 语句，多次扫描一个冷表，而且这个语句执行时间超过 1 秒，就会在再次扫描冷表的时候，把冷表的数据页移到 LRU 链表头部，进入 young 区域，此时就会导致：</p><ol><li>原本在 young 区真正的热点 page 被挤到 old 区了。</li><li>在 join 语句执行完之后，被驱动表的数据就真正的冷却了，将很少被访问到，此时 MySQL 会逐渐淘汰这些数据页，修复 LRU 链表的冷热特征，但是因为这些冷表(被驱动表)的数据页被移动到 young 区，导致修复周期加长，此间总体内存命中率低。</li></ol></li><li><p>被驱动表是较大表：</p><p>如果这个冷表很大，就会出现另外一种情况：业务正常访问的数据页，没有机会进入 young 区域。由于优化机制的存在，一个正常访问的数据页，要进入 young 区域，需要隔 1 秒后再次被访问到。但是，由于我们的 join 语句在循环读磁盘和淘汰内存页，进入 old 区域的数据页，很可能在 1 秒之内就被淘汰了。这样，就会导致：</p><ol><li>这个 MySQL 实例的 Buffer Pool 在这段时间内，young 区域的数据页没有被合理地淘汰。</li><li>IO 负载变高</li></ol><blockquote><p>假设大表t大小是M页&gt;old区域N页，由于Block Nested-Loop Join需要对t进行k次全表扫描。第一次扫描时，1<sub>N页依次被放入old区域，访问N+1页时淘汰1页，放入N+1页，以此类推，第一次扫描结束后old区域存放的是M-N+1</sub>M页。第二次扫描开始，访问1页，淘汰M-N+1页，放入1页。可以把M页想象成一个环，N页想象成在这个环上滑动的窗口，由于M&gt;N，如果一个数据页内的数据行数量不能支撑 MySQL 扫描 1s，那么将永远不会有被驱动表的数据页&quot;因为被访问的时候在LRU链表上存在超过1s进入young区&quot;：</p><ul><li>如果 page size 太小，或者一行数据太多，就会导致扫描被驱动表的时候在一个 page 上停留的时间很短，就要到磁盘加载下一个 page，此时冷表数据页无法进入 young 区，在 old 区此时循环加载和淘汰尾部数据页。</li><li>如果 page size 太大，或者一行数据太少，导致扫描被驱动表的时候在一个 page 上停留时间长，从磁盘加载下一个内存页时间变慢，使得访问该页超过了1s，这样被驱动表的数据页将会进入 young 区。</li></ul></blockquote></li></ul><p>也就是说，这两种情况都会影响 Buffer Pool 的正常运作。**大表 join 操作虽然对 IO 有影响，但是在语句执行结束后，对 IO 的影响也就结束了。但是，对 Buffer Pool 的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。**为了减少这种影响，你可以考虑增大 join_buffer_size 的值，减少对被驱动表的扫描次数。</p><p>也就是说，BNL 算法对系统的影响主要包括三个方面：</p><ol><li>可能会多次扫描被驱动表，占用磁盘 IO 资源；</li><li>判断 join 条件需要执行 M*N 次对比（M、N 分别是两张表的行数），如果是大表就会占用非常多的 CPU 资源；</li><li>可能会导致 Buffer Pool 的热数据被淘汰，影响内存命中率。</li></ol><h4 id="优化：BNL-转-BKA"><a class="header-anchor" href="#优化：BNL-转-BKA">¶</a>优化：BNL 转 BKA</h4><p>我们执行语句之前，需要通过理论分析和查看 explain 结果的方式，确认是否要使用 BNL 算法。如果确认优化器会使用 BNL 算法，就需要做优化。优化的常见做法是，给被驱动表的 join 字段加上索引，把 BNL 算法转成 BKA 算法。接下来，我们就具体看看，这个优化怎么做？</p><p><strong>一些情况下，我们可以直接在被驱动表上建索引，这时就可以直接转成 BKA 算法了</strong>。但是，有时候你确实会碰到一些不适合在被驱动表上建索引的情况。比如下面这个语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from t1 join t2 on (t1.b=t2.b) where t2.b>=1 and t2.b<=2000;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>表 t2 中是插入了 100 万行数据，但是经过 where 条件过滤后，需要参与 join 的只有 2000 行数据。如果这条语句同时是一个低频的 SQL 语句，那么再为这个语句在表 t2 的字段 b 上创建一个索引就很浪费了（当该查询频率很低的时候，此时认为写数据和读数据频率一致，而写数据的时候维护索引和读数据全表扫描索引的相比前者成本高）。</p><p>但是，如果使用 BNL 算法来 join 的话，这个语句的执行流程是这样的：</p><ol><li>把表 t1 的所有字段取出来，存入 join_buffer 中。这个表只有 1000 行，join_buffer_size 默认值是 256k，可以完全存入。</li><li>扫描表 t2，取出每一行数据跟 join_buffer 中的数据进行对比，<ul><li>如果不满足 t1.b=t2.b，则跳过；</li><li>如果满足 t1.b=t2.b, 再判断其他条件，也就是是否满足 t2.b 处于[1,2000]的条件，如果是，就作为结果集的一部分返回，否则跳过。</li></ul></li></ol><p>对于表 t2 的每一行，判断 join 是否满足的时候，都需要遍历 join_buffer 中的所有行。因此判断等值条件的次数是 1000*100 万 =10 亿次，这个判断的工作量很大。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133507.png" alt="BNL explain 结果"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133512.png" alt="语句执行时间"></p><p>可以看到，explain 结果里 Extra 字段显示使用了 BNL 算法。在我的测试环境里，这条语句需要执行 1 分 11 秒。</p><h4 id="建立临时表"><a class="header-anchor" href="#建立临时表">¶</a>建立临时表</h4><p>在表 t2 的字段 b 上创建索引会浪费资源，但是不创建索引的话这个语句的等值条件要判断 10 亿次，想想也是浪费。那么，有没有两全其美的办法呢？这时候，我们可以考虑<strong>使用临时表</strong>。使用临时表的大致思路是：</p><ol><li>把表 t2 中满足条件的数据放在临时表 <code>tmp_t</code> 中；</li><li>为了让 join 使用 BKA 算法，给临时表 <code>tmp_t</code> 的字段 <code>b</code> 加上索引；</li><li>让表 <code>t1</code> 和 <code>tmp_t</code> 做 join 操作。</li></ol><p>此时，对应的 SQL 语句的写法如下：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create temporary table temp_t(id int primary key, a int, b int, index(b))engine=innodb;insert into temp_t select * from t2 where b>=1 and b<=2000;select * from t1 join temp_t on (t1.b=temp_t.b);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>下图就是这个语句序列的执行效果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133519.png" alt="使用临时表的执行效果"></p><p>可以看到，整个过程 3 个语句执行时间的总和还不到 1 秒，相比于前面的 1 分 11 秒，性能得到了大幅提升。接下来，我们一起看一下这个过程的消耗：</p><ol><li>执行 insert 语句构造 <code>temp_t</code> 表并插入数据的过程中，对表 <code>t2</code> 做了全表扫描，这里扫描行数是 100 万。</li><li>之后的 join 语句，扫描表 <code>t1</code>，这里的扫描行数是 1000；join 比较过程中，做了 1000 次带索引的查询。相比于优化前的 join 语句需要做 10 亿次条件判断来说，这个优化效果还是很明显的。</li></ol><p>总体来看，不论是在原表上加索引，还是用有索引的临时表，我们的思路都是<strong>让 join 语句能够用上被驱动表上的索引</strong>，来触发 BKA 算法，提升查询性能。</p><h4 id="扩展：hash-join"><a class="header-anchor" href="#扩展：hash-join">¶</a>扩展：hash join</h4><p>其实上面计算 10 亿次那个操作，看上去有点儿傻。如果 join_buffer 里面维护的不是一个无序数组，而是一个哈希表的话，那么就不是 10 亿次判断，而是 100 万次 hash 查找。这样的话，整条语句的执行速度就快多了吧？确实如此。这，也正是 MySQL 的优化器和执行器一直被诟病的一个原因：不支持哈希 join。并且，MySQL 官方的 roadmap，也是迟迟没有把这个优化排上议程。</p><p>实际上，这个优化思路，我们可以自己实现在业务端。实现流程大致如下：<code>select * from t1;</code>取得表 t1 的全部 1000 行数据，在业务端存入一个 hash 结构，比如 C++ 里的 set、PHP 的数组这样的数据结构。<code>select * from t2 where b&gt;=1 and b&lt;=2000;</code> 获取表 t2 中满足条件的 2000 行数据。把这 2000 行数据，一行一行地取到业务端，到 hash 结构的数据表中寻找匹配的数据。满足匹配的条件的这行数据，就作为结果集的一行。理论上，这个过程会比临时表方案的执行速度还要快一些。</p><h3 id="优化例子"><a class="header-anchor" href="#优化例子">¶</a>优化例子</h3><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t1` ( `id` int(11) NOT NULL, `a` int(11) DEFAULT NULL, `b` int(11) DEFAULT NULL, `c` int(11) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB;create table t2 like t1;create table t3 like t2;insert into ... //初始化三张表的数据<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from t1 join t2 on(t1.a=t2.a) join t3 on (t2.b=t3.b) where t1.c>=X and t2.c>=Y and t3.c>=Z;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>为了得到最快的执行速度，如果让你来设计表 t1、t2、t3 上的索引，来支持这个 join 语句，你会加哪些索引呢？</p><p>第一原则是要尽量使用 BKA 算法。需要注意的是，使用 BKA 算法的时候，并不是“先计算两个表 join 的结果，再跟第三个表 join”，而是直接嵌套查询的。具体实现是：在 t1.c&gt;=X、t2.c&gt;=Y、t3.c&gt;=Z 这三个条件里，选择一个经过过滤以后，数据最少的那个表，作为第一个驱动表。此时，可能会出现如下两种情况。</p><ul><li><p>第一种情况，如果选出来是表 t1 或者 t3，那剩下的部分就固定了。</p><ul><li><p>如果驱动表是 t1，则连接顺序是 t1-&gt;t2-&gt;t3，要在被驱动表字段创建上索引，也就是 t2.a 和 t3.b 上创建索引；</p><blockquote><p>如：t1增加索引©、t2增加组合索引(b,c)、t3增加组合索引(b,c)；语句改成：<code>select * from t1 straight_join t2 on(t1.a=t2.a) straight_join t3 on (t2.b=t3.b) where t1.c&gt;=X and t2.c&gt;=Y and t3.c&gt;=Z;</code></p></blockquote></li><li><p>如果驱动表是 t3，则连接顺序是 t3-&gt;t2-&gt;t1，需要在 t2.b 和 t1.a 上创建索引。同时，我们还需要在第一个驱动表的字段 c 上创建索引。</p></li></ul></li><li><p>第二种情况是，如果选出来的第一个驱动表是表 t2 的话，则需要评估另外两个条件的过滤效果。</p></li></ul><p>总之，整体的思路就是，尽量让每一次参与 join 的驱动表的数据集，越小越好，因为这样我们的驱动表就会越小。</p><h2 id="join-的写法"><a class="header-anchor" href="#join-的写法">¶</a>join 的写法</h2><p>上面介绍 join 执行顺序的时候，用的都是 <code>straight_join</code></p><ul><li>如果用 left join 的话，左边的表一定是驱动表吗？</li><li>如果两个表的 join 包含多个条件的等值匹配，是都要写到 on 里面呢，还是只把一个条件写到 on 里面，其他条件写到 <code>where</code> 部分？</li></ul><h3 id="例子说明"><a class="header-anchor" href="#例子说明">¶</a>例子说明</h3><p>构造两个表 a 和 b：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create table a(f1 int, f2 int, index(f1))engine=innodb;create table b(f1 int, f2 int)engine=innodb;insert into a values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6);insert into b values(3,3),(4,4),(5,5),(6,6),(7,7),(8,8);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>表 a 和 b 都有两个字段 f1 和 f2，不同的是表 a 的字段 f1 上有索引。然后，我往两个表中都插入了 6 条记录，其中在表 a 和 b 中同时存在的数据有 4 行。<strong>上面的第二个问题</strong>，其实就是下面这种写法的区别：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from a left join b on(a.f1=b.f1) and (a.f2=b.f2); /*Q1*/select * from a left join b on(a.f1=b.f1) where (a.f2=b.f2);/*Q2*/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>首先，需要说明的是，这两个 <code>left join</code> 语句的语义逻辑并不相同。我们先来看一下它们的执行结果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133530.png" alt="两个 join 的查询结果"></p><p>可以看到：</p><ul><li>语句 Q1 返回的数据集是 6 行，表 a 中即使没有满足匹配条件的记录，查询结果中也会返回一行，并将表 b 的各个字段值填成 NULL。</li><li>语句 Q2 返回的是 4 行。从逻辑上可以这么理解，最后的两行，由于表 b 中没有匹配的字段，结果集里面 b.f2 的值是空，不满足 where 部分的条件判断，因此不能作为结果集的一部分。</li></ul><p>接下来，我们看看实际执行这两条语句时，MySQL 是怎么做的。我们先一起看看语句 Q1 的 explain 结果：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133539.png" alt="Q1 的 explain 结果"></p><p>可以看到，这个结果符合我们的预期：</p><ul><li>驱动表是表 a，被驱动表是表 b；</li><li>由于表 b 的 f1 字段上没有索引，所以使用的是 Block Nested Loop Join（简称 BNL） 算法。</li></ul><p>看到 BNL 算法，你就应该知道这条语句的执行流程其实是这样的：</p><ol><li>把表 a 的内容读入 join_buffer 中。因为是 select * ，所以字段 f1 和 f2 都被放入 join_buffer 了。</li><li>顺序扫描表 b，对于每一行数据，判断 join 条件（也就是 <code>(a.f1=b.f1) and (a.f2=b.f2)</code>）是否满足，满足条件的记录, 作为结果集的一行返回。如果语句中有 where 子句，需要先判断 where 部分满足条件后，再返回。</li><li>表 b 扫描完成后，对于没有被匹配的表 a 的行（在这个例子中就是 (1,1)、(2,2) 这两行），把剩余字段补上 NULL，再放入结果集中。</li></ol><p>对应的流程图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133547.jpg" alt="left join -BNL 算法"></p><p>可以看到，这条语句确实是以表 a 为驱动表，而且从执行效果看，也和使用 <code>straight_join</code> 是一样的。那语句 Q2 的查询结果里面少了最后两行数据，是不是就是把上面流程中的步骤 3 去掉呢？我们还是先看一下语句 Q2 的 expain 结果吧。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133554.png" alt="Q2 的 explain 结果"></p><p>可以看到，这条语句是以表 b 为驱动表的。而如果一条 join 语句的 Extra 字段什么都没写的话，就表示使用的是 Index Nested-Loop Join（简称 NLJ）算法。因此，语句 Q2 的执行流程是这样的：顺序扫描表 b，每一行用 <code>b.f1</code> 到表 a 中去查，匹配到记录后判断 <code>a.f2=b.f2</code> 是否满足，满足条件的话就作为结果集的一部分返回。</p><p>那么，为什么语句 Q1 和 Q2 这两个查询的执行流程会差距这么大呢？其实，这是因为优化器基于 Q2 这个查询的语义做了优化。为了理解这个问题，需要知道一个背景知识点：在 MySQL 里，NULL 跟任何值执行等值判断和不等值判断的结果，都是 NULL。这里包括， select NULL = NULL 的结果，也是返回 NULL。因此，语句 Q2 里面 <code>where a.f2=b.f2</code> 就表示，查询结果里面不会包含 <code>b.f2</code> 是 NULL 的行，这样这个 <code>left join</code> 的语义就是“找到这两个表里面，f1、f2 对应相同的行。对于表 a 中存在，而表 b 中匹配不到的行，就放弃”（<code>where a.f2=b.f2</code> 的意思是 <code>where (a.f2 is not null) and (b.f2 is not null) and (a.f2 =b.f2)</code>，因为 <code>on a.f1=b.f1</code> 和 <code>where a.f2=b.f2</code> 是与关系，所以后者对前者的<code>left join</code>不匹配则填充 null 行为限制退化成了和<code>join</code>语义一样的行为）。</p><p>这样，这条语句虽然用的是 <code>left join</code>，但是语义跟 <code>join</code> 是一致的。因此，优化器就把这条语句的 <code>left join</code> 改写成了 <code>join</code>，然后因为表 a 的 <code>f1</code> 上有索引，就把表 b 作为驱动表，这样就可以用上 NLJ 算法。在执行 explain 之后，你再执行 show warnings，就能看到这个改写的结果，如图所示。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133602.png" alt="Q2 的改写结果"></p><p>这个例子说明，即使我们在 SQL 语句中写成 <code>left join</code>，执行过程还是有可能不是从左到右连接的。也就是说，<strong>使用 <code>left join</code> 时，左边的表不一定是驱动表。这样看来，如果需要 <code>left join</code> 的语义，就不能把被驱动表的字段放在 <code>where</code> 条件里面做等值判断或不等值判断，必须都写在 <code>on</code> 里面</strong>。那如果是 <code>join</code> 语句呢？这时候，我们再看看这两条语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from a join b on(a.f1=b.f1) and (a.f2=b.f2); /*Q3*/select * from a join b on(a.f1=b.f1) where (a.f2=b.f2);/*Q4*/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>我们再使用一次看 explain 和 show warnings 的方法，看看优化器是怎么做的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133618.png" alt="join 语句改写"></p><p>可以看到，这两条语句都被改写成：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from a join b where (a.f1=b.f1) and (a.f2=b.f2);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行计划自然也是一模一样的。也就是说，在这种情况下，<strong>join 将判断条件是否全部放在 on 部分就没有区别</strong>了。</p><h1>二十三、临时表</h1><p>在优化 join 查询的时候使用到了临时表：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create temporary table temp_t like t1;alter table temp_t add index(b);insert into temp_t select * from t2 where b>=1 and b<=2000;select * from t1 join temp_t on (t1.b=temp_t.b);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>有的人可能会认为，临时表就是内存表。但是，这两个概念可是完全不同的。</p><ul><li>内存表，指的是使用 Memory 引擎的表，建表语法是 <code>create table … engine=memory</code>。这种表的数据都保存在内存里，系统重启的时候会被清空，但是<strong>表结构还在</strong>。除了这两个特性看上去比较“奇怪”外，从其他的特征上看，它就是一个正常的表。</li><li>而临时表，可以使用各种引擎类型 。如果是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，写数据的时候是写到磁盘上的。当然，临时表也可以使用 Memory 引擎。</li></ul><p>弄清楚了内存表和临时表的区别以后，我们再来看看临时表有哪些特征。</p><h2 id="临时表的特性"><a class="header-anchor" href="#临时表的特性">¶</a>临时表的特性</h2><p>为了便于理解，我们来看下下面这个操作序列：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133627.png" alt="临时表特性示例"></p><p>可以看到，临时表在使用上有以下几个特点：</p><ol><li>建表语法是 <code>create temporary table …</code>。</li><li>一个临时表只能被创建它的 session 访问，对其他线程不可见。所以，图中 session A 创建的临时表 t，对于 session B 就是不可见的。</li><li>临时表可以与普通表同名。</li><li>session A 内有同名的临时表和普通表的时候，<code>show create</code> 语句，以及增删改查语句访问的是临时表。</li><li><code>show tables</code> 命令不显示临时表。</li></ol><p>由于临时表只能被创建它的 session 访问，所以在这个 session 结束的时候，会自动删除临时表。也正是由于这个特性，临时表就特别适合我们文章开头的 join 优化这种场景。为什么呢？原因主要包括以下两个方面：</p><ol><li><p>不同 session 的临时表是可以重名的，如果有多个 session 同时执行 join 优化，不需要担心表名重复导致建表失败的问题。</p></li><li><p>不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表由于会自动回收，所以不需要这个额外的操作。</p><blockquote><p>但是需要注意的时候，现在的数据库连接通常都是使用连接池管理，不会轻易关闭，所以临时表用完就删除是一个好习惯。</p></blockquote></li></ol><h2 id="临时表的应用场景示例：分库分表"><a class="header-anchor" href="#临时表的应用场景示例：分库分表">¶</a>临时表的应用场景示例：分库分表</h2><p>由于不用担心线程之间的重名冲突，临时表经常会被用在复杂查询的优化过程中。其中，分库分表系统的跨库查询就是一个典型的使用场景。一般分库分表的场景，就是要把一个逻辑上的大表分散到不同的数据库实例上。比如。将一个大表 <code>ht</code>，按照字段 <code>f</code>，拆分成 1024 个分表，然后分布到 32 个数据库实例上。如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133635.jpg" alt="分库分表简图"></p><p>一般情况下，这种分库分表系统都有一个中间层 proxy。不过，也有一些方案会让客户端直接连接数据库，也就是没有 proxy 这一层。在这个架构中，分区 key 的选择是以“减少跨库和跨表查询”为依据的。如果大部分的语句都会包含 <code>f</code> 的等值条件，那么就要用 <code>f</code> 做分区键。这样，在 proxy 这一层解析完 SQL 语句以后，就能确定将这条语句路由到哪个分表做查询。比如下面这条语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select v from ht where f=N;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这时，我们就可以通过分表规则（比如，<code>N%1024</code>) 来确认需要的数据被放在了哪个分表上。这种语句只需要访问一个分表，是分库分表方案最欢迎的语句形式了。</p><p>但是，如果这个表上还有另外一个索引 <code>k</code>，并且查询语句是这样的：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select v from ht where k >= M order by t_modified desc limit 100;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这时候，由于查询条件里面没有用到分区字段 <code>f</code>，只能到所有的分区中去查找满足条件的所有行，然后统一做 <code>order by</code> 的操作。这种情况下，有两种比较常用的思路。</p><ol><li><p><strong>第一种思路</strong>是，在 proxy 层的进程代码中实现排序。</p><p>这种方式的优势是处理速度快，拿到分库的数据以后，直接在内存中参与计算。不过，这个方案的缺点也比较明显：</p><ul><li>需要的开发工作量比较大。我们举例的这条语句还算是比较简单的，如果涉及到复杂的操作，比如 group by，甚至 join 这样的操作，对中间层的开发能力要求比较高；</li><li>对 proxy 端的压力比较大，尤其是很容易出现内存不够用和 CPU 瓶颈的问题。</li></ul></li><li><p><strong>另一种思路</strong>就是，把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在这个汇总实例上做逻辑操作。</p><p>比如上面这条语句，执行流程可以类似这样：</p><ul><li><p>在汇总库上创建一个临时表 <code>temp_ht</code>，表里包含三个字段 <code>v</code>、<code>k</code>、<code>t_modified</code>；</p></li><li><p>在各个分库上执行</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select v,k,t_modified from ht_x where k >= M order by t_modified desc limit 100;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>把分库执行的结果插入到 temp_ht 表中；</p></li><li><p>执行</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select v from temp_ht order by t_modified desc limit 100; <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>得到结果。</p></li></ul><p>这个过程对应的流程图如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133644.jpg" alt="跨库查询流程示意图"></p><p>在实践中，我们往往会发现每个分库的计算量都不饱和，所以会直接把临时表 temp_ht 放到 32 个分库中的某一个上。这时的查询逻辑与上图类似。</p></li></ol><h2 id="为什么临时表可以重名？"><a class="header-anchor" href="#为什么临时表可以重名？">¶</a>为什么临时表可以重名？</h2><p>我们在执行</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create temporary table temp_t(id int primary key)engine=innodb;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个语句的时候，MySQL 要给这个 InnoDB 表创建一个 frm 文件保存表结构定义，还要有地方保存表数据。</p><p>这个 frm 文件放在临时文件目录下，文件名的后缀是.frm，前缀是<code>#sql{进程 id}_{线程 id}_ 序列号</code>。你可以使用 <code>select @@tmpdir</code> 命令，来显示实例的临时文件目录。</p><p>而关于表中数据的存放方式，在不同的 MySQL 版本中有着不同的处理方式：</p><ul><li>在 5.6 以及之前的版本里，MySQL 会在临时文件目录下创建一个相同前缀、以.ibd 为后缀的文件，用来存放数据文件；</li><li>而从 5.7 版本开始，MySQL 引入了一个临时文件表空间，专门用来存放临时文件的数据。因此，我们就不需要再创建 ibd 文件了。</li></ul><p>从文件名的前缀规则，我们可以看到，其实创建一个叫作 t1 的 InnoDB 临时表，MySQL 在存储上认为我们创建的表名跟普通表 t1 是不同的，因此同一个库下面已经有普通表 t1 的情况下，还是可以再创建一个临时表 t1 的。为了便于后面讨论，先来举一个例子。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133652.png" alt="临时表的表名"></p><p>这个进程的进程号是 1234，session A 的线程 id 是 4，session B 的线程 id 是 5。session A 和 session B 创建的临时表，在磁盘上的文件不会重名。MySQL 维护数据表，除了物理上要有文件外，内存里面也有一套机制区别不同的表，每个表都对应一个 table_def_key。</p><ul><li>一个普通表的 table_def_key 的值是由“库名 + 表名”得到的，所以如果你要在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现 table_def_key 已经存在了。</li><li>而对于临时表，table_def_key 在“库名 + 表名”基础上，又加入了“server_id+thread_id”。</li></ul><p>也就是说，session A 和 sessionB 创建的两个临时表 t1，它们的 table_def_key 不同，磁盘文件名也不同，因此可以并存。</p><p>在实现上，每个线程都维护了自己的临时表链表。这样每次 session 内操作表的时候，先遍历链表，<strong>检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表</strong>；在 session 结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE + 表名”操作。这时候你会发现，binlog 中也记录了 DROP TEMPORARY TABLE 这条命令。你一定会觉得奇怪，临时表只在线程内自己可以访问，为什么需要写到 binlog 里面？这，就需要说到主备复制了。</p><h2 id="临时表和主备复制"><a class="header-anchor" href="#临时表和主备复制">¶</a>临时表和主备复制</h2><p>既然写 binlog，就意味着备库需要。你可以设想一下，在主库上执行下面这个语句序列：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create table t_normal(id int primary key, c int)engine=innodb;/*Q1*/create temporary table temp_t like t_normal;/*Q2*/insert into temp_t values(1,1);/*Q3*/insert into t_normal select * from temp_t;/*Q4*/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>如果关于临时表的操作都不记录，那么在备库就只有 <code>create table t_normal</code> 表和 <code>insert into t_normal select * from temp_t</code> 这两个语句的 binlog 日志，备库在执行到 <code>insert into t_normal</code> 的时候，就会报错“表 temp_t 不存在”。</p><p>如果把 binlog 设置为 row 格式就好了吧？因为 binlog 是 row 格式时，在记录 <code>insert into t_normal</code> 的 binlog 时，记录的是这个操作的数据，即：write_row event 里面记录的逻辑是“插入一行数据（1,1)”。你可能会说，如果把 binlog 设置为 row 格式就好了吧？因为 binlog 是 row 格式时，在记录 insert into t_normal 的 binlog 时，记录的是这个操作的数据，即：write_row event 里面记录的逻辑是“插入一行数据（1,1)”。</p><p>确实是这样。如果当前的 <code>binlog_format=row</code>，那么跟临时表有关的语句，就不会记录到 binlog 里。也就是说，只在 <code>binlog_format</code>=statment/mixed 的时候，binlog 中才会记录临时表的操作。这种情况下，创建临时表的语句会传到备库执行，因此备库的同步线程就会创建这个临时表。主库在线程退出的时候，会自动删除临时表，但是备库同步线程是持续在运行的。所以，这时候我们就需要在主库上再写一个 <code>DROP TEMPORARY TABLE</code> 传给备库执行。</p><p>MySQL 在记录 binlog 的时候，不论是 <code>create table</code> 还是 <code>alter table</code> 语句，都是原样记录，甚至于连空格都不变。但是如果执行 <code>drop table t_normal</code>，系统记录 binlog 就会写成：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">DROP TABLE `t_normal` /* generated by server */<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>也就是改成了标准的格式。为什么要这么做呢 ？因为 <code>drop table</code> 命令是可以一次删除多个表的。比如，在上面的例子中，设置 <code>binlog_format=row</code>，如果主库上执行 <code>drop table t_normal, temp_t;</code> 这个命令，那么 binlog 中就只能记录：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">DROP TABLE `t_normal` /* generated by server */<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因为备库上并没有表 <code>temp_t</code>，将这个命令重写后再传到备库执行，才不会导致备库同步线程停止。所以，<code>drop table</code> 命令记录 binlog 的时候，就必须对语句做改写。“/* generated by server */”说明了这是一个被服务端改写过的命令。</p><h3 id="主备复制临时表如何解决重名问题"><a class="header-anchor" href="#主备复制临时表如何解决重名问题">¶</a>主备复制临时表如何解决重名问题</h3><p>说到主备复制，还有另外一个问题需要解决：主库上不同的线程创建同名的临时表是没关系的，但是传到备库执行是怎么处理的呢？举个例子，下面的序列中实例 S 是 M 的备库。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133700.png" alt="主备关系中的临时表操作"></p><p>主库 M 上的两个 session 创建了同名的临时表 t1，这两个 <code>create temporary table t1</code> 语句都会被传到备库 S 上。但是，备库的应用日志线程是共用的，也就是说要在应用线程里面先后执行这个 <code>create</code> 语句两次。（即使开了多线程复制，也可能被分配到从库的同一个 worker 中执行）。那么，这会不会导致同步线程报错 ？</p><p>显然是不会的，否则临时表就是一个 bug 了。也就是说，备库线程在执行的时候，要把这两个 t1 表当做两个不同的临时表来处理。这，又是怎么实现的呢？MySQL 在记录 binlog 的时候，会把主库执行这个语句的线程 id 写到 binlog 中。这样，在备库的应用线程就能够知道执行每个语句的主库线程 id，并利用这个线程 id 来构造临时表的 table_def_key：</p><ol><li>session A 的临时表 t1，在备库的 table_def_key 就是：库名 +t1+“M 的 serverid”+“session A 的 thread_id”;</li><li>session B 的临时表 t1，在备库的 table_def_key 就是 ：库名 +t1+“M 的 serverid”+“session B 的 thread_id”。</li></ol><p>由于 table_def_key 不同，所以这两个表在备库的应用线程里面是不会冲突的。</p><h2 id="为什么临时表改名是-alter-而不是-rename"><a class="header-anchor" href="#为什么临时表改名是-alter-而不是-rename">¶</a>为什么临时表改名是 <code>alter</code> 而不是 <code>rename</code></h2><p>我们可以使用 <code>alter table</code> 语法修改临时表的表名，而不能使用 <code>rename</code> 语法。这是什么原因呢？</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133707.png" alt="临时表改名"></p><p>在实现上，执行 <code>rename table</code> 语句的时候，要求按照“库名 / 表名.frm”的规则去磁盘找文件，但是临时表在磁盘上的 frm 文件是放在 tmpdir 目录下的，并且文件名的规则是 <code>#sql{进程 id}_{线程 id}_ 序列号.frm</code>，因此会报“找不到文件名”的错误。</p><h2 id="内部临时表"><a class="header-anchor" href="#内部临时表">¶</a>内部临时表</h2><p>上面提到的都是用户根据需求通过 DDL 建立的临时表，称为<strong>用户临时表</strong>。sort buffer、内存临时表和 join buffer。这三个数据结构都是用来存放语句执行过程中的中间数据，以辅助 SQL 语句的执行的。其中，我们在排序的时候用到了 sort buffer，在使用 join 语句的时候用到了 join buffer，而类似函数计算字段等操作会涉及到<strong>内部临时表</strong>构建，除了函数计算之后其实还有其它操作会使得 MySQL 通过构建临时表来实现，下面进行详细介绍。</p><h3 id="union-执行流程"><a class="header-anchor" href="#union-执行流程">¶</a><code>union</code> 执行流程</h3><p>为了便于量化分析，用下面的表 t1 来举例。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create table t1(id int primary key, a int, b int, index(a));delimiter ;;create procedure idata()begin  declare i int;  set i=1;  while(i<=1000)do    insert into t1 values(i, i, i);    set i=i+1;  end while;end;;delimiter ;call idata();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后，我们执行下面这条语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">(select 1000 as f) union (select id from t1 order by id desc limit 2);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这条语句用到了 <code>union</code>，它的语义是，取这两个子查询结果的并集。并集的意思就是这两个集合加起来，重复的行只保留一行。下图是这个语句的 explain 结果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133715.png" alt="union 语句 explain 结果"></p><p>可以看到：</p><ul><li>第二行的 key=PRIMARY，说明第二个子句用到了索引 id。</li><li>第三行的 Extra 字段，表示在对子查询的结果集做 union 的时候，使用了临时表 (Using temporary)。</li></ul><p>这个语句的执行流程是这样的：</p><ol><li>创建一个内存临时表，这个临时表只有一个整型字段 f，并且 f 是主键字段。</li><li>执行第一个子查询，得到 1000 这个值，并存入临时表中。</li><li>执行第二个子查询：<ul><li>拿到第一行 id=1000，试图插入临时表中。但由于 1000 这个值已经存在于临时表了，违反了唯一性约束，所以插入失败，然后继续执行；</li><li>取到第二行 id=999，插入临时表成功。</li></ul></li><li>从临时表中按行取出数据，返回结果，并删除临时表，结果中包含两行数据分别是 1000 和 999。</li></ol><p>这个过程的流程图如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133721.jpg" alt="union 执行流程"></p><p>可以看到，这里的内存临时表起到了暂存数据的作用，而且计算过程还用上了临时表主键 id 的唯一性约束，实现了 union 的语义。</p><p>顺便提一下，如果把上面这个语句中的 union 改成 union all 的话，就没有了“去重”的语义。<strong>这样执行的时候，就依次执行子查询，得到的结果直接作为结果集的一部分，发给客户端。因此也就不需要临时表了</strong>。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133731.png" alt="union all 的 explain 结果"></p><p>可以看到，第二行的 Extra 字段显示的是 Using index，表示只使用了覆盖索引，没有用临时表了。</p><h3 id="group-by-执行流程"><a class="header-anchor" href="#group-by-执行流程">¶</a><code>group by</code> 执行流程</h3><p>另外一个常见的使用临时表的例子是 <code>group by</code>，我们来看一下这个语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select id%10 as m, count(*) as c from t1 group by m;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个语句的逻辑是把表 t1 里的数据，按照 <code>id%10</code> 进行分组统计，并按照 m 的结果排序后输出。它的 explain 结果如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133738.png" alt="group by 的 explain 结果"></p><p>在 Extra 字段里面，我们可以看到三个信息：</p><ul><li>Using index，表示这个语句使用了覆盖索引，选择了索引 a，不需要回表；</li><li>Using temporary，表示使用了临时表；</li><li>Using filesort，表示需要排序。</li></ul><p>这个语句的执行流程是这样的：</p><ol><li>创建内存临时表，表里有两个字段 m 和 c，主键是 m；</li><li>扫描表 t1 的索引 a，依次取出叶子节点上的 id 值，计算 id%10 的结果，记为 x；<ul><li>如果临时表中没有主键为 x 的行，就插入一个记录 (x,1);</li><li>如果表中有主键为 x 的行，就将 x 这一行的 c 值加 1；</li></ul></li><li>遍历完成后，再根据字段 m 做排序（为什么需要额外做排序？因为内存临时表默认使用 memory 引擎，该引擎的表数据是无序的，因为 <code>group by</code> 又提供了有序语义，所以返回前需要做额外排序，作为对比可以看下面的磁盘临时表），得到结果集返回给客户端。</li></ol><p>这个流程的执行图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133744.jpg" alt="group by 执行流程"></p><p>其中，临时表的排序过程就是下图中虚线框内的过程。：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133752.jpg" alt="内存临时表排序流程"></p><p>接下来，我们再看一下这条语句的执行结果(有序)：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133800.png" alt="group by 执行结果"></p><h4 id="优化：order-by-null-去除默认排序"><a class="header-anchor" href="#优化：order-by-null-去除默认排序">¶</a>优化：<code>order by null</code> 去除默认排序</h4><p>如果你的需求并不需要对结果进行排序，那你可以在 SQL 语句末尾增加 <code>order by null</code>，也就是改成：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select id%10 as m, count(*) as c from t1 group by m order by null;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这样就跳过了最后排序的阶段，直接从临时表中取数据返回。返回的结果如下图所示。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133808.png" alt="group + order by null 的结果（内存临时表）"></p><p>由于表 t1 中的 id 值是从 1 开始的，因此返回的结果集中第一行是 id=1；扫描到 id=10 的时候才插入 m=0 这一行，因此结果集里最后一行才是 m=0。</p><blockquote><p>可以看到现在 0 排在了最后，这和上面提到的内存临时表使用的是 memory 引擎，表中数据无序有关。 <code>order by null</code> 使得返回前无序额外使用 sort_buffer 排序，所以将内存临时表的内容直接返回。</p></blockquote><h4 id="内存临时表转成磁盘临时表"><a class="header-anchor" href="#内存临时表转成磁盘临时表">¶</a>内存临时表转成磁盘临时表</h4><p>这个例子里由于临时表只有 10 行，内存可以放得下，因此全程只使用了内存临时表。但是，内存临时表的大小是有限制的，参数 <code>tmp_table_size</code> 就是控制这个内存大小的，默认是 16M。如果执行下面这个语句序列：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">set tmp_table_size=1024;select id%100 as m, count(*) as c from t1 group by m order by null limit 10;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>把内存临时表的大小限制为最大 1024 字节，并把语句改成 id % 100，这样返回结果里有 100 行数据。但是，这时的内存临时表大小不够存下这 100 行数据，也就是说，执行过程中会发现内存临时表大小到达了上限（1024 字节）。那么，这时候就会把内存临时表转成磁盘临时表，磁盘临时表默认使用的引擎是 InnoDB。 这时，返回的结果如下所示。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133815.png" alt="group + order by null 的结果（磁盘临时表）"></p><p>如果这个表 t1 的数据量很大，很可能这个查询需要的磁盘临时表就会占用大量的磁盘空间。</p><blockquote><p>磁盘临时表默认使用 InnoDB 引擎，所以表内数据都是按照主键索引组织的，故即使使用了 <code>order by null</code>，表内数据还是会按照主键 <code>m</code> 即 <code>id % 100</code>进行排序，在返回的时候和内存临时表的动作是一样的，不会进行额外排序。</p></blockquote><h4 id="优化：索引"><a class="header-anchor" href="#优化：索引">¶</a>优化：索引</h4><p>可以看到，不论是使用内存临时表还是磁盘临时表，<code>group by</code> 逻辑都需要构造一个带唯一索引的表，执行代价都是比较高的。如果表的数据量比较大，上面这个 <code>group by</code> 语句执行起来就会很慢，我们有什么优化的方法呢？</p><p>可以先想一下这个问题：执行 <code>group by</code> 语句为什么需要临时表？<code>group by</code> 的语义逻辑，是统计不同的值出现的个数。但是，由于每一行的 <code>id%100</code> 的结果是无序的，所以我们就需要有一个临时表，来记录并统计结果。那么，如果扫描过程中可以保证出现的数据是有序的，是不是就简单了呢？假设，现在有一个类似下图的这么一个数据结构，我们来看看 <code>group by</code> 可以怎么做。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133821.jpg" alt="group by 算法优化 - 有序输入"></p><p>可以看到，如果可以确保输入的数据是有序的，那么计算 <code>group by</code> 的时候，就只需要从左到右，顺序扫描，依次累加。也就是下面这个过程：</p><ol><li>当碰到第一个 1 的时候，已经知道累积了 X 个 0，结果集里的第一行就是 (0,X);</li><li>当碰到第一个 2 的时候，已经知道累积了 Y 个 1，结果集里的第二行就是 (1,Y);</li></ol><p>按照这个逻辑执行的话，扫描到整个输入的数据结束，就可以拿到 <code>group by</code> 的结果，不需要临时表，也不需要再额外排序。</p><p>InnoDB 的索引，就可以满足这个输入有序的条件。在 MySQL 5.7 版本支持了 generated column 机制，用来实现列数据的关联更新（由一个列自动计算出另一个列的数据）。可以用下面的方法创建一个列 z，然后在 z 列上创建一个索引（如果是 MySQL 5.6 及之前的版本，也可以创建普通列和索引，来解决这个问题）。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">alter table t1 add column z int generated always as(id % 100), add index(z);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这样，索引 z 上的数据就是类似上图这样有序的了。上面的 <code>group by</code> 语句就可以改成：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select z, count(*) as c from t1 group by z;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>优化后的 <code>group by</code> 语句的 explain 结果，如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133829.png" alt="group by 优化的 explain 结果"></p><p>从 Extra 字段可以看到，这个语句的执行不再需要临时表，也不需要排序了。</p><h4 id="优化：直接排序"><a class="header-anchor" href="#优化：直接排序">¶</a>优化：直接排序</h4><p>所以，如果可以通过加索引来完成 <code>group by</code> 逻辑就再好不过了。但是，如果碰上不适合创建索引的场景，我们还是要老老实实做排序的。那么，这时候的 <code>group by</code> 要怎么优化呢？</p><p>如果我们明明知道，一个 <code>group by</code> 语句中需要放到临时表上的数据量特别大，却还是要按照“先放到内存临时表，插入一部分数据后，发现内存临时表不够用了再转成磁盘临时表”，看上去就有点儿傻。那么，我们就会想了，MySQL 有没有让我们直接走磁盘临时表的方法呢？答案是，有的。</p><p>在 <code>group by</code> 语句中加入 <code>SQL_BIG_RESULT</code> 这个提示（hint），就可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。MySQL 的优化器一看，磁盘临时表是 B+ 树存储，存储效率不如数组来得高。所以，既然你告诉我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。因此，下面这个语句</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>的执行流程就是这样的：</p><ol><li>初始化 sort_buffer，确定放入一个整型字段，记为 m；</li><li>扫描表 t1 的索引 a，依次取出里面的 id 值, 将 <code>id%100</code> 的值存入 sort_buffer 中；</li><li>扫描完成后，对 sort_buffer 的字段 m 做排序（如果 sort_buffer 内存不够用，就会利用磁盘临时文件辅助排序）；</li><li>排序完成后，就得到了一个有序数组。</li></ol><p>根据有序数组，得到数组里面的不同值，以及每个值的出现次数，此时开始就类似前面说到的加索引之后针对索引做的聚合操作了。下面两张图分别是执行流程图和执行 explain 命令得到的结果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133836.jpg" alt="使用 SQL_BIG_RESULT 的执行流程图"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133843.png" alt="使用 SQL_BIG_RESULT 的 explain 结果"></p><p>从 Extra 字段可以看到，这个语句的执行没有再使用临时表，而是直接用了排序算法。</p><h3 id="总结-v4"><a class="header-anchor" href="#总结-v4">¶</a>总结</h3><p>基于上面的 <code>union</code>、<code>union all</code> 和 <code>group by</code> 语句的执行过程的分析：MySQL 什么时候会使用内部临时表？</p><ol><li>如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；</li><li>join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构；</li><li>如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，<code>union</code> 需要用到唯一索引约束， <code>group by</code> 还需要用到另外一个字段来存累积计数。</li></ol><p>优化思想：</p><ol><li>如果对 <code>group by</code> 语句的结果没有排序要求，要在语句后面加 <code>order by null;</code></li><li>尽量让 <code>group by</code> 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort；</li><li>如果 <code>group by</code> 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 <code>tmp_table_size</code> 参数，来避免用到磁盘临时表；</li><li>如果数据量实在太大，使用 <code>SQL_BIG_RESULT</code> 这个提示，来告诉优化器直接使用排序算法得到 <code>group by</code> 的结果。</li></ol><h3 id="distinct-和-group-by-的性能"><a class="header-anchor" href="#distinct-和-group-by-的性能">¶</a><code>distinct</code> 和 <code>group by</code> 的性能</h3><p>如果只需要去重，不需要执行聚合函数，<code>distinct</code> 和 <code>group by</code> 哪种效率高一些呢？展开一下这个问题：如果表 t 的字段 a 上没有索引，那么下面这两条语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select a from t group by a order by null;select distinct a from t;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>的性能是不是相同的?</p><p>首先需要说明的是，这种 <code>group by</code> 的写法，并不是 SQL 标准的写法。标准的 <code>group by</code> 语句，是需要在 <code>select</code> 部分加一个聚合函数，比如：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select a,count(*) from t group by a order by null;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这条语句的逻辑是：按照字段 a 分组，计算每组的 a 出现的次数。在这个结果里，由于做的是聚合计算，相同的 a 只出现一次。</p><p>如果没有了 count(*) 以后，也就是不再需要执行“计算总数”的逻辑时，第一条语句的逻辑就变成是：按照字段 a 做分组，相同的 a 的值只返回一行。而这就是 <code>distinct</code> 的语义，所以不需要执行聚合函数时，<code>distinct</code> 和 <code>group b</code>y 这两条语句的语义和执行流程是相同的，因此执行性能也相同。这两条语句的执行流程是下面这样的。</p><ol><li>创建一个临时表，临时表有一个字段 a，并且在这个字段 a 上创建一个唯一索引；</li><li>遍历表 t，依次取数据插入临时表中：<ul><li>如果发现唯一键冲突，就跳过；</li><li>否则插入成功；</li></ul></li><li>遍历完成后，将临时表作为结果集返回给客户端。</li></ol><h1>二十四、Memory 引擎</h1><h2 id="内存表的数据组织结构"><a class="header-anchor" href="#内存表的数据组织结构">¶</a>内存表的数据组织结构</h2><p>假设有以下的两张表 t1 和 t2，其中表 t1 使用 Memory 引擎， 表 t2 使用 InnoDB 引擎。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create table t1(id int primary key, c int) engine=Memory;create table t2(id int primary key, c int) engine=innodb;insert into t1 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);insert into t2 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>然后，分别执行 <code>select * from t1</code> 和 <code>select * from t2</code>。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133851.png" alt="两个查询结果 -0 的位置"></p><p>可以看到，内存表 t1 的返回结果里面 0 在最后一行，而 InnoDB 表 t2 的返回结果里 0 在第一行。出现这个区别的原因，要从这两个引擎的主键索引的组织方式说起。表 t2 用的是 InnoDB 引擎，InnoDB 表的数据就放在主键索引树上，主键索引是 B+ 树。所以表 t2 的数据组织方式如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133859.jpg" alt="表 t2 的数据组织"></p><p>主键索引上的值是有序存储的。在执行 <code>select *</code> 的时候，就会按照叶子节点从左到右扫描，所以得到的结果里，0 就出现在第一行。与 InnoDB 引擎不同，Memory 引擎的数据和索引是分开的。我们来看一下表 t1 中的数据内容。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133907.jpg" alt="表 t1 的数据组织"></p><p>可以看到，内存表的数据部分以数组的方式单独存放，而主键 id 索引里，存的是每个数据的位置。<strong>主键 id 是 hash 索引</strong>，可以看到索引上的 key 并不是有序的。在内存表 t1 中，当执行 <code>select *</code> 的时候，走的是全表扫描，也就是顺序扫描这个数组。因此，0 就是最后一个被读到，并放入结果集的数据。</p><p>可见，InnoDB 和 Memory 引擎的数据组织方式是不同的：</p><ul><li>InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）。</li><li>而 Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。</li></ul><p>从中我们可以看出，这两个引擎的一些典型不同：</p><ol><li>InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；</li><li>当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；</li><li>数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引(也就说在 memory 表中建立的所有索引都会包含数据所在内存地址的指针，内存地址发生变化，所有指向该行数据的索引更新为修改变化后的指针)；</li><li>InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。</li><li>InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。</li></ol><p>由于内存表的这些特性，每个数据行被删除以后，空出的这个位置都可以被接下来要插入的数据复用。比如，如果要在表 t1 中执行：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">delete from t1 where id=5;insert into t1 values(10,10);select * from t1;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>就会看到返回结果里，id=10 这一行出现在 id=4 之后，也就是原来 id=5 这行数据的位置。需要指出的是，表 t1 的这个主键索引是哈希索引，因此如果执行范围查询，比如</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from t1 where id<5;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>是用不上主键索引的，需要走全表扫描。那如果要让内存表支持范围扫描，应该怎么办呢 ？</p><h2 id="hash-索引和-B-Tree-索引"><a class="header-anchor" href="#hash-索引和-B-Tree-索引">¶</a>hash 索引和 B-Tree 索引</h2><p>实际上，内存表也是支 B-Tree 索引的。在 id 列上创建一个 B-Tree 索引，SQL 语句可以这么写：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">alter table t1 add index a_btree_index using btree (id);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这时，表 t1 的数据组织形式就变成了这样：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133916.jpg" alt="表 t1 的数据组织 -- 增加 B-Tree 索引"></p><p>这跟 InnoDB 的 b+ 树索引组织形式类似。作为对比，可以看一下这下面这两个语句的输出：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133923.png" alt="使用 B-Tree 和 hash 索引查询返回结果对比"></p><p>可以看到，执行 <code>select * from t1 where id&lt;5</code> 的时候，优化器会选择 B-Tree 索引，所以返回结果是 0 到 4。 使用 force index 强行使用主键 id 这个索引，id=0 这一行就在结果集的最末尾了。其实，一般在我们的印象中，内存表的优势是速度快，其中的一个原因就是 Memory 引擎支持 hash 索引。当然，更重要的原因是，内存表的所有数据都保存在内存，而内存的读写速度总是比磁盘快。</p><h2 id="不建议在生产环境使用内存表"><a class="header-anchor" href="#不建议在生产环境使用内存表">¶</a>不建议在生产环境使用内存表</h2><p>这里的原因主要包括两个方面：</p><ol><li>锁粒度问题；</li><li>数据持久化问题。</li></ol><h3 id="内存表的锁"><a class="header-anchor" href="#内存表的锁">¶</a>内存表的锁</h3><p>先来说说内存表的锁粒度问题。内存表不支持行锁，只支持表锁。因此，一张表只要有更新，就会堵住其他所有在这个表上的读写操作。需要注意的是，这里的表锁跟之前我们介绍过的 MDL 锁不同，但都是表级的锁。接下来，通过下面这个场景，模拟一下内存表的表级锁。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133931.png" alt="内存表的表锁 -- 复现步骤"></p><p>在这个执行序列里，session A 的 update 语句要执行 50 秒，在这个语句执行期间 session B 的查询会进入锁等待状态。session C 的 <code>show processlist</code> 结果输出如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133936.png" alt="内存表的表锁 -- 结果"></p><p>跟行锁比起来，表锁对并发访问的支持不够好。所以，内存表的锁粒度问题，决定了它在处理并发事务的时候，性能也不会太好。</p><h3 id="数据持久性问题"><a class="header-anchor" href="#数据持久性问题">¶</a>数据持久性问题</h3><p>接下来，我们再看看数据持久性的问题。数据放在内存中，是内存表的优势，但也是一个劣势。因为，数据库重启的时候，所有的内存表都会被清空。你可能会说，如果数据库异常重启，内存表被清空也就清空了，不会有什么问题啊。但是，在高可用架构下，内存表的这个特点简直可以当做 bug 来看待了。为什么这么说呢？</p><p>我们先看看 M-S 架构下，使用内存表存在的问题。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133942.jpg" alt="M-S 基本架构"></p><p>我们来看一下下面这个时序：</p><ol><li>业务正常访问主库；</li><li>备库硬件升级，备库重启，内存表 t1 内容被清空；</li><li>备库重启后，客户端发送一条 update 语句，修改表 t1 的数据行，这时备库应用线程就会报错“找不到要更新的行”。</li></ol><p>这样就会导致主备同步停止。当然，如果这时候发生主备切换的话，客户端会看到，表 t1 的数据“丢失”了。</p><p>在上图中这种有 proxy 的架构里，大家默认主备切换的逻辑是由数据库系统自己维护的。这样对客户端来说，就是“网络断开，重连之后，发现内存表数据丢失了”。可能说这还好啊，毕竟主备发生切换，连接会断开，业务端能够感知到异常。但是，接下来内存表的这个特性就会让使用现象显得更“诡异”了。由于 MySQL 知道重启之后，内存表的数据会丢失。所以，担心主库重启之后，出现主备不一致，MySQL 在实现上做了这样一件事儿：在数据库重启之后，往 binlog 里面写入一行 <code>DELETE FROM t1</code>。如果你使用是如下图所示的双 M 结构的话：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221133952.jpg" alt="双 M 结构"></p><p>在备库重启的时候，备库 binlog 里的 <code>delete</code> 语句就会传到主库，然后把主库内存表的内容删除。这样你在使用的时候就会发现，主库的内存表数据突然被清空了。</p><h4 id="双-M-结构下存在内存表导致主库表删除备库停止同步如何处理"><a class="header-anchor" href="#双-M-结构下存在内存表导致主库表删除备库停止同步如何处理">¶</a>双 M 结构下存在内存表导致主库表删除备库停止同步如何处理</h4><p>如果你维护的 MySQL 系统里有内存表，怎么避免内存表突然丢数据，然后导致主备同步停止的情况？假设当时的业务场景暂时不允许你修改引擎，你可以加上什么自动化逻辑，来避免主备同步停止呢？那么就把备库的内存表引擎先都改成 InnoDB。对于每个内存表，执行</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">set sql_log_bin=off;alter table tbl_name engine=innodb;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这样就能避免备库重启的时候，数据丢失的问题。由于主库重启后，会往 binlog 里面写 <code>delete from tbl_name</code>，这个命令传到备库，备库的同名的表数据也会被清空。因此，就不会出现主备同步停止的问题。</p><p>如果由于主库异常重启，触发了 HA，这时候我们之前修改过引擎的备库变成了主库。而原来的主库变成了新备库，在新备库上把所有的内存表（这时候表里没数据）都改成 InnoDB 表。所以，如果我们不能直接修改主库上的表引擎，可以配置一个自动巡检的工具，在备库上发现内存表就把引擎改了。同时，跟业务开发同学约定好建表规则，避免创建新的内存表。</p><h3 id="总结-v5"><a class="header-anchor" href="#总结-v5">¶</a>总结</h3><p>基于上面的分析，内存表并不适合在生产环境上作为普通数据表使用。但是内存表执行速度快呀，岂不是很浪费。这个问题，其实可以这么分析：</p><ol><li>如果你的表更新量大，那么并发度是一个很重要的参考指标，InnoDB 支持行锁，并发度比内存表好；</li><li>能放到内存表的数据量都不大。如果你考虑的是读的性能，一个读 QPS 很高并且数据量不大的表，即使是使用 InnoDB，数据也是都会缓存在 InnoDB Buffer Pool 里的。因此，使用 InnoDB 表的读性能也不会差。</li></ol><h2 id="推荐使用的场景"><a class="header-anchor" href="#推荐使用的场景">¶</a>推荐使用的场景</h2><p>所以，建议你把普通内存表都用 InnoDB 表来代替。但是，有一个场景却是例外的。这个场景就是，前面提到的用户临时表。在数据量可控，不会耗费过多内存的情况下，可以考虑使用内存表。</p><p>内存临时表刚好可以无视内存表的两个不足，主要是下面的三个原因：</p><ol><li>临时表不会被其他线程访问，没有并发性的问题；</li><li>临时表重启后也是需要删除的，清空数据这个问题不存在；</li><li>备库的临时表也不会影响主库的用户线程。</li></ol><p>现在，再看一下<a href="####%E5%BB%BA%E7%AB%8B%E4%B8%B4%E6%97%B6%E8%A1%A8">前面 join 语句优化的例子</a>，当时建议的是创建一个 InnoDB 临时表，使用的语句序列是：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create temporary table temp_t(id int primary key, a int, b int, index(b))engine=innodb;insert into temp_t select * from t2 where b>=1 and b<=2000;select * from t1 join temp_t on (t1.b=temp_t.b);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>了解了内存表的特性，其实这里使用内存临时表的效果更好，原因有三个：</p><ol><li>相比于 InnoDB 表，使用内存表不需要写磁盘，往表 <code>temp_t</code> 的写数据的速度更快；</li><li>索引 b 使用 hash 索引，查找的速度比 B-Tree 索引快；</li><li>临时表数据只有 2000 行，占用的内存有限。</li></ol><p>因此，你可以对该语句序列做一个改写，将临时表 temp_t 改成内存临时表，并且在字段 b 上创建一个 hash 索引。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create temporary table temp_t(id int primary key, a int, b int, index (b))engine=memory;insert into temp_t select * from t2 where b>=1 and b<=2000;select * from t1 join temp_t on (t1.b=temp_t.b);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134001.png" alt="使用内存临时表的执行效果"></p><p>可以看到，不论是导入数据的时间，还是执行 join 的时间，使用内存临时表的速度都比使用 InnoDB 临时表要更快一些。</p><h1>二十五、自增主键为什么不是连续的</h1><p>业务设计依赖于自增主键的连续性，也就是说，这个设计假设自增主键是连续的。但实际上，这样的假设是错的，因为自增主键不能保证连续递增。那么什么情况下自增主键会出现 “空洞”？</p><p>为了便于说明，创建一个表 t，其中 id 是自增主键字段、c 是唯一索引。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `c` int(11) DEFAULT NULL,  `d` int(11) DEFAULT NULL,  PRIMARY KEY (`id`),  UNIQUE KEY `c` (`c`)) ENGINE=InnoDB;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="自增值保存在哪儿？"><a class="header-anchor" href="#自增值保存在哪儿？">¶</a>自增值保存在哪儿？</h2><p>在这个空表 t 里面执行 <code>insert into t values(null, 1, 1);</code> 插入一行数据，再执行 <code>show create table</code> 命令，就可以看到如下图所示的结果：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134012.png" alt="自动生成的 AUTO_INCREMENT 值"></p><p>可以看到，表定义里面出现了一个 AUTO_INCREMENT=2，表示下一次插入数据时，如果需要自动生成自增值，会生成 id=2。其实，这个输出结果容易引起这样的误解：自增值是保存在表结构定义里的。<strong>实际上，表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值</strong>。不同的引擎对于自增值的保存策略不同：</p><ul><li><p>MyISAM 引擎的自增值保存在数据文件中。</p></li><li><p>InnoDB 引擎的自增值，其实是保存在了内存里，并且到了 MySQL 8.0 版本后，才有了“自增值持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为 MySQL 重启前的值”，具体情况是：</p><ul><li><p>在 MySQL 5.7 及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。</p><p>举例来说，如果一个表当前数据行里最大的 id 是 10，AUTO_INCREMENT=11。这时候，我们删除 id=10 的行，AUTO_INCREMENT 还是 11。但如果马上重启实例，重启后这个表的 AUTO_INCREMENT 就会变成 10。﻿也就是说，MySQL 重启可能会修改一个表的 AUTO_INCREMENT 的值。</p></li><li><p>在 MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。</p></li></ul></li></ul><p>理解了 MySQL 对自增值的保存策略以后，我们再看看自增值修改机制。</p><h2 id="自增值修改机制"><a class="header-anchor" href="#自增值修改机制">¶</a>自增值修改机制</h2><p>在 MySQL 里面，如果字段 id 被定义为 AUTO_INCREMENT，在插入一行数据的时候，自增值的行为如下：</p><ol><li>如果插入数据时 id 字段指定为 0、null 或未指定值，那么就把这个表当前的 AUTO_INCREMENT 值填到自增字段；</li><li>如果插入数据时 id 字段指定了具体的值，就直接使用语句里指定的值。</li></ol><p>根据要插入的值和当前自增值的大小关系，自增值的变更结果也会有所不同。假设，某次要插入的值是 X，当前的自增值是 Y。</p><ol><li><p>如果 X&lt;Y，那么这个表的自增值不变；</p></li><li><p>如果 X≥Y，就需要把当前自增值修改为新的自增值。</p><p>新的自增值生成算法是：从 <code>auto_increment_offset</code> 开始，以 <code>auto_increment_increment</code> 为步长，持续叠加，直到找到第一个大于 X 的值，作为新的自增值。</p><p>其中，<code>auto_increment_offset</code> 和 <code>auto_increment_increment</code> 是两个系统参数，分别用来表示自增的初始值和步长，默认值都是 1。</p><blockquote><p>备注：在一些场景下，使用的就不全是默认值。比如，双 M 的主备结构里要求双写的时候，我们就可能会设置成 auto_increment_increment=2，让一个库的自增 id 都是奇数，另一个库的自增 id 都是偶数，避免两个库生成的主键发生冲突。</p></blockquote></li></ol><p>当 <code>auto_increment_offset</code> 和 <code>auto_increment_increment</code> 都是 1 的时候，新的自增值生成逻辑很简单，就是：如果准备插入的值 &gt;= 当前自增值，新的自增值就是“准备插入的值 +1”；否则，自增值不变。这就引入了开头提到的问题，在这两个参数都设置为 1 的时候，自增主键 id 却不能保证是连续的，这是什么原因呢？要回答这个问题，我们就要看一下<strong>自增值的修改时机</strong>。</p><h2 id="1-唯一键冲突或者rollback导致事务回滚"><a class="header-anchor" href="#1-唯一键冲突或者rollback导致事务回滚">¶</a>1&gt;唯一键冲突或者rollback导致事务回滚</h2><p>假设，表 t 里面已经有了 (1,1,1) 这条记录，这时我再执行一条插入数据命令：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">insert into t values(null, 1, 1); <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个语句的执行流程就是：</p><ol><li>执行器调用 InnoDB 引擎接口写入一行，传入的这一行的值是 (0,1,1);</li><li>InnoDB 发现用户没有指定自增 id 的值，获取表 t 当前的自增值 2；</li><li>将传入的行的值改成 (2,1,1);</li><li>将表的自增值改成 3；</li><li>继续执行插入数据操作，由于已经存在 c=1 的记录，所以报 Duplicate key error，语句返回。</li></ol><p>对应的执行流程图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134021.jpg" alt="insert(null, 1,1) 唯一键冲突"></p><p>可以看到，这个表的自增值改成 3，是在真正执行插入数据的操作之前。这个语句真正执行的时候，因为碰到唯一键 c 冲突，所以 id=2 这一行并没有插入成功，但也没有将自增值再改回去。所以，在这之后，再插入新的数据行时，拿到的自增 id 就是 3。也就是说，出现了自增主键不连续的情况。</p><p>如下图所示就是完整的演示结果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134031.png" alt="一个自增主键 id 不连续的复现步骤"></p><p>可以看到，这个操作序列复现了一个自增主键 id 不连续的现场 (没有 id=2 的行）。<strong>可见，唯一键冲突是导致自增主键 id 不连续的第一种原因。同样地，事务回滚也会产生类似的现象，这就是第二种原因</strong>。下面这个语句序列就可以构造不连续的自增 id</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">insert into t values(null,1,1);begin;insert into t values(null,2,2);rollback;insert into t values(null,2,2);//插入的行是(3,2,2)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="为什么事务回滚不回退自增值"><a class="header-anchor" href="#为什么事务回滚不回退自增值">¶</a>为什么事务回滚不回退自增值</h3><p>为什么在出现唯一键冲突或者回滚的时候，MySQL 没有把表 t 的自增值改回去呢？如果把表 t 的当前自增值从 3 改回 2，再插入新数据的时候，不就可以生成 id=2 的一行数据了吗？其实，MySQL 这么设计是为了提升性能。接下来分析一下这个设计思路，看看自增值为什么不能回退。</p><p>假设有两个并行执行的事务，在申请自增值的时候，为了避免两个事务申请到相同的自增 id，肯定要加锁，然后顺序申请。</p><ol><li>假设事务 A 申请到了 id=2， 事务 B 申请到 id=3，那么这时候表 t 的自增值是 4，之后继续执行。</li><li>事务 B 正确提交了，但事务 A 出现了唯一键冲突。</li><li>如果允许事务 A 把自增 id 回退，也就是把表 t 的当前自增值改回 2，那么就会出现这样的情况：表里面已经有 id=3 的行，而当前的自增 id 值是 2。</li><li>接下来，继续执行的其他事务就会申请到 id=2，然后再申请到 id=3。这时，就会出现插入语句报错“主键冲突”。</li></ol><p>而为了解决这个主键冲突，有两种方法：</p><ol><li>每次申请 id 之前，先判断表里面是否已经存在这个 id。如果存在，就跳过这个 id。但是，这个方法的成本很高。因为，本来申请 id 是一个很快的操作，现在还要再去主键索引树上判断 id 是否存在（这种方案逻辑上还是不连续的，后面插入的行补了前面回滚事务申请的自增 id 的坑，此时数据的插入顺序和自增 id 大小排序是不匹配的）。</li><li>把自增 id 的锁范围扩大，必须等到一个事务执行完成并提交，下一个事务才能再申请自增 id。这个方法的问题，就是锁的粒度太大，系统并发能力大大下降。</li></ol><p>可见，这两个方法都会导致性能问题。造成这些麻烦的罪魁祸首，就是我们假设的这个“允许自增 id 回退”的前提导致的。因此，InnoDB 放弃了这个设计，语句执行失败也不回退自增 id。也正是因为这样，所以才<strong>只保证了自增 id 是递增的，但不保证是连续的</strong>。</p><h2 id="2-自增锁的优化"><a class="header-anchor" href="#2-自增锁的优化">¶</a>2&gt;自增锁的优化</h2><p>可以看到，自增 id 锁并不是一个事务锁，而是每次申请完就马上释放，以便允许别的事务再申请。其实，在 MySQL 5.1 版本之前，并不是这样的。接下来，先介绍下自增锁设计的历史，这样有助于分析接下来的一个问题。在 MySQL 5.0 版本的时候，自增锁的范围是语句级别。也就是说，如果一个语句申请了一个表自增锁，这个锁会等语句执行结束以后才释放。显然，这样设计会影响并发度。</p><h3 id="5-1-版本自增锁优化及数据一致性考虑"><a class="header-anchor" href="#5-1-版本自增锁优化及数据一致性考虑">¶</a>5.1 版本自增锁优化及数据一致性考虑</h3><p>MySQL 5.1.22 版本引入了一个新策略，新增参数 <code>innodb_autoinc_lock_mode</code>，默认值是 1。</p><ol><li>这个参数的值被设置为 0 时，表示采用之前 MySQL 5.0 版本的策略，即语句执行结束后才释放锁；</li><li>这个参数的值被设置为 1 时：普通 <code>insert</code> 语句，自增锁在申请之后就马上释放；类似 <code>insert … select</code> 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；</li><li>这个参数的值被设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁。</li></ol><p>为什么默认设置下，<code>insert … select</code> 要使用语句级的锁？为什么这个参数的默认值不是 2？答案是，这么设计还是为了数据的一致性。一起来看一下这个场景：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134039.png" alt="批量插入数据的自增锁"></p><p>在这个例子里，往表 t1 中插入了 4 行数据，然后创建了一个相同结构的表 t2，然后两个 session 同时执行向表 t2 中插入数据的操作。你可以设想一下，如果 session B 是申请了自增值以后马上就释放自增锁，那么就可能出现这样的情况：</p><ul><li>session B 先插入了两个记录，(1,1,1)、(2,2,2)；</li><li>然后，session A 来申请自增 id 得到 id=3，插入了（3,5,5)；</li><li>之后，session B 继续执行，插入两条记录 (4,3,3)、 (5,4,4)。</li></ul><p>最终导致为 t1 数据为(1,1,1)、(2,2,2)、(3,3,3)、(4,4,4)，而 t2 数据为(1,1,1)、(2,2,2)、(3,5,5)、(4,3,3)、(5,4,4) 。或许也没关系吧，毕竟 session B 的语义本身就没有要求表 t2 的所有行的数据都跟 session A 相同。是的，从数据逻辑上看是对的。但是，如果我们现在的 <code>binlog_format=statement</code>，你可以设想下，binlog 会怎么记录呢？由于两个 session 是同时执行插入数据命令的，所以 binlog 里面对表 t2 的更新日志只有两种情况：要么先记 session A 的，要么先记 session B 的。</p><p>但不论是哪一种，这个 binlog 拿去从库执行，或者用来恢复临时实例，备库和临时实例里面，session B 这个语句执行出来，生成的结果里面，id 都是连续的。这时，这个库就发生了数据不一致。你可以分析一下，出现这个问题的原因是什么？其实，这是因为原库 session B 的 insert 语句，生成的 id 不连续。这个不连续的 id，用 statement 格式的 binlog 来<strong>串行执行</strong>，是执行不出来的。而要解决这个问题，有两种思路：</p><ol><li>一种思路是，让原库的批量插入数据语句，固定生成连续的 id 值。所以，自增锁直到语句执行结束才释放，就是为了达到这个目的。</li><li>另一种思路是，在 binlog 里面把插入数据的操作都如实记录进来，到备库执行的时候，不再依赖于自增主键去生成。这种情况，其实就是 <code>innodb_autoinc_lock_mode</code> 设置为 2，同时 <code>binlog_format</code> 设置为 row。</li></ol><p>因此，在生产上，尤其是有 <code>insert … select</code> 这种批量插入数据的场景时，<strong>从并发插入数据性能的角度考虑，建议这样设置：<code>innodb_autoinc_lock_mode=2</code> ，并且 <code>binlog_format=row</code></strong>. 这样做，既能提升并发性，又不会出现数据一致性问题。需要注意的是，<strong>这里说的批量插入数据，包含的语句类型是 <code>insert … select</code>、<code>replace … select</code> 和 <code>load data</code> 语句</strong>。</p><p>但是，在<strong>普通的 insert 语句里面包含多个 value 值</strong>的情况下，即使 <code>innodb_autoinc_lock_mode</code> 设置为 1，也不会等语句执行完成才释放锁。因为这类语句在申请自增 id 的时候，是可以精确计算出需要多少个 id 的，然后一次性申请，申请完成后锁就可以释放了。</p><h3 id="针对会多次申请自增值的语句的优化"><a class="header-anchor" href="#针对会多次申请自增值的语句的优化">¶</a>针对会多次申请自增值的语句的优化</h3><p>也就是说，批量插入数据的语句，之所以需要这么设置，是因为“不知道要预先申请多少个 id”。既然预先不知道要申请多少个自增 id，那么一种直接的想法就是需要一个时申请一个。但如果一个 <code>select … insert</code> 语句要插入 10 万行数据，按照这个逻辑的话就要申请 10 万次。显然，这种申请自增 id 的策略，在大批量插入数据的情况下，不但速度慢，还会影响并发插入的性能。</p><p>因此，对于批量插入数据的语句，MySQL 有一个批量申请自增 id 的策略：</p><ol><li>语句执行过程中，第一次申请自增 id，会分配 1 个；</li><li>1 个用完以后，这个语句第二次申请自增 id，会分配 2 个；</li><li>2 个用完以后，还是这个语句，第三次申请自增 id，会分配 4 个；</li><li>依此类推，同一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍。</li></ol><p>举个例子，我们一起看看下面的这个语句序列：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">insert into t values(null, 1,1);insert into t values(null, 2,2);insert into t values(null, 3,3);insert into t values(null, 4,4);create table t2 like t;insert into t2(c,d) select c,d from t;insert into t2 values(null, 5,5);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>insert…select</code>，实际上往表 t2 中插入了 4 行数据。但是，这四行数据是分三次申请的自增 id，第一次申请到了 id=1，第二次被分配了 id=2 和 id=3， 第三次被分配到 id=4 到 id=7。由于这条语句实际只用上了 4 个 id，所以 id=5 到 id=7 就被浪费掉了。之后，再执行 <code>insert into t2 values(null, 5,5)</code>，实际上插入的数据就是(8,5,5)。<strong>这是主键 id 出现自增 id 不连续的第三种原因</strong>。</p><h2 id="备库自增主键问题"><a class="header-anchor" href="#备库自增主键问题">¶</a>备库自增主键问题</h2><p>在 <code>binlog_format=statement</code> 时，语句 A 先获取 id=1，然后语句 B 获取 id=2；接着语句 B 提交，写 binlog，然后语句 A 再写 binlog。这时候，如果 binlog 重放，是不是会发生语句 B 的 id 为 1，而语句 A 的 id 为 2 的不一致情况呢？</p><p>首先，这个问题默认了“自增 id 的生成顺序，和 binlog 的写入顺序可能是不同的”，这个理解是正确的。其次，这个问题限定在 statement 格式下，也是对的。因为 row 格式的 binlog 就没有这个问题了，Write row event 里面直接写了每一行的所有字段的值。而至于为什么不会发生不一致的情况，我们来看一下下面的这个例子。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create table t(id int auto_increment primary key);insert into t values(null);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134049.png" alt="insert 语句的 binlog"></p><p>可以看到，在 <code>insert</code> 语句之前，还有一句 <code>SET INSERT_ID=1</code>。这条命令的意思是，这个线程里下一次需要用到自增值的时候，不论当前表的自增值是多少，固定用 1 这个值。这个 <code>SET INSERT_ID</code> 语句是固定跟在 <code>insert</code> 语句之前的，比如上面提到的场景，主库上语句 A 的 id 是 1，语句 B 的 id 是 2，但是写入 binlog 的顺序先 B 后 A，那么 binlog 就变成：</p><pre><code>SET INSERT_ID=2;语句B；SET INSERT_ID=1;语句A；</code></pre><p>在备库上语句 B 用到的 <code>INSERT_ID</code> 依然是 2，跟主库相同。因此，即使两个 <code>INSERT</code> 语句在主备库的执行顺序不同，自增主键字段的值也不会不一致。</p><h1>二十六、<code>insert</code> 语句加锁</h1><p>前面提到 MySQL 对自增主键锁做了优化，尽量在申请到自增 id 以后，就释放自增锁。因此，insert 语句是一个很轻量的操作。不过，这个结论对于“普通的 insert 语句”才有效。也就是说，还有些 insert 语句是属于“特殊情况”的，在执行过程中需要给其他资源加锁，或者无法在申请到自增 id 以后就立马释放自增锁。</p><h2 id="先导：例子-v6"><a class="header-anchor" href="#先导：例子-v6">¶</a>先导：例子</h2><p>表 t 和 t2 的表结构、初始化数据语句如下</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `c` int(11) DEFAULT NULL,  `d` int(11) DEFAULT NULL,  PRIMARY KEY (`id`),  UNIQUE KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(null, 1,1);insert into t values(null, 2,2);insert into t values(null, 3,3);insert into t values(null, 4,4);create table t2 like t<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="insert-…-select-语句"><a class="header-anchor" href="#insert-…-select-语句">¶</a><code>insert … select</code> 语句</h2><p>现在，我们一起来看看为什么在可重复读隔离级别下，<code>binlog_format=statement</code> 时执行：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">insert into t2(c,d) select c,d from t;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个语句时，需要对表 t 的所有行和间隙加锁呢？其实，这个问题我们需要考虑的还是日志和数据的一致性。我们看下这个执行序列：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134556.png" alt="并发 insert 场景"></p><p>实际的执行效果是，如果 session B 先执行，由于这个语句对表 t 主键索引加了 <code>(-∞,1]</code>这个 next-key lock，会在语句执行完成后，才允许 session A 的 insert 语句执行。但如果没有锁的话，就可能出现 session B 的 insert 语句先执行，但是后写入 binlog 的情况。于是，在 <code>binlog_format=statement</code> 的情况下，binlog 里面就记录了这样的语句序列：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">insert into t values(-1,-1,-1);insert into t2(c,d) select c,d from t;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这个语句到了备库执行，就会把 id=-1 这一行也写到表 t2 中，出现主备不一致。</p><h2 id="insert-循环写入"><a class="header-anchor" href="#insert-循环写入">¶</a><code>insert</code> 循环写入</h2><p>当然了，执行 <code>insert … select</code> 的时候，对目标表也不是锁全表，而是只锁住需要访问的资源。如果现在有这么一个需求：要往表 t2 中插入一行数据，这一行的 c 值是表 t 中 c 值的最大值加 1。此时，我们可以这么写这条 SQL 语句 ：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">insert into t2(c,d)  (select c+1, d from t force index(c) order by c desc limit 1);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个语句的加锁范围，就是表 t 索引 c 上的 <code>(3,4]</code>和 <code>(4,supremum]</code>这两个 next-key lock，以及主键索引上 id=4 这一行。</p><p>它的执行流程也比较简单，从表 t 中按照索引 c 倒序，扫描第一行，拿到结果写入到表 t2 中。因此整条语句的扫描行数是 1。这个语句执行的慢查询日志（slow log），如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134100.png" alt="慢查询日志 -- 将数据插入表 t2"></p><p>通过这个慢查询日志，我们看到 Rows_examined=1，正好验证了执行这条语句的扫描行数为 1。</p><p>那么，如果我们是要把这样的一行数据插入到表 t 中的话：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">insert into t(c,d)  (select c+1, d from t force index(c) order by c desc limit 1);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>语句的执行流程是怎样的？扫描行数又是多少呢？这时候，我们再看慢查询日志就会发现不对了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134106.png" alt="慢查询日志 -- 将数据插入表 t"></p><p>可以看到，这时候的 Rows_examined 的值是 5。</p><p>看一下这条语句的 explain 结果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134112.png" alt="将数据插入表t explain 结果"></p><p>从 Extra 字段可以看到“Using temporary”字样，表示这个语句用到了临时表。也就是说，执行过程中，需要把表 t 的内容读出来，写入临时表。图中 rows 显示的是 1，我们不妨先对这个语句的执行流程做一个猜测：如果说是把子查询的结果读出来（扫描 1 行），写入临时表，然后再从临时表读出来（扫描 1 行），写回表 t 中。那么，这个语句的扫描行数就应该是 2，而不是 5。所以，这个猜测不对。实际上，Explain 结果里的 rows=1 是因为受到了 limit 1 的影响。从另一个角度考虑的话，我们可以看看 InnoDB 扫描了多少行。如下图所示，是在执行这个语句前后查看 <code>Innodb_rows_read</code> 的结果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134118.png" alt="查看 Innodb_rows_read 变化"></p><p>可以看到，这个语句执行前后，<code>Innodb_rows_read</code> 的值增加了 4。因为默认临时表是使用 Memory 引擎的，所以这 4 行查的都是表 t，也就是说<strong>对表 t 做了全表扫描</strong>。这样，我们就把整个执行过程理清楚了：</p><ol><li>创建临时表，表里有两个字段 c 和 d。</li><li>按照索引 c 扫描表 t，依次取 c=4、3、2、1，然后回表，读到 c 和 d 的值写入临时表。这时，Rows_examined=4。</li><li>由于语义里面有 limit 1，所以只取了临时表的第一行，再插入到表 t 中。这时，Rows_examined 的值加 1，变成了 5。</li></ol><p>也就是说，<strong>这个语句会导致在表 t 上做全表扫描，并且会给索引 c 上的所有间隙都加上共享的 next-key lock</strong>。所以，这个语句执行期间，其他事务不能在这个表上插入数据。至于这个语句的执行为什么需要临时表，原因是这类一边遍历数据，一边更新数据的情况，如果读出来的数据直接写回原表，就可能在遍历过程中，读到刚刚插入的记录，新插入的记录如果参与计算逻辑，就跟语义不符。</p><p>由于实现上这个语句没有在子查询中就直接使用 limit 1，从而导致了这个语句的执行需要遍历整个表 t。它的优化方法也比较简单，就是用前面介绍的方法，先自己直接 select 出来然后再使用  insert into 到临时表 temp_t，这样就只需要扫描一行；然后再从表 temp_t 里面取出这行数据插入表 t1。</p><p>当然，由于这个语句涉及的数据量很小，你可以考虑使用内存临时表来做这个优化。使用内存临时表优化时，语句序列的写法如下：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create temporary table temp_t(c int,d int) engine=memory;insert into temp_t  (select c+1, d from t force index(c) order by c desc limit 1);insert into t select * from temp_t;drop table temp_t;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="insert-唯一键冲突"><a class="header-anchor" href="#insert-唯一键冲突">¶</a>insert 唯一键冲突</h2><p>前面的两个例子是使用 <code>insert … select</code> 的情况，接下来要介绍的这个例子就是最常见的 <code>insert</code> 语句出现唯一键冲突的情况。对于有唯一键的表，插入数据时出现唯一键冲突也是常见的情况了。先举一个简单的唯一键冲突的例子。<img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134127.png" alt="唯一键冲突加锁"></p><p>这个例子也是在可重复读（repeatable read）隔离级别下执行的。可以看到，session B 要执行的 insert 语句进入了锁等待状态。也就是说，session A 执行的 <code>insert</code> 语句，发生唯一键冲突的时候，并不只是简单地报错返回，还在冲突的索引上加了锁。我们前面说过，一个 next-key lock 就是由它右边界的值定义的。这时候，session A 持有索引 c 上的 <code>(5,10]</code>共享 next-key lock（读锁）。</p><blockquote><p>至于为什么要加这个读锁，其实我也没有找到合理的解释。从作用上来看，这样做可以避免这一行被别的事务删掉。这里<a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html" target="_blank" rel="noopener">官方文档</a>有一个描述错误，认为如果冲突的是主键索引，就加记录锁，唯一索引才加 next-key lock。但实际上，这两类索引冲突加的都是 next-key lock。</p><p>备注：这个 bug，是丁大在写这篇文章查阅文档时发现的，已经<a href="https://bugs.mysql.com/bug.php?id=93806" target="_blank" rel="noopener">发给官方</a>并被 verified 了。</p></blockquote><h3 id="死锁示例"><a class="header-anchor" href="#死锁示例">¶</a>死锁示例</h3><p>有多个唯一索引的表中并发插入数据时，会出现死锁。这里先和你分享一个经典的死锁场景：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134136.png" alt="唯一键冲突 -- 死锁"></p><p>在 session A 执行 rollback 语句回滚的时候，session C 几乎同时发现死锁并返回。这个死锁产生的逻辑是这样的：</p><ol><li>在 T1 时刻，启动 session A，并执行 <code>insert</code> 语句，此时在索引 c 的 c=5 上加了记录锁。注意，这个索引是唯一索引，因此退化为记录锁 X but not gap lock。</li><li>在 T2 时刻，session B 要执行相同的 insert 语句，发现了唯一键冲突，尝试加上 S Next-key lock；同样地，session C 也在索引 c 上，c=5 这一个记录上，尝试加上 S Next-key lock；两者都被 session A 的 X but not gap lock 阻塞。</li><li>T3 时刻，session A 回滚。这时候，session B 和 session C 都顺利获得 S Next-key lock，并且都要继续执行插入操作，继续尝试插入意向锁(LOCK_INSERT_INTENTION) 后插入数据，但是双方的插入意向锁动作都被双方的 S Next-key lock 阻塞，所以就出现了死锁。</li></ol><h2 id="insert-into-…-on-duplicate-key-update"><a class="header-anchor" href="#insert-into-…-on-duplicate-key-update">¶</a><code>insert into … on duplicate key update</code></h2><p>上面这个例子是主键冲突后直接报错，如果是改写成</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">insert into t values(11,10,10) on duplicate key update d=100; <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>的话，就会给索引 c 上 <code>(5,10]</code> 加一个排他的 next-key lock（写锁）。<code>insert into … on duplicate key update</code> 这个语义的逻辑是，插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。</p><p>注意，如果有多个列违反了唯一性约束，就会按照索引的顺序，对和第一个索引冲突的行进行更新操作。假设现在表 t 里面已经有了 (1,1,1) 和 (2,2,2) 这两行，我们再来看看下面这个语句执行的效果：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134143.png" alt="两个唯一键同时冲突"></p><p>可以看到，主键 id 是先判断的，MySQL 认为这个语句跟 id=2 这一行冲突，所以修改的是 id=2 的行。需要注意的是，执行这条语句的 affected rows 返回的是 2，很容易造成误解。实际上，真正更新的只有一行，只是在代码实现上，insert 和 update 都认为自己成功了，update 计数加了 1， insert 计数也加了 1。</p><h2 id="总结-v6"><a class="header-anchor" href="#总结-v6">¶</a>总结</h2><p><code>insert … select</code> 是很常见的在两个表之间拷贝数据的方法。你需要注意，在可重复读隔离级别下</p><ul><li><p>这个语句会给 <code>select</code> 的表里扫描到的记录和间隙加读锁。</p></li><li><p>而如果 <code>insert</code> 和 <code>select</code> 的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。</p></li><li><p>insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的 next-key lock(S 锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。</p></li></ul><h1>二十七、怎么最快地复制一张表</h1><p>简单地使用 <code>insert … select</code> 语句即可实现。当然，为了避免对源表加读锁，更稳妥的方案是先将数据写到外部文本文件，然后再写回目标表。这时，有两种常用的方法。接下来的内容，会详细展开一下这两种方法。</p><p>为了便于说明，还是先创建一个表 <code>db1.t</code>，并插入 1000 行数据，同时创建一个相同结构的表 <code>db2.t</code>。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create database db1;use db1;create table t(id int primary key, a int, b int, index(a))engine=innodb;delimiter ;;  create procedure idata()  begin    declare i int;    set i=1;    while(i<=1000)do      insert into t values(i,i,i);      set i=i+1;    end while;  end;;delimiter ;call idata();create database db2;create table db2.t like db1.t<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>假设，我们要把 <code>db1.t</code> 里面 a&gt;900 的数据行导出来，插入到 <code>db2.t</code> 中。</p><h2 id="mysqldump-方法"><a class="header-anchor" href="#mysqldump-方法">¶</a><code>mysqldump</code> 方法</h2><p>一种方法是，使用 <code>mysqldump</code> 命令将数据导出成一组 <code>INSERT</code> 语句。你可以使用下面的命令：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --result-file=/client_tmp/t.sql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>把结果输出到临时文件。这条命令中，主要参数含义如下：</p><ol><li><code>–single-transaction</code> 的作用是，在导出数据的时候不需要对表 <code>db1.t</code> 加表锁，而是使用 <code>START TRANSACTION WITH CONSISTENT SNAPSHOT</code> 的方法；</li><li><code>–add-locks</code> 设置为 0，表示在输出的文件结果里，不增加&quot; LOCK TABLES t WRITE;&quot; ；</li><li><code>–no-create-info</code> 的意思是，不需要导出表结构；</li><li><code>–set-gtid-purged=off</code> 表示的是，不输出跟 GTID 相关的信息；</li><li><code>–result-file</code> 指定了输出文件的路径，其中 client 表示生成的文件是在客户端机器上的。</li></ol><p>通过这条 mysqldump 命令生成的 <code>t.sql</code> 文件中就包含了如下图所示的 <code>INSERT</code> 语句</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134152.png" alt="mysqldump 输出文件的部分结果"></p><p>可以看到，一条 <code>INSERT</code> 语句里面会包含多个 value 对，这是为了后续用这个文件来写入数据的时候，执行速度可以更快。如果你希望生成的文件中一条 <code>INSERT</code> 语句只插入一行数据的话，可以在执行 mysqldump 命令时，加上参数<code>–skip-extended-insert</code>。</p><p>然后，你可以通过下面这条命令，将这些 <code>INSERT</code> 语句放到 <code>db2</code> 库里去执行。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">mysql -h127.0.0.1 -P13000  -uroot db2 -e "source /client_tmp/t.sql"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>需要说明的是，<code>source</code> 并不是一条 SQL 语句，而是一个客户端命令。mysql 客户端执行这个命令的流程是这样的：</p><ol><li>打开文件，默认以分号为结尾读取一条条的 SQL 语句；</li><li>将 SQL 语句发送到服务端执行。</li></ol><p>也就是说，服务端执行的并不是这个 <code>source t.sql</code> 语句，而是 <code>INSERT</code> 语句。所以，不论是在慢查询日志（slow log），还是在 binlog，记录的都是这些要被真正执行的 <code>INSERT</code> 语句。</p><p>另一种应用场景是使用 mysqlbinlog 工具解析 binlog 文件，并应用到目标库的情况。可以使用下面这条命令 ：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">mysqlbinlog $binlog_file | mysql -h$host -P$port -u$user -p$pwd<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>把日志直接解析出来发给目标库执行。增加 local，就能让这个方法支持非本地的 <code>$host</code>。</p><h2 id="导出-CSV-文件"><a class="header-anchor" href="#导出-CSV-文件">¶</a>导出 CSV 文件</h2><p>另一种方法是直接将结果导出成.csv 文件。MySQL 提供了下面的语法，用来将查询结果导出到服务端本地目录：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select * from db1.t where a>900 into outfile '/server_tmp/t.csv';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我们在使用这条语句时，需要注意如下几点。</p><ol><li>这条语句会将结果保存在服务端。如果你执行命令的客户端和 MySQL 服务端不在同一个机器上，客户端机器的临时目录下是不会生成 t.csv 文件的。</li><li><code>into outfile</code> 指定了文件的生成位置（<code>/server_tmp/</code>），这个位置必须受参数 <code>secure_file_priv</code> 的限制。参数 <code>secure_file_priv</code> 的可选值和作用分别是：<ul><li>如果设置为 empty，表示不限制文件生成的位置，这是不安全的设置；</li><li>如果设置为一个表示路径的字符串，就要求生成的文件只能放在这个指定的目录，或者它的子目录；</li><li>如果设置为 NULL，就表示禁止在这个 MySQL 实例上执行 <code>select … into outfile</code> 操作。</li></ul></li><li>这条命令不会帮你覆盖文件，因此你需要确保 <code>/server_tmp/t.csv</code> 这个文件不存在，否则执行语句时就会因为有同名文件的存在而报错。</li><li>这条命令生成的文本文件中，原则上一个数据行对应文本文件的一行。但是，如果字段中包含换行符，在生成的文本中也会有换行符。不过类似换行符、制表符这类符号，前面都会跟上“\”这个转义符，这样就可以跟字段之间、数据行之间的分隔符区分开。</li></ol><p>得到.csv 导出文件后，你就可以用下面的 <code>load data</code> 命令将数据导入到目标表 <code>db2.t</code> 中。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">load data infile '/server_tmp/t.csv' into table db2.t;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这条语句的执行流程如下所示。</p><ol><li>打开文件 <code>/server_tmp/t.csv</code>，以制表符 (\t) 作为字段间的分隔符，以换行符（\n）作为记录之间的分隔符，进行数据读取；</li><li>启动事务。</li><li>判断每一行的字段数与表 <code>db2.t</code> 是否相同：<ul><li>若不相同，则直接报错，事务回滚；</li><li>若相同，则构造成一行，调用 InnoDB 引擎接口，写入到表中。</li></ul></li><li>重复步骤 3，直到 <code>/server_tmp/t.csv</code> 整个文件读入完成，提交事务。</li></ol><p>如果 <code>binlog_format=statement</code>，这个 load 语句记录到 binlog 里以后，怎么在备库重放呢？由于 <code>/server_tmp/t.csv</code> 文件只保存在主库所在的主机上，如果只是把这条语句原文写到 binlog 中，在备库执行的时候，备库的本地机器上没有这个文件，就会导致主备同步停止。所以，这条语句执行的完整流程，其实是下面这样的。</p><ol><li><p>主库执行完成后，将 <code>/server_tmp/t.csv</code> 文件的内容直接写到 binlog 文件中。</p></li><li><p>往 binlog 文件中写入语句 <code>load data local infile ‘/tmp/SQL_LOAD_MB-1-0’ INTO TABLE db2.t</code>。</p></li><li><p>把这个 binlog 日志传到备库。</p></li><li><p>备库的 apply 线程在执行这个事务日志时：</p><p>a. 先将 binlog 中 t.csv 文件的内容读出来，写入到本地临时目录 <code>/tmp/SQL_LOAD_MB-1-0</code> 中；</p><p>b. 再执行 <code>load data</code> 语句，往备库的 <code>db2.t</code> 表中插入跟主库相同的数据。</p></li></ol><p>执行流程如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134201.jpg" alt="load data 的同步流程"></p><p>注意，这里备库执行的 load data 语句里面，多了一个“local”。它的意思是“将执行这条命令的客户端所在机器的本地文件 <code>/tmp/SQL_LOAD_MB-1-0</code> 的内容，加载到目标表 <code>db2.t</code> 中”，而此时对于接受 binlog 的备库来说，local laod data 和 load data 都是加载在同一机器下的文件。也就是说，<code>load data</code> 命令有两种用法：</p><ol><li>不加“local”，是读取服务端的文件，这个文件必须在 <code>secure_file_priv</code> 指定的目录或子目录下；</li><li>加上“local”，读取的是客户端的文件，只要 mysql 客户端有访问这个文件的权限即可。这时候，MySQL 客户端会先把本地文件传给服务端，然后执行上述的 load data 流程。</li></ol><blockquote><p>所以在通过 binlog 传输 load data 命令给备库的时候，加上 local 是为了确保备库应用 binlog 正常。因为备库可能配置了 secure_file_priv=null，所以如果不用 local 的话，可能会导入失败，造成主备同步延迟。</p></blockquote><p>另外需要注意的是，<code>select …into outfile</code> 方法不会生成表结构文件, 所以我们导数据时还需要单独的命令得到表结构定义。mysqldump 提供了一个<code>–tab</code> 参数，可以同时导出表结构定义文件和 csv 数据文件。这条命令的使用方法如下：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">mysqldump -h$host -P$port -u$user ---single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --tab=$secure_file_priv<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这条命令会在 <code>$secure_file_priv</code> 定义的目录下，创建一个 <code>t.sql</code> 文件保存建表语句，同时创建一个 <code>t.txt</code> 文件保存 CSV 数据。</p><h2 id="物理拷贝方法"><a class="header-anchor" href="#物理拷贝方法">¶</a>物理拷贝方法</h2><p>前面我们提到的 mysqldump 方法和导出 CSV 文件的方法，都是逻辑导数据的方法，也就是将数据从表 <code>db1.t</code> 中读出来，生成文本，然后再写入目标表 <code>db2.t</code> 中。那么有物理导数据的方法吗？比如，直接把 <code>db1.t</code> 表的.frm 文件和.ibd 文件拷贝到 <code>db2</code> 目录下，是否可行呢？</p><p>答案是不行的。</p><p>因为，一个 InnoDB 表，除了包含这两个物理文件外，还需要在数据字典中注册。直接拷贝这两个文件的话，因为数据字典中没有 <code>db2.t</code> 这个表，系统是不会识别和接受它们的。不过，在 MySQL 5.6 版本引入了<strong>可传输表空间</strong>(transportable tablespace) 的方法，可以通过导出 + 导入表空间的方式，实现物理拷贝表的功能。</p><p>假设我们现在的目标是在 <code>db1</code> 库下，复制一个跟表 <code>t</code> 相同的表 <code>r</code>，具体的执行步骤如下：</p><ol><li>执行 <code>create table r like t</code>，创建一个相同表结构的空表；</li><li>执行 <code>alter table r discard tablespace</code>，这时候 r.ibd 文件会被删除；</li><li>执行 <code>flush table t for export</code>，这时候 <code>db1</code> 目录下会生成一个 t.cfg 文件；</li><li>在 <code>db1</code> 目录下执行 <code>cp t.cfg r.cfg</code>；<code>cp t.ibd r.ibd</code>；这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL 进程要有读写权限）；</li><li>执行 <code>unlock tables</code>，这时候 t.cfg 文件会被删除；</li><li>执行 <code>alter table r import tablespace</code>，将这个 r.ibd 文件作为表 r 的新的表空间，由于这个文件的数据内容和 t.ibd 是相同的，所以表 r 中就有了和表 t 相同的数据。</li></ol><p>至此，拷贝表数据的操作就完成了。这个流程的执行过程图如下</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134209.jpg" alt="物理拷贝表"></p><p>关于拷贝表的这个流程，有以下几个注意点：</p><ol><li>在第 3 步执行完 <code>flsuh table</code> 命令之后，<code>db1.t</code> 整个表处于只读状态，直到执行 <code>unlock tables</code> 命令后才释放读锁；</li><li>在执行 <code>import tablespace</code> 的时候，为了让文件里的表空间 id 和数据字典中的一致，会修改 r.ibd 的表空间 id。而这个表空间 id 存在于每一个数据页中。因此，如果是一个很大的文件（比如 TB 级别），每个数据页都需要修改，所以你会看到这个 import 语句的执行是需要一些时间的。当然，如果是相比于逻辑导入的方法，<code>import</code> 语句的耗时是非常短的。</li></ol><h2 id="总结对比"><a class="header-anchor" href="#总结对比">¶</a>总结对比</h2><p>我们来对比一下这三种方法的优缺点。</p><ol><li>物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：<ul><li>必须是全表拷贝，不能只拷贝部分数据；</li><li>需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；</li><li>由于是通过拷贝物理文件实现的，源表和目标表都是使用 InnoDB 引擎时才能使用。</li></ul></li><li>用 mysqldump 生成包含 <code>INSERT</code> 语句文件的方法，可以在 <code>where</code> 参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用 <code>join</code> 这种比较复杂的 <code>where</code> 条件写法。</li><li>用 <code>select … into outfile</code> 的方法是最灵活的，支持所有的 SQL 写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。后两种方式都是逻辑备份方式，是可以跨引擎使用的。</li></ol><h1>二十八、grant之后要跟着flush privileges吗？</h1><p>在 MySQL 里面，<code>grant</code> 语句是用来给用户赋权的。不知道你有没有见过一些操作文档里面提到，<code>grant</code> 之后要马上跟着执行一个 <code>flush privileges</code> 命令，才能使赋权语句生效。那么，<code>grant</code> 之后真的需要执行 <code>flush privileges</code> 吗？如果没有执行这个 <code>flush</code> 命令的话，赋权语句真的不能生效吗？</p><p>为了便于说明，先创建一个用户：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create user 'ua'@'%' identified by 'pa';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这条语句的逻辑是创建一个用户’ua’@’%’，密码是 pa。注意，在 MySQL 里面，用户名 (user)+ 地址 (host) 才表示一个用户，因此 <code>ua@ip1</code> 和 <code>ua@ip2</code> 代表的是两个不同的用户。</p><p>这条命令做了两个动作：</p><ol><li>磁盘上，往 <code>mysql.user</code> 表里插入一行，由于没有指定权限，所以这行数据上所有表示权限的字段的值都是 N；</li><li>内存里，往数组 <code>acl_users</code> 里插入一个 <code>acl_user</code> 对象，这个对象的 <code>access</code> 字段值为 0。</li></ol><p>下图就是这个时刻用户 <code>ua</code> 在 <code>user</code> 表中的状态。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134218.png" alt="mysql.user 数据行"></p><p>在 MySQL 中，用户权限是有不同的范围的。接下来，就按照用户权限范围从大到小的顺序依次说明。</p><h2 id="全局权限"><a class="header-anchor" href="#全局权限">¶</a>全局权限</h2><p>全局权限，作用于整个 MySQL 实例，这些权限信息保存在 <code>mysql</code> 库的 <code>user</code> 表里。如果要给用户 <code>ua</code> 赋一个最高权限的话，语句是这么写的：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">grant all privileges on *.* to 'ua'@'%' with grant option;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个 <code>grant</code> 命令做了两个动作：</p><ol><li>磁盘上，将 <code>mysql.user</code> 表里，用户’ua’@’%'这一行的所有表示权限的字段的值都修改为‘Y’；</li><li>内存里，从数组 <code>acl_users</code> 中找到这个用户对应的对象，将 access 值（权限位）修改为二进制的“全 1”。</li></ol><p>在这个 <code>grant</code> 命令执行完成后，如果有新的客户端使用用户名 <code>ua</code> 登录成功，MySQL 会为新连接维护一个线程对象，然后从 <code>acl_users</code> 数组里查到这个用户的权限，并将权限值<strong>拷贝到这个线程对象</strong>中。之后在这个连接中执行的语句，所有关于全局权限的判断，都直接使用线程对象内部保存的权限位。</p><p>基于上面的分析我们可以知道：</p><ol><li><code>grant</code> 命令对于全局权限，同时更新了磁盘和内存。命令完成后即时生效，接下来新创建的连接会使用新的权限。</li><li>对于一个已经存在的连接，它的全局权限不受 <code>grant</code> 命令的影响。</li></ol><p>需要说明的是，一般在生产环境上要合理控制用户权限的范围。上面用到的这个 <code>grant</code> 语句就是一个典型的错误示范。如果一个用户有所有权限，一般就不应该设置为所有 IP 地址都可以访问。如果要回收上面的 <code>grant</code> 语句赋予的权限，可以使用下面这条命令：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">revoke all privileges on *.* from 'ua'@'%';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这条 <code>revoke</code> 命令的用法与 <code>grant</code> 类似，做了如下两个动作：</p><ol><li>磁盘上，将 <code>mysql.user</code> 表里，用户’ua’@’%'这一行的所有表示权限的字段的值都修改为“N”；</li><li>内存里，从数组 <code>acl_users</code> 中找到这个用户对应的对象，将 access 的值修改为 0。</li></ol><h2 id="db-权限"><a class="header-anchor" href="#db-权限">¶</a>db 权限</h2><p>除了全局权限，MySQL 也支持库级别的权限定义。如果要让用户 <code>ua</code> 拥有库 <code>db1</code> 的所有权限，可以执行下面这条命令：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">grant all privileges on db1.* to 'ua'@'%' with grant option;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>基于库的权限记录保存在 <code>mysql.db</code> 表中，在内存里则保存在数组 <code>acl_dbs</code> 中。这条 <code>grant</code> 命令做了如下两个动作：</p><ol><li>磁盘上，往 <code>mysql.db</code> 表中插入了一行记录，所有权限位字段设置为“Y”；</li><li>内存里，增加一个对象到数组 <code>acl_dbs</code> 中，这个对象的权限位为“全 1”。</li></ol><p>下图就是这个时刻用户 <code>ua</code> 在 <code>db</code> 表中的状态。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134228.png" alt="mysql.db 数据行"></p><p>每次需要判断一个用户对一个数据库读写权限的时候，都需要遍历一次 <code>acl_dbs</code> 数组，根据 <code>user</code>、<code>host</code> 和 <code>db</code> 找到匹配的对象，然后根据对象的权限位来判断。也就是说，<code>grant</code> 修改 <code>db</code> 权限的时候，是同时对磁盘和内存生效的。</p><p><strong><code>grant</code> 操作对于已经存在的连接的影响，在全局权限和基于 <code>db</code> 的权限效果是不同的</strong>。接下来，我们做一个对照试验来分别看一下。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134237.png" alt="权限操作效果"></p><p>需要说明的是，图中 <code>set global sync_binlog</code> 这个操作是需要 super 权限的。</p><p>可以看到，虽然用户 <code>ua</code> 的 super 权限在 T3 时刻已经通过 <code>revoke</code> 语句回收了，但是在 T4 时刻执行 <code>set global</code> 的时候，权限验证还是通过了。这是因为 super 是全局权限，这个权限信息在线程对象中，而 revoke 操作影响不到这个线程对象。</p><p>而在 T5 时刻去掉 <code>ua</code> 对 <code>db1</code> 库的所有权限后，在 T6 时刻 session B 再操作 <code>db1</code> 库的表，就会报错“权限不足”。这是因为 <code>acl_dbs</code> 是一个全局数组，所有线程判断 db 权限都用这个数组，这样 revoke 操作马上就会影响到 session B。</p><p>这里在代码实现上有一个特别的逻辑，如果当前会话已经处于某一个 db 里面，之前 <code>use</code> 这个库的时候拿到的库权限会保存在会话变量中。你可以看到在 T6 时刻，session C 和 session B 对表 t 的操作逻辑是一样的。但是 session B 报错，而 session C 可以执行成功。这是因为 session C 在 T2 时刻执行的 <code>use db1</code>，拿到了这个库的权限，在切换出 <code>db1</code> 库之前，session C 对这个库就一直有权限。</p><h2 id="表权限和列权限"><a class="header-anchor" href="#表权限和列权限">¶</a>表权限和列权限</h2><p>除了 <code>db</code> 级别的权限外，MySQL 支持更细粒度的表权限和列权限。其中，表权限定义存放在表 <code>mysql.tables_priv</code> 中，列权限定义存放在表 <code>mysql.columns_priv</code> 中。这两类权限，组合起来存放在内存的 hash 结构 <code>column_priv_hash</code> 中。</p><p>这两类权限的赋权命令如下：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create table db1.t1(id int, a int);grant all privileges on db1.t1 to 'ua'@'%' with grant option;GRANT SELECT(id), INSERT (id,a) ON mydb.mytbl TO 'ua'@'%' with grant option;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>跟 <code>db</code> 权限类似，这两个权限每次 <code>grant</code> 的时候都会修改数据表，也会同步修改内存中的 hash 结构。因此，对这两类权限的操作，也会马上影响到已经存在的连接。</p><h2 id="是否需要-flush-privileges"><a class="header-anchor" href="#是否需要-flush-privileges">¶</a>是否需要 <code>flush privileges</code></h2><p>看上去 <code>grant</code> 语句都是即时生效的，那这么看应该就不需要执行 <code>flush privileges</code> 语句了呀。答案也确实是这样的。<code>flush privileges</code> 命令会清空 <code>acl_users</code> 数组，然后从 <code>mysql.user</code> 表中读取数据重新加载，重新构造一个 <code>acl_users</code> 数组。也就是说，以数据表中的数据为准，会将全局权限内存数组重新加载一遍。</p><p>同样地，对于 <code>db</code> 权限、表权限和列权限，MySQL 也做了这样的处理。也就是说，如果内存的权限数据和磁盘数据表相同的话，不需要执行 <code>flush privileges</code>。而如果我们都是用 <code>grant</code>/<code>revoke</code> 语句来执行的话，内存和数据表本来就是保持同步更新的。</p><p>因此，正常情况下，<code>grant</code> 命令之后，没有必要跟着执行 <code>flush privileges</code> 命令。</p><h3 id="flush-privileges-使用场景"><a class="header-anchor" href="#flush-privileges-使用场景">¶</a><code>flush privileges</code> 使用场景</h3><p>那么，<code>flush privileges</code> 是在什么时候使用呢？显然，当数据表中的权限数据跟内存中的权限数据不一致的时候，<code>flush privileges</code> 语句可以用来重建内存数据，达到一致状态。这种不一致往往是由不规范的操作导致的，比如直接用 DML 语句操作系统权限表。我们来看一下下面这个场景：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134246.png" alt="使用 flush privileges"></p><p>可以看到，T3 时刻虽然已经用 <code>delete</code> 语句删除了用户 <code>ua</code>，但是在 T4 时刻，仍然可以用 <code>ua</code> 连接成功。原因就是，这时候内存中 <code>acl_users</code> 数组中还有这个用户，因此系统判断时认为用户还正常存在。在 T5 时刻执行过 <code>flush</code> 命令后，内存更新，T6 时刻再要用 <code>ua</code> 来登录的话，就会报错“无法访问”了。直接操作系统表是不规范的操作，这个不一致状态也会导致一些更“诡异”的现象发生。比如，前面这个通过 <code>delete</code> 语句删除用户的例子，就会出现下面的情况：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134252.png" alt="不规范权限操作导致的异常"></p><p>可以看到，由于在 T3 时刻直接删除了数据表的记录，而内存的数据还存在。这就导致了：</p><ol><li>T4 时刻给用户 ua 赋权限失败，因为 <code>mysql.user</code> 表中找不到这行记录；</li><li>而 T5 时刻要重新创建这个用户也不行，因为在做内存判断的时候，会认为这个用户还存在。</li></ol><h2 id="总结-v7"><a class="header-anchor" href="#总结-v7">¶</a>总结</h2><p><code>grant</code> 语句会同时修改数据表和内存，判断权限的时候使用的是内存数据。因此，规范地使用 <code>grant</code> 和 <code>revoke</code> 语句，是不需要随后加上 <code>flush privileges</code> 语句的。<code>flush privileges</code> 语句本身会用数据表的数据重建一份内存权限数据，所以在权限数据可能存在不一致的情况下再使用。而这种不一致往往是由于直接用 DML 语句操作系统权限表导致的，所以我们尽量不要使用这类语句。</p><p>另外，在使用 <code>grant</code> 语句赋权时，你可能还会看到这样的写法：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">grant super on *.* to 'ua'@'%' identified by 'pa';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这条命令加了 <code>identified by ‘密码’</code>， 语句的逻辑里面除了赋权外，还包含了：如果用户<code>’ua’@’%'</code>不存在，就创建这个用户，密码是 <code>pa</code>；如果用户 <code>ua</code> 已经存在，就将密码修改成 <code>pa</code>。这也是一种不建议的写法，因为这种写法很容易就会不慎把密码给改了。</p><h1>二十九、要不要使用分区表？</h1><h2 id="分区表是什么？"><a class="header-anchor" href="#分区表是什么？">¶</a>分区表是什么？</h2><p>为了说明分区表的组织形式，先创建一个表 t：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t` (  `ftime` datetime NOT NULL,  `c` int(11) DEFAULT NULL,  KEY (`ftime`)) ENGINE=InnoDB DEFAULT CHARSET=latin1PARTITION BY RANGE (YEAR(ftime))(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB, PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB, PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);insert into t values('2017-4-1',1),('2018-4-1',1);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134301.png" alt="表 t 的磁盘文件"></p><p>在表 t 中初始化插入了两行记录，按照定义的分区规则，这两行记录分别落在 p_2018 和 p_2019 这两个分区上。可以看到，这个表包含了一个.frm 文件和 4 个.ibd 文件，每个分区对应一个.ibd 文件。也就是说：</p><ul><li>对于引擎层来说，这是 4 个表；</li><li>对于 Server 层来说，这是 1 个表。</li></ul><h2 id="分区表的引擎层行为"><a class="header-anchor" href="#分区表的引擎层行为">¶</a>分区表的引擎层行为</h2><p>先举个在分区表加间隙锁的例子，目的是说明对于 InnoDB 来说，这是 4 个表。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134310.png" alt="分区表间隙锁示例"></p><p>初始化表 t 的时候，只插入了两行数据， <code>ftime</code> 的值分别是，‘2017-4-1’ 和’2018-4-1’ 。session A 的 <code>select</code> 语句对索引 <code>ftime</code> 上这两个记录之间的间隙加了锁。如果是一个普通表的话，那么 T1 时刻，在表 t 的 <code>ftime</code> 索引上，间隙和加锁状态应该是图 3 这样的。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134317.jpg" alt="普通表的加锁范围"></p><p>也就是说，‘2017-4-1’ 和’2018-4-1’ 这两个记录之间的间隙是会被锁住的。那么，sesion B 的两条插入语句应该都要进入锁等待状态。</p><p>但是，从上面的实验效果可以看出，session B 的第一个 <code>insert</code> 语句是可以执行成功的。这是因为，对于引擎来说，p_2018 和 p_2019 是两个不同的表，也就是说 2017-4-1 的下一个记录并不是 2018-4-1，而是 p_2018 分区的 supremum。所以 T1 时刻，在表 t 的 ftime 索引上，间隙和加锁的状态其实是下图这样的：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134324.jpg" alt="分区表 t 的加锁范围"></p><p>由于分区表的规则，session A 的 select 语句其实只操作了分区 p_2018，因此加锁范围就是上图中深绿色的部分。所以，session B 要写入一行 ftime 是 2018-2-1 的时候是可以成功的，而要写入 2017-12-1 这个记录，就要等 session A 的间隙锁。下图就是这时候的 <code>show engine innodb status</code> 的部分结果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134332.png" alt="session B 被锁住信息"></p><p>看完 InnoDB 引擎的例子，我们再来一个 MyISAM 分区表的例子。首先用 <code>alter table t engine=myisam</code>，把表 t 改成 MyISAM 表；然后，再用下面这个例子说明，对于 MyISAM 引擎来说，这是 4 个表。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134339.png" alt="用 MyISAM 表锁验证"></p><p>在 session A 里面，用 <code>sleep(100)</code> 将这条语句的执行时间设置为 100 秒。由于 MyISAM 引擎只支持表锁，所以这条 <code>update</code> 语句会锁住整个表 t 上的读。但我们看到的结果是，session B 的第一条查询语句是可以正常执行的，第二条语句才进入锁等待状态。</p><p>这正是因为 MyISAM 的表锁是在引擎层实现的，session A 加的表锁，其实是锁在分区 p_2018 上。因此，只会堵住在这个分区上执行的查询，落到其他分区的查询是不受影响的。</p><p>看上去分区表看来还不错嘛，为什么很多公司规范都不让用呢？我们使用分区表的一个重要原因就是单表过大。那么，如果不使用分区表的话，我们就是要使用手动分表的方式。接下来，我们一起看看手动分表和分区表有什么区别。</p><p>比如，按照年份来划分，我们就分别创建普通表 t_2017、t_2018、t_2019 等等。手工分表的逻辑，也是找到需要更新的所有分表，然后依次执行更新。在性能上，这和分区表并没有实质的差别。分区表和手工分表，一个是由 server 层来决定使用哪个分区，一个是由应用层代码来决定使用哪个分表。因此，从引擎层看，这两种方式也是没有差别的。其实这两个方案的区别，主要是在 server 层上。从 server 层看，我们就不得不提到分区表一个被广为诟病的问题：打开表的行为。</p><h3 id="分区策略"><a class="header-anchor" href="#分区策略">¶</a>分区策略</h3><p>每当第一次访问一个分区表的时候，MySQL 需要把所有的分区都访问一遍。一个典型的报错情况是这样的：如果一个分区表的分区很多，比如超过了 1000 个，而 MySQL 启动的时候，<code>open_files_limit</code> 参数使用的是默认值 1024，那么就会在访问这个表的时候，由于需要打开所有的文件，导致打开表文件的个数超过了上限而报错。下图就是创建的一个包含了很多分区的表 <code>t_myisam</code>，执行一条插入语句后报错的情况。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134346.png" alt="insert 语句报错"></p><p>可以看到，这条 insert 语句，明显只需要访问一个分区，但语句却无法执行。可以看出这个表用的是 MyISAM 引擎。是的，因为使用 InnoDB 引擎的话，并不会出现这个问题。</p><ul><li><p>MyISAM 分区表使用的分区策略，我们称为<strong>通用分区策略</strong>（generic partitioning），每次访问分区都由 server 层控制。通用分区策略，是 MySQL 一开始支持分区表的时候就存在的代码，在文件管理、表管理的实现上很粗糙，因此有比较严重的性能问题。</p></li><li><p>从 MySQL 5.7.9 开始，InnoDB 引擎引入了<strong>本地分区策略</strong>（native partitioning）。这个策略是在 InnoDB 内部自己管理打开分区的行为。</p></li><li><p>MySQL 从 5.7.17 开始，将 MyISAM 分区表标记为即将弃用 (deprecated)，意思是“从这个版本开始不建议这么使用，请使用替代方案。在将来的版本中会废弃这个功能”。</p></li><li><p>从 MySQL 8.0 版本开始，就不允许创建 MyISAM 分区表了，只允许创建已经实现了本地分区策略的引擎。目前来看，只有 InnoDB 和 NDB 这两个引擎支持了本地分区策略。</p></li></ul><h3 id="分区表的-server-层行为"><a class="header-anchor" href="#分区表的-server-层行为">¶</a>分区表的 server 层行为</h3><p>接下来，我们再看一下分区表在 server 层的行为。如果从 server 层看的话，一个分区表就只是一个表。这句话是什么意思呢？接下来就用下面这个例子来和你说明。如下面两图所示，分别是这个例子的操作序列和执行结果图。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134354.png" alt="分区表的 MDL 锁"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134359.png" alt="show processlist 结果"></p><p>可以看到，虽然 session B 只需要操作 p_2107 这个分区，但是由于 session A 持有整个表 t 的 MDL 锁，就导致了 session B 的 <code>alter</code> 语句被堵住。这也是 DBA 同学经常说的，分区表，在做 DDL 的时候，影响会更大。如果你使用的是普通分表，那么当你在 <code>truncate</code> 一个分表的时候，肯定不会跟另外一个分表上的查询语句，出现 MDL 锁冲突。</p><h3 id="小结-v7"><a class="header-anchor" href="#小结-v7">¶</a>小结</h3><ol><li>MySQL 在第一次打开分区表的时候，需要访问所有的分区；</li><li>在 server 层，认为这是同一张表，因此所有分区共用同一个 MDL 锁；</li><li>在引擎层，认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则，只访问必要的分区。</li></ol><p>而关于“必要的分区”的判断，就是根据 SQL 语句中的 where 条件，结合分区规则来实现的。比如我们上面的例子中，where ftime=‘2018-4-1’，根据分区规则 year 函数算出来的值是 2018，那么就会落在 p_2019 这个分区。</p><p>但是，如果这个 where 条件改成 where ftime&gt;=‘2018-4-1’，虽然查询结果相同，但是这时候根据 where 条件，就要访问 p_2019 和 p_others 这两个分区。</p><p>如果查询语句的 where 条件中没有分区 key，那就只能访问所有分区了。当然，这并不是分区表的问题。即使是使用业务分表的方式，where 条件中没有使用分表的 key，也必须访问所有的分表。</p><h2 id="分区表的应用场景"><a class="header-anchor" href="#分区表的应用场景">¶</a>分区表的应用场景</h2><p>我们已经理解了分区表的概念，那么什么场景下适合使用分区表呢？</p><p>分区表的一个显而易见的优势是对业务透明，相对于用户分表来说，使用分区表的业务代码更简洁。</p><p>还有，分区表可以很方便的清理历史数据。如果一项业务跑的时间足够长，往往就会有根据时间删除历史数据的需求。这时候，按照时间分区的分区表，就可以直接通过 <code>alter table t drop partition …</code>这个语法删掉分区，从而删掉过期的历史数据。这个 <code>alter table t drop partition …</code>操作是直接删除分区文件，效果跟 <code>drop</code> 普通表类似。与使用 <code>delete</code> 语句删除数据相比，优势是速度快、对系统影响小。</p><h2 id="分区表自增主键"><a class="header-anchor" href="#分区表自增主键">¶</a>分区表自增主键</h2><p>表中没有用到自增主键，假设现在要创建一个自增字段 id。MySQL 要求分区表中的主键必须包含分区字段。如果要在表 t 的基础上做修改，你会怎么定义这个表的主键呢？为什么这么定义呢？</p><p>这时候就有两种可选：一种是 (ftime, id)，另一种是 (id, ftime)。</p><p>如果从利用率上来看，应该使用 (ftime, id) 这种模式。因为用 ftime 做分区 key，说明大多数语句都是包含 ftime 的，使用这种模式，可以利用前缀索引的规则，减少一个索引。</p><p>这时的建表语句是：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `ftime` datetime NOT NULL,  `c` int(11) DEFAULT NULL,  PRIMARY KEY (`ftime`,`id`)) ENGINE=MyISAM DEFAULT CHARSET=latin1PARTITION BY RANGE (YEAR(ftime))(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = MyISAM, PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = MyISAM, PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = MyISAM, PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = MyISAM);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>建议尽量使用 InnoDB 引擎。InnoDB 表要求至少有一个索引，以自增字段作为第一个字段，所以需要加一个 id 的单独索引。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `ftime` datetime NOT NULL,  `c` int(11) DEFAULT NULL,  PRIMARY KEY (`ftime`,`id`),  KEY `id` (`id`)) ENGINE=InnoDB DEFAULT CHARSET=latin1PARTITION BY RANGE (YEAR(ftime))(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB, PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB, PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB, PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当然把字段反过来，创建成：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">  PRIMARY KEY (`id`,`ftime`),  KEY `id` (`ftime`)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="总结-v8"><a class="header-anchor" href="#总结-v8">¶</a>总结</h2><p>需要注意的是，上面是以范围分区（range）为例介绍分区表的。实际上，MySQL 还支持 hash 分区、list 分区等分区方法。可以在需要用到的时候，再翻翻<a href="https://dev.mysql.com/doc/refman/8.0/en/partitioning-types.html" target="_blank" rel="noopener">手册</a>。</p><p>实际使用时，分区表跟用户分表比起来，有两个绕不开的问题：</p><ol><li>一个是第一次访问的时候需要访问所有分区，</li><li>另一个是共用 MDL 锁。</li></ol><p>因此，如果要使用分区表，就不要创建太多的分区。曾经有一个用户做了按天分区策略，然后预先创建了 10 年的分区。这种情况下，访问分区表的性能自然是不好的。这里有两个问题需要注意：</p><ol><li>分区并不是越细越好。实际上，单表或者单分区的数据一千万行，只要没有特别大的索引，对于现在的硬件能力来说都已经是小表了。</li><li>分区也不要提前预留太多，在使用之前预先创建即可。比如，如果是按月分区，每年年底时再把下一年度的 12 个新分区创建上即可。对于没有数据的历史分区，要及时的 drop 掉。</li></ol><p>至于分区表的其他问题，比如查询需要跨多个分区取数据，查询性能就会比较慢，基本上就不是分区表本身的问题，而是数据量的问题或者说是使用方式的问题了。当然，如果你的团队已经维护了成熟的分库分表中间件，用业务分表，对业务开发同学没有额外的复杂性，对 DBA 也更直观，自然是更好的。</p><h1>三十、MySQL 中的各种自增 ID</h1><p>MySQL 里有很多自增的 id，每个自增 id 都是定义了初始值，然后不停地往上加步长。虽然自然数是没有上限的，但是在计算机里，只要定义了表示这个数的字节长度，那它就有上限。比如，无符号整型 (unsigned int) 是 4 个字节，上限就是 2<sup>32</sup>-1。既然自增 id 有上限，就有可能被用完。但是，自增 id 用完了会怎么样呢？</p><h2 id="表定义自增值-id"><a class="header-anchor" href="#表定义自增值-id">¶</a>表定义自增值 id</h2><p>表定义的自增值达到上限后的逻辑是：再申请下一个 id 时，得到的值保持不变。我们可以通过下面这个语句序列验证一下：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">create table t(id int unsigned auto_increment primary key) auto_increment=4294967295;insert into t values(null);//成功插入一行 4294967295show create table t;/* CREATE TABLE `t` (  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,  PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=4294967295;*/insert into t values(null);//Duplicate entry '4294967295' for key 'PRIMARY'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，第一个 insert 语句插入数据成功后，这个表的 AUTO_INCREMENT 没有改变（还是 4294967295），就导致了第二个 insert 语句又拿到相同的自增 id 值，再试图执行插入语句，报主键冲突错误。</p><p>2<sup>32</sup>-1（4294967295）不是一个特别大的数，对于一个频繁插入删除数据的表来说，是可能会被用完的。因此在建表的时候你需要考察你的表是否有可能达到这个上限，如果有可能，就应该创建成 8 个字节的 bigint unsigned。</p><h2 id="InnoDB-系统自增-row-id"><a class="header-anchor" href="#InnoDB-系统自增-row-id">¶</a>InnoDB 系统自增 <code>row_id</code></h2><p>如果你创建的 InnoDB 表没有指定主键，那么 InnoDB 会给你创建一个不可见的，长度为 6 个字节的 <code>row_id</code>。InnoDB 维护了一个全局的 <code>dict_sys.row_id</code> 值，所有无主键的 InnoDB 表，每插入一行数据，都将当前的 <code>dict_sys.row_id</code> 值作为要插入数据的 <code>row_id</code>，然后把 <code>dict_sys.row_id</code> 的值加 1。</p><p>实际上，在代码实现时 <code>row_id</code> 是一个长度为 8 字节的无符号长整型 (bigint unsigned)。但是，InnoDB 在设计时，给 <code>row_id</code> 留的只是 6 个字节的长度，这样写到数据表中时只放了最后 6 个字节，所以 <code>row_id</code> 能写到数据表中的值，就有两个特征：</p><ol><li><code>row_id</code> 写入表中的值范围，是从 0 到 2<sup>48</sup>-1；</li><li>当 <code>dict_sys.row_id</code>=2<sup>48</sup>时，如果再有插入数据的行为要来申请 row_id，拿到以后再取最后 6 个字节的话就是 0。</li></ol><p>也就是说，写入表的 <code>row_id</code> 是从 0 开始到 2<sup>48</sup>-1。达到上限后，下一个值就是 0，然后继续循环。</p><p>当然，2<sup>48</sup>-1 这个值本身已经很大了，但是如果一个 MySQL 实例跑得足够久的话，还是可能达到这个上限的。在 InnoDB 逻辑里，申请到 <code>row_id</code>=N 后，就将这行数据写入表中；如果表中已经存在 <code>row_id</code>=N 的行，新写入的行就会覆盖原有的行。要验证这个结论的话，可以通过 gdb 修改系统的自增 <code>row_id</code> 来实现。注意，用 gdb 改变量这个操作是为了便于我们复现问题，只能在测试环境使用。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134418.png" alt="row_id 用完的验证序列"></p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134413.png" alt="row_id 用完的效果验证"></p><p>可以看到，在用 gdb 将 <code>dict_sys.row_id</code> 设置为 2<sup>48</sup>之后，再插入的 a=2 的行会出现在表 t 的第一行，因为这个值的 <code>row_id</code>=0。之后再插入的 a=3 的行，由于 <code>row_id</code>=1，就覆盖了之前 a=1 的行，因为 a=1 这一行的 <code>row_id</code> 也是 1。</p><p>从这个角度看，我们还是应该在 InnoDB 表中主动创建自增主键。因为，表自增 id 到达上限后，再插入数据时报主键冲突错误，是更能被接受的。毕竟覆盖数据，就意味着数据丢失，影响的是数据可靠性；报主键冲突，是插入失败，影响的是可用性。而一般情况下，可靠性优先于可用性。</p><h2 id="Xid"><a class="header-anchor" href="#Xid">¶</a>Xid</h2><p>在介绍 redo log 和 binlog 相配合的时候，提到了它们有一个共同的字段叫作 Xid。它在 MySQL 中是用来对应事务的。那么，Xid 在 MySQL 内部是怎么生成的呢？</p><p>MySQL 内部维护了一个全局变量 <code>global_query_id</code>，每次执行语句的时候将它赋值给 <code>Query_id</code>，然后给这个变量加 1。如果当前语句是这个事务执行的第一条语句，那么 MySQL 还会同时把 <code>Query_id</code> 赋值给这个事务的 Xid。</p><p>而 <code>global_query_id</code> 是一个纯内存变量，重启之后就清零了。所以在同一个数据库实例中，不同事务的 Xid 也是有可能相同的。但是 MySQL 重启之后会重新生成新的 binlog 文件，这就保证了，<strong>同一个 binlog 文件里，Xid 一定是唯一的</strong>。</p><p>虽然 MySQL 重启不会导致同一个 binlog 里面出现两个相同的 Xid，但是如果 <code>global_query_id</code> 达到上限后，就会继续从 0 开始计数。从理论上讲，还是就会出现同一个 binlog 里面出现相同 Xid 的场景。因为 <code>global_query_id</code> 定义的长度是 8 个字节，这个自增值的上限是 2<sup>64</sup>-1。要出现这种情况，必须是下面这样的过程：</p><ol><li>执行一个事务，假设 Xid 是 A；</li><li>接下来执行 2<sup>64</sup>次查询语句，让 <code>global_query_id</code> 回到 A；</li><li>再启动一个事务，这个事务的 Xid 也是 A。</li></ol><p>不过，2<sup>64</sup>这个值太大了，大到你可以认为这个可能性只会存在于理论上。</p><h2 id="Innodb-trx-id"><a class="header-anchor" href="#Innodb-trx-id">¶</a>Innodb <code>trx_id</code></h2><p>Xid 和 InnoDB 的 <code>trx_id</code> 是两个容易混淆的概念。**Xid 是由 server 层维护的。InnoDB 内部使用 Xid，就是为了能够在 InnoDB 事务和 server 之间做关联。但是，InnoDB 自己的 <code>trx_id</code>，是另外维护的。**其实这个 <code>trx_id</code> 就是事务隔离中的实现事务可见性用到的事务 id（transaction id）。</p><p>InnoDB 内部维护了一个 <code>max_trx_id</code> 全局变量，每次需要申请一个新的 <code>trx_id</code> 时，就获得 <code>max_trx_id</code> 的当前值，然后并将 <code>max_trx_id</code> 加 1。InnoDB 数据可见性的核心思想是：每一行数据都记录了更新它的 <code>trx_id</code>，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 <code>trx_id</code> 做对比。对于正在执行的事务，你可以从 <code>information_schema.innodb_trx</code> 表中看到事务的 <code>trx_id</code>。</p><p>他查看了一下 innodb_trx，发现这个事务的 <code>trx_id</code> 是一个很大的数（281479535353408），而且似乎在同一个 session 中启动的会话得到的 trx_id 是保持不变的。当执行任何加写锁的语句后，<code>trx_id</code> 都会变成一个很小的数字（118378）。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134427.png" alt="事务的 trx_id"></p><p>session B 里，从 <code>innodb_trx</code> 表里查出的这两个字段，第二个字段 <code>trx_mysql_thread_id</code> 就是线程 id。显示线程 id，是为了说明这两次查询看到的事务对应的线程 id 都是 5，也就是 session A 所在的线程。</p><p>可以看到，T2 时刻显示的 <code>trx_id</code> 是一个很大的数；T4 时刻显示的 <code>trx_id</code> 是 1289，看上去是一个比较正常的数字。这是什么原因呢？实际上，在 T1 时刻，session A 还没有涉及到更新，是一个只读事务。而对于只读事务，InnoDB 并不会分配 <code>trx_id</code>。也就是说：</p><ol><li>在 T1 时刻，<code>trx_id</code> 的值其实就是 0。而这个很大的数，只是显示用的。下面会提到这个数据的生成逻辑。</li><li>直到 session A 在 T3 时刻执行 <code>insert</code> 语句的时候，InnoDB 才真正分配了 <code>trx_id</code>。所以，T4 时刻，session B 查到的这个 <code>trx_id</code> 的值就是 1289。</li></ol><blockquote><p>需要注意的是，除了显而易见的修改类语句外，如果在 <code>select</code> 语句后面加上 <code>for update</code>，这个事务也不是只读事务。</p></blockquote><p>另外，虽然说 <code>max_trx_id</code> 是按步长 1 递增的，但是：</p><ol><li><code>update</code> 和 <code>delete</code> 语句除了事务本身，还涉及到标记删除旧数据，也就是要把数据放到 purge 队列里等待后续物理删除，这个操作也会把 <code>max_trx_id</code>+1， 因此在一个事务中至少加 2；</li><li>InnoDB 的后台操作，比如表的索引信息统计这类操作，也是会启动内部事务的，因此你可能看到，<code>trx_id</code> 值并不是按照加 1 递增的。</li></ol><p>那么，<strong>T2 时刻查到的这个很大的数字是怎么来的呢？</strong></p><p>其实，这个数字是每次查询的时候由系统临时计算出来的。它的算法是：把当前事务的 trx 变量的指针地址转成整数，再加上 2<sup>48</sup>。使用这个算法，就可以保证以下两点：</p><ol><li>因为同一个只读事务在执行期间，它的指针地址是不会变的，所以不论是在 innodb_trx 还是在 innodb_locks 表里，同一个只读事务查出来的 <code>trx_id</code> 就会是一样的。</li><li>如果有并行的多个只读事务，每个事务的 trx 变量的指针地址肯定不同。这样，不同的并发只读事务，查出来的 <code>trx_id</code> 就是不同的。</li></ol><p>那么，**为什么还要再加上 2<sup>48</sup>呢？**在显示值里面加上 2<sup>48</sup>，目的是要保证只读事务显示的 <code>trx_id</code> 值比较大，正常情况下就会区别于读写事务的 id。但是，<code>trx_id</code> 跟 <code>row_id</code> 的逻辑类似，定义长度也是 8 个字节。因此，在理论上还是可能出现一个读写事务与一个只读事务显示的 <code>trx_id</code> 相同的情况。不过这个概率很低，并且也没有什么实质危害，可以不管它。</p><p>另一个问题是，<strong>只读事务不分配 <code>trx_id</code>，有什么好处呢？</strong></p><ul><li>一个好处是，这样做可以减小事务视图里面活跃事务数组的大小。因为当前正在运行的只读事务，是不影响数据的可见性判断的。所以，在创建事务的一致性视图时，InnoDB 就只需要拷贝读写事务的 <code>trx_id</code>。</li><li>另一个好处是，可以减少 <code>trx_id</code> 的申请次数。在 InnoDB 里，即使你只是执行一个普通的 <code>select</code> 语句，在执行过程中，也是要对应一个只读事务的。所以只读事务优化后，普通的查询语句不需要申请 <code>trx_id</code>，就大大减少了并发事务申请 <code>trx_id</code> 的锁冲突。</li></ul><p>由于只读事务不分配 <code>trx_id</code>，一个自然而然的结果就是 <code>trx_id</code> 的增加速度变慢了。但是，<code>max_trx_id</code> 会持久化存储，重启也不会重置为 0，那么从理论上讲，只要一个 MySQL 服务跑得足够久，就可能出现 <code>max_trx_id</code> 达到 2<sup>48</sup>-1 的上限，然后从 0 开始的情况。当达到这个状态后，MySQL 就会持续出现一个脏读的 bug，我们来复现一下这个 bug。</p><p>首先我们需要把当前的 <code>max_trx_id</code> 先修改成 2<sup>48</sup>-1。注意：这个 case 里使用的是可重复读隔离级别。具体的操作流程如下：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134439.png" alt="复现脏读1"></p><ul><li>由于我们已经把系统的 <code>max_trx_id</code> 设置成了 2<sup>48</sup>-1，所以在 session A 启动的事务 TA 的低水位就是 2<sup>48</sup>-1。</li><li>在 T2 时刻，session B 执行第一条 <code>update</code> 语句的事务 id 就是 2<sup>48</sup>-1，而第二条 <code>update</code> 语句的事务 id 就是 0 了，这条 <code>update</code> 语句执行后生成的数据版本上的 <code>trx_id</code> 就是 0。</li><li>在 T3 时刻，session A 执行 select 语句的时候，判断可见性发现，c=3 这个数据版本的 <code>trx_id</code>，小于事务 TA 的低水位，因此认为这个数据可见。但这个是脏读。由于低水位值会持续增加，而事务 id 从 0 开始计数，就导致了系统在这个时刻之后，所有的查询都会出现脏读的。并且，MySQL 重启时 <code>max_trx_id</code> 也不会清 0，也就是说重启 MySQL，这个 bug 仍然存在。</li></ul><p>那么，**这个 bug 也是只存在于理论上吗？**假设一个 MySQL 实例的 TPS 是每秒 50 万，持续这个压力的话，在 17.8 年后，就会出现这个情况。如果 TPS 更高，这个年限自然也就更短了。但是，从 MySQL 的真正开始流行到现在，恐怕都还没有实例跑到过这个上限。不过，这个 bug 是只要 MySQL 实例服务时间够长，就会必然出现的。</p><h2 id="thread-id"><a class="header-anchor" href="#thread-id">¶</a><code>thread_id</code></h2><p>接下来，我们再看看线程 id（<code>thread_id</code>）。其实，线程 id 才是 MySQL 中最常见的一种自增 id。平时我们在查各种现场的时候，<code>show processlist</code> 里面的第一列，就是 <code>thread_id</code>。</p><p><code>thread_id</code> 的逻辑很好理解：系统保存了一个全局变量 <code>thread_id_counter</code>，每新建一个连接，就将 <code>thread_id_counter</code> 赋值给这个新连接的线程变量。<code>thread_id_counter</code> 定义的大小是 4 个字节，因此达到 2<sup>32</sup>-1 后，它就会重置为 0，然后继续增加。但是，你不会在 <code>show processlist</code> 里看到两个相同的 <code>thread_id</code>。</p><p>这是因为 MySQL 设计了一个唯一数组的逻辑，给新线程分配 <code>thread_id</code> 的时候，逻辑代码是这样的：</p><pre class="line-numbers language-language-c++"><code class="language-language-c++">do {  new_id= thread_id_counter++;} while (!thread_ids.insert_unique(new_id).second);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>存储引擎一般是以页为单位从硬盘读取，而Server层的执行器每次读取一行 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>只要我们写的是DML语句（insert,update,delete,create）等等，那么我们在数据库服务端执行的时候就会涉及到 redo log(重做日志) 和 binlog(归档日志) 两个日志文件的变动。 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>日志也是在磁盘上的，这也是一个写磁盘的过程，但是与更新过程不一样的是，更新过程是在磁盘上随机IO(需要现在磁盘上找到要更新的那行数据)，费时。 而写redo log 是在磁盘上顺序IO(直接将当前更新追加在指定文件后面)。效率要高。 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>即&quot;刷脏&quot;操作，此时也会将在buffer中的数据写入到数据文件中，此时发生随机IO <a href="#fnref4" class="footnote-backref">↩︎</a> <a href="#fnref4:1" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都 fsync 直接持久化到磁盘，即使宕机也不会丢失事务；当设置为2时，则在事务提交时只做write操作，只保证写到系统的page cache，因此实例crash不会丢失事务，但宕机则可能丢失事务；当设置为0时，事务提交不会触发redo写操作(当前事务 redo log 保留在 redo log buffer 中)，而是留给后台线程每秒一次的刷盘(flush/fsync)操作，因此实例crash将最多丢失1秒钟内的事务。建议设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。 <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>sync_binlog=0，当事务提交之后，MySQL不做fsync之类的磁盘同步指令刷新binlog_cache中的信息到磁盘，而让Filesystem自行决定什么时候来做同步，或者cache满了之后才同步到磁盘。sync_binlog=n，当每进行n次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据强制写入磁盘。 <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>这里的事务和我们前面讲的事务不是同一意义的，这里的事务仅指写入日志文件本身。 <a href="#fnref7" class="footnote-backref">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>undo log，原子性的实现也会利用到，另外如果一个事务长时间没有commit 或者 rollback，那么这个事务在回滚段中的写入将一直不能被删除，所以为什么说看上去业务处理失败了，一定要 rollback 事务呢。因为即使是显示开启事务，没有 commit 无需 rollback 看上去对于数据也没有影响，但是事务不提交就一致会占用回滚段导致其无法删除，无用地占用资源。undo log 存储在共享表空间中，共享表空间会持久化为&quot;ibdata&quot;文件。 <a href="#fnref8" class="footnote-backref">↩︎</a> <a href="#fnref8:1" class="footnote-backref">↩︎</a></p></li><li id="fn9" class="footnote-item"><p>对比跳表，跳表是多层链表的结合，所以对于它的修改成本处理得好的话是接近O(1)的，当然，如果是要先查找再修改，还是要O(log(N)). <a href="#fnref9" class="footnote-backref">↩︎</a></p></li><li id="fn10" class="footnote-item"><p>对于机械硬盘来说，磁盘IO的最小单位是某个磁道的一个扇面(即存储数据的单位、寻址单位)，如果某个数据块跨越两个扇面，则需要进行两次磁盘寻址，磁盘寻址是较耗时的过程，涉及寻道时间(磁头从当前磁道移动到操作系统指定的磁道需要的时间)、旋转延迟(磁头移动到指定磁道之后等待磁盘旋转到指定扇区)。操作系统在对磁盘进行管理时通常以磁盘块作为最小单位。磁盘块通常为扇面数的整数倍，更为常见的是2的幂次方倍，如32个扇面或者64个扇面等。而访问数据也是按照磁盘块为单位进行访问，对应的就是磁盘块地址，它相对于实际的硬盘地址(磁道+扇面)是一个逻辑地址。 <a href="#fnref10" class="footnote-backref">↩︎</a></p></li><li id="fn11" class="footnote-item"><p>操作系统按照数据块为单位进行磁盘访问，因为数据块的大小是固定的，所以每次操作系统调度磁盘访问都会经过一样的磁盘寻址将数据块中包含的扇面数据全部加载出来。所以减少数据块的访问次数就是减少了磁盘访问，减少磁盘寻址时间。 <a href="#fnref11" class="footnote-backref">↩︎</a> <a href="#fnref11:1" class="footnote-backref">↩︎</a></p></li><li id="fn12" class="footnote-item"><p>在64位系统中,理论可以访问的内存高达16EB(2的64次幂)字节。实际上,基于需求(用不到那么多内存)、性能(地址越宽在做地址转换时需要的页表级数越多)和成本(消耗更多晶体管)的考虑,在AMD64架构中只支持到52位(4PB)的地址总线和48位(256TB)的虚拟地址空间,所以目前64位的硬件实际能够支持的最大内存只有256TB。此外,操作系统一侧也还会施加自己的约束,64位的Linux则分别支持47位(128TB)的进程虚拟地址空间和46位(64TB)的物理地址空间,64位的Windows系统甚至只支持44位(16TB)的物理地址空间。 <a href="#fnref12" class="footnote-backref">↩︎</a></p></li><li id="fn13" class="footnote-item"><p>这里提到的全局锁和表锁由Server层实现，行锁由 InnoDB 实现 <a href="#fnref13" class="footnote-backref">↩︎</a></p></li><li id="fn14" class="footnote-item"><p>可以通过 <code>unlock tables;</code> 语句解锁 <a href="#fnref14" class="footnote-backref">↩︎</a></p></li><li id="fn15" class="footnote-item"><p>memory 表的位置信息相当于 InnoDB 表的 row id。所谓的 row id 排序就是参与排序的每行数据只包含两个字段，一个是排序字段，另外一个是行的唯一标识字段。InnoDB 表中行的唯一标识字段是 row id，如果表中指明了主键，则该主键为 row id；如果没有，就自动生成一个 row id。memory 表的组织方式和 InnoDB 的索引组织(树+有序数组)方式不同，可以把它当成一个数组，每行相当于数组中的一个元素，位置信息相当于每行的数组索引位置。这样设计将 row id 排序策略与实际的表组织方式解耦开，每个表根据自己的逻辑提供对应的行唯一标识即可。 <a href="#fnref15" class="footnote-backref">↩︎</a> <a href="#fnref15:1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux的fork()和exec()</title>
      <link href="/2020/12/22/linux/personal/linux-de-fork-he-exec/"/>
      <url>/2020/12/22/linux/personal/linux-de-fork-he-exec/</url>
      
        <content type="html"><![CDATA[<p>fork 会基于现有的进程复制一个子进程出来，该子进程代码空间和数据空间都指向父进程的物理空间。只要两个进程的任一个对数据进行修改，此时会产生一个系统中断，中断处理函数对该数据所在内存单元进行拷贝副本到子进程，然后再进行后续操作。即为写时复制。</p><p>fork 函数后只会对子进程的数据物理内存地址做修改，但是不会对代码物理内存地址做修改。而exec 函数则是要修改子进程的代码物理内存地址(从指定内存或者磁盘加载可执行文件或者脚本)，其实就是相当于要执行新的程序了，从它的名字也可以看出来。</p><p>linux 所有进程的祖先都是 init 进程，其过程都是 fork + exec。</p><blockquote><p><a href="https://juejin.im/post/6844903702373859335" target="_blank" rel="noopener">参考阅读</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>00_elastalert概述</title>
      <link href="/2020/12/22/elastalert/00-elastalert-gai-shu/"/>
      <url>/2020/12/22/elastalert/00-elastalert-gai-shu/</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a class="header-anchor" href="#简介">¶</a>简介</h2><p>ElastAlert 是一个用来监控 ES 中的异常、毛刺(spike) 或者其它规则的数据的简单的框架。如果想对一些近实时写入 ES 的数据进行某种规则的监控并做出告警的动作，可以用它来做。</p><h2 id="特性"><a class="header-anchor" href="#特性">¶</a>特性</h2><h4 id="具备可靠性"><a class="header-anchor" href="#具备可靠性">¶</a>具备可靠性</h4><p>ElastAlert 拥有以下特性使得它在重启和 ES 不可达的情况下更可靠</p><ul><li>ElastAlert 会将它的状态信息保存到 ES 中，当它启动的时候，将会恢复到停止之前的状态</li><li>如果 ES 不可响应，ElastAlert 将会等待 ES 恢复之后才会继续下一步</li><li><code>告警器</code> 发生错误的时候会自动重试数次</li></ul><h4 id="高度模块化"><a class="header-anchor" href="#高度模块化">¶</a>高度模块化</h4><p>ElastAlert 的三个主要组件都可以被当成一个模块进行导入或者进行定制开发</p><ul><li><code>规则类型</code>(Rule types)：<code>规则类型</code> 负责处理从 ES 返回的数据。它会根据规则配置被初始化，配置在规则文件中的 filter 查询从 ES 中查询数据返回，然后根据这份数据的匹配结果进行输出。</li><li><code>告警器</code>(Alerts)：<code>告警器</code> 负责基于一个 <code>匹配</code> 进行一定的动作。一个 <code>匹配</code> 通常是一个包含了所有从 ES 中查询回来的 document 的字段，不过可能会包含一些被 <code>规则类型</code> 增加的任意数据。</li><li><code>增强器</code>(Enhancements)：<code>增强器</code> 是一种拦截、修改、增强<code>告警器</code>的途径。在 <code>匹配</code> 字段发送到 <code>告警器</code> 之前，这些数据会先被发到 <code>增强器</code>。</li></ul><h4 id="易于配置"><a class="header-anchor" href="#易于配置">¶</a>易于配置</h4><p>ElastAlert 拥有一个全局的配置文件，<code>config.yaml</code>，里面定义了它作为一个进程启动的时候的一些行为：</p><ul><li><code>buffer_time</code>：<strong>每次轮询 ES 都是查询从当前时间往前推 <code>buffer_time</code> 时间段内的文档</strong>。基于这种方式，一定时间之前的日志仍然可以被 ElastAlert 查询到并处理。<strong>在单独的规则配置文件中可以重写这个选项</strong>。<strong>当规则配置文件中的 <code>use_count_query</code> 和 <code>use_term_query</code> 被设置为 true 的时候，对应的规则将会忽略这个选项。</strong></li><li><code>es_host</code>：用于存储 ElastAlert 状态(metadata)的 ES 集群地址。环境变量 <code>ES_HOST</code> 会覆盖这个字段。</li><li><code>es_port</code>：用于存储 ElastAlert 状态(metadata)的 ES 集群端口。环境变量 <code>ES_PORT</code> 会覆盖这个字段。</li><li><u><code>use_ssl</code></u>：可选；是否使用 TLS 连接 <code>es_host</code>；值为 <code>True</code> 或者 <code>False</code>；环境变量 <code>ES_USE_SSL</code> 会覆盖这个字段。</li><li><code>verify_certs</code>: Optional; 是否验证 TLS 的证书; <code>True</code> or <code>False</code>. 默认为 <code>True</code>.</li><li><code>client_cert</code>: Optional;  客户端 PEM 验证文件路径.</li><li><code>client_key</code>: Optional; 客户端私钥.</li><li><code>ca_certs</code>: Optional; CA 证书路径</li><li><code>es_username</code>: Optional; 连接到 <code>es_host</code> 的用户名. 环境变量 <code>ES_USERNAME</code> 会覆盖这个字段.</li><li><code>es_password</code>: Optional; 连接到 <code>es_host</code> 的密码. 环境变量 <code>ES_PASSWORD</code> 会覆盖这个字段.</li><li><code>es_url_prefix</code>: Optional; ES 端点的 URL 拼接前缀. 环境变量 <code>ES_URL_PREFIX</code> 会覆盖这个字段.</li><li><code>es_send_get_body_as</code>: Optional; 查询 ES 的请求方法 - <code>GET</code>, <code>POST</code> or <code>source</code>. 默认是 <code>GET</code></li><li><strong><code>es_conn_timeout</code>: Optional; 设置连接和查询 <code>es_host</code> 的超时时间; 默认是 <code>20</code>.</strong></li><li><strong><code>rules_loader</code>: Optional; 设置加载规则文件的类. 默认是 <code>FileRulesLoader</code> .</strong></li><li><strong><code>rules_folder</code>: 当<code>rules_loader</code> 是默认值的时候生效。指的是包含所有规则配置文件的文件夹名。ElastAlert 会加载该文件夹及其所有子孙文件夹下以 <code>.yaml</code> 结束的文件。如果这个文件夹内的文件发生了变化，ElastAlert 会分别加载、重载、移除这些文件(自动监听且热加载？).</strong></li><li><strong><code>scan_subdirectories</code>: Optional;  当<code>rules_loader</code> 是默认值的时候生效。设置是否递归扫描 <code>rules_folder</code> - <code>true</code> or <code>false</code>. 默认是 <code>true</code></strong></li><li><strong><code>run_every</code>: 定义 ElastAlert 轮询 ES 的间隔(ElastAlert记住它上次查询的时间，然后按照这个值定期查询) 。这个字段是一个嵌套对象字段, 这个对象的属性可以是各时间单位，例如 <code>minutes: 5</code>，这也是 ElastAlert 所有配置文件中定义时间的方式.</strong></li><li><strong><code>writeback_index</code>:  <code>es_host</code> 中被用来存储 ES 元信息的索引名称.</strong></li><li><code>max_query_size</code>: 每次查询 ES 的时候的限制查询文档的最大数量. 默认是 10,000, 如果你的需求接近了这个数值，考虑在 <code>规则</code> 定义中使用 <code>use_count_query</code> 选项. 如果查询文档数量达到这个限制，ElastAlert 将会使用使用 ES 的 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html" target="_blank" rel="noopener">scroll</a> API 进行查询，将 <code>max_query_size</code> 作为每一次 scroll 的页数, 然后一直 scroll <code>max_scrolling_count</code> 次，如果 <code>max_scrolling_count</code> 没有设置，将会一直 scroll 完整个查询快照.</li><li><code>max_scrolling_count</code>: 允许 scroll 的最大页数. 默认是 <code>0</code>, 不限制 scroll 的页数. 例如如果这个值被设置为 <code>5</code> 且 <code>max_query_size</code> 设置为 <code>10000</code> ，那么最多 <code>50000</code> 个文档会被查询出来.</li><li><code>scroll_keepalive</code>: scrolling 的上下文(快照)允许存在的最大时间 (格式为 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/common-options.html#time-units" target="_blank" rel="noopener">Time Units</a>) . 避免设置一个很大的值，因为这会滥用 ES 的资源, 但是同时要注意允许足够多的时间以获取查询结果并处理.</li><li><code>max_aggregation</code>: 最大的聚合告警数量. 如果一个<code>规则</code>设置了 <code>aggregation</code> , 所有在一个时间区间内(timeframe) 出现的告警将会被一起发生. 默认值是 10,000.</li><li><strong><code>old_query_limit</code>: 当 ElastAlert 启动的时候，允许它从上次发出查询的日期继续查询的最大间隔. 当 ElastAlert 启动的时候，对于每一个 <code>规则</code> ，它都会从 <code>elastalert_metadata</code> 中查询上次轮询的时间然后从该时间开始查询数据, 除非该时间比 <code>old_query_limit</code> 还要早, 此时它就会从当前时间开始查询. 默认是一个星期.</strong></li><li><strong><code>disable_rules_on_error</code>: 如果设置为 true, ElastAlert 将会禁用那些抛出未捕获异常(非 EAException)的 <code>规则</code> . 它会上传一个异常追溯信息到 <code>elastalert_metadata</code> 并且如果 <code>notify_email</code> 如果设置了, 就会发送一个<code>提醒邮件</code>. 被禁用的<code>规则</code>将不再会运行直到 ElastAlert 重启或者<code>规则</code>配置文件被修改了. 默认是 True.</strong></li><li><code>show_disabled_rules</code>: 如果是 true, ElastAlert 在完成执行之后会显示(打印)被禁用的<code>规则</code>列表. 默认是 True.</li><li><strong><code>notify_email</code>: 一个或者一组被用来发送<code>提醒邮件</code>的邮件地址. 在当前，只有抛出未捕获异常的时候会发送<code>提醒邮件</code>. 发送地址, SMTP 服务器地址 以及邮件的 reply-to 头部可以通过 <code>from_addr</code>, <code>smtp_host</code>, and <code>email_reply_to</code> 选项进行分别设置. 默认情况下，不会发出任何邮件.</strong></li><li><code>from_addr</code>: <code>提醒邮件</code>中的 from 头部. 这个值也会被 <code>邮件告警</code> 中使用, 除非在 <code>规则</code> 配置中被重写. 默认值是 “ElastAlert”.</li><li><code>smtp_host</code>: 指定发送<code>提醒邮件</code>的 SMTP 服务地址. 这个值也会被 <code>邮件告警</code> 中使用，除非在 <code>规则</code> 配置中被重写. 默认值是 “localhost”.</li><li><code>email_reply_to</code>: 设置邮件的 Reply-To (回复地址)头部. 默认值就是收件地址(例如<code>notify_email</code>).</li><li><code>aws_region</code>: 这会使得 ElastAlert 在使用亚马逊 ES 服务的时候对 HTTP 请求进行签名. 它会使用实例角色(instance role keys)密钥对请求进行签名. 环境变量 <code>AWS_DEFAULT_REGION</code> 会覆盖这个字段.</li><li><code>boto_profile</code>: 已废弃! 用来对发向 Amazon Elasticsearch Service 请求的签名的 Boto profile, 如果你不使用 instance role keys.</li><li><code>profile</code>: 用来对 Amazon Elasticsearch Service 请求进行签名的 AWS profile , 如果你不使用 instance role keys. 环境变量 <code>AWS_DEFAULT_PROFILE</code> 会覆盖这个字段.</li><li><code>replace_dots_in_field_names</code>: 如果是 <code>True</code>, ElastAlert 会在将 documents 写入到 ES 之前将字段中的任何<code>点</code>替换成<code>下划线</code>. 默认值是 <code>False</code>. Elasticsearch 2.0 - 2.3 不支持在字段名称中存在<code>点</code>.</li><li><code>string_multi_field_name</code>: 作为 ES 中 string multi-fields 的 subfield. Elasticsearch 2 默认值 <code>.raw</code>  、Elasticsearch 5 默认值是 <code>.keyword</code>.</li><li><code>add_metadata_alert</code>: 设置<code>告警</code>是否包含在<code>规则</code>配置文件中包含的元信息 (<code>category</code>, <code>description</code>, <code>owner</code> and <code>priority</code>); 设置 <code>True</code> or <code>False</code>. 默认是 <code>False</code>.</li><li><strong><code>skip_invalid</code>: 如果设置为 <code>True</code>, 跳过无效文件而不是退出.</strong></li></ul><p>默认情况下，ElastAlert 使用一个简单的基础日志配置来打印标准错误的日志信息。可以通过使用 <code>--verbose</code> 或者 <code>--debug</code> 命令行选项将日志级别改成 <code>INFO</code>. 如果你需要一个更复杂的日志配置，你可以在 config 文件提供一个完整的日志配置, 这会使得你可以配置日志输出到一个文件，或者 Logstash 或者调整日志格式。</p><h2 id="主要原理"><a class="header-anchor" href="#主要原理">¶</a>主要原理</h2><p>基于两个核心组件<code>规则类型</code>和<code>告警器</code>定期向 ES 发出请求，然后将 ES 的响应数据传递给 <code>规则类型</code>，由<code>规则类型</code>决定是否出现匹配。当出现匹配的时候，这些数据将会被投递给一个或者多个<code>告警器</code>，具体行为取决于匹配的结果。</p><p>以上提到的内容都被配置在一些规则文件中，每个文件中定义了一个查询、一个<code>规则类型</code>、和一组<code>告警器</code>。</p><h2 id="支持的常见监控规则"><a class="header-anchor" href="#支持的常见监控规则">¶</a>支持的常见监控规则</h2><p>以下是 ElastAlert 提供的一些基于常见的监控模型实现的<code>规则类型</code>：</p><ul><li>frequency：在指定时间 Y 内触发事件 X 次</li><li>spike：当事件发生的速率增长或者下降的时候</li><li>flatline：在指定时间 Y 内触发事件少于 X 次</li><li>blacklist以及whitelist：当某个字段中的值匹配 blacklist 或者 whitelist</li><li>any：当多个 filter 中的任一事件匹配的时候</li><li>change：当一个字段在同一时间内拥有两个不同的值的时候</li></ul><h2 id="支持的告警类型"><a class="header-anchor" href="#支持的告警类型">¶</a>支持的告警类型</h2><ul><li>Command</li><li>Email</li><li>JIRA</li><li>OpsGenie</li><li>SNS</li><li>HipChat</li><li>Slack</li><li>Telegram</li><li>GoogleChat</li><li>Debug</li><li>Stomp</li><li>theHive</li></ul><h2 id="支持自定义"><a class="header-anchor" href="#支持自定义">¶</a>支持自定义</h2><p>自定义额外的<code>规则类型</code>和<code>告警器</code>容易编写和集成。</p><h2 id="除了监控外的用途"><a class="header-anchor" href="#除了监控外的用途">¶</a>除了监控外的用途</h2><ul><li><code>告警器</code>可以链接到 Kibana 面板，显示触发告警的数据</li><li>基于任一字段做聚合统计</li><li>将告警和定期报告进行组合</li><li>使用一个唯一值字段对告警进行分离/隔离</li><li>对<code>规则类型</code>匹配的数据做拦截和增强</li></ul><h2 id="运行-ElastAlert-命令及参数"><a class="header-anchor" href="#运行-ElastAlert-命令及参数">¶</a>运行 ElastAlert 命令及参数</h2><pre><code>$ python elastalert/elastalert.py</code></pre><p>在运行 ElastAlert 的时候有几个参数是可用的:</p><p><code>--config</code> 声明要使用的配置文件. 默认是 <code>config.yaml</code>.</p><p><code>--debug</code> 以 debug 模式. 这会使得 ElastAlert 日志变得冗长, 将所有的 <code>告警器</code> 修改为 <code>DebugAlerter</code>, 仅在控制台打印告警而不执行正常的告警行为, 并且不会将对 ES 的查询和告警元数据写入 ES. 和 –verbose 不能一起使用.</p><p><code>--verbose</code> 也会使得 ElastAlert 日志变得冗长, 使得你可以看到关于查询 ES 的状态信息. 和 –debug 不能一起使用.</p><p><code>--start &lt;timestamp&gt;</code> 将会强制 ElastAlert 从给定时间开始查询, 而不是默认的从当前时间开始查询. 时间戳格式应该是 ISO8601, 例如<code>YYYY-MM-DDTHH:MM:SS</code> (UTC) 或者携带时区 <code>YYYY-MM-DDTHH:MM:SS-08:00</code> (PST). 请注意如果查询一个很大的时间区间，那么在该<code>规则</code>完成整个时间段查询之前将不会发出告警. 强制从当前时间开始查询, 使用 “NOW”.</p><p><code>--end &lt;timestamp&gt;</code> 会导致 ElastAlert 在指定时间戳停止查询. 默认情况下, ElastAlert 将会无限定期查询 ES.</p><p><code>--rule &lt;rule.yaml&gt;</code> 只会执行给定<code>规则</code>文件. 该值应该是一个完全文件路径或者一个文件名存在于 <code>rules_folder</code> 或者它的子孙文件夹.</p><p><code>--silence &lt;unit&gt;=&lt;number&gt;</code> 会将给定<code>规则</code>中<code>告警</code>静默一段时间. <code>规则</code> 必须通过 <code>--rule</code> 给出. <code>&lt;unit&gt;</code> 可以是 days, weeks, hours, minutes or seconds. <code>&lt;number&gt;</code> 是一个整型. 举个例子, <code>--rule noisy_rule.yaml --silence hours=4</code> 会禁止 noisy_rule 在 4 hours 内发出告警.</p><p><code>--es_debug</code> 将会对所有对于 Elasticsearch 的查询进行日志记录.</p><p><code>--es_debug_trace &lt;trace.log&gt;</code> 会将所有对于 ES 做参数的 curl 命令进行日志记录到指定文件. <code>--es_debug_trace</code> 会被传递到 <a href="http://elasticsearch-py.readthedocs.io/en/master/index.html#logging" target="_blank" rel="noopener">elasticsearch.py</a> , 它记录的是 localhost:9200 而不是实际的 <code>es_host</code>:<code>es_port</code>.</p><p><code>--end &lt;timestamp&gt;</code> will force ElastAlert to stop querying after the given time, instead of the default, querying to the present time. This really only makes sense when running standalone. The timestamp is formatted as <code>YYYY-MM-DDTHH:MM:SS</code> (UTC) or with timezone <code>YYYY-MM-DDTHH:MM:SS-XX:00</code> (UTC-XX).</p><p><code>--pin_rules</code> 将会禁止 ElastAlert 在<code>规则</code>配置文件发生变化的时候对<code>规则</code>进行加载、重载、移除(热重载).</p>]]></content>
      
      
      <categories>
          
          <category> elastalert </category>
          
          <category> ES学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES学习 </tag>
            
            <tag> ELK告警 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2020/09/15/jvm/source/bian-yi-diao-shi-jdk9/"/>
      <url>/2020/09/15/jvm/source/bian-yi-diao-shi-jdk9/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>同步、异步、阻塞、非阻塞</title>
      <link href="/2020/09/01/wang-luo-bian-cheng/tong-bu-zu-sai-wen-ti/"/>
      <url>/2020/09/01/wang-luo-bian-cheng/tong-bu-zu-sai-wen-ti/</url>
      
        <content type="html"><![CDATA[<p>同步、异步指的是通信双方约定被调用方如何返回的机制，是在本次会话中返回结果，还是在另外一个会话中返回。</p><p>阻塞、非阻塞指的是调用方是否在被调用方未返回结果的过程中一直等待该结果而不去处理其他事情。</p><p>实际例子：</p><ol><li>同步阻塞：调用方调用被调用方获取结果，被调用方一直计算结果，直到结果出来才会返回结果到调用方，而调用方此时整个进程都会阻塞在这里等待这个结果返回。</li><li>同步非阻塞：调用方调用被调用方获取结果，被调用方一直计算结果，直到结果出来才会返回结果到调用方，而调用方此时可能在多线程处理其他事务。</li><li>异步阻塞：调用方调用被调用方获取结果，被调用方立即返回，并将结果回调地址携带在返回结果中，而调用方即使得到了立即返回，但是直到被调用方结果计算出来放到回调地址中为止它都是整个进程阻塞在这里，不处理其他事务</li><li>异步非阻塞：调用方调用被调用方获取结果，被调用方立即返回，并将结果回调地址携带在返回结果中，而调用方获取到返回之后就去做其他事情了。</li></ol><p>总的来说，同步、非同步主要是描述被调用方如何返回的行为，阻塞、非阻塞主要描述的是调用方如何调用的行为。</p>]]></content>
      
      
      <categories>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2020/05/04/elasticsearch/ce-shi/di-er-bu-fen-ce-shi/"/>
      <url>/2020/05/04/elasticsearch/ce-shi/di-er-bu-fen-ce-shi/</url>
      
        <content type="html"><![CDATA[<p><img src="%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E6%B5%8B%E8%AF%95.resources/image-20200430111848519.png" alt="image-20200430111848519"></p><p><img src="%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E6%B5%8B%E8%AF%95.resources/image-20200430111706978.png" alt="image-20200430111706978"></p><ol><li>对</li><li>数据量小的时候设置分片数为1；数据量大的时候调整 shard_size 参数</li><li>使用 cardinality 聚合操作。（类似 disitinct）</li><li>多字段查询的时候使用算分最高的字段的分值作为整体查询分值</li><li>from、size</li><li>不能</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2020/05/04/elasticsearch/docker-compose/docker-hot-warm-cold/docker-compose/"/>
      <url>/2020/05/04/elasticsearch/docker-compose/docker-hot-warm-cold/docker-compose/</url>
      
        <content type="html"><![CDATA[{"version":"2.2","services":{"cerebro":{"image":"lmenezes/cerebro:0.8.3","container_name":"hwc_cerebro","ports":["9000:9000"],"command":["-Dhosts.0.host=http://elasticsearch:9200"],"networks":["hwc_es7net"]},"kibana":{"image":"docker.elastic.co/kibana/kibana:7.1.0","container_name":"hwc_kibana7","environment":["XPACK_GRAPH_ENABLED=true","TIMELION_ENABLED=true","XPACK_MONITORING_COLLECTION_ENABLED=\"true\""],"ports":["5601:5601"],"networks":["hwc_es7net"]},"elasticsearch":{"image":"docker.elastic.co/elasticsearch/elasticsearch:7.1.0","container_name":"es7_hot","environment":["cluster.name=geektime-hwc","node.name=es7_hot","node.attr.box_type=hot","bootstrap.memory_lock=true","ES_JAVA_OPTS=-Xms512m -Xmx512m","discovery.seed_hosts=es7_hot,es7_warm,es7_cold","cluster.initial_master_nodes=es7_hot,es7_warm,es7_cold"],"ulimits":{"memlock":{"soft":-1,"hard":-1}},"volumes":["hwc_es7data_hot:/usr/share/elasticsearch/data"],"ports":["9200:9200"],"networks":["hwc_es7net"]},"elasticsearch2":{"image":"docker.elastic.co/elasticsearch/elasticsearch:7.1.0","container_name":"es7_warm","environment":["cluster.name=geektime-hwc","node.name=es7_warm","node.attr.box_type=warm","bootstrap.memory_lock=true","ES_JAVA_OPTS=-Xms512m -Xmx512m","discovery.seed_hosts=es7_hot,es7_warm,es7_cold","cluster.initial_master_nodes=es7_hot,es7_warm,es7_cold"],"ulimits":{"memlock":{"soft":-1,"hard":-1}},"volumes":["hwc_es7data_warm:/usr/share/elasticsearch/data"],"networks":["hwc_es7net"]},"elasticsearch3":{"image":"docker.elastic.co/elasticsearch/elasticsearch:7.1.0","container_name":"es7_cold","environment":["cluster.name=geektime-hwc","node.name=es7_cold","node.attr.box_type=cold","bootstrap.memory_lock=true","ES_JAVA_OPTS=-Xms512m -Xmx512m","discovery.seed_hosts=es7_hot,es7_warm,es7_cold","cluster.initial_master_nodes=es7_hot,es7_warm,es7_cold"],"ulimits":{"memlock":{"soft":-1,"hard":-1}},"volumes":["hwc_es7data_cold:/usr/share/elasticsearch/data"],"networks":["hwc_es7net"]}},"volumes":{"hwc_es7data_hot":{"driver":"local"},"hwc_es7data_warm":{"driver":"local"},"hwc_es7data_cold":{"driver":"local"}},"networks":{"hwc_es7net":{"driver":"bridge"}}}]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2020/04/26/elasticsearch/ce-shi/di-yi-bu-fen-ce-shi/"/>
      <url>/2020/04/26/elasticsearch/ce-shi/di-yi-bu-fen-ce-shi/</url>
      
        <content type="html"><![CDATA[<p><img src="%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E6%B5%8B%E8%AF%95.resources/image-20200424193550390.png" alt="image-20200424193550390"></p><p><img src="%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E6%B5%8B%E8%AF%95.resources/image-20200424193503614.png" alt="image-20200424193503614"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2020/04/22/readme/"/>
      <url>/2020/04/22/readme/</url>
      
        <content type="html"><![CDATA[<p>个人笔记</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Btrfs文件系统之subvolume与snapshot</title>
      <link href="/2020/02/16/linux/btrfs-wen-jian-xi-tong-zhi-subvolume-yu-snapshot/"/>
      <url>/2020/02/16/linux/btrfs-wen-jian-xi-tong-zhi-subvolume-yu-snapshot/</url>
      
        <content type="html"><![CDATA[<p>对于大部分文件系统来说，在磁盘上创建好文件系统，然后再挂载到系统中去就完事了。但对于Btrfs来说，除了在格式化和挂载的时候指定不同的参数外，还支持很多其他的功能，比如管理多块硬盘，支持LVM和RAID等，具体的可以参考它的<a href="https://btrfs.wiki.kernel.org/index.php/Main_Page" target="_blank" rel="noopener">官方文档</a>或者<a href="https://segmentfault.com/a/1190000008481493" target="_blank" rel="noopener">Linux下常见文件系统对比</a></p><p><a href="https://btrfs.wiki.kernel.org/index.php/Main_Page" target="_blank" rel="noopener">Btrfs</a>是Linux下大家公认的将会替代ext4的下一代文件系统，功能非常强大。本篇不会介绍Btrfs的原理，也不会介绍Btrfs的所有功能，只是挑了其中的subvolume和snapshot这两个特性来进行介绍</p><blockquote><p>本篇所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="准备环境"><a class="header-anchor" href="#准备环境">¶</a>准备环境</h2><p>先创建一个虚拟的硬盘，然后将它格式化成Btrfs，最后将它挂载到目录/mnt/btrfs</p><pre><code>#为了简单起见，这里只使用一块硬盘来做测试（Btrfs可以管理多块硬盘或分区）。#新建一个文件，用来虚拟一块硬盘dev@ubuntu:~$ fallocate -l 512M /tmp/btrfs.img#在上面创建Btrfs文件系统dev@ubuntu:~$ mkfs.btrfs /tmp/btrfs.imgbtrfs-progs v4.4See http://btrfs.wiki.kernel.org for more information.Label:              (null)UUID:               fd5efcd3-adc2-406b-a684-e6c87dde99a1Node size:          16384Sector size:        4096Filesystem size:    512.00MiBBlock group profiles:  Data:             single            8.00MiB  Metadata:         DUP              40.00MiB  System:           DUP              12.00MiBSSD detected:       noIncompat features:  extref, skinny-metadataNumber of devices:  1Devices:   ID        SIZE  PATH    1   512.00MiB  /tmp/btrfs.img#创建文件夹并挂载dev@ubuntu:~$ sudo mkdir /mnt/btrfsdev@ubuntu:~$ sudo mount /tmp/btrfs.img /mnt/btrfs#修改权限，这样后面的部分操作就不再需要sudodev@ubuntu:~$ sudo chmod 777 /mnt/btrfs</code></pre><h2 id="subvolume"><a class="header-anchor" href="#subvolume">¶</a>subvolume</h2><p>可以把subvolume理解为一个虚拟的设备，由Btrfs管理，创建好了之后就自动挂载到了Btrfs文件系统的一个目录上，所以我们在文件系统里面看到的subvolume就是一个目录，但它是一个特殊的目录，具有挂载点的一些属性。</p><p>新创建的Btrfs文件系统会创建一个路径为“/”的默认subvolume，即root subvolume，其ID为5（别名为0），这是一个ID和目录都预设好的subvolume。</p><pre><code>#这里从mount的参数“subvolid=5,subvol=/”就可以看出来，#默认的root subvolume的id为5，路径为“/”dev@debian:/mnt/btrfs$ mount|grep btrfs/dev/loop1 on /mnt/btrfs type btrfs (rw,relatime,space_cache,subvolid=5,subvol=/)</code></pre><h3 id="创建subvolume"><a class="header-anchor" href="#创建subvolume">¶</a>创建subvolume</h3><p>这里我们将会利用Btrfs提供的工具创建两个新subvolume和两个文件夹，来看看他们之间的差别</p><pre><code>dev@ubuntu:~$ cd /mnt/btrfs#btrfs命令是Btrfs提供的应用层工具，可以用来管理Btrfs#这里依次创建两个subvolume，创建完成之后会自动在当前目录下生成两个目录dev@ubuntu:/mnt/btrfs$ btrfs subvolume create sub1Create subvolume './sub1'dev@ubuntu:/mnt/btrfs$ btrfs subvolume create sub2Create subvolume './sub2'#创建两个文件夹dev@ubuntu:/mnt/btrfs$ mkdir dir1 dir2#在sub1、sub2和dir1中分别创建一个文件dev@ubuntu:/mnt/btrfs$ touch dir1/dir1-01.txtdev@ubuntu:/mnt/btrfs$ touch sub1/sub1-01.txtdev@ubuntu:/mnt/btrfs$ touch sub2/sub2-01.txt#最后看看目录结构，是不是看起来sub1和dir1没什么区别？dev@ubuntu:/mnt/btrfs$ tree.├── dir1│   └── dir1-01.txt├── dir2├── sub1│   └── sub1-01.txt└── sub2    └── sub2-01.txt</code></pre><p>不过由于每个subvolume都是一个单独的虚拟设备，所以无法跨subvolume建立硬链接</p><pre><code>#虽然sub1和sub2属于相同的Btrfs文件系统，并且在一块物理硬盘上#但由于他们属于不同的subvolume，所以在它们之间建立硬链接失败dev@ubuntu:/mnt/btrfs$ ln ./sub1/sub1-01.txt ./sub2/ln: failed to create hard link './sub2/sub1-01.txt' =&gt; './sub1/sub1-01.txt': Invalid cross-device link</code></pre><h2 id="删除subvolume"><a class="header-anchor" href="#删除subvolume">¶</a>删除subvolume</h2><p>subvolume不能用rm来删除，只能通过btrfs命令来删除</p><pre><code>#普通的目录通过rm就可以被删除dev@ubuntu:/mnt/btrfs$ rm -r dir2#通过rm命令删除subvolume失败dev@ubuntu:/mnt/btrfs$ sudo rm -r sub2rm: cannot remove 'sub2': Operation not permitted#需要通过btrfs命令才能删除#删除sub2成功（就算subvolume里面有文件也能被删除）dev@ubuntu:/mnt/btrfs$ sudo btrfs subvolume del sub2Delete subvolume (no-commit): '/mnt/btrfs/sub2'dev@ubuntu:/mnt/btrfs$ tree.├── dir1│   └── dir1-01.txt└── sub1    └── sub1-01.txt</code></pre><p>上面删除的时候可以看到这样的提示： Delete subvolume (no-commit)，表示subvolume被删除了，但没有提交，意思是在内存里面生效了，但磁盘上的内容还没删，意味着如果这个时候系统crash掉，这个subvolume有可能还会回来。btrfs这样做的好处是删除速度很快，不会影响使用，缺点是有可能在后台commit的过程中系统挂掉，导致commit失败。</p><p>为了确保subvolume里的数据被真正的从磁盘上移除掉，可以在删除subvolume的时候指定-c参数，这样btrfs命令会等提交完成之后再返回</p><pre><code>dev@ubuntu:/mnt/btrfs$ sudo btrfs subvolume del -c sub2Delete subvolume (commit): '/mnt/btrfs/sub2'</code></pre><h2 id="挂载subvolume"><a class="header-anchor" href="#挂载subvolume">¶</a>挂载subvolume</h2><p>subvolume可以直接通过mount命令挂载，和挂载其它设备没什么区别，具体的挂载参数请参考<a href="https://btrfs.wiki.kernel.org/index.php/Mount_options" target="_blank" rel="noopener">文档</a></p><pre><code>#创建一个用于挂载点的目录dev@ubuntu:/mnt/btrfs$ sudo mkdir /mnt/sub1#先查看待挂载的subvolume的iddev@debian:/mnt/btrfs$ sudo btrfs subvolume list /mnt/btrfs/ID 256 gen 9 top level 5 path sub1#通过-o参数来指定要挂载的subvolume的ID#通过路径来挂载也是一样的效果：sudo mount -o subvol=/sub1 /tmp/btrfs.img /mnt/sub1/dev@debian:/mnt/btrfs$ sudo mount -o subvolid=256 /tmp/btrfs.img /mnt/sub1/dev@debian:/mnt/btrfs$ tree /mnt/sub1//mnt/sub1/└── sub1-01.txt</code></pre><h2 id="设置subvolume只读"><a class="header-anchor" href="#设置subvolume只读">¶</a>设置subvolume只读</h2><p>subvolume可以被设置成只读状态</p><pre><code>#通过btrfs property可以查看和修改subvolume的只读状态#默认情况下，subvolume的只读属性为false，即允许写dev@ubuntu:/mnt/btrfs$ btrfs property get -ts ./sub1/ro=false#将sub1的只读属性设置成truedev@ubuntu:/mnt/btrfs$ btrfs property set -ts ./sub1/ ro truedev@ubuntu:/mnt/btrfs$ btrfs property get -ts ./sub1ro=true#写文件失败，提示文件系统只读dev@ubuntu:/mnt/btrfs$ touch ./sub1/sub1-02.txttouch: cannot touch './sub1/sub1-02.txt': Read-only file system#将sub1的状态改回去，以免影响后续测试dev@ubuntu:/mnt/btrfs$ btrfs property set -ts ./sub1/ ro false</code></pre><h2 id="snapshot"><a class="header-anchor" href="#snapshot">¶</a>snapshot</h2><p>可以在subvolume的基础上制作快照，几点需要注意：</p><ul><li>默认情况下subvolume的快照是可写的</li><li>快照是特殊的subvolume，具有subvolume的属性。所以快照也可以通过mount挂载，也可以通过btrfs property命令设置只读属性</li><li>由于快照的本质就是一个subvolume，所以可以在快照上面再做快照</li></ul><p>在subvolume上做了快照后，subvolume和快照就会共享所有的文件，只有当文件更新的时候，才会触发COW（copy on write），所以创建快照很快，基本不花时间，并且Btrfs的COW机制很高效，就算多个快照共享一个文件，更新这个文件也和更新一个普通文件差不多的速度。</p><p>如果用过git的话，就能很容易理解Btrfs里的快照，可以把subvolume理解为git里面的master分支，而快照就是从master checkout出来的新分支，于是快照跟git里的分支有类似的特点：</p><ul><li>创建快照几乎没有开销</li><li>可以在快照的基础上再创建快照</li><li>当前快照里面的修改不会影响其它快照</li><li>快照可以被删除</li></ul><p>当然subvolume也可以像git里的master一样被删除。</p><h3 id="创建快照"><a class="header-anchor" href="#创建快照">¶</a>创建快照</h3><pre><code>#在root subvolume的基础上创建一个快照#默认情况下快照是可写的，如果要创建只读快照，需要加上-r参数dev@debian:/mnt/btrfs$ sudo btrfs subvolume snapshot ./ ./snap-rootCreate a snapshot of './' in './snap-root'#创建完成后，可以看到我们已经有了两个subvolumedev@debian:/mnt/btrfs$ sudo btrfs subvolume list ./ID 256 gen 11 top level 5 path sub1ID 257 gen 13 top level 5 path snap-root#我们可以通过指定-s参数来只列出快照dev@debian:/mnt/btrfs$ sudo btrfs subvolume list -s ./ID 257 gen 10 cgen 10 top level 5 otime 2017-03-05 21:46:03 path snap-root#再来看看快照snap-root中的文件，可以看到有dir1及下面的文件，#但看不到sub1下的文件，那是因为sub1是一个subvolume，#在做一个subvolume的快照的时候，不会将它里面的subvolume也做快照dev@debian:/mnt/btrfs$ tree ./snap-root./snap-root├── dir1│   └── dir1-01.txt└── sub1#创建sub1的一个快照，可以看到sub1里面的文件出现在了快照里面dev@debian:/mnt/btrfs$ sudo btrfs subvolume snapshot ./sub1/ ./snap-sub1Create a snapshot of './sub1/' in './snap-sub1'#然后在sub1和它的快照snap-sub1下面各自创建一个文件，#会发现它们之间不受影响dev@debian:/mnt/btrfs$ touch snap-sub1/snap-sub1-01.txtdev@debian:/mnt/btrfs$ touch sub1/sub1-02.txtdev@debian:/mnt/btrfs$ tree.├── dir1│   └── dir1-01.txt├── snap-root│   ├── dir1│   │   └── dir1-01.txt│   └── sub1├── snap-sub1│   ├── snap-sub1-01.txt│   └── sub1-01.txt└── sub1    ├── sub1-01.txt    └── sub1-02.txt</code></pre><h3 id="删除快照"><a class="header-anchor" href="#删除快照">¶</a>删除快照</h3><p>删除快照和删除subvolume是一样的，没有区别</p><pre><code>dev@debian:/mnt/btrfs$ sudo btrfs subvolume del snap-rootDelete subvolume (no-commit): '/mnt/btrfs/snap-root'dev@debian:/mnt/btrfs$ sudo btrfs subvolume del snap-sub1Delete subvolume (no-commit): '/mnt/btrfs/snap-sub1'dev@debian:/mnt/btrfs$ tree.├── dir1│   └── dir1-01.txt└── sub1    ├── sub1-01.txt    └── sub1-02.txt</code></pre><h2 id="default-subvolume"><a class="header-anchor" href="#default-subvolume">¶</a>default subvolume</h2><p>可以设置Btrfs分区的默认subvolume，即在挂载磁盘的时候，可以只让分区中的指定subvolume对用户可见。看下面的例子：</p><pre><code>#查看sub1的IDdev@debian:/mnt/btrfs$ sudo btrfs subvolume list ./ID 256 gen 14 top level 5 path sub1#将sub1设置为当前Btrfs文件系统的默认subvolumedev@debian:/mnt/btrfs$ sudo btrfs subvolume set-default 256 /mnt/btrfs/#重新将虚拟硬盘挂载到一个新目录dev@debian:/mnt/btrfs$ sudo mkdir /mnt/btrfs1dev@debian:/mnt/btrfs$ sudo mount /tmp/btrfs.img /mnt/btrfs1/#这里将只能看到sub1下的文件dev@debian:/mnt/btrfs$ tree /mnt/btrfs1/mnt/btrfs1├── sub1-01.txt└── sub1-02.txt#由于Btrfs原来的默认subvolume是root subvolume，#其ID是5（也可以通过0来标识），#所以我们可以通过同样的命令将默认subvolume再改回去dev@debian:/mnt/btrfs$ sudo btrfs subvolume set-default 0 /mnt/btrfs/</code></pre><h4 id="default-subvolume有什么用呢？"><a class="header-anchor" href="#default-subvolume有什么用呢？">¶</a>default subvolume有什么用呢？</h4><p>利用snapshot和default subvolume，可以很方便的实现不同系统版本的切换，比如将系统安装在一个subvolume下面，当要做什么危险操作的时候，先在subvolume的基础上做一个快照A，如果操作成功，那么什么都不用做（或者把A删掉），继续用原来的subvolume，A不被删掉也没关系，多一个快照在那里也不占空间，如果操作失败，那么可以将A设置成default subvolume，并将原来的subvolume删除，这样就相当于系统回滚。</p><p>有了这样的功能后，Linux的每次操作都能回滚，养成在修改操作前做snapshot的习惯，就再也不用担心rm误删文件了。</p><p>现在有些发行版已经有了类似的功能，如ubuntu，将安装工具（apt）和Btrfs结合，自动的在安装软件之前打一个snapshot，然后安装软件，如果成功，删除新的snapshot，如果失败，修改default subvolume为新的snapshot，删除掉原来的snapshot，这样对系统没有任何影响，并且所有操作对用户是透明的。</p><p>随着Btrfs的成熟和普及，相信会改变一些我们使用Linux的习惯。</p><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>Btrfs的功能太多，需要在使用的过程中去熟悉，本文只是粗略的介绍了一下subvolume和snapshot，关于subvolume的增量备份和磁盘限额都没有涉及到，下次有时间再继续这部分内容。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-btrfs/" target="_blank" rel="noopener">新一代 Linux 文件系统 btrfs 简介</a></li><li><a href="https://btrfs.wiki.kernel.org/index.php/Main_Page" target="_blank" rel="noopener">Btrfs Main Page</a></li><li><a href="https://lwn.net/Articles/579009/" target="_blank" rel="noopener">Btrfs: Subvolumes and snapshots</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LInux CPU 使用率</title>
      <link href="/2020/02/16/linux/linux-cpu-shi-yong-lu/"/>
      <url>/2020/02/16/linux/linux-cpu-shi-yong-lu/</url>
      
        <content type="html"><![CDATA[<p>在Linux下面，可以通过top命令看到CPU的负载情况，其输出大概如下（只摘录CPU部分）：</p><pre><code>top - 01:24:41 up 6 min,  2 users,  load average: 0.00, 0.03, 0.00%Cpu(s):  2.5 us,  1.8 sy,  3.1 ni, 90.5 id,  1.7 wa,  0.0 hi,  0.4 si,  0.0 st</code></pre><p>这里的load average以及缩写的us、sy、ni、id、wa、hi、si、st都是些什么意思呢？这些值在一个什么样的区间比较合理呢？如果值超过了合理区间，应该怎么处理呢？这篇将来聊聊这些问题。</p><h2 id="load-average"><a class="header-anchor" href="#load-average">¶</a>load average</h2><p>load average代表CPU的平均负载值，上面示例中的<code>load average: 0.00, 0.03, 0.00</code>分别表示当前CPU在1分钟、5分钟和15分钟内的平均负载。这些负载值是怎么来的呢？</p><p>这些数据来自于文件/proc/loadavg，内核会负责统计出这些数据。</p><p>top和uptime命令显示的内容就来自于这个文件，那么这里所谓的平均负载是个什么概念？ 根据proc的<a href="http://man7.org/linux/man-pages/man5/proc.5.html" target="_blank" rel="noopener">帮助文件</a>可知，这里的值就是单位时间内处于运行状态以及等待disk I/O状态的平均job数量。这里的运行状态和job都是内核的概念，这里简单澄清一下：</p><ul><li>对内核来说，进程和线程都是job</li><li>job处于运行状态指job处于内核的运行队列中，正在或等待被CPU调度（用户空间的进程正在运行不代表需要被CPU调度，有可能在等待I/O，也有可能在sleep等等）</li></ul><p>因为某一刻（瞬间）等待调度的进程多少并不能反映系统的整体压力，所以这里取了1,5和15分钟的平均值。</p><p>那么这个值的大小反映系统什么样的一个压力状态呢？这里以单核CPU为例</p><ul><li>小于1： 说明平均每次只有不到一个job在忙，对于单核的CPU来说，完全能处理过来</li><li>等于1： 说明平均每次刚好有一个job在忙，对于单核的CPU来说，刚好能处理过来</li><li>大于1： 说明平均每次有多于一个job在忙，对于单核的CPU来说，由于一次只能处理一个任务，所以肯定有任务在等待，说明系统负载较大，调度不过来，有job需要等待</li></ul><p>从上面可以看出，一旦大于1，就说明job得不到及时调度，系统性能将受影响。对于多核来说，由于一次可以调度多个job，所以大于1不一定有问题，以4核CPU为例，该值大于4才说明CPU忙不过来。</p><p>那这个平均负载保持在多少比较合适呢？其实没有一个标准值，但一般的做法是预留一定的空间来应对系统负载的波动，建议控制在“0.7<em>核数”以内，比如4核，那么0.7</em>4=2.8比较合适，一旦超过这个值，需要分析原因并着手解决。</p><h2 id="Cpu-s"><a class="header-anchor" href="#Cpu-s">¶</a>%Cpu(s)</h2><p>load average通过统计等待运行的平均job数量来推断CPU的繁忙程度，而%Cpu(s)则直接统计CPU处于不同状态的时间，比上面的load average更直观，所以在实际上也被使用的更多。</p><p>总体来说，CPU会处于下面三种状态中的一种：</p><ul><li>Idle： 处于空闲状态，没有任务需要调度</li><li>User space： 正在运行user space的代码（处于用户态）</li><li>Kernel： 正在运行内核的代码（处于内核态）</li></ul><p>对上面这三种状态，内核又进一步细分为很多状态，这里以上面输出的8种状态为例进行说明：</p><ul><li><strong>2.5 us</strong> ： 表示CPU有2.5%的时间在运行用户态代码（即在运行用户态程序）</li><li><strong>1.8 sy</strong> ： 表示CPU有1.8%的时间在运行内核态代码。内核负责管理系统的所有进程和硬件资源，所有的内核代码都运行在内核态，当用户态进程需要访问硬件资源时，如分配内存，读写I/O等，也需要通过系统调用进入内核态运行内核代码。%sy高说明内核占用太多资源，或者用户进程发起了太多的系统调用。</li><li><strong>3.1 ni</strong> ： 表示CPU有3.1%的时间在运行niceness不为0的进程代码。默认情况下，进程的niceness值都为0，但可以通过命令<a href="http://man7.org/linux/man-pages/man1/nice.1.html" target="_blank" rel="noopener">nice</a>来启动一个进程并指定其niceness值，niceness的取值范围是-20到19，值越小，表示优先级越高，越优先被内核调度。</li><li><strong>90.5 id</strong> ： 表示CPU有90.5%的时间处于空闲状态</li><li><strong>1.7 wa</strong> ： 表示CPU有1.7%的时间处于I/O等待状态。通常情况下，当CPU遇到一个I/O操作时，会先触发I/O操作，然后去干别的，等I/O操作完成后，CPU再接着继续工作，但如果这时系统比较空闲，CPU没有别的事情可以做，那么CPU将处于等待状态，这种处于等待状态的时间将会被统计进I/O wait，也就是说CPU处于I/O wait状态即CPU闲着没事干在等I/O操作结束，和idle几乎是一样的。这个值高说明CPU闲且I/O操作多或者I/O操作慢，但低并不能说明没有I/O操作或者I/O操作快，有可能是CPU在忙别的，所以这只是一个参考值，需要和其他的统计项一起来分析。</li><li><strong>0.0 hi &amp; 0.4 si</strong> ：　这两个值反映了CPU有多少时间花在了中断处理上，hi（hardware interrupts）是硬件中断，si(softirqs)是软件中断。硬件中断一般由I/O设备引起，如网卡、磁盘等，发生硬件中断后，CPU需要立即处理，当硬件中断中需要处理的事情很多时，内核会生成相应的软中断，然后将耗时且不需要立即处理完成的操作放在软中断中执行，比如当网卡收到网络包时，需要CPU立即把数据拷贝到内存中去，因为网卡自带的缓存较小，如果不及时处理的话后面的数据包就进不来，导致丢包，当数据拷贝到内存中之后，就不需要那么着急的处理了，这时候可以将处理数据包（协议栈）的代码放在软中断中执行。本人不是内核专家，关于软中断的部分请参考<a href="https://www.safaribooksonline.com/library/view/understanding-the-linux/0596005652/ch04s07.html" target="_blank" rel="noopener">Understanding the Linux Kernel, 3rd Edition</a></li><li><strong>0.0 st</strong>　： %st和虚拟机有关，当系统运行在虚拟机中时，当前虚拟机就会和宿主机以及其它的虚拟机共享CPU，%st就表示当前虚拟机在等待CPU为它服务的时间。该值越大，表示物理CPU被宿主机和其它虚拟机占用的时间越长，导致当前虚拟机得不到充足的CPU资源。如果%st长时间大于0，说明CPU资源得不到满足，这时可以考虑将虚拟机移到其它机器上，或者减少当前机器运行的虚拟机数量。</li></ul><p>上面这些统计项的总和等于100%，除了%idle之外，其它的任何一项数值过高都代表系统有问题，需要具体问题具体分析。</p><h2 id="问题处理"><a class="header-anchor" href="#问题处理">¶</a>问题处理</h2><ul><li><strong>%us过高</strong> ： 表示有用户态进程占用了过多的CPU，通过top命令可以很清楚的看到是哪个进程，如果这不是预期的行为，可以通过kill命令杀死相应的进程或者重启它</li><li><strong>%sy过高</strong> ： 如果只是偶尔过高的话，不用担心，但如果是持续走高的话，就需要重视，有可能是某些进程的系统调用太频繁，比如进程不停的往控制台输出日志，但如果用户态的进程都没有问题，那可能是内核里面的代码出现了问题，尤其是代码写的不好的驱动模块</li><li><strong>%ni过高</strong> ： 说明有人用nice程序运行了比较耗CPU的进程。如果niceness值大于0的话，就没什么好担心的，因为它的优先级比默认优先级要低，不会影响CPU性能，但最好还是确认一下该进程不会抢占系统的其它资源，如内存、磁盘I/O等，避免对系统整体性能造成影响。如果niceness值小于0的话，表示该进程优先级高且占用CPU资源多，需要确保该进程占用的CPU资源是符合预期的，如果不是，可以用top命令把它找出来并kill掉或者重启。</li><li><strong>%wa过高</strong> ： 意味着系统中有进程在做大量的I/O操作，或者在读写速度比较慢的I/O设备，比如频繁的读写磁盘，这时可以通过<a href="http://guichaz.free.fr/iotop/" target="_blank" rel="noopener">iotop</a>命令来查看是哪些进程占I/O，然后再针对不同的进程做相应的处理；还有一种情况就是系统在频繁的使用交换分区，这时需要解决的就是内存的问题，而不是I/O的问题。</li><li><strong>%hi或者%si过高</strong> ： %hi过高一般是硬件出问题了，%si过高一般是内核里面的代码出问题了</li><li><strong>%st 过高</strong> ： 正如上面介绍介绍的那样，%st过高表示当前虚拟机得不到足够的CPU资源。这时可以考虑将当前虚拟机搬迁到其它的主机上，或者想办法降低当前主机的负载，比如关掉一些其它的虚拟机。</li></ul><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>load average和%Cpu(s)以不同的方式给出了当前主机的CPU负载情况，通过%Cpu(s)我们可以看到系统当前的实时负载，现在很多监控系统每隔一段时间都会采集一次%Cpu(s)，然后存储起来以图形的方式展示出来，这样就能很直观的看到CPU负载的变化，当然如果没有这样的监控系统的话，通过load average也能大概的知道最近一段时间内的平均负载（最长15分钟）。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="http://www.howtogeek.com/194642/understanding-the-load-average-on-linux-and-other-unix-like-systems/" target="_blank" rel="noopener">Understanding the Load Average on Linux and Other Unix-like Systems</a></li><li><a href="http://blog.scoutapp.com/articles/2009/07/31/understanding-load-averages" target="_blank" rel="noopener">Understanding Linux CPU Load</a></li><li><a href="http://blog.scoutapp.com/articles/2015/02/24/understanding-linuxs-cpu-stats" target="_blank" rel="noopener">Understanding Linux CPU stats</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux OOM Killer</title>
      <link href="/2020/02/16/linux/linux-oom-killer/"/>
      <url>/2020/02/16/linux/linux-oom-killer/</url>
      
        <content type="html"><![CDATA[<p>作为Linux下的程序员，有时不得不面对一个问题，那就是系统内存被用光了，这时当进程再向内核申请内存时，内核会怎么办呢？程序里面调用的malloc函数会返回null吗？</p><p>为了处理内存不足时的问题，Linux内核发明了一种机制，叫OOM(Out Of Memory) killer，通过配置它可以控制内存不足时内核的行为。</p><h2 id="OOM-killer"><a class="header-anchor" href="#OOM-killer">¶</a>OOM killer</h2><p>当物理内存和交换空间都被用完时，如果还有进程来申请内存，内核将触发OOM killer，其行为如下：</p><p>1.检查文件/proc/sys/vm/panic_on_oom，如果里面的值为2，那么系统一定会触发panic<br>2.如果/proc/sys/vm/panic_on_oom的值为1，那么系统有可能触发panic（见后面的介绍）<br>3.如果/proc/sys/vm/panic_on_oom的值为0，或者上一步没有触发panic，那么内核继续检查文件/proc/sys/vm/oom_kill_allocating_task<br>3.如果/proc/sys/vm/oom_kill_allocating_task为1，那么内核将kill掉当前申请内存的进程<br>4.如果/proc/sys/vm/oom_kill_allocating_task为0，内核将检查每个进程的分数，分数最高的进程将被kill掉（见后面介绍）</p><p>进程被kill掉之后，如果/proc/sys/vm/oom_dump_tasks为1，且系统的rlimit中设置了core文件大小，将会由/proc/sys/kernel/core_pattern里面指定的程序生成core dump文件，这个文件里将包含<br>pid, uid, tgid, vm size, rss, nr_ptes, nr_pmds, swapents, oom_score_adj<br>score, name等内容，拿到这个core文件之后，可以做一些分析，看为什么这个进程被选中kill掉。</p><p>这里可以看看ubuntu默认的配置：</p><pre><code>#OOM后不panicdev@ubuntu:~$ cat /proc/sys/vm/panic_on_oom0#OOM后kill掉分数最高的进程dev@ubuntu:~$ cat /proc/sys/vm/oom_kill_allocating_task0#进程由于OOM被kill掉后将生成core dump文件dev@ubuntu:~$ cat /proc/sys/vm/oom_dump_tasks1#默认max core file size是0， 所以系统不会生成core文件dev@ubuntu:~$ prlimit|grep CORECORE max core file size 0 unlimited blocks#core dump文件的生成交给了apport，相关的设置可以参考apport的资料dev@ubuntu:~$ cat /proc/sys/kernel/core_pattern|/usr/share/apport/apport %p %s %c %P</code></pre><p>参考：<a href="https://wiki.ubuntu.com/Apport" target="_blank" rel="noopener">apport</a></p><h3 id="panic-on-oom"><a class="header-anchor" href="#panic-on-oom">¶</a>panic_on_oom</h3><p>正如上面所介绍的那样，该文件的值可以取0/1/2，0是不触发panlic，2是一定触发panlic，如果为1的话就要看<a href="https://www.kernel.org/doc/Documentation/vm/numa_memory_policy.txt" target="_blank" rel="noopener">mempolicy</a>和<a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cpusets.txt" target="_blank" rel="noopener">cpusets</a>，这篇不介绍这方面的内容。</p><p>panic后内核的默认行<br>为是死在那里，目的是给开发人员一个连上去debug的机会。但对于大多数应用层开发人员来说没啥用，倒是希望它赶紧重启。为了让内核panic后重启，可以修改文件/proc/sys/kernel/panic，里面表示的是panic多少秒后系统将重启，这个文件的默认值是0，表示永远不重启。</p><pre><code>#设置panic后3秒重启系统dev@ubuntu:~$ sudo sh -c &quot;echo 3 &gt; /proc/sys/kernel/panic&quot;</code></pre><h3 id="调整分数"><a class="header-anchor" href="#调整分数">¶</a>调整分数</h3><p>当oom_kill_allocating_task的值为0时（系统默认配置），系统会kill掉系统中分数最高的那个进程，这里的分数是怎么来的呢？该值由内核维护，并存储在每个进程的/proc/<pid>/oom_score文件中。</pid></p><p>每个进程的分数受多方面的影响，比如进程运行的时间，时间越长表明这个程序越重要，所以分数越低；进程从启动后分配的内存越多，表示越占内存，分数会越高；这里只是列举了一两个影响分数的因素，实际情况要复杂的多，需要看内核代码，这里有篇文章可以参考：<a href="https://lwn.net/Articles/317814/" target="_blank" rel="noopener">Taming the OOM killer</a></p><p>由于分数计算复杂，比较难控制，于是内核提供了另一个文件用来调控分数，那就是文件/proc/<pid>/oom_adj，这个文件的默认值是0，但它可以配置为-17到15中间的任何一个值，内核在计算了进程的分数后，会和这个文件的值进行一个计算，得到的结果会作为进程的最终分数写入/proc/<pid>/oom_score。计算方式大概如下：</pid></pid></p><ul><li>如果/proc/<pid>/oom_adj的值为正数，那么分数将会被乘以2的n次方，这里n是文件里面的值</pid></li><li>如果/proc/<pid>/oom_adj的值为负数，那么分数将会被除以2的n次方，这里n是文件里面的值</pid></li></ul><p>由于进程的分数在内核中是一个16位的整数，所以-17就意味着最终进程的分数永远是0，也即永远不会被kill掉。</p><p>当然这种控制方式也不是非常精确，但至少比没有强多了。</p><h3 id="修改配置"><a class="header-anchor" href="#修改配置">¶</a>修改配置</h3><p>上面的这些文件都可以通过下面三种方式来修改，这里以panic_on_oom为例做个示范：</p><ul><li><p>直接写文件（重启后失效）</p><pre><code>dev@ubuntu:~$ sudo sh -c &quot;echo 2&gt; /proc/sys/vm/panic_on_oom&quot;</code></pre></li><li><p>通过控制命令（重启后失效）</p><pre><code>dev@dev:~$ sudo sysctl vm.panic_on_oom=2</code></pre></li><li><p>修改配置文件（重启后继续生效）</p><pre><code>#通过编辑器将vm.panic_on_oom=2添加到文件sysctl.conf中（如果已经存在，修改该配置项即可）dev@dev:~$ sudo vim /etc/sysctl.conf#重新加载sysctl.conf，使修改立即生效dev@dev:~$ sudo sysctl -p</code></pre></li></ul><h3 id="日志"><a class="header-anchor" href="#日志">¶</a>日志</h3><p>一旦OOM killer被触发，内核将会生成相应的日志，一般可以在/var/log/messages里面看到，如果配置了syslog，日志可能在/var/log/syslog里面，这里是ubuntu里的日志样例</p><pre><code>dev@dev:~$ grep oom /var/log/syslogJan 23 21:30:29 dev kernel: [  490.006836] eat_memory invoked oom-killer: gfp_mask=0x24280ca, order=0, oom_score_adj=0Jan 23 21:30:29 dev kernel: [  490.006871]  [&lt;ffffffff81191442&gt;] oom_kill_process+0x202/0x3c0</code></pre><h2 id="cgroup的OOM-killer"><a class="header-anchor" href="#cgroup的OOM-killer">¶</a>cgroup的OOM killer</h2><p>除了系统的OOM killer之外，如果配置了memory cgroup，那么进程还将受到自己所属memory cgroup的限制，如果超过了cgroup的限制，将会触发cgroup的OOM killer，cgroup的OOM killer和系统的OOM killer行为略有不同，详情请参考<a href="https://segmentfault.com/a/1190000008125359" target="_blank" rel="noopener">Linux Cgroup系列（04）：限制cgroup的内存使用</a>。</p><h2 id="malloc"><a class="header-anchor" href="#malloc">¶</a>malloc</h2><p>malloc是libc的函数，C/C++程序员对这个函数应该都很熟悉，它里面实际上调用的是内核的<a href="http://man7.org/linux/man-pages/man2/brk.2.html" target="_blank" rel="noopener">sbrk</a>和<a href="http://man7.org/linux/man-pages/man2/mmap.2.html" target="_blank" rel="noopener">mmap</a>，为了避免频繁的调用内核函数和优化性能，它里面在内核函数的基础上实现了一套自己的内存管理功能。</p><p>既然内存不够时有OOM killer帮我们kill进程，那么这时调用的malloc还会返回NULL给应用进程吗？答案是不会，因为这时只有两种情况：</p><ol><li>当前申请内存的进程被kill掉：都被kill掉了，返回什么都没有意义了</li><li>其它进程被kill掉：释放出了空闲的内存，于是内核就能给当前进程分配内存了</li></ol><p>那什么时候我们调用malloc的时候会返回NULL呢，从malloc函数的<a href="http://man7.org/linux/man-pages/man3/malloc.3.html" target="_blank" rel="noopener">帮助文件</a>可以看出，下面两种情况会返回NULL：</p><ul><li>使用的虚拟地址空间超过了RLIMIT_AS的限制</li><li>使用的数据空间超过了RLIMIT_DATA的限制，这里的数据空间包括程序的数据段，BSS段以及heap</li></ul><p>关于虚拟地址空间和heap之类的介绍请参考<a href="https://segmentfault.com/a/1190000008125059" target="_blank" rel="noopener">Linux进程的内存使用情况</a>，这两个参数的默认值为unlimited，所以只要不修改它们的默认配置，限制就不会被触发。有一种极端情况需要注意，那就是代码写的有问题，超过了系统的虚拟地址空间范围，比如32位系统的虚拟地址空间范围只有4G，这种情况下不确定系统会以一种什么样的方式返回错误。</p><h2 id="rlimit"><a class="header-anchor" href="#rlimit">¶</a>rlimit</h2><p>上面提到的RLIMIT_AS和RLIMIT_DATA都可以通过函数<a href="http://man7.org/linux/man-pages/man2/getrlimit.2.html" target="_blank" rel="noopener">getrlimit和setrlimit</a>来设置和读取，同时linux还提供了一个<a href="http://man7.org/linux/man-pages/man1/prlimit.1.html" target="_blank" rel="noopener">prlimit</a>程序来设置和读取rlimit的配置。</p><p>prlimit是用来替代<br><a href="http://man7.org/linux/man-pages/man3/ulimit.3.html" target="_blank" rel="noopener">ulimit</a>的一个程序，除了能设置上面的那两个参数之外，还有其它的一些参数，比如core文件的大小。关于prlimit的用法请参考它的<a href="http://man7.org/linux/man-pages/man1/prlimit.1.html" target="_blank" rel="noopener">帮助文件</a>。</p><pre><code>#默认情况下，RLIMIT_AS和RLIMIT_DATA的值都是unlimiteddev@dev:~$ prlimit |egrep &quot;DATA|AS&quot;AS         address space limit                unlimited unlimited bytesDATA       max data size                      unlimited unlimited bytes</code></pre><h2 id="测试代码"><a class="header-anchor" href="#测试代码">¶</a>测试代码</h2><p>C语言的程序会受到libc的影响，可能在触发OOM killer之前就触发了segmentfault错误，如果要用C语言程序来测试触发OOM killer，一定要注意malloc的行为受MMAP_THRESHOLD影响，一次申请分配太多内存的话，malloc会调用mmap映射内存，从而不一定触发OOM killer，具体细节目前还不太清楚。这里是一个触发oom killer的例子，供参考：</p><pre><code>#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#define M (1024 * 1024)#define K 1024int main(int argc, char *argv[]){    char *p;    int size =0;    while(1) {        p = (char *)malloc(K);        if  (p == NULL){            printf(&quot;memory allocate failed!\n&quot;);            return -1;        }        memset(p, 0, K);        size += K;        if (size%(100*M) == 0){            printf(&quot;%d00M memory allocated\n&quot;, size/(100*M));            sleep(1);        }    }    return 0;}</code></pre><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>对一个进程来说，内存的使用受多种因素的限制，可能在系统内存不足之前就达到了rlimit和memory cgroup的限制，同时它还可能受不同编程语言所使用的相关内存管理库的影响，就算系统处于内存不足状态，申请新内存也不一定会触发OOM killer，需要具体问题具体分析。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://www.kernel.org/doc/Documentation/sysctl/vm.txt" target="_blank" rel="noopener">sysctl/vm.txt</a></li><li><a href="http://www.oracle.com/technetwork/articles/servers-storage-dev/oom-killer-1911807.html" target="_blank" rel="noopener">How to Configure the Linux Out-of-Memory Killer</a></li><li><a href="http://www.linuxdevcenter.com/pub/a/linux/2006/11/30/linux-out-of-memory.html?page=2" target="_blank" rel="noopener">When Linux Runs Out of Memory</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux mount （第一部分）</title>
      <link href="/2020/02/16/linux/linux-mount-di-yi-bu-fen/"/>
      <url>/2020/02/16/linux/linux-mount-di-yi-bu-fen/</url>
      
        <content type="html"><![CDATA[<p>本篇将介绍一些比较实用的mount用法，包括挂载内核中的虚拟文件系统、loop device和bind mount。</p><blockquote><p>下面的所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="基本用法"><a class="header-anchor" href="#基本用法">¶</a>基本用法</h2><p>mount命令的标准格式如下</p><pre><code>mount -t type -o options device dir</code></pre><ul><li>device: 要挂载的设备（必填）。有些文件系统不需要指定具体的设备，这里可以随便填一个字符串</li><li>dir: 挂载到哪个目录（必填）</li><li>type： 文件系统类型（可选）。大部分情况下都不用指定该参数，系统都会自动检测到设备上的文件系统类型</li><li>options： 挂载参数（可选）。<br>options一般分为两类，一类是Linux VFS所提供的通用参数，就是每个文件系统都可以使用这类参数，详情请参考“<a href="http://man7.org/linux/man-pages/man8/mount.8.html" target="_blank" rel="noopener">FILESYSTEM-INDEPENDENT MOUNT OPTIONS</a>”。另一类是每个文件系统自己支持的特有参数，这个需要参考每个文件系统的文档，如btrfs支持的参数可以在<a href="https://btrfs.wiki.kernel.org/index.php/Mount_options" target="_blank" rel="noopener">这里</a>找到。</li></ul><p>网上关于如何利用mount命令挂载设备的例子很多，这里就不再啰嗦了。</p><h2 id="挂载虚拟文件系统"><a class="header-anchor" href="#挂载虚拟文件系统">¶</a>挂载虚拟文件系统</h2><p>proc、tmpfs、sysfs、devpts等都是Linux内核映射到用户空间的虚拟文件系统，他们不和具体的物理设备关联，但他们具有普通文件系统的特征，应用层程序可以像访问普通文件系统一样来访问他们。</p><p>这里只是示例一下怎么挂载他们，不会对他们具体的功能做详细介绍。</p><pre><code>#将内核的proc文件系统挂载到/mnt，#这样就可以在/mnt目录下看到系统当前运行的所有进程的信息，#由于proc是内核虚拟的一个文件系统，并没有对应的设备，#所以这里-t参数必须要指定，不然mount就不知道要挂载啥了。#由于没有对应的源设备，这里none可以是任意字符串，#取个有意义的名字就可以了，因为用mount命令查看挂载点信息时第一列显示的就是这个字符串。dev@ubuntu:~$ sudo mount -t proc none /mnt#在内存中创建一个64M的tmpfs文件系统，并挂载到/mnt下，#这样所有写到/mnt目录下的文件都存储在内存中，速度非常快，#不过要注意，由于数据存储在内存中，所以断电后数据会丢失掉dev@ubuntu:~$ sudo mount -t tmpfs -o size=64m tmpfs /mnt</code></pre><h2 id="挂载-loop-device"><a class="header-anchor" href="#挂载-loop-device">¶</a>挂载 <a href="https://en.wikipedia.org/wiki/Loop_device" target="_blank" rel="noopener">loop device</a></h2><p>在Linux中，硬盘、光盘、软盘等都是常见的块设备，他们在Linux下的目录一般是/dev/hda1, /dev/cdrom, /dev/sda1，/dev/fd0这样的。而loop device是虚拟的块设备，主要目的是让用户可以像访问上述块设备那样访问一个文件。 loop device设备的路径一般是/dev/loop0, dev/loop1, …等，具体的个数跟内核的配置有关，Ubuntu16.04下面默认是8个，如果8个都被占用了，那么就需要修改内核参数来增加loop device的个数。</p><h3 id="ISO文件"><a class="header-anchor" href="#ISO文件">¶</a>ISO文件</h3><p>需要用到loop device的最常见的场景是mount一个ISO文件，示例如下</p><pre><code>#利用mkisofs构建一个用于测试的iso文件dev@ubuntu:~$ mkdir -p iso/subdir01dev@ubuntu:~$ mkisofs -o ./test.iso ./iso#mount ISO 到目录 /mntdev@ubuntu:~$ sudo mount ./test.iso /mntmount: /dev/loop0 is write-protected, mounting read-only#mount成功，能看到里面的文件夹dev@ubuntu:~$ ls /mntsubdir01#通过losetup命令可以看到占用了loop0设备dev@ubuntu:~$ losetup -a/dev/loop0: []: (/home/dev/test.iso)</code></pre><h3 id="虚拟硬盘"><a class="header-anchor" href="#虚拟硬盘">¶</a>虚拟硬盘</h3><p>loop device另一种常用的用法是虚拟一个硬盘，比如我想尝试下btrfs这个文件系统，但系统中目前的所有分区都已经用了，里面都是有用的数据，不想格式化他们，这时虚拟硬盘就有用武之地了，示例如下</p><pre><code>#因为btrfs对分区的大小有最小要求，所以利用dd命令创建一个128M的文件dev@ubuntu:~$ dd if=/dev/zero bs=1M count=128 of=./vdisk.img#在这个文件里面创建btrfs文件系统#有些同学可能会想，硬盘一般不都是先分区再创建文件系统的吗？#是的，分区是为了方便磁盘的管理，#但对于文件系统来说，他一点都不关心分区的概念，你给他多大的空间，他就用多大的空间，#当然这里也可以先用fdisk在vdisk.img中创建分区，然后再在分区上创建文件系统，#只是这里的虚拟硬盘不需要用作其他的用途，为了方便，我就把整个硬盘全部给btrfs文件系统，dev@ubuntu:~$ mkfs.btrfs ./vdisk.img#这里会输出一些信息，提示创建成功#mount虚拟硬盘dev@ubuntu:~$ sudo mount ./vdisk.img /mnt/#在虚拟硬盘中创建文件成功dev@ubuntu:~$ sudo touch /mnt/aaaaaadev@ubuntu:~$ ls /mnt/aaaaaa#加上刚才上面mount的iso文件，我们已经用了两个loop device了dev@ubuntu:~$ losetup -a/dev/loop0: []: (/home/dev/test.iso)/dev/loop1: []: (/home/dev/vdisk.img)</code></pre><h2 id="挂载多个设备到一个文件夹"><a class="header-anchor" href="#挂载多个设备到一个文件夹">¶</a>挂载多个设备到一个文件夹</h2><p>细心的朋友可能已经发现了，在上面的例子中，将test.iso和vdisk.img都mount到了/mnt目录下，这个在Linux下是支持的，默认会用后面的mount覆盖掉前面的mount，只有当umount后面的device后，原来的device才看的到。 看下面的例子</p><pre><code>#先umount上面的iso和vdisk.imgdev@ubuntu:~$ sudo umount ./test.isodev@ubuntu:~$ sudo umount ./vdisk.img#在/mnt目录下先创建一个空的test文件夹dev@ubuntu:~$ sudo mkdir /mnt/testdev@ubuntu:~$ ls /mnt/test#mount iso文件dev@ubuntu:~$ sudo mount ./test.iso /mnt#再看/mnt里面的内容，已经被iso里面的内容给覆盖掉了dev@ubuntu:~$ ls /mnt/subdir01#再mount vdisk.imgdev@ubuntu:~$ sudo mount ./vdisk.img /mnt/#再看/mnt里面的内容，已经被vdisk.img里面的内容给覆盖掉了dev@ubuntu:~$ ls /mnt/aaaaaa#通过mount命令可以看出，test.iso和vdisk.img都mount在了/mnt#但我们在/mnt下只能看到最后一个mount的设备里的东西dev@ubuntu:~$ mount|grep /mnt/home/dev/test.iso on /mnt type iso9660 (ro,relatime)/home/dev/vdisk.img on /mnt type btrfs (rw,relatime,space_cache,subvolid=5,subvol=/)#umount /mnt，这里也可以用命令sudo umount ./vdisk.img，一样的效果dev@ubuntu:~$ sudo umount /mnt#test.iso文件里面的东西再次出现了dev@ubuntu:~$ ls /mnt/subdir01#再次umount /mnt，这里也可以用命令sudo umount ./test.iso，一样的效果dev@ubuntu:~$ sudo umount /mnt#最开始/mnt目录里面的文件可以看到了dev@ubuntu:~$ ls /mnt/test</code></pre><p>有了这个功能，平时挂载设备的时候就不用专门去创建空目录了，随便找个暂时不用的目录挂上去就可以了。</p><h2 id="挂载一个设备到多个目录"><a class="header-anchor" href="#挂载一个设备到多个目录">¶</a>挂载一个设备到多个目录</h2><p>当然我们也可以把一个设备mount到多个文件夹，这样在多个文件夹中都可以访问该设备中的内容。</p><pre><code>#新建两目录用于挂载点dev@ubuntu:~$ sudo mkdir /mnt/disk1 /mnt/disk2#将vdisk.img依次挂载到disk1和disk2dev@ubuntu:~$ sudo mount ./vdisk.img /mnt/disk1dev@ubuntu:~$ sudo mount ./vdisk.img /mnt/disk2#这样在disk1下和disk2下面都能看到相同的内容dev@ubuntu:~$ tree /mnt/mnt├── disk1│   └── aaaaaa└── disk2    └── aaaaaa#在disk1下创建一个新文件dev@ubuntu:~$ sudo touch /mnt/disk1/bbbbbb#这个文件在disk2下面也能看到dev@ubuntu:~$ tree /mnt/mnt├── disk1│   ├── aaaaaa│   └── bbbbbb└── disk2    ├── aaaaaa    └── bbbbbb</code></pre><h2 id="bind-mount"><a class="header-anchor" href="#bind-mount">¶</a>bind mount</h2><p>bind mount功能非常强大，可以将任何一个挂载点、普通目录或者文件挂载到其他地方，是玩转Linux的必备技能</p><h3 id="基本功能"><a class="header-anchor" href="#基本功能">¶</a>基本功能</h3><p>bind mount会将源目录绑定到目的目录，然后在目的目录下就可以看到源目录里的文件</p><pre><code>#准备要用到的目录dev@ubuntu:~$ mkdir -p bind/bind1/sub1dev@ubuntu:~$ mkdir -p bind/bind2/sub2dev@ubuntu:~$ tree bindbind├── bind1│   └── sub1└── bind2    └── sub2#bind mount后，bind2里面显示的就是bind1目录的内容dev@ubuntu:~$ sudo mount --bind ./bind/bind1/ ./bind/bind2dev@ubuntu:~$ tree bindbind├── bind1│   └── sub1└── bind2    └── sub1</code></pre><h3 id="readonly-bind"><a class="header-anchor" href="#readonly-bind">¶</a>readonly bind</h3><p>我们可以在bind的时候指定readonly，这样原来的目录还是能读写，但目的目录为只读</p><pre><code>#通过readonly的方式bind mountdev@ubuntu:~$ sudo mount -o bind,ro ./bind/bind1/ ./bind/bind2dev@ubuntu:~$ tree bindbind├── bind1│   └── sub1└── bind2    └── sub1#bind2目录为只读，没法touch里面的文件dev@ubuntu:~$ touch ./bind/bind2/sub1/aaatouch: cannot touch './bind/bind2/sub1/aaa': Read-only file system#bind1还是能读写dev@ubuntu:~$ touch ./bind/bind1/sub1/aaa#我们可以在bind1和bind2目录下看到刚创建的文件dev@ubuntu:~$ tree bindbind├── bind1│   └── sub1│       └── aaa└── bind2    └── sub1        └── aaa</code></pre><p>如果我们想让当前目录readonly，那么可以bind自己，并且指定readonly参数：</p><pre><code>#bind mount并且指定readonlydev@ubuntu:~$ sudo mount -o bind,ro ./bind/bind1/ ./bind/bind1#创建新文件失败dev@ubuntu:~$ touch ./bind/bind1/sub1/aaatouch: cannot touch './bind/bind1/sub1/aaa': Read-only file system#umount之后，文件夹恢复到原来的读写权限dev@ubuntu:~$ sudo umount ./bind/bind1/##touch文件成功dev@ubuntu:~$ touch ./bind/bind1/sub1/aaadev@ubuntu:~$</code></pre><h3 id="bind-mount单个文件"><a class="header-anchor" href="#bind-mount单个文件">¶</a>bind mount单个文件</h3><p>我们也可以bind mount单个文件，这个功能尤其适合需要在不同版本配置文件之间切换的时候</p><pre><code>#创建两个用于测试的文件dev@ubuntu:~$ echo aaaaaa &gt; bind/aadev@ubuntu:~$ echo bbbbbb &gt; bind/bbdev@ubuntu:~$ cat bind/aaaaaaaadev@ubuntu:~$ cat bind/bbbbbbbb#bind mount后，bb里面看到的是aa的内容dev@ubuntu:~$ sudo mount --bind ./bind/aa bind/bbdev@ubuntu:~$ cat bind/bbaaaaaa#即使我们删除aa文件，我们还是能够通过bb看到aa里面的内容dev@ubuntu:~$ rm bind/aadev@ubuntu:~$ cat bind/bbaaaaaa#umount bb文件后，bb的内容出现了，不过aa的内容再也找不到了dev@ubuntu:~$ sudo umount bind/bbdev@ubuntu:~$ cat bind/bbbbbbbb</code></pre><h3 id="move一个挂载点到另一个地方"><a class="header-anchor" href="#move一个挂载点到另一个地方">¶</a>move一个挂载点到另一个地方</h3><p>move操作可以将一个挂载点移动到别的地方，这里以bind mount为例来演示，当然其他类型的挂载点也可以通过move操作来移动。</p><pre><code>#umount上面操作所产生的挂载点dev@ubuntu:~$ sudo umount /home/dev/bind/bind1dev@ubuntu:~$ sudo umount /home/dev/bind/bind2#bind mountdev@ubuntu:~$ sudo mount --bind ./bind/bind1/ ./bind/bind2/dev@ubuntu:~$ ls ./bind/bind*./bind/bind1:sub1./bind/bind2:sub1#move操作要求mount point的父mount point不能为shared。#在这里./bind/bind2/的父mount point为'/'，所以需要将'/'变成private后才能做move操作#关于shared、private的含义将会在下一篇介绍dev@ubuntu:~$ findmnt -o TARGET,PROPAGATION /TARGET PROPAGATION/      shareddev@ubuntu:~$ sudo mount --make-private /dev@ubuntu:~$ findmnt -o TARGET,PROPAGATION /TARGET PROPAGATION/      private#move成功，在mnt下能看到bind1里面的内容dev@ubuntu:~$ sudo mount --move ./bind/bind2/ /mntdev@ubuntu:~$ ls /mnt/sub1#由于bind2上的挂载点已经被移动到了/mnt上，于是能看到bind2目录下原来的文件了dev@ubuntu:~$ ls ./bind/bind2/sub2</code></pre><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>在这篇文章中演示了一些比较实用的mount操作，尤其是bind mount，至于在哪些情况下要用哪些功能，需要我们自己去挖掘。下一篇中将介绍mount相关的“Shared subtrees”</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="http://man7.org/linux/man-pages/man8/mount.8.html" target="_blank" rel="noopener">mount a filesystem</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux TTYPTS概述</title>
      <link href="/2020/02/16/linux/linux-ttypts-gai-shu/"/>
      <url>/2020/02/16/linux/linux-ttypts-gai-shu/</url>
      
        <content type="html"><![CDATA[<p>当我们在键盘上敲下一个字母的时候，到底是怎么发送到相应的进程的呢？我们通过ps、who等命令看到的类似tty1、pts/0这样的输出，它们的作用和区别是什么呢？</p><h2 id="TTY历史"><a class="header-anchor" href="#TTY历史">¶</a>TTY历史</h2><h3 id="支持多任务的计算机出现之前"><a class="header-anchor" href="#支持多任务的计算机出现之前">¶</a>支持多任务的计算机出现之前</h3><p>在计算机出来以前，人们就已经在使用一种叫teletype的设备，用来相互之间传递信息，看起来像下面这样：</p><pre><code>+----------+     Physical Line     +----------+| teletype |&lt;---------------------&gt;| teletype |+----------+                       +----------+</code></pre><p>两个teletype之间用线连接起来，线两端可能也有类似于调制解调器之类的设备（这里将它们忽略），在一端的teletype上敲键盘时，相应的数据会发送到另一端的teletype，具体功能是干什么的，我也不太了解。(我脑袋里面想到画面是在一端敲字，另一端打印出来)</p><blockquote><p>这些都是老古董了，完全没接触过，所以只能简单的推测。</p></blockquote><h3 id="支持多任务的计算机出现之后"><a class="header-anchor" href="#支持多任务的计算机出现之后">¶</a>支持多任务的计算机出现之后</h3><p>等到计算机支持多任务后，人们想到把这些teletype连到计算机上，作为计算机的终端，从而可以操作计算机。</p><p>使用teletype的主要原因有两个（个人见解）：</p><ul><li>现实中已经存在了大量不同厂商的teletype，可以充分利用现有资源</li><li>teletype的相关网络已经比较成熟，连起来方便</li></ul><p>于是连接就发展成这样：</p><pre><code>                                                                      +----------+ +----------+   +-------+     Physical Line     +-------+   +------+   |          || Terminal |&lt;-&gt;| Modem |&lt;---------------------&gt;| Modem |&lt;-&gt;| UART |&lt;-&gt;| Computer |+----------+   +-------+                       +-------+   +------+   |          |                                                                      +----------+</code></pre><ul><li>左边的Terminal就是各种各样的teletype</li><li>物理线路两边用上了Modem，就是我们常说的“猫”，那是因为后来网络已经慢慢的变发达了，大家可以共享连接了。（大概推测，可能不对）</li><li>UART可以理解为将teletype的信号转换成计算机能识别的信号的设备</li></ul><h3 id="内核TTY子系统"><a class="header-anchor" href="#内核TTY子系统">¶</a>内核TTY子系统</h3><p>计算机为了支持这些teletype，于是设计了名字叫做TTY的子系统，内部结构如下：</p><pre><code>    +-----------------------------------------------+    |                    Kernel                     |    |                                 +--------+    |    |   +--------+   +------------+   |        |    |       +----------------+    |   |  UART  |   |    Line    |   |  TTY   |&lt;----------&gt;| User process A |&lt;------&gt;|        |&lt;-&gt;|            |&lt;-&gt;|        |    |       +----------------+    |   | driver |   | discipline |   | driver |&lt;----------&gt;| User process B |    |   +--------+   +------------+   |        |    |       +----------------+    |                                 +--------+    |    |                                               |    +-----------------------------------------------+</code></pre><ul><li>UART driver对接外面的UART设备</li><li>Line discipline主要是对输入和输出做一些处理，可以理解它是TTY driver的一部分</li><li>TTY driver用来处理各种终端设备</li><li>用户空间的进程通过TTY driver来和终端打交道</li></ul><blockquote><p>为了简单起见，后面的介绍中不再单独列出UART driver和Line discipline，可以认为它们是TTY driver的一部分</p></blockquote><h3 id="TTY设备"><a class="header-anchor" href="#TTY设备">¶</a>TTY设备</h3><p>对于每一个终端，TTY driver都会创建一个TTY设备与它对应，如果有多个终端连接过来，那么看起来就是这个样子的：</p><pre><code>                      +----------------+                      |   TTY Driver   |                      |                |                      |   +-------+    |       +----------------+ +------------+       |   |       |&lt;----------&gt;| User process A | | Terminal A |&lt;---------&gt;| ttyS0 |    |       +----------------+ +------------+       |   |       |&lt;----------&gt;| User process B |                      |   +-------+    |       +----------------+                      |                |                      |   +-------+    |       +----------------+ +------------+       |   |       |&lt;----------&gt;| User process C | | Terminal B |&lt;---------&gt;| ttyS1 |    |       +----------------+ +------------+       |   |       |&lt;----------&gt;| User process D |                      |   +-------+    |       +----------------+                      |                |                      +----------------+</code></pre><p>当驱动收到一个终端的连接时，就会根据终端的型号和参数创建相应的tty设备（上图中设备名称叫ttyS0是因为大部分终端的连接都是串行连接），由于每个终端可能都不一样，有自己的特殊命令和使用习惯，于是每个tty设备的配置可能都不一样。比如按delete键的时候，有些可能是要删前面的字符，而有些可能是删后面的，如果没配置对，就会导致某些按键不是自己想要的行为，这也是我们在使用模拟终端时，如果默认的配置跟我们的习惯不符，需要做一些个性化配置的原因。</p><p>后来随着计算机的不断发展，teletype这些设备逐渐消失，我们不再需要专门的终端设备了，每个机器都有自己的键盘和显示器，每台机器都可以是其它机器的终端，远程的操作通过ssh来实现，但是内核TTY驱动这一架构没有发生变化，我们想要和系统中的进程进行I/O交互，还是需要通过TTY设备，于是出现了各种终端模拟软件，并且模拟的也是常见的几种终端，如VT100、VT220、XTerm等。</p><blockquote><ol><li>可以通过命令<code>toe -a</code>列出系统支持的所有终端类型</li><li>可以通过命令infocmp来比较两个终端的区别，比如<code>infocmp vt100 vt220</code>将会输出vt100和vt220的区别。</li></ol></blockquote><h2 id="程序如何和TTY打交道"><a class="header-anchor" href="#程序如何和TTY打交道">¶</a>程序如何和TTY打交道</h2><p>在讨论TTY设备是如何被创建及配置之前，我们先来看看TTY是如何被进程使用的：</p><pre><code>#先用tty命令看看当前bash关联到了哪个ttydev@debian:~$ tty/dev/pts/1#看tty都被哪些进程打开了dev@debian:~$ lsof /dev/pts/1COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAMEbash     907  dev    0u   CHR  136,1      0t0    4 /dev/pts/1bash     907  dev    1u   CHR  136,1      0t0    4 /dev/pts/1bash     907  dev    2u   CHR  136,1      0t0    4 /dev/pts/1bash     907  dev  255u   CHR  136,1      0t0    4 /dev/pts/1lsof    1118  dev    0u   CHR  136,1      0t0    4 /dev/pts/1lsof    1118  dev    1u   CHR  136,1      0t0    4 /dev/pts/1lsof    1118  dev    2u   CHR  136,1      0t0    4 /dev/pts/1#往tty里面直接写数据跟写标准输出是一样的效果dev@dev:~$ echo aaa &gt; /dev/pts/2aaa</code></pre><blockquote><p>pts也是tty设备，它们的关系后面会介绍到</p></blockquote><p>通过上面的lsof可以看出，当前运行的bash和lsof进程的stdin(0u)、stdout(1u)、stderr(2u)都绑定到了这个TTY上。</p><p>下面是tty和进程以及I/O设备交互的结构图：</p><pre><code>   Input    +--------------------------+    R/W     +------+-----------&gt;|                          |&lt;----------&gt;| bash |            |          pts/1           |            +------+&lt;-----------|                          |&lt;----------&gt;| lsof |   Output   | Foreground process group |    R/W     +------+            +--------------------------+                               </code></pre><ul><li>可以把tty理解成一个管道（pipe），在一端写的内容可以从另一端读取出来，反之亦然。</li><li>这里input和output可以简单的理解为键盘和显示器，后面会介绍在各种情况下input/ouput都连接的什么东西。</li><li>tty里面有一个很重要的属性，叫Foreground process group，记录了当前前端的进程组是哪一个。process group的概念会在下一篇文章中介绍，这里可以简单的认为process group里面只有一个进程。</li><li>当pts/1收到input的输入后，会检查当前前端进程组是哪一个，然后将输入放到进程组的leader的输入缓存中，这样相应的leader进程就可以通过read函数得到用户的输入</li><li>当前端进程组里面的进程往tty设备上写数据时，tty就会将数据输出到output设备上</li><li>当在shell中执行不同的命令时，前端进程组在不断的变化，而这种变化会由shell负责更新到tty设备中</li></ul><p>从上面可以看出，进程和tty打交道很简单，只要保证后台进程不要读写tty就可以了，即写后台程序时，要将stdin/stdout/stderr重定向到其它地方（当然deamon程序还需要做很多其它处理）。</p><p>先抛出两个问题(后面有答案)：</p><ul><li>当非前端进程组里面的进程（后台进程）往tty设备上写数据时，会发生什么？会输出到outpu上吗？</li><li>当非前端进程组里面的进程（后台进程）从tty设备上读数据时，会发生什么？进程会阻塞吗？</li></ul><h2 id="TTY是如何被创建的"><a class="header-anchor" href="#TTY是如何被创建的">¶</a>TTY是如何被创建的</h2><p>下面介绍几种常见的情况下tty设备是如何创建的，以及input和output设备都是啥。</p><h3 id="键盘显示器直连（终端）"><a class="header-anchor" href="#键盘显示器直连（终端）">¶</a>键盘显示器直连（终端）</h3><p>先看图再说话：</p><pre><code>                   +-----------------------------------------+                   |          Kernel                         |                   |                           +--------+    |       +----------------+  +----------+      |   +-------------------+   |  tty1  |&lt;----------&gt;| User processes | | Keyboard |---------&gt;|                   |   +--------+    |       +----------------+ +----------+      |   | Terminal Emulator |&lt;-&gt;|  tty2  |&lt;----------&gt;| User processes | | Monitor  |&lt;---------|                   |   +--------+    |       +----------------+ +----------+      |   +-------------------+   |  tty3  |&lt;----------&gt;| User processes |                   |                           +--------+    |       +----------------+                   |                                         |                   +-----------------------------------------+</code></pre><p>键盘、显示器都和内核中的终端模拟器相连，由模拟器决定创建多少tty，比如你在键盘上输入ctrl+alt+F1时，模拟器首先捕获到该输入，然后激活tty1，这样键盘的输入会转发到tty1，而tty1的输出会转发到显示器，同理用输入ctrl+alt+F2，就会切换到tty2。</p><p>当模拟器激活tty时如果发现没有进程与之关联，意味着这是第一次打开该tty，于是会启动配置好的进程并和该tty绑定，一般该进程就是负责login的进程。</p><p>当切换到tty2后，tty1里面的输出会输出到哪里呢？tty1的输出还是会输出给模拟器，模拟器里会有每个tty的缓存，不过由于模拟器的缓存空间有限，所以下次切回tty1的时候，只能看到最新的输出，以前的输出已经不在了。</p><blockquote><p>不确定这里的终端模拟器对应内核中具体的哪个模块，但肯定有这么个东西存在</p></blockquote><h3 id="SSH远程访问"><a class="header-anchor" href="#SSH远程访问">¶</a>SSH远程访问</h3><pre><code> +----------+       +------------+ | Keyboard |------&gt;|            | +----------+       |  Terminal  | | Monitor  |&lt;------|            | +----------+       +------------+                          |                          |  ssh protocol                          |                          ↓                    +------------+                    |            |                    | ssh server |--------------------------+                    |            |           fork           |                    +------------+                          |                        |   ↑                               |                        |   |                               |                  write |   | read                          |                        |   |                               |                  +-----|---|-------------------+           |                  |     |   |                   |           ↓                  |     ↓   |      +-------+    |       +-------+                  |   +--------+   | pts/0 |&lt;----------&gt;| shell |                  |   |        |   +-------+    |       +-------+                  |   |  ptmx  |&lt;-&gt;| pts/1 |&lt;----------&gt;| shell |                  |   |        |   +-------+    |       +-------+                  |   +--------+   | pts/2 |&lt;----------&gt;| shell |                  |                +-------+    |       +-------+                  |    Kernel                   |                  +-----------------------------+</code></pre><p>这里的Terminal可能是任何地方的程序，比如windows上的putty，所以不讨论客户端的Terminal程序是怎么和键盘、显示器交互的。由于Terminal要和ssh服务器打交道，所以肯定要实现ssh的客户端功能。</p><p>这里将建立连接和收发数据分两条线路解释，为了描述简洁，这里以sshd代替ssh服务器程序：</p><h4 id="建立连接"><a class="header-anchor" href="#建立连接">¶</a>建立连接</h4><ul><li>1.Terminal请求和sshd建立连接</li><li>2.如果验证通过，sshd将创建一个新的session</li><li>3.调用API（posix_openpt()）请求ptmx创建一个pts，创建成功后，sshd将得到和ptmx关联的fd，并将该fd和session关联起来。</li></ul><pre><code>#pty（pseudo terminal device）由两部分构成，ptmx是master端，pts是slave端，#进程可以通过调用API请求ptmx创建一个pts，然后将会得到连接到ptmx的读写fd和一个新创建的pts，#ptmx在内部会维护该fd和pts的对应关系，随后往这个fd的读写会被ptmx转发到对应的pts。#这里可以看到sshd已经打开了/dev/ptmxdev@debian:~$ sudo lsof /dev/ptmxCOMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAMEsshd    1191  dev    8u   CHR    5,2      0t0 6531 /dev/ptmxsshd    1191  dev   10u   CHR    5,2      0t0 6531 /dev/ptmxsshd    1191  dev   11u   CHR    5,2      0t0 6531 /dev/ptmx</code></pre><ul><li>4.同时sshd创建shell进程，将新创建的pts和shell绑定</li></ul><h4 id="收发消息"><a class="header-anchor" href="#收发消息">¶</a>收发消息</h4><ul><li>1.Terminal收到键盘的输入，Terminal通过ssh协议将数据发往sshd</li><li>2.sshd收到客户端的数据后，根据它自己管理的session，找到该客户端对应的关联到ptmx上的fd</li><li>3.往找到的fd上写入客户端发过来的数据</li><li>4.ptmx收到数据后，根据fd找到对应的pts（该对应关系由ptmx自动维护），将数据包转发给对应的pts</li><li>5.pts收到数据包后，检查绑定到自己上面的当前前端进程组，将数据包发给该进程组的leader</li><li>6.由于pts上只有shell，所以shell的read函数就收到了该数据包</li><li>7.shell对收到的数据包进行处理，然后输出处理结果（也可能没有输出）</li><li>8.shell通过write函数将结果写入pts</li><li>9.pts将结果转发给ptmx</li><li>10.ptmx根据pts找到对应的fd，往该fd写入结果</li><li>11.sshd收到该fd的结果后，找到对应的session，然后将结果发给对应的客户端</li></ul><h3 id="键盘显示器直连（图形界面）"><a class="header-anchor" href="#键盘显示器直连（图形界面）">¶</a>键盘显示器直连（图形界面）</h3><pre><code> +----------+       +------------+ | Keyboard |------&gt;|            | +----------+       |  Terminal  |--------------------------+ | Monitor  |&lt;------|            |           fork           | +----------+       +------------+                          |                        |   ↑                               |                        |   |                               |                  write |   | read                          |                        |   |                               |                  +-----|---|-------------------+           |                  |     |   |                   |           ↓                  |     ↓   |      +-------+    |       +-------+                  |   +--------+   | pts/0 |&lt;----------&gt;| shell |                  |   |        |   +-------+    |       +-------+                  |   |  ptmx  |&lt;-&gt;| pts/1 |&lt;----------&gt;| shell |                  |   |        |   +-------+    |       +-------+                  |   +--------+   | pts/2 |&lt;----------&gt;| shell |                  |                +-------+    |       +-------+                  |    Kernel                   |                  +-----------------------------+</code></pre><blockquote><p>为了简化起见，本篇不讨论Linux下图形界面里Terminal程序是怎么和键盘、显示器交互的。</p></blockquote><p>这里和上面的不同点就是，这里的Terminal不需要实现ssh客户端，但需要把ssh服务器要干的活也干了（当然ssh通信相关的除外）。</p><h3 id="SSH-Screen-Tmux"><a class="header-anchor" href="#SSH-Screen-Tmux">¶</a>SSH + Screen/Tmux</h3><p>常用Linux的同学应该对screen和tmux不陌生，通过它们启动的进程，就算网络断开了，也不会受到影响继续执行，下次连上去时还能看到进程的所有输出，还能继续接着干活。</p><p>这里以tmux为例介绍其原理：</p><pre><code> +----------+       +------------+ | Keyboard |------&gt;|            | +----------+       |  Terminal  | | Monitor  |&lt;------|            | +----------+       +------------+                          |                          |  ssh protocol                          |                          ↓                    +------------+                    |            |                    | ssh server |--------------------------+                    |            |           fork           |                    +------------+                          |                        |   ↑                               |                        |   |                               |                  write |   | read                          |                        |   |                               |                  +-----|---|-------------------+           |                  |     ↓   |                   |           ↓                  |   +--------+   +-------+    |       +-------+  fork   +-------------+                  |   |  ptmx  |&lt;-&gt;| pts/0 |&lt;----------&gt;| shell |--------&gt;| tmux client |                  |   +--------+   +-------+    |       +-------+         +-------------+                  |   |        |                |                               ↑                  |   +--------+   +-------+    |       +-------+               |                  |   |  ptmx  |&lt;-&gt;| pts/2 |&lt;----------&gt;| shell |               |                  |   +--------+   +-------+    |       +-------+               |                  |     ↑   |  Kernel           |           ↑                   |                  +-----|---|-------------------+           |                   |                        |   |                               |                   |                        |w/r|   +---------------------------+                   |                        |   |   |            fork                               |                        |   ↓   |                                               |                    +-------------+                                             |                    |             |                                             |                    | tmux server |&lt;--------------------------------------------+                    |             |                    +-------------+</code></pre><blockquote><p>系统中的ptmx只有一个，上图中画出来了两个，目的是为了表明tmux服务器和sshd都用ptmx，但它们之间又互不干涉。</p></blockquote><p>这种情况要稍微复杂一点，不过原理都是一样的，前半部分和普通ssh的方式是一样的，只是pts/0关联的前端进程不是shell了，而是变成了tmux客户端，所以ssh客户端发过来的数据包都会被tmux客户端收到，然后由tmux客户端转发给tmux服务器，而tmux服务器干的活和ssh的类似，也是维护一堆的session，为每个session创建一个pts，然后将tmux客户端发过来的数据转发给相应的pts。</p><p>由于tmux服务器只和tmux客户端打交道，和sshd没有关系，当终端和sshd的连接断开时，虽然pts/0会被关闭，和它相关的shell和tmux客户端也将被kill掉，但不会影响tmux服务器，当下次再用tmux客户端连上tmux服务器时，看到的还是上次的内容。</p><h2 id="TTY和PTS的区别"><a class="header-anchor" href="#TTY和PTS的区别">¶</a>TTY和PTS的区别</h2><p>从上面的流程中应该可以看出来了，对用户空间的程序来说，他们没有区别，都是一样的；从内核里面来看，pts的另一端连接的是ptmx，而tty的另一端连接的是内核的终端模拟器，ptmx和终端模拟器都只是负责维护会话和转发数据包；再看看ptmx和内核终端模拟器的另一端，ptmx的另一端连接的是用户空间的应用程序，如sshd、tmux等，而内核终端模拟器的另一端连接的是具体的硬件，如键盘和显示器。</p><h2 id="常见的TTY配置"><a class="header-anchor" href="#常见的TTY配置">¶</a>常见的TTY配置</h2><p>先先来看看当前tty的所有配置：</p><pre><code>dev@dev:~$ stty -aspeed 38400 baud; rows 51; columns 204; line = 0;intr = ^C; quit = ^\; erase = ^?; kill = ^U; eof = ^D; eol = M-^?; eol2 = M-^?; swtch = &lt;undef&gt;; start = ^Q; stop = ^S; susp = ^Z; rprnt = ^R; werase = ^W; lnext = ^V; discard = ^O; min = 1; time = 0;-parenb -parodd -cmspar cs8 -hupcl -cstopb cread -clocal -crtscts-ignbrk -brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr icrnl ixon -ixoff -iuclc ixany imaxbel -iutf8opost -olcuc -ocrnl onlcr -onocr -onlret -ofill -ofdel nl0 cr0 tab0 bs0 vt0 ff0isig icanon iexten echo echoe echok -echonl -noflsh -xcase -tostop -echoprt echoctl echoke -flusho -extproc</code></pre><blockquote><p>stty还可以用来修改tty的参数，用法请参考<code>man stty</code></p></blockquote><p>只要是有权限的程序，都可以通过Linux提供的API来修改TTY的配置，下面介绍一些常见的的配置项。</p><h4 id="rows-51-columns-204"><a class="header-anchor" href="#rows-51-columns-204">¶</a>rows 51; columns 204;</h4><p>这个配置一般由终端控制，当终端的窗口大小发生变化时，需要通过一定的手段修改该配置，比如ssh协议里面就有修改窗口大小的参数，sshd收到客户端的请求后，会通过API修改tty的这个参数，然后由tty通过信号SIGWINCH通知前端程序（比如shell或者vim），前端程序收到信号后，再去读tty的这个参数，然后就知道如何调整自己的输出排版了。</p><h4 id="intr-C"><a class="header-anchor" href="#intr-C">¶</a>intr = ^C</h4><p>tty除了在终端和前端进程之间转发数据之外，还支持很多控制命令，比如终端输入了CTRL+C，那么tty不会将该输入串转发给前端进程，而是将它转换成信号SIGINT发送给前端进程。这个就是用来配置控制命令对应的输入组合的，比如我们可以配置“intr = ^E”表示用CTRL+E代替CTRL+C。</p><h4 id="start-Q-stop-S"><a class="header-anchor" href="#start-Q-stop-S">¶</a>start = ^Q; stop = ^S;</h4><p>这是两个特殊的控制命令，估计经常有人会碰到，在键盘上不小心输入CTRL+S后，终端没反应了，即没输出，也不响应任何输入。这是因为这个命令会告诉TTY暂停，阻塞所有读写操作，即不转发任何数据，只有按了CTRL+Q后，才会继续。这个功能应该是历史遗留，以前终端和服务器之间没有流量控制功能，所以有可能服务器发送数据过快，导致终端处理不过来，于是需要这样一个命令告诉服务器不要再发了，等终端处理完了后在通知服务器继续。</p><p>该命令现在比较常用的一个场景就是用<code>tail -f</code>命令监控日志文件的内容时，可以随时按CTRL+S让屏幕停止刷新，看完后再按CTRL+Q让它继续刷，如果不这样的话，需要先CTRL+C退出，看完后在重新运行<code>tail -f</code>命令。</p><h4 id="echo"><a class="header-anchor" href="#echo">¶</a>echo</h4><p>在终端输入字符的时候，之所以我们能及时看到我们输入的字符，那是因为TTY在收到终端发过去的字符后，会先将字符原路返回一份，然后才交给前端进程处理，这样终端就能及时的显示输入的字符。echo就是用来控制该功能的配置项，如果是-echo的话表示disable echo功能。</p><h4 id="tostop"><a class="header-anchor" href="#tostop">¶</a>-tostop</h4><p>如果你在shell中运行程序的时候，后面添加了&amp;，比如<code>./myapp &amp;</code>，这样myapp这个进程就会在后台运行，但如果这个进程继续往tty上写数据呢？这个参数就用来控制是否将输出转发给终端，也即结果会不会在终端显示，这里“-tostop”表示会输出到终端，如果配置为“tostop”的话，将不输出到终端，并且tty会发送信号SIGTTOU给myapp，该信号的默认行为是将暂停myapp的执行。</p><h2 id="TTY相关信号"><a class="header-anchor" href="#TTY相关信号">¶</a>TTY相关信号</h2><p>除了上面介绍配置时提到的SIGINT，SIGTTOU，SIGWINCHU外，还有这么几个跟TTY相关的信号</p><h4 id="SIGTTIN"><a class="header-anchor" href="#SIGTTIN">¶</a>SIGTTIN</h4><p>当后台进程读tty时，tty将发送该信号给相应的进程组，默认行为是暂停进程组中进程的执行。暂停的进程如何继续执行呢？请参考下一篇文章中的SIGCONT。</p><h4 id="SIGHUP"><a class="header-anchor" href="#SIGHUP">¶</a>SIGHUP</h4><p>当tty的另一端挂掉的时候，比如ssh的session断开了，于是sshd关闭了和ptmx关联的fd，内核将会给和该tty相关的所有进程发送SIGHUP信号，进程收到该信号后的默认行为是退出进程。</p><h4 id="SIGTSTP"><a class="header-anchor" href="#SIGTSTP">¶</a>SIGTSTP</h4><p>终端输入CTRL+Z时，tty收到后就会发送SIGTSTP给前端进程组，其默认行为是将前端进程组放到后端，并且暂停进程组里所有进程的执行。</p><blockquote><p>跟tty相关的信号都是可以捕获的，可以修改它的默认行为</p></blockquote><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>本文介绍了常见的tty功能和特点，下一篇中将详细介绍和tty密切相关的进程session id，进程组，job，后台程序等，敬请期待。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="http://www.linusakesson.net/programming/tty/index.php" target="_blank" rel="noopener">The TTY demystified</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IPV6简介</title>
      <link href="/2020/02/16/linux/ipv6-jian-jie/"/>
      <url>/2020/02/16/linux/ipv6-jian-jie/</url>
      
        <content type="html"><![CDATA[<p>IPv6仅仅只是“长”吗？IPv6的地址长什么样？平时我们是怎么使用IPv6的呢？编写网络程序的时候要怎么处理IPv6？且待本篇一一道来。</p><h2 id="为什么需要IPv6"><a class="header-anchor" href="#为什么需要IPv6">¶</a>为什么需要IPv6?</h2><p>全球的IP地址由一个名字叫<a href="https://www.iana.org/" target="_blank" rel="noopener">IANA</a>（Internet Assigned Numbers Authority）的机构管理，在它下面有5个分管机构，名字叫分别叫AFRINIC、<a href="https://www.apnic.net/" target="_blank" rel="noopener">APNIC</a>、ARIN、PIPE NCC和LACNIC，他们分别负责全球五个不同地区的IP地址分配，中国就归APNIC管。</p><p>IANA只负责将IP地址分配给下面的5个分管机构，分管机构再负责将IP地址分配给相关地区的网络运营商或者研究机构等。</p><p>IPv4的长度只有32位，总共约42亿的地址，除去<a href="https://en.wikipedia.org/wiki/Reserved_IP_addresses" target="_blank" rel="noopener">预留的大约6亿地址</a>外，实际在公网中可以被使用的地址大约只有36亿，而据最新统计，世界人口已经超过了70亿，并且截至2016年，人们正在使用的智能手机数量已经超过了20亿。</p><p>截至2011年01月31日，IANA已经将所有的IP地址分配给了下面的5个分管机构，而到2011年04月15日，APNIC的IP地址已经全部分配完了，就是说，如果我们的中国电信、移动和联通的IP地址不够用的话，已经没有地方可以申请更多的IP地址了。</p><p>很明显，如果每个设备都用一个公网IP的话，IPv4早就不够用了，虽然现在用<a href="https://en.wikipedia.org/wiki/Network_address_translation" target="_blank" rel="noopener">NAT</a>的方式还能坚持一段时间，但终究不是长久之策，我们需要一个更大的IP地址空间。</p><h2 id="IPv6的优点"><a class="header-anchor" href="#IPv6的优点">¶</a>IPv6的优点</h2><h4 id="更大的地址空间"><a class="header-anchor" href="#更大的地址空间">¶</a>更大的地址空间</h4><p>名字叫IPv6，但它的长度并不是64位，而是128位，总的地址空间大约为3.4*10^38，一个亿是10的8次方，那么IPv6就有340万亿亿亿亿个地址（4个亿连一起），所以说给地球上的每一粒沙子分配一个IP地址不是在吹牛，是真可以。</p><p>可以参考<a href="https://itsnobody.wordpress.com/2012/02/17/how-many-addresses-can-ipv6-hold/" target="_blank" rel="noopener">这篇文章</a>和<a href="http://www.npr.org/sections/krulwich/2012/09/17/161096233/which-is-greater-the-number-of-sand-grains-on-earth-or-stars-in-the-sky" target="_blank" rel="noopener">这篇文章</a>，里面提到地球上所有沙滩的沙子大约有7.5*10<sup>18粒，这个值跟IPv6的10</sup>38相差了很多个数量级，就算加上沙漠等其它的地方，IPv6的数量也足够覆盖它。</p><h4 id="点到点通信更方便"><a class="header-anchor" href="#点到点通信更方便">¶</a>点到点通信更方便</h4><p>IPv6完全有能力为联网的每个设备分配一个公网IP，于是我们可以不再需要NAT，从而非常方便的实现点到点的直接通信。</p><p>说好处之前，先了解一下NAT的缺点：</p><ul><li>使用了NAT之后，每次通信都要做一次NAT转换，影响性能。</li><li>处于两个不同NAT网络内部的机器不能直接通信，他们之间的通信得依赖第三方的服务器，极大的限制了网络的连通性，同时所有的数据都会被第三方所监控。</li><li>为了支持NAT，很多网络协议变得很复杂，大大增加了网络的复杂性。</li></ul><p>没有了NAT之后，当然上面的这些缺点也就没有了，同时会带来下面这些比较直观的好处：</p><ul><li>更方便： 想象一下，每个电脑都有公网IP，你电脑出了点问题，找我帮忙看一下，只要把你的IP给我，我就可以连上去了，而我们现在的情况是，两个人都是内网IP，没法直接访问，非得用QQ共享桌面之类的软件。</li><li>更安全： 配合点到点的加密，让网络更安全，不给第三方监听的机会； 以网络聊天为例，通过使用点到点的聊天软件，就不用担心被人监听聊天记录了；同时访问家里的摄像头不再需要经过第三方服务器，不用担心给别人看直播了。</li></ul><h4 id="IP配置更方便"><a class="header-anchor" href="#IP配置更方便">¶</a>IP配置更方便</h4><p>IPv6有一个功能叫<a href="https://tools.ietf.org/html/rfc2462" target="_blank" rel="noopener">Stateless Auto Configuration</a>，简单点说，就是可以不借助DHCP服务器实现IP地址的分配，插上网线就能上网。</p><p>系统起来后，就会为每个网卡生成一个Link-Local的IP地址，简单点说就是一个固定的前缀加上mac地址，由于mac地址全球唯一，所以这样构成的IP地址是唯一的，有了这个地址后，就可以局域网进行通信了，但是这种地址路由器是不会转发的。</p><p>如果网络里有路由器； 系统会通过广播的方式问路由器，路由器会返回一个子网前缀，类似于IPv4里面的192.168.0.0/16，系统将子网前缀和mac地址组合起来，构成了一个唯一的IP地址，这个IP地址可以通过路由器路由。</p><p>也就是说，就算不做任何配置，系统启动起来后，网卡就一定会有IPv6地址，有了IPv6地址就可以通信。</p><p>当然IP地址也可以由DHCP6服务器来分配，这种方式分配叫做Stateful Auto Configuration。</p><h4 id="局域网内更安全"><a class="header-anchor" href="#局域网内更安全">¶</a>局域网内更安全</h4><p>由<a href="https://tools.ietf.org/html/rfc4861" target="_blank" rel="noopener">Neighbor Discovery</a>代替了IPv4里面的<a href="https://en.wikipedia.org/wiki/Address_Resolution_Protocol" target="_blank" rel="noopener">ARP</a>协议，没有ARP后，跟<a href="https://en.wikipedia.org/wiki/ARP_spoofing" target="_blank" rel="noopener">ARP相关的攻击</a>就不存在了</p><h4 id="路由更快"><a class="header-anchor" href="#路由更快">¶</a>路由更快</h4><ul><li>跟IPv4不同，IPv6包头的字段长度是固定的，没有可选字段，所以路由器不需要检查IP包头是否包含可选字段。</li><li>IPv6包头里面没有checksum字段，不需要像IPv4那样每次TTL减1后都需要重新计算包头的checksum。</li><li>IPv6不支持在中途被分片和重组，即不能在路由器和防火墙上被分片，从而减轻了路由器的负担。</li></ul><p>IPv6包头里面没有checksum，那么会不会不安全呢？如果数据传输的过程中损坏了怎么办呢？首先，现在的网络都比较好，出现损坏的情况很少；其次，就算损坏了，有两种情况，一种是被路由器丢弃或者发到了错误的主机，这种情况不会造成什么问题，因为IP层本来就不保证可靠的传输，而是由上面的传输层来保证（如TCP），另一种情况是接受方收到了数据包，但由于数据包受损，内容已经和发送方发出来的不一样了，这种情况也是交给上面的传输层协议处理，比如UDP、TCP，它们都有自己的校验码，完全有能力发现数据损坏的问题。</p><p>不允许路由器对IPv6包进行分片，那么怎么保证发送端不会发送太大的数据包呢？首先，IPv6要求入网链路至少能传输1280字节的IP包，如果出现不能传输1280字节IP包这种情况，需要链路层自己处理分片和重组的过程；其次，跟IPv4里面PMTUD（Path MTU Discovery）是可选的不同，在IPv6里面，<a href="https://tools.ietf.org/html/rfc1981" target="_blank" rel="noopener">PMTUD</a>是一个非常重要且必须的功能；所以一般情况下发送小于等于1280字节的IP包肯定能到达目的地，加上现在大部分人都用以太网（MTU为1500，包含以太网的包头），绝大部分情况下一个包过去就能确定PMTU（Path MTU ），不会影响数据传输性能。</p><h4 id="更安全"><a class="header-anchor" href="#更安全">¶</a>更安全</h4><p>在设计IPv4的时候，根本没有考虑过安全问题。</p><p>而在设计IPv6的时候，安全问题作为一个很重要的方面被考虑进来了，尤其是端到端的安全，IPsec正是在这样的背景下被设计出来的，有了IPsec后，在IP层就能实现安全传输。</p><p>虽然IPsec也被引入到了IPv4，但由于IPsec连传输层的端口都进行了加密，导致IPsec碰到NAT网络的时候，会造成很多麻烦，虽然现在已经有了解决办法，但IPsec在IPv4网络里面还是受到诸多限制。</p><h4 id="更好的QoS"><a class="header-anchor" href="#更好的QoS">¶</a>更好的QoS</h4><p>IPv6的包头里面包含了一个叫做<a href="https://tools.ietf.org/html/rfc6437" target="_blank" rel="noopener">Flow Label</a>的字段，专门为QoS服务。</p><h4 id="更好的支持移动设备"><a class="header-anchor" href="#更好的支持移动设备">¶</a>更好的支持移动设备</h4><p>移动网络要求设备能在不同的网络里面快速的切换，并且现有的通信不受切换的影响，在IPv6里面，有专门的协议<a href="https://tools.ietf.org/html/rfc6275" target="_blank" rel="noopener">Mobile IPv6 (MIPv6)</a>来处理这个事情。</p><h2 id="IPv6格式"><a class="header-anchor" href="#IPv6格式">¶</a>IPv6格式</h2><p>这里不介绍报文的格式，只介绍IPv6地址的格式。</p><h4 id="地址表示方式"><a class="header-anchor" href="#地址表示方式">¶</a>地址表示方式</h4><p>IPv6地址的128位分成了由冒号分割的8段，每段2个字节16位，这16位由16进制表示，这里是一些例子，左边是完整的格式，右边是缩写格式：</p><table><thead><tr><th>完整的格式</th><th>缩写格式</th></tr></thead><tbody><tr><td>0000:0000:0000:0000:0000:0000:0000:0000</td><td>::</td></tr><tr><td>0000:0000:0000:0000:0000:0000:0000:0001</td><td>::1</td></tr><tr><td>FF02:0000:0000:0000:0000:0000:0000:0001</td><td>FF02::1</td></tr><tr><td>FC00:0001:A000:0B00:0000:0527:0127:00AB</td><td>FC00:1:A000:B00::527:127:AB</td></tr><tr><td>2001:0000:1111:000A:00B0:0000:9000:0200</td><td>2001:0:1111:A:B0::9000:200</td></tr><tr><td>2001:0DB8:0000:0000:ABCD:0000:0000:1234</td><td>2002:DB8::ABCD:0:0:1234 或者 2001:DB8:0:0:ABCD::1234</td></tr><tr><td>2001:0DB8:AAAA:0001:0000:0000:0000:0100</td><td>2001:DB8:AAAA:1::100</td></tr></tbody></table><p>两条缩写规则：</p><ul><li>用冒号分割的每段里面的前面的0可以省略掉，如:0001:可以缩写成:1:，:0000:可以缩写成:0:</li><li>如果冒号里面的是0的话，可以忽略掉（相邻的多个0可以一起忽略掉），直接写成两个冒号，如:0000:0000:可以被缩写成::</li></ul><p>**注意：**如果地址中有多个连续为0的段，只能将其中的一个缩写成::，如果两个都缩写了，就不知道每个缩写了多少个0，这也是上面的表格中2001:0DB8:0000:0000:ABCD:0000:0000:1234被缩写成2002:DB8::ABCD:0:0:1234或者2001:DB8:0:0:ABCD::1234的原因，它不能被缩写成2001:DB8::ABCD::1234，一般的做法是哪种方法省略的0越多就用哪种。</p><h4 id="网段表示方式"><a class="header-anchor" href="#网段表示方式">¶</a>网段表示方式</h4><p>IPv6和IPv4一样，也有网段和子网的概念，在IPv6里面，表示子网号或者网段的时候，也是类似的方法，如：2001:0:0:CD30::/60，这个时候前面的地址只需要写前60位，后面的所有位都用::来缩写，类似于IPv4里面的192.168.0。0/16，不过要注意的是，这里2001:0:0:CD30::不能把前面的两个0也缩写，因为这样就不是一个合法的IPv6地址了。</p><h2 id="IPv6地址类型"><a class="header-anchor" href="#IPv6地址类型">¶</a>IPv6地址类型</h2><p>IPv6里面有三种地址类型；</p><ul><li>Unicast: 单播地址，就是我们常用的地址，唯一标识一个网络接口</li><li>Anycast: 任意播（直译有点怪），一类特殊的IP地址，多个网络接口（不同的设备）都配上相同的地址，往这个地址发送数据的时候，路由器会只发往其中的一个接口，一般发往最近的那一个。（这个好像对实现负载均衡比较有用）</li><li>Multicast: 多播地址，代表一类unicast的集合，但往这个地址发送数据的时候，会将数据发给属于这个多播组的每个unicast地址。</li></ul><p>IPv6里面没有类似于IPv4那样单独的广播概念，它的功能被包含在多播里面。</p><blockquote><p>本人对anycast和multicast不是特别了解，所以没法描述的很清楚。</p></blockquote><h4 id="IPv6地址分类"><a class="header-anchor" href="#IPv6地址分类">¶</a>IPv6地址分类</h4><p>现有的IP地址被分配成如下几大类：</p><table><thead><tr><th>类型</th><th>前缀</th><th>IPv6表示方法</th></tr></thead><tbody><tr><td>Unspecified</td><td>00…00 (128位)</td><td>::/128</td></tr><tr><td>Loopback</td><td>00…01 (128位)</td><td>::1/128</td></tr><tr><td>Multicast</td><td>11111111</td><td>FF00::/8</td></tr><tr><td>Link-Local unicast</td><td>1111111010</td><td>FE80::/10</td></tr><tr><td>Unique local address</td><td>1111110</td><td>FC00::/7</td></tr><tr><td>Global Unicast</td><td>所有其它</td><td></td></tr></tbody></table><ul><li>全0的地址::/128为未定义地址，大家不要去使用</li><li>除了最后一位是1，其它都是0的地址::1/128为本地环回地址，同IPv4里面的127.0.0.1</li><li>FF00::/8这个网段的地址都是多播地址</li><li>FE80::/10为Link-Local的单播地址，这类地址不能穿过路由器</li><li>FC00::/7为本地的单播地址，可以穿过本地的路由器，但不能穿过外网的路由器，即只可以在本地使用，和IPv4里面的192.168.0.0/16相似</li><li><strong>全局的单播地址目前只有2000::/3开头的可以被申请使用，其它的都被预留了</strong></li></ul><h4 id="预定义的多播地址"><a class="header-anchor" href="#预定义的多播地址">¶</a>预定义的多播地址</h4><p>这里是两个常用的预定义的多播地址：</p><table><thead><tr><th>地址</th><th>含义</th></tr></thead><tbody><tr><td>FF02:0:0:0:0:0:0:1</td><td>子网内的所有机器</td></tr><tr><td>FF02:0:0:0:0:0:0:2</td><td>子网内的所有路由器</td></tr></tbody></table><p>后面有例子演示如何使用多播</p><h2 id="子网的划分"><a class="header-anchor" href="#子网的划分">¶</a>子网的划分</h2><p>IPv6要求所有的单播（unicast）地址的子网必须是64位的，即下面这种格式：</p><pre><code>   |         64 bits         |         64 bits         |   +-------------------------+-------------------------+   |        subnet ID        |       interface ID      |   </code></pre><p>如果子网的长度不是64位的话，会导致一些IPv6的功能不可用，详情请参考<a href="https://tools.ietf.org/html/rfc5375" target="_blank" rel="noopener">IPv6 Unicast Address Assignment Considerations</a>。</p><p>Interface ID为<a href="http://standards.ieee.org/develop/regauth/tut/eui64.pdf" target="_blank" rel="noopener">Modified EUI-64</a>格式，标准里面提供了如何将48位mac地址转换成EUI-64格式的方法。</p><p>IPv6标准要求单播地址的子网必须是64位的，主要是为了简化IPv6的管理，同时路由也方便，毕竟现在CPU都是64位的，如果子网号超过64位的话，会给路由造成一定的困难，同时64位的接口ID也比较容易存放一个UUID，比如可以容纳48位的mac地址，为Stateless Auto Configuration的地址分配提供了足够的空间。</p><p>64位的子网够用吗？64位的子网已经可以容纳2^64的设备了，相当于40亿个现在的IPv4地址空间的规模，实在是想不出还有哪种场合需要更大的子网。</p><p>64位的子网浪费吗？想想IPv4时代，几个人或者一群人通过NAT共享1个公网IP，而到了IPv6时代，这些人竟然可以拥有2^64个IP地址，想用几个用几个，为几个人分配一个64位的子网是不是有点浪费呢？其实谈不上浪费，IPv6的地址就是有那么多，大家都空着不用也是浪费，按道理64位的IP地址在可预见的将来已经够用了，而之所以采用128位IP加64位子网的方式，是因为能给我们的管理和使用方面带来很多的方便，如上面提到的便于路由和地址分配等。就算以后IP不够用了，再来放开子网位数的限制应该问题也不大。</p><blockquote><p>想起了一句话： 等我有了钱，要装两条宽带，一条玩游戏，一条聊QQ。</p></blockquote><h2 id="Linux上配置IPv6"><a class="header-anchor" href="#Linux上配置IPv6">¶</a>Linux上配置IPv6</h2><blockquote><p>下面的所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><p>现在的大部分Linux发行版默认情况下都启用了IPv6，如果没有，请参考发行版相关文档进行配置</p><pre><code>#这里有输出，表示IPv6已结启用了dev@ubuntu:~$ test -f /proc/net/if_inet6 &amp;&amp; echo &quot;IPv6 is already enabled&quot;IPv6 is already enabled</code></pre><p>IPv6启用后，每个网卡都会有一个IPv6地址，如下：</p><pre><code>dev@ubuntu:~$ ifconfigenp0s3    Link encap:Ethernet  HWaddr 08:00:27:03:d0:e7          inet addr:192.168.3.12  Bcast:192.168.3.255  Mask:255.255.255.0          inet6 addr: fe80::a00:27ff:fe03:d0e7/64 Scope:Link          ......lo        Link encap:Local Loopback          inet addr:127.0.0.1  Mask:255.0.0.0          inet6 addr: ::1/128 Scope:Host          ......</code></pre><p>这里lo的IPv6地址是环回地址::1，而enp0s3有一个“Scope:Link”的IPv6地址fe80::a00:27ff:fe03:d0e7，这个IP地址即上面说到的Link-local地址，它没法通过路由器，只能在子网内部使用。</p><blockquote><p>由于IPv6对交换机没有要求，所以就算没有支持IPv6的路由器，我们也可以在本地局域网内试玩一下IPv6</p></blockquote><p>通过ip命令就可以给网卡添加IPv6地址，和一个网卡只能有一个IPv4地址不同，一个网卡可以配置多个IPv6地址。</p><pre><code>#添加一个global的地址dev@ubuntu:~$ sudo ip -6 addr add 2001::1/64 dev enp0s3#添加一个Unique local address地址dev@ubuntu:~$ sudo ip -6 addr add fd00::1/64 dev enp0s3dev@ubuntu:~$ ifconfig enp0s3enp0s3    Link encap:Ethernet  HWaddr 08:00:27:03:d0:e7          inet addr:192.168.3.12  Bcast:192.168.3.255  Mask:255.255.255.0          inet6 addr: fd00::1/64 Scope:Global          inet6 addr: 2001::1/64 Scope:Global          inet6 addr: fe80::a00:27ff:fe03:d0e7/64 Scope:Link          ......</code></pre><p>再来看看系统默认的路由表：</p><pre><code>dev@ubuntu:~$ route -A inet6Kernel IPv6 routing tableDestination                    Next Hop                   Flag Met Ref Use If2001::/64                      ::                         U    256 0     0 enp0s3fd00::/64                      ::                         U    256 0     0 enp0s3fe80::/64                      ::                         U    256 1     3 enp0s3::/0                           ::                         !n   -1  1   832 lo::1/128                        ::                         Un   0   3    36 lo2001::1/128                    ::                         Un   0   3     9 lofd00::1/128                    ::                         Un   0   2     5 lofe80::a00:27ff:fe03:d0e7/128   ::                         Un   0   3   193 loff00::/8                       ::                         U    256 2    84 enp0s3::/0                           ::                         !n   -1  1   832 lo</code></pre><p>从“Next Hop”列可以看出，这里的所有网段都是本地接口可以直接到达的网段，不需要路由器转发。</p><h2 id="使用IPv6"><a class="header-anchor" href="#使用IPv6">¶</a>使用IPv6</h2><p>上节配置好了IPv6之后，我们这节来看看怎么使用这些地址</p><blockquote><p>这里只用一台机器来演示怎么和自己通信，大家有条件的话可以试试两台机器之间通信，效果是一样的。</p></blockquote><h4 id="ping6"><a class="header-anchor" href="#ping6">¶</a>ping6</h4><p>和IPv4里面的ping相对于的命令是ping6，对于不同类型的地址，ping的方式不一样(为了节省篇幅，示例中省略了ping成功时的输出)：</p><pre><code>#ping lo的环回地址dev@ubuntu:~$ ping6 ::1#ping类型为“Scope:Global”的地址dev@ubuntu:~$ ping6 fd00::1dev@ubuntu:~$ ping6 2001::1#ping类型为“Scope:Link”的地址dev@ubuntu:~$ ping6 -I enp0s3 fe80::a00:27ff:fe03:d0e7#ping一个多播（Multicast）地址，ff02::1代表子网中的所有机器dev@ubuntu:~$ ping6 -I enp0s3 ff02::1PING ff02::1(ff02::1) from fe80::a00:27ff:fe03:d0e7 enp0s3: 56 data bytes64 bytes from fe80::a00:27ff:fe03:d0e7: icmp_seq=1 ttl=64 time=0.036 ms64 bytes from fe80::3aea:a7ff:fe6c:ecff: icmp_seq=1 ttl=64 time=0.744 ms (DUP!)64 bytes from fe80::188d:cbae:80d5:7a7a: icmp_seq=1 ttl=64 time=0.791 ms (DUP!)......#可以看到局域网中的其它机器回复的结果，这些IP都是其它机器的“Scope:Link”地址#这里(DUP!)是由于ping多播地址时会收到多个回复，导致ping认为有重复的应答，其实是正常情况#选择其中的任意一个，单独ping一下试试dev@ubuntu:~$ ping6 -I enp0s3 fe80::188d:cbae:80d5:7a7a#访问Link-local的地址的时候，除了-I参数外，我们可以直接这样访问dev@ubuntu:~$ ping6 fe80::188d:cbae:80d5:7a7a%enp0s3#或者根据enp0s3的id来访问#获取enp0s3的iddev@ubuntu:~$ grep enp0s3 /proc/net/if_inet6 | cut -d' ' -f2 | uniq02dev@ubuntu:~$ ping6 fe80::188d:cbae:80d5:7a7a%2</code></pre><p>从上面可以看出，ping环回地址和global地址时，直接ping就可以了，而ping多播和Link-Local地址时，需要指定从哪个接口出去，这是因为机器上所有接口的Link-Local地址都属于同一个网段，当有多个接口时，根本没办法自动的判断应该从哪个接口出去。（不过从上面的路由表里面可以看出，在本地只有一个接口时，已经标识fe80::/64和ff00::/8可以从enp0s3口出去，不确定为什么在这种情况下，应用层的程序还要求指定接口名称，可能是为了保持统一吧，不管有几个接口，都一样的用法）。</p><blockquote><p>注意： 如果是访问其它机器的link-local地址，-I参数和百分号的后面一定要指定本机出去的接口名称，而不是目的IP对应的接口名称</p></blockquote><h4 id="DNS"><a class="header-anchor" href="#DNS">¶</a>DNS</h4><p>DNS里面有一个专门的IPv6类型，叫AAAA，查询的时候指定类型就可以了</p><pre><code>#host命令默认情况下只查询A类地址，即IPv4地址#指定-t AAAA即可查询域名的IPv6地址#这里的结果显示，baidu.com还不支持IPv6，google.com已经支持了dev@ubuntu:~$ host -t AAAA baidu.combaidu.com has no AAAA recorddev@ubuntu:~$ host -t AAAA google.comgoogle.com has IPv6 address 2607:f8b0:400e:c04::65#dig命令也是一样的参数dev@ubuntu:~$ dig -t AAAA google.com#这里省略输出结果，有点长</code></pre><h4 id="SSH"><a class="header-anchor" href="#SSH">¶</a>SSH</h4><p>下面四种方式都可以登陆当前机器</p><pre><code>dev@ubuntu:~$ ssh ::1   dev@ubuntu:~$ ssh 2001::1dev@ubuntu:~$ ssh fe80::a00:27ff:fe03:d0e7%enp0s3dev@ubuntu:~$ ssh fe80::a00:27ff:fe03:d0e7%2</code></pre><h4 id="http"><a class="header-anchor" href="#http">¶</a>http</h4><p>下面以curl来进行演示，如果有图形界面的浏览器的话，可以直接在浏览器里面输入同样的地址</p><pre><code>#--------------------------第一个shell窗口----------------------#准备一个支持IPv6的http服务器dev@ubuntu:~$ sudo apt-get install phpdev@ubuntu:~$ mkdir webdev@ubuntu:~$ echo &quot;hello world!&quot; &gt; web/index.html#启动http服务器，监听所有接口的8080端口dev@ubuntu:~$ php -S [::]:8080 -t ./web/PHP 7.0.15-0ubuntu0.16.04.4 Development Server started at Mon Mar 20 23:44:26 2017Listening on http://[::]:8080Document root is /home/dev/webPress Ctrl-C to quit.#--------------------------第二个shell窗口----------------------#确认监听正确，这里:::8080就表示监听了所有IPv6和IPv4接口的8080端口dev@ubuntu:~$ netstat -anp|grep 8080tcp6       0      0 :::8080                 :::*                    LISTEN      13716/php#先试试用IPv4的地址连过来，没有问题dev@ubuntu:~$ curl http://127.0.0.1:8080/hello world!#IPv6的环回地址dev@ubuntu:~$ curl http://[::1]:8080/hello world!#IPv6的global地址dev@ubuntu:~$ curl http://[2001::1]:8080/hello world!#link-local地址dev@ubuntu:~$ curl http://[fe80::a00:27ff:fe03:d0e7%enp0s3]:8080/hello world!dev@ubuntu:~$ curl http://[fe80::a00:27ff:fe03:d0e7%2]:8080/hello world!</code></pre><h2 id="IPv6编程示例"><a class="header-anchor" href="#IPv6编程示例">¶</a>IPv6编程示例</h2><p>这里以python代码为示例，写了一个UDP的服务器和客户端，演示如何同时支持IPv4和IPv6。（为了简化起见，代码里面没有做错误处理）</p><h4 id="server-py"><a class="header-anchor" href="#server-py">¶</a><a href="http://server.py" target="_blank" rel="noopener">server.py</a></h4><pre><code>import socketimport sysip,port = sys.argv[1],int(sys.argv[2])addrinfo = socket.getaddrinfo(ip, port, proto=socket.IPPROTO_UDP)[0]sock = socket.socket(addrinfo[0], socket.SOCK_DGRAM)addr = addrinfo[4]sock.bind(addr)print(&quot;Listening on [{}]:{}...&quot;.format(addr[0], addr[1]))while True:    data, addr = sock.recvfrom(65535)    print(&quot;Recvfrom [{}]:{}\t{}&quot;.format(addr[0], addr[1], data))    sock.sendto(data, addr)</code></pre><h4 id="client-py"><a class="header-anchor" href="#client-py">¶</a><a href="http://client.py" target="_blank" rel="noopener">client.py</a></h4><pre><code>import socketimport syshost,port = sys.argv[1],int(sys.argv[2])addrinfos = socket.getaddrinfo(host, port, proto=socket.IPPROTO_UDP)for addrinfo in addrinfos:    sock = socket.socket(addrinfo[0], socket.SOCK_DGRAM)    sock.settimeout(2)    data = b'hello'    addr = addrinfo[4]    sock.sendto(data, addr)    print(&quot;Sendto   [{}]:{}\t{}&quot;.format(addr[0], addr[1], data))    try:        data, addr = sock.recvfrom(65535)        print(&quot;Recvfrom [{}]:{}\t{}&quot;.format(addr[0], addr[1], data))    except socket.timeout:        print(&quot;timeout&quot;)</code></pre><p>如果参数传入的是域名或者主机名，getaddrinfo函数可能返回多个IP，这时候客户端需要根据自己的应用特点选择一个或多个进行通信，在本例中是发送数据包给所有的IP。</p><p>getaddrinfo返回的IP列表里面的顺序是有讲究的，如果对这个很在意的话，请参考<a href="https://tools.ietf.org/html/rfc6724" target="_blank" rel="noopener">rfc6724</a>，默认情况一般是IPv6的地址在前面，在Linux下还可以通过<a href="https://linux.die.net/man/5/gai.conf" target="_blank" rel="noopener">/etc/gai.conf</a>来配置相关的顺序。</p><h4 id="server使用示例"><a class="header-anchor" href="#server使用示例">¶</a>server使用示例</h4><pre><code>dev@ubuntu:~/ipv6$ python3 server.py :: 8000Listening on [::]:8000...dev@ubuntu:~/ipv6$ python3 server.py 0.0.0.0 8000Listening on [0.0.0.0]:8000...dev@ubuntu:~/ipv6$ python3 server.py 2001::1 8000Listening on [2001::1]:8000...dev@ubuntu:~/ipv6$ python3 server.py fe80::a00:27ff:fe03:d0e7%enp0s3 8000Listening on [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000...dev@ubuntu:~/ipv6$ python3 server.py fe80::a00:27ff:fe03:d0e7%2 8000Listening on [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000...</code></pre><h4 id="server绑定所有IPv4和IPv6的接口，-然后client用不同的方式发包"><a class="header-anchor" href="#server绑定所有IPv4和IPv6的接口，-然后client用不同的方式发包">¶</a>server绑定所有IPv4和IPv6的接口， 然后client用不同的方式发包</h4><pre><code>dev@ubuntu:~/ipv6$ python3 server.py :: 8000Listening on [::]:8000...Recvfrom [fe80::a00:27ff:fe03:d0e7%enp0s3]:48033        b'hello'Recvfrom [fe80::a00:27ff:fe03:d0e7%enp0s3]:50298        b'hello'Recvfrom [2001::1]:60882        b'hello'Recvfrom [::1]:44664    b'hello'Recvfrom [::ffff:127.0.0.1]:46676       b'hello'Recvfrom [::1]:55518    b'hello'Recvfrom [::ffff:127.0.0.1]:35961       b'hello'Recvfrom [fe80::a00:27ff:fe03:d0e7%enp0s3]:36281        b'hello'dev@ubuntu:~/ipv6$ python3 client.py fe80::a00:27ff:fe03:d0e7%enp0s3 8000Sendto   [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000 b'hello'Recvfrom [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000 b'hello'dev@ubuntu:~/ipv6$ python3 client.py fe80::a00:27ff:fe03:d0e7%2 8000Sendto   [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000 b'hello'Recvfrom [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000 b'hello'dev@ubuntu:~/ipv6$ python3 client.py 2001::1 8000Sendto   [2001::1]:8000 b'hello'Recvfrom [2001::1]:8000 b'hello'dev@ubuntu:~/ipv6$ python3 client.py ::1 8000Sendto   [::1]:8000     b'hello'Recvfrom [::1]:8000     b'hello'dev@ubuntu:~/ipv6$ python3 client.py 127.0.0.1 8000Sendto   [127.0.0.1]:8000       b'hello'Recvfrom [127.0.0.1]:8000       b'hello'#由于localhost在/etc/hosts里面配置了两个IP，所以这里发了两个数据包，#并且是先发IPv6的地址dev@ubuntu:~/ipv6$ python3 client.py localhost 8000Sendto   [::1]:8000     b'hello'Recvfrom [::1]:8000     b'hello'Sendto   [127.0.0.1]:8000       b'hello'Recvfrom [127.0.0.1]:8000       b'hello'#通过多播地址发给当前子网中的所有机器dev@ubuntu:~/ipv6$ python3 client.py FF02:0:0:0:0:0:0:1%enp0s3 8000Sendto   [ff02::1%enp0s3]:8000  b'hello'Recvfrom [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000 b'hello'</code></pre><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><p><a href="http://etherealmind.com/allocating-64-wasteful-ipv6-not/" target="_blank" rel="noopener">Why Allocating a /64 is Not Wasteful and Necessary</a><br><a href="http://ipv6.com/articles/general/Top-10-Features-that-make-IPv6-greater-than-IPv4.htm" target="_blank" rel="noopener">Top 10 Features that make IPv6 ‘greater’ than IPv4</a><br><a href="https://tools.ietf.org/html/rfc4291" target="_blank" rel="noopener">IP Version 6 Addressing Architecture</a>IPv6仅仅只是“长”吗？IPv6的地址长什么样？平时我们是怎么使用IPv6的呢？编写网络程序的时候要怎么处理IPv6？且待本篇一一道来。</p><h2 id="为什么需要IPv6-v2"><a class="header-anchor" href="#为什么需要IPv6-v2">¶</a>为什么需要IPv6?</h2><p>全球的IP地址由一个名字叫<a href="https://www.iana.org/" target="_blank" rel="noopener">IANA</a>（Internet Assigned Numbers Authority）的机构管理，在它下面有5个分管机构，名字叫分别叫AFRINIC、<a href="https://www.apnic.net/" target="_blank" rel="noopener">APNIC</a>、ARIN、PIPE NCC和LACNIC，他们分别负责全球五个不同地区的IP地址分配，中国就归APNIC管。</p><p>IANA只负责将IP地址分配给下面的5个分管机构，分管机构再负责将IP地址分配给相关地区的网络运营商或者研究机构等。</p><p>IPv4的长度只有32位，总共约42亿的地址，除去<a href="https://en.wikipedia.org/wiki/Reserved_IP_addresses" target="_blank" rel="noopener">预留的大约6亿地址</a>外，实际在公网中可以被使用的地址大约只有36亿，而据最新统计，世界人口已经超过了70亿，并且截至2016年，人们正在使用的智能手机数量已经超过了20亿。</p><p>截至2011年01月31日，IANA已经将所有的IP地址分配给了下面的5个分管机构，而到2011年04月15日，APNIC的IP地址已经全部分配完了，就是说，如果我们的中国电信、移动和联通的IP地址不够用的话，已经没有地方可以申请更多的IP地址了。</p><p>很明显，如果每个设备都用一个公网IP的话，IPv4早就不够用了，虽然现在用<a href="https://en.wikipedia.org/wiki/Network_address_translation" target="_blank" rel="noopener">NAT</a>的方式还能坚持一段时间，但终究不是长久之策，我们需要一个更大的IP地址空间。</p><h2 id="IPv6的优点-v2"><a class="header-anchor" href="#IPv6的优点-v2">¶</a>IPv6的优点</h2><h4 id="更大的地址空间-v2"><a class="header-anchor" href="#更大的地址空间-v2">¶</a>更大的地址空间</h4><p>名字叫IPv6，但它的长度并不是64位，而是128位，总的地址空间大约为3.4*10^38，一个亿是10的8次方，那么IPv6就有340万亿亿亿亿个地址（4个亿连一起），所以说给地球上的每一粒沙子分配一个IP地址不是在吹牛，是真可以。</p><p>可以参考<a href="https://itsnobody.wordpress.com/2012/02/17/how-many-addresses-can-ipv6-hold/" target="_blank" rel="noopener">这篇文章</a>和<a href="http://www.npr.org/sections/krulwich/2012/09/17/161096233/which-is-greater-the-number-of-sand-grains-on-earth-or-stars-in-the-sky" target="_blank" rel="noopener">这篇文章</a>，里面提到地球上所有沙滩的沙子大约有7.5*10<sup>18粒，这个值跟IPv6的10</sup>38相差了很多个数量级，就算加上沙漠等其它的地方，IPv6的数量也足够覆盖它。</p><h4 id="点到点通信更方便-v2"><a class="header-anchor" href="#点到点通信更方便-v2">¶</a>点到点通信更方便</h4><p>IPv6完全有能力为联网的每个设备分配一个公网IP，于是我们可以不再需要NAT，从而非常方便的实现点到点的直接通信。</p><p>说好处之前，先了解一下NAT的缺点：</p><ul><li>使用了NAT之后，每次通信都要做一次NAT转换，影响性能。</li><li>处于两个不同NAT网络内部的机器不能直接通信，他们之间的通信得依赖第三方的服务器，极大的限制了网络的连通性，同时所有的数据都会被第三方所监控。</li><li>为了支持NAT，很多网络协议变得很复杂，大大增加了网络的复杂性。</li></ul><p>没有了NAT之后，当然上面的这些缺点也就没有了，同时会带来下面这些比较直观的好处：</p><ul><li>更方便： 想象一下，每个电脑都有公网IP，你电脑出了点问题，找我帮忙看一下，只要把你的IP给我，我就可以连上去了，而我们现在的情况是，两个人都是内网IP，没法直接访问，非得用QQ共享桌面之类的软件。</li><li>更安全： 配合点到点的加密，让网络更安全，不给第三方监听的机会； 以网络聊天为例，通过使用点到点的聊天软件，就不用担心被人监听聊天记录了；同时访问家里的摄像头不再需要经过第三方服务器，不用担心给别人看直播了。</li></ul><h4 id="IP配置更方便-v2"><a class="header-anchor" href="#IP配置更方便-v2">¶</a>IP配置更方便</h4><p>IPv6有一个功能叫<a href="https://tools.ietf.org/html/rfc2462" target="_blank" rel="noopener">Stateless Auto Configuration</a>，简单点说，就是可以不借助DHCP服务器实现IP地址的分配，插上网线就能上网。</p><p>系统起来后，就会为每个网卡生成一个Link-Local的IP地址，简单点说就是一个固定的前缀加上mac地址，由于mac地址全球唯一，所以这样构成的IP地址是唯一的，有了这个地址后，就可以局域网进行通信了，但是这种地址路由器是不会转发的。</p><p>如果网络里有路由器； 系统会通过广播的方式问路由器，路由器会返回一个子网前缀，类似于IPv4里面的192.168.0.0/16，系统将子网前缀和mac地址组合起来，构成了一个唯一的IP地址，这个IP地址可以通过路由器路由。</p><p>也就是说，就算不做任何配置，系统启动起来后，网卡就一定会有IPv6地址，有了IPv6地址就可以通信。</p><p>当然IP地址也可以由DHCP6服务器来分配，这种方式分配叫做Stateful Auto Configuration。</p><h4 id="局域网内更安全-v2"><a class="header-anchor" href="#局域网内更安全-v2">¶</a>局域网内更安全</h4><p>由<a href="https://tools.ietf.org/html/rfc4861" target="_blank" rel="noopener">Neighbor Discovery</a>代替了IPv4里面的<a href="https://en.wikipedia.org/wiki/Address_Resolution_Protocol" target="_blank" rel="noopener">ARP</a>协议，没有ARP后，跟<a href="https://en.wikipedia.org/wiki/ARP_spoofing" target="_blank" rel="noopener">ARP相关的攻击</a>就不存在了</p><h4 id="路由更快-v2"><a class="header-anchor" href="#路由更快-v2">¶</a>路由更快</h4><ul><li>跟IPv4不同，IPv6包头的字段长度是固定的，没有可选字段，所以路由器不需要检查IP包头是否包含可选字段。</li><li>IPv6包头里面没有checksum字段，不需要像IPv4那样每次TTL减1后都需要重新计算包头的checksum。</li><li>IPv6不支持在中途被分片和重组，即不能在路由器和防火墙上被分片，从而减轻了路由器的负担。</li></ul><p>IPv6包头里面没有checksum，那么会不会不安全呢？如果数据传输的过程中损坏了怎么办呢？首先，现在的网络都比较好，出现损坏的情况很少；其次，就算损坏了，有两种情况，一种是被路由器丢弃或者发到了错误的主机，这种情况不会造成什么问题，因为IP层本来就不保证可靠的传输，而是由上面的传输层来保证（如TCP），另一种情况是接受方收到了数据包，但由于数据包受损，内容已经和发送方发出来的不一样了，这种情况也是交给上面的传输层协议处理，比如UDP、TCP，它们都有自己的校验码，完全有能力发现数据损坏的问题。</p><p>不允许路由器对IPv6包进行分片，那么怎么保证发送端不会发送太大的数据包呢？首先，IPv6要求入网链路至少能传输1280字节的IP包，如果出现不能传输1280字节IP包这种情况，需要链路层自己处理分片和重组的过程；其次，跟IPv4里面PMTUD（Path MTU Discovery）是可选的不同，在IPv6里面，<a href="https://tools.ietf.org/html/rfc1981" target="_blank" rel="noopener">PMTUD</a>是一个非常重要且必须的功能；所以一般情况下发送小于等于1280字节的IP包肯定能到达目的地，加上现在大部分人都用以太网（MTU为1500，包含以太网的包头），绝大部分情况下一个包过去就能确定PMTU（Path MTU ），不会影响数据传输性能。</p><h4 id="更安全-v2"><a class="header-anchor" href="#更安全-v2">¶</a>更安全</h4><p>在设计IPv4的时候，根本没有考虑过安全问题。</p><p>而在设计IPv6的时候，安全问题作为一个很重要的方面被考虑进来了，尤其是端到端的安全，IPsec正是在这样的背景下被设计出来的，有了IPsec后，在IP层就能实现安全传输。</p><p>虽然IPsec也被引入到了IPv4，但由于IPsec连传输层的端口都进行了加密，导致IPsec碰到NAT网络的时候，会造成很多麻烦，虽然现在已经有了解决办法，但IPsec在IPv4网络里面还是受到诸多限制。</p><h4 id="更好的QoS-v2"><a class="header-anchor" href="#更好的QoS-v2">¶</a>更好的QoS</h4><p>IPv6的包头里面包含了一个叫做<a href="https://tools.ietf.org/html/rfc6437" target="_blank" rel="noopener">Flow Label</a>的字段，专门为QoS服务。</p><h4 id="更好的支持移动设备-v2"><a class="header-anchor" href="#更好的支持移动设备-v2">¶</a>更好的支持移动设备</h4><p>移动网络要求设备能在不同的网络里面快速的切换，并且现有的通信不受切换的影响，在IPv6里面，有专门的协议<a href="https://tools.ietf.org/html/rfc6275" target="_blank" rel="noopener">Mobile IPv6 (MIPv6)</a>来处理这个事情。</p><h2 id="IPv6格式-v2"><a class="header-anchor" href="#IPv6格式-v2">¶</a>IPv6格式</h2><p>这里不介绍报文的格式，只介绍IPv6地址的格式。</p><h4 id="地址表示方式-v2"><a class="header-anchor" href="#地址表示方式-v2">¶</a>地址表示方式</h4><p>IPv6地址的128位分成了由冒号分割的8段，每段2个字节16位，这16位由16进制表示，这里是一些例子，左边是完整的格式，右边是缩写格式：</p><table><thead><tr><th>完整的格式</th><th>缩写格式</th></tr></thead><tbody><tr><td>0000:0000:0000:0000:0000:0000:0000:0000</td><td>::</td></tr><tr><td>0000:0000:0000:0000:0000:0000:0000:0001</td><td>::1</td></tr><tr><td>FF02:0000:0000:0000:0000:0000:0000:0001</td><td>FF02::1</td></tr><tr><td>FC00:0001:A000:0B00:0000:0527:0127:00AB</td><td>FC00:1:A000:B00::527:127:AB</td></tr><tr><td>2001:0000:1111:000A:00B0:0000:9000:0200</td><td>2001:0:1111:A:B0::9000:200</td></tr><tr><td>2001:0DB8:0000:0000:ABCD:0000:0000:1234</td><td>2002:DB8::ABCD:0:0:1234 或者 2001:DB8:0:0:ABCD::1234</td></tr><tr><td>2001:0DB8:AAAA:0001:0000:0000:0000:0100</td><td>2001:DB8:AAAA:1::100</td></tr></tbody></table><p>两条缩写规则：</p><ul><li>用冒号分割的每段里面的前面的0可以省略掉，如:0001:可以缩写成:1:，:0000:可以缩写成:0:</li><li>如果冒号里面的是0的话，可以忽略掉（相邻的多个0可以一起忽略掉），直接写成两个冒号，如:0000:0000:可以被缩写成::</li></ul><p>**注意：**如果地址中有多个连续为0的段，只能将其中的一个缩写成::，如果两个都缩写了，就不知道每个缩写了多少个0，这也是上面的表格中2001:0DB8:0000:0000:ABCD:0000:0000:1234被缩写成2002:DB8::ABCD:0:0:1234或者2001:DB8:0:0:ABCD::1234的原因，它不能被缩写成2001:DB8::ABCD::1234，一般的做法是哪种方法省略的0越多就用哪种。</p><h4 id="网段表示方式-v2"><a class="header-anchor" href="#网段表示方式-v2">¶</a>网段表示方式</h4><p>IPv6和IPv4一样，也有网段和子网的概念，在IPv6里面，表示子网号或者网段的时候，也是类似的方法，如：2001:0:0:CD30::/60，这个时候前面的地址只需要写前60位，后面的所有位都用::来缩写，类似于IPv4里面的192.168.0。0/16，不过要注意的是，这里2001:0:0:CD30::不能把前面的两个0也缩写，因为这样就不是一个合法的IPv6地址了。</p><h2 id="IPv6地址类型-v2"><a class="header-anchor" href="#IPv6地址类型-v2">¶</a>IPv6地址类型</h2><p>IPv6里面有三种地址类型；</p><ul><li>Unicast: 单播地址，就是我们常用的地址，唯一标识一个网络接口</li><li>Anycast: 任意播（直译有点怪），一类特殊的IP地址，多个网络接口（不同的设备）都配上相同的地址，往这个地址发送数据的时候，路由器会只发往其中的一个接口，一般发往最近的那一个。（这个好像对实现负载均衡比较有用）</li><li>Multicast: 多播地址，代表一类unicast的集合，但往这个地址发送数据的时候，会将数据发给属于这个多播组的每个unicast地址。</li></ul><p>IPv6里面没有类似于IPv4那样单独的广播概念，它的功能被包含在多播里面。</p><blockquote><p>本人对anycast和multicast不是特别了解，所以没法描述的很清楚。</p></blockquote><h4 id="IPv6地址分类-v2"><a class="header-anchor" href="#IPv6地址分类-v2">¶</a>IPv6地址分类</h4><p>现有的IP地址被分配成如下几大类：</p><table><thead><tr><th>类型</th><th>前缀</th><th>IPv6表示方法</th></tr></thead><tbody><tr><td>Unspecified</td><td>00…00 (128位)</td><td>::/128</td></tr><tr><td>Loopback</td><td>00…01 (128位)</td><td>::1/128</td></tr><tr><td>Multicast</td><td>11111111</td><td>FF00::/8</td></tr><tr><td>Link-Local unicast</td><td>1111111010</td><td>FE80::/10</td></tr><tr><td>Unique local address</td><td>1111110</td><td>FC00::/7</td></tr><tr><td>Global Unicast</td><td>所有其它</td><td></td></tr></tbody></table><ul><li>全0的地址::/128为未定义地址，大家不要去使用</li><li>除了最后一位是1，其它都是0的地址::1/128为本地环回地址，同IPv4里面的127.0.0.1</li><li>FF00::/8这个网段的地址都是多播地址</li><li>FE80::/10为Link-Local的单播地址，这类地址不能穿过路由器</li><li>FC00::/7为本地的单播地址，可以穿过本地的路由器，但不能穿过外网的路由器，即只可以在本地使用，和IPv4里面的192.168.0.0/16相似</li><li><strong>全局的单播地址目前只有2000::/3开头的可以被申请使用，其它的都被预留了</strong></li></ul><h4 id="预定义的多播地址-v2"><a class="header-anchor" href="#预定义的多播地址-v2">¶</a>预定义的多播地址</h4><p>这里是两个常用的预定义的多播地址：</p><table><thead><tr><th>地址</th><th>含义</th></tr></thead><tbody><tr><td>FF02:0:0:0:0:0:0:1</td><td>子网内的所有机器</td></tr><tr><td>FF02:0:0:0:0:0:0:2</td><td>子网内的所有路由器</td></tr></tbody></table><p>后面有例子演示如何使用多播</p><h2 id="子网的划分-v2"><a class="header-anchor" href="#子网的划分-v2">¶</a>子网的划分</h2><p>IPv6要求所有的单播（unicast）地址的子网必须是64位的，即下面这种格式：</p><pre><code>   |         64 bits         |         64 bits         |   +-------------------------+-------------------------+   |        subnet ID        |       interface ID      |   </code></pre><p>如果子网的长度不是64位的话，会导致一些IPv6的功能不可用，详情请参考<a href="https://tools.ietf.org/html/rfc5375" target="_blank" rel="noopener">IPv6 Unicast Address Assignment Considerations</a>。</p><p>Interface ID为<a href="http://standards.ieee.org/develop/regauth/tut/eui64.pdf" target="_blank" rel="noopener">Modified EUI-64</a>格式，标准里面提供了如何将48位mac地址转换成EUI-64格式的方法。</p><p>IPv6标准要求单播地址的子网必须是64位的，主要是为了简化IPv6的管理，同时路由也方便，毕竟现在CPU都是64位的，如果子网号超过64位的话，会给路由造成一定的困难，同时64位的接口ID也比较容易存放一个UUID，比如可以容纳48位的mac地址，为Stateless Auto Configuration的地址分配提供了足够的空间。</p><p>64位的子网够用吗？64位的子网已经可以容纳2^64的设备了，相当于40亿个现在的IPv4地址空间的规模，实在是想不出还有哪种场合需要更大的子网。</p><p>64位的子网浪费吗？想想IPv4时代，几个人或者一群人通过NAT共享1个公网IP，而到了IPv6时代，这些人竟然可以拥有2^64个IP地址，想用几个用几个，为几个人分配一个64位的子网是不是有点浪费呢？其实谈不上浪费，IPv6的地址就是有那么多，大家都空着不用也是浪费，按道理64位的IP地址在可预见的将来已经够用了，而之所以采用128位IP加64位子网的方式，是因为能给我们的管理和使用方面带来很多的方便，如上面提到的便于路由和地址分配等。就算以后IP不够用了，再来放开子网位数的限制应该问题也不大。</p><blockquote><p>想起了一句话： 等我有了钱，要装两条宽带，一条玩游戏，一条聊QQ。</p></blockquote><h2 id="Linux上配置IPv6-v2"><a class="header-anchor" href="#Linux上配置IPv6-v2">¶</a>Linux上配置IPv6</h2><blockquote><p>下面的所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><p>现在的大部分Linux发行版默认情况下都启用了IPv6，如果没有，请参考发行版相关文档进行配置</p><pre><code>#这里有输出，表示IPv6已结启用了dev@ubuntu:~$ test -f /proc/net/if_inet6 &amp;&amp; echo &quot;IPv6 is already enabled&quot;IPv6 is already enabled</code></pre><p>IPv6启用后，每个网卡都会有一个IPv6地址，如下：</p><pre><code>dev@ubuntu:~$ ifconfigenp0s3    Link encap:Ethernet  HWaddr 08:00:27:03:d0:e7          inet addr:192.168.3.12  Bcast:192.168.3.255  Mask:255.255.255.0          inet6 addr: fe80::a00:27ff:fe03:d0e7/64 Scope:Link          ......lo        Link encap:Local Loopback          inet addr:127.0.0.1  Mask:255.0.0.0          inet6 addr: ::1/128 Scope:Host          ......</code></pre><p>这里lo的IPv6地址是环回地址::1，而enp0s3有一个“Scope:Link”的IPv6地址fe80::a00:27ff:fe03:d0e7，这个IP地址即上面说到的Link-local地址，它没法通过路由器，只能在子网内部使用。</p><blockquote><p>由于IPv6对交换机没有要求，所以就算没有支持IPv6的路由器，我们也可以在本地局域网内试玩一下IPv6</p></blockquote><p>通过ip命令就可以给网卡添加IPv6地址，和一个网卡只能有一个IPv4地址不同，一个网卡可以配置多个IPv6地址。</p><pre><code>#添加一个global的地址dev@ubuntu:~$ sudo ip -6 addr add 2001::1/64 dev enp0s3#添加一个Unique local address地址dev@ubuntu:~$ sudo ip -6 addr add fd00::1/64 dev enp0s3dev@ubuntu:~$ ifconfig enp0s3enp0s3    Link encap:Ethernet  HWaddr 08:00:27:03:d0:e7          inet addr:192.168.3.12  Bcast:192.168.3.255  Mask:255.255.255.0          inet6 addr: fd00::1/64 Scope:Global          inet6 addr: 2001::1/64 Scope:Global          inet6 addr: fe80::a00:27ff:fe03:d0e7/64 Scope:Link          ......</code></pre><p>再来看看系统默认的路由表：</p><pre><code>dev@ubuntu:~$ route -A inet6Kernel IPv6 routing tableDestination                    Next Hop                   Flag Met Ref Use If2001::/64                      ::                         U    256 0     0 enp0s3fd00::/64                      ::                         U    256 0     0 enp0s3fe80::/64                      ::                         U    256 1     3 enp0s3::/0                           ::                         !n   -1  1   832 lo::1/128                        ::                         Un   0   3    36 lo2001::1/128                    ::                         Un   0   3     9 lofd00::1/128                    ::                         Un   0   2     5 lofe80::a00:27ff:fe03:d0e7/128   ::                         Un   0   3   193 loff00::/8                       ::                         U    256 2    84 enp0s3::/0                           ::                         !n   -1  1   832 lo</code></pre><p>从“Next Hop”列可以看出，这里的所有网段都是本地接口可以直接到达的网段，不需要路由器转发。</p><h2 id="使用IPv6-v2"><a class="header-anchor" href="#使用IPv6-v2">¶</a>使用IPv6</h2><p>上节配置好了IPv6之后，我们这节来看看怎么使用这些地址</p><blockquote><p>这里只用一台机器来演示怎么和自己通信，大家有条件的话可以试试两台机器之间通信，效果是一样的。</p></blockquote><h4 id="ping6-v2"><a class="header-anchor" href="#ping6-v2">¶</a>ping6</h4><p>和IPv4里面的ping相对于的命令是ping6，对于不同类型的地址，ping的方式不一样(为了节省篇幅，示例中省略了ping成功时的输出)：</p><pre><code>#ping lo的环回地址dev@ubuntu:~$ ping6 ::1#ping类型为“Scope:Global”的地址dev@ubuntu:~$ ping6 fd00::1dev@ubuntu:~$ ping6 2001::1#ping类型为“Scope:Link”的地址dev@ubuntu:~$ ping6 -I enp0s3 fe80::a00:27ff:fe03:d0e7#ping一个多播（Multicast）地址，ff02::1代表子网中的所有机器dev@ubuntu:~$ ping6 -I enp0s3 ff02::1PING ff02::1(ff02::1) from fe80::a00:27ff:fe03:d0e7 enp0s3: 56 data bytes64 bytes from fe80::a00:27ff:fe03:d0e7: icmp_seq=1 ttl=64 time=0.036 ms64 bytes from fe80::3aea:a7ff:fe6c:ecff: icmp_seq=1 ttl=64 time=0.744 ms (DUP!)64 bytes from fe80::188d:cbae:80d5:7a7a: icmp_seq=1 ttl=64 time=0.791 ms (DUP!)......#可以看到局域网中的其它机器回复的结果，这些IP都是其它机器的“Scope:Link”地址#这里(DUP!)是由于ping多播地址时会收到多个回复，导致ping认为有重复的应答，其实是正常情况#选择其中的任意一个，单独ping一下试试dev@ubuntu:~$ ping6 -I enp0s3 fe80::188d:cbae:80d5:7a7a#访问Link-local的地址的时候，除了-I参数外，我们可以直接这样访问dev@ubuntu:~$ ping6 fe80::188d:cbae:80d5:7a7a%enp0s3#或者根据enp0s3的id来访问#获取enp0s3的iddev@ubuntu:~$ grep enp0s3 /proc/net/if_inet6 | cut -d' ' -f2 | uniq02dev@ubuntu:~$ ping6 fe80::188d:cbae:80d5:7a7a%2</code></pre><p>从上面可以看出，ping环回地址和global地址时，直接ping就可以了，而ping多播和Link-Local地址时，需要指定从哪个接口出去，这是因为机器上所有接口的Link-Local地址都属于同一个网段，当有多个接口时，根本没办法自动的判断应该从哪个接口出去。（不过从上面的路由表里面可以看出，在本地只有一个接口时，已经标识fe80::/64和ff00::/8可以从enp0s3口出去，不确定为什么在这种情况下，应用层的程序还要求指定接口名称，可能是为了保持统一吧，不管有几个接口，都一样的用法）。</p><blockquote><p>注意： 如果是访问其它机器的link-local地址，-I参数和百分号的后面一定要指定本机出去的接口名称，而不是目的IP对应的接口名称</p></blockquote><h4 id="DNS-v2"><a class="header-anchor" href="#DNS-v2">¶</a>DNS</h4><p>DNS里面有一个专门的IPv6类型，叫AAAA，查询的时候指定类型就可以了</p><pre><code>#host命令默认情况下只查询A类地址，即IPv4地址#指定-t AAAA即可查询域名的IPv6地址#这里的结果显示，baidu.com还不支持IPv6，google.com已经支持了dev@ubuntu:~$ host -t AAAA baidu.combaidu.com has no AAAA recorddev@ubuntu:~$ host -t AAAA google.comgoogle.com has IPv6 address 2607:f8b0:400e:c04::65#dig命令也是一样的参数dev@ubuntu:~$ dig -t AAAA google.com#这里省略输出结果，有点长</code></pre><h4 id="SSH-v2"><a class="header-anchor" href="#SSH-v2">¶</a>SSH</h4><p>下面四种方式都可以登陆当前机器</p><pre><code>dev@ubuntu:~$ ssh ::1   dev@ubuntu:~$ ssh 2001::1dev@ubuntu:~$ ssh fe80::a00:27ff:fe03:d0e7%enp0s3dev@ubuntu:~$ ssh fe80::a00:27ff:fe03:d0e7%2</code></pre><h4 id="http-v2"><a class="header-anchor" href="#http-v2">¶</a>http</h4><p>下面以curl来进行演示，如果有图形界面的浏览器的话，可以直接在浏览器里面输入同样的地址</p><pre><code>#--------------------------第一个shell窗口----------------------#准备一个支持IPv6的http服务器dev@ubuntu:~$ sudo apt-get install phpdev@ubuntu:~$ mkdir webdev@ubuntu:~$ echo &quot;hello world!&quot; &gt; web/index.html#启动http服务器，监听所有接口的8080端口dev@ubuntu:~$ php -S [::]:8080 -t ./web/PHP 7.0.15-0ubuntu0.16.04.4 Development Server started at Mon Mar 20 23:44:26 2017Listening on http://[::]:8080Document root is /home/dev/webPress Ctrl-C to quit.#--------------------------第二个shell窗口----------------------#确认监听正确，这里:::8080就表示监听了所有IPv6和IPv4接口的8080端口dev@ubuntu:~$ netstat -anp|grep 8080tcp6       0      0 :::8080                 :::*                    LISTEN      13716/php#先试试用IPv4的地址连过来，没有问题dev@ubuntu:~$ curl http://127.0.0.1:8080/hello world!#IPv6的环回地址dev@ubuntu:~$ curl http://[::1]:8080/hello world!#IPv6的global地址dev@ubuntu:~$ curl http://[2001::1]:8080/hello world!#link-local地址dev@ubuntu:~$ curl http://[fe80::a00:27ff:fe03:d0e7%enp0s3]:8080/hello world!dev@ubuntu:~$ curl http://[fe80::a00:27ff:fe03:d0e7%2]:8080/hello world!</code></pre><h2 id="IPv6编程示例-v2"><a class="header-anchor" href="#IPv6编程示例-v2">¶</a>IPv6编程示例</h2><p>这里以python代码为示例，写了一个UDP的服务器和客户端，演示如何同时支持IPv4和IPv6。（为了简化起见，代码里面没有做错误处理）</p><h4 id="server-py-v2"><a class="header-anchor" href="#server-py-v2">¶</a><a href="http://server.py" target="_blank" rel="noopener">server.py</a></h4><pre><code>import socketimport sysip,port = sys.argv[1],int(sys.argv[2])addrinfo = socket.getaddrinfo(ip, port, proto=socket.IPPROTO_UDP)[0]sock = socket.socket(addrinfo[0], socket.SOCK_DGRAM)addr = addrinfo[4]sock.bind(addr)print(&quot;Listening on [{}]:{}...&quot;.format(addr[0], addr[1]))while True:    data, addr = sock.recvfrom(65535)    print(&quot;Recvfrom [{}]:{}\t{}&quot;.format(addr[0], addr[1], data))    sock.sendto(data, addr)</code></pre><h4 id="client-py-v2"><a class="header-anchor" href="#client-py-v2">¶</a><a href="http://client.py" target="_blank" rel="noopener">client.py</a></h4><pre><code>import socketimport syshost,port = sys.argv[1],int(sys.argv[2])addrinfos = socket.getaddrinfo(host, port, proto=socket.IPPROTO_UDP)for addrinfo in addrinfos:    sock = socket.socket(addrinfo[0], socket.SOCK_DGRAM)    sock.settimeout(2)    data = b'hello'    addr = addrinfo[4]    sock.sendto(data, addr)    print(&quot;Sendto   [{}]:{}\t{}&quot;.format(addr[0], addr[1], data))    try:        data, addr = sock.recvfrom(65535)        print(&quot;Recvfrom [{}]:{}\t{}&quot;.format(addr[0], addr[1], data))    except socket.timeout:        print(&quot;timeout&quot;)</code></pre><p>如果参数传入的是域名或者主机名，getaddrinfo函数可能返回多个IP，这时候客户端需要根据自己的应用特点选择一个或多个进行通信，在本例中是发送数据包给所有的IP。</p><p>getaddrinfo返回的IP列表里面的顺序是有讲究的，如果对这个很在意的话，请参考<a href="https://tools.ietf.org/html/rfc6724" target="_blank" rel="noopener">rfc6724</a>，默认情况一般是IPv6的地址在前面，在Linux下还可以通过<a href="https://linux.die.net/man/5/gai.conf" target="_blank" rel="noopener">/etc/gai.conf</a>来配置相关的顺序。</p><h4 id="server使用示例-v2"><a class="header-anchor" href="#server使用示例-v2">¶</a>server使用示例</h4><pre><code>dev@ubuntu:~/ipv6$ python3 server.py :: 8000Listening on [::]:8000...dev@ubuntu:~/ipv6$ python3 server.py 0.0.0.0 8000Listening on [0.0.0.0]:8000...dev@ubuntu:~/ipv6$ python3 server.py 2001::1 8000Listening on [2001::1]:8000...dev@ubuntu:~/ipv6$ python3 server.py fe80::a00:27ff:fe03:d0e7%enp0s3 8000Listening on [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000...dev@ubuntu:~/ipv6$ python3 server.py fe80::a00:27ff:fe03:d0e7%2 8000Listening on [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000...</code></pre><h4 id="server绑定所有IPv4和IPv6的接口，-然后client用不同的方式发包-v2"><a class="header-anchor" href="#server绑定所有IPv4和IPv6的接口，-然后client用不同的方式发包-v2">¶</a>server绑定所有IPv4和IPv6的接口， 然后client用不同的方式发包</h4><pre><code>dev@ubuntu:~/ipv6$ python3 server.py :: 8000Listening on [::]:8000...Recvfrom [fe80::a00:27ff:fe03:d0e7%enp0s3]:48033        b'hello'Recvfrom [fe80::a00:27ff:fe03:d0e7%enp0s3]:50298        b'hello'Recvfrom [2001::1]:60882        b'hello'Recvfrom [::1]:44664    b'hello'Recvfrom [::ffff:127.0.0.1]:46676       b'hello'Recvfrom [::1]:55518    b'hello'Recvfrom [::ffff:127.0.0.1]:35961       b'hello'Recvfrom [fe80::a00:27ff:fe03:d0e7%enp0s3]:36281        b'hello'dev@ubuntu:~/ipv6$ python3 client.py fe80::a00:27ff:fe03:d0e7%enp0s3 8000Sendto   [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000 b'hello'Recvfrom [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000 b'hello'dev@ubuntu:~/ipv6$ python3 client.py fe80::a00:27ff:fe03:d0e7%2 8000Sendto   [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000 b'hello'Recvfrom [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000 b'hello'dev@ubuntu:~/ipv6$ python3 client.py 2001::1 8000Sendto   [2001::1]:8000 b'hello'Recvfrom [2001::1]:8000 b'hello'dev@ubuntu:~/ipv6$ python3 client.py ::1 8000Sendto   [::1]:8000     b'hello'Recvfrom [::1]:8000     b'hello'dev@ubuntu:~/ipv6$ python3 client.py 127.0.0.1 8000Sendto   [127.0.0.1]:8000       b'hello'Recvfrom [127.0.0.1]:8000       b'hello'#由于localhost在/etc/hosts里面配置了两个IP，所以这里发了两个数据包，#并且是先发IPv6的地址dev@ubuntu:~/ipv6$ python3 client.py localhost 8000Sendto   [::1]:8000     b'hello'Recvfrom [::1]:8000     b'hello'Sendto   [127.0.0.1]:8000       b'hello'Recvfrom [127.0.0.1]:8000       b'hello'#通过多播地址发给当前子网中的所有机器dev@ubuntu:~/ipv6$ python3 client.py FF02:0:0:0:0:0:0:1%enp0s3 8000Sendto   [ff02::1%enp0s3]:8000  b'hello'Recvfrom [fe80::a00:27ff:fe03:d0e7%enp0s3]:8000 b'hello'</code></pre><h2 id="参考-v2"><a class="header-anchor" href="#参考-v2">¶</a>参考</h2><p><a href="http://etherealmind.com/allocating-64-wasteful-ipv6-not/" target="_blank" rel="noopener">Why Allocating a /64 is Not Wasteful and Necessary</a><br><a href="http://ipv6.com/articles/general/Top-10-Features-that-make-IPv6-greater-than-IPv4.htm" target="_blank" rel="noopener">Top 10 Features that make IPv6 ‘greater’ than IPv4</a><br><a href="https://tools.ietf.org/html/rfc4291" target="_blank" rel="noopener">IP Version 6 Addressing Architecture</a></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux mount （第二部分 - Shared subtrees）</title>
      <link href="/2020/02/16/linux/linux-mount-di-er-bu-fen-shared-subtrees/"/>
      <url>/2020/02/16/linux/linux-mount-di-er-bu-fen-shared-subtrees/</url>
      
        <content type="html"><![CDATA[<p>简单点说，<a href="https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt" target="_blank" rel="noopener">Shared subtrees</a>就是一种控制子挂载点能否在其他地方被看到的技术，它只会在bind mount和mount namespace中用到，属于不怎么常用的功能。本篇将以bind mount为例对Shared subtrees做一个简单介绍，</p><blockquote><p>本篇所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="概述"><a class="header-anchor" href="#概述">¶</a>概述</h2><p>回想一下<a href="https://segmentfault.com/a/1190000006878392" target="_blank" rel="noopener">上一篇</a>中介绍的bind mount部分，如果bind在一起的两个目录下的子目录再挂载了设备的话，他们之间还能相互看到子目录里挂载的内容吗？ 比如在第一个目录下的子目录里面再mount了一个设备，那么在另一个目录下面能看到这个mount的设备里面的东西吗？答案是要看bind mount的propagation type。那什么是propagation type呢？</p><p>peer group和propagation type都是随着shared subtrees一起被引入的概念，下面分别对他们做一个介绍。</p><h3 id="peer-group"><a class="header-anchor" href="#peer-group">¶</a>peer group</h3><p>peer group就是一个或多个挂载点的集合，他们之间可以共享挂载信息。目前在下面两种情况下会使两个挂载点属于同一个peer group（前提条件是挂载点的propagation type是shared）</p><ul><li>利用mount --bind命令，将会使源和目的挂载点属于同一个peer group，当然前提条件是‘源’必须要是一个挂载点。</li><li>当创建新的mount namespace时，新namespace会拷贝一份老namespace的挂载点信息，于是新的和老的namespace里面的相同挂载点就会属于同一个peer group。</li></ul><h3 id="propagation-type"><a class="header-anchor" href="#propagation-type">¶</a>propagation type</h3><p>每个挂载点都有一个propagation type标志, 由它来决定当一个挂载点的下面创建和移除挂载点的时候，是否会传播到属于相同peer group的其他挂载点下去，也即同一个peer group里的其他的挂载点下面是不是也会创建和移除相应的挂载点.现在有4种不同类型的propagation type：</p><ul><li>MS_SHARED: 从名字就可以看出，挂载信息会在同一个peer group的不同挂载点之间共享传播. 当一个挂载点下面添加或者删除挂载点的时候，同一个peer group里的其他挂载点下面也会挂载和卸载同样的挂载点</li><li>MS_PRIVATE: 跟上面的刚好相反，挂载信息根本就不共享，也即private的挂载点不会属于任何peer group</li><li>MS_SLAVE: 跟名字一样，信息的传播是单向的，在同一个peer group里面，master的挂载点下面发生变化的时候，slave的挂载点下面也跟着变化，但反之则不然，slave下发生变化的时候不会通知master，master不会发生变化。</li><li>MS_UNBINDABLE: 这个和MS_PRIVATE相同，只是这种类型的挂载点不能作为bind mount的源，主要用来防止递归嵌套情况的出现。这种类型不常见，本篇将不介绍这种类型，有兴趣的同学请参考<a href="https://lwn.net/Articles/690679/" target="_blank" rel="noopener">这里的例子</a>。</li></ul><p>还有一些概念需要澄清一下：</p><ul><li>propagation type是挂载点的属性，每个挂载点都是独立的</li><li>挂载点是有父子关系的，比如挂载点/和/mnt/cdrom，/mnt/cdrom都是‘/’的子挂载点，‘/’是/mnt/cdrom的父挂载点</li><li>默认情况下，如果父挂载点是MS_SHARED，那么子挂载点也是MS_SHARED的，否则子挂载点将会是MS_PRIVATE，跟爷爷挂载点没有关系</li></ul><h2 id="示例"><a class="header-anchor" href="#示例">¶</a>示例</h2><p>这里将只演示bind mount的情况，mount namespace的情况请参考<a href="https://segmentfault.com/a/1190000006912742" target="_blank" rel="noopener">这里</a></p><h3 id="准备环境"><a class="header-anchor" href="#准备环境">¶</a>准备环境</h3><pre><code>#准备4个虚拟的disk，并在上面创建ext2文件系统，用于后续的mount测试dev@ubuntu:~$ mkdir disks &amp;&amp; cd disksdev@ubuntu:~/disks$ dd if=/dev/zero bs=1M count=32 of=./disk1.imgdev@ubuntu:~/disks$ dd if=/dev/zero bs=1M count=32 of=./disk2.imgdev@ubuntu:~/disks$ dd if=/dev/zero bs=1M count=32 of=./disk3.imgdev@ubuntu:~/disks$ dd if=/dev/zero bs=1M count=32 of=./disk4.imgdev@ubuntu:~/disks$ mkfs.ext2 ./disk1.imgdev@ubuntu:~/disks$ mkfs.ext2 ./disk2.imgdev@ubuntu:~/disks$ mkfs.ext2 ./disk3.imgdev@ubuntu:~/disks$ mkfs.ext2 ./disk4.img#准备两个目录用于挂载上面创建的diskdev@ubuntu:~/disks$ mkdir disk1 disk2dev@ubuntu:~/disks$ lsdisk1  disk1.img  disk2  disk2.img  disk3.img  disk4.img#确保根目录的propagation type是shared，#这一步是为了保证大家的操作结果和示例中的一样dev@ubuntu:~/disks$ sudo mount --make-shared /</code></pre><h3 id="查看propagation-type和peer-group"><a class="header-anchor" href="#查看propagation-type和peer-group">¶</a>查看propagation type和peer group</h3><p>默认情况下，子挂载点会继承父挂载点的propagation type</p><pre><code>#显式的以shared方式挂载disk1dev@ubuntu:~/disks$ sudo mount --make-shared ./disk1.img ./disk1#显式的以private方式挂载disk2dev@ubuntu:~/disks$ sudo mount --make-private ./disk2.img ./disk2#mountinfo比mounts文件包含有更多的关于挂载点的信息#这里sed主要用来过滤掉跟当前主题无关的信息#shared:105表示挂载点/home/dev/disks/disk1是以shared方式挂载，且peer group id为105#而挂载点/home/dev/disks/disk2没有相关信息，表示是以private方式挂载dev@ubuntu:~/disks$ cat /proc/self/mountinfo |grep disk | sed 's/ - .*//'164 24 7:1 / /home/dev/disks/disk1 rw,relatime shared:105173 24 7:2 / /home/dev/disks/disk2 rw,relatime#分别在disk1和disk2目录下创建目录disk3和disk4，然后挂载disk3，disk4到这两个目录dev@ubuntu:~/disks$ sudo mkdir ./disk1/disk3 ./disk2/disk4dev@ubuntu:~/disks$ sudo mount ./disk3.img ./disk1/disk3dev@ubuntu:~/disks$ sudo mount ./disk4.img ./disk2/disk4#查看挂载信息，第一列的数字是挂载点ID，第二例是父挂载点ID，#从结果来看，176和164的类型都是shared，而179和173的类型都是private的，#说明在默认mount的情况下，子挂载点会继承父挂载点的propagation typedev@ubuntu:~/disks$ cat /proc/self/mountinfo |grep disk| sed 's/ - .*//'164 24 7:1 / /home/dev/disks/disk1 rw,relatime shared:105 173 24 7:2 / /home/dev/disks/disk2 rw,relatime 176 164 7:3 / /home/dev/disks/disk1/disk3 rw,relatime shared:107 179 173 7:4 / /home/dev/disks/disk2/disk4 rw,relatime </code></pre><h3 id="shared-和-private-mount"><a class="header-anchor" href="#shared-和-private-mount">¶</a>shared 和 private mount</h3><pre><code>#umount掉disk3和disk4，创建两个新的目录bind1和bind2用于bind测试dev@ubuntu:~/disks$ sudo umount /home/dev/disks/disk1/disk3dev@ubuntu:~/disks$ sudo umount /home/dev/disks/disk2/disk4dev@ubuntu:~/disks$ mkdir bind1 bind2#bind的方式挂载disk1到bind1，disk2到bind2dev@ubuntu:~/disks$ sudo mount --bind ./disk1 ./bind1dev@ubuntu:~/disks$ sudo mount --bind ./disk2 ./bind2#查看挂载信息，显然默认情况下bind1和bind2的propagation type继承自父挂载点24(/)，都是shared。#由于bind2的源挂载点disk2是private的，所以bind2没有和disk2在同一个peer group里面，#而是重新创建了一个新的peer group，这个group里面就只有它一个。#因为164和176都是shared类型且是通过bind方式mount在一起的，所以他们属于同一个peer group 105。dev@ubuntu:~/disks$ cat /proc/self/mountinfo |grep disk| sed 's/ - .*//'164 24 7:1 / /home/dev/disks/disk1 rw,relatime shared:105 173 24 7:2 / /home/dev/disks/disk2 rw,relatime 176 24 7:1 / /home/dev/disks/bind1 rw,relatime shared:105 179 24 7:2 / /home/dev/disks/bind2 rw,relatime shared:109 #ID为24的挂载点为根目录的挂载点dev@ubuntu:~/disks$ cat /proc/self/mountinfo |grep ^24| sed 's/ - .*//'24 0 252:0 / / rw,relatime shared:1#这时disk3和disk4目录都是空的dev@ubuntu:~/disks$ ls bind1/disk3/dev@ubuntu:~/disks$ ls bind2/disk4/dev@ubuntu:~/disks$ ls disk1/disk3/dev@ubuntu:~/disks$ ls disk2/disk4/#重新挂载disk3和disk4dev@ubuntu:~/disks$ sudo mount ./disk3.img ./disk1/disk3dev@ubuntu:~/disks$ sudo mount ./disk4.img ./disk2/disk4#由于disk1/和bind1/属于同一个peer group，#所以在挂载了disk3后，在两个目录下都能看到disk3下的内容dev@ubuntu:~/disks$ ls disk1/disk3/lost+founddev@ubuntu:~/disks$ ls bind1/disk3/lost+found#而disk2/是private类型的，所以在他下面挂载disk4不会通知bind2，#于是bind2下的disk4目录是空的dev@ubuntu:~/disks$ ls disk2/disk4/lost+founddev@ubuntu:~/disks$ ls bind2/disk4/dev@ubuntu:~/disks$#再看看disk3，虽然182和183的父挂载点不一样，但由于他们父挂载点属于同一个peer group，#且disk3是以默认方式挂载的，所以他们属于同一个peer groupdev@ubuntu:~/disks$ cat /proc/self/mountinfo |egrep &quot;disk3&quot;| sed 's/ - .*//'182 164 7:3 / /home/dev/disks/disk1/disk3 rw,relatime shared:111 183 176 7:3 / /home/dev/disks/bind1/disk3 rw,relatime shared:111 #umount bind1/disk3后，disk1/disk3也相应的自动umount掉了dev@ubuntu:~/disks$ sudo umount bind1/disk3dev@ubuntu:~/disks$ cat /proc/self/mountinfo |grep disk3dev@ubuntu:~/disks$</code></pre><h3 id="slave-mount"><a class="header-anchor" href="#slave-mount">¶</a>slave mount</h3><pre><code>#umount除disk1的所有其他挂载点dev@ubuntu:~/disks$ sudo umount ./disk2/disk4dev@ubuntu:~/disks$ sudo umount /home/dev/disks/bind1dev@ubuntu:~/disks$ sudo umount /home/dev/disks/bind2dev@ubuntu:~/disks$ sudo umount /home/dev/disks/disk2#确认只剩disk1dev@ubuntu:~/disks$ cat /proc/self/mountinfo |grep disk| sed 's/ - .*//'164 24 7:1 / /home/dev/disks/disk1 rw,relatime shared:105 #分别显式的用shared和slave的方式bind disk1dev@ubuntu:~/disks$ sudo mount --bind --make-shared ./disk1 ./bind1dev@ubuntu:~/disks$ sudo mount --bind --make-slave ./bind1 ./bind2#164、173和176都属于同一个peer group，#master:105表示/home/dev/disks/bind2是peer group 105的slavedev@ubuntu:~/disks$ cat /proc/self/mountinfo |grep disk| sed 's/ - .*//'164 24 7:1 / /home/dev/disks/disk1 rw,relatime shared:105 173 24 7:1 / /home/dev/disks/bind1 rw,relatime shared:105 176 24 7:1 / /home/dev/disks/bind2 rw,relatime master:105 #mount disk3到disk1的子目录disk3下dev@ubuntu:~/disks$ sudo mount ./disk3.img ./disk1/disk3/#其他两个目录bin1和bind2里面也挂载成功，说明master发生变化的时候，slave会跟着变化dev@ubuntu:~/disks$ cat /proc/self/mountinfo |grep disk| sed 's/ - .*//'164 24 7:1 / /home/dev/disks/disk1 rw,relatime shared:105 173 24 7:1 / /home/dev/disks/bind1 rw,relatime shared:105 176 24 7:1 / /home/dev/disks/bind2 rw,relatime master:105 179 164 7:2 / /home/dev/disks/disk1/disk3 rw,relatime shared:109 181 176 7:2 / /home/dev/disks/bind2/disk3 rw,relatime master:109 180 173 7:2 / /home/dev/disks/bind1/disk3 rw,relatime shared:109 #umount disk3，然后mount disk3到bind2目录下dev@ubuntu:~/disks$ sudo umount ./disk1/disk3/dev@ubuntu:~/disks$ sudo mount ./disk3.img ./bind2/disk3/#由于bind2的propagation type是slave，所以disk1和bind1两个挂载点下面不会挂载disk3#从179的类型可以看出，当父挂载点176是slave类型时，默认情况下其子挂载点179是private类型dev@ubuntu:~/disks$ cat /proc/self/mountinfo |grep disk| sed 's/ - .*//'164 24 7:1 / /home/dev/disks/disk1 rw,relatime shared:105 173 24 7:1 / /home/dev/disks/bind1 rw,relatime shared:105 176 24 7:1 / /home/dev/disks/bind2 rw,relatime master:105 179 176 7:2 / /home/dev/disks/bind2/disk3 rw,relatime -</code></pre><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>如果用到了bind mount和mount namespace，在挂载设备的时候就需要注意一下父挂载点是否和其他挂载点有peer group关系，如果有且父挂载点是shared，就说明你挂载的设备除了在当前挂载点可以看到，在父挂载点的peer group的下面也可以看到。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt" target="_blank" rel="noopener">kernel:Shared Subtrees</a></li><li><a href="https://lwn.net/Articles/159077/" target="_blank" rel="noopener">lwn:Shared subtrees</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux session和进程组概述</title>
      <link href="/2020/02/16/linux/linux-session-he-jin-cheng-zu-gai-shu/"/>
      <url>/2020/02/16/linux/linux-session-he-jin-cheng-zu-gai-shu/</url>
      
        <content type="html"><![CDATA[<p>在<a href="https://segmentfault.com/a/1190000009082089" target="_blank" rel="noopener">上一篇</a>中介绍了tty的相关原理，这篇将介绍跟tty密切相关的session和进程组。</p><blockquote><p>本篇主要目的是澄清一些概念，不涉及细节</p></blockquote><h2 id="session"><a class="header-anchor" href="#session">¶</a>session</h2><p>session就是一组进程的集合，session id就是这个session中leader的进程ID。</p><h3 id="session的特点"><a class="header-anchor" href="#session的特点">¶</a>session的特点</h3><p>session的主要特点是当session的leader退出后，session中的所有其它进程将会收到SIGHUP信号，其默认行为是终止进程，即session的leader退出后，session中的其它进程也会退出。</p><p>如果session和tty关联的话，它们之间只能一一对应，一个tty只能属于一个session，一个session只能打开一个tty。当然session也可以不和任何tty关联。</p><h3 id="session的创建"><a class="header-anchor" href="#session的创建">¶</a>session的创建</h3><p>session可以在任何时候创建，调用setsid函数即可，session中的第一个进程即为这个session的leader，leader是不能变的。常见的创建session的场景是：</p><ul><li>用户登录后，启动shell时将会创建新的session，shell会作为session的leader，随后shell里面运行的进程都将属于这个session，当shell退出后，所有该用户运行的进程将退出。这类session一般都会和一个特定的tty关联，session的leader会成为tty的控制进程，当session的前端进程组发生变化时，控制进程负责更新tty上关联的前端进程组，当tty要关闭的时候，控制进程所在session的所有进程都会收到SIGHUP信号。</li><li>启动deamon进程，这类进程需要和父进程划清界限，所以需要启动一个新的session。这类session一般不会和任何tty关联。</li></ul><h2 id="进程组"><a class="header-anchor" href="#进程组">¶</a>进程组</h2><p>进程组（process group）也是一组进程的集合，进程组id就是这个进程组中leader的进程ID。</p><h3 id="进程组的特点"><a class="header-anchor" href="#进程组的特点">¶</a>进程组的特点</h3><p>进程组的主要特点是可以以进程组为单位通过函数<a href="http://man7.org/linux/man-pages/man3/killpg.3.html" target="_blank" rel="noopener">killpg</a>发送信号</p><h3 id="进程组的创建"><a class="header-anchor" href="#进程组的创建">¶</a>进程组的创建</h3><p>进程组主要用在shell里面，shell负责进程组的管理，包括创建、销毁等。（这里shell就是session的leader）</p><ul><li>对大部分进程来说，它自己就是进程组的leader，并且进程组里面就只有它自己一个进程</li><li>shell里面执行类似<code>ls|more</code>这样的以管道连接起来的命令时，两个进程就属于同一个进程组，ls是进程组的leader。</li><li>shell里面启动一个进程后，一般都会将该进程放到一个单独的进程组，然后该进程fork的所有进程都会属于该进程组，比如多进程的程序，它的所有进程都会属于同一个进程组，当在shell里面按下CTRL+C时，该程序的所有进程都会收到SIGINT而退出。</li></ul><h3 id="后台进程组"><a class="header-anchor" href="#后台进程组">¶</a>后台进程组</h3><p>shell中启动一个进程时，默认情况下，该进程就是一个前端进程组的leader，可以收到用户的输入，并且可以将输出打印到终端，只有当该进程组退出后，shell才可以再响应用户的输入。</p><p>但我们也可以将该进程组运行在后台，这样shell就可以继续相应用户的输入，常见的方法如下：</p><ul><li>启动程序时，在后面加&amp;，如<code>sleep 1000 &amp;</code>，进程将会进入后台继续运行</li><li>程序启动后，可以按CTRL+Z让它进入后台，和后面加&amp;不同的是，进程会被暂停执行</li></ul><p>对于后台运行的进程组，在shell里面体现为job的概念，即一个后台进程组就是一个job，job有如下限制：</p><ul><li>默认情况下，只要后台进程组的任何一个进程读tty，将会使整个进程组的所有进程暂停</li><li>默认情况下，只要后台进程组的任何一个进程写tty，将有可能会使整个进程组的所有进程暂停（依赖于tty的配置，请参考<a href="https://segmentfault.com/a/1190000009082089" target="_blank" rel="noopener">TTY/PTS概述</a>）</li></ul><p>所有后台运行的进程组可以通过jobs命令查看到，也可以通过fg命令将后台进程组切换到前端，这样就可以继续接收用户的输入了。这两个命令的具体用法请参考它们的帮助文件，这里只给出一个简单的例子：</p><pre><code>#通常情况下，sleep命令会一直等待在那里，直到指定的时间过去后才退出。#shell启动sleep程序时，就将sleep放到了一个新的进程组，#并且该进程组为前端进程组，虽然sleep不需要输入，也没有输出，#但当前session的标准输入和输出还是归它，别人用不了，#只有我们按下CTRL+C使sleep进程退出后，shell自己重新变成了前端进程组，#于是shell重新具备了响应输入以及输出能力dev@debian:~$ sleep 1000^C#我们可以在命令行的后面加上&amp;符号，shell还是照样会创建新的进程组，#并且sleep进程就是新进程组的leader，#但是shell会将sleep进程组放到后端，让它成为后台进程组#这里[1]是job id，1627是进程组的ID，即sleep进程的iddev@debian:~$ sleep 1000 &amp;[1] 1627#可以通过jobs命令看到当前有哪些后台进程组（job）dev@debian:~$ jobs[1]+  Running                 sleep 1000 &amp;#使用fg命令带上job id，即可让后端进程组回到前端，#然后我们使用CTRL+Z命令可以让它再次回到后端，并暂停进程的执行#CTRL+Z和&amp;不一样的地方就是CTRL+Z会让进程暂停执行，而&amp;不会dev@debian:~$ fg 1sleep 1000^Z[1]+  Stopped                 sleep 1000#Stopped状态表示进程在后台已经暂停执行了dev@debian:~$ jobs[1]+  Stopped                 sleep 1000</code></pre><h2 id="session和进程组的关系"><a class="header-anchor" href="#session和进程组的关系">¶</a>session和进程组的关系</h2><p>deamon程序虽然也是一个session的leader，但一般它不会创建新的进程组，也没有job的管理功能，所以这种情况下一个session就只有一个进程组，所有的进程都属于同样的进程组和session。</p><p>我们这里看一下shell作为session leader的情况，假设我们在shell里面执行了这些命令：</p><pre><code>dev@debian:~$ sleep 1000 &amp;[1] 1646dev@debian:~$ cat | wc -l &amp;[2] 1648dev@debian:~$ jobs[1]-  Running                 sleep 1000 &amp;[2]+  Stopped                 cat | wc -l</code></pre><p>下面这张图标明了这种情况下它们之间的关系：</p><pre><code>+--------------------------------------------------------------+|                                                              ||      pg1             pg2             pg3            pg4      ||    +------+       +-------+        +-----+        +------+   ||    | bash |       | sleep |        | cat |        | jobs |   ||    +------+       +-------+        +-----+        +------+   || session leader                     | wc  |                   ||                                    +-----+                   ||                                                              |+--------------------------------------------------------------+                            session</code></pre><blockquote><p>pg = process group(进程组)</p></blockquote><ul><li>bash是session的leader，sleep、cat、wc和jobs这四个进程都由bash fork而来，所以他们也属于这个session</li><li>bash也是自己所在进程组的leader</li><li>bash会为自己启动的每个进程都创建一个新的进程组，所以这里sleep和jobs进程属于自己单独的进程组</li><li>对于用管道符号“|”连接起来的命令，bash会将它们放到一个进程组中</li></ul><h2 id="nohup"><a class="header-anchor" href="#nohup">¶</a>nohup</h2><p>nohup是咋回事呢？nohup干了这么几件事：</p><ul><li>将stdin重定向到/dev/null，于是程序读标准输入将会返回EOF</li><li>将stdout和stderr重定向到nohup.out或者用户通过参数指定的文件，程序所有输出到stdout和stderr的内容将会写入该文件（有时在文件中看不到输出，有可能是程序没有调用flush）</li><li>屏蔽掉SIGHUP信号</li><li>调用exec启动指定的命令（nohup进程将会被新进程取代，但进程ID不变）</li></ul><p>从上面nohup干的事可以看出，通过nohup启动的程序有这些特点：</p><ul><li>nohup程序不负责将进程放到后台，这也是为什么我们经常在nohup命令后面要加上符号“&amp;”的原因</li><li>由于stdin、stdout和stderr都被重定向了，nohup启动的程序不会读写tty</li><li>由于stdin重定向到了/dev/null，程序读stdin的时候会收到EOF返回值</li><li>nohup启动的进程本质上还是属于当前session的一个进程组，所以在当前shell里面可以通过jobs看到nohup启动的程序</li><li>当session leader退出后，该进程会收到SIGHUP信号，但由于nohup帮我们忽略了该信号，所以该进程不会退出</li><li>由于session leader已经退出，而nohup启动的进程属于该session，于是出现了一种情况，那就是通过nohup启动的这个进程组所在的session没有leader，这是一种特殊的情况，内核会帮我们处理这种特殊情况，这里就不再深入介绍</li></ul><p>通过nohup，我们最后达到了就算session leader（一般是shell）退出后，进程还可以照常运行的目的。</p><h2 id="deamon"><a class="header-anchor" href="#deamon">¶</a>deamon</h2><p>通过nohup，就可以实现让进程在后台一直执行的功能，为什么我们还要写deamon进程呢？</p><p>从上面的nohup的介绍中可以看出来，虽然进程是在后台执行，但进程跟当前session还是有着千丝万缕的关系，至少其父进程还是被session管着的，所以我们还是需要一个跟任何session都没有关系的进程来实现deamon的功能。实现deamon进程的大概步骤如下：</p><ul><li>调用fork生成一个新进程，然后原来的进程退出，这样新进程就变成了孤儿进程，于是被init进程接收，这样新进程就和调用进程没有父子关系了。</li><li>调用setsid，创建新的session，新进程将成为新session的leader，同时该新session不和任何tty关联。</li><li>切换当前工作目录到其它地方，一般是切换到根目录，这样就取消了对原工作目录的引用，如果原工作目录是某个挂载点下面的目录，这样就不会影响该挂载点的卸载。</li><li>关闭一些从父进程继承过来而自己不需要的fd，避免不小心读写这些fd。</li><li>重定向stdin、stdout和stderr，避免读写它们出现错误。</li></ul><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://www.win.tue.nl/~aeb/linux/lk/lk-10.html" target="_blank" rel="noopener">Processes</a></li><li><a href="https://www.gnu.org/savannah-checkouts/gnu/libc/manual/html_node/Job-Control.html" target="_blank" rel="noopener">Job Control</a></li><li><a href="https://www.ibm.com/developerworks/cn/linux/1702_zhangym_demo/index.html" target="_blank" rel="noopener">那些永不消逝的进程</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux交换空间(swap space)</title>
      <link href="/2020/02/16/linux/linux-jiao-huan-kong-jian-swap-space/"/>
      <url>/2020/02/16/linux/linux-jiao-huan-kong-jian-swap-space/</url>
      
        <content type="html"><![CDATA[<p>每次安装Linux的时候，都会要求配置交换分区，那么这个分区是干嘛的呢？不设置这个分区有什么后果？如果一定要设置，设置多大比较合适？本篇将试图回答这些问题并尽量覆盖所有swap相关的知识。</p><blockquote><p>下面的所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h3 id="什么是swap"><a class="header-anchor" href="#什么是swap">¶</a>什么是swap?</h3><p>swap space是磁盘上的一块区域，可以是一个分区，也可以是一个文件，或者是他们的组合。简单点说，当系统物理内存吃紧时，Linux会将内存中不常访问的数据保存到swap上，这样系统就有更多的物理内存为各个进程服务，而当系统需要访问swap上存储的内容时，再将swap上的数据加载到内存中，这就是我们常说的swap out和swap in。</p><h3 id="为什么需要swap"><a class="header-anchor" href="#为什么需要swap">¶</a>为什么需要swap?</h3><p>要回答这个问题，就需要回答swap给我们带来了哪些好处。</p><ul><li>对于一些大型的应用程序(如LibreOffice、video editor等)，在启动的过程中会使用大量的内存，但这些内存很多时候只是在启动的时候用一下，后面的运行过程中很少再用到这些内存。有了swap后，系统就可以将这部分不这么使用的内存数据保存到swap上去，从而释放出更多的物理内存供系统使用。</li><li>很多发行版(如ubuntu)的休眠功能依赖于swap分区，当系统休眠的时候，会将内存中的数据保存到swap分区上，等下次系统启动的时候，再将数据加载到内存中，这样可以加快系统的启动速度，所以如果要使用休眠的功能，必须要配置swap分区，并且大小一定要大于等于物理内存</li><li>在某些情况下，物理内存有限，但又想运行耗内存的程序怎么办？这时可以通过配置足够的swap空间来达到目标，虽然慢一点，但至少可以运行。</li><li>虽然大部分情况下，物理内存都是够用的，但是总有一些意想不到的状况，比如某个进程需要的内存超过了预期，或者有进程存在内存泄漏等，当内存不够的时候，就会触发内核的OOM killer，根据OOM killer的配置，某些进程会被kill掉或者系统直接重启（默认情况是优先kill耗内存最多的那个进程），不过有了swap后，可以拿swap当内存用，虽然速度慢了点，但至少给了我们一个去debug、kill进程或者保存当前工作进度的机会。</li><li>如果看过<a href="https://segmentfault.com/a/1190000008125006" target="_blank" rel="noopener">Linux内存管理</a>，就会知道系统会尽可能多的将空闲内存用于cache，以加快系统的I/O速度，所以如果能将不怎么常用的内存数据移动到swap上，就会有更多的物理内存用于cache，从而提高系统整体性能。</li></ul><h3 id="swap的缺点"><a class="header-anchor" href="#swap的缺点">¶</a>swap的缺点?</h3><p>上面介绍了swap的优点，那swap的缺点呢？swap是存放在磁盘上的，磁盘的速度和内存比较起来慢了好几个数量级，如果不停的读写swap，那么对系统的性能肯定有影响，尤其是当系统内存很吃紧的时候，读写swap空间发生的频率会很高，导致系统运行很慢，像死了一样，这个时候添加物理内存是唯一的解决办法。</p><blockquote><p>由于系统会自动将不常用的内存数据移到swap上，对桌面程序来说，有可能会导致最小化一个程序后，再打开时小卡一下，因为需要将swap上的数据重新加载到内存中来。</p></blockquote><h3 id="到底要不要swap？"><a class="header-anchor" href="#到底要不要swap？">¶</a>到底要不要swap？</h3><p>上面介绍了什么是swap以及它们的优缺点，那么到底要不要配置swap呢？答案是：看情况。</p><p>下面分别讨论内存不够用、内存勉强够用和内存很充裕这三种情况下服务器和桌面环境对swap的选择。</p><h4 id="内存不够用"><a class="header-anchor" href="#内存不够用">¶</a>内存不够用</h4><p>不管是桌面还是服务器，当物理内存明显不够用，而又想跑程序的话，添加swap是唯一的选择，慢点总比不能工作强。</p><h4 id="内存勉强够用"><a class="header-anchor" href="#内存勉强够用">¶</a>内存勉强够用</h4><p>建议配置swap，这样内核会将不常用的数据从内存移到swap上，从而有更多的物理内存供系统调用，提升系统性能，同时也避免因偶尔的物理内存不够造成进程异常退出，提升系统稳定性，但对服务器来说，一定要限制或者监控swap空间的使用情况，当出现swap空间使用超预期或者swap in/out频繁时，要及时采取措施，不然对性能影响很大</p><h4 id="内存充裕"><a class="header-anchor" href="#内存充裕">¶</a>内存充裕</h4><p>理论上来说，如果物理内存足够多并且不需要休眠功能，那swap就没什么用，可关键问题是我们很难保证物理内存在任何情况下都够用，因为总有意想不到的情况发生，比如某些进程耗内存超预期，服务器压力超预期，内存泄漏等。</p><p>在内存充裕的这种情况下，如果发生异常，swap能帮到我们吗？</p><h5 id="桌面环境"><a class="header-anchor" href="#桌面环境">¶</a>桌面环境</h5><p>一般不会开什么监控功能，所以也没法提前预知内存使用异常，当内存被用光的时候，分两种情况：</p><ul><li>配置了swap：在系统变慢的时候能感觉到，可能还有机会杀掉一些进程和保存当前工作进度，当然也会出现慢的想砸电脑的情况，不过在磁盘如此廉价的情况下，浪费点磁盘空间换取这样的一个机会还是值得的。</li><li>没有配置swap：内核的OOM killer被触发，可能连保存工作进度的机会都没有。</li></ul><h5 id="服务器环境"><a class="header-anchor" href="#服务器环境">¶</a>服务器环境</h5><p>服务器一般都会配置监控程序，当内存用量达到一个阈值的时候告警或者会自动重启异常的进程。但如果没有监控呢？当内存被用光的时候，分两种情况：</p><ul><li>配置了swap：这时服务器还能提供服务，但性能会降低好几个档次，直到最终处于几乎死机状态，并且这一过程将持续很长一段时间，对服务器来说是个灾难；所以配置swap只能让服务再苟延残喘一会儿，然后就是长时间的服务中断(比如原来是每秒处理1000个请求的服务器，由于频繁使用swap，导致现在每秒只能处理50个请求，站在系统角度，进程还在运行，但是在业务角度服务已经几乎中断了)。</li><li>没配置swap：这时内核的OOM killer被触发，在默认配置下，耗内存的进程会被优先kill掉，这种进程一般就是我们的业务进程，这时守护进程就会自动重启该业务进程(没有守护进程？开什么玩笑)，这种情况只会造成服务中断一会会儿(取决于进程重启的时间)，不会出现上面因配置了swap而导致性能很差且服务持续中断的情况。就算OOM killer没有kill掉预期的进程，我们通过测试也能发现，然后将OOM killer配置成重启系统，那也比配置了swap在那里苟延残喘的好。</li></ul><p>从上面可以看出，对服务器来说，似乎不配置swap更好，可以让有问题的进程尽快重启，缩短业务受影响的时间。</p><p>并且，就算没有配置监控程序，我们还有<a href="https://segmentfault.com/a/1190000006917884" target="_blank" rel="noopener">cgroups</a>中的<a href="https://segmentfault.com/a/1190000008125359" target="_blank" rel="noopener">内存控制模块</a>，可以控制一组进程所能使用的最大内存数，当超过这个数的时候，可以触发相应的行为，比如重启进程等。</p><p>总的来说，对于桌面环境来说，一般内存没有服务器端那么充裕，并且由于使用场景原因，会打开很多不同类型的GUI窗口，但前台的进程只有一个，大部分都是在后台待命，所以配置swap对提升性能还是有必要的；对于服务器来说，配置的内存都比较充裕，启动起来的进程也都是要干活的进程(不然就不应该被启动起来)，并且也没有休眠的需求，再加上有了cgroups之后，可以更轻松的限制进程的内存使用，个人认为配置swap基本没什么必要了，看看<a href="https://coreos.com/" target="_blank" rel="noopener">coreos</a>，默认就没有swap。</p><h3 id="swap大小配置多少比较合适？"><a class="header-anchor" href="#swap大小配置多少比较合适？">¶</a>swap大小配置多少比较合适？</h3><p>既然配置swap对桌面系统有帮助，那么配置多少大小的swap比较合适呢？下面是ubuntu给出的建议：</p><ul><li>当物理内存小于1G且不需要休眠时，设置和内存同样大小的swap空间即可；当需要休眠时，建议配置两倍物理内存的大小，但最大值不要超过两倍内存大小</li><li>当物理内存大于1G且不需要休眠时，建议大小为round(sqrt(RAM))，其中RAM为物理内存大小；当需要休眠时，建议大小是RAM+round(sqrt(RAM))，但最大值不要超过两倍内存大小</li><li>如果两倍物理内存大小的swap空间还不够用，建议增加内存而不是增加swap</li></ul><p>下面是详细的不同物理内存情况下的建议，第一列是物理内存的大小，第二列和第三列是不需要和需要休眠两种情况下推荐的大小，第四列是不要超过的最大值</p><pre><code> 物理内存(MB)  不需要休眠  需要休眠  最大值 256          256       512     512 512          512       1024    1024 1024         1024      2048    2048物理内存(GB)  不需要休眠  需要休眠  最大值  1          1         2        2  2          1         3        4  3          2         5        6  4          2         6        8  5          2         7        10  6          2         8        12  8          3         11       16  12         3         15       24  16         4         20       32  24         5         29       48  32         6         38       64  64         8         72       128  128        11       139       256</code></pre><h3 id="怎么配置swap？"><a class="header-anchor" href="#怎么配置swap？">¶</a>怎么配置swap？</h3><p>当我们确定好配置多大的swap空间后，具体应该怎么配置呢？当然可以在系统安装的时候分配好，但如果对安装时分配的大小不满意，我们还可以在后面进行调整。在这里将不介绍安装的时候怎么配，只介绍如何往系统中添加更多的swap空间。</p><p>Linux下有两种类型的swap空间，swap分区和swap文件，他们有各自的特点：</p><ul><li>swap分区上面由于没有文件系统，所以相当于内核直接访问连续的磁盘空间，效率相对要高点，但由于swap分区一般安装系统时就分配好了了，后期要缩减空间和扩容都很不方便。</li><li>swap文件放在指定分区的文件系统里面，所以有可能受文件系统性能的影响，但据说2.6版本以后的内核可以直接访问swap文件对应的物理磁盘地址，相当于跳过了文件系统直接访问磁盘，不过如果swap文件在磁盘上的物理位置不连续时，还是会对性能产生不利影响，但其优点就是灵活，随时可以增加和移除swap文件。</li></ul><h4 id="查看系统中已经配置的swap"><a class="header-anchor" href="#查看系统中已经配置的swap">¶</a>查看系统中已经配置的swap</h4><p>使用命令swapon -s即可查看系统中在用的swap</p><pre><code>dev@dev:~$ swapon -sFilename                Type        Size    Used    Priority/dev/dm-1               partition   524284  0       -1</code></pre><p>如果配置有多个swap分区或者文件的话，这里将会有多行，每行代表一个正在被系统使用的swap分区或文件，下面是每个字段的意思：</p><ul><li>Filename：如果swap类型是分区，这里将是分区的路径，如果swap类型是文件，这里将是文件的路径</li><li>Type：swap的类型，partition代表这是一个swap分区，file代表这是一个swap文件</li><li>Size：swap的大小，单位是k，这里524284表示的差不多是512M</li><li>Used：已经被使用的大小，这里0表示还没有被使用到</li><li>Priority：优先级，优先级高的swap将会被优先使用，同等优先级的swap将会被均匀的使用（round-robin算法），优先级可以通过“swapon -p”命令来设置</li></ul><h4 id="查看系统中swap-in-out的情况"><a class="header-anchor" href="#查看系统中swap-in-out的情况">¶</a>查看系统中swap in/out的情况</h4><p>并不是swap空间占用多就一定性能下降，真正影响性能是swap in和out的频率，频率越高，对系统的性能影响越大，我们可以通过vmstat命令来查看swap in/out的频率</p><pre><code>#参数2表示每两秒统计一次，si和so两列就是每秒swap in和out的次数dev@ubuntu:~$ vmstat 2procs------------memory--------------swap----io-----system-----------cpu----- r b    swpd  free  buff cache      si so   bi bo   in  cs      us sy id wa st 0 0    70232 75620 7940 209476     0  0    0  0    111 180     0  1  99 0  0 0 0    70232 75620 7940 209476     0  0    0  0    116 186     1  1  99 0  0 0 0    70228 75620 7940 209476     2  0    2  0    120 193     1  1  98 1  0 0 0    70228 75620 7940 209476     0  0    0  0    117 186     0  0  100 0 0 0 0    70228 75620 7940 209476     0  0    0  0    113 184     0  1  99 0  0</code></pre><h4 id="添加swap分区"><a class="header-anchor" href="#添加swap分区">¶</a>添加swap分区</h4><p>在添加swap分区前，首先得有一个空闲的分区，如果是一块新的磁盘，可以用fdisk来创建一个新的分区用于swap。</p><blockquote><p><strong>注意</strong>：磁盘分区操作一定要小心，弄不好就会造成数据丢失、系统挂掉的后果。磁盘分区操作不是本篇要介绍的内容，所以这里不会讨论fdisk怎么用。</p></blockquote><pre><code>#本篇使用的测试环境是虚拟机，/dev/sdb是一块新加的硬盘并且已经用fdisk创建好了一个分区#本例中将使用/dev/sdb1这个分区dev@dev:~$ sudo fdisk -l /dev/sdbDevice     Boot Start     End Sectors Size Id Type/dev/sdb1        2048 4194303 4192256   2G 83 Linux#创建swap分区dev@dev:~$ sudo mkswap /dev/sdb1Setting up swapspace version 1, size = 2 GiB (2146430976 bytes)no label, UUID=d69621de-618a-4bea-9a96-b8e8b0d0ea40#查看系统中现在正在使用的swap，以便于和添加后做比较dev@dev:~$ swapon -sFilename                Type        Size    Used    Priority/dev/dm-1                               partition   524284  0   -1#将新的分区加入到系统中dev@dev:~$ sudo swapon /dev/sdb1#这时候可以看到新的swap分区已经被加入到系统中了，并且优先级比原来的要低dev@dev:~$ swapon -sFilename                Type        Size    Used    Priority/dev/dm-1               partition   524284  0       -1/dev/sdb1               partition   2096124 0       -2#为了保证系统重启后会自动加载我们新的swap分区，需要修改/etc/fstab文件dev@dev:~$ sudo sh -c 'echo &quot;/dev/sdb1 none  swap    sw   0    0&quot; &gt;&gt; /etc/fstab'#查看一下，确保写入成功，这里的第一条是原来的系统的swap分区，第二条是我们刚添加的dev@dev:~$ grep swap /etc/fstab/dev/mapper/dev--vg-swap_1 none            swap    sw              0       0/dev/sdb1 none  swap    sw   0    0</code></pre><h4 id="添加swap文件"><a class="header-anchor" href="#添加swap文件">¶</a>添加swap文件</h4><p>添加swap文件就简单多了，也没有分区操作那么有风险。</p><pre><code>#先创建一个新的512M的文件，用来作为swap文件，文件路径可以随便#fallocate这个命令依赖于文件系统，有些老的文件系统不支持这个命令，比如ext2，#这种情况下可以用dd来实现同样的效果：#sudo dd if=/dev/zero of=/mnt/512MiB.swap bs=1024 count=524288#fallocate和dd的区别在于：#fallocate是先声明这么多，然后在具体用到的时候文件系统才分配真正的物理磁盘空间，就是用一点分配一点，#而dd是一开始就实实在在的写了512m的数据到物理磁盘空间。#所以作为测试来说fallocate方便些，因为刚开始不用写任何数据，要快dev@dev:~$ sudo fallocate -l 512m /mnt/512MiB.swap#修改文件的权限，避免其他用户对这个文件进行误操作dev@dev:~$ sudo chmod 600 /mnt/512MiB.swap#格式化为swap文件dev@dev:~$ sudo mkswap /mnt/512MiB.swap#将新的文件加入到系统中dev@dev:~$ sudo swapon /mnt/512MiB.swap#这时候可以看到新的swap文件已经被加入到系统中了，类型为file#这里可以看到由于优先级最高，第一个swap分区/dev/dm-1已经被使用了24Kdev@dev:~$ swapon -sFilename                Type        Size    Used    Priority/dev/dm-1               partition   524284  24      -1/dev/sdb1               partition   2096124 0       -2/mnt/512MiB.swap        file        524284  0       -3#从free命令的输出可以看到，经过前面两轮添加swap分区和文件，#现在系统的交换空间已经变成3G(3144692K)了dev@dev:~$ free              total        used        free      shared  buff/cache   availableMem:         500192       39112        9564        1996      451516      430820Swap:       3144692          24     3144668#同样为了保证系统重启后会自动加载我们新的swap文件，需要修改/etc/fstab文件dev@dev:~$ sudo sh -c 'echo &quot;/mnt/512MiB.swap none  swap    sw   0    0&quot; &gt;&gt; /etc/fstab'</code></pre><blockquote><p>注意：不是所有的文件系统都支持创建swap文件，如btrfs，在btrfs分区里创建swap文件将失败。</p></blockquote><h4 id="取消所有的swap"><a class="header-anchor" href="#取消所有的swap">¶</a>取消所有的swap</h4><p>如果经过深思熟虑之后，确定不再需要swap，那么可以将所有的swap分区和文件从系统中移除，步骤和上面的刚好相反</p><pre><code>#停掉所有系统正在使用的swapdev@dev:~$ sudo swapoff -a#swapon -s命令没有任何输出，free命令显示swap空间为0，说明swapoff成功dev@dev:~$ swapon -sdev@dev:~$ free              total        used        free      shared  buff/cache   availableMem:         500192       35924      348888        2004      115380      433924Swap:             0           0           0#当然我们还需要修改/etc/fstab，否则下次重启后，系统又会重新挂载相应的swap分区和文件#使用自己喜欢的编辑器，将/etc/fstab中跟swap相关的三行删掉即可(本例中是三行，请根据实际情况调整)</code></pre><h3 id="如何优化swap性能"><a class="header-anchor" href="#如何优化swap性能">¶</a>如何优化swap性能?</h3><p>怎么配置swap可以让它的性能更好呢？</p><ul><li>尽量使用swap分区，相对于swap文件来说，分区肯定是连续的物理磁盘空间，而swap文件有可能不是</li><li>将swap分区和系统所在的分区放在不同的磁盘上，这样就不会和系统盘抢同一个磁盘的I/O带宽</li><li>如果有多块磁盘的话，可以在每个盘上创建一个swap分区，并且将它们的优先级设置的一样，这样内核就会平均的访问这些swap分区，性能相当于原来的N倍(这里N是磁盘的数量)</li></ul><p>不过话又说回来了，如果频繁的访问swap的话，怎么优化swap都没用，跟内存比还是低几个数量级，性能还是下降的厉害，如果不频繁访问swap的话，优化swap又有啥意义呢？所以其实优化swap性能的实际意义不大，这里了解一下就好。</p><h2 id="配置swappiness"><a class="header-anchor" href="#配置swappiness">¶</a>配置swappiness</h2><p>有时我们桌面环境确实配置了比较充裕的内存，并且也配置了swap空间，这个时候就希望尽量减少swap空间的使用，避免对系统性能造成影响，Linux早就帮我们考虑到这种情况了，在2.6内核中，增加了一个叫做swappiness的参数，用于配置需要将内存中不常用的数据移到swap中去的紧迫程度。这个参数的取值范围是0～100，0告诉内核尽可能的不要将内存数据移到swap中，也即只有在迫不得已的情况下才这么做，而100告诉内核只要有可能，尽量的将内存中不常访问的数据移到swap中。</p><p>Ubuntu的desktop和server的默认配置都是60(可能会随着版本变化)，对于桌面环境来说，界面的响应速度直接关系到系统的流畅程度，如果内存比较充裕的话，可以将这个值设置的小一点，这样就尽可能的把数据留在内存中，从而唤醒后台界面程序会更快一些，Ubuntu desktop建议将该值设置为10，当然大家可以根据swap空间的实际使用情况，任意调整这个参数，直到自己满意的水平为止。对于服务器来说，主要性能衡量标准是整体的处理能力，而不是具体某一次的响应速度，能把更多的内存用来做I/O cache可能效果更好，所以Ubuntu server建议保持60的默认值。</p><ul><li>查看当前系统中swappiness的值</li></ul><pre><code>dev@dev:~$ cat /proc/sys/vm/swappiness60</code></pre><ul><li>修改当前系统中swappiness的值</li></ul><pre><code>dev@dev:~$ sudo sysctl vm.swappiness=10vm.swappiness = 10dev@dev:~$ cat /proc/sys/vm/swappiness10</code></pre><p>上面通过sysctl修改的swappiness值在系统重启后会失效，要想重启后继续生效，需要修改配置文件/etc/sysctl.conf，将下面这行修改成10，如果文件中找不到这行的话，在文件末位加上这行就可以了</p><pre><code>vm.swappiness=10</code></pre><h3 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h3><ul><li><a href="https://www.linux.com/news/all-about-linux-swap-space" target="_blank" rel="noopener">All about Linux swap space</a></li><li><a href="https://help.ubuntu.com/community/SwapFaq" target="_blank" rel="noopener">Swap Faq</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux内存管理</title>
      <link href="/2020/02/16/linux/linux-nei-cun-guan-li/"/>
      <url>/2020/02/16/linux/linux-nei-cun-guan-li/</url>
      
        <content type="html"><![CDATA[<p>在linux下，使用top，vmstat,free等命令查看系统或者进程的内存使用情况时，经常看到buff/cache memeory，swap，avail Mem等，他们都代表什么意思呢？这篇文章将来聊一聊Linux下的内存管理并解答这个问题。</p><p>讨论Linux下的内存管理其实就是讨论Linux下虚拟内存的实现方式，本人不是内核专家，所以这篇文章只会介绍一些概念性的东西，不会深入实现细节，有些地方描述的有可能不精确。</p><p>在早些时候，物理内存比较有限，人们希望程序可以使用的内存空间能超过实际物理内存，于是出现了虚拟内存的概念，不过随着时间的推移，虚拟内存的意义已经远远的超过了最初的想法。</p><h2 id="虚拟内存"><a class="header-anchor" href="#虚拟内存">¶</a>虚拟内存</h2><p>虚拟内存是Linux管理内存的一种技术。它使得每个应用程序都认为自己拥有独立且连续的可用的内存空间（一段连续完整的地址空间），而实际上，它通常是被映射到多个物理内存段，还有部分暂时存储在外部磁盘存储器上，在需要时再加载到内存中来。</p><p>每个进程所能使用的虚拟地址大小和CPU位数有关，在32位的系统上，虚拟地址空间大小是4G，在64位系统上，是2^64=？（算不过来了）。而实际的物理内存可能远远小于虚拟地址空间的大小。</p><p>虚拟地址和进程息息相关，不同进程里的同一个虚拟地址指向的物理地址不一定一样，所以离开进程谈虚拟地址没有任何意义。</p><blockquote><p><strong>注意</strong>：网上很多文章将虚拟内存等同于交换空间，其实描述不够严谨，交换空间只是虚拟内存这张大蓝图中的一部分。</p></blockquote><h2 id="虚拟内存和物理内存的关系"><a class="header-anchor" href="#虚拟内存和物理内存的关系">¶</a>虚拟内存和物理内存的关系</h2><p>下面这张表很直观的表述了它们之间的关系</p><pre><code>  进程X                                                                      进程Y+-------+                                                                  +-------+| VPFN7 |--+                                                               | VPFN7 |+-------+  |       进程X的                                 进程Y的           +-------+| VPFN6 |  |      Page Table                              Page Table     +-| VPFN6 |+-------+  |      +------+                                +------+       | +-------+| VPFN5 |  +-----&gt;| .... |---+                    +-------| .... |&lt;---+  | | VPFN5 |+-------+         +------+   |        +------+    |       +------+    |  | +-------+| VPFN4 |    +---&gt;| .... |---+-+      | PFN4 |    |       | .... |    |  | | VPFN4 |+-------+    |    +------+   | |      +------+    |       +------+    |  | +-------+| VPFN3 |--+ |    | .... |   | | +---&gt;| PFN3 |&lt;---+  +----| .... |&lt;---+--+ | VPFN3 |+-------+  | |    +------+   | | |    +------+       |    +------+    |    +-------+| VPFN2 |  +-+---&gt;| .... |---+-+-+    | PFN2 |&lt;------+    | .... |    |    | VPFN2 |+-------+    |    +------+   | |      +------+            +------+    |    +-------+| VPFN1 |    |               | +-----&gt;| FPN1 |                        +----| VPFN1 |+-------+    |               |        +------+                             +-------+| VPFN0 |----+               +-------&gt;| PFN0 |                             | VPFN0 |+-------+                             +------+                             +-------+ 虚拟内存                               物理内存                               虚拟内存PFN(the page frame number)： 页编号</code></pre><p>当进程执行一个程序时，需要先从先内存中读取该进程的指令，然后执行，获取指令时用到的就是虚拟地址，这个地址是程序链接时确定的（内核加载并初始化进程时会调整动态库的地址范围），为了获取到实际的数据，CPU需要将虚拟地址转换成物理地址，CPU转换地址时需要用到进程的page table，而page table里面的数据由操作系统维护。</p><blockquote><p>注意：Linux内核代码访问内存时用的都是实际的物理地址，所以不存在虚拟地址到物理地址的转换，只有应用层程序才需要。</p></blockquote><p>为了转换方便，Linux将虚拟内存和物理内存都拆分为固定大小的页，x86的系统一般内存页大小是4K，每个页都会分配一个唯一的编号，这就是页编号（PFN）.</p><p>从上面的图中可以看出，虚拟内存和物理内存的page之间通过page table进行映射。进程X和Y的虚拟内存是相互独立的，且page table也是独立的，它们之间共享物理内存。进程可以随便访问自己的虚拟地址空间，而page table和物理内存由内核维护。当进程需要访问内存时，CPU会根据进程的page table将虚拟地址翻译成物理地址，然后进行访问。</p><blockquote><p>注意：并不是每个虚拟地址空间的page都有对应的Page Table相关联，只有虚拟地址被分配给进程后，也即进程调用类似malloc函数之后，系统才会为相应的虚拟地址在Page Table中添加记录，如果进程访问一个没有和Page Table关联的虚拟地址，系统将会抛出SIGSEGV信号，导致进程退出，这也是为什么我们访问野指针时会经常出现segmentfault的原因。换句话说，虽然每个进程都有4G（32位系统）的虚拟地址空间，但只有向系统申请了的那些地址空间才能用，访问未分配的地址空间将会出segmentfault错误。Linux会将虚拟地址0不映射到任何地方，这样我们访问空指针就一定会报segmentfault错误。</p></blockquote><h2 id="虚拟内存的优点"><a class="header-anchor" href="#虚拟内存的优点">¶</a>虚拟内存的优点</h2><ul><li>更大的地址空间：并且是连续的，使得程序编写、链接更加简单</li><li>进程隔离：不同进程的虚拟地址之间没有关系，所以一个进程的操作不会对其它进程造成影响</li><li>数据保护：每块虚拟内存都有相应的读写属性，这样就能保护程序的代码段不被修改，数据块不能被执行等，增加了系统的安全性</li><li>内存映射：有了虚拟内存之后，可以直接映射磁盘上的文件（可执行文件或动态库）到虚拟地址空间，这样可以做到物理内存延时分配，只有在需要读相应的文件的时候，才将它真正的从磁盘上加载到内存中来，而在内存吃紧的时候又可以将这部分内存清空掉，提高物理内存利用效率，并且所有这些对应用程序来说是都透明的</li><li>共享内存：比如动态库，只要在内存中存储一份就可以了，然后将它映射到不同进程的虚拟地址空间中，让进程觉得自己独占了这个文件。进程间的内存共享也可以通过映射同一块物理内存到进程的不同虚拟地址空间来实现共享</li><li>物理内存管理：物理地址空间全部由操作系统管理，进程无法直接分配和回收，从而系统可以更好的利用内存，平衡进程间对内存的需求</li><li>其它：有了虚拟地址空间后，交换空间和COW（copy on write）等功能都能很方便的实现</li></ul><h2 id="page-table"><a class="header-anchor" href="#page-table">¶</a>page table</h2><p>page table可以简单的理解为一个memory mapping的链表（当然实际结构很复杂），里面的每个memory mapping都将一块虚拟地址映射到一个特定的资源（物理内存或者外部存储空间）。每个进程拥有自己的page table，和其它进程的page table没有关系。</p><h2 id="memory-mapping"><a class="header-anchor" href="#memory-mapping">¶</a>memory mapping</h2><p>每个memory mapping就是对一段虚拟内存的描述，包括虚拟地址的起始位置，长度，权限(比如这段内存里的数据是否可读、写、执行), 以及关联的资源(如物理内存page，swap空间上的page，磁盘上的文件内容等)。</p><p>当进程申请内存时，系统将返回虚拟内存地址，同时为相应的虚拟内存创建memory mapping并将它放入page table，但这时系统不一定会分配相应的物理内存，系统一般会在进程真正访问这段内存的时候才会分配物理内存并关联到相应的memory mapping，这就是所谓的延时分配/按需分配。</p><p>每个memory mapping都有一个标记，用来表示所关联的物理资源类型，一般分两大类，那就是anonymous和file backed，在这两大类中，又分了一些小类，比如anonymous下面有更具体的shared和copy on write类型, file backed下面有更具体的device backed类型。下面是每个类型所代表的意思：</p><h4 id="file-backed"><a class="header-anchor" href="#file-backed">¶</a>file backed</h4><p>这种类型表示memory mapping对应的物理资源存放在磁盘上的文件中，它所包含的信息包括文件的位置、offset、rwx权限等。</p><p>当进程第一次访问对应的虚拟page的时候，由于在memory mapping中找不到对应的物理内存，CPU会报page fault中断，然后操作系统就会处理这个中断并将文件的内容加载到物理内存中，然后更新memory mapping，这样下次CPU就能访问这块虚拟地址了。以这种方式加载到内存的数据一般都会放到page cache中，关于page cache会在后面介绍到.</p><p>一般程序的可执行文件，动态库都是以这种方式映射到进程的虚拟地址空间的。</p><h4 id="device-backed"><a class="header-anchor" href="#device-backed">¶</a>device backed</h4><p>和file backed类似，只是后端映射到了磁盘的物理地址，比如当物理内存被swap out后，将被标记为device backed。</p><h4 id="anonymous"><a class="header-anchor" href="#anonymous">¶</a>anonymous</h4><p>程序自己用到的数据段和堆栈空间，以及通过mmap分配的共享内存，它们在磁盘上找不到对应的文件，所以这部分内存页被叫做anonymous page。anonymous page和file backed最大的差别是当内存吃紧时，系统会直接删除掉file backed对应的物理内存，因为下次需要的时候还能从磁盘加载到内存，但anonymous page不能被删除，只能被swap out。</p><h4 id="shared"><a class="header-anchor" href="#shared">¶</a>shared</h4><p>不同进程的Page Table里面的多个memory mapping可以映射到相同的物理地址，通过虚拟地址（不同进程里的虚拟地址可能不一样）可以访问到相同的内容，当一个进程里面修改内存的内容后，在另一个进程中可以立即读取到。这种方式一般用来实现进程间高速的共享数据（如mmap）。当标记为shared的memory mapping被删除回收时，需要更新物理page上的引用计数，便于物理page的计数变0后被回收。</p><h4 id="copy-on-write"><a class="header-anchor" href="#copy-on-write">¶</a>copy on write</h4><p>copy on write基于shared技术，当读这种类型的内存时，系统不需要做任何特殊的操作，而当要写这块内存时，系统将会生成一块新的内存并拷贝原来内存中的数据到新内存中，然后将新内存关联到相应的memory mapping，然后执行写操作。Linux下很多功能都依赖于copy on write技术来提高性能，比如fork等。</p><p>通过上面的介绍，我们可以简单的将内存的使用过程总结如下：</p><ol><li>进程向系统发出内存申请请求</li><li>系统会检查进程的虚拟地址空间是否被用完，如果有剩余，给进程分配虚拟地址</li><li>系统为这块虚拟地址创建相应的memory mapping（可能多个），并将它放进该进程的page table</li><li>系统返回虚拟地址给进程，进程开始访问该虚拟地址</li><li>CPU根据虚拟地址在该进程的page table中找到了相应的memory mapping，但是该mapping没有和物理内存关联，于是产生缺页中断</li><li>操作系统收到缺页中断后，分配真正的物理内存并将它关联到相应的memory mapping</li><li>中断处理完成后，CPU就可以访问该内存了</li></ol><p>当然缺页中断不是每次都会发生，只有系统觉得有必要延迟分配内存的时候才用的着，也即很多时候在上面的第3步系统会分配真正的物理内存并和memory mapping关联。</p><h2 id="其它概念"><a class="header-anchor" href="#其它概念">¶</a>其它概念</h2><p>操作系统只要实现了虚拟内存和物理内存之间的映射关系，就能正常工作了，但要使内存访问更高效，还有很多东西需要考虑，在这里我们可以看看跟内存有关的一些其它概念以及它们的作用。</p><h3 id="MMU（Memory-Management-Unit）"><a class="header-anchor" href="#MMU（Memory-Management-Unit）">¶</a>MMU（Memory Management Unit）</h3><p>MMU是CPU的一个用来将进程的虚拟地址转换成物理地址的模块，简单点说，这个模块的输入是进程的page table和虚拟地址，输出是物理地址。将虚拟地址转换成物理地址的速度直接影响着系统的速度，所以CPU包含了这个模块用来加速。</p><h3 id="TLB（Translation-Lookaside-Buffer）"><a class="header-anchor" href="#TLB（Translation-Lookaside-Buffer）">¶</a>TLB（Translation Lookaside Buffer）</h3><p>上面介绍到，MMU的输入是page table，而page table又存在内存里面，跟CPU的cache相比，内存的速度很慢，所以为了进一步加快虚拟地址到物理地址的转换速度，Linux发明了TLB，它存在于CPU的L1 cache里面，用来缓存已经找到的虚拟地址到物理地址的映射，这样下次转换前先查一下TLB，如果已经在里面了就不需要调用MMU了.</p><h3 id="按需分配物理页"><a class="header-anchor" href="#按需分配物理页">¶</a>按需分配物理页</h3><p>由于实际情况下物理内存要比虚拟内存少很多，所以操作系统必须很小心的分配物理内存，以使内存的使用率达到最大化。一个节约物理内存的办法就是只加载当前正在使用的虚拟page对应的数据到内存。比如，一个很大的数据库程序，如果你只是用了查询操作，那么负责插入删除等部分的代码段就没必要加载到内存中，这样就能节约很多物理内存，这种方法就叫做物理内存页按需分配，也可以称作延时加载。</p><p>其实现原理很简单，就是当CPU访问一个虚拟内存页的时候，如果这个虚拟内存页对应的数据还没加载到物理内存中，则CPU就会通知操作系统发生了page fault，然后由操作系统负责将数据加载进物理内存。由于将数据加载进内存比较耗时，所以CPU不会等在那里，而是去调度其它进程，当它下次再调度到该进程时，数据已经在物理内存上了。</p><p>Linux主要使用这种方式来加载可执行文件和动态库，当程序被内核开始调度执行时，内核将进程的可执行文件和动态库映射到进程的虚拟地址空间，并只加载马上要用到的那小部分数据到物理内存中，其它的部分只有当CPU访问到它们时才去加载。</p><h3 id="交换空间"><a class="header-anchor" href="#交换空间">¶</a>交换空间</h3><p>当一个进程需要加载数据到物理内存中，但实际的物理内存已经被用完时，操作系统需要回收一些物理内存中的page以满足当前进程的需要。</p><p>对于file backed的内存数据，即物理内存里面的数据来自于磁盘上的文件，那么内核将直接将该部分数据从内存中移除掉来释放出更多的内存，当下次有进程需要访问这部分数据时，再将它从磁盘上加载到内存中来。但是，如果这部分数据被修改过且没被写入文件，那这部分数据就变成了脏数据，脏数据不能被直接删掉，只能被移动到交换空间上去。（可执行文件和动态库文件不会被修改，但通过mmap+private的方式映射到内存的磁盘文件有可能被修改，这种方式映射的内存比较特殊，没修改之前是file backed，修改后但没有写回磁盘之前就变成了anonymous的）</p><p>对于anonymous的内存数据，在磁盘上没有对应的文件，这部分数据不能直接被删除，而是被系统移到交换空间上去。交换空间就是磁盘上预留的一块特殊空间，被系统用来临时存放内存中不常被访问的数据，当下次有进程需要访问交换空间上的数据时，系统再将数据加载到内存中。由于交换空间在磁盘上，所以访问速度要比内存慢很多，频繁的读写交换空间会带来性能问题。</p><p>关于swap空间的详细介绍请参考<a href="https://segmentfault.com/a/1190000008125116" target="_blank" rel="noopener">Linux交换空间</a></p><h3 id="共享内存"><a class="header-anchor" href="#共享内存">¶</a>共享内存</h3><p>有了虚拟内存之后，进程间共享内存变得特别的方便。进程所有的内存访问都通过虚拟地址来实现，而每个进程都有自己的page tables。当两个进程共享一块物理内存时，只要将物理内存的页号映射到两个进程的page table中就可以了，这样两个进程就可以通过不同的虚拟地址来访问同一块物理内存。</p><p>从上面的那个图中可以看出，进程X和进程Y共享了物理内存页PFN3，在进程X中，PFN3被映射到了VPFN3，而在进程Y中，PFN3被映射到了VPFN1，但两个进程通过不同的虚拟地址访问到的物理内存是同一块。</p><h3 id="访问控制"><a class="header-anchor" href="#访问控制">¶</a>访问控制</h3><p>page table里面的每条虚拟内存到物理内存的映射记录（memory mapping）都包含一份控制信息，当进程要访问一块虚拟内存时，系统可以根据这份控制信息来检查当前的操作是否是合法的。</p><p>为什么需要做这个检查呢？比如有些内存里面放的是程序的可执行代码，那么就不应该去修改它；有些内存里面存放的是程序运行时用到的数据，那么这部分内存只能被读写，不应该被执行；有些内存里面存放的是内核的代码，那么在用户态就不应该去执行它；有了这些检查之后会大大增强系统的安全性。</p><h3 id="huge-pages"><a class="header-anchor" href="#huge-pages">¶</a>huge pages</h3><p>由于CPU的cache有限，所以TLB里面缓存的数据也有限，而采用了huge page后，由于每页的内存变大（比如由原来的4K变成了4M），虽然TLB里面的纪录数没变，但这些纪录所能覆盖的地址空间变大，相当于同样大小的TLB里面能缓存的映射范围变大，从而减少了调用MMU的次数，加快了虚拟地址到物理地址的转换速度。</p><h3 id="Caches"><a class="header-anchor" href="#Caches">¶</a>Caches</h3><p>为了提高系统性能，Linux使用了一些跟内存管理相关的cache，并且尽量将空闲的内存用于这些cache。这些cache都是系统全局共享的：</p><ul><li>Buffer Cache<br>用来缓冲块设备上的数据，比如磁盘，当读写块设备时，系统会将相应的数据存放到这个cache中，等下次再访问时，可以直接从cache中拿数据，从而提高系统效率。它里面的数据结构是一个块设备ID和block编号到具体数据的映射，只要根据块设备ID和块的编号，就能找到相应的数据。</li><li>Page Cache<br>这个cache主要用来加快读写磁盘上文件的速度。它里面的数据结构是文件ID和offset到文件内容的映射，根据文件ID和offset就能找到相应的数据（这里文件ID可能是inode或者path，本人没有仔细去研究）。</li></ul><p>从上面的定义可以看出，page cache和buffer cache有重叠的地方，不过实际情况是buffer cache只缓存page cache不缓存的那部分内容，比如磁盘上文件的元数据。所以一般情况下和page cache相比，Buffer Cache的大小基本可以忽略不计。</p><p>当然，使用cache也有一些不好的地方，比如需要时间和空间去维护cache，cache一旦出错，整个系统就挂了。</p><h2 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h2><p>有了上面介绍的知识，再来看看我们刚开始提出来的问题，以top命令的输出为例：</p><pre><code>KiB Mem :   500192 total,   349264 free,    36328 used,   114600 buff/cacheKiB Swap:   524284 total,   524284 free,        0 used.   433732 avail Mem</code></pre><p>KiB Mem代表物理内存，KiB Swap代表交换空间，它们的单位都是KiB。</p><p>total、used和free没什么好介绍的，就是总共多少，然后用了多少，还剩多少。</p><p>buff/cached代表了buff和cache总共用了多少，buff代表buffer cache占了多少空间，由于它主要用来缓存磁盘上文件的元数据，所以一般都比较小，跟cache比可以忽略不计；cache代表page cache和其它一些占用空间比较小且大小比较固定的cache的总和，基本上cache就约等于page cache，page cache的准确值可以通过查看/proc/meminf中的Cached得到。由于page cache是用来缓存磁盘上文件内容的，所以占有空间很大，Linux一般会尽可能多的将空闲物理内存用于page cache。</p><p>avail Mem表示可用于进程下一次分配的物理内存数量，这个大小一般比free大一点，因为除了free的空间外，系统还能立即释放出一些空间来。</p><p>那么怎么判断当前内存使用情况出现了异常呢？有下面几点供参考：</p><ul><li>Mem free的值比较小，并且buff/cache的值也小<br>free的值比较少并不一定代表有问题，因为Linux会尽可能多的将内存用于page cache，但是如果buff/cache的值也小，就说明内存吃紧了，系统没有足够多的内存用于cache，如果当前服务器部署是一个需要频繁的读写磁盘的应用，如FTP服务器，那么对性能的影响将会非常大。</li><li>Swap used的值比较大，<br>这种情况比上面的更严重，正常情况下swap应该很少被使用，used值比较大说明交换空间被使用的比较多，如果通过vmstat命令看到swap in/out的比较频繁的话，说明系统内存严重不足，整体性能已经受到严重影响</li></ul><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="http://www.tldp.org/LDP/tlk/mm/memory.html" target="_blank" rel="noopener">Memory Management</a></li><li><a href="http://landley.net/writing/memory-faq.txt" target="_blank" rel="noopener">Mmemory FAQ</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux下常见文件系统对比</title>
      <link href="/2020/02/16/linux/linux-xia-chang-jian-wen-jian-xi-tong-dui-bi/"/>
      <url>/2020/02/16/linux/linux-xia-chang-jian-wen-jian-xi-tong-dui-bi/</url>
      
        <content type="html"><![CDATA[<p>本文将对Linux下常见的几种文件系统进行对比，包括ext2、ext3、ext4、XFS和Btrfs，希望能帮助大家更好的选择合适的文件系统。</p><blockquote><p>内容来自于网上找的资料以及自己的一些经验，能力有限，错误在所难免，仅供参考</p></blockquote><h2 id="历史"><a class="header-anchor" href="#历史">¶</a>历史</h2><table><thead><tr><th>文件系统</th><th>创建者</th><th>创建时间</th><th>最开始支持的平台</th></tr></thead><tbody><tr><td><a href="https://en.wikipedia.org/wiki/Ext2" target="_blank" rel="noopener">ext2</a></td><td><a href="https://en.wikipedia.org/wiki/R%C3%A9my_Card" target="_blank" rel="noopener">Rémy Card</a></td><td>1993</td><td>Linux,<a href="https://en.wikipedia.org/wiki/GNU_Hurd" target="_blank" rel="noopener">Hurd</a></td></tr><tr><td><a href="https://en.wikipedia.org/wiki/XFS" target="_blank" rel="noopener">XFS</a></td><td><a href="https://en.wikipedia.org/wiki/Silicon_Graphics" target="_blank" rel="noopener">SGI</a></td><td>1994</td><td><a href="https://en.wikipedia.org/wiki/IRIX" target="_blank" rel="noopener">IRIX</a>, Linux, FreeBSD</td></tr><tr><td><a href="https://en.wikipedia.org/wiki/Ext3" target="_blank" rel="noopener">ext3</a></td><td><a href="https://en.wikipedia.org/wiki/Stephen_Tweedie" target="_blank" rel="noopener">Dr. Stephen C. Tweedie</a></td><td>1999</td><td>Linux</td></tr><tr><td><a href="https://en.wikipedia.org/wiki/ZFS" target="_blank" rel="noopener">ZFS</a></td><td>Sun</td><td>2004</td><td>Solaris</td></tr><tr><td><a href="https://en.wikipedia.org/wiki/Ext4" target="_blank" rel="noopener">ext4</a></td><td>众多开发者</td><td>2006</td><td>Linux</td></tr><tr><td><a href="https://en.wikipedia.org/wiki/Btrfs" target="_blank" rel="noopener">Btrfs</a></td><td>Oracle</td><td>2007</td><td>Linux</td></tr></tbody></table><p>从创建时间可以看出他们所处的不同时代，因为Btrfs的实现借鉴自ZFS，所以这里也将ZFS列出来作为参考。</p><h2 id="大小限制"><a class="header-anchor" href="#大小限制">¶</a>大小限制</h2><table><thead><tr><th>文件系统</th><th>最大文件名长度</th><th>最大文件大小</th><th>最大分区大小</th></tr></thead><tbody><tr><td>ext2</td><td>255 bytes</td><td>2 TB</td><td>16 TB</td></tr><tr><td>ext3</td><td>255 bytes</td><td>2 TB</td><td>16 TB</td></tr><tr><td>ext4</td><td>255 bytes</td><td>16 TB</td><td>1 EB</td></tr><tr><td>XFS</td><td>255 bytes</td><td>8 EB</td><td>8 EB</td></tr><tr><td>Btrfs</td><td>255 bytes</td><td>16 EB</td><td>16 EB</td></tr></tbody></table><p>最大文件和分区大小受格式化分区时所采用的块大小（block size）所影响，块越大，所支持的最大文件和分区越大，也越可能浪费磁盘空间，上表列出的数据基于4K的块大小。</p><h2 id="代码规模"><a class="header-anchor" href="#代码规模">¶</a>代码规模</h2><p>从代码规模可以看出文件系统的功能丰富程度以及复杂度，下面列出的数据来自于kernel-4.1-rc8，只是简单的用wc -l来统计，没有过滤空行、注释等。</p><table><thead><tr><th>文件系统</th><th>源文件(.c)</th><th>头文件(.h)</th></tr></thead><tbody><tr><td>ext2</td><td>8363</td><td>1016</td></tr><tr><td>ext3</td><td>16496</td><td>1567</td></tr><tr><td>ext4</td><td>44650</td><td>4522</td></tr><tr><td>XFS</td><td>89605</td><td>15091</td></tr><tr><td>Btrfs</td><td>105254</td><td>7933</td></tr></tbody></table><ul><li>Btrfs还在快速的开发过程中，代码行数可能还有比较大的变化</li><li>XFS和Btrfs都使用了B-tree</li></ul><h2 id="ext2"><a class="header-anchor" href="#ext2">¶</a>ext2</h2><p>ext的优点是比较简单，文件比较少时性能较好，比较适合文件少的场景，主要缺点如下</p><ul><li>inode的数量是固定不变的，在格式化分区的时候可以指定inode和数据块所占空间的比例，但一旦格式化好，后续就没法再改变了</li><li>当块大小为4K时，单个文件大小不能超过2TB，分区大小不能超过16TB（目前硬盘大小一般都只有几TB，所以也不是什么大问题，）</li><li>一个目录下最多只能有32000个子目录</li><li>由于目录里面存储的文件和子目录都是以线性方式来组织的，所以遍历目录效率不高，尤其当目录下文件个数达到10K以上规模的时候，速度会明显的变慢</li><li>当底层的磁盘分区空间变大时（使用LVM时很常见），ext2没法动态的扩展来使用增加的空间</li><li>没有日志（Journal）功能，所以数据的安全性不高</li></ul><h2 id="ext3"><a class="header-anchor" href="#ext3">¶</a>ext3</h2><p>ext3在ext2的基础上实现了下面几个功能，其它的都保持不变，即ext2的缺点ext3也有</p><ul><li>支持日志（Journal）功能，数据的安全性较ext2有很大的提高</li><li>当底层的分区空间变大时，ext3可以自动扩展来使用增加的空间</li><li>使用HTree来组织目录里面的文件和子目录，使目录下的文件和子目录数不再受性能限制（数量超过10K也不会有性能问题）</li></ul><h2 id="ext4"><a class="header-anchor" href="#ext4">¶</a>ext4</h2><p>ext4借鉴了当前成熟的一些文件系统技术，在ext3上增加了一些功能，并且对性能做了一些改进，主要变化如下</p><ul><li>当块大小为4K时，支持的最大文件和最大分区大小分别达到了16TB和1EB</li><li>不再受32000个子目录数的限制，支持不限数量的子目录个数</li><li>支持Extents，提高了大文件的操作性能</li><li>内部实现上支持一次分配多个数据块，较ext3的性能有所提高</li><li>支持延时分配（即支持fallocate函数）（fallocate是libc的函数，在不支持该功能的文件系统上，libc会创建一个占用磁盘空间文件）</li><li>支持在线快速扫描</li><li>支持在线碎片整理（单个文件或者整个分区）</li><li>日志（Journal）支持校验码（checksum），数据的安全性进一步提高</li><li>支持无日志（No Journaling）模式（ext3不支持该功能），这样就和ext2一样，消除了写日志对性能的影响</li><li>支持纳秒级的时间戳</li><li>记录了文件的创建时间，由于相关的应用层工具还不支持，所以只能通过debug的方式看到文件的创建时间</li></ul><p>这里是一个查看文件/etc/fstab创建时间的例子（文件存在/dev/sda1分区上）：</p><pre><code>dev@ubuntu:~$ ls -i /etc/fstab10747906 /etc/fstabdev@ubuntu:~$ sudo debugfs -R 'stat &lt;10747906&gt;' /dev/sda1Inode: 10747906   Type: regular    Mode:  0644   Flags: 0x80000Links: 1   Blockcount: 8ctime: 0x5546dc54:6e6bc80c -- Sun May  3 22:41:24 2015 atime: 0x55d1b014:8bcf7b44 -- Mon Aug 17 05:57:40 2015 mtime: 0x5546dc54:6e6bc80c -- Sun May  3 22:41:24 2015crtime: 0x5546dc54:6e6bc80c -- Sun May  3 22:41:24 2015Size of extra inode fields: 28EXTENTS: (0):46712815</code></pre><p><strong>Extents：</strong> 在最开始的ext2文件系统中，数据块都是一个一个单独管理的，inode中存有指向数据块的指针，文件占用了多少个数据块，inode里面就有多少个指针（多级），想象一下一个1G的文件，4K的块大小，那么需要(1024 * 1024)/4=262144个数据块，即需要262144个指针，创建文件的时候需要初始化这些指针，删除文件的时候需要回收这些指针，影响性能。现代的文件系统都支持Extents的功能，简单点说，Extent就是数据块的集合，以前一次分配一个数据块，现在可以一次分配一个Extent，里面包含很多数据块，同时inode里面只需要分配指向Extent的指针就可以了，从而大大减少了指针的数量和层级，提高了大文件操作的性能。</p><p><strong>inode数量固定：</strong> 在ext2/3/4系列的文件系统中，inode的数量都是固定的，坏处是如果存很多小文件的话，有可能造成inode被用光，但磁盘还有很多剩余空间无法被使用的情况，不过它也有一个好处，就是一旦磁盘损坏，恢复起来要相对简单些，因为数据在磁盘上布局相对要固定简单。</p><h2 id="xfs"><a class="header-anchor" href="#xfs">¶</a>xfs</h2><p>和ext4相比，xfs不支持下面这些功能</p><ul><li>不支持日志（Journal）校验码</li><li>不支持无日志（No Journaling）模式</li><li>不支持文件创建时间</li><li>不支持数据日志（data journal），只有元数据日志（metadata journal）</li></ul><p>但xfs有下面这些特性</p><ul><li>支持的最大文件和分区都达到了8EB</li><li>inode动态分配，从而不受inode数量的限制，再也不用担心存储大量小文件导致inode不够用的问题了。</li><li><a href="https://en.wikipedia.org/wiki/XFS#Extended_attributes" target="_blank" rel="noopener">更大的xattr(extended attributes)</a>空间，ext2/3/4及btrfs都限制xattr的长度不能超过一个块（一般是4K），而xfs可以达到64K</li><li>内部采用Allocation groups机制，各个group之间没有依赖，支持并发操作，在多核环境的某些场景下性能表现不错</li><li>提供了原生的dump和restore工具，并且支持在线dump</li></ul><h2 id="btrfs"><a class="header-anchor" href="#btrfs">¶</a>btrfs</h2><p>btrfs是一个和ZFS类似的文件系统，支持的功能非常多，据说将来会替换ext4成为Linux下的默认文件系统。这里列举一些重要的功能</p><ul><li>支持的最大文件和分区达到了16EB</li><li>支持COW（copy on write）</li><li>针对小文件和SSD做了优化</li><li>inode动态分配</li><li>支持子分区（Subvolumes），子分区可以单独挂载</li><li>支持元数据和数据的校验（crc32）</li><li>支持压缩，去重</li><li>支持多个磁盘和分区，可动态扩展</li><li>支持LVM,RAID的功能（有了btrfs，就不再需要lvm和软raid了）</li><li>增量备份和恢复</li><li>支持快照</li><li>将ext2/3/4转换成btrfs（反过来不行）</li></ul><p>btrfs最大的缺点就是由于其COW的实现方式，导致碎片化问题比较严重，不太适合频繁写的场景，比如数据库、虚拟机的磁盘文件等。不过大部分场合不需要担心，btrfs有在线的碎片整理工具。</p><h2 id="如何选择"><a class="header-anchor" href="#如何选择">¶</a>如何选择</h2><p>下表仅供参考</p><table><thead><tr><th>文件系统</th><th>适用场景</th><th>原因</th></tr></thead><tbody><tr><td>ext2</td><td>U盘</td><td>U盘一般不会存很多文件，且U盘的文件在电脑上有备份，安全性要求没那么高，由于ext2不写日志（journal），所以写U盘性能比较好。当然由于ext2的兼容性没有fat好，目前大多数U盘格式还是用fat</td></tr><tr><td>ext3</td><td>对稳定性要求高的地方</td><td>有了ext4后，好像没什么原因还要用ext3，ext4现在的问题是出来时间不长，还需要一段时间变稳定</td></tr><tr><td>ext4</td><td>小文件较少</td><td>ext系列的文件系统都不支持inode动态分配，所以如果有大量小文件需要存储的话，不建议用ext4</td></tr><tr><td>xfs</td><td>小文件多或者需要大的xttr空间，如<a href="https://docs.openstack.org/developer/swift/" target="_blank" rel="noopener">openstack swift</a>将数据文件的元数据放在了xttr里面</td><td>xfs支持inode动态分配，所以不存在inode不够的情况，并且xttr的最大长度可以达到64K</td></tr><tr><td>btrfs</td><td>没有频繁的写操作，且需要btrfs的一些特性</td><td>btrfs虽然还不稳定，但支持众多的功能，如果你需要这些功能，且不会频繁的写文件，那么选择btrfs</td></tr></tbody></table><p>另外，ext系列文件系统内部结构相对简单一些，出问题后恢复相对容易。</p><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>本篇没有比较它们的性能，在通常情况下，他们之间没有太大的性能差别，只有在特定的场景下，才能看出区别，如果对性能比较敏感，建议根据自己的使用场景来测试不同的文件系统，然后根据结果来选择。</p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux文件系统之aufs</title>
      <link href="/2020/02/16/linux/linux-wen-jian-xi-tong-zhi-aufs/"/>
      <url>/2020/02/16/linux/linux-wen-jian-xi-tong-zhi-aufs/</url>
      
        <content type="html"><![CDATA[<p>aufs的全称是advanced multi-layered unification filesystem，主要功能是把多个文件夹的内容合并到一起，提供一个统一的视图，主要用于各个Linux发行版的livecd中，以及docker里面用来组织image。</p><p>据说由于aufs代码的可维护性不好（代码可读性和注释不太好），所以一直没有被合并到Linux内核的主线中去，不过有些发行版的kernel里面维护的有该文件系统，比如在ubuntu 16.04的内核代码中，就有该文件系统。</p><blockquote><p>本篇所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="检查系统是否支持aufs"><a class="header-anchor" href="#检查系统是否支持aufs">¶</a>检查系统是否支持aufs</h2><p>在使用aufs之前，可以通过下面的命令确认当前系统是否支持aufs，如果不支持，请自行根据相应发行版的文档安装</p><pre><code>#下面的命令如果没有输出，表示内核不支持aufs#由于ubuntu 16.04的内核中已经将aufs编译进去了，所以默认就支持dev@ubuntu:~$ grep aufs /proc/filesystemsnodev   aufs#这里nodev表示该文件系统不需要建在设备上</code></pre><blockquote><p>注意：有些Linux发行版可能将aufs编译成了模块，所以虽然这里显示内核不支持，但其实后面的命令都能正常运行</p></blockquote><h2 id="挂载aufs"><a class="header-anchor" href="#挂载aufs">¶</a>挂载aufs</h2><p>选择好相应的参数（参考<a href="http://manpages.ubuntu.com/manpages/xenial/en/man5/aufs.5.html" target="_blank" rel="noopener">帮助文档</a>），调用mount命令即可，示例如下</p><pre><code># mount -t aufs -o br=./Branch-0:./Branch-1:./Branch-2 none ./MountPoint</code></pre><ul><li>-t aufs： 指定挂载类型为aufs</li><li>-o br=./Branch-0:./Branch-1:./Branch-2： 表示将当前目录下的Branch-0，Branch-1，Branch-2三个文件夹联合到一起</li><li>none：aufs不需要设备，只依赖于-o br指定的文件夹，所以这里填none即可</li><li>./MountPoint：表示将最后联合的结果挂载到当前的MountPoint目录下，然后我们就可以往这个目录里面读写文件了</li></ul><p>假设Branch-0里面有文件001.txt、003.txt，Branch-1里面有文件001.txt、003.txt、004.txt，Branch-2里面有文件002.txt、003.txt。</p><p>mount完成后，得到的结果将会如下图所示</p><pre><code>              /*001.txt(b0)表示Branch-0的001.txt文件，其它的以此类推*/           +-------------+-------------+-------------+-------------+MountPoint | 001.txt(b0) | 002.txt(b2) | 003.txt(b0) | 004.txt(b1) |               +-------------+-------------+-------------+-------------+                  ↑             ↑             ↑             ↑                  |             |             |             |           +-------------+-------------+-------------+-------------+Branch-0   |   001.txt   |             |   003.txt   |             |           +-------------+-------------+-------------+-------------+Branch-1   |   001.txt   |             |   003.txt   |   004.txt   |           +-------------+-------------+-------------+-------------+Branch-2   |             |   002.txt   |   003.txt   |             |           +-------------+-------------+-------------+-------------+</code></pre><p>联合之后，在MountPoint下将会看到四个文件，分别是Branch-0下的001.txt、003.txt，Branch-1下的04.txt，以及Branch-2下的002.txt。</p><ul><li>branch是aufs里面的概念，其实一个branch就是一个目录，所以上面的Branch-0,1,2就是三个目录</li><li>branch是有index的，index越小的branch会放在最上面，如果多个branch里面有同样的文件，只有index最小的那个branch下的文件才会被访问到</li><li>MountPoint就是最后这三个目录联合后挂载到的位置，访问这个目录下的文件都会经过aufs文件系统，换句话说，直接访问Branch-0,1,2这三个目录的话，aufs是不知道的</li></ul><blockquote><p>注意：并不是所有文件系统里的目录都能作为aufs的branch，目前aufs不支持的有：btrfs aufs eCryptfs</p></blockquote><p>读这些文件的时候访问的是最上层的文件，但如果要写这些文件呢？或者在挂载点下创建新的文件呢？请看下面的示例</p><h2 id="只读挂载"><a class="header-anchor" href="#只读挂载">¶</a>只读挂载</h2><p>挂载时，可以指定每个branch的读写权限，如果不指定的话，第一个目录将会是可写的，其它的目录是只读的，在实际使用时，最好是显示的指定每个branch的读写属性，这样大家都一眼就能看懂。这里先演示一下只读挂载：</p><pre><code>#准备相应的目录和文件dev@ubuntu:~$ mkdir /tmp/aufs &amp;&amp; cd /tmp/aufsdev@ubuntu:/tmp/aufs$ mkdir dir0 dir1 rootdev@ubuntu:/tmp/aufs$ echo dir0 &gt; dir0/001.txtdev@ubuntu:/tmp/aufs$ echo dir0 &gt; dir0/002.txtdev@ubuntu:/tmp/aufs$ echo dir1 &gt; dir1/002.txtdev@ubuntu:/tmp/aufs$ echo dir1 &gt; dir1/003.txt#最后用tree命令来看看最终的目录结构dev@ubuntu:/tmp/aufs$ tree.├── dir0│   ├── 001.txt│   └── 002.txt├── dir1│   ├── 002.txt│   └── 003.txt└── root#通过指定ro参数来让两个branch都为只读dev@ubuntu:/tmp/aufs$ sudo mount -t aufs -o br=./dir0=ro:./dir1=ro none ./root#联合后最终的root目录下将看到三个文件dev@ubuntu:/tmp/aufs$ ls root/001.txt  002.txt  003.txt#其中002.txt的内容是dir0中的002.txt的内容，说明dir0的index要比dir1的index小dev@ubuntu:/tmp/aufs$ cat root/002.txtdir0#由于是只读挂载，所以touch失败dev@ubuntu:/tmp/aufs$ touch root/001.txttouch: cannot touch 'root/001.txt': Read-only file systemdev@ubuntu:/tmp/aufs$ touch root/003.txttouch: cannot touch 'root/003.txt': Read-only file system#但是我们可以跳过root目录来修改001.txt和003.txt，#因为跳过了root目录，所以就不受aufs控制dev@ubuntu:/tmp/aufs$ touch dir0/001.txtdev@ubuntu:/tmp/aufs$ touch dir1/003.txt#我们还能在下面的目录中创建新的文件dev@ubuntu:/tmp/aufs$ touch dir1/004.txt#新创建的文件能及时的反应到挂载点上去dev@ubuntu:/tmp/aufs$ ls ./root/001.txt  002.txt  003.txt  004.txt#删除该文件，以免影响后续的演示dev@ubuntu:/tmp/aufs$ rm ./dir1/004.txt</code></pre><p>从上面的演示可以看出，我们可以跳过挂载点直接读写底层的目录，这样就不受aufs的控制，但我们修改的内容（dir1里面创建的004.txt）还是能在挂载点下看到，这是因为aufs在访问文件时，默认的做法是如果最上层目录里面没这个文件，就一层一层的往下找，所以下层有变动的话，aufs会自动发现。控制这种行为的参数为“udba”，有兴趣可以参考<a href="http://manpages.ubuntu.com/manpages/xenial/en/man5/aufs.5.html" target="_blank" rel="noopener">帮助文档</a></p><blockquote><p>由于访问一个文件时需要一级一级往下找，所以如果联合的目录（层级）过多的话，会影响性能</p></blockquote><h2 id="读写挂载"><a class="header-anchor" href="#读写挂载">¶</a>读写挂载</h2><p>如果联合的文件夹有写的权限，那么所有的修改都会写入可写的那个文件夹，如果可写的文件夹有多个，那么写入哪个文件夹就依赖于相应的策略，有round-robin、最多剩余空间等，详情请参考<a href="http://manpages.ubuntu.com/manpages/xenial/en/man5/aufs.5.html" target="_blank" rel="noopener">帮助文档</a>中的“create”参数，这里不做介绍。</p><pre><code>dev@ubuntu:/tmp/aufs$ sudo umount ./root#dir0具有读写权限，dir1为只读权限dev@ubuntu:/tmp/aufs$ sudo mount -t aufs -o br=./dir0=rw:./dir1=ro none ./rootdev@ubuntu:/tmp/aufs$ echo &quot;root-&gt;write&quot; &gt;&gt; ./root/001.txtdev@ubuntu:/tmp/aufs$ echo &quot;root-&gt;write&quot; &gt;&gt; ./root/002.txtdev@ubuntu:/tmp/aufs$ echo &quot;root-&gt;write&quot; &gt;&gt; ./root/003.txtdev@ubuntu:/tmp/aufs$ echo &quot;root-&gt;write&quot; &gt;&gt; ./root/005.txt#跟开始前相比，dir0目录下多了003.txt和005.txt，其它的保持不变dev@ubuntu:/tmp/aufs$ ls ./root/001.txt  002.txt  003.txt  005.txtdev@ubuntu:/tmp/aufs$ ls ./dir0/001.txt  002.txt  003.txt  005.txtdev@ubuntu:/tmp/aufs$ ls ./dir1/002.txt  003.txt#再来看看内容，dir1里面的内容保持不变dev@ubuntu:/tmp/aufs$ cat ./dir1/002.txtdir1dev@ubuntu:/tmp/aufs$ cat ./dir1/003.txtdir1#dir0下的文件内容都变了dev@ubuntu:/tmp/aufs$ cat ./dir0/001.txtdir0root-&gt;writedev@ubuntu:/tmp/aufs$ cat ./dir0/002.txtdir0root-&gt;writedev@ubuntu:/tmp/aufs$ cat ./dir0/003.txtdir1root-&gt;writedev@ubuntu:/tmp/aufs$ cat ./dir0/005.txtroot-&gt;write</code></pre><ul><li>当创建一个新文件的时候，新的文件会写入具有rw权限的那个目录，如果有多个目录具有rw权限，那么依赖于挂载时配置的的创建策略</li><li>当修改一个具有rw权限目录下的文件时，直接修改该文件</li><li>当修改一个只有ro权限目录下的文件时，aufs会先将该文件拷贝到一个rw权限的目录里面，然后在上面进行修改，这就是所谓的COW(copy on write)，拷贝的速度依赖于底层branch所在的文件系统。</li></ul><p>从上面可以看出，COW对于大文件来说，性能还是很低的，同时也会占用很多的空间，但由于只需要在第一次修改的时候拷贝一次，所以很多情况下还是能接受。</p><h2 id="删除文件"><a class="header-anchor" href="#删除文件">¶</a>删除文件</h2><p>删除文件时，如果该文件只在rw目录下有，那就直接删除rw目录下的该文件，如果该文件在ro目录下有，那么aufs将会在rw目录里面创建一个.wh开头的文件，标识该文件已被删除</p><pre><code>#通过aufs删除所有文件dev@ubuntu:/tmp/aufs$ rm ./root/001.txt ./root/002.txt ./root/003.txt ./root/005.txt#dir0下的文件全被删除了，但dir1目录下的文件没动dev@ubuntu:/tmp/aufs$ tree.├── dir0├── dir1│   ├── 002.txt│   └── 003.txt└── root#通过-a参数来看看dir0目录下的内容#可以看到aufs为002.txt和003.txt新建了两个特殊的以.wh开头的文件，#用来表示这两个文件已经被删掉了#这里其他.wh开头的文件都是aufs用到的一些属性文件dev@ubuntu:/tmp/aufs$ ls ./dir0/ -a.  ..  .wh.002.txt  .wh.003.txt  .wh..wh.aufs  .wh..wh.orph  .wh..wh.plnk</code></pre><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>这里只介绍了aufs的基本功能，其它的高级配置项没有涉及，比如动态的增加和删除branch等。</p><p>使用aufs时，建议参考livecd及docker的使用方式，就是将所有的目录都以只读的方式和一个支持读写的空目录联合起来，这样所有的修改都会存到那个指定的空目录中，不用之后删除掉那个目录就可以了，并且在使用的过程中不要绕过aufs直接操作底层的branch，也不要动态的增加和删除branch，如果把使用场景弄得太复杂，由于aufs里面的细节很多，很有可能会由于对aufs的理解不深而踩坑。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="http://aufs.sourceforge.net/" target="_blank" rel="noopener">aufs</a></li><li><a href="http://manpages.ubuntu.com/manpages/xenial/en/man5/aufs.5.html" target="_blank" rel="noopener">aufs manual</a></li><li><a href="http://www.thegeekstuff.com/2013/05/linux-aufs/" target="_blank" rel="noopener">Linux AuFS Examples</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux虚拟文件系统简介</title>
      <link href="/2020/02/16/linux/linux-xu-ni-wen-jian-xi-tong-jian-jie/"/>
      <url>/2020/02/16/linux/linux-xu-ni-wen-jian-xi-tong-jian-jie/</url>
      
        <content type="html"><![CDATA[<p>本文将对Linux下的VFS做一个简单介绍，主要包括VFS里面的一些概念，以及文件系统是如何与VFS交互的。</p><blockquote><p>本文所涉及的代码摘自Linux-4.4.0-59</p></blockquote><h2 id="什么是VFS"><a class="header-anchor" href="#什么是VFS">¶</a>什么是VFS</h2><p>VFS的全称为virtual File System（虚拟文件系统），可以把它理解为Linux下的文件系统平台。</p><ul><li>对应用层来说，只要和VFS打交道就可以了，VFS对外提供了read，write等接口，应用层程序不需要关心底层具体的的文件系统是怎么实现的。</li><li>对具体的文件系统来说，VFS就是一个框架，提供了文件系统通用的一些数据结构和函数，文件系统只需要提供VFS所要求的数据和实现所要求的函数就可以了，就像是在VFS上开发一个插件一样。</li></ul><h2 id="文件系统在系统中的位置"><a class="header-anchor" href="#文件系统在系统中的位置">¶</a>文件系统在系统中的位置</h2><p>下面这张图展示了文件系统在系统中的位置</p><pre><code>+---------------------------------------------------------------+|                +---------------------+                        ||                |  User Applications  |                        ||                +---------------------+                        ||                   |         ↓                 User Space      ||                   |  +---------------+                        ||                   |  | GNU C Library |                        ||                   |  +---------------+                        ||...................|.........|.................................||                   ↓         ↓                                 ||                +-------------------------+                    ||                |  System Call Interface  |                    ||                +-------------------------+                    ||                             ↓                                 || +-----------+  +-------------------------+  +---------------+ || |Inode Cache|--|   Virtual File System   |--|Directory Cache| || +-----------+  +-------------------------+  +---------------+ ||                             ↓                                 ||                +-------------------------+                    ||                | Individual File System  |                    ||                +-------------------------+                    ||                             ↓                                 ||                    +----------------+                         ||                    |  Buffer Cache  |         Kernel Space    ||                    +----------------+                         ||                             ↓                                 ||                    +----------------+                         ||                    |  Device Driver |                         ||                    +----------------+                         |+---------------------------------------------------------------+</code></pre><ul><li>应用层程序（User Applications）可以通过libc（GNU C Library），或者直接通过内核提供的系统调用（System Call Interface ）来访问文件</li><li>在内核里面，相应的系统调用里面调用的其实就是VFS提供的函数</li><li>VFS根据文件路径找到相应的挂载点，就得到了具体的文件系统信息，然后调用具体文件系统的相应函数。（Inode Cache和Directory Cache是VFS中的一部分，用来加快inode和directory的访问）</li><li>具体的文件系统根据自己对磁盘（可能是别的介质，本篇统一以磁盘为例）上数据的组织方式，操作相应的数据。（Buffer Cache是内核中块设备的缓存）</li></ul><h2 id="VFS相关的对象"><a class="header-anchor" href="#VFS相关的对象">¶</a>VFS相关的对象</h2><p>下面这张图简要的说明了VFS里面各种object之间的关系</p><pre><code>. . . . . .. . . . .     . . . . . . . . . . . . . . . . . . . . . . . . . .      . . . . . . . . . . . . . . . . . . . . . . . . ..      Process A   .     .                                                 .      .                                               ..         fd       .     .                                 Kernel          .      .                  File System                  ..        +---+     .     .   +--------------+                              .      .                                               .. stdin  | 0 |--------------&gt;| File Object1 |--------+                     .      .                                               ..        +---+     .     .   +--------------+        |                     .      .                                               .. stdout | 1 |-------+   .   +--------------+        |                     .      .                                               ..        +---+     . +------&gt;| File Object2 |------+ |                     .      .                                               .. stderr | 2 |-------+   .   +--------------+      | |                     .      .   +------------+                              ..        +---+     .     .   +--------------+      | |                     . +-------&gt;|Inode Object|--+     +-----------------+   ..        | 3 |--------------&gt;| File Object3 |----+ | |    DEntry Cache     . |    .   +------------+  |  +-&gt;|Superblock Object|   ..        +---+     .     .   +--------------+    | | |  +-------------+    . |    .   +------------+  |  |  +-----------------+   ..        |...|     .     .                    +--+-+-+-&gt;|DEntry Object|------+  +----&gt;|Inode Object|--+  |           |            ..        +---+     .     .                    |  | |    +-------------+    .    | .   +------------+  +--+           |            .. . . . . .. . . . .     .                    |  | +---&gt;|DEntry Object|---------+ .   +------------+  |  |           ↓            .                         .                    |  |      +-------------+    .      .+-&gt;|Inode Object|--+  |  +-----------------+   .                         .                    |  +-----&gt;|DEntry Object|------------+  +------------+  |  |  |                 |   .. . . . . .. . . . .     .                    |  |      +-------------+    .      .   +------------+  |  +-&gt;|       Disk      |   ..      Process B   .     .                    |  |  +--&gt;|DEntry Object|--------------&gt;|Inode Object|--+     |                 |   ..         fd       .     .   +--------------+ |  |  |   +-------------+    .      .   +------------+        +-----------------+   ..        +---+     . +------&gt;| File Object4 |-+  |  |   |    .....    |    .      .                                               .. stdin  | 0 |-------+   .   +--------------+    |  |   +-------------+    .      .                                               ..        +---+     .     .   +--------------+    |  |                      .      .                                               .. stdout | 1 |--------------&gt;| File Object5 |----+  |                      .      .                                               ..        +---+     .     .   +--------------+    |  |                      .      .                                               .. stderr | 2 |-------+   .   +--------------+    |  |                      .      .                                               ..        +---+     . +------&gt;| File Object6 |----+  |                      .      .                                               ..        | 3 |---+ .     .   +--------------+       |                      .      .                                               ..        +---+   | .     .   +--------------+       |                      .      .                                               ..        |...|   +----------&gt;| File Object7 |-------+                      .      .                                               ..        +---+     .     .   +--------------+                              .      .                                               .. . . . . .. . . . .     . . . . . . . . . . . . . . . . . . . . . . . . . .      . . . . . . . . . . . . . . . . . . . . . . . . .</code></pre><h4 id="fd列表"><a class="header-anchor" href="#fd列表">¶</a>fd列表</h4><p>在进程的眼里，看到的是fd列表，列表里面存放的是指向file object的指针，所以同样的fd在不同的进程中可能会指向不同的file object</p><h4 id="File-Object"><a class="header-anchor" href="#File-Object">¶</a>File Object</h4><p>file object是内核中的对象，代表了一个被进程打开的文件，和具体的进程相关联</p><p>这里是它的数据结构（只摘取部分）</p><pre><code>//linux/fs.hstruct file {    mode_t          f_mode;     /*rwx权限及文件类型，来自inode object*/    struct path     f_path;     /*文件的路径，由dentry object组成*/    struct inode    *f_inode;   /*指向的inode*/    const struct file_operations    *f_op;  /*和文件相关的函数，比如read，write等，来自inode object*/    loff_t          f_pos;      /*当前文件访问到的位置*/}//linux/path.hstruct path {        struct vfsmount *mnt;   /*所属的挂载点信息*/        struct dentry *dentry;  /*指向的dentry object*/};</code></pre><p>当应用程序调用open函数的时候，VFS就会创建相应的file object，除了f_pos是进程私有的数据外，其他的数据都来自于inode和dentry，和所有进程共享，不同进程的file object可以指向同一个dentry和inode</p><h4 id="DEntry-Objectry"><a class="header-anchor" href="#DEntry-Objectry">¶</a>DEntry Objectry</h4><p>DEntry Object由VFS维护，所有文件系统共享，不和具体的进程关联，每个DEntry Object都指向一个Inode object，在加载inode时根据inode自动生成。</p><p>当调用open函数打开一个文件时，内核会第一时间到dentry cache里面根据path来找相应的dentry，找到了就直接构造file object并返回，如果没找到的话，就会根据找到的最近的目录一级一级的往下加载，直到找到相应的文件。（加载的过程就是从磁盘加载inode的过程，所有被加载的inode都会生成相应的dentry然后缓存起来）</p><p>dentry chache的作用就是用来加快根据path找到相应文件的速度，它里面有自己设计的便于快速查找的数据结构，dentry只存在于内存中，不会被存储在磁盘上，由于内存有限，所以并不是磁盘上所有inode所对应的dentry都会被缓存起来，VFS有自己的缓存策略。</p><p>这里是它的数据结构（只摘取部分）</p><pre><code>//linux/dcache.hstruct dentry {        struct dentry *d_parent;        /* 父目录 */        struct qstr d_name;             /* 名字 */        struct inode *d_inode;          /* 关联的inode */   */        struct list_head d_child;       /* 父目录中的子目录和文件 */        struct list_head d_subdirs;     /* 当前目录中的子目录和文件 */};</code></pre><blockquote><p>注意：dentry虽然名字叫directory entry，实际上它对应的inode也可以是普通文件</p></blockquote><h4 id="Inode-object"><a class="header-anchor" href="#Inode-object">¶</a>Inode object</h4><ul><li>inode的结构体由VFS定义，代表了磁盘上的一个文件、目录、链接或者其它类型的文件。</li><li>inode里面包含的数据存放在磁盘上，由具体的文件系统进行组织，当需要访问一个inode时，会由文件系统从磁盘上加载相应的数据并构造好相应的inode</li><li>一个inode可能被多个dentry所关联，比如多个hard links指向同一个文件的情况</li></ul><p>这里是它的数据结构（只摘取部分）</p><pre><code>//linux/fs.hstruct inode {        umode_t                 i_mode;     /*rwx权限及文件类型*/        kuid_t                  i_uid;      /*user id*/        kgid_t                  i_gid;      /*group id*/        const struct inode_operations   *i_op;  /*inode相关的操作函数，如创create，mkdir，lookup，rename等，请参考fs.h里的定义*/        struct super_block      *i_sb;        unsigned long           i_ino;      /*inode的编号*/        loff_t                  i_size;     /*文件大小*/        struct timespec         i_atime;    /*最后访问时间*/        struct timespec         i_mtime;    /*文件内容最后修改时间*/        struct timespec         i_ctime;    /*文件元数据最后修改时间（包括文件名称）*/        const struct file_operations    *i_fop; /* 文件操作函数，包括open，llseek，read，write等，请参考fs.h里的定义 */        void                    *i_private;     /* 文件系统的私有数据，一般可以从这里面知道文件对应的数据在哪 */};</code></pre><h4 id="Superblock-Object"><a class="header-anchor" href="#Superblock-Object">¶</a>Superblock Object</h4><p>它的结构体由VFS定义，但里面的数据由具体的文件系统填充，每个superblock代表了一个具体的分区。</p><p>每个磁盘分区上都有一份superblock，里面包含了当前磁盘分区的信息，如文件系统类型、剩余空间等。</p><p>由于superblock非常重要，所以一般文件系统都会在磁盘上存储多份，防止数据损坏导致整个分区无法读取。</p><p>这里是它的数据结构（只摘取部分）</p><pre><code>//linux/fs.hstruct super_block {        unsigned long           s_blocksize;    /* block的大小，常见文件系统一般都是4K */        loff_t                  s_maxbytes;     /* 支持的最大文件大小 */        struct file_system_type *s_type;        /* 文件系统系统类型 */        struct dentry           *s_root;        /* 分区内文件树的根节点 */        struct list_head        s_mounts;       /* 一个分区可以mount到多个地方，这里是mount的相关信息*/        struct block_device     *s_bdev;        /* 对应的物理设备信息 */        u8 s_uuid[16];                          /* 分区的UUID */        void                    *s_fs_info;     /* 文件系统的私有数据*/};</code></pre><h2 id="实现文件系统的大概步骤"><a class="header-anchor" href="#实现文件系统的大概步骤">¶</a>实现文件系统的大概步骤</h2><p>文件系统主要负责管理磁盘上的空间，磁盘上至少要包含三部分数据： superblock，inodes和数据块。</p><ol><li>首先得有一个创建文件系统的工具(如ext2文件系统的mke2fs)，用来将磁盘分区格式化成想要的格式，主要是初始化superblock和root inode。</li><li>写一个内核模块，在里面注册自己的文件系统，并且初始化mount函数</li><li>当用户在应用层调用mount命令时，VFS就会根据指定的文件系统类型找到我们写的内核模块，并且调用里面的mount函数</li><li>在mount函数里面读取磁盘上的superblock和root inode</li><li>初始化root inode的inode_operations和file_operations，然后返回给VFS</li><li>这样VFS就能根据root inode里提供的函数一级一级的往下找到path对应文件的inode</li><li>读取inode所指向的数据块（一个或者多个），根据文件的类型，解析数据块的内容。如果文件类型是普通文件，那么数据块里面就是文件的内容；如果文件类型是目录，那么数据块里面存储的就是目录下面所有子目录和文件的名称及它们对应的inode号；如果文件类型是软链接，那么数据块里面存储的就是链接到的文件路径。</li></ol><p>总的来说，实现文件系统就是怎么在磁盘上组织文件，然后实现VFS所要求的superblock，inode以及inode_operations和file_operations。</p><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>本篇只是介绍了VFS里面的基本概念，没有深入细节（因为我也没有相关经验），希望对大家理解文件系统有所帮助。</p><p>要实现一个真正的文件系统除了需要了解VFS外，还需要很多内核编程及磁盘操作的知识，如果感兴趣，可以参考<a href="http://www.nongnu.org/ext2-doc/index.html" target="_blank" rel="noopener">ext2文件系统的实现</a>，相对简单且<a href="https://github.com/torvalds/linux/tree/v4.4/fs/ext2" target="_blank" rel="noopener">代码</a>少（不到1万行）。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="http://www.ibm.com/developerworks/cn/linux/l-linux-filesystem/index.html" target="_blank" rel="noopener">Linux 文件系统剖析</a></li><li><a href="https://www.kernel.org/doc/Documentation/filesystems/vfs.txt" target="_blank" rel="noopener">Overview of the Linux Virtual File System</a></li><li><a href="https://lwn.net/Articles/13325/" target="_blank" rel="noopener">Creating Linux virtual filesystems</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux进程的内存使用情况</title>
      <link href="/2020/02/16/linux/linux-jin-cheng-de-nei-cun-shi-yong-qing-kuang/"/>
      <url>/2020/02/16/linux/linux-jin-cheng-de-nei-cun-shi-yong-qing-kuang/</url>
      
        <content type="html"><![CDATA[<p>在linux下，使用top，ps等命令查看进程的内存使用情况时，经常看到VIRT，RES，SHR等，他们都代表什么意思呢？不同的大小对进程有什么影响呢？这篇文章将来聊一聊这个问题。阅读本篇前建议先阅读<a href="https://segmentfault.com/a/1190000008125006" target="_blank" rel="noopener">Linux内存管理</a>，了解一些Linux下内存的基本概念，如什么是anonymous和file backed映射等。</p><h2 id="查看进程所使用的内存"><a class="header-anchor" href="#查看进程所使用的内存">¶</a>查看进程所使用的内存</h2><p>在进程的眼里，所有的内存都是虚拟内存，但是这些虚拟内存所对应的物理内存是多少呢？正如我们在<a href="https://segmentfault.com/a/1190000008125006" target="_blank" rel="noopener">Linux内存管理</a>中所介绍的那样，并不是每块虚拟内存都有对应的物理内存，可能对应的数据在磁盘上的一个文件中，或者交换空间上的一块区域里。一个进程真正的物理内存使用情况只有内核知道，我们只能通过内核开放的一些接口来获取这些统计数据。</p><h2 id="top"><a class="header-anchor" href="#top">¶</a>top</h2><p>先看看top的输出（top用到的数据来自于/proc/[pid]/statm），这里只是摘录了几条数据：</p><pre><code>  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND 2530 root      20   0       0      0      0 S  0.3  0.0   0:02.69 kworker/0:0 2714 dev       20   0   41824   3700   3084 R  0.3  0.7   0:00.02 top 3008 dev       20   0   22464   5124   3356 S  0.0  1.0   0:00.02 bash</code></pre><p>VIRT：进程所使用的虚拟内存大小</p><p>RES：系统为虚拟内存分配的物理内存大小，包括file backed和anonymous内存，其中anonymous包含了进程自己分配和使用的内存，以及和别的进程通过mmap共享的内存；而file backed的内存就是指加载可执行文件和动态库所占的内存，以及通过private方式调用mmap映射文件所使用的内存（当在内存中修改了这部分数据且没有写回文件，那么这部分内存就变成了anonymous），这部分内存也可能跟别的进程共享。</p><p>SHR：RES的一部分，表示和别的进程共享的内存，包括通过mmap共享的内存和file backed的内存。当通过prive方式调用mmap映射一个文件时，如果没有修改文件的内容，那么那部分内容就是SHR的，一旦修改了文件内容且没有写回文件，那么这部分内存就是anonymous且非SHR的。</p><p>%MEM：等于RES/total*100%，这里total指总的物理内存大小。</p><blockquote><p>注意：由于SHR可能会被多个进程所共享，所以系统中所有进程的RES加起来可能会超过总的物理内存数量，由于同样的原因，所有进程的%MEM总和可能超过100%。</p></blockquote><p>从上面的分析可以看出，VIRT的参考意义不大，它只能反应出程序的大小，而RES也不能完全的代表一个进程真正占用的内存空间，因为它里面还包含了SHR的部分，比如三个bash进程共享了一个libc动态库，那么libc所占用的内存算谁的呢？三个进程平分吗？如果启动一个bash占用了4M的RES，其中3M是libc占用的，由于三个进程都共享那3M的libc，那么启动3个bash实际占用的内存将是3*(4-3)+3=6M，但是如果单纯的按照RES来算的话，三个进程就用了12M的空间。所以理解RES和SHR这两个数据的含义对我们在评估一台服务器能跑多少个进程时尤其重要，不要一看到apache的进程占用了20M，就认为系统能跑的apache进程数就是总的物理内存数除以20M，其实这20M里面有可能有很大一部分是SHR的。</p><blockquote><p>注意：top命令输出中的RES和pmap输出中的RSS是一个东西。</p></blockquote><h2 id="pmap"><a class="header-anchor" href="#pmap">¶</a>pmap</h2><p>上面top命令只是给出了一个进程大概占用了多少的内存，而pmap能更详细的给出内存都是被谁占用了。pmap命令输出的内容来自于/proc/[pid]/maps和/proc/[pid]/smaps这两个文件，第一个文件包含了每段的一个大概描述，而后一个文件包含了更详细的信息。</p><p>这里用pmap看看当前bash的内存使用情况，：</p><pre><code>#这里$$代表当前bash的进程ID，下面只显示了部分输出结果dev@dev:~$ pmap  $$2805:   bash0000000000400000    976K r-x-- bash00000000006f3000      4K r---- bash00000000006f4000     36K rw--- bash00000000006fd000     24K rw---   [ anon ]0000000000be4000   1544K rw---   [ anon ]......00007f1fa0e9e000   2912K r---- locale-archive00007f1fa1176000   1792K r-x-- libc-2.23.so00007f1fa1336000   2044K ----- libc-2.23.so00007f1fa1535000     16K r---- libc-2.23.so00007f1fa1539000      8K rw--- libc-2.23.so00007f1fa153b000     16K rw---   [ anon ]......00007f1fa196c000    152K r-x-- ld-2.23.so00007f1fa1b7e000     28K r--s- gconv-modules.cache00007f1fa1b85000     16K rw---   [ anon ]00007f1fa1b8f000      8K rw---   [ anon ]00007f1fa1b91000      4K r---- ld-2.23.so00007f1fa1b92000      4K rw--- ld-2.23.so00007f1fa1b93000      4K rw---   [ anon ]00007ffde903a000    132K rw---   [ stack ]00007ffde90e4000      8K r----   [ anon ]00007ffde90e6000      8K r-x--   [ anon ]ffffffffff600000      4K r-x--   [ anon ] total            22464K</code></pre><p>这里第一列是内存的起始地址，第二列是mapping的地址大小，第三列是这段内存的访问权限，最后一列是mapping到的文件。这里的地址都是虚拟地址，大小也是虚拟地址大小。</p><p>这里的输出有很多的[ anon ]行，表示在磁盘上没有对应的文件，这些一般都是可执行文件或者动态库里的bss段。当然有对应文件的mapping也有可能是anonymous，比如文件的数据段。关于程序的数据段和bss段的介绍请参考<a href="http://man7.org/linux/man-pages/man5/elf.5.html" target="_blank" rel="noopener">elf的相关资料</a>。</p><p>上面可以看到bash、libc-2.23.so等文件出现了多行，但每行的权限不一样，这是因为每个动态库或者可执行文件里面都分很多段，有只能读和执行的代码段，有能读写的数据段，还有比如这一行“00007f1fa153b000 16K rw— [ anon ]”，就是它上面一行libc-2.23.so的bss段。</p><p>[ stack ]表示进程用到的栈空间，而heap在这里看不到，因为pmap默认情况下不单独标记heap出来，由于heap是anonymous，所以从这里的大小可以推测出来，heap就是“0000000000be4000 1544K rw— [ anon ]”。</p><p>其实从上面的结果根本看不出实际上每段占用了多少物理内存，要想看到RSS，需要使用-X参数，下面看看更详细的输出：</p><pre><code>dev@dev:~$ pmap -X $$2805:   bash         Address Perm   Offset Device  Inode  Size  Rss  Pss Referenced Anonymous Shared_Hugetlb Private_Hugetlb Swap SwapPss Locked Mapping        00400000 r-xp 00000000  fc:00 390914   976  888  526        888         0              0               0    0       0      0 bash        006f3000 r--p 000f3000  fc:00 390914     4    4    4          4         4              0               0    0       0      0 bash        006f4000 rw-p 000f4000  fc:00 390914    36   36   36         36        36              0               0    0       0      0 bash        006fd000 rw-p 00000000  00:00      0    24   24   24         24        24              0               0    0       0      0        00be4000 rw-p 00000000  00:00      0  1544 1544 1544       1544      1544              0               0    0       0      0 [heap]    .....    7f1fa0e9e000 r--p 00000000  fc:00 136340  2912  400   83        400         0              0               0    0       0      0 locale-archive    7f1fa1176000 r-xp 00000000  fc:00 521726  1792 1512   54       1512         0              0               0    0       0      0 libc-2.23.so    7f1fa1336000 ---p 001c0000  fc:00 521726  2044    0    0          0         0              0               0    0       0      0 libc-2.23.so    7f1fa1535000 r--p 001bf000  fc:00 521726    16   16   16         16        16              0               0    0       0      0 libc-2.23.so    7f1fa1539000 rw-p 001c3000  fc:00 521726     8    8    8          8         8              0               0    0       0      0 libc-2.23.so    7f1fa153b000 rw-p 00000000  00:00      0    16   12   12         12        12              0               0    0       0      0    ......    7f1fa196c000 r-xp 00000000  fc:00 521702   152  144    4        144         0              0               0    0       0      0 ld-2.23.so    7f1fa1b7e000 r--s 00000000  fc:00 132738    28   28    9         28         0              0               0    0       0      0 gconv-modules.cache    7f1fa1b85000 rw-p 00000000  00:00      0    16   16   16         16        16              0               0    0       0      0    7f1fa1b8f000 rw-p 00000000  00:00      0     8    8    8          8         8              0               0    0       0      0    7f1fa1b91000 r--p 00025000  fc:00 521702     4    4    4          4         4              0               0    0       0      0 ld-2.23.so    7f1fa1b92000 rw-p 00026000  fc:00 521702     4    4    4          4         4              0               0    0       0      0 ld-2.23.so    7f1fa1b93000 rw-p 00000000  00:00      0     4    4    4          4         4              0               0    0       0      0    7ffde903a000 rw-p 00000000  00:00      0   136   24   24         24        24              0               0    0       0      0 [stack]    7ffde90e4000 r--p 00000000  00:00      0     8    0    0          0         0              0               0    0       0      0 [vvar]    7ffde90e6000 r-xp 00000000  00:00      0     8    4    0          4         0              0               0    0       0      0 [vdso]ffffffffff600000 r-xp 00000000  00:00      0     4    0    0          0         0              0               0    0       0      0 [vsyscall]                                             ===== ==== ==== ========== ========= ============== =============== ==== ======= ======                                             22468 5084 2578       5084      1764              0               0    0       0      0 KB</code></pre><ul><li>权限字段多了一个s和p的标记，s表示是和别人共享的内存空间，读写会影响到其他进程，而p表示这是自己私有的内存空间，读写这部分内存不会对其他进程造成影响。</li><li>输出标示出了[heap]段，并且也说明了后面几个[anon]代表的什么意思（vvar，vdso，vsyscall都是映射到内核的特殊段），mapping字段为空的都是上一行mapping文件里面的bss段（可是gconv-modules.cache后面有两行anonymous mapping，可能跟共享内存有关系，没有深究）。</li><li>Anonymous列标示出了哪些是并且有多少是Anonymous方式映射的物理内存，其大小小于等于RSS</li><li>RSS列表示实际占用的物理内存大小</li></ul><h2 id="top命令输出的SHR内存"><a class="header-anchor" href="#top命令输出的SHR内存">¶</a>top命令输出的SHR内存</h2><p>最后来看看top命令输出的SHR到底由pmap的哪些输出构成</p><pre><code>dev@dev:~$ pmap -d $$3108:   bashAddress           Kbytes Mode  Offset           Device    Mapping0000000000400000     976 r-x-- 0000000000000000 0fc:00000 bash00000000006f3000       4 r---- 00000000000f3000 0fc:00000 bash00000000006f4000      36 rw--- 00000000000f4000 0fc:00000 bash00000000006fd000      24 rw--- 0000000000000000 000:00000   [ anon ]0000000000c23000    1544 rw--- 0000000000000000 000:00000   [ anon ]......00007f53af18e000      16 rw--- 0000000000000000 000:00000   [ anon ]00007f53af198000       8 rw--- 0000000000000000 000:00000   [ anon ]00007f53af19a000       4 r---- 0000000000025000 0fc:00000 ld-2.23.so00007f53af19b000       4 rw--- 0000000000026000 0fc:00000 ld-2.23.so00007f53af19c000       4 rw--- 0000000000000000 000:00000   [ anon ]00007ffc5a94b000     132 rw--- 0000000000000000 000:00000   [ stack ]00007ffc5a9b7000       8 r---- 0000000000000000 000:00000   [ anon ]00007ffc5a9b9000       8 r-x-- 0000000000000000 000:00000   [ anon ]ffffffffff600000       4 r-x-- 0000000000000000 000:00000   [ anon ]mapped: 22464K    writeable/private: 1848K    shared: 28Kdev@dev:~$ top -p $$  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND 3108 dev       20   0   22464   5028   3264 S  0.0  1.0   0:00.02 bash</code></pre><p>从上面的输出可看出SHR ≈ RES - writeable/private，其中writeable/private主要包含stack和heap以及可执行文件和动态库的data和bss段，而stack+heap=1544+132=1675，这已经占了绝大部分，从而data和bss段之类的基本上可以忽略了，所以一般情况下，SHR ≈ RES - [heap] - [stack]，由于stack一般都比较小，上面的等式可以进一步约等于：SHR ≈ RES - [heap]。</p><h2 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h2><p>top命令能看到一个进程占用的虚拟内存空间、物理内存空间以及和别的进程共享的物理内存空间，这里共享的空间包括通过mmap共享的内存以及共享的可执行文件以及动态库。而mmap命令能看到更详细的信息，比如可执行文件和它所链接的动态库大小，以及物理内存都是被哪些段给占用了。</p><p>进程占用的虚拟地址空间大小跟程序的规模有关，除了stack和heap段，其他段的大小基本上都是固定的，并且在程序链接的时候就已经确定了，所以基本上只要关注stack和heap段就可以了，由于stack相对heap来说很小，所以只要没什么stack异常，只需要关注heap。</p><p>在实际的工作过程中，其实我们更关心的是RSS用了多少，都被谁用了，简单点说，如果我们没有同时启动多个进程（同一个程序），RSS就是一个很好的实际物理内存使用参考值，但如果是像apache那样同时跑很多个进程，那么RSS减去SHR所占用的空间就是一个很好的实际物理内存占用参考值，当然这都是大概估算值。</p><p>要想精确评估一个进程到底占了多少内存，还是很难的，需要对进程的每个段有深入的理解，尤其是SHR部分都有哪些进程在一起共享，不过现在服务器上的内存都是以G为单位的，所以一般情况下大概的估算一下加上合理的测试就能满足我们的需求了。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://techtalk.intersec.com/2013/07/memory-part-2-understanding-process-memory/" target="_blank" rel="noopener">Understanding Process memory</a></li><li><a href="http://virtualthreads.blogspot.jp/2006/02/understanding-memory-usage-on-linux.html" target="_blank" rel="noopener">Understanding memory usage on Linux</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SSLTLS及证书概述</title>
      <link href="/2020/02/16/linux/ssltls-ji-zheng-shu-gai-shu/"/>
      <url>/2020/02/16/linux/ssltls-ji-zheng-shu-gai-shu/</url>
      
        <content type="html"><![CDATA[<p>每次配置HTTPS或者SSL时，都需要指定一些cacert，cert，key之类的东西，他们的具体作用是什么呢？为什么配置了他们之后通信就安全了呢？怎么用openssl命令来生成它们呢？程序中应该如何使用这些文件呢？</p><blockquote><p>本篇以TLS 1.2作为参考，只介绍原理，不深入算法的细节</p></blockquote><h2 id="SSL和TLS的关系"><a class="header-anchor" href="#SSL和TLS的关系">¶</a>SSL和TLS的关系</h2><p>SSL(Secure Sockets Layer)和TLS(Transport Layer Security)的关系就像windows XP和windows 7的关系，升级后改了个名字而已。下面这张表格列出了它们的历史：</p><table><thead><tr><th>协议</th><th>创建时间</th><th>创建者</th><th>RFC</th><th>注释</th></tr></thead><tbody><tr><td>SSL1.0</td><td>n/a</td><td>Netscape</td><td>n/a</td><td>由于有很多安全问题，所以网景公司没有将它公之于众</td></tr><tr><td>SSL2.0</td><td>1995</td><td>Netscape</td><td>n/a</td><td>这是第一个被公众所了解的SSL版本</td></tr><tr><td>SSL3.0</td><td>1996</td><td>Netscape</td><td><a href="https://tools.ietf.org/html/rfc6101" target="_blank" rel="noopener">rfc6101</a></td><td>由于2.0还是被发现有很多安全问题，Netscape于是设计了3.0，并且IETF将它整理成RFC发布了出来</td></tr><tr><td>TLS1.0</td><td>1999</td><td>IETF</td><td><a href="https://tools.ietf.org/html/rfc2246" target="_blank" rel="noopener">rfc2246</a></td><td>TLS 1.0基于SSL 3.0，修改不大，在某些场合也被称之为SSL 3.1，改名主要是为了和Netscape撇清关系，表示一个新时代的来临。类似于饭店换老板了，然后改了个名字，厨师还是原来的</td></tr><tr><td>TLS1.1</td><td>2006</td><td>IETF</td><td><a href="https://tools.ietf.org/html/rfc4346" target="_blank" rel="noopener">rfc4346</a></td><td></td></tr><tr><td>TLS1.2</td><td>2008</td><td>IETF</td><td><a href="https://tools.ietf.org/html/rfc5246" target="_blank" rel="noopener">rfc5246</a></td><td></td></tr><tr><td>TLS1.3</td><td>TBD</td><td>IETF</td><td>TBD</td><td>还在开发过程中，<a href="https://tlswg.github.io/tls13-spec/" target="_blank" rel="noopener">draft</a></td></tr></tbody></table><blockquote><p>最初的SSL只支持TCP，不过现在已经可以支持UDP了，请参考<a href="https://tools.ietf.org/html/rfc6347" target="_blank" rel="noopener">Datagram Transport Layer Security Version 1.2</a></p></blockquote><h2 id="HTTPS和TLS的关系"><a class="header-anchor" href="#HTTPS和TLS的关系">¶</a>HTTPS和TLS的关系</h2><p>HTTPS=HTTP+TLS，其它的协议也类似，如FTPS=FTP+TLS。</p><blockquote><p>注意：SSH和SSL/TLS是两个不同的协议，SSH并不依赖于SSL/TLS</p></blockquote><h2 id="加密相关的概念"><a class="header-anchor" href="#加密相关的概念">¶</a>加密相关的概念</h2><p>在正式开始介绍TLS之前，先澄清一些跟加密相关的概念：</p><h4 id="对称加密"><a class="header-anchor" href="#对称加密">¶</a>对称加密</h4><p>这是我们加密文件常用的方式，加密的时候输入一个密码，解密的时候也用这个密码，加密和解密都用同一个密码，所以叫对称加密。常见的算法有AES、3DES。</p><h4 id="非对称加密"><a class="header-anchor" href="#非对称加密">¶</a>非对称加密</h4><p>非对称加密是一个很神奇的东西，它有两个不一样的密码，一个叫私钥，另一个叫公钥，用其中一个加密的数据只能用另一个密码解开，用自己的都解不了，也就是说用公钥加密的数据只能由私钥解开，反之亦然。</p><p>私钥一般自己保存，而公钥是公开的，同等加密强度下，非对称加密算法的速度比不上对称加密算法的速度，所以非对称加密一般用于数字签名和密码（对称加密算法的密码）的交换。常见的算法有RSA、DSA、ECC。</p><h4 id="摘要算法"><a class="header-anchor" href="#摘要算法">¶</a>摘要算法</h4><p>摘要算法<strong>不是用来加密的</strong>，其输出长度固定，相当于计算数据的指纹，主要用来做数据校验，验证数据的完整性和正确性。常见的算法有CRC、MD5、SHA1、SHA256。</p><h4 id="数字签名"><a class="header-anchor" href="#数字签名">¶</a>数字签名</h4><p>数字签名就是“非对称加密+摘要算法”，其目的不是为了加密，而是用来防止他人篡改数据。</p><p>其核心思想是：比如A要给B发送数据，A先用摘要算法得到数据的指纹，然后用A的私钥加密指纹，加密后的指纹就是A的签名，B收到数据和A的签名后，也用同样的摘要算法计算指纹，然后用A公开的公钥解密签名，比较两个指纹，如果相同，说明数据没有被篡改，确实是A发过来的数据。假设C想改A发给B的数据来欺骗B，因为篡改数据后指纹会变，要想跟A的签名里面的指纹一致，就得改签名，但由于没有A的私钥，所以改不了，如果C用自己的私钥生成一个新的签名，B收到数据后用A的公钥根本就解不开。</p><h2 id="TLS握手过程"><a class="header-anchor" href="#TLS握手过程">¶</a>TLS握手过程</h2><p>TLS主要包含两部分协议，一部分是Record Protocol，描述了数据的格式，另一部分是Handshaking Protocols，描述了握手过程，本篇中只介绍握手过程，不介绍具体的通信数据格式。</p><p>握手的目的有两个，一个是保证通信的双方都是自己期待的对方，任何一方都不可能被冒充，另一个是交换加密密码，使得只有通信的双方知道这个密码，而别人不知道。前一个就是我们常说的认证，而后一个就是密码交换。认证是通过证书来达到的，而密码交换是通过证书里面的非对称加密算法（公私钥）来实现的。</p><p>先看握手的交互图：</p><pre><code>+--------+                                      +--------+|        |   1. ClientHello                     |        ||        |-------------------------------------&gt;|        ||        |                                      |        ||        |   2. ServerHello                     |        ||        |   3. Certificate                     |        ||        |   4. ServerKeyExchange (optional)    |        ||        |   5. CertificateRequest (optional)   |        ||        |   6. ServerHelloDone                 |        ||        |&lt;------------------------------------ |        || Client |                                      | Server ||        |   7. Certificate (optional)          |        ||        |   8. ClientKeyExchange               |        ||        |   9. CertificateVerify (optional)    |        ||        |  10. Finished                        |        ||        |------------------------------------&gt; |        ||        |                                      |        ||        |  11. Finished                        |        ||        |&lt;------------------------------------ |        |+--------+                                      +--------+</code></pre><blockquote><p>注意： 下面解释过程中用到的具体协议版本、算法和值都是示例，实际中可能不是这些</p></blockquote><h4 id="ClientHello"><a class="header-anchor" href="#ClientHello">¶</a>ClientHello</h4><pre><code>client-&gt;server: hello，咱建立个连接呗，我这边的支持的最高版本是TLS1.1，支持的密码套件（cipher suite）有“TLS_RSA_WITH_AES_128_CBC_SHA”和“TLS_RSA_WITH_AES_256_CBC_SHA256”，支持的压缩算法有DEFLATE，我这边生成的随机串是abc123456。</code></pre><p>这里有几点需要解释一下：</p><ul><li>客户端会把自己最喜欢的密码套件放在最前面，这样服务器端就会根据客户端的要求优先选择排在前面的算法套件</li><li>密码套件就是一个密码算法三件套，里面包含了一个非对称加密算法，一个对称加密算法，以及一个数据摘要算法。以TLS_RSA_WITH_AES_128_CBC_SHA为例，RSA是非对称加密算法，表示后面用到的证书里面的公钥用的是RSA算法，通信的过程中需要签名的地方也用这个算法，并且密码（key）的交换过程也使用这个算法；AES_128_CBC是对称加密算法，用来加密握手后传输的数据，其密码由RSA负责协商生成；SHA是数据摘要算法，表示后面交换的证书里签名<br>用到的摘要算法是sha1，并且后续通信过程中需要用到数据校验的地方也是用的这个算法。在Record Protocol协议中，摘要算法是必须的，即数据包都需要有校验码，而签名是可选的。</li><li>ClientHello里面还可以包含session id，即表示重用前面session里的一些内容，比如已经协商好的算法套件等，服务器收到session id后会去内存里面找，如果这是一个合法的session id，那么它就可以选择重用前面的session，这样可以省去很多握手的过程。为了简化讨论，这里不介绍session重用的问题。</li></ul><h4 id="ServerHello"><a class="header-anchor" href="#ServerHello">¶</a>ServerHello</h4><p>server收到client的hello消息后，就在自己加载的证书中去找一个和客户支持的算法套件相匹配的证书，并且挑选一个自己也支持的对称加密算法（证书里面只有非对称加密和摘要算法，不包含对称加密算法）。如果出现下面几种情况，握手失败：</p><ul><li>客户端支持的TLS版本太低，比如server要求最低版本为1.2，而客户端支持的最高版本是1.1</li><li>根据客户端所支持的密码套件，找不到相应要求的证书</li><li>无法就支持的对称加密算法达成一致</li></ul><p>如果一切都OK，那么服务器端将返回ServerHello：</p><pre><code>server-&gt;client: hello，没问题，我们就使用TLS1.1吧，算法采用“TLS_RSA_WITH_AES_256_CBC_SHA256”，这个加密强度更高更安全，压缩就算了，我这边不支持，我这边生成的随机数是654321def。</code></pre><blockquote><p>如果server支持session重用的话，这里还会返回session id</p></blockquote><h4 id="Certificate"><a class="header-anchor" href="#Certificate">¶</a>Certificate</h4><p>服务器在发送完ServerHello之后紧接着发送Certificate消息，里面包含自己的证书。</p><blockquote><p>当然这步在有些情况下可以忽略掉，就是非对称加密算法选择使用dh_anon，当然这是特殊的情况，并且也不安全，所以这里就不展开讨论。</p></blockquote><pre><code>server-&gt;client: 这是我的证书（身份证），请过目</code></pre><h4 id="ServerKeyExchange（可选）"><a class="header-anchor" href="#ServerKeyExchange（可选）">¶</a>ServerKeyExchange（可选）</h4><p>在前面的ServerHello中，双方已经协商好了密码套件，对于套件里面的非对称加密算法，有些需要更多的信息才能生成一个可靠的密码，而有些不需要，比如RSA，就不需要发送这个消息，客户端自己生成一个准密码（premaster）就可以了，而有些算法，比如DHE_RSA，就需要发送一点特殊的信息给客户端，便于它生成premaster。</p><blockquote><p>premaster可以理解为最终密码的初级版本，有了这个密码之后，稍微再做一下计算就可以得到最终要使用的对称加密的密码</p></blockquote><pre><code>server-&gt;client: 这是生成premaster所需要的一些信息，请查收</code></pre><h4 id="CertificateRequest（可选）"><a class="header-anchor" href="#CertificateRequest（可选）">¶</a>CertificateRequest（可选）</h4><p>只有在需要验证客户端的身份的时候才用得着，在大部分情况下，尤其是HTTPS，这一步不需要。比如我们访问银行的网站，我们只要保证那确实是银行的网站就可以了，银行验证我们是通过账号密码，而不是我们的证书。而U盾就是一个验证客户端的例子，银行给你的U盾里面有你的证书，你通过U盾访问银行的时候，银行会验证U盾里面证书是不是你的，这种情况下，你和银行之间进行TLS握手的时候，银行会给你发这个CertificateRequest请求。</p><pre><code>server-&gt;client: 把你的证书（身份证）也给我看看，我要确认一下你是不是XXX。</code></pre><h4 id="ServerHelloDone"><a class="header-anchor" href="#ServerHelloDone">¶</a>ServerHelloDone</h4><pre><code>server-&gt;client: 我要告诉你的就是这么多了，处理完了给我个回话吧。</code></pre><h4 id="Certificate（可选）"><a class="header-anchor" href="#Certificate（可选）">¶</a>Certificate（可选）</h4><p>如果客户端在前面收到了服务器的CertificateRequest请求，那么将会在这里给服务器发送自己的证书，就算自己没有证书，也要发送这个消息告诉服务器端自己没有证书，然后由服务器端来决定是否继续。</p><pre><code>client-&gt;server: 这是我的证书（身份证），请过目</code></pre><h4 id="ClientKeyExchange"><a class="header-anchor" href="#ClientKeyExchange">¶</a>ClientKeyExchange</h4><p>客户端验证完服务器端的证书后（怎么验证证书将在后面介绍），就会生成一个premaster，生成的方式跟采用的密码交换算法有关，以TLS_RSA_WITH_AES_128_CBC_SHA为例，其密码交换算法是RSA，于是客户端自己直接生成一个48字节长度的premaster即可，不需要服务器发过来的ServerKeyExchange。</p><pre><code>client-&gt;server: 这是计算真正密码要用到的premaster，它是用你证书里的公钥加密了的哦，记得用你的私钥解密后才能看到哦</code></pre><h4 id="CertificateVerify（可选）"><a class="header-anchor" href="#CertificateVerify（可选）">¶</a>CertificateVerify（可选）</h4><p>如果客户端给服务器发了证书，就需要发送该消息给服务器，主要用于验证证书对应的私钥确实是在客户端手里。</p><pre><code>client-&gt;server: 这是一段用我私钥加密的数据，你用我给你的证书里的公钥解密看看，如果能解开，说明我没骗你，私钥确实是在我手里，并不是我随便找了一个别人的证书忽悠你</code></pre><blockquote><p>发送的消息里面都带有校验码，所以解密后计算下校验码，能对上说明解密成功</p></blockquote><h4 id="Finished"><a class="header-anchor" href="#Finished">¶</a>Finished</h4><p>当前面的过程都没问题后，服务器和客户端都根据得到的信息计算对称加密用的密码，这是RFC里面给出的计算方法：</p><pre><code>master_secret = PRF(pre_master_secret, &quot;master secret&quot;,                          ClientHello.random + ServerHello.random)                          [0..47];</code></pre><p>虽然不太了解PRF的细节，但至少客户端和服务器端用的算法和输入都是一样的，所以得到的master密码也是一样的。这里pre_master_secret就是ClientKeyExchange里面客户端发给服务器端的premaster，ClientHello.random和ServerHello.random分别是握手开始时双方发送的hello请求中的随机字符串。</p><blockquote><p>这里加入随机数的原因主要是为了防止重放攻击，保证每次握手后得到的密码都是不一样的</p></blockquote><p>然后双方将自己缓存的握手过程中的数据计算一个校验码，并用对称加密算法和刚算出来的master密码加密，发给对方，这一步有两目的，一个是保证双方算出来的master密码都是一样的，即我这边加密的数据你那边能解开；另一个目的是确保我们两个人的通信过程中的每一步都没有被其他人篡改，因为握手的前半部分都是明文，所以有可能被篡改，只要双方根据各自缓存的握手过程的数据算出来的校验码是一样的，说明中间没人篡改过。</p><pre><code>client-&gt;server: 这是用我们协商的对称加密算法和密码加密过的握手数据的指纹，看能不能解开，并且和你那边算出来的指纹是一样的server-&gt;client: 这是用我们协商的对称加密算法和密码加密过的握手数据的指纹，你也看看能不能解开，并且和你那边算出来的指纹是一样的</code></pre><p>如果双方发送完Finished而对方没有报错，握手就完成了，双发都得到了密码，并且这个密码别人不知道，后续的所有数据传输过程都会用这个密码进行加密，加密算法就是ServerHello里面协商好的对称加密算法。</p><blockquote><p>在上面握手的过程中，一旦有任何一方觉得有问题，都可能随时终止握手过程</p></blockquote><h2 id="握手不成功常见问题"><a class="header-anchor" href="#握手不成功常见问题">¶</a>握手不成功常见问题</h2><p>配置好了之后还是连不上，一般会是下面几种问题：</p><ul><li>版本不一致，有一方的版本太低，另一方为了安全不同意跟它通信</li><li>无法就cipher suite达成一致，有一方支持的加密算法太弱，安全程度不够</li><li>证书有问题，没法通过验证</li><li>服务器端需要验证客户端的证书，而客户端没有配置</li></ul><h2 id="证书相关"><a class="header-anchor" href="#证书相关">¶</a>证书相关</h2><p>开始之前，看看我们常说的那些跟证书相关的概念</p><h3 id="基本概念"><a class="header-anchor" href="#基本概念">¶</a>基本概念</h3><h4 id="私钥"><a class="header-anchor" href="#私钥">¶</a>私钥</h4><p>私钥就是一个算法名称加上密码串，自己保存，从不给任何人看</p><h4 id="公钥"><a class="header-anchor" href="#公钥">¶</a>公钥</h4><p>公钥也是一个算法名称加上密码串，一般不会单独给别人，而是嵌在证书里面一起给别人</p><h4 id="CA"><a class="header-anchor" href="#CA">¶</a>CA</h4><p>专门用自己的私钥给别人进行签名的单位或者机构</p><h4 id="申请（签名）文件"><a class="header-anchor" href="#申请（签名）文件">¶</a>申请（签名）文件</h4><p>在公钥的基础上加上一些申请人的属性信息，比如我是谁，来自哪里，名字叫什么，证书适用于什么场景等的信息，然后带上进行的签名，发给CA（私下安全的方式发送），带上自己签名的目的是为了防止别人篡改文件。</p><h4 id="证书文件"><a class="header-anchor" href="#证书文件">¶</a>证书文件</h4><p>证书由公钥加上描述信息，然后经过私钥签名之后得到，一般都是一个人的私钥给另一个人的公钥签名，如果是自己的私钥给自己的公钥签名，就叫自签名。</p><h4 id="签名过程"><a class="header-anchor" href="#签名过程">¶</a>签名过程</h4><p>CA收到申请文件后，会走核实流程，确保申请人确实是证书中描述的申请人，防止别人冒充申请者申请证书，核实通过后，会用CA的私钥对申请文件进行签名，签名后的证书包含申请者的基本信息，CA的基本信息，证书的使用年限，申请人的公钥，签名用到的摘要算法，CA的签名。</p><p>签完名之后，证书就可以用了。</p><h3 id="证书找谁签名合适"><a class="header-anchor" href="#证书找谁签名合适">¶</a>证书找谁签名合适</h3><p>别人认不认你的证书要看上面签的是谁的名，所以签名一定要找权威的人来签，否则别人不认，哪谁是权威的人呢？那就是<a href="https://en.wikipedia.org/wiki/Certificate_authority" target="_blank" rel="noopener">CA</a>，哪些CA是受人相信的呢？那就要看软件的配置，配置相信谁就相信谁，比如浏览器里面默认配置的那些，只要是那些CA签名的证书，浏览器都会相信，而你自己写的程序，可以由你自己指定信任的CA。</p><p>信任一个CA就是说你相信你手上拿到的CA的证书是正确的，这是安全的前提，CA的证书是怎么到你手里的，这个不属于规范的范畴，不管你是U盘拷贝的，还是怎么弄来得，反正你得确保拿到的CA证书没问题，比如浏览器、操作系统等，安装好了之后里面就内置了很多信任的CA的证书。</p><p>那么CA的证书又是谁签的名呢？一般CA都是分级的，CA的证书都是由上一级的CA来签名，而最上一级CA的证书是自签名证书。</p><h3 id="证书如何验证"><a class="header-anchor" href="#证书如何验证">¶</a>证书如何验证</h3><p>下面以浏览器为例，说明证书的验证过程：</p><ol><li>在TLS握手的过程中，浏览器得到了网站的证书</li><li>打开证书，查看是哪个CA签名的这个证书</li><li>在自己信任的CA库中，找相应CA的证书，</li><li>用CA证书里面的公钥解密网站证书上的签名，取出网站证书的校验码（指纹），然后用同样的算法（比如sha256）算出出网站证书的校验码，如果校验码和签名中的校验码对的上，说明这个证书是合法的，且没被人篡改过</li><li>读出里面的CN，对于网站的证书，里面一般包含的是域名</li><li>检查里面的域名和自己访问网站的域名对不对的上，对的上的话，就说明这个证书确实是颁发给这个网站的</li><li>到此为止检查通过</li></ol><p>如果浏览器发现证书有问题，一般是证书里面的签名者不是浏览器认为值得信任的CA，浏览器就会给出警告页面，这时候需要谨慎，有可能证书被掉包了。如访问12306网站，由于12306的证书是自己签的名，并且浏览器不认为12306是受信的CA，所以就会给警告，但是一旦你把12306的根证书安装到了你的浏览器中，那么下次就不会警告了，因为你配置了浏览器让它相信12306是一个受信的CA。</p><h3 id="证书生成示例"><a class="header-anchor" href="#证书生成示例">¶</a>证书生成示例</h3><p>下面以实际的例子来看看怎么生成证书。</p><h4 id="生成CA的私钥和证书"><a class="header-anchor" href="#生成CA的私钥和证书">¶</a>生成CA的私钥和证书</h4><pre><code>#创建一个cert目录，后续操作都在该目录下进行dev@dev:~$ mkdir cert &amp;&amp; cd certdev@dev:~/cert$ openssl req -newkey rsa:2048 -nodes -sha256 -keyout ca.key -x509 -days 365 -out ca.crt......Common Name (e.g. server FQDN or YOUR name) []:ca.com......</code></pre><ul><li>-newkey rsa:2048：生成一个长度为2048的采用RSA算法的私钥</li><li>-nodes：这个私钥在本地存储的时候不加密（可以通过其它参数来加密私钥，这样存储比较安全）</li><li>-sha256：生成的证书里面使用sha256作为摘要算法</li><li>-keyout ca.key： 输出私钥到key.pem</li><li>-x509：证书文件格式为x509，目前TLS默认只支持这种格式的证书</li><li>-days 365：证书有效期1年</li><li>-out ca.crt：生成的证书文件保存到ca.crt</li></ul><p>生成的过程中会要求填一些信息，除了Common Name要取一个容易区分的名字之外，其它都可以随便填写，<a href="http://xn--ca-tz2c90an33an0bn4i63az11bws5i3qe.com" target="_blank" rel="noopener">我们在这里将它填为ca.com</a>.</p><h4 id="生成私钥和证书签名申请文件"><a class="header-anchor" href="#生成私钥和证书签名申请文件">¶</a>生成私钥和证书签名申请文件</h4><pre><code>dev@dev:~/cert$ openssl req -newkey rsa:2048 -nodes -sha256 -keyout domain.key -new -out domain.csr......Common Name (e.g. server FQDN or YOUR name) []:domain.com......#这里将CN设置成domain.com</code></pre><p>这里和上面的区别就是这里是-new生成一个证书签名申请文件，而上面用-x509生成一个自签名文件，其它的参数意义都一样。</p><p>从这里可以看出，CA的私钥和普通人的私钥没什么区别，唯一的区别就是CA用私钥自签名的证书受别人相信，而普通人的自签名证书别人不信，所以需要CA来给证书签名。</p><h4 id="使用CA的私钥对申请文件进行签名"><a class="header-anchor" href="#使用CA的私钥对申请文件进行签名">¶</a>使用CA的私钥对申请文件进行签名</h4><pre><code>dev@dev:~/cert$ openssl x509 -CA ca.crt -CAkey ca.key -in domain.csr -req -days 365 -out domain.crt -CAcreateserial -sha256</code></pre><p>由于需要往生成的证书里写入签名者的信息，所以这里需要ca.crt，因为只有这里有CA的描述信息，ca.key里面只有私钥的信息。</p><h4 id="查看证书内容"><a class="header-anchor" href="#查看证书内容">¶</a>查看证书内容</h4><p>上面生成的证书文件格式都是pem格式。通过下面这个命令可以看到证书的内容：</p><pre><code>dev@dev:~/cert$ openssl x509 -text -noout -in ca.crtdev@dev:~/cert$ openssl x509 -text -noout -in domain.crt</code></pre><h2 id="程序支持TLS需要哪些文件"><a class="header-anchor" href="#程序支持TLS需要哪些文件">¶</a>程序支持TLS需要哪些文件</h2><p>回到最开始的问题，cacert，cert，key对应于上面的哪些东西呢？ cacert就是CA的证书，cert就是程序自己的证书，key就是程序自己的私钥。对于服务器来说，至少需要有自己的私钥和证书，而对于客户端来说，至少需要一个cacert，不然没法验证服务器的证书是否正确。</p><h2 id="TLS开发示例"><a class="header-anchor" href="#TLS开发示例">¶</a>TLS开发示例</h2><h3 id="server"><a class="header-anchor" href="#server">¶</a>server</h3><p>服务器采用python开发，只需要指定server的私钥和证书就可以了，代码如下：</p><pre><code>import BaseHTTPServer, SimpleHTTPServerimport sslhttpd = BaseHTTPServer.HTTPServer(('localhost', 443), SimpleHTTPServer.SimpleHTTPRequestHandler)httpd.socket = ssl.wrap_socket (httpd.socket, keyfile=&quot;./domain.key&quot;, certfile='./domain.crt', server_side=True)httpd.serve_forever()</code></pre><p><a href="http://xn--server-9o7iymu4cp6dyx4ctybcx0npmew86l.py" target="_blank" rel="noopener">将上面的代码保存为server.py</a>，然后启动服务：</p><pre><code>#监听443端口需要root权限dev@dev:~/cert$ sudo python server.py</code></pre><h3 id="client"><a class="header-anchor" href="#client">¶</a>client</h3><p>这里使用大家都熟悉的curl作为客户端来测试：</p><pre><code>#直接访问报错，提示证书验证失败，#那是因为domain.crt是我们自己的CA签名的，curl根本就不认识，更谈不上相信它了dev@dev:~/cert$ curl https://127.0.0.1curl: (60) server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: noneMore details here: http://curl.haxx.se/docs/sslcerts.html......#参数中显式的指定我们CA的证书，让它成为curl信任的CA，这样curl就认为我们的证书没问题了#但curl还是报错，说这个证书是发给domain.com的，而不是127.0.0.1dev@dev:~/cert$ curl --cacert ./ca.crt https://127.0.0.1curl: (51) SSL: certificate subject name (domain.com) does not match target host name '127.0.0.1'#往/etc/hosts加上一条记录，设置域名domain.com的ip地址为127.0.0.1dev@dev:~/cert$ sudo sh -c &quot;echo '127.0.0.1 domain.com' &gt;&gt; /etc/hosts&quot;#然后通过域名来访问，得到了服务器的正确返回dev@dev:~/cert$ curl --cacert ./ca.crt  https://domain.com&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 3.2 Final//EN&quot;&gt;&lt;html&gt;&lt;title&gt;Directory listing for /&lt;/title&gt;&lt;body&gt;&lt;h2&gt;Directory listing for /&lt;/h2&gt;&lt;hr&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;ca.crt&quot;&gt;ca.crt&lt;/a&gt;&lt;li&gt;&lt;a href=&quot;ca.key&quot;&gt;ca.key&lt;/a&gt;&lt;li&gt;&lt;a href=&quot;ca.srl&quot;&gt;ca.srl&lt;/a&gt;&lt;li&gt;&lt;a href=&quot;domain.crt&quot;&gt;domain.crt&lt;/a&gt;&lt;li&gt;&lt;a href=&quot;domain.csr&quot;&gt;domain.csr&lt;/a&gt;&lt;li&gt;&lt;a href=&quot;domain.key&quot;&gt;domain.key&lt;/a&gt;&lt;li&gt;&lt;a href=&quot;server.py&quot;&gt;server.py&lt;/a&gt;&lt;/ul&gt;&lt;hr&gt;&lt;/body&gt;&lt;/html&gt;#测试完成之后记得手动将domain.com从/etc/hosts里面删掉</code></pre><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><p><a href="https://en.wikipedia.org/wiki/Transport_Layer_Security" target="_blank" rel="noopener">Transport Layer Security</a><br><a href="https://www.digitalocean.com/community/tutorials/openssl-essentials-working-with-ssl-certificates-private-keys-and-csrs" target="_blank" rel="noopener">OpenSSL Essentials: Working with SSL Certificates, Private Keys and CSRs</a></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>简述Linux的启动过程</title>
      <link href="/2020/02/16/linux/jian-shu-linux-de-qi-dong-guo-cheng/"/>
      <url>/2020/02/16/linux/jian-shu-linux-de-qi-dong-guo-cheng/</url>
      
        <content type="html"><![CDATA[<p>本文将简单介绍一下Linux的启动过程，希望对那些安装Linux的过程中遇到了问题的朋友有些帮助</p><blockquote><p><strong>声明：</strong> 本人没用过UEFI模式和GPT分区格式，所有关于这两部分的内容都是网络上找的资料，仅供参考。</p></blockquote><h2 id="典型启动顺序"><a class="header-anchor" href="#典型启动顺序">¶</a>典型启动顺序</h2><ol><li>计算机通电后，CPU开始从一个固定的地址加载代码并开始执行，这个地址就是BIOS的驱动程序所在的位置，于是BIOS的驱动开始执行。</li><li>BIOS驱动首先进行一些自检工作，然后根据配置的启动顺序，依次尝试加载启动程序。比如配置的启动顺序是CD-&gt;网卡01-&gt;USB-&gt;硬盘。 BIOS 将先检查是否能从CD启动，如果不行，接着试着从网卡启动，再试USB盘，最后再试硬盘。</li><li>CD，U盘和硬盘的启动都是一样的，对BIOS来说，它们都是块设备，BIOS通过硬件访问接口直接访问这些块设备（如通过IDE访问硬盘），加载固定位置的内容到内存，然后跳转到那个内存的位置开始执行，这里固定位置所存放的就是Bootloader的代码，从这个时间点开始，启动的工作就由BIOS交接到了Bootloader手中了。对大多数发行版来说，CD和U盘里面放的都是安装程序，里面用的Bootloader一般都是<a href="http://www.syslinux.org/wiki/index.php?title=ISOLINUX" target="_blank" rel="noopener">isolinux</a>，而硬盘里面存放的是安装好的系统，常用的Bootloader是<a href="https://www.gnu.org/software/grub/" target="_blank" rel="noopener">GRUB2</a>，当然开源的Bootloader有<a href="https://en.wikipedia.org/wiki/Comparison_of_boot_loaders" target="_blank" rel="noopener">很多种</a>，并且各有各的特点.</li><li>从网卡启动稍微有所不同，当然前提条件是网卡支持PXE启动。 下面是大概的步骤<ol><li>从网卡中加载PXE firmware到内存并执行，里面主要包含一个很小的网络驱动和TFTP client的实现</li><li>发送UDP广播到当前局域网，向DHCP服务器要IP和NBP(Network Boot Program)的地址</li><li>DHCP服务器收到广播后，会发送应答，里面包含分配给请求机器的IP以及NBP的所在位置</li><li>将分配的IP应用到网卡上，然后根据收到的NBP的地址，用TFTP协议到相应的服务器上取相应的NBP文件（取文件的过程不再是广播，而是点对点的文件传输过程，所以当前网卡必须要有IP）</li><li>开始执行取到的NBP（Linux一般使用<a href="http://www.syslinux.org/wiki/index.php?title=PXELINUX" target="_blank" rel="noopener">pxelinux</a>作为NBP）</li></ol></li></ol><blockquote><p>从上面的过程可以看出，一个PXE服务器至少包含一个DHCP server和一个TFTP server。</p></blockquote><h2 id="以硬盘启动及GRUB2为例，接着介绍Linux的启动过程"><a class="header-anchor" href="#以硬盘启动及GRUB2为例，接着介绍Linux的启动过程">¶</a>以硬盘启动及GRUB2为例，接着介绍Linux的启动过程</h2><ol><li>BIOS加载硬盘<a href="https://en.wikipedia.org/wiki/Master_boot_record" target="_blank" rel="noopener">MBR</a>中的<a href="https://zh.wikipedia.org/wiki/GNU_GRUB" target="_blank" rel="noopener">GRUB</a>后，启动过程就被GRUB2接管</li><li>由于MBR里面空间很小，GRUB2只能放部分代码到里面，所以它采用了好几级的结构来加载自己，详情请点<a href="https://en.wikipedia.org/wiki/GNU_GRUB#Booting" target="_blank" rel="noopener">这里</a>，总之，最后GRUB2会加载/boot/grub/下的驱动到内存中。</li><li>GRUB2加载内核和initrd image，并启动内核。GRUB2和内核之间的协议请参考<a href="https://www.kernel.org/pub/linux/kernel/people/marcelo/linux-2.4/Documentation/i386/boot.txt" target="_blank" rel="noopener">i386/boot.txt</a>。</li><li>内核接管整个系统后，加载/sbin/init并创建第一个用户态的进程</li><li>init进程开始调用一系列的脚本来创建很多子进程，这些子进程负责初始化整个系统</li></ol><h2 id="注意事项："><a class="header-anchor" href="#注意事项：">¶</a>注意事项：</h2><h3 id="GRUB2"><a class="header-anchor" href="#GRUB2">¶</a>GRUB2</h3><p>GRUB2需要加载/boot下的grub模块才能工作，所以格式化Linux分区一定要注意，如果不小心格式化了/boot所在的分区，会导致GRUB2用不了，从而启动不了任何系统。<br>GRUB2同时需要加载硬盘上的Linux内核文件，所以它也需要有文件系统的驱动，当然它只需要读取文件，所以驱动很小。GRUB2已经支持所有的常见文件系统，并且完全支持LVM和RAID。</p><p>参考：</p><ul><li><a href="http://www.gnu.org/software/grub/manual/grub.html#Changes-from-GRUB-Legacy" target="_blank" rel="noopener">GRUB2: Differences from previous versions</a></li><li><a href="http://www.gnu.org/software/grub/manual/grub.html#Features" target="_blank" rel="noopener">GRUB2: features</a></li></ul><h3 id="BIOS-VS-UEFI"><a class="header-anchor" href="#BIOS-VS-UEFI">¶</a><a href="https://en.wikipedia.org/wiki/BIOS" target="_blank" rel="noopener">BIOS</a> VS <a href="https://en.wikipedia.org/wiki/Unified_Extensible_Firmware_Interface" target="_blank" rel="noopener">UEFI</a></h3><p>UEFI可以简单理解为新一代的BIOS，支持更多新的功能，当然它也向下兼容BIOS，现在新的主板都支持UEFI，只是我们BIOS叫习惯了，所以就算主板已经支持新的UEFI，我们还是把它当BIOS用。UEFI的优点请参考<a href="https://en.wikipedia.org/wiki/Unified_Extensible_Firmware_Interface#Advantages" target="_blank" rel="noopener">这里</a>。</p><p>BIOS和UEFI两者启动系统的方式不一样，BIOS是读取硬盘第一个扇区的MBR到内存中，然后将控制权交给MBR里的Bootloader。而UEFI是读取efi分区，如果efi分区存在且里面有启动程序的话，将控制权交给启动程序，否则和BIOS一样，读取硬盘第一个扇区的MBR到内存中，将控制权交给MBR里面的Bootloader。从这里可以看出：</p><ul><li><p>UEFI是兼容BIOS的，就是说就算主板支持UEFI，只要我们不用efi分区，主板还是按照原来BIOS的方式来启动系统</p></li><li><p>两者只能选其一，使用efi分区里面的启动程序，或者是MBR里面的Bootloader</p><p>那什么时候应该用UEFI呢？</p></li><li><p>如果这台机器原来没有任何系统，那可以完全不用关心是BIOS还是UEFI，因为就算BIOS模式，Linux也可以从GPT盘启动</p></li><li><p>如果机器上已经有了一个系统，那么就必须确保新安装的Linux和原有的系统采取同样的模式。</p></li></ul><p>如何判断原系统的模式：</p><ul><li><a href="http://www.howtogeek.com/175649/what-you-need-to-know-about-using-uefi-instead-of-the-bios/" target="_blank" rel="noopener">Windows 8</a>及以上版本默认采用UEFI模式, Windows 7默认用BIOS模式</li><li><a href="https://help.ubuntu.com/community/UEFI#Identifying_if_an_Ubuntu_has_been_installed_in_UEFI_mode" target="_blank" rel="noopener">Ubuntu</a></li></ul><p>如何以UEFI模式安装： <a href="https://help.ubuntu.com/community/UEFI" target="_blank" rel="noopener">Ubuntu</a></p><p>参考：</p><ul><li><a href="http://superuser.com/questions/496026/what-is-the-difference-in-boot-with-bios-and-boot-with-uefi" target="_blank" rel="noopener">What is the difference in “Boot with BIOS” and “Boot with UEFI”</a></li><li><a href="http://www.howtogeek.com/56958/" target="_blank" rel="noopener">Learn How UEFI Will Replace Your PC’s BIOS</a></li></ul><h3 id="MBR-VS-GPT"><a class="header-anchor" href="#MBR-VS-GPT">¶</a>MBR VS <a href="https://en.wikipedia.org/wiki/GUID_Partition_Table" target="_blank" rel="noopener">GPT</a></h3><p>MBR格式硬盘的布局</p><pre><code>    ------------------------------------------------------------------    |   |         |         |        |-------------------------------|    |MBR| 主分区1  | 主分区2 | 主分区3 | 扩展 |逻辑分区1|...|逻辑分区n   |    |   |         |         |        |-------------------------------|    ------------------------------------------------------------------                                        ↓     扩展分区是一个特殊的主分区，分区最前面包含所有逻辑分区的描述，包含大小，位置等</code></pre><ul><li>由于留给MBR的空间太小，所以MBR格式的硬盘只能支持四个分区，就是我们常说的四个主分区。如果想把磁盘分成大于4个分区，就需要将其中的一个或者多个分区设置成扩展分区，然后在扩展分区里面划分逻辑分区。</li><li>对Linux而言，可以安装在主分区和逻辑分区里面，所以怎么划分硬盘都没关系。但对于Windows而言，由于只支持安装在主分区里面，所以必须至少有一个主分区，如果我们安装Linux时不小心将磁盘全部划分成逻辑分区，则以后要安装Windows就比较麻烦，需要重新划分磁盘分区格式。</li><li>同样由于留给MBR的空间太小，它所能表述的磁盘空间有限，只能支持小于2T的硬盘。</li></ul><p>GPT主要用来替换MBR，并且配合UEFI使用。 在Windows和OS X上，只支持通过UEFI方式启动GPT硬盘，而FreeBSD，Linux依然支持BIOS模式启动GPT硬盘。</p><p>GPT的主要优点：</p><ul><li>支持几乎无限制的磁盘分区个数，再也不需要主分区、扩展分区和逻辑分区这些概念了</li><li>支持超过2T的硬盘</li><li>分区数据在磁盘的不同位置存有多份，且有CRC校验码，所以更安全</li></ul><p>参考：</p><ul><li><a href="http://www.howtogeek.com/193669/whats-the-difference-between-gpt-and-mbr-when-partitioning-a-drive/" target="_blank" rel="noopener">What’s the Difference Between GPT and MBR When Partitioning a Drive?</a></li></ul><h3 id="内核参数和initrd-image"><a class="header-anchor" href="#内核参数和initrd-image">¶</a>内核参数和initrd image</h3><p>下面是一个GRUB2配置的例子</p><pre><code>    kernel /boot/vmlinuz-2.6.9-1.667 ro root=/dev/hda5 quiet    initrd /boot/initrd-2.6.9-1.667.img</code></pre><p>当GRUB2加载完Linux内核（/boot/vmlinuz-2.6.9-1.667）后，将这里的“ro root=/dev/hda5 quiet”做为参数传给Linux内核，然后将控制权交给Linux内核。Linux支持的内核参数请点<a href="https://www.kernel.org/doc/Documentation/kernel-parameters.txt" target="_blank" rel="noopener">这里</a>，其中一个重要的参数是&quot;init&quot;</p><pre><code>  'init=...'      指定init程序的位置，Linux内核初始化完成后，将运行该位置所指定的程序    ，      并将该进程作为第一个用户态进程，设置其进程ID为1      如果没有指定这个参数，或者这个参数指定的位置不存在，      Linux内核将依次搜索/sbin/init, /etc/init, /bin/init, /bin/sh这些路径，      如果都不存在，Linux将启动失败。    　　这里指定的init程序可以是可执行文件，软链接，也可以是脚本。</code></pre><h4 id="initrd-image是干嘛的呢？"><a class="header-anchor" href="#initrd-image是干嘛的呢？">¶</a>initrd image是干嘛的呢？</h4><p>我们都知道Linux内核模块的概念，比方说Linux支持N种不同的文件系统，Ext2/3/4，XFS, Btrfs等等，那需要把所有的这些文件系统驱动都编译进内核吗？当然不需要，因为这样做会导致内核太大，运行时占用太多的内存，取而代之，我们会把这些驱动编译成一个一个的内核模块，在需要用到的时候再把它们加载进内核，其它时间存放在磁盘上就好了。</p><p>现在有个问题，在GRUB将控制权交给Linux内核后，内核需要启动init程序，这个init程序是放在某个磁盘分区上的，这个磁盘分区用的是N个文件系统中的某一个，内核到哪里找这个文件系统的驱动呢？这个时候initrd image出场了，它里面包含了很多驱动模块，并且用的是内存文件系统，内存文件系统的驱动已经编译到内核中了，所以内核是可以直接访问initrd image的(老版本的initrd可能用的其它格式，但不管怎么样，肯定是被内核支持的格式)。当然initrd image里面不仅仅只包含文件系统的驱动，还有其它的很多文件，这个跟每个发行版有关，具体的内容可以参考相应的发行版。</p><h4 id="init"><a class="header-anchor" href="#init">¶</a>init</h4><p>内核启动的第一个用户态进程init到底是个什么东东？其实它就是一个普通的程序，内核并没有对它做什么要求，只是别退出就好，init进程如果挂了的话，系统就崩溃了，至于init进程干些啥，启动其它的哪些进程，跟内核已经没有关系了，内核的任务就是管理硬件资源并调度这些用户态进程。我们也可以写一个我们自己的init程序放到那里，它也会正常的被内核启动起来。</p><p>除了在init进程里指定了handler的信号外，内核会帮init进程屏蔽掉其他所有信号，包括普通进程无法捕获和屏蔽的信号SIGKILL和SIGSTOP，这样可以防止其他进程不小心kill掉init进程导致系统挂掉。这是内核给用户态启动的第一个进程的特殊待遇。</p><p>init是用户态的第一个进程，所以非常重要，各个Linux发行版都用这个进程来创建很多子进程，然后让这些子进程来初始化用户态的环境，如mount各个分区，启动各个服务等，现在各个发行版主要采用这三种框架中的一种<a href="http://savannah.nongnu.org/projects/sysvinit" target="_blank" rel="noopener">sysvinit</a>，<a href="http://upstart.ubuntu.com/" target="_blank" rel="noopener">upstart</a>，<a href="https://www.freedesktop.org/wiki/Software/systemd/" target="_blank" rel="noopener">systemd</a></p><p>简单点说，sysvinit出现最早，简单易用，但缺点是速度慢，比如有10个服务需要在开机时启动，那么sysvinit只能一个接一个的启动它们，即使他们之间没有任何关系，也不能并行的启动。于是出现了upstart，upstart基于事件驱动，可以让没有关系的服务并行的启动，这样可以加快开机速度。但是人们觉得还是不够快，于是出现了systemd，它可以通过一定的技术和技巧让有关系的服务也能并发的启动，当然导致的结果是systemd比较复杂。这里只提到了启动速度，当然还有其他方面的改进，详情请参考：</p><ul><li><a href="https://www.ibm.com/developerworks/cn/linux/1407_liuming_init1/" target="_blank" rel="noopener">浅析 Linux 初始化 init 系统，第 1 部分: sysvinit</a></li><li><a href="https://www.ibm.com/developerworks/cn/linux/1407_liuming_init2/" target="_blank" rel="noopener">浅析 Linux 初始化 init 系统，第 2 部分: UpStart</a></li><li><a href="https://www.ibm.com/developerworks/cn/linux/1407_liuming_init3/" target="_blank" rel="noopener">浅析 Linux 初始化 init 系统，第 3 部分: Systemd</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql随机</title>
      <link href="/2020/02/16/mysql/sui-ji/"/>
      <url>/2020/02/16/mysql/sui-ji/</url>
      
        <content type="html"><![CDATA[<h1>命令行中特殊转义字符</h1><p>\G 行转列并发送给 mysql server<br>\g 等同于 ;<br>! 执行系统命令<br>\q exit<br>\c 清除当前SQL（不执行）<br>\s mysql status 信息<br>其他参考 \h</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JSONP原理</title>
      <link href="/2020/02/16/web-qian-duan/jsonp-yuan-li/"/>
      <url>/2020/02/16/web-qian-duan/jsonp-yuan-li/</url>
      
        <content type="html"><![CDATA[<h1>script 标签</h1><p>script 标签会根据 src 中的内容构建一个请求发出，然后将响应回来的包体作为一段 js 脚本(默认)进行执行。同时这个请求不受同源策略限制。</p><h1>jsonp</h1><p>jsonp 的原理中有几个要素组成：</p><ol><li><p>服务端将原本处理业务请求的 api 的返回结果(json格式)进行包装。例如以下是原本订单创建后返回订单号的一个例子：</p><pre><code>{ orderNo: &quot;1234&quot; }</code></pre><p>现在改成：</p><pre><code>someCallBackFunction({ orderNo: &quot;1234&quot; })</code></pre><p>其中 someCallBackFunction 是客户端中要请求服务端返回的订单号的函数，这个函数要在客户端发起创建订单api的时候告诉服务端，如何告诉服务端需要双方约定，例如增加一个 URL query 参数 <code>cb</code> 指定回调函数名称。</p></li><li><p>客户端根据双方约定好的指定回调函数名称的参数构建一个 <code>script</code> 标签，并在 <code>src</code> 中塞进服务端改造之后的创建订单 jsonp url，并指定 <code>cb</code> 参数为 <code>someCallBackFunction</code>。</p></li><li><p>此时浏览器会构建请求发送到服务端。</p></li><li><p>服务端收到请求后进行订单创建并返回第一步中返回的内容。</p></li><li><p>浏览器收到返回内容后将其作为一个 js 脚本解析，随即调用 <code>someCallBackFunction</code> 函数。</p></li></ol><h1>参考阅读</h1><p><a href="https://stackoverflow.com/questions/10193085/confused-on-how-a-jsonp-request-works" target="_blank" rel="noopener">Confused on how a JSONP request works</a></p><p><a href="https://wangdoc.com/javascript/bom/engine.html" target="_blank" rel="noopener">script标签原理</a></p>]]></content>
      
      
      <categories>
          
          <category> web前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JSONP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>学习前端资料记录</title>
      <link href="/2020/02/16/web-qian-duan/xue-xi-qian-duan-zi-liao-ji-lu/"/>
      <url>/2020/02/16/web-qian-duan/xue-xi-qian-duan-zi-liao-ji-lu/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.w3schools.com/js/default.asp" target="_blank" rel="noopener">w3c</a></p><p><a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Object" target="_blank" rel="noopener">信息较详细的网站</a></p><p><a href="https://www.zhihu.com/question/19562698" target="_blank" rel="noopener">书籍推荐1</a></p><p><a href="https://zhuanlan.zhihu.com/p/54841090https://zhuanlan.zhihu.com/p/54841090" target="_blank" rel="noopener">书籍推荐2</a></p><p><a href="http://www.ruanyifeng.com/blog/javascript/" target="_blank" rel="noopener">一个大牛的blog</a></p><p><a href="https://wangdoc.com/javascript/" target="_blank" rel="noopener">还是阮一峰老师的js教程</a></p>]]></content>
      
      
      <categories>
          
          <category> web前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习资料 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>待刷算法题</title>
      <link href="/2020/02/16/suan-fa/dai-chu-li/"/>
      <url>/2020/02/16/suan-fa/dai-chu-li/</url>
      
        <content type="html"><![CDATA[<h3 id="预习知识点："><a class="header-anchor" href="#预习知识点：">¶</a>预习知识点：</h3><ul><li><a href="https://time.geekbang.org/column/article/68638" target="_blank" rel="noopener">红黑树（上）：为什么工程中都用红黑树这种二叉树？</a></li><li><a href="https://time.geekbang.org/column/article/68976" target="_blank" rel="noopener">红黑树（下）：掌握这些技巧，你也可以实现一个红黑树</a></li><li><a href="https://time.geekbang.org/column/article/78175" target="_blank" rel="noopener">搜索：如何用 A* 搜索算法实现游戏中的寻路功能？</a></li><li><a href="https://time.geekbang.org/column/article/72414" target="_blank" rel="noopener">Trie 树：如何实现搜索引擎的搜索关键词提示功能？</a></li><li><a href="https://time.geekbang.org/column/article/77830" target="_blank" rel="noopener">B+ 树：MySQL 数据库索引是如何实现的？</a></li><li><a href="https://time.geekbang.org/column/article/78175" target="_blank" rel="noopener">搜索：如何用 A* 搜索算法实现游戏中的寻路功能？</a></li><li><a href="https://time.geekbang.org/column/article/78449" target="_blank" rel="noopener">索引：如何在海量数据中快速查找某个数据？</a></li></ul><h3 id="预习题目："><a class="header-anchor" href="#预习题目：">¶</a>预习题目：</h3><ul><li><a href="https://leetcode-cn.com/problems/implement-trie-prefix-tree/#/description" target="_blank" rel="noopener">实现 Trie (前缀树)</a></li><li><a href="https://leetcode-cn.com/problems/word-search-ii/" target="_blank" rel="noopener">单词搜索 II</a></li><li><a href="https://leetcode-cn.com/problems/number-of-islands/" target="_blank" rel="noopener">岛屿数量</a></li><li><a href="https://leetcode-cn.com/problems/valid-sudoku/description/" target="_blank" rel="noopener">有效的数独</a></li><li><a href="https://leetcode-cn.com/problems/n-queens/" target="_blank" rel="noopener">N 皇后</a></li><li><a href="https://leetcode-cn.com/problems/word-ladder/" target="_blank" rel="noopener">单词接龙</a></li><li><a href="https://leetcode-cn.com/problems/shortest-path-in-binary-matrix/" target="_blank" rel="noopener">二进制矩阵中的最短路径</a></li></ul><h1>6.字典树和并查集</h1><h3 id="Trie树的基本实现和特性"><a class="header-anchor" href="#Trie树的基本实现和特性">¶</a>Trie树的基本实现和特性</h3><ul><li><a href="https://leetcode-cn.com/problems/binary-tree-level-order-traversal/" target="_blank" rel="noopener">二叉树的层次遍历</a></li><li><a href="https://leetcode-cn.com/problems/implement-trie-prefix-tree/solution/" target="_blank" rel="noopener">实现 Trie</a></li><li><a href="https://shimo.im/docs/Pk6vPY3HJ9hKkh33" target="_blank" rel="noopener">Tire 树代码模板</a></li></ul><h3 id="Trie树实战题目解析：单词搜索2"><a class="header-anchor" href="#Trie树实战题目解析：单词搜索2">¶</a>Trie树实战题目解析：单词搜索2</h3><ul><li><a href="https://leetcode-cn.com/problems/implement-trie-prefix-tree/#/description" target="_blank" rel="noopener">https://leetcode-cn.com/problems/implement-trie-prefix-tree/#/description</a></li><li><a href="https://leetcode-cn.com/problems/word-search-ii/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/word-search-ii/</a></li></ul><h3 id="并查集的基本实现、特性和实战题目解析"><a class="header-anchor" href="#并查集的基本实现、特性和实战题目解析">¶</a>并查集的基本实现、特性和实战题目解析</h3><p>参考链接</p><ul><li><a href="https://leetcode-cn.com/problems/number-of-islands/" target="_blank" rel="noopener">岛屿数量</a></li><li><a href="https://shimo.im/docs/ydPCH33xDhK9YwWR" target="_blank" rel="noopener">并查集代码模板</a></li></ul><p>实战题目</p><ul><li><a href="https://leetcode-cn.com/problems/friend-circles" target="_blank" rel="noopener">https://leetcode-cn.com/problems/friend-circles</a></li><li><a href="https://leetcode-cn.com/problems/number-of-islands/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/number-of-islands/</a></li><li><a href="https://leetcode-cn.com/problems/surrounded-regions/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/surrounded-regions/</a></li></ul><h1>6.高级搜索</h1><h3 id="剪枝的实现和特性"><a class="header-anchor" href="#剪枝的实现和特性">¶</a>剪枝的实现和特性</h3><ul><li><a href="http://shimo.im/docs/ddgwCccJQKxkrcTq/" target="_blank" rel="noopener">DFS 代码模板</a></li><li><a href="http://shimo.im/docs/P8TqKHGKt3ytkYYd/" target="_blank" rel="noopener">BFS 代码模板</a></li><li><a href="https://nikcheerla.github.io/deeplearningschool/2018/01/01/AlphaZero-Explained/" target="_blank" rel="noopener">AlphaZero Explained</a></li><li><a href="https://en.wikipedia.org/wiki/Game_complexity" target="_blank" rel="noopener">棋类复杂度</a></li></ul><h4 id="剪枝实战题目解析：数独"><a class="header-anchor" href="#剪枝实战题目解析：数独">¶</a>剪枝实战题目解析：数独</h4><ul><li><a href="https://leetcode-cn.com/problems/climbing-stairs/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/climbing-stairs/</a></li><li><a href="https://leetcode-cn.com/problems/generate-parentheses/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/generate-parentheses/</a></li><li><a href="https://leetcode-cn.com/problems/n-queens/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/n-queens</a></li><li><a href="https://leetcode-cn.com/problems/valid-sudoku/description/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/valid-sudoku/description/</a></li><li><a href="https://leetcode-cn.com/problems/sudoku-solver/#/description" target="_blank" rel="noopener">https://leetcode-cn.com/problems/sudoku-solver/#/description</a></li></ul><h3 id="双向BFS的实现、特性和题解"><a class="header-anchor" href="#双向BFS的实现、特性和题解">¶</a>双向BFS的实现、特性和题解</h3><ul><li><a href="https://leetcode-cn.com/problems/word-ladder/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/word-ladder/</a></li><li><a href="https://leetcode-cn.com/problems/minimum-genetic-mutation/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/minimum-genetic-mutation/</a></li></ul><h3 id="启发式搜索的实现、特性和题解"><a class="header-anchor" href="#启发式搜索的实现、特性和题解">¶</a>启发式搜索的实现、特性和题解</h3><p>参考链接</p><ul><li><a href="https://shimo.im/docs/CXvjHyWhpQcxXjcw/" target="_blank" rel="noopener">A* 代码模板</a></li><li><a href="https://dataaspirant.com/2015/04/11/five-most-popular-similarity-measures-implementation-in-python/" target="_blank" rel="noopener">相似度测量方法</a></li><li><a href="https://leetcode.com/problems/shortest-path-in-binary-matrix/discuss/313347/A*-search-in-Python" target="_blank" rel="noopener">二进制矩阵中的最短路径的 A* 解法</a></li><li><a href="https://zxi.mytechroad.com/blog/searching/8-puzzles-bidirectional-astar-vs-bidirectional-bfs/" target="_blank" rel="noopener">8 puzzles 解法比较</a></li></ul><p>实战题目</p><ul><li><a href="https://leetcode-cn.com/problems/shortest-path-in-binary-matrix/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/shortest-path-in-binary-matrix/</a></li><li><a href="https://leetcode-cn.com/problems/sliding-puzzle/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/sliding-puzzle/</a></li><li><a href="https://leetcode-cn.com/problems/sudoku-solver/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/sudoku-solver/</a></li></ul><h1>6.红黑树和AVL树</h1><ul><li><a href="https://en.wikipedia.org/wiki/Self-balancing_binary_search_tree" target="_blank" rel="noopener">平衡树</a></li></ul><h2 id="本周作业"><a class="header-anchor" href="#本周作业">¶</a>本周作业</h2><h3 id="简单"><a class="header-anchor" href="#简单">¶</a>简单</h3><ul><li><a href="https://leetcode-cn.com/problems/climbing-stairs/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/climbing-stairs/</a></li></ul><h3 id="中等"><a class="header-anchor" href="#中等">¶</a>中等</h3><ul><li><a href="https://leetcode-cn.com/problems/implement-trie-prefix-tree/#/description" target="_blank" rel="noopener">https://leetcode-cn.com/problems/implement-trie-prefix-tree/#/description</a></li><li><a href="https://leetcode-cn.com/problems/friend-circles" target="_blank" rel="noopener">https://leetcode-cn.com/problems/friend-circles</a></li><li><a href="https://leetcode-cn.com/problems/number-of-islands/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/number-of-islands/</a></li><li><a href="https://leetcode-cn.com/problems/surrounded-regions/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/surrounded-regions/</a></li><li><a href="https://leetcode-cn.com/problems/valid-sudoku/description/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/valid-sudoku/description/</a></li><li><a href="https://leetcode-cn.com/problems/generate-parentheses/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/generate-parentheses/</a></li><li><a href="https://leetcode-cn.com/problems/word-ladder/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/word-ladder/</a></li><li><a href="https://leetcode-cn.com/problems/minimum-genetic-mutation/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/minimum-genetic-mutation/</a></li></ul><h3 id="困难"><a class="header-anchor" href="#困难">¶</a>困难</h3><ul><li><a href="https://leetcode-cn.com/problems/word-search-ii/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/word-search-ii/</a></li><li><a href="https://leetcode-cn.com/problems/n-queens/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/n-queens</a></li><li><a href="https://leetcode-cn.com/problems/sudoku-solver/#/description" target="_blank" rel="noopener">https://leetcode-cn.com/problems/sudoku-solver/#/description</a></li></ul><h2 id="下周预习"><a class="header-anchor" href="#下周预习">¶</a>下周预习</h2><h3 id="预习知识点：-v2"><a class="header-anchor" href="#预习知识点：-v2">¶</a>预习知识点：</h3><ul><li><a href="https://time.geekbang.org/column/article/76827" target="_blank" rel="noopener">位图：如何实现网页爬虫中的 URL 去重功能？</a></li><li><a href="https://time.geekbang.org/column/article/77142" target="_blank" rel="noopener">概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？</a></li><li><a href="https://time.geekbang.org/column/article/41802" target="_blank" rel="noopener">排序（上）：为什么插入排序比冒泡排序更受欢迎？</a></li><li><a href="https://time.geekbang.org/column/article/41913" target="_blank" rel="noopener">排序（下）：如何用快排思想在 O(n) 内查找第 K 大元素？</a></li><li><a href="https://time.geekbang.org/column/article/42038" target="_blank" rel="noopener">线性排序：如何根据年龄给 100 万用户数据排序？</a></li><li><a href="https://time.geekbang.org/column/article/42359" target="_blank" rel="noopener">排序优化：如何实现一个通用的、高性能的排序函数？</a></li><li><a href="https://time.geekbang.org/column/article/69913" target="_blank" rel="noopener">堆和堆排序：为什么说堆排序没有快速排序快？</a></li><li><a href="https://time.geekbang.org/column/article/76207" target="_blank" rel="noopener">拓扑排序：如何确定代码源文件的编译依赖关系？</a></li></ul><h3 id="预习题目：-v2"><a class="header-anchor" href="#预习题目：-v2">¶</a>预习题目：</h3><ul><li><a href="https://leetcode-cn.com/problems/n-queens/description/" target="_blank" rel="noopener">N 皇后</a></li><li><a href="https://leetcode-cn.com/problems/lru-cache/#/" target="_blank" rel="noopener">LRU 缓存机制</a></li><li><a href="https://leetcode-cn.com/problems/valid-anagram/" target="_blank" rel="noopener">有效的字母异位词</a></li></ul><h1>7.位运算</h1><h3 id="位运算基础及实战要点"><a class="header-anchor" href="#位运算基础及实战要点">¶</a>位运算基础及实战要点</h3><ul><li><a href="https://zh.wikihow.com/%E4%BB%8E%E5%8D%81%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2%E4%B8%BA%E4%BA%8C%E8%BF%9B%E5%88%B6" target="_blank" rel="noopener">如何从十进制转换为二进制</a></li></ul><h3 id="位运算实战题目解析"><a class="header-anchor" href="#位运算实战题目解析">¶</a>位运算实战题目解析</h3><p>参考链接</p><ul><li><a href="https://shimo.im/docs/rHTyt8hcpT6D9Tj8/" target="_blank" rel="noopener">N 皇后位运算代码示例</a></li></ul><p>实战题目 / 课后作业</p><ul><li><a href="https://leetcode-cn.com/problems/number-of-1-bits/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/number-of-1-bits/</a></li><li><a href="https://leetcode-cn.com/problems/power-of-two/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/power-of-two/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-bits/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-bits/</a></li><li><a href="https://leetcode-cn.com/problems/n-queens/description/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/n-queens/description/</a></li><li><a href="https://leetcode-cn.com/problems/n-queens-ii/description/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/n-queens-ii/description/</a></li><li><a href="https://leetcode-cn.com/problems/counting-bits/description/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/counting-bits/description/</a></li></ul><h1>7.布隆过滤器和LRU缓存</h1><h3 id="布隆过滤器的实现及应用"><a class="header-anchor" href="#布隆过滤器的实现及应用">¶</a>布隆过滤器的实现及应用</h3><ul><li><a href="https://www.cnblogs.com/cpselvis/p/6265825.html" target="_blank" rel="noopener">布隆过滤器的原理和实现</a></li><li><a href="https://blog.csdn.net/tianyaleixiaowu/article/details/74721877" target="_blank" rel="noopener">使用布隆过滤器解决缓存击穿、垃圾邮件识别、集合判重</a></li><li><a href="https://shimo.im/docs/xKwrcwrDxRv3QpKG/" target="_blank" rel="noopener">布隆过滤器 Python 代码示例</a></li><li><a href="https://www.geeksforgeeks.org/bloom-filters-introduction-and-python-implementation/" target="_blank" rel="noopener">布隆过滤器 Python 实现示例</a></li><li><a href="https://github.com/jhgg/pybloof" target="_blank" rel="noopener">高性能布隆过滤器 Python 实现示例</a></li><li><a href="https://github.com/lovasoa/bloomfilter/blob/master/src/main/java/BloomFilter.java" target="_blank" rel="noopener">布隆过滤器 Java 实现示例 1</a></li><li><a href="https://github.com/Baqend/Orestes-Bloomfilter" target="_blank" rel="noopener">布隆过滤器 Java 实现示例 2</a></li></ul><h3 id="LRU-Cache的实现、应用和题解"><a class="header-anchor" href="#LRU-Cache的实现、应用和题解">¶</a>LRU Cache的实现、应用和题解</h3><p>参考链接</p><ul><li><a href="https://www.sqlpassion.at/archive/2018/01/06/understanding-the-meltdown-exploit-in-my-own-simple-words/" target="_blank" rel="noopener">Understanding the Meltdown exploit</a></li><li><a href="https://en.wikipedia.org/wiki/Cache_replacement_policies" target="_blank" rel="noopener">替换算法总揽</a></li><li><a href="https://shimo.im/docs/tTxRkGwJpXG6WkGY/" target="_blank" rel="noopener">LRU Cache Python 代码示例</a></li></ul><p>实战题目 / 课后作业</p><ul><li><a href="https://leetcode-cn.com/problems/lru-cache/#/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/lru-cache/#/</a></li></ul><h1>7.排序算法</h1><h3 id="初级排序和高级排序的实现和特性"><a class="header-anchor" href="#初级排序和高级排序的实现和特性">¶</a>初级排序和高级排序的实现和特性</h3><p>参考链接</p><ul><li><a href="https://www.cnblogs.com/onepixel/p/7674659.html" target="_blank" rel="noopener">十大经典排序算法</a></li><li><a href="https://shimo.im/docs/98KjvGwwGpTpYGKy/" target="_blank" rel="noopener">快速排序代码示例</a></li><li><a href="https://shimo.im/docs/YqgG6vtdKwkXJkWx/" target="_blank" rel="noopener">归并排序代码示例</a></li><li><a href="https://shimo.im/docs/6kRVHRphpgjHgCtx/" target="_blank" rel="noopener">堆排序代码示例</a></li><li>直播课回顾: <a href="https://pan.baidu.com/s/1sFuZ8GjDCXy5mPCNLZhHxw" target="_blank" rel="noopener">https://pan.baidu.com/s/1sFuZ8GjDCXy5mPCNLZhHxw </a>提取码: 2rdy</li></ul><p>课后作业</p><p>用自己熟悉的编程语言，手写各种初级排序代码，提交到第 7 周学习总结中。</p><h3 id="特殊排序及实战题目详解"><a class="header-anchor" href="#特殊排序及实战题目详解">¶</a>特殊排序及实战题目详解</h3><p>参考链接</p><ul><li><a href="https://www.cnblogs.com/onepixel/p/7674659.html" target="_blank" rel="noopener">十大经典排序算法</a></li><li><a href="https://www.bilibili.com/video/av25136272" target="_blank" rel="noopener">9 种经典排序算法可视化动画</a></li><li><a href="https://www.bilibili.com/video/av63851336" target="_blank" rel="noopener">6 分钟看完 15 种排序算法动画展示</a></li></ul><p>实战题目 / 课后作业</p><ul><li><a href="https://leetcode-cn.com/problems/relative-sort-array/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/relative-sort-array/</a></li><li><a href="https://leetcode-cn.com/problems/valid-anagram/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/valid-anagram/</a></li><li><a href="https://leetcode-cn.com/problems/design-a-leaderboard/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/design-a-leaderboard/</a></li><li><a href="https://leetcode-cn.com/problems/merge-intervals/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/merge-intervals/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-pairs/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-pairs/</a></li></ul><h2 id="本周作业-v2"><a class="header-anchor" href="#本周作业-v2">¶</a>本周作业</h2><p>简单</p><ul><li><a href="https://leetcode-cn.com/problems/number-of-1-bits/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/number-of-1-bits/</a></li><li><a href="https://leetcode-cn.com/problems/power-of-two/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/power-of-two/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-bits/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-bits/</a></li><li>用自己熟悉的编程语言，手写各种初级排序代码，提交到第 7 周学习总结中。</li><li><a href="https://leetcode-cn.com/problems/relative-sort-array/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/relative-sort-array/</a></li><li><a href="https://leetcode-cn.com/problems/valid-anagram/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/valid-anagram/</a></li></ul><p>中等</p><ul><li><a href="https://leetcode-cn.com/problems/lru-cache/#/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/lru-cache/#/</a></li><li><a href="https://leetcode-cn.com/problems/design-a-leaderboard/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/design-a-leaderboard/</a></li><li><a href="https://leetcode-cn.com/problems/merge-intervals/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/merge-intervals/</a></li></ul><p>困难</p><ul><li><a href="https://leetcode-cn.com/problems/n-queens/description/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/n-queens/description/</a></li><li><a href="https://leetcode-cn.com/problems/n-queens-ii/description/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/n-queens-ii/description/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-pairs/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-pairs/</a></li></ul><h2 id="下周预习-v2"><a class="header-anchor" href="#下周预习-v2">¶</a>下周预习</h2><h3 id="预习知识点：-v3"><a class="header-anchor" href="#预习知识点：-v3">¶</a>预习知识点：</h3><ul><li><a href="http://time.geekbang.org/column/article/71187" target="_blank" rel="noopener">字符串匹配基础：如何借助哈希算法实现高效字符串匹配？</a></li><li><a href="http://time.geekbang.org/column/article/71525" target="_blank" rel="noopener">字符串匹配基础：如何实现文本编辑器中的查找功能？</a></li><li><a href="http://time.geekbang.org/column/article/71845" target="_blank" rel="noopener">字符串匹配基础：如何借助 BM 算法轻松理解 KMP 算法？</a></li></ul><h3 id="预习题目：-v3"><a class="header-anchor" href="#预习题目：-v3">¶</a>预习题目：</h3><ul><li><a href="http://leetcode-cn.com/problems/unique-paths/" target="_blank" rel="noopener">不同路径</a></li><li><a href="http://leetcode-cn.com/problems/minimum-path-sum/" target="_blank" rel="noopener">最小路径和</a></li></ul><h1>8.高级动态规划</h1><h3 id="动态规划、状态转移方程串讲"><a class="header-anchor" href="#动态规划、状态转移方程串讲">¶</a>动态规划、状态转移方程串讲</h3><p>参考链接</p><ul><li><a href="https://leetcode-cn.com/problems/climbing-stairs/" target="_blank" rel="noopener">爬楼梯</a></li><li><a href="https://leetcode-cn.com/problems/unique-paths/" target="_blank" rel="noopener">不同路径</a></li><li><a href="https://leetcode-cn.com/problems/house-robber/" target="_blank" rel="noopener">打家劫舍</a></li><li><a href="https://leetcode-cn.com/problems/minimum-path-sum/" target="_blank" rel="noopener">最小路径和</a></li><li><a href="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/" target="_blank" rel="noopener">股票买卖</a></li></ul><p>课后作业</p><p>在第 8 周学习总结中，写出<a href="https://leetcode-cn.com/problems/unique-paths-ii/" target="_blank" rel="noopener">不同路径 2 </a>这道题目的状态转移方程。</p><h3 id="高级动态规划题目详解"><a class="header-anchor" href="#高级动态规划题目详解">¶</a>高级动态规划题目详解</h3><p>参考链接</p><ul><li><a href="https://leetcode-cn.com/problems/climbing-stairs/" target="_blank" rel="noopener">爬楼梯</a></li><li><a href="https://leetcode-cn.com/problems/min-cost-climbing-stairs/" target="_blank" rel="noopener">使用最小花费爬楼梯</a></li><li><a href="https://leetcode-cn.com/problems/edit-distance/" target="_blank" rel="noopener">编辑距离</a></li></ul><p>课后作业</p><ul><li><a href="https://leetcode-cn.com/problems/longest-increasing-subsequence/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-increasing-subsequence/</a></li><li><a href="https://leetcode-cn.com/problems/decode-ways/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/decode-ways/</a></li><li><a href="https://leetcode-cn.com/problems/longest-valid-parentheses/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-valid-parentheses/</a></li><li><a href="https://leetcode-cn.com/problems/maximal-rectangle/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/maximal-rectangle/</a></li><li><a href="https://leetcode-cn.com/problems/distinct-subsequences/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/distinct-subsequences/</a></li><li><a href="https://leetcode-cn.com/problems/race-car/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/race-car/</a></li></ul><h1>8.字符串算法</h1><h3 id="字符串基础知识和引申题目"><a class="header-anchor" href="#字符串基础知识和引申题目">¶</a>字符串基础知识和引申题目</h3><p>参考链接</p><ul><li><a href="https://lemire.me/blog/2017/07/07/are-your-strings-immutable/" target="_blank" rel="noopener">不可变字符串</a></li><li><a href="https://shimo.im/docs/KkDKkpWxjjrJXdpY/" target="_blank" rel="noopener">Atoi 代码示例</a></li></ul><p>字符串基础问题</p><ul><li><a href="https://leetcode-cn.com/problems/to-lower-case/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/to-lower-case/</a></li><li><a href="https://leetcode-cn.com/problems/length-of-last-word/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/length-of-last-word/</a></li><li><a href="https://leetcode-cn.com/problems/jewels-and-stones/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/jewels-and-stones/</a></li><li><a href="https://leetcode-cn.com/problems/first-unique-character-in-a-string/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/first-unique-character-in-a-string/</a></li><li><a href="https://leetcode-cn.com/problems/string-to-integer-atoi/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/string-to-integer-atoi/</a></li></ul><p>字符串操作问题</p><ul><li><a href="https://leetcode-cn.com/problems/longest-common-prefix/description/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-common-prefix/description/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-string" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-string</a></li><li><a href="https://leetcode-cn.com/problems/reverse-string-ii/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-string-ii/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-words-in-a-string/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-words-in-a-string/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-words-in-a-string-iii/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-words-in-a-string-iii/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-only-letters/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-only-letters/</a></li></ul><p>异位词问题</p><ul><li><a href="https://leetcode-cn.com/problems/valid-anagram/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/valid-anagram/</a></li><li><a href="https://leetcode-cn.com/problems/group-anagrams/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/group-anagrams/</a></li><li><a href="https://leetcode-cn.com/problems/find-all-anagrams-in-a-string/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/find-all-anagrams-in-a-string/</a></li></ul><p>回文串问题</p><ul><li><a href="https://leetcode-cn.com/problems/valid-palindrome/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/valid-palindrome/</a></li><li><a href="https://leetcode-cn.com/problems/valid-palindrome-ii/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/valid-palindrome-ii/</a></li><li><a href="https://leetcode-cn.com/problems/longest-palindromic-substring/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-palindromic-substring/</a></li></ul><h3 id="高级字符串算法"><a class="header-anchor" href="#高级字符串算法">¶</a>高级字符串算法</h3><p>最长子串、子序列问题</p><ul><li><a href="https://leetcode-cn.com/problems/longest-common-subsequence/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-common-subsequence/</a></li><li><a href="https://leetcode-cn.com/problems/edit-distance/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/edit-distance/</a></li><li><a href="https://leetcode-cn.com/problems/longest-palindromic-substring/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-palindromic-substring/</a></li></ul><p>字符串 +DP 问题</p><ul><li><a href="https://leetcode-cn.com/problems/regular-expression-matching/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/regular-expression-matching/</a></li><li><a href="https://leetcode-cn.com/problems/regular-expression-matching/solution/ji-yu-guan-fang-ti-jie-gen-xiang-xi-de-jiang-jie-b/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/regular-expression-matching/solution/ji-yu-guan-fang-ti-jie-gen-xiang-xi-de-jiang-jie-b/</a></li><li><a href="https://leetcode-cn.com/problems/wildcard-matching/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/wildcard-matching/</a></li><li><a href="https://leetcode-cn.com/problems/distinct-subsequences/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/distinct-subsequences/</a></li></ul><h3 id="字符串匹配算法"><a class="header-anchor" href="#字符串匹配算法">¶</a>字符串匹配算法</h3><p>参考链接</p><ul><li><a href="https://www.ruanyifeng.com/blog/2013/05/boyer-moore_string_search_algorithm.html" target="_blank" rel="noopener">Boyer-Moore 算法</a></li><li><a href="https://blog.csdn.net/u012505432/article/details/52210975" target="_blank" rel="noopener">Sunday 算法</a></li><li><a href="https://shimo.im/docs/dQDxQW8yXPXxh3Hg/" target="_blank" rel="noopener">字符串匹配暴力法代码示例</a></li><li><a href="https://shimo.im/docs/KXDdkT99TVtXvTXP/" target="_blank" rel="noopener">Rabin-Karp 代码示例</a></li><li><a href="https://www.bilibili.com/video/av11866460?from=search&amp;seid=17425875345653862171" target="_blank" rel="noopener">KMP 字符串匹配算法视频</a></li><li><a href="http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html" target="_blank" rel="noopener">字符串匹配的 KMP 算法</a></li></ul><p>课后作业</p><ul><li><a href="https://leetcode-cn.com/problems/first-unique-character-in-a-string/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/first-unique-character-in-a-string/</a></li><li><a href="https://leetcode-cn.com/problems/string-to-integer-atoi/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/string-to-integer-atoi/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-string-ii/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-string-ii/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-words-in-a-string/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-words-in-a-string/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-words-in-a-string-iii/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-words-in-a-string-iii/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-only-letters/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-only-letters/</a></li><li><a href="https://leetcode-cn.com/problems/find-all-anagrams-in-a-string/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/find-all-anagrams-in-a-string/</a></li><li><a href="https://leetcode-cn.com/problems/longest-palindromic-substring/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-palindromic-substring/</a></li><li><a href="https://leetcode-cn.com/problems/isomorphic-strings/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/isomorphic-strings/</a></li><li><a href="https://leetcode-cn.com/problems/valid-palindrome-ii/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/valid-palindrome-ii/</a></li><li><a href="https://leetcode-cn.com/problems/wildcard-matching" target="_blank" rel="noopener">https://leetcode-cn.com/problems/wildcard-matching</a></li><li><a href="https://leetcode-cn.com/problems/longest-valid-parentheses" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-valid-parentheses</a></li><li><a href="https://leetcode-cn.com/problems/distinct-subsequences/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/distinct-subsequences/</a></li></ul><h2 id="本周作业-v3"><a class="header-anchor" href="#本周作业-v3">¶</a>本周作业</h2><p>简单</p><ul><li><a href="https://leetcode-cn.com/problems/first-unique-character-in-a-string/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/first-unique-character-in-a-string/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-string-ii/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-string-ii/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-words-in-a-string/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-words-in-a-string/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-words-in-a-string-iii/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-words-in-a-string-iii/</a></li><li><a href="https://leetcode-cn.com/problems/reverse-only-letters/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-only-letters/</a></li><li><a href="https://leetcode-cn.com/problems/isomorphic-strings/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/isomorphic-strings/</a></li><li><a href="https://leetcode-cn.com/problems/valid-palindrome-ii/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/valid-palindrome-ii/</a></li></ul><p>中等</p><ul><li>在第 8 周学习总结中，写出<a href="https://leetcode-cn.com/problems/unique-paths-ii/" target="_blank" rel="noopener">不同路径 2 </a>这道题目的状态转移方程。</li><li><a href="https://leetcode-cn.com/problems/longest-increasing-subsequence/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-increasing-subsequence/</a></li><li><a href="https://leetcode-cn.com/problems/decode-ways/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/decode-ways/</a></li><li><a href="https://leetcode-cn.com/problems/string-to-integer-atoi/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/string-to-integer-atoi/</a></li><li><a href="https://leetcode-cn.com/problems/find-all-anagrams-in-a-string/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/find-all-anagrams-in-a-string/</a></li><li><a href="https://leetcode-cn.com/problems/longest-palindromic-substring/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-palindromic-substring/</a></li></ul><p>困难</p><ul><li><a href="https://leetcode-cn.com/problems/longest-valid-parentheses/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-valid-parentheses/</a></li><li><a href="https://leetcode-cn.com/problems/race-car/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/race-car/</a></li><li><a href="https://leetcode-cn.com/problems/wildcard-matching" target="_blank" rel="noopener">https://leetcode-cn.com/problems/wildcard-matching</a></li><li><a href="https://leetcode-cn.com/problems/longest-valid-parentheses" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-valid-parentheses</a></li><li><a href="https://leetcode-cn.com/problems/distinct-subsequences/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/distinct-subsequences/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构与算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql学习笔记：高可用</title>
      <link href="/2020/02/16/mysql/gao-ke-yong/"/>
      <url>/2020/02/16/mysql/gao-ke-yong/</url>
      
        <content type="html"><![CDATA[<h1>MySQL是怎么保证主备一致的</h1><p>毫不夸张地说，MySQL 能够成为现下最流行的开源数据库，binlog 功不可没。在最开始，MySQL 是以容易学习和方便的高可用架构，被开发人员青睐的。而它的几乎所有的高可用架构，都直接依赖于 binlog。虽然这些高可用架构已经呈现出越来越复杂的趋势，但都是从最基本的一主一备演化过来的。</p><h2 id="MySQL-主备的基本原理"><a class="header-anchor" href="#MySQL-主备的基本原理">¶</a>MySQL 主备的基本原理</h2><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134822.png" alt="MySQL主备切换流程"></p><p>在状态 1 中，客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据是相同的。当需要切换的时候，就切成状态 2。这时候客户端读写访问的都是节点 B，而节点 A 是 B 的备库。</p><p>在状态 1 中，虽然节点 B 没有被直接访问，但是依然建议你把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：</p><ol><li>有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；</li><li>防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；</li><li>可以用 readonly 状态，来判断节点的角色。</li></ol><p>把备库设置成只读了，还怎么跟主库保持同步更新呢？这个问题不用担心。<strong>因为 readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限</strong>。</p><h2 id="主备同步"><a class="header-anchor" href="#主备同步">¶</a>主备同步</h2><p>接下来，再看看节点 A 到 B 这条线的内部流程是什么样的。下图就是一个 update 语句在节点 A 执行，然后同步到节点 B 的完整流程图。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134829.png" alt="主备流程图"></p><p>主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。</p><p>备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：</p><ol><li>在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。</li><li>在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。</li><li>主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。</li><li>备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。</li><li>sql_thread 读取中转日志，解析出日志里的命令，并执行。</li></ol><blockquote><p>这里需要说明，后来由于多线程复制方案的引入，sql_thread 演化成为了多个线程，跟这里要介绍的原理没有直接关系，暂且不展开。</p></blockquote><h2 id="binlog-的三种格式对比"><a class="header-anchor" href="#binlog-的三种格式对比">¶</a>binlog 的三种格式对比</h2><p>分析完了这个长连接的逻辑，再来看一个问题：binlog 里面到底是什么内容，为什么备库拿过去可以直接执行。binlog 有三种格式：</p><ol><li>statement</li><li>row</li><li>mixed</li></ol><p>建表如下：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> CREATE TABLE `t` (  `id` int(11) NOT NULL,  `a` int(11) DEFAULT NULL,  `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,  PRIMARY KEY (`id`),  KEY `a` (`a`),  KEY `t_modified`(`t_modified`)) ENGINE=InnoDB;insert into t values(1,1,'2018-11-13');insert into t values(2,2,'2018-11-12');insert into t values(3,3,'2018-11-11');insert into t values(4,4,'2018-11-10');insert into t values(5,5,'2018-11-09');<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果要在表中删除一行数据的话，来看看这个 <code>delete</code> 语句的 binlog 是怎么记录的。</p><blockquote><p>注意，下面这个语句包含注释，如果你用 MySQL 客户端来做这个实验的话，要记得加 <code>-c</code> 参数，否则客户端会自动去掉注释。</p></blockquote><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> delete from t /*comment*/  where a>=4 and t_modified<='2018-11-10' limit 1;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="statement"><a class="header-anchor" href="#statement">¶</a>statement</h3><p>当 <code>binlog_format=statement</code> 时，binlog 里面记录的就是 SQL 语句的原文。可以用以下命令看 binlog 中的内容。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> show binlog events in 'master.000001';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134837.png" alt="statement 格式 binlog 示例"></p><ol><li>第一行 <code>SET @@SESSION.GTID_NEXT='ANONYMOUS’</code>在主备切换的时候用到；</li><li>第二行是一个 <code>BEGIN</code>，跟第四行的 <code>commit</code> 对应，表示中间是一个事务；</li><li>第三行就是真实执行的语句了。可以看到，在真实执行的 <code>delete</code> 命令之前，还有一个<code>use ‘test’</code>命令。这条命令不是我们主动执行的，而是 MySQL 根据当前要操作的表所在的数据库，自行添加的。这样做可以保证日志传到备库去执行的时候，不论当前的工作线程在哪个库里，都能够正确地更新到 test 库的表 t。<code>use 'test’</code>命令之后的 <code>delete</code> 语句，就是我们输入的 SQL 原文了。可以看到，binlog“忠实”地记录了 SQL 命令，甚至连注释也一并记录了。</li><li>最后一行是一个 <code>COMMIT</code>。你可以看到里面写着 <code>xid=61</code>。</li></ol><h4 id="和-row-格式的区别"><a class="header-anchor" href="#和-row-格式的区别">¶</a>和 row 格式的区别</h4><p>为了说明 statement 和 row 格式的区别，我们来看一下这条 delete 命令的执行效果图：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134841.png" alt="delete 执行 warnings"></p><p>可以看到，运行这条 <code>delete</code> 命令产生了一个 warning，原因是当前 binlog 设置的是 statement 格式，并且语句中有 limit，所以这个命令可能是 unsafe 的。为什么这么说呢？这是因为 delete 带 limit，很可能会出现主备数据不一致的情况。比如上面这个例子：</p><ol><li>如果 <code>delete</code> 语句使用的是索引 <code>a</code>，那么会根据索引 <code>a</code> 找到第一个满足条件的行，也就是说删除的是 a=4 这一行；</li><li>但如果使用的是索引 <code>t_modified</code>，那么删除的就是 t_modified='2018-11-09’也就是 a=5 这一行。</li></ol><p>由于 <code>statement</code> 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 <code>a</code>；而在备库执行这条 SQL 语句的时候，却使用了索引 <code>t_modified</code>。因此，MySQL 认为这样写是有风险的。</p><h3 id="row"><a class="header-anchor" href="#row">¶</a>row</h3><p>那么，如果把 binlog 的格式改为 <code>binlog_format=‘row’</code>， 是不是就没有这个问题了呢？我们先来看看这时候 binog 中的内容吧。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134843.png" alt="row 格式 binlog 示例"></p><p>可以看到，与 statement 格式的 binlog 相比，前后的 <code>BEGIN</code> 和 <code>COMMIT</code> 是一样的。但是，row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。</p><ol><li><code>Table_map event</code>，用于说明接下来要操作的表是 test 库的表 t;</li><li><code>Delete_rows event</code>，用于定义删除的行为。</li></ol><p>其实，通过上图是看不到 row 格式的详细信息的，还需要借助 mysqlbinlog 工具，用下面这个命令解析和查看 binlog 中的内容。因为上图中的信息显示，这个事务的 binlog 是从 8900 这个位置开始的，所以可以用 <code>start-position</code> 参数来指定从这个位置的日志开始解析。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysqlbinlog  -vv data/master.000001 --start-position=8900;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134848.png" alt="row 格式 binlog 示例的详细信息"></p><p>从这个图中，我们可以看到以下几个信息：</p><ol><li>server id 1，表示这个事务是在 server_id=1 的这个库上执行的。</li><li>每个 event 都有 CRC32 的值，这是因为把参数 <code>binlog_checksum</code> 设置成了 CRC32。</li><li><code>Table_map event</code> 跟在前面的图中看到的相同，显示了接下来要打开的表，map 到数字 226。现在我们这条 SQL 语句只操作了一张表，如果要操作多张表呢？每个表都有一个对应的 <code>Table_map event</code>、都会 map 到一个单独的数字，用于区分对不同表的操作。</li><li>我们在 mysqlbinlog 的命令中，使用了 <code>-vv</code> 参数是为了把内容都解析出来，所以从结果里面可以看到各个字段的值（比如，@1=4、 @2=4 这些值）。</li><li><code>binlog_row_image</code> 的默认配置是 <code>FULL</code>，因此 Delete_event 里面，包含了删掉的行的所有字段的值。如果把 <code>binlog_row_image</code> 设置为 <code>MINIMAL</code>，则只会记录必要的信息，在这个例子里，就是只会记录 id=4 这个信息。</li><li>最后的 <code>Xid event</code>，用于表示事务被正确地提交了。</li></ol><p>你可以看到，当 <code>binlog_format</code> 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。</p><h3 id="mixed"><a class="header-anchor" href="#mixed">¶</a>mixed</h3><p>基于上面的信息来讨论一个问题：为什么会有 mixed 这种 binlog 格式的存在场景？推论过程是这样的：</p><ul><li>因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。</li><li>但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。</li><li>所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。</li></ul><p>也就是说，mixed 格式可以利用 statment 格式的优点，同时又避免了数据不一致的风险。<strong>因此，如果你的线上 MySQL 设置的 binlog 格式是 statement 的话，那基本上就可以认为这是一个不合理的设置。你至少应该把 binlog 的格式设置为 mixed</strong>。比如我们这个例子，设置为 mixed 后，就会记录为 row 格式；而如果执行的语句去掉 limit 1，就会记录为 statement 格式。</p><h2 id="row-的好处"><a class="header-anchor" href="#row-的好处">¶</a>row 的好处</h2><p>现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。这么做的理由有很多，举一个可以直接看出来的好处：<strong>恢复数据</strong>。接下来，我们就分别从 <code>delete</code>、<code>insert</code> 和 <code>update</code> 这三种 SQL 语句的角度，来看看数据恢复的问题。</p><h3 id="恢复数据举例"><a class="header-anchor" href="#恢复数据举例">¶</a>恢复数据举例</h3><p>通过上图可以看出来，即使执行的是 <code>delete</code> 语句，row 格式的 binlog 也会把被删掉的行的整行信息保存起来。所以，如果你在执行完一条 <code>delete</code> 语句以后，发现删错数据了，可以直接把 binlog 中记录的 <code>delete</code> 语句转成 <code>insert</code>，把被错删的数据插入回去就可以恢复了。</p><p>如果你是执行错了 <code>insert</code> 语句呢？那就更直接了。row 格式下，<code>insert</code> 语句的 binlog 里会记录所有的字段信息，这些信息可以用来精确定位刚刚被插入的那一行。这时，你直接把 <code>insert</code> 语句转成 <code>delete</code> 语句，删除掉这被误插入的一行数据就可以了。</p><p>如果执行的是 <code>update</code> 语句的话，binlog 里面会记录修改前整行的数据和修改后的整行数据。所以，如果你误执行了 <code>update</code> 语句的话，只需要把这个 event 前后的两行信息对调一下，再去数据库里面执行，就能恢复这个更新操作了。</p><h3 id="恢复数据工具"><a class="header-anchor" href="#恢复数据工具">¶</a>恢复数据工具</h3><p>其实，由 <code>delete</code>、<code>insert</code> 或者 <code>update</code> 语句导致的数据操作错误，需要恢复到操作之前状态的情况，也时有发生。MariaDB 的<a href="https://mariadb.com/kb/en/flashback/" target="_blank" rel="noopener">Flashback</a>工具就是基于上面介绍的原理来回滚数据的。</p><h2 id="binlog-恢复数据注意点"><a class="header-anchor" href="#binlog-恢复数据注意点">¶</a>binlog 恢复数据注意点</h2><p>虽然 mixed 格式的 binlog 现在已经用得不多了，但这里还是要再借用一下 mixed 格式来说明一个问题，来看一下这条 SQL 语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> insert into t values(10,10, now());<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134855.png" alt="mixed 格式和 now()"></p><p>可以看到，MySQL 用的居然是 statement 格式。你一定会奇怪，如果这个 binlog 过了 1 分钟才传给备库的话，那主备的数据不就不一致了吗？接下来，我们再用 mysqlbinlog 工具来看看：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134857.png" alt="TIMESTAMP 命令"></p><p>从图中的结果可以看到，原来 binlog 在记录 event 的时候，多记了一条命令：<code>SET TIMESTAMP=1546103491</code>。它用 SET TIMESTAMP 命令约定了接下来的 <code>now()</code> 函数的返回时间。因此，不论这个 binlog 是 1 分钟之后被备库执行，还是 3 天后用来恢复这个库的备份，这个 <code>insert</code> 语句插入的行，值都是固定的。也就是说，通过这条 <code>SET TIMESTAMP</code> 命令，MySQL 就确保了主备数据的一致性。</p><p>所以不能用 mysqlbinlog 解析出日志直接把里面的 statement 语句直接拷贝出来执行。这个方法是有风险的。因为有些语句的执行结果是依赖于上下文命令的，直接执行的结果很可能是错误的。所以，用 binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。类似下面的命令：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">mysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个命令的意思是，将 master.000001 文件里面从第 2738 字节到第 2973 字节中间这段内容解析出来，放到 MySQL 去执行。</p><h2 id="循环复制问题"><a class="header-anchor" href="#循环复制问题">¶</a>循环复制问题</h2><p>binlog 的特性确保了在备库执行相同的 binlog，可以得到与主库相同的状态。因此，我们可以认为正常情况下主备的数据是一致的。也就是说，[该图中](##MySQL 主备的基本原理) A、B 两个节点的内容是一致的，其实，该图中画的是 M-S 结构，但实际生产上使用比较多的是双 M 结构，也就是下图所示的主备切换流程。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134902.png" alt="MySQL 主备切换流程 -- 双 M 结构"></p><p>可以发现，双 M 结构和 M-S 结构，其实区别只是多了一条线，即：节点 A 和 B 之间总是互为主备关系。这样在切换的时候就不用再修改主备关系（只是增加了一条关系，同一时间还是只有一台 MySQL 可以写入数据）。</p><p>但是，双 M 结构还有一个问题需要解决。业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（建议把参数 <code>log_slave_updates</code> 设置为 <code>on</code>，表示备库执行 relay log 后生成 binlog）。那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。这个要怎么解决呢？</p><h3 id="解决问题"><a class="header-anchor" href="#解决问题">¶</a>解决问题</h3><p>从上图中可以看到，MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题：</p><ol><li>规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；</li><li>一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；</li><li>每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。</li></ol><p>按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样：</p><ol><li>从节点 A 更新的事务，binlog 里面记的都是 A 的 server id；</li><li>传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id；</li><li>再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。</li></ol><p>所以，死循环在这里就断掉了。</p><h4 id="还是会出现循环复制的场景"><a class="header-anchor" href="#还是会出现循环复制的场景">¶</a>还是会出现循环复制的场景</h4><p>一种场景是，在一个主库更新事务后，用命令 <code>set global server_id=x</code> 修改了 server_id。等日志再传回来的时候，发现 server_id 跟自己的 server_id 不同，就只能执行了。</p><p>另一种场景是，有三个节点的时候，如下图所示，trx1 是在节点 B 执行的，因此 binlog 上的 server_id 就是 B，binlog 传给节点 A，然后 A 和 A’搭建了双 M 结构，就会出现循环复制。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134905.png" alt="三节点循环复制"></p><p>这种三节点复制的场景，做数据库迁移的时候会出现。如果出现了循环复制，可以在 A 或者 A’上，执行如下命令：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">stop slave；CHANGE MASTER TO IGNORE_SERVER_IDS=(server_id_of_B);start slave;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>这样这个节点收到日志后就不会再执行。过一段时间后，再执行下面的命令把这个值改回来。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">stop slave；CHANGE MASTER TO IGNORE_SERVER_IDS=();start slave;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h1>MySQL是怎么保证高可用的</h1><p>正常情况下，只要主库执行更新生成的所有 binlog，都可以传到备库并被正确地执行，备库就能达到跟主库一致的状态，这就是最终一致性。但是，MySQL 要提供高可用能力，只有最终一致性是不够的。为什么这么说呢？这里，再放一次双 M 结构的主备切换流程图。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134909.png" alt="MySQL 主备切换流程--双 M 结构"></p><h2 id="主备切换基础知识"><a class="header-anchor" href="#主备切换基础知识">¶</a>主备切换基础知识</h2><p>主备切换可能是一个主动运维动作，比如软件升级、主库所在机器按计划下线等，也可能是被动操作，比如主库所在机器掉电。</p><h3 id="主备延迟时间计算"><a class="header-anchor" href="#主备延迟时间计算">¶</a>主备延迟时间计算</h3><p>接下来先一起看看主动切换的场景。在介绍主动切换流程的详细步骤之前，要先你说明一个概念，即“同步延迟”。与数据同步有关的时间点主要包括以下三个：</p><ol><li>主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;</li><li>之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;</li><li>备库 B 执行完成这个事务，我们把这个时刻记为 T3。</li></ol><p><strong>所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1</strong>。可以在备库上执行 <code>show slave status</code> 命令，它的返回结果里面会显示 <code>seconds_behind_master</code>，用于表示当前备库延迟了多少秒。<code>seconds_behind_master</code> 的计算方法是这样的：</p><ol><li>每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间；</li><li>备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 <code>seconds_behind_master</code>。</li></ol><p>可以看到，其实 <code>seconds_behind_master</code> 这个参数计算的就是 T3-T1。所以，可以用 <code>seconds_behind_master</code> 来作为主备延迟的值，这个值的时间精度是秒。</p><p>如果主备库机器的系统时间设置不一致，会不会导致主备延迟的值不准？其实不会的。因为，备库连接到主库的时候，会通过执行 <code>SELECT UNIX_TIMESTAMP()</code> 函数来获得当前主库的系统时间。如果这时候发现主库的系统时间与自己不一致，备库在执行 <code>seconds_behind_master</code> 计算的时候会自动扣掉这个差值。</p><p>需要说明的是，在网络正常的时候，日志从主库传给备库所需的时间是很短的，即 T2-T1 的值是非常小的。也就是说，网络正常情况下，主备延迟的主要来源是备库接收完 binlog 和执行完这个事务之间的时间差。<strong>所以说，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢</strong>，所以接下来分析这可能是由哪些原因导致的。</p><h3 id="主备延迟的来源"><a class="header-anchor" href="#主备延迟的来源">¶</a>主备延迟的来源</h3><h4 id="1-备库机器性能较差"><a class="header-anchor" href="#1-备库机器性能较差">¶</a>1&gt;备库机器性能较差</h4><p>首先，有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。一般情况下，有人这么部署时的想法是，反正备库没有请求，所以可以用差一点儿的机器。或者，他们会把 20 个主库放在 4 台机器上，而把备库集中在一台机器上。其实更新请求对 IOPS 的压力，在主库和备库上是无差别的。所以，做这种部署时，一般都会将备库设置为“非双 1”的模式。</p><p>但实际上，更新过程中也会触发大量的读操作。所以，<strong>当备库主机上的多个备库都在争抢资源的时候，就可能会导致主备延迟了</strong>。当然，这种部署现在比较少了。因为主备可能发生切换，备库随时可能变成主库，<strong>所以主备库选用相同规格的机器，并且做对称部署</strong>，是现在比较常见的情况。</p><h4 id="2-备库压力大"><a class="header-anchor" href="#2-备库压力大">¶</a>2&gt;备库压力大</h4><p>即使做了对称部署以后，还可能会有延迟。这是为什么呢？这就是第二种常见的可能了，即备库的压力大。一般的想法是，主库既然提供了写能力，那么备库可以提供一些读能力。或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在备库上跑。</p><p>由于主库直接影响业务，大家使用起来会比较克制，反而忽视了备库的压力控制。结果就是，备库上的查询耗费了大量的 CPU 资源，影响了同步速度，造成主备延迟。这种情况，我们一般可以这么处理：</p><ol><li>一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。</li><li>通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。</li></ol><p>其中，一主多从的方式大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能力。而从库，就很适合用来做备份。</p><blockquote><p>备注：这里需要说明一下，从库和备库在概念上其实差不多。在这里会在 HA 过程中被选成新主库的，称为备库，其他的称为从库。</p></blockquote><h4 id="3-大事务"><a class="header-anchor" href="#3-大事务">¶</a>3&gt;大事务</h4><p>采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？这就是第三种可能了，即大事务。大事务这种情况很好理解。因为主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟。</p><ul><li>一次性地用 delete 语句删除太多数据就是一个典型的大事务场景。比如，一些归档类的数据，平时没有注意删除历史数据，等到空间快满了，业务开发人员要一次性地删掉大量历史数据。同时，又因为要避免在高峰期操作会影响业务（至少有这个意识还是很不错的），所以会在晚上执行这些大量数据的删除操作。结果，负责的 DBA 同学半夜就会收到延迟报警。然后，DBA 团队就要求你后续再删除数据的时候，要控制每个事务删除的数据量，分成多次删除。</li><li>另一种典型的大事务场景，就是大表 DDL。这个场景处理方案就是，计划内的 DDL，建议使用 gh-ost 方案。</li></ul><h4 id="4-备库的并行复制能力"><a class="header-anchor" href="#4-备库的并行复制能力">¶</a>4&gt;备库的并行复制能力</h4><p>如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？造成主备延迟还有一个大方向的原因，就是备库的并行复制能力。前面几种可能导致备库延迟的原因，不论是偶发性的查询压力，还是备份，对备库延迟的影响一般是分钟级的，而且在备库恢复正常以后都能够追上来。但是，如果备库执行日志的速度持续低于主库生成日志的速度，那这个延迟就有可能成了小时级别。而且对于一个压力持续比较高的主库来说，备库很可能永远都追不上主库的节奏。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134917.png" alt="主备流程图并行能力"></p><p>谈到主备的并行复制能力，我们要关注的是图中黑色的两个箭头。一个箭头代表了客户端写入主库，另一箭头代表的是备库上 sql_thread 执行中转日志（relay log）。如果用箭头的粗细来代表并行度的话，那么真实情况就如上图所示，第一个箭头要明显粗于第二个箭头。在主库上，影响并发度的原因就是各种锁了。由于 InnoDB 引擎支持行锁，除了所有并发事务都在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的。所以，在性能测试的时候会发现，并发压测线程 32 就比单线程时，总体吞吐量高。</p><p>而日志在备库上的执行，就是图中备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟。</p><h5 id="MySQL-5-6-之前不支持并行复制"><a class="header-anchor" href="#MySQL-5-6-之前不支持并行复制">¶</a>MySQL 5.6 之前不支持并行复制</h5><p>在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。从单线程复制到最新版本的多线程复制，中间的演化经历了好几个版本。其实说到底，所有的多线程复制机制，都是要把上图中只有一个线程的 sql_thread，拆成多个线程，也就是都符合下面的这个模型：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134919.png" alt="多线程模型"></p><p>上图中，coordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了 worker 线程。而 work 线程的个数，就是由参数 <code>slave_parallel_workers</code> 决定的。根据经验，把这个值设置为 8~16 之间最好（32 核物理机的情况），毕竟备库还有可能要提供读查询，不能把 CPU 都吃光了。</p><h5 id="并行复制发展过程"><a class="header-anchor" href="#并行复制发展过程">¶</a>并行复制发展过程</h5><ul><li>事务能不能按照轮询的方式分发给各个 worker，也就是第一个事务分给 worker_1，第二个事务发给 worker_2 呢？其实是不行的。因为，事务被分发给 worker 以后，不同的 worker 就独立执行了。但是，由于 CPU 的调度策略，很可能第二个事务最终比第一个事务先执行。而如果这时候刚好这两个事务更新的是同一行，也就意味着，同一行上的两个事务，在主库和备库上的执行顺序相反，会导致主备不一致的问题。</li><li>同一个事务的多个更新语句，能不能分给不同的 worker 来执行呢？答案是，也不行。举个例子，一个事务更新了表 t1 和表 t2 中的各一行，如果这两条更新语句被分到不同 worker 的话，虽然最终的结果是主备一致的，但如果表 t1 执行完成的瞬间，备库上有一个查询，就会看到这个事务“更新了一半的结果”，破坏了事务逻辑的隔离性。</li></ul><p>所以，coordinator 在分发的时候，需要满足以下这两个基本要求：</p><ul><li>不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。</li><li>同一个事务不能被拆开，必须放到同一个 worker 中。</li></ul><p>各个版本的多线程复制，都遵循了这两条基本原则。接下来就看看各个版本的并行复制策略。</p><h6 id="丁大开发的MySQL-5-5-版本的并行复制策略"><a class="header-anchor" href="#丁大开发的MySQL-5-5-版本的并行复制策略">¶</a>丁大开发的MySQL 5.5 版本的并行复制策略</h6><p>官方 MySQL 5.5 版本是不支持并行复制的。但是，在 2012 年的时候，丁大自己服务的业务出现了严重的主备延迟，原因就是备库只有单线程复制，然后就先后写了两个版本的并行策略。</p><ol><li><p><strong>按表分发策略</strong></p><p>按表分发事务的基本思路是，如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个 worker 不会更新同一行。当然，如果有跨表的事务，还是要把两张表放在一起考虑的。如下图所示，就是按表分发的规则。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134927.png" alt="按表并行复制程模型"></p><p>可以看到，每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。</p><p>在有事务分配给 worker 时，事务里面涉及的表会被加到对应的 hash 表中。worker 执行完成后，这个表会被从 hash 表中去掉。上图中，hash_table_1 表示，现在 worker_1 的“待执行事务队列”里，有 4 个事务涉及到 <code>db1.t1</code> 表，有 1 个事务涉及到 <code>db2.t2</code> 表；hash_table_2 表示，现在 worker_2 中有一个事务会更新到表 <code>t3</code> 的数据。</p><p>假设在图中的情况下，coordinator 从中转日志中读入一个新事务 T，这个事务修改的行涉及到表 <code>t1</code> 和 <code>t3</code>。现在我们用事务 T 的分配流程，来看一下分配规则：</p><ol><li>由于事务 T 中涉及修改表 <code>t1</code>，而 worker_1 队列中有事务在修改表 <code>t1</code>，事务 T 和队列中的某个事务要修改同一个表的数据，这种情况我们说事务 T 和 worker_1 是冲突的。</li><li>按照这个逻辑，顺序判断事务 T 和每个 worker 队列的冲突关系，会发现事务 T 跟 worker_2 也冲突。事务 T 跟多于一个 worker 冲突，coordinator 线程就进入等待。</li><li>每个 worker 继续执行，同时修改 hash_table。假设 hash_table_2 里面涉及到修改表 t3 的事务先执行完成，就会从 hash_table_2 中把 <code>db1.t3</code> 这一项去掉。</li><li>这样 coordinator 会发现跟事务 T 冲突的 worker 只有 worker_1 了，因此就把它分配给 worker_1。</li><li>coordinator 继续读下一个中转日志，继续分配事务。</li></ol><p>也就是说，每个事务在分发的时候，跟所有 worker 的冲突关系包括以下三种情况：</p><ol><li>如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker;</li><li>如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；</li><li>如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker。</li></ol><p>这个按表分发的方案，在多个表负载均匀的场景里应用效果很好。但是，如果碰到热点表，比如所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个 worker 中，就变成单线程复制了。</p></li><li><p><strong>按行分发策略</strong></p><p>要解决热点表的并行复制问题，就需要一个按行并行复制的方案。按行复制的核心思路是：如果两个事务没有更新相同的行，它们在备库上可以并行执行。<strong>显然，这个模式要求 binlog 格式必须是 row</strong>。这时候，我们判断一个事务 T 和 worker 是否冲突，用的就规则就不是“修改同一个表”，而是“修改同一行”。按行复制和按表复制的数据结构差不多，也是为每个 worker，分配一个 hash 表。只是要实现按行分发，这时候的 key，就必须是“库名 + 表名 + 唯一键的值”。但是，这个“唯一键”只有主键 id 还是不够的，我们还需要考虑下面这种场景，表 t1 中除了主键，还有唯一索引 a：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t1` (  `id` int(11) NOT NULL,  `a` int(11) DEFAULT NULL,  `b` int(11) DEFAULT NULL,  PRIMARY KEY (`id`),  UNIQUE KEY `a` (`a`)) ENGINE=InnoDB;insert into t1 values(1,1,1),(2,2,2),(3,3,3),(4,4,4),(5,5,5);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>假设，接下来我们要在主库执行这两个事务：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134930.png" alt="唯一键冲突示例"></p><p>可以看到，这两个事务要更新的行的主键值不同，但是如果它们被分到不同的 worker，就有可能 session B 的语句先执行。这时候 id=1 的行的 a 的值还是 1，就会报唯一键冲突。</p><p>因此，基于行的策略，事务 hash 表中还需要考虑到表中除了主键之外还是有可能存在其它唯一键的，此时 key 应该是“库名 + 表名 + 索引 a 的名字 +a 的值”。</p><p>比如，在上面这个例子中，要在表 <code>t1</code> 上执行 <code>update t1 set a=1 where id=2</code> 语句，在 binlog 里面记录了整行的数据修改前各个字段的值，和修改后各个字段的值。因此，coordinator 在解析这个语句的 binlog 的时候，这个事务的 hash 表就有三个项:</p><ol><li>key=hash_func(db1+t1+“PRIMARY”+2), value=2; 这里 value=2 是因为修改前后的行 id 值不变，出现了两次。</li><li>key=hash_func(db1+t1+“a”+2), value=1，表示会影响到这个表 a=2 的行。</li><li>key=hash_func(db1+t1+“a”+1), value=1，表示会影响到这个表 a=1 的行。</li></ol><p>可见，相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。</p></li></ol><p>这两个方案其实都有一些约束条件：</p><ul><li>要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；</li><li>表必须有主键；</li><li>不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。</li></ul><p>但，好在这三条约束规则，本来就是 DBA 之前要求业务开发人员必须遵守的线上使用规范，所以这两个并行复制策略在应用上也没有碰到什么麻烦。对比按表分发和按行分发这两个方案的话，按行分发策略的并行度更高。不过，如果是要操作很多行的大事务的话，按行分发的策略有两个问题：</p><ul><li>耗费内存。比如一个语句要删除 100 万行数据，这时候 hash 表就要记录 100 万个项。</li><li>耗费 CPU。解析 binlog，然后计算 hash 值，对于大事务，这个成本还是很高的。</li></ul><p>所以在实现这个策略的时候会设置一个阈值，单个事务如果超过设置的行数阈值（比如，如果单个事务更新的行数超过 10 万行），就暂时退化为单线程模式，退化过程的逻辑大概是这样的：</p><ol><li>coordinator 暂时先 hold 住这个事务；</li><li>等待所有 worker 都执行完成，变成空队列；</li><li>coordinator 直接执行这个事务；</li><li>恢复并行模式。</li></ol><h6 id="MySQL-5-6-版本的并行复制策略"><a class="header-anchor" href="#MySQL-5-6-版本的并行复制策略">¶</a>MySQL 5.6 版本的并行复制策略</h6><p>官方 MySQL5.6 版本，支持了并行复制，只是支持的粒度是按库并行。理解了上面介绍的按表分发策略和按行分发策略，你就理解了，用于决定分发策略的 hash 表里，key 就是数据库名。</p><p>这个策略的并行效果，取决于压力模型。如果在主库上有多个 DB，并且各个 DB 的压力均衡，使用这个策略的效果会很好。相比于按表和按行分发，这个策略有两个优势：</p><ol><li>构造 hash 值的时候很快，只需要库名；而且一个实例上 DB 数也不会很多，不会出现需要构造 100 万个项这种情况。</li><li>不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。</li></ol><p>但是，如果你的主库上的表都放在同一个 DB 里面，这个策略就没有效果了；或者如果不同 DB 的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。理论上你可以创建不同的 DB，把相同热度的表均匀分到这些不同的 DB 中，强行使用这个策略。不过由于需要特地移动数据，这个策略用得并不多。</p><h6 id="MariaDB-的并行复制策略"><a class="header-anchor" href="#MariaDB-的并行复制策略">¶</a>MariaDB 的并行复制策略</h6><p>MariaDB 的并行复制策略利用的是 redo log 和 binlog 组提交就是这个特性：</p><ol><li>能够在同一组里提交的事务，一定不会修改同一行（因为冲突的两个事务必定因为锁阻塞有一个先后提交顺序，只有前者提交了，后者才能继续执行，而所有事务的提交都会随着一个唯一的事务组提交，所以不可能存在冲突的事务在同一个提交组里面）；</li><li>主库上可以并行执行的事务，备库上也一定是可以并行执行的。</li></ol><p>在实现上，MariaDB 是这么做的：</p><ol><li>在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；</li><li>commit_id 直接写到 binlog 里面；</li><li>传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；</li><li>这一组全部执行完成后，coordinator 再去取下一批。</li></ol><p>当时，这个策略出来的时候是相当惊艳的。因为，之前业界的思路都是在“分析 binlog，并拆分到 worker”上。而 MariaDB 的这个策略，目标是“模拟主库的并行模式”。但是，这个策略有一个问题，它并没有实现“<strong>真正的模拟主库并发度</strong>”这个目标。</p><p>在主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的。如下图所示，假设了三组事务在主库的执行情况，你可以看到在 trx1、trx2 和 trx3 提交的时候，trx4、trx5 和 trx6 是在执行的。这样，在第一组事务提交完成的时候，下一组事务很快就会进入 commit 状态。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135153.png" alt="主库并行事务"></p><p>而按照 MariaDB 的并行复制策略，备库上的执行效果如下图所示。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134940.png" alt="MariaDB 并行复制，备库并行效果"></p><p>可以看到，<strong>在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行（需要保证同一个提交组的事务完全提交下一组才能开始执行，即使下一组已经准备就绪了），这样系统的吞吐量就不够。另外，这个方案很容易被大事务拖后腿。假设 trx2 是一个超大事务，那么在备库应用的时候，trx1 和 trx3 执行完成后，就只能等 trx2 完全执行完成，下一组才能开始执行。这段时间，只有一个 worker 线程在工作，是对资源的浪费</strong>。不过即使如此，这个策略仍然是一个很漂亮的创新。因为，它对原系统的改造非常少，实现也很优雅。</p><h6 id="MySQL-5-7-的并行复制策略"><a class="header-anchor" href="#MySQL-5-7-的并行复制策略">¶</a>MySQL 5.7 的并行复制策略</h6><p>在 MariaDB 并行复制实现之后，官方的 MySQL5.7 版本也提供了类似的功能，由参数 <code>slave-parallel-type</code> 来控制并行复制策略：</p><ol><li>配置为 <code>DATABASE</code>，表示使用 MySQL 5.6 版本的按库并行策略；</li><li>配置为 <code>LOGICAL_CLOCK</code>，表示的就是类似 MariaDB 的策略。不过，<strong>MySQL 5.7 这个策略，针对并行度做了优化</strong>。</li></ol><p>上面提到 MariaDB 的从库并行复制策略中，即使下一组在主库已经提交的事务已经传送到 relay log 等待执行，在当前组事务完全提交之前，它都不能执行，也就是说，它是在每一次日志 fsync 的时候对同一批已经 prepare 完毕准备被标记为 commit 状态的事务进行聚合成为一组并行执行事务。<strong>因为它同时还要保证存在更新冲突的事务在主备库上的更新都是一致的，所以以事务被标记为 commit 状态的先后顺序作为同步点入手是可以得到主库上冲突事务的执行的前后顺序的</strong>。但是这里面是否可以优化呢？有的，上面提到的 MySQL 5.7 的优化就是这里，再回顾一下两阶段提交：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134947.png" alt="两阶段提交细化过程图"></p><p>其实，不用等到 commit 阶段，只要能够到达 redo log prepare 阶段，就表示事务已经通过锁冲突的检验了，即只有当前事务所需要的资源没有被其它未提交事务占有的情况下，当前事务执行提交的时候才可以不经阻塞进入 redo log prepare 状态，否则当前事务将会被阻塞。也就是说，除了上面提到的 MariaDB 的从库根据事务被标记为 commit 状态的先后顺序与主库进行冲突事务的提交顺序同步之外，还可以根据事务被标记为 prepare 状态的先后顺序与主库进行同步。</p><p>因此，MySQL 5.7 并行复制策略的思想是：</p><ol><li>同时处于 prepare 状态的事务，在备库执行时是可以并行的；</li><li>处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。</li></ol><blockquote><p>相较于 MariaDB 在组提交的时候才对 prepare 完毕的事务申请最新的 commit id；MySQL 5.7 在事务进入 prepare 状态的时候就会给该事务申请最新的 commit id。所以 MySQL 5.7 可以聚合为同一组并行执行的事务的范围就更大了，也就是拥有一样的 commit id 的事务数量就更多了。（备库在执行一个事务的时候，就是先检查 worker 线程中是否存在比当前事务 commit id 小的事务在执行，如果有就需要阻塞，没有就可以执行，所以相同的 commit id 事务越多，阻塞就越少，并行度越高）</p></blockquote><p>另外，以下两个参数也是用于故意拉长 binlog 从 write 到 fsync 的时间，以此减少 binlog 的写盘次数。在 MySQL 5.7 的并行复制策略里，它们可以用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度。</p><ol><li><code>binlog_group_commit_sync_delay</code> 参数，表示延迟多少微秒后才调用 fsync;</li><li><code>binlog_group_commit_sync_no_delay_count</code> 参数，表示累积多少次以后才调用 fsync。</li></ol><p>也就是说，这两个参数，既可以“故意”让主库提交得慢些，又可以让备库执行得快些。在 MySQL 5.7 处理备库延迟的时候，可以考虑调整这两个参数值，来达到提升备库复制并发度的目的。</p><h6 id="MySQL-5-7-22-的并行复制策略"><a class="header-anchor" href="#MySQL-5-7-22-的并行复制策略">¶</a>MySQL 5.7.22 的并行复制策略</h6><p>在 2018 年 4 月份发布的 MySQL 5.7.22 版本里，<strong>MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制</strong>。相应地，新增了一个参数 <code>binlog-transaction-dependency-tracking</code>，用来控制是否启用这个新策略。这个参数的可选值有以下三种。</p><ol><li><code>COMMIT_ORDER</code>，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。</li><li><code>WRITESET</code>，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。</li><li><code>WRITESET_SESSION</code>，是在 <code>WRITESET</code> 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序，不能并行执行。</li></ol><blockquote><ul><li>对于<code>WRITESET</code>，一个线程中执行的不同事务，只要这些事务没有冲突就可以并行执行（即保证物理上备库和主库数据一致的情况下最高程度并发）。（什么情况下可能会出现一个线程中不同事务可以并行执行呢？其实很常见，并行复制不及时的话，事务执行就会延迟，所以对于一个线程，是可能存在前一个事务没来得及在备库中执行，下一个事务又从主库传过来了，此时这两个事务根据 hash 值计算出没有冲突，可以并行执行）</li><li>对于 <code>WRITESET_SESSION</code> 一个线程中执行的不同事务无论计算的 hash 值是否有冲突不能并行执行，必须按照 commit id 顺序同步执行。</li></ul></blockquote><p>当然为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。这跟前面介绍的丁大实现的基于 MySQL 5.5 版本的按行分发的策略是差不多的。</p><p>不过，MySQL 官方的这个实现还是有很大的优势：</p><ol><li><strong>writeset 是在主库生成后直接写入到 binlog 里面的</strong>，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；（<strong>相较于丁大的实现方式，是不改变原有 binlog 格式，在备库里面实时计算的，以下两点的区别原因也在于此</strong>）</li><li>不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；</li><li>由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。</li></ol><p>因此，MySQL 5.7.22 的并行复制策略在通用性上还是有保证的。当然，对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。</p><h5 id="一个例子理解-5-7-22-的并行复制策略"><a class="header-anchor" href="#一个例子理解-5-7-22-的并行复制策略">¶</a>一个例子理解 5.7.22 的并行复制策略</h5><p>假设一个 MySQL 5.7.22 版本的主库，单线程插入了很多数据，过了 3 个小时后，我们要给这个主库搭建一个相同版本的备库。<strong>这时候，为了更快地让备库追上主库，要开并行复制</strong>。在 <code>binlog-transaction-dependency-tracking</code> 参数的 COMMIT_ORDER、<code>WRITESET</code> 和 <code>WRITE_SESSION</code> 这三个取值中，你会选择哪一个呢？你选择的原因是什么？如果设置另外两个参数，你认为会出现什么现象呢？</p><p>由于主库是单线程压力模式，所以每个事务的 commit_id 都不同，那么设置为 <code>COMMIT_ORDER</code> 模式的话，从库也只能单线程执行。同样地，由于 <code>WRITESET_SESSION</code> 模式要求在备库应用日志的时候，同一个线程的日志必须与主库上执行的先后顺序相同，也会导致主库单线程压力模式下退化成单线程复制。所以，应该将 <code>binlog-transaction-dependency-tracking</code> 设置为 <code>WRITESET</code>。</p><h4 id="5-其它"><a class="header-anchor" href="#5-其它">¶</a>5&gt;其它</h4><ul><li>表上无主键的情况(主库利用索引更改数据,备库回放只能用全表扫描,这种情况可以调整<code>slave_rows_search_algorithms</code>参数适当优化下)</li><li>设置的是延迟备库</li><li>备库空间不足的情况下</li><li>… …</li></ul><h3 id="主备延迟时间分析示例"><a class="header-anchor" href="#主备延迟时间分析示例">¶</a>主备延迟时间分析示例</h3><p>一般现在的数据库运维系统都有备库延迟监控，其实就是在备库上执行 show slave status，采集 seconds_behind_master 的值。假设，现在你看到你维护的一个备库，它的延迟监控的图像类似下图，是一个 45°斜向上的线段，你觉得可能是什么原因导致呢？你又会怎么去确认这个原因呢？</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134953.png" alt="备库延迟"></p><p>看这曲线应该是T3随着时间的增长在增长，而T1这个时间点是没变的。即备库的同步在这段时间完全被堵住了。产生这种现象典型的场景主要包括两种：</p><ul><li><p>一种是大事务（包括大表 DDL、一个事务操作很多行）；</p></li><li><p>还有一种情况比较隐蔽，就是备库起了一个长事务，比如</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">begin; select * from t limit 1;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后就不动了。这时候主库对表 t 做了一个加字段操作，即使这个表很小，这个 DDL 在备库应用的时候也会被堵住，也不能看到这个现象。</p></li></ul><h3 id="主备切换策略"><a class="header-anchor" href="#主备切换策略">¶</a>主备切换策略</h3><p>由于主备延迟的存在，所以在主备切换的时候，就相应的有不同的策略。</p><h4 id="可靠性优先策略"><a class="header-anchor" href="#可靠性优先策略">¶</a>可靠性优先策略</h4><p>在前面的双 M 结构图中，从状态 1 到状态 2 切换的详细过程是这样的：</p><ol><li>判断备库 B 现在的 <code>seconds_behind_master</code>，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；</li><li>把主库 A 改成只读状态，即把 <code>readonly</code> 设置为 true；</li><li>判断备库 B 的 <code>seconds_behind_master</code> 的值，直到这个值变成 0 为止；</li><li>把备库 B 改成可读写状态，也就是把 <code>readonly</code> 设置为 false；</li><li>把业务请求切到备库 B。</li></ol><p>这个切换流程，一般是由专门的 HA 系统来完成的，暂时称之为可靠性优先流程。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221134956.png" alt="MySQL 可靠性优先主备切换流程"></p><blockquote><p>注：图中的 SBM，是 seconds_behind_master 参数的简写。</p></blockquote><p>可以看到，这个切换流程中是有不可用时间的。因为在步骤 2 之后，主库 A 和备库 B 都处于 readonly 状态，也就是说这时系统处于不可写状态，直到步骤 5 完成后才能恢复。在这个不可用状态中，比较耗费时间的是步骤 3，可能需要耗费好几秒的时间。这也是为什么需要在步骤 1 先做判断，确保 seconds_behind_master 的值足够小。试想如果一开始主备延迟就长达 30 分钟，而不先做判断直接切换的话，系统的不可用时间就会长达 30 分钟，这种情况一般业务都是不可接受的。当然，系统的不可用时间，是由这个数据可靠性优先的策略决定的。你也可以选择可用性优先的策略，来把这个不可用时间几乎降为 0。</p><h4 id="可用性优先策略"><a class="header-anchor" href="#可用性优先策略">¶</a>可用性优先策略</h4><p>如果强行把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了。我们把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。接下来介绍一个可用性优先流程产生数据不一致的例子。假设有一个表 t：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> CREATE TABLE `t` (  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,  `c` int(11) unsigned DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(c) values(1),(2),(3);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个表定义了一个自增主键 id，初始化数据后，主库和备库上都是 3 行数据。接下来，业务人员要继续在表 t 上执行两条插入语句的命令，依次是：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">insert into t(c) values(4);insert into t(c) values(5);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>假设，现在主库上其他的数据表有大量的更新，导致主备延迟达到 5 秒。在插入一条 c=4 的语句后，发起了主备切换。下图是可用性优先策略，且 <code>binlog_format=mixed</code> 时的切换流程和数据结果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135002.png" alt="可用性优先策略，且 binlog_format=mixed"></p><ol><li>步骤 2 中，主库 A 执行完 <code>insert</code> 语句，插入了一行数据（4,4），之后开始进行主备切换。</li><li>步骤 3 中，由于主备之间有 5 秒的延迟，所以备库 B 还没来得及应用“插入 c=4”这个中转日志，就开始接收客户端“插入 c=5”的命令。</li><li>步骤 4 中，备库 B 插入了一行数据（4,5），并且把这个 binlog 发给主库 A。</li><li>步骤 5 中，备库 B 执行“插入 c=4”这个中转日志，插入了一行数据（5,4）。而直接在备库 B 执行的“插入 c=5”这个语句，传到主库 A，就插入了一行新数据（5,5）。</li></ol><p>最后的结果就是，主库 A 和备库 B 上出现了两行不一致的数据。可以看到，这个数据不一致，是由可用性优先流程导致的。</p><p>那么，如果还是用可用性优先策略，但设置 <code>binlog_format=row</code>，情况又会怎样呢？因为 row 格式在记录 binlog 的时候，会记录新插入的行的所有字段值，所以最后只会有一行不一致。而且，两边的主备同步的应用线程会报错 duplicate key error 并停止。也就是说，这种情况下，备库 B 的 (5,4) 和主库 A 的 (5,5) 这两行数据，都不会被对方执行。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135009.png" alt="可用性优先策略，且 binlog_format=row"></p><h4 id="两者比较"><a class="header-anchor" href="#两者比较">¶</a>两者比较</h4><p>从上面的分析中，可以看到一些结论：</p><ol><li>使用 row 格式的 binlog 时，数据不一致的问题更容易被发现。而使用 mixed 或者 statement 格式的 binlog 时，数据很可能悄悄地就不一致了。如果过了很久才发现数据不一致的问题，很可能这时的数据不一致已经不可查，或者连带造成了更多的数据逻辑不一致。</li><li>主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，都建议你使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。</li></ol><p>但事无绝对，有没有哪种情况数据的可用性优先级更高呢？答案是，有的。</p><p>有这样的一个场景：</p><ul><li>有一个库的作用是记录操作日志。这时候，如果数据不一致可以通过 binlog 来修补，而这个短暂的不一致也不会引发业务问题。</li><li>同时，业务系统依赖于这个日志写入逻辑，如果这个库不可写，会导致线上的业务操作无法执行。</li></ul><p>这时候，可能就需要选择先强行切换，事后再补数据的策略。当然，事后复盘的时候，我们想到了一个改进措施就是，让业务逻辑不要依赖于这类日志的写入。也就是说，日志写入这个逻辑模块应该可以降级，比如写到本地文件，或者写到另外一个临时库里面。这样的话，这种场景就又可以使用可靠性优先策略了。</p><h5 id="主备延迟的重要"><a class="header-anchor" href="#主备延迟的重要">¶</a>主备延迟的重要</h5><p>按照可靠性优先的思路，异常切换会是什么效果？假设，主库 A 和备库 B 间的主备延迟是 30 分钟，这时候主库 A 掉电了，HA 系统要切换 B 作为主库。我们在主动切换的时候，可以等到主备延迟小于 5 秒的时候再启动切换，但这时候已经别无选择了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135012.png" alt="可靠性优先策略，主库不可用"></p><p>采用可靠性优先策略的话，就必须得等到备库 B 的 <code>seconds_behind_master=0</code> 之后，才能切换。但现在的情况比刚刚更严重，并不是系统只读、不可写的问题了，而是系统处于完全不可用的状态。因为，主库 A 掉电后，我们的连接还没有切到备库 B。</p><p>那能不能直接切换到备库 B，但是保持 B 只读呢？这样也不行。因为，这段时间内，中转日志还没有应用完成，如果直接发起主备切换，客户端查询看不到之前执行完成的事务，会认为有“数据丢失”。虽然随着中转日志的继续应用，这些数据会恢复回来，但是对于一些业务来说，查询到“暂时丢失数据的状态”也是不能被接受的。</p><p>所以在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。<strong>所以在实际的应用中，更建议使用可靠性优先的策略。毕竟保证数据准确，应该是数据库服务的底线。在这个基础上，通过减少主备延迟，提升系统的可用性。</strong></p><h2 id="一主多从：如何正确地切换主备"><a class="header-anchor" href="#一主多从：如何正确地切换主备">¶</a>一主多从：如何正确地切换主备</h2><p>上面讲的都是一主一备的结构。大多数的互联网应用场景都是读多写少，所以业务在发展过程中很可能先会遇到读性能的问题。而在数据库层解决读性能问题，就要涉及到一主多从的架构。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135019.png" alt="一主多从基本结构"></p><p>图中，虚线箭头表示的是主备关系，也就是 A 和 A’互为主备， 从库 B、C、D 指向的是主库 A。一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。下图就是主库发生故障，主备切换后的结果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135026.png" alt="一主多从基本结构--主备切换"></p><p>相比于一主一备的切换流程，一主多从结构在切换完成后，A’会成为新的主库，从库 B、C、D 也要改接到 A’。正是由于多了从库 B、C、D 重新指向的这个过程，所以主备切换的复杂性也相应增加了。</p><p>接下来，我们再一起看看一个切换系统会怎么完成一主多从的主备切换过程。</p><h3 id="基于位点的主备切换"><a class="header-anchor" href="#基于位点的主备切换">¶</a>基于位点的主备切换</h3><p>当我们把节点 B 设置成节点 A’的从库的时候，需要执行一条 <code>change master</code> 命令：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CHANGE MASTER TO MASTER_HOST=$host_name MASTER_PORT=$port MASTER_USER=$user_name MASTER_PASSWORD=$password MASTER_LOG_FILE=$master_log_name MASTER_LOG_POS=$master_log_pos  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这条命令有这么 6 个参数：</p><ul><li><code>MASTER_HOST</code>、<code>MASTER_PORT</code>、<code>MASTER_USER</code> 和 <code>MASTER_PASSWORD</code> 四个参数，分别代表了主库 A’的 IP、端口、用户名和密码。</li><li>最后两个参数 <code>MASTER_LOG_FILE</code> 和 <code>MASTER_LOG_POS</code> 表示，要从主库的 master_log_name 文件的 master_log_pos 这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。</li></ul><p>那么，这里就有一个问题了，节点 B 要设置成 A’的从库，就要执行 <code>change master</code> 命令，就不可避免地要设置位点的这两个参数，但是这两个参数到底应该怎么设置呢？原来节点 B 是 A 的从库，本地记录的主库位点就是 A 的位点。但是相同的日志，在 A 的位点和 A’的位点是不同的，不能直接将两者的位点做一个直接映射。</p><h4 id="寻找位点"><a class="header-anchor" href="#寻找位点">¶</a>寻找位点</h4><p>因此，从库 B 要切换的时候，就需要先经过“找同步位点”这个逻辑。这个位点很难精确取到，只能取一个大概位置。为什么这么说呢？来分析一下看看这个位点一般是怎么获取到的。考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库 B 上已经执行过的事务。一种取同步位点的方法是这样的：</p><ol><li><p>等待新主库 A’把中转日志（relay log）全部同步完成；</p></li><li><p>在 A’上执行 <code>show master status</code> 命令，得到当前 A’上最新的 binlog File 和 Position；</p></li><li><p>取原主库 A 故障的时刻 T；</p></li><li><p>用 mysqlbinlog 工具结合第二步查到的 A’ 的当前最新的 binlog File 和位置解析 A’的 File，得到 T 时刻的位点。</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">mysqlbinlog File --stop-datetime=T --start-datetime=T<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135033.png" alt="mysqlbinlog 部分输出结果"></p><p>图中，end_log_pos 后面的值“123”，表示的就是 A’这个实例，在 T 时刻写入新的 binlog 的位置。然后，我们就可以把 123 这个值作为 $master_log_pos ，用在节点 B 的 <code>change master</code> 命令里。</p></li></ol><h4 id="无法定位到精准位点"><a class="header-anchor" href="#无法定位到精准位点">¶</a>无法定位到精准位点</h4><p>当然这个值并不精确。为什么呢？你可以设想有这么一种情况，假设在 T 这个时刻，主库 A 已经执行完成了一个 insert 语句插入了一行数据 R，并且已经将 binlog 传给了 A’和 B，然后在传完的瞬间主库 A 的主机就掉电了。</p><p>那么，这时候系统的状态是这样的：</p><ol><li>在从库 B 上，由于同步了 binlog， R 这一行已经存在；</li><li>在新主库 A’上， R 这一行也已经存在，日志是写在 123 这个位置之后的；</li><li>我们在从库 B 上执行 change master 命令，指向 A’的 File 文件的 123 位置，就会把插入 R 这一行数据的 binlog 又同步到从库 B 去执行。</li></ol><p>这时候，从库 B 的同步线程就会报告 <code>Duplicate entry ‘id_of_R’ for key ‘PRIMARY’</code> 错误，提示出现了主键冲突，然后停止同步。</p><h4 id="处理问题位点"><a class="header-anchor" href="#处理问题位点">¶</a>处理问题位点</h4><p>所以，通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。</p><h5 id="逐步跳过错误位点"><a class="header-anchor" href="#逐步跳过错误位点">¶</a>逐步跳过错误位点</h5><p>一种做法是，主动跳过一个事务。跳过命令的写法是：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">set global sql_slave_skip_counter=1;start slave;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>因为切换过程中，可能会不止重复执行一个事务，所以我们需要在从库 B 刚开始接到新主库 A’时，持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情况，以此来跳过可能涉及的所有事务。</p><blockquote><p><code>sql_slave_skip_counter</code> 跳过的其实是一个 event，由于 MySQL 总不能执行一半的事务，所以既然跳过了一个 event，就会跳到这个事务的末尾，因此上面的语句是可以跳过整个事务的</p></blockquote><h5 id="一次性忽略所有错误位点"><a class="header-anchor" href="#一次性忽略所有错误位点">¶</a>一次性忽略所有错误位点</h5><p>另外一种方式是，通过设置 <code>slave_skip_errors</code> 参数，直接设置跳过指定的错误。在执行主备切换时，有这么两类错误，是经常会遇到的：</p><ul><li>1062 错误是插入数据时唯一键冲突；</li><li>1032 错误是删除数据时找不到行。</li></ul><p>因此，我们可以把 <code>slave_skip_errors</code> 设置为 “1032,1062”，这样中间碰到这两个错误时就直接跳过。这里需要注意的是，这种直接跳过指定错误的方法，针对的是主备切换时，由于找不到精确的同步位点，所以只能采用这种方法来创建从库和新主库的主备关系。这个背景是，我们很清楚在主备切换过程中，直接跳过 1032 和 1062 这两类错误是无损的，所以才可以这么设置 <code>slave_skip_errors</code> 参数。等到主备间的同步关系建立完成，并稳定执行一段时间之后，我们还需要把这个参数设置为空，以免之后真的出现了主从数据不一致，也跳过了。</p><h3 id="GTID"><a class="header-anchor" href="#GTID">¶</a>GTID</h3><p>通过 <code>sql_slave_skip_counter</code> 跳过事务和通过 <code>slave_skip_errors</code> 忽略错误的方法，虽然都最终可以建立从库 B 和新主库 A’的主备关系，但这两种操作都很复杂，而且容易出错。所以，MySQL 5.6 版本引入了 GTID，彻底解决了定位同步位点这个困难。</p><h4 id="GTID-介绍"><a class="header-anchor" href="#GTID-介绍">¶</a>GTID 介绍</h4><p>GTID 的全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。它由两部分组成，格式是：</p><pre><code>GTID=server_uuid:gno</code></pre><p>其中：</p><ul><li>server_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值；</li><li>gno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1。</li></ul><p>这里需要说明一下，在 MySQL 的官方文档里，GTID 格式是这么定义的：</p><pre><code>GTID=source_id:transaction_id</code></pre><p>这里的 source_id 就是 server_uuid；而后面的这个 transaction_id，容易造成误导，所以改成了 gno。为什么说使用 transaction_id 容易造成误解呢？因为，<strong>在 MySQL 里面我们说 transaction_id 就是指事务 id，事务 id 是在事务执行过程中分配的，如果这个事务回滚了，事务 id 也会递增，而 gno 是在事务提交的时候才会分配</strong>。从效果上看，GTID 往往是连续的，因此我们用 gno 来表示更容易理解。</p><h4 id="GTID-使用"><a class="header-anchor" href="#GTID-使用">¶</a>GTID 使用</h4><p>GTID 模式的启动也很简单，我们只需要在启动一个 MySQL 实例的时候，加上参数 <code>gtid_mode=on</code> 和 <code>enforce_gtid_consistency=on</code> 就可以了。在 GTID 模式下，每个事务都会跟一个 GTID 一一对应。这个 GTID 有两种生成方式，而使用哪种方式取决于 session 变量 <code>gtid_next</code> 的值：</p><ol><li>如果 <code>gtid_next=automatic</code>，代表使用默认值。这时，MySQL 就会把 <code>server_uuid:gno</code> 分配给这个事务。<ol><li>记录 binlog 的时候，先记录一行 <code>SET @@SESSION.GTID_NEXT=‘server_uuid:gno’</code>作为当前事务的全局唯一标识，主要给从库识别用的;</li><li>把这个 GTID 加入本实例的 GTID 集合，表示当前实例已经执行过这个事务了，当下次有事务要执行的时候，如果发现 session 变量 <code>gtid_next</code> 的值等于集合中的某个 GTID，这个事务将被跳过，不执行。</li></ol></li><li>如果 gtid_next 是一个指定的 GTID 的值，比如通过 <code>set gtid_next='current_gtid’</code>指定为 current_gtid，那么就有两种可能：<ol><li>如果 current_gtid 已经存在于实例的 GTID 集合中，接下来执行的这个事务会直接被系统忽略；</li><li>如果 current_gtid 没有存在于实例的 GTID 集合中，就将这个 current_gtid 分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的 GTID，因此 gno 也不用加 1。</li></ol></li></ol><p>注意，一个 current_gtid 只能给一个事务使用。这个事务提交后，如果要执行下一个事务，就要执行 set 命令，把 gtid_next 设置成另外一个 gtid 或者 automatic。<strong>这样，每个 MySQL 实例都维护了一个 GTID 集合，用来对应“这个实例执行过的所有事务”</strong>。</p><h5 id="使用示例"><a class="header-anchor" href="#使用示例">¶</a>使用示例</h5><p>在实例 X 中创建一个表 t。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CREATE TABLE `t` (  `id` int(11) NOT NULL,  `c` int(11) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t values(1,1);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135040.png" alt="初始化数据的 binlog"></p><p>可以看到，事务的 BEGIN 之前有一条 <code>SET @@SESSION.GTID_NEXT</code> 命令。这时，如果实例 X 有从库，那么将 <code>CREATE TABLE</code> 和 <code>insert</code> 语句的 binlog 同步到从库，从库在执行事务之前就会先执行这两个 SET 命令， 这样被加入从库的 GTID 集合的，就是图中的这两个 GTID。</p><p>假设，现在这个实例 X 是另外一个实例 Y 的从库，并且此时在实例 Y 上执行了下面这条插入语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">insert into t values(1,1);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>并且，这条语句在实例 Y 上的 GTID 是 “aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10”。那么，实例 X 作为 Y 的从库，就要同步这个事务过来执行然后将这个 GTID 加入到自己的 GTID 集合中，但是显然因为表 t 已经插入过 id 为 1 的行，该主库语句执行出现主键冲突，导致实例 X 的同步线程停止。这时，我们应该怎么处理呢？</p><p>处理方法就是，你可以执行下面的这个语句序列：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">set gtid_next='aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10';begin;commit;set gtid_next=automatic;start slave;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中，前三条语句的作用，是通过提交一个空事务，把这个 GTID 加到实例 X 的 GTID 集合中。如下图所示，就是执行完这个空事务之后的 <code>show master status</code> 的结果。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135043.png" alt="show master status 结果"></p><p>可以看到实例 X 的 <code>Executed_Gtid_set</code> (GTID集合)里面，已经加入了这个 GTID。这样，再执行 <code>start slave</code> 命令让同步线程执行起来的时候，虽然实例 X 上还是会继续执行实例 Y 传过来的事务，但是由于“aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10”已经存在于实例 X 的 GTID 集合中了，所以实例 X 就会直接跳过这个事务，也就不会再出现主键冲突的错误。</p><blockquote><p>在上面的这个语句序列中，start slave 命令之前还有一句 <code>set gtid_next=automatic</code>。这句话的作用是“恢复 GTID 的默认分配行为”，也就是说如果之后有新的事务再执行，就还是按照原来的分配方式，继续分配 gno=3（当然，在同步主库的线程中，会通过主动设置主库的 GTID 为 current_gtid 执行主库事务，而在当前库上新执行的事务就是 automatic 了）。</p></blockquote><h4 id="基于-GTID-的主备切换"><a class="header-anchor" href="#基于-GTID-的主备切换">¶</a>基于 GTID 的主备切换</h4><p>在 GTID 模式下，备库 B 要设置为新主库 A’的从库的语法如下：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">CHANGE MASTER TO MASTER_HOST=$host_name MASTER_PORT=$port MASTER_USER=$user_name MASTER_PASSWORD=$password master_auto_position=1 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中，<code>master_auto_position=1</code> 就表示这个主备关系使用的是 GTID 协议。可以看到，前面让我们头疼不已的 <code>MASTER_LOG_FILE</code> 和 <code>MASTER_LOG_POS</code> 参数，已经不需要指定了。我们把现在这个时刻，实例 A’的 GTID 集合记为 set_a，实例 B 的 GTID 集合记为 set_b。接下来，我们就看看现在的主备切换逻辑。我们在实例 B 上执行 <code>start slave</code> 命令，取 binlog 的逻辑是这样的：</p><ol><li><p>实例 B 指定主库 A’，基于主备协议建立连接。</p></li><li><p>实例 B 把 set_b 发给主库 A’。</p></li><li><p>实例 A’算出 set_a 与 set_b 的差集，也就是所有存在于 set_a，但是不存在于 set_b 的 GTID 的集合，判断 A’本地是否包含了这个差集需要的所有 binlog 事务。</p><ol><li><p>如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误；</p><blockquote><p>此时解决方案：</p><ol><li>如果业务允许主从不一致的情况，那么可以在主库上先执行 <code>show global variables like ‘gtid_purged’</code>，得到主库已经删除的 GTID 集合，假设是 gtid_purged1；然后先在从库上执行 reset master，再执行 set global gtid_purged =‘gtid_purged1’；最后执行 start slave，就会从主库现存的 binlog 开始同步。binlog 缺失的那一部分，数据在从库上就可能会有丢失，造成主从不一致。</li><li>如果需要主从数据一致的话，最好还是通过重新搭建从库来做。</li><li>如果有其他的从库保留有全量的 binlog 的话，可以把新的从库先接到这个保留了全量 binlog 的从库，追上日志以后，如果有需要，再接回主库。</li><li>如果 binlog 有备份的情况，可以先在从库上应用缺失的 binlog，然后再执行 start slave。</li></ol></blockquote></li><li><p>如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B；</p></li></ol></li><li><p>之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行。</p></li></ol><p>其实，这个逻辑里面包含了一个设计思想：在基于 GTID 的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。因此，如果实例 B 需要的日志已经不存在，A’就拒绝把日志发给 B。这跟基于位点的主备协议不同。基于位点的协议，是由备库决定的，备库指定哪个位点，主库就发哪个位点，不做日志的完整性判断。</p><p>基于上面的介绍，我们再来看看引入 GTID 后，一主多从的切换场景下，主备切换是如何实现的。由于不需要找位点了，所以从库 B、C、D 只需要分别执行 <code>change master</code> 命令指向实例 A’即可。其实，严谨地说，主备切换不是不需要找位点了，<strong>而是找位点这个工作，在实例 A’内部就已经自动完成了</strong>。但由于这个工作是自动的，所以对 HA 系统的开发人员来说，非常友好。</p><p>之后这个系统就由新主库 A’写入，主库 A’的自己生成的 binlog 中的 GTID 集合格式是：<code>server_uuid_of_A’:1-M</code>。如果之前从库 B 的 GTID 集合格式是 <code>server_uuid_of_A:1-N</code>， 那么切换之后 GTID 集合的格式就变成了 server_uuid_of_A:1-N, <code>server_uuid_of_A’:1-M</code>。当然，主库 A’之前也是 A 的备库，因此主库 A’和从库 B 的 GTID 集合是一样的。这就达到了我们预期。</p><h4 id="GTID-和在线-DDL"><a class="header-anchor" href="#GTID-和在线-DDL">¶</a>GTID 和在线 DDL</h4><p>在业务高峰期的慢查询性能问题时，分析到如果是由于索引缺失引起的性能问题，我们可以通过在线加索引来解决。但是，考虑到要避免新增索引对主库性能造成的影响，我们可以先在备库加索引，然后再切换。<strong>在双 M 结构下，备库执行的 DDL 语句也会传给主库，为了避免传回后对主库造成影响，要通过 <code>set sql_log_bin=off</code> 暂时关掉备库的 binlog 写</strong>。这样操作的话，数据库里面是加了索引，但是 binlog 并没有记录下这一个更新，是会导致数据和日志不一致的。现在可以通过 GTID 方案实现 online DDL 的执行。</p><p>假设，这两个互为主备关系的库还是实例 X 和实例 Y，且当前主库是 X，并且都打开了 GTID 模式。这时的主备切换流程可以变成下面这样：</p><ul><li><p>在实例 X 上执行 <code>stop slave</code> ，停止复制实例 Y，此时双 M 变成单 M 结构，Y -&gt; X。</p></li><li><p>在实例 Y 上执行 DDL 语句。注意，这里并不需要关闭 binlog。</p></li><li><p>执行完成后，查出这个 DDL 语句对应的 GTID，并记为 <code>server_uuid_of_Y:gno</code>。</p></li><li><p>到实例 X 上执行以下语句序列：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">set GTID_NEXT="server_uuid_of_Y:gno";begin;commit;set gtid_next=automatic;start slave;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这样做的目的在于，既可以让实例 Y 的更新有 binlog 记录，同时也可以确保不会在实例 X 上执行这条更新。</p></li><li><p>接下来，执行完主备切换，然后照着上述流程再执行一遍即可。</p></li></ul><h2 id="一主多从：主备延迟带来的读写分离问题"><a class="header-anchor" href="#一主多从：主备延迟带来的读写分离问题">¶</a>一主多从：主备延迟带来的读写分离问题</h2><p>所谓的一主多从的结构，其实就是读写分离的基本结构了。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135049.png" alt="读写分离基本结构"></p><p>读写分离的主要目标就是分摊主库的压力。图 1 中的结构是客户端（client）主动做负载均衡，这种模式下一般会把数据库的连接信息放在客户端的连接层。也就是说，由客户端来选择后端数据库进行查询。还有一种架构是，在 MySQL 和客户端之间有一个中间代理层 proxy，客户端只连接 proxy， 由 proxy 根据请求类型和上下文决定请求的分发路由。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135051.jpg" alt="带 proxy 的读写分离架构"></p><h3 id="客户端直连和-proxy-读写分离架构"><a class="header-anchor" href="#客户端直连和-proxy-读写分离架构">¶</a>客户端直连和 proxy 读写分离架构</h3><ol><li>客户端直连方案，因为少了一层 proxy 转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便。但是这种方案，由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。你可能会觉得这样客户端也太麻烦了，信息大量冗余，架构很丑。其实也未必，一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如 Zookeeper，尽量让业务端只专注于业务逻辑开发。</li><li>带 proxy 的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由 proxy 完成的。但这样的话，对后端维护团队的要求会更高。而且，proxy 也需要有高可用架构。因此，带 proxy 架构的整体就相对比较复杂。</li></ol><p>理解了这两种方案的优劣，具体选择哪个方案就取决于数据库团队提供的能力了。但目前看，趋势是往带 proxy 的架构方向发展的。</p><h3 id="主备延迟"><a class="header-anchor" href="#主备延迟">¶</a>主备延迟</h3><p>但是，不论使用哪种架构，都会即将要讨论的问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。<strong>这种“在从库上会读到系统的一个过期状态”的现象，在这里暂且称之为“过期读”。</strong></p><h3 id="解决方案"><a class="header-anchor" href="#解决方案">¶</a>解决方案</h3><p>前面说过了几种可能导致主备延迟的原因，以及对应的优化策略，但是主从延迟还是不能 100% 避免的。不论哪种结构，客户端都希望查询从库的数据结果，跟查主库的数据结果是一样的。接下来，我们就来讨论怎么处理过期读问题。</p><p>处理过期读的方案汇总：</p><ul><li>强制走主库方案；</li><li>sleep 方案；</li><li>判断主备无延迟方案；</li><li>配合 semi-sync 方案；</li><li>等主库位点方案；</li><li>等 GTID 方案。</li></ul><h4 id="强制走主库方案"><a class="header-anchor" href="#强制走主库方案">¶</a>强制走主库方案</h4><p>强制走主库方案其实就是，将查询请求做分类。通常情况下，我们可以将查询请求分为这么两类：</p><ol><li>对于必须要拿到最新结果的请求，强制将其发到主库上。比如，在一个交易平台上，卖家发布商品以后，马上要返回主页面，看商品是否发布成功。那么，这个请求需要拿到最新的结果，就必须走主库。</li><li>对于可以读到旧数据的请求，才将其发到从库上。在这个交易平台上，买家来逛商铺页面，就算晚几秒看到最新发布的商品，也是可以接受的。那么，这类请求就可以走从库。</li></ol><p>这个方案是不是有点畏难和取巧的意思，但其实这个方案是用得最多的。当然，这个方案最大的问题在于，有时候你会碰到“所有查询都不能是过期读”的需求，比如一些金融类的业务。这样的话，你就要放弃读写分离，所有读写压力都在主库，等同于放弃了扩展性。因此接下来讨论的话题是：可以支持读写分离的场景下，有哪些解决过期读的方案，并分析各个方案的优缺点。</p><h4 id="Sleep-方案"><a class="header-anchor" href="#Sleep-方案">¶</a>Sleep 方案</h4><p>主库更新后，读从库之前先 sleep 一下。具体的方案就是，类似于执行一条 <code>select sleep(1)</code> 命令。这个方案的假设是，大多数情况下主备延迟在 1 秒之内，做一个 sleep 可以有很大概率拿到最新的数据。</p><p>这个方案的第一感觉，很可能是不靠谱儿，应该不会有人用吧？并且，还可能会说，直接在发起查询时先执行一条 sleep 语句，用户体验很不友好啊。但，这个思路确实可以在一定程度上解决问题。</p><p>为了看起来更靠谱儿，我们可以换一种方式。以卖家发布商品为例，商品发布后，用 Ajax（Asynchronous JavaScript + XML，异步 JavaScript 和 XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。这样，卖家就可以通过这个显示，来确认产品已经发布成功了。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了 sleep 的目的，进而也就解决了过期读的问题。也就是说，这个 sleep 方案确实解决了类似场景下的过期读问题。</p><p>但，从严格意义上来说，这个方案存在的问题就是不精确。这个不精确包含了两层意思：如果这个查询请求本来 0.5 秒就可以在从库上拿到正确结果，也会等 1 秒；如果延迟超过 1 秒，还是会出现过期读。是不是有一种“你是不是在逗我”的感觉，这个改进方案虽然可以解决类似 Ajax 场景下的过期读问题，但还是怎么看都不靠谱儿。别着急，接下来就你介绍一些更准确的方案。</p><h4 id="判断主备无延迟方案"><a class="header-anchor" href="#判断主备无延迟方案">¶</a>判断主备无延迟方案</h4><p>要确保备库无延迟，通常有三种做法。前面提到<code>show slave status</code> 结果里的 <code>seconds_behind_master</code> 参数的值，可以用来衡量主备延迟时间的长短。</p><p>所以<strong>第一种确保主备无延迟的方法</strong>是，每次从库执行查询请求前，先判断 <code>seconds_behind_master</code> 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求。<code>seconds_behind_master</code> 的单位是秒，如果你觉得精度不够的话，还可以采用对比位点和 GTID 的方法来确保主备无延迟，也就是接下来要说的第二和第三种方法。</p><p>如下图所示，是一个 <code>show slave status</code> 结果的部分截图</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135056.png" alt="show slave status 结果"></p><p>现在，我们就通过这个结果，来看看具体如何通过对比位点和 GTID 来确保主备无延迟。</p><p><strong>第二种方法，对比位点确保主备无延迟</strong>：</p><ul><li>Master_Log_File 和 Read_Master_Log_Pos，表示的是读到的主库的最新位点；</li><li>Relay_Master_Log_File 和 Exec_Master_Log_Pos，表示的是备库执行的最新位点。</li></ul><p>如果 Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和 Exec_Master_Log_Pos 这两组值完全相同，就表示接收到的日志已经同步完成。</p><p><strong>第三种方法，对比 GTID 集合确保主备无延迟</strong>：</p><ul><li>Auto_Position=1 ，表示这对主备关系使用了 GTID 协议。</li><li>Retrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；</li><li>Executed_Gtid_Set，是备库所有已经执行完成的 GTID 集合。</li></ul><p>如果这两个集合相同，也表示备库接收到的日志都已经同步完成。可见，对比位点和对比 GTID 这两种方法，都要比判断 <code>seconds_behind_master</code> 是否为 0 更准确。在执行查询请求之前，先判断从库是否同步完成的方法，相比于 sleep 方案，准确度确实提升了不少，但还是没有达到“精确”的程度。为什么这么说呢？</p><p>一个事务的 binlog 在主备库之间的状态：</p><ol><li>主库执行完成，写入 binlog，并反馈给客户端；</li><li>binlog 被从主库发送给备库，备库收到；</li><li>在备库执行 binlog 完成。</li></ol><p>我们上面判断主备无延迟的逻辑，是“备库收到的日志都执行完成了”。但是，从 binlog 在主备之间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。如下图所示就是这样的一个状态。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135101.png" alt="备库还没收到 trx3"></p><p>这时，主库上执行完成了三个事务 trx1、trx2 和 trx3，其中：</p><ol><li>trx1 和 trx2 已经传到从库，并且已经执行完成了；</li><li>trx3 在主库执行完成，并且已经回复给客户端，但是还没有传到从库中。</li></ol><p>如果这时候你在从库 B 上执行查询请求，按照我们上面的逻辑，从库认为已经没有同步延迟，但还是查不到 trx3 的。严格地说，就是出现了过期读。那么，这个问题有没有办法解决呢？</p><h4 id="配合-semi-sync"><a class="header-anchor" href="#配合-semi-sync">¶</a>配合 semi-sync</h4><p>要解决这个问题，就要引入半同步复制，也就是 semi-sync replication。semi-sync 做了这样的设计：</p><ol><li>事务提交的时候，主库把 binlog 发给从库；</li><li>从库收到 binlog 以后，发回给主库一个 ack，表示收到了；</li><li>主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。</li></ol><p>也就是说，如果启用了 semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。此时可以来讨论一个问题，如果主库掉电的时候，有些 binlog 还来不及发给从库，会不会导致系统数据丢失？答案是，如果使用的是普通的异步复制模式，就可能会丢失，但 semi-sync 就可以解决这个问题。</p><p>这样，semi-sync 配合前面关于位点的判断，就能够确定在从库上执行的查询请求，可以避免过期读。但是，semi-sync+ 位点判断的方案，只对一主一备的场景是成立的。在一主多从场景中，主库只要等到一个从库的 ack，就开始给客户端返回确认。这时，在从库上执行查询请求，就有两种情况：</p><ol><li>如果查询是落在这个响应了 ack 的从库上，是能够确保读到最新数据；</li><li>但如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。</li></ol><p>其实，判断同步位点的方案还有另外一个潜在的问题，即：如果在业务更新的高峰期，主库的位点或者 GTID 集合更新很快，那么上面的两个位点等值判断就会一直不成立，很可能出现从库上迟迟无法响应查询请求的情况。实际上，回到我们最初的业务逻辑里，当发起一个查询请求以后，我们要得到准确的结果，其实并不需要等到“主备完全同步”。为什么这么说呢？我们来看一下这个时序图。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135105.png" alt="主备持续延迟一个事务"></p><p>上图中，就是等待位点方案的一个 bad case。图中备库 B 下的虚线框，分别表示 relaylog 和 binlog 中的事务。可以看到，从状态 1 到状态 4，一直处于延迟一个事务的状态。备库 B 一直到状态 4 都和主库 A 存在延迟，如果用上面必须等到无延迟才能查询的方案，select 语句直到状态 4 都不能被执行。但是，其实客户端是在发完 trx1 更新后发起的 select 语句，我们只需要确保 trx1 已经执行完成就可以执行 select 语句了。也就是说，如果在状态 3 执行查询请求，得到的就是预期结果了。</p><h5 id="semi-sync-判断主备无延迟的方案的问题："><a class="header-anchor" href="#semi-sync-判断主备无延迟的方案的问题：">¶</a>semi-sync + 判断主备无延迟的方案的问题：</h5><ul><li>一主多从的时候，在某些从库执行查询请求会存在过期读的现象；</li><li>在持续延迟的情况下，可能出现过度等待的问题。</li></ul><h4 id="等主库位点方案"><a class="header-anchor" href="#等主库位点方案">¶</a>等主库位点方案</h4><p>要理解等主库位点方案，需要先介绍一条命令：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select master_pos_wait(file, pos[, timeout]);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这条命令的逻辑如下：</p><ol><li>它是在从库执行的；</li><li>参数 file 和 pos 指的是主库上的文件名和位置；</li><li>timeout 可选，设置为正整数 N 表示这个函数最多等待 N 秒。</li></ol><p>这个命令正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。当然，除了正常返回一个正整数 M 外，这条命令还会返回一些其他结果，包括：</p><ol><li>如果执行期间，备库同步线程发生异常，则返回 NULL；</li><li>如果等待超过 N 秒，就返回 -1；</li><li>如果刚开始执行的时候，就发现已经执行过这个位置了，则返回 0。</li></ol><p>对于前面图中先执行 trx1，再执行一个查询请求的逻辑，要保证能够查到正确的数据，我们可以使用这个逻辑：</p><ol><li>trx1 事务更新完成后，马上执行 <code>show master status</code> 得到当前主库执行到的 File 和 Position；</li><li>选定一个从库执行查询语句；</li><li>在从库上执行 <code>select master_pos_wait(File, Position, 1);</code></li><li>如果返回值是 &gt;=0 的正整数，则在这个从库执行查询语句；</li><li>否则，到主库执行查询语句。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135109.png" alt="master_pos_wait 方案"></p><p>这里我们假设，这条 select 查询最多在从库上等待 1 秒。那么，如果 1 秒内 <code>master_pos_wait</code> 返回一个大于等于 0 的整数，就确保了从库上执行的这个查询结果一定包含了 trx1 的数据。</p><p>步骤 5 到主库执行查询语句，是这类方案常用的退化机制。因为从库的延迟时间不可控，不能无限等待，所以如果等待超时，就应该放弃，然后到主库去查。如果所有的从库都延迟超过 1 秒了，那查询压力不就都跑到主库上了吗？确实是这样。但是，按照我们设定不允许过期读的要求，就只有两种选择，一种是超时放弃，一种是转到主库查询。具体怎么选择，就需要业务开发同学做好限流策略了。</p><h4 id="GTID-方案"><a class="header-anchor" href="#GTID-方案">¶</a>GTID 方案</h4><p>如果你的数据库开启了 GTID 模式，对应的也有等待 GTID 的方案。MySQL 中同样提供了一个类似的命令：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">select wait_for_executed_gtid_set(gtid_set, 1);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这条命令的逻辑是：</p><ol><li>等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；</li><li>超时返回 1。</li></ol><p>在前面等位点的方案中，我们执行完事务后，还要主动去主库执行 <code>show master status</code>。而 MySQL 5.7.6 版本开始，允许在执行完更新类事务后，把这个事务的 GTID 返回给客户端，这样等 GTID 的方案就可以减少一次查询。这时，等 GTID 的执行流程就变成了：</p><ol><li>trx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1；</li><li>选定一个从库执行查询语句；</li><li>在从库上执行 <code>select wait_for_executed_gtid_set(gtid1, 1);</code></li><li>如果返回值是 0，则在这个从库执行查询语句；</li><li>否则，到主库执行查询语句。</li></ol><p>跟等主库位点的方案一样，等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135112.png" alt="wait_for_executed_gtid_set 方案"></p><p>在上面的第一步中，trx1 事务更新完成后，从返回包直接获取这个事务的 GTID。问题是，怎么能够让 MySQL 在执行事务后，返回包中带上 GTID 呢？只需要将参数 <code>session_track_gtids</code> 设置为 <code>OWN_GTID</code>，然后通过 API 接口 <code>mysql_session_track_get_first</code> 从返回包解析出 GTID 的值即可。</p><p>类似的 <code>mysql_reset_connection</code> 也存在这类 API 接口，那么这类接口应该怎么使用呢？其实，MySQL 并没有提供这类接口的 SQL 用法，是提供给程序的 <a href="https://dev.mysql.com/doc/refman/5.7/en/c-api-functions.html" target="_blank" rel="noopener">API</a>。比如，为了让客户端在事务提交后，返回的 GITD 能够在客户端显示出来，可以对 MySQL 客户端代码做点修改，如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135114.png" alt="显示更新事务的 GTID-- 代码"></p><p>这样，就可以看到语句执行完成，显示出 GITD 的值。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135119.png" alt="显示更新事务的 GTID-- 效果"></p><p>当然了，这只是一个例子。你要使用这个方案的时候，还是应该在你的客户端代码中调用 <code>mysql_session_track_get_first</code> 这个函数。</p><h5 id="问题"><a class="header-anchor" href="#问题">¶</a>问题</h5><p>假设系统采用了等 GTID 的方案，现在要对主库的一张大表做 DDL，可能会出现什么情况呢？为了避免这种情况，你会怎么做呢？</p><p>假设，这条语句在主库上要执行 10 分钟，提交后传到备库就要 10 分钟（典型的大事务）。那么，在主库 DDL 之后再提交的事务的 GTID，去备库查的时候，就会等 10 分钟才出现。这样，这个读写分离机制在这 10 分钟之内都会超时，然后走主库。</p><ul><li>这种预期内的操作，应该在业务低峰期的时候，确保主库能够支持所有业务查询，然后把读请求都切到主库，再在主库上做 DDL。等备库延迟追上以后，再把读请求切回备库。所以大事务对等位点方案的影响挺大的。当然了，使用 gh-ost 方案来解决这个问题也是不错的选择。</li><li>另外，也可以使用前面提到的现在先从库中执行 DDL 然后切换主备再执行的方式进行。</li></ul><h3 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h3><p>这几种方案中，有的方案看上去是做了妥协，有的方案看上去不那么靠谱儿，但都是有实际应用场景的，你需要根据业务需求选择。即使是最后等待位点和等待 GTID 这两个方案，虽然看上去比较靠谱儿，但仍然存在需要权衡的情况。如果所有的从库都延迟，那么请求就会全部落到主库上，这时候会不会由于压力突然增大，把主库打挂了呢？</p><p>其实，在实际应用中，这几个方案是可以混合使用的。比如，先在客户端对请求做分类，区分哪些请求可以接受过期读，而哪些请求完全不能接受过期读；然后，对于不能接受过期读的语句，再使用等 GTID 或等位点的方案。但话说回来，过期读在本质上是由一写多读导致的。在实际应用中，可能会有别的不需要等待就可以水平扩展的数据库方案，但这往往是用牺牲写性能换来的，也就是需要在读性能和写性能中取权衡。</p><h2 id="如何检测一个数据库是否有问题"><a class="header-anchor" href="#如何检测一个数据库是否有问题">¶</a>如何检测一个数据库是否有问题</h2><p>在一主一备的双 M 架构里，主备切换只需要把客户端流量切到备库；而在一主多从架构里，主备切换除了要把客户端流量切到备库外，还需要把从库接到新主库上。主备切换有两种场景，一种是主动切换，一种是被动切换。而其中被动切换，往往是因为主库出问题了，由 HA 系统发起的。那么怎么判断一个主库出问题了？连上 MySQL，执行个 select 1 就好了。但是 select 1 成功返回了，就表示主库没问题吗？</p><h3 id="select-1-判断"><a class="header-anchor" href="#select-1-判断">¶</a>select 1 判断</h3><p>实际上，select 1 成功返回，只能说明这个库的进程还在，并不能说明主库没问题。现在，我们来看一下这个场景。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">set global innodb_thread_concurrency=3;CREATE TABLE `t` (  `id` int(11) NOT NULL,  `c` int(11) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t values(1,1)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135122.png" alt="查询 blocked"></p><p>我们设置 <code>innodb_thread_concurrency</code> 参数的目的是，控制 InnoDB 的并发线程上限。也就是说，一旦并发线程数达到这个值，InnoDB 在接收到新请求的时候，就会进入等待状态，直到有线程退出。这里把 <code>innodb_thread_concurrency</code> 设置成 3，表示 InnoDB 只允许 3 个线程并行执行。</p><p>而在我们的例子中，前三个 session 中的 sleep(100)，使得这三个语句都处于“执行”状态，以此来模拟大查询。 session D 里面，<code>select 1</code> 是能执行成功的，但是查询表 t 的语句会被堵住。也就是说，如果这时候我们用 select 1 来检测实例是否正常的话，是检测不出问题的。</p><p>在 InnoDB 中，<code>innodb_thread_concurrency</code> 这个参数的默认值是 0，表示不限制并发线程数量。但是，不限制并发线程数肯定是不行的。因为，一个机器的 CPU 核数有限，线程全冲进来，上下文切换的成本就会太高。所以，通常情况下，我们建议把 <code>innodb_thread_concurrency</code> 设置为 64~128 之间的值。</p><blockquote><p>另外，这里有一个常见的问题，空间满之后，发现数据库连接不上了，更不用说想做什么删除动作了。其实空间满本身是不会导致连不上的。但是因为空间满，事务无法提交，可能会导致接下来外部事务重试，新重试的业务还是堵在提交阶段，持续累积可能会把连接数用满达到最大连接数。</p></blockquote><ol><li><p>但是线上的并发连接数动不动就上千了，并发线程上限数设置为 128 够吗？这里面涉及到了两个概念，一个是并发连接，一个是并发查询，而<code>innodb_thread_concurrency</code>设置的就是并发查询的线程数，它和并发连接线程数没有直接关系。在 <code>show processlist</code> 的结果里，看到的几千个连接，指的就是并发连接。而“当前正在执行”的语句，才是我们所说的并发查询。</p></li><li><p>并发连接数达到几千个影响并不大，就是多占一些内存而已。我们应该关注的是并发查询，因为并发查询太高才是 CPU 杀手。这也是为什么我们需要设置 <code>innodb_thread_concurrency</code> 参数的原因（连接着的不一定在执行，只有执行的才会占用 CPU 时间，产生上下文切换）。</p></li><li><p>那在热点更新和死锁检测的时候，如果把 <code>innodb_thread_concurrency</code> 设置为 128 的话，那么出现同一行热点更新的问题时，是不是很快就把 128 消耗完了，这样整个系统是不是就挂了呢？实际上，在线程进入锁等待以后，并发线程的计数会减一，也就是说等行锁（也包括间隙锁）的线程是不算在 128 里面的。MySQL 这样设计是非常有意义的。因为，进入锁等待的线程已经不吃 CPU 了；更重要的是，必须这么设计，才能避免整个系统锁死。为什么呢？假设处于锁等待的线程也占并发线程的计数，你可以设想一下这个场景：</p><ol><li>线程 1 执行 <code>begin; update t set c=c+1 where id=1</code>, 启动了事务 trx1， 然后保持这个状态。这时候，线程处于空闲状态，不算在并发线程里面。</li><li>线程 2 到线程 129 都执行 <code>update t set c=c+1 where id=1;</code> 由于等行锁，进入等待状态。这样就有 128 个线程处于等待状态；</li><li>如果处于锁等待状态的线程计数不减一，InnoDB 就会认为线程数用满了，会阻止其他语句进入引擎执行，这样线程 1 不能提交事务。而另外的 128 个线程又处于锁等待状态，整个系统就堵住了。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135126.png" alt="系统锁死状态（假设等行锁的语句占用并发计数）"></p><p>这时候 InnoDB 不能响应任何请求，整个系统被锁死。而且，由于所有线程都处于等待状态，此时占用的 CPU 却是 0，而这明显不合理。所以，我们说 InnoDB 在设计时，遇到进程进入锁等待的情况时，将并发线程的计数减 1 的设计，是合理而且是必要的。</p></li></ol><p><strong>虽然说等锁的线程不算在并发线程计数里，但如果它在真正地执行查询，就比如我们上面例子中前三个事务中的 <code>select sleep(100) from t</code>，还是要算进并发线程的计数的</strong>。在这个例子中，同时在执行的语句超过了设置的 <code>innodb_thread_concurrency</code> 的值，这时候系统其实已经不行了，但是通过 <code>select 1</code> 来检测系统，MySQL 却是正常返回的，此时 HA 会认为数据库还是正常的。因此，我们使用 <code>select 1</code> 的判断逻辑要修改一下。</p><h3 id="查表判断"><a class="header-anchor" href="#查表判断">¶</a>查表判断</h3><p>为了能够检测 InnoDB 并发线程数过多导致的系统不可用情况，我们需要找一个访问 InnoDB 的场景。一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为 <code>health_check</code>，里面只放一行数据，然后定期执行：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select * from mysql.health_check; <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>使用这个方法，我们可以检测出由于并发线程过多导致的数据库不可用的情况。但是，我们马上还会碰到下一个问题，即：空间满了以后，这种方法又会变得不好使。</p><p>更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的（只要读操作不涉及事务提交。例如如果没有显示开启事务，<code>select</code> 语句不会产生事务提交）。因此，我们还是把这条监控语句再改进一下。接下来，我们就看看把查询语句改成更新语句后的效果。</p><h3 id="更新判断"><a class="header-anchor" href="#更新判断">¶</a>更新判断</h3><p>既然要更新，就要放个有意义的字段，常见做法是放一个 <code>timestamp</code> 字段，用来表示最后一次执行检测的时间。这条更新语句类似于：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> insert into mysql.health_check(id, t_modified) values (1, now()) on duplicate key update t_modified=now();<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>节点可用性的检测都应该包含主库和备库。如果用更新来检测主库的话，那么备库也要进行更新检测。但，备库的检测也是要写 binlog 的。由于我们一般会把数据库 A 和 B 的主备关系设计为双 M 结构，所以在备库 B 上执行的检测命令，也要发回给主库 A。</p><p>但是，如果主库 A 和备库 B 都用相同的更新命令，就可能出现行冲突（主备都是空表的时候），也就是可能会导致主备同步停止。所以，现在看来 <code>mysql.health_check</code> 这个表就不能<strong>只有一行数据</strong>了。</p><p>为了让主备之间的更新不产生冲突，我们可以在 <code>mysql.health_check</code> 表上存入多行数据，并用 A、B 的 <code>server_id</code> 做主键。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> CREATE TABLE `health_check` (  `id` int(11) NOT NULL,  `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,  PRIMARY KEY (`id`)) ENGINE=InnoDB;/* 检测命令 */insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified=now();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由于 MySQL 规定了主库和备库的 server_id 必须不同（否则创建主备关系的时候就会报错），这样就可以保证主、备库各自的检测命令不会发生冲突。更新判断是一个相对比较常用的方案了，不过依然存在一些问题。其中，“判定慢”一直是让 DBA 头疼的问题。</p><h4 id="判定慢-问题"><a class="header-anchor" href="#判定慢-问题">¶</a>&quot;判定慢&quot;问题</h4><p>更新语句，如果失败或者超时，就可以发起主备切换了，为什么还会有判定慢的问题呢？其实，这里涉及到的是服务器 IO 资源分配的问题。</p><ol><li>首先，所有的检测逻辑都需要一个超时时间 N。执行一条 <code>update</code> 语句，超过 N 秒后还不返回，就认为系统不可用。</li><li>可以设想一个日志盘的 IO 利用率已经是 100% 的场景。这时候，整个系统响应非常慢，已经需要做主备切换了。</li><li>但是 IO 利用率 100% 表示系统的 IO 是在工作的，每个请求都有机会获得 IO 资源，执行自己的任务。而我们的检测使用的 <code>update</code> 命令，<strong>需要的资源很少</strong>，所以可能在拿到 IO 资源的时候就可以提交成功，并且在超时时间 N 秒未到达之前就返回给了检测系统。</li><li>检测系统一看，<code>update</code> 命令没有超时，于是就得到了“系统正常”的结论。</li></ol><p>也就是说，这时候在业务系统上正常的 SQL 语句已经执行得很慢了，但是 DBA 上去一看，HA 系统还在正常工作，并且认为主库现在处于可用状态。之所以会出现这个现象，根本原因是我们上面说的所有方法，都是基于外部检测的。外部检测天然有一个问题，就是随机性。因为，外部检测都需要<strong>定时轮询</strong>，所以系统可能已经出问题了，但是却需要等到下一个检测发起执行语句的时候，我们才有可能发现问题。而且，如果你的运气不够好的话，可能第一次轮询还不能发现，这就会导致切换慢的问题。所以，接下来我要再和你介绍一种在 MySQL 内部发现数据库问题的方法。</p><h3 id="内部统计"><a class="header-anchor" href="#内部统计">¶</a>内部统计</h3><p>针对磁盘利用率这个问题，如果 MySQL 可以告诉我们，内部每一次 IO 请求的时间，那我们判断数据库是否出问题的方法就可靠得多了。其实，MySQL 5.6 版本以后提供的 <code>performance_schema</code> 库，就在 <code>file_summary_by_event_name</code> 表里统计了每次 IO 请求的时间。<code>file_summary_by_event_name</code> 表里有很多行数据，我们先来看看 <code>event_name='wait/io/file/innodb/innodb_log_file’</code>这一行。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135133.png" alt="performance_schema.file_summary_by_event_name 的一行"></p><ul><li>这一行表示统计的是 redo log 的写入时间，第一列 <code>EVENT_NAME</code> 表示统计的类型。</li><li>接下来的三组数据，显示的是 redo log 操作的时间统计。<ul><li>第一组五列，是所有 IO 类型的统计。其中，<code>COUNT_STAR</code> 是所有 IO 的总次数，接下来四列是具体的统计项， 单位是皮秒；前缀 <code>SUM</code>、<code>MIN</code>、<code>AVG</code>、<code>MAX</code>，顾名思义指的就是总和、最小值、平均值和最大值。</li><li>第二组六列，是读操作的统计。最后一列 <code>SUM_NUMBER_OF_BYTES_READ</code> 统计的是，总共从 redo log 里读了多少个字节。</li><li>第三组六列，统计的是写操作。</li></ul></li><li>最后的第四组数据，是对其他类型数据的统计。在 redo log 里，你可以认为它们就是对 fsync 的统计。</li></ul><p>在 <code>performance_schema</code> 库的 <code>file_summary_by_event_name</code> 表里，binlog 对应的是 <code>event_name = &quot;wait/io/file/sql/binlog&quot;</code>这一行。各个字段的统计逻辑，与 redo log 的各个字段完全相同。</p><p>因为我们每一次操作数据库，<code>performance_schema</code> 都需要额外地统计这些信息，所以我们打开这个统计功能是有性能损耗的。丁大的测试结果是，如果打开所有的 <code>performance_schema</code> 项，性能大概会下降 10% 左右。所以，建议只打开自己需要的项进行统计。可以通过下面的方法打开或者关闭某个具体项的统计。</p><p>如果要打开 redo log 的时间监控，你可以执行这个语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> update setup_instruments set ENABLED='YES', Timed='YES' where name like '%wait/io/file/innodb/innodb_log_file%';<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>假设，现在你已经开启了 redo log 和 binlog 这两个统计信息，那要怎么把这个信息用在实例状态诊断上呢？很简单，你可以通过 <code>MAX_TIMER</code> 的值来判断数据库是否出问题了。比如，你可以设定阈值，单次 IO 请求时间超过 200 毫秒属于异常，然后使用类似下面这条语句作为检测逻辑。</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_name where event_name in ('wait/io/file/innodb/innodb_log_file','wait/io/file/sql/binlog') and MAX_TIMER_WAIT>200*1000000000;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>发现异常后，取到你需要的信息，再通过下面这条语句：</p><pre class="line-numbers language-language-mysql"><code class="language-language-mysql">mysql> truncate table performance_schema.file_summary_by_event_name;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="总结-v2"><a class="header-anchor" href="#总结-v2">¶</a>总结</h2><p>看完后可能会觉得，<code>select 1</code> 这样的方法是不是已经被淘汰了呢，但实际上使用非常广泛的 MHA（Master High Availability），默认使用的就是这个方法。MHA 中的另一个可选方法是只做连接，就是 “如果连接成功就认为主库没问题”。不过选择这个方法的很少。其实，每个改进的方案，都会增加额外损耗，并不能用“对错”做直接判断，需要你根据业务实际情况去做权衡。丁大个人比较倾向的方案，是优先考虑 <code>update</code> 系统表，然后再配合增加检测 <code>performance_schema</code> 的信息。</p><h1>如何处理误删数据情况</h1><p>前面提到的传统高可用架构是不能预防误删数据的，因为主库的一个 <code>drop table</code> 命令，会通过 binlog 传给所有从库和级联从库，进而导致整个集群的实例都会执行这个命令。我们需要先对和 MySQL 相关的误删数据，做下分类：</p><ol><li>使用 <code>delete</code> 语句误删数据行；</li><li>使用 <code>drop table</code> 或者 <code>truncate table</code> 语句误删数据表；</li><li>使用 <code>drop database</code> 语句误删数据库；</li><li>使用 <code>rm</code> 命令误删整个 MySQL 实例。</li></ol><h2 id="误删行"><a class="header-anchor" href="#误删行">¶</a>误删行</h2><p>如果是使用 delete 语句误删了数据行，可以用 <a href="https://mariadb.com/kb/en/flashback/" target="_blank" rel="noopener">Flashback</a> 工具通过闪回把数据恢复回来。Flashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保 <code>binlog_format=row</code> 和 <code>binlog_row_image=FULL</code>。</p><p>具体恢复数据时，对单个事务做如下处理：</p><ol><li>对于 <code>insert</code> 语句，对应的 binlog event 类型是 Write_rows event，把它改成 Delete_rows event 即可；</li><li>同理，对于 <code>delete</code> 语句，也是将 Delete_rows event 改为 Write_rows event；</li><li>而如果是 Update_rows 的话，binlog 里面记录了数据行修改前和修改后的值，对调这两行的位置即可。</li></ol><p>如果误操作不是一个，而是多个，如：</p><pre><code>(A)delete ...(B)insert ...(C)update ...</code></pre><p>现在要把数据库恢复回这三个事务操作之前的状态，用 Flashback 工具解析 binlog 后，写回主库的命令是：</p><pre><code>(reverse C)update ...(reverse B)delete ...(reverse A)insert ...</code></pre><p>也就是说，如果误删数据涉及到了多个事务的话，需要将事务的顺序调过来再执行。</p><h3 id="注意不要直接在主库上恢复"><a class="header-anchor" href="#注意不要直接在主库上恢复">¶</a>注意不要直接在主库上恢复</h3><p>需要说明的是，不建议直接在主库上执行这些操作。<strong>恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库</strong>。</p><p>为什么要这么做呢？这是因为，一个在执行线上逻辑的主库，数据状态的变更往往是有关联的。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。</p><h3 id="预防"><a class="header-anchor" href="#预防">¶</a>预防</h3><p>当然，我们不止要说误删数据的事后处理办法，更重要是要做到事前预防。有以下两个建议：</p><ol><li>把 <code>sql_safe_updates</code> 参数设置为 on。这样一来，如果我们忘记在 <code>delete</code> 或者 <code>update</code> 语句中写 <code>where</code> 条件，或者 <code>where</code> 条件里面没有包含索引字段的话，这条语句的执行就会报错。</li><li>代码上线前，必须经过 SQL 审计。</li></ol><p>设置了 <code>sql_safe_updates=on</code>，如果真的要把一个小表的数据全部删掉，应该怎么办呢？如果确定这个删除操作没问题的话，可以在 <code>delete</code> 语句中加上 <code>where</code> 条件，比如 <code>where id&gt;=0</code>。但是，<code>delete</code> 全表是很慢的，需要生成回滚日志、写 redo、写 binlog。所以，从性能角度考虑，应该优先考虑使用 <code>truncate table</code> 或者 <code>drop table</code> 命令。</p><h2 id="误删库-表"><a class="header-anchor" href="#误删库-表">¶</a>误删库/表</h2><p>使用 <code>delete</code> 命令删除的数据，还可以用 Flashback 来恢复。而使用 <code>truncate</code> /<code>drop table</code> 和 <code>drop database</code> 命令删除的数据，就没办法通过 Flashback 来恢复了。为什么呢？这是因为，即使我们配置了 <code>binlog_format=row</code>，执行这三个命令时，记录的 binlog 还是 statement 格式。binlog 里面就只有一个 <code>truncate</code>/<code>drop</code> 语句，这些信息是恢复不出数据的。那么，如果我们真的是使用这几条命令误删数据了，又该怎么办呢？这种情况下，要想恢复数据，就需要使用全量备份，加增量日志的方式了。<strong>这个方案要求线上有定期的全量备份，并且实时备份 binlog</strong>。</p><p>在这两个条件都具备的情况下，假如有人中午 12 点误删了一个库，恢复数据的流程如下：</p><ol><li>取最近一次全量备份，假设这个库是一天一备，上次备份是当天 0 点；</li><li>用全量备份恢复出一个临时库；</li><li>从日志备份里面，取出凌晨 0 点之后的日志；</li><li>把这些日志，除了误删除数据的语句外，全部应用到临时库。</li></ol><p>这个流程的示意图如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135141.png" alt="数据恢复流程 -mysqlbinlog 方法"></p><h3 id="注意点"><a class="header-anchor" href="#注意点">¶</a>注意点</h3><ol><li>为了加速数据恢复，如果这个临时库上有多个数据库，你可以在使用 <code>mysqlbinlog</code> 命令时，加上一个<code>–database</code> 参数，用来指定误删表所在的库。这样，就避免了在恢复数据时还要应用其他库日志的情况。</li><li>在应用日志的时候，需要跳过 12 点误操作的那个语句的 binlog：<ul><li>如果原实例没有使用 GTID 模式，只能在应用到包含 12 点的 binlog 文件的时候，先用<code>–stop-position</code> 参数执行到误操作之前的日志，然后再用<code>–start-position</code> 从误操作之后的日志继续执行；</li><li>如果实例使用了 GTID 模式，就方便多了。假设误操作命令的 GTID 是 gtid1，那么只需要执行 <code>set gtid_next=gtid1;begin;commit;</code> 先把这个 GTID 加到临时实例的 GTID 集合，之后按顺序执行 binlog 的时候，就会自动跳过误操作的语句。</li></ul></li></ol><p>不过，即使这样，使用 mysqlbinlog 方法恢复数据还是不够快，主要原因有两个：</p><ol><li>如果是误删表，最好就是只恢复出这张表，也就是只重放这张表的操作，但是 mysqlbinlog 工具并不能指定只解析一个表的日志；</li><li>用 mysqlbinlog 解析出日志应用，应用日志的过程就只能是单线程。前面介绍的关于备库同步主库的那些并行复制的方法，在这里都用不上。</li></ol><h3 id="加速恢复"><a class="header-anchor" href="#加速恢复">¶</a>加速恢复</h3><p>一种加速的方法是，<strong>在用备份恢复出临时实例之后，将这个临时实例设置成线上备库的从库</strong>：在 <code>start slave</code> 之前，先通过执行﻿﻿<code>change replication filter replicate_do_table = (tbl_name)</code> 命令，就可以让临时库只同步误操作的表；这样做也可以用上并行复制技术，来加速整个数据恢复过程。</p><p><img src="https://cdn.jsdelivr.net/gh/JohnZhongg/blog_images/image/20201221135144.png" alt="数据恢复流程 -master-slave 方法"></p><p>可以看到，图中 binlog 备份系统到线上备库有一条虚线，是指如果由于时间太久，备库上已经删除了临时实例需要的 binlog 的话，我们可以从 binlog 备份系统中找到需要的 binlog，再放回备库中。</p><p>假设，我们发现当前临时实例需要的 binlog 是从 master.000005 开始的，但是在备库上执行 show binlogs 显示的最小的 binlog 文件是 master.000007，意味着少了两个 binlog 文件。这时，我们就需要去 binlog 备份系统中找到这两个文件。</p><p>把之前删掉的 binlog 放回备库的操作步骤，是这样的：</p><ol><li>从备份系统下载 master.000005 和 master.000006 这两个文件，放到备库的日志目录下；</li><li>打开日志目录下的 master.index 文件，在文件开头加入两行，内容分别是 “./master.000005”和“./master.000006”;</li><li>重启备库，目的是要让备库重新识别这两个日志文件；</li><li>现在这个备库上就有了临时库需要的所有 binlog 了，建立主备关系，就可以正常同步了。</li></ol><h3 id="小结"><a class="header-anchor" href="#小结">¶</a>小结</h3><p>不论是把 mysqlbinlog 工具解析出的 binlog 文件应用到临时库，还是把临时库接到备库上，这两个方案的共同点是：误删库或者表后，恢复数据的思路主要就是通过备份，再加上应用 binlog 的方式。也就是说，这两个方案都要求备份系统定期备份全量日志，而且需要确保 binlog 在被从本地删除之前已经做了备份。</p><p>但是，一个系统不可能备份无限的日志，你还需要根据成本和磁盘空间资源，设定一个日志保留的天数。如果你的 DBA 团队告诉你，可以保证把某个实例恢复到半个月内的任意时间点，这就表示备份系统保留的日志时间就至少是半个月。</p><p>另外，建议你不论使用上述哪种方式，都要把这个数据恢复功能做成自动化工具，并且经常拿出来演练。为什么这么说呢？这里的原因，主要包括两个方面：虽然“发生这种事，大家都不想的”，但是万一出现了误删事件，能够快速恢复数据，将损失降到最小，也应该不用跑路了。而如果临时再手忙脚乱地手动操作，最后又误操作了，对业务造成了二次伤害，那就说不过去了。</p><h2 id="临时实例恢复完成后的工作"><a class="header-anchor" href="#临时实例恢复完成后的工作">¶</a>临时实例恢复完成后的工作</h2><p>以上提到的都是恢复误删数据前的数据库状态到一个临时库中的动作，完成之后我们还有确认恢复是否成功。确认之后即可以从临时库恢复数据到线上库了，操作随着情况的不同也不同：</p><ul><li><p>如果原库是误删了一些行，那只能在临时库里面select数据出来，按照业务的需要去补了</p></li><li><p>如果原库是删表(例如 truncate)，就把临时库里面的表导过去，小表逻辑导，大表可以用“透明表空间机制”物理导；</p><ol><li>创建一个同版本的空 MySQL 实例，建一个名字 + 结构一模一样的表</li><li>discard这个表的 tablespace</li><li>从之前的备份集中 <code>innobackupex --apply-log</code> 并记录binlog位置（用innobackupex备份的）。还原后找到误操作表的.ibd文件，copy到新实例对应的位置</li><li>之前创建的 MySQL 实例上 import tablespace</li><li>利用 mysqlbinlog 处理增量数据</li><li>最后导出 再导入</li></ol></li></ul><h2 id="延迟复制备库"><a class="header-anchor" href="#延迟复制备库">¶</a>延迟复制备库</h2><p>虽然我们可以通过利用并行复制来加速恢复数据的过程，但是这个方案仍然存在“恢复时间不可控”的问题。如果一个库的备份特别大，或者误操作的时间距离上一个全量备份的时间较长，比如一周一备的实例，在备份之后的第 6 天发生误操作，那就需要恢复 6 天的日志，这个恢复时间可能是要按天来计算的。那么，我们有什么方法可以缩短恢复数据需要的时间呢？</p><p>如果有非常核心的业务，不允许太长的恢复时间，我们可以考虑预先搭建延迟复制的备库。这个功能是 MySQL 5.6 版本引入的。一般的主备复制结构存在的问题是，如果主库上有个表被误删了，这个命令很快也会被发给所有从库，进而导致所有从库的数据表也都一起被误删了。延迟复制的备库是一种特殊的备库，通过 <code>CHANGE MASTER TO MASTER_DELAY = N</code> 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。</p><p>比如你把 N 设置为 3600，这就代表了如果主库上有数据被误删了，并且在 1 小时内发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行 <code>stop slave</code>，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。这样的话，你就随时可以得到一个，只需要最多再追 1 小时，就可以恢复出数据的临时实例，也就缩短了整个数据恢复需要的时间。</p><h2 id="预防误删库-表的方法"><a class="header-anchor" href="#预防误删库-表的方法">¶</a>预防误删库 / 表的方法</h2><p>虽然常在河边走，很难不湿鞋，但终究还是可以找到一些方法来避免的。所以这里，也会给一些减少误删操作风险的建议。</p><ol><li>第一条建议是，账号分离。这样做的目的是，避免写错命令。比如：<ul><li>我们只给业务开发同学 DML 权限，而不给 <code>truncate</code>/<code>drop</code> 权限。而如果业务开发人员有 DDL 需求的话，也可以通过开发管理系统得到支持。</li><li>即使是 DBA 团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。</li></ul></li><li>第二条建议是，制定操作规范。这样做的目的，是避免写错要删除的表名。比如：<ul><li>在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。</li><li>改表名的时候，要求给表名加固定的后缀（比如加 _to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表。</li></ul></li></ol><h2 id="rm-删除数据"><a class="header-anchor" href="#rm-删除数据">¶</a>rm 删除数据</h2><p>其实，对于一个有高可用机制的 MySQL 集群来说，最不怕的就是 rm 删除数据了。只要不是恶意地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA 系统就会开始工作，选出一个新的主库，从而保证整个集群的正常工作。这时，你要做的就是在这个节点上把数据恢复回来，再接入整个集群。当然了，现在不止是 DBA 有自动化系统，SA（系统管理员）也有自动化系统，所以也许一个批量下线机器的操作，会让你整个 MySQL 集群的所有节点都全军覆没。应对这种情况，我的建议只能是说尽量把你的备份跨机房，或者最好是跨城市保存。</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
            <tag> 高可用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1、Cgroup概述</title>
      <link href="/2020/02/16/linux/cgroup/1-cgroup-gai-shu/"/>
      <url>/2020/02/16/linux/cgroup/1-cgroup-gai-shu/</url>
      
        <content type="html"><![CDATA[<p>cgroup和namespace类似，也是将进程进行分组，但它的目的和namespace不一样，namespace是为了隔离进程组之间的资源，而cgroup是为了对一组进程进行统一的资源监控和限制。</p><p>cgroup分<a href="https://www.kernel.org/doc/Documentation/cgroup-v1" target="_blank" rel="noopener">v1</a>和<a href="https://www.kernel.org/doc/Documentation/cgroup-v2.txt" target="_blank" rel="noopener">v2</a>两个版本，v1实现较早，功能比较多，但是由于它里面的功能都是零零散散的实现的，所以规划的不是很好，导致了一些使用和维护上的不便，v2的出现就是为了解决v1中这方面的问题，在最新的4.5内核中，cgroup v2声称已经可以用于生产环境了，但它所支持的功能还很有限，随着v2一起引入内核的还有cgroup namespace。v1和v2可以混合使用，但是这样会更复杂，所以一般没人会这样用。</p><p>本系列只介绍v1，因为这是目前大家正在用的版本，包括systemd，docker等。如果对v1比较熟悉的话，适应v2也不是问题。</p><blockquote><p>本篇所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="为什么需要cgroup"><a class="header-anchor" href="#为什么需要cgroup">¶</a>为什么需要cgroup</h2><p>在Linux里，一直以来就有对进程进行分组的概念和需求，比如<a href="https://www.win.tue.nl/~aeb/linux/lk/lk-10.html" target="_blank" rel="noopener">session group， progress group</a>等，后来随着人们对这方面的需求越来越多，比如需要追踪一组进程的内存和IO使用情况等，于是出现了cgroup，用来统一将进程进行分组，并在分组的基础上对进程进行监控和资源控制管理等。</p><h2 id="什么是cgroup"><a class="header-anchor" href="#什么是cgroup">¶</a>什么是cgroup</h2><p>术语cgroup在不同的上下文中代表不同的意思，可以指整个Linux的cgroup技术，也可以指一个具体进程组。</p><p>cgroup是Linux下的一种将进程按组进行管理的机制，在用户层看来，cgroup技术就是把系统中的所有进程组织成一颗一颗独立的树，每棵树都包含系统的所有进程，树的每个节点是一个进程组，而每颗树又和一个或者多个subsystem关联，树的作用是将进程分组，而subsystem的作用就是对这些组进行操作。cgroup主要包括下面两部分：</p><ul><li><strong>subsystem</strong> 一个subsystem就是一个内核模块，他被关联到一颗cgroup树之后，就会在树的每个节点（进程组）上做具体的操作。subsystem经常被称作&quot;resource controller&quot;，因为它主要被用来调度或者限制每个进程组的资源，但是这个说法不完全准确，因为有时我们将进程分组只是为了做一些监控，观察一下他们的状态，比如perf_event subsystem。到目前为止，Linux支持12种subsystem，比如限制CPU的使用时间，限制使用的内存，统计CPU的使用情况，冻结和恢复一组进程等，后续会对它们一一进行介绍。</li><li><strong>hierarchy</strong> 一个hierarchy可以理解为一棵cgroup树，树的每个节点就是一个进程组，每棵树都会与零到多个subsystem关联。在一颗树里面，会包含Linux系统中的所有进程，但每个进程只能属于一个节点（进程组）。系统中可以有很多颗cgroup树，每棵树都和不同的subsystem关联，一个进程可以属于多颗树，即一个进程可以属于多个进程组，只是这些进程组和不同的subsystem关联。目前Linux支持12种subsystem，如果不考虑不与任何subsystem关联的情况（systemd就属于这种情况），Linux里面最多可以建12颗cgroup树，每棵树关联一个subsystem，当然也可以只建一棵树，然后让这棵树关联所有的subsystem。当一颗cgroup树不和任何subsystem关联的时候，意味着这棵树只是将进程进行分组，至于要在分组的基础上做些什么，将由应用程序自己决定，systemd就是一个这样的例子。</li></ul><h2 id="如何查看当前系统支持哪些subsystem"><a class="header-anchor" href="#如何查看当前系统支持哪些subsystem">¶</a>如何查看当前系统支持哪些subsystem</h2><p>可以通过查看/proc/cgroups(since Linux 2.6.24)知道当前系统支持哪些subsystem，下面是一个例子</p><pre><code>#subsys_name    hierarchy       num_cgroups     enabledcpuset          11              1               1cpu             3               64              1cpuacct         3               64              1blkio           8               64              1memory          9               104             1devices         5               64              1freezer         10              4               1net_cls         6               1               1perf_event      7               1               1net_prio        6               1               1hugetlb         4               1               1pids            2               68              1</code></pre><p>从左到右，字段的含义分别是：</p><ol><li>subsystem的名字</li><li>subsystem所关联到的cgroup树的ID，如果多个subsystem关联到同一颗cgroup树，那么他们的这个字段将一样，比如这里的cpu和cpuacct就一样，表示他们绑定到了同一颗树。如果出现下面的情况，这个字段将为0：<ul><li>当前subsystem没有和任何cgroup树绑定</li><li>当前subsystem已经和cgroup v2的树绑定</li><li>当前subsystem没有被内核开启</li></ul></li><li>subsystem所关联的cgroup树中进程组的个数，也即树上节点的个数</li><li>1表示开启，0表示没有被开启(可以通过设置内核的启动参数“cgroup_disable”来控制subsystem的开启).</li></ol><h2 id="如何使用cgroup"><a class="header-anchor" href="#如何使用cgroup">¶</a>如何使用cgroup</h2><p>cgroup相关的所有操作都是基于内核中的cgroup virtual filesystem，使用cgroup很简单，挂载这个文件系统就可以了。一般情况下都是挂载到/sys/fs/cgroup目录下，当然挂载到其它任何目录都没关系。</p><p>这里假设目录/sys/fs/cgroup已经存在，下面用到的xxx为任意字符串，取一个有意义的名字就可以了，当用mount命令查看的时候，xxx会显示在第一列</p><ul><li><p>挂载一颗和所有subsystem关联的cgroup树到/sys/fs/cgroup</p><pre><code>mount -t cgroup xxx /sys/fs/cgroup</code></pre></li><li><p>挂载一颗和cpuset subsystem关联的cgroup树到/sys/fs/cgroup/cpuset</p><pre><code>mkdir /sys/fs/cgroup/cpusetmount -t cgroup -o cpuset xxx /sys/fs/cgroup/cpuset</code></pre></li><li><p>挂载一颗与cpu和cpuacct subsystem关联的cgroup树到/sys/fs/cgroup/cpu,cpuacct</p><pre><code>mkdir /sys/fs/cgroup/cpu,cpuacctmount -t cgroup -o cpu,cpuacct xxx /sys/fs/cgroup/cpu,cpuacct</code></pre></li><li><p>挂载一棵cgroup树，但不关联任何subsystem，下面就是systemd所用到的方式</p><pre><code>mkdir /sys/fs/cgroup/systemdmount -t cgroup -o none,name=systemd xxx /sys/fs/cgroup/systemd</code></pre></li></ul><p>在很多使用systemd的系统中，比如ubuntu 16.04，systemd已经帮我们将各个subsystem和cgroup树关联并挂载好了</p><pre><code>dev@ubuntu:~$ mount|grep cgrouptmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,mode=755)cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd)cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls,net_prio)cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)</code></pre><p>创建并挂载好一颗cgroup树之后，就有了树的根节点，也即根cgroup，这时候就可以通过创建文件夹的方式创建子cgroup，然后再往每个子cgroup中添加进程。在后续介绍具体的subsystem的时候会详细介绍如何操作cgroup。</p><p><strong>注意</strong></p><ul><li><p>第一次挂载一颗和指定subsystem关联的cgroup树时，会创建一颗新的cgroup树，当再一次用同样的参数挂载时，会重用现有的cgroup树，也即两个挂载点看到的内容是一样的。</p><pre><code>#在ubuntu 16.04中，systemd已经将和cpu,cpuacct绑定的cgroup树挂载到了/sys/fs/cgroup/cpu,cpuacctdev@ubuntu:~$ mount|grep /sys/fs/cgroup/cpu,cpuacctcgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct,nsroot=/)#创建一个子目录，用于后面的测试dev@ubuntu:~$ sudo mkdir /sys/fs/cgroup/cpu,cpuacct/testdev@ubuntu:~$ ls -l /sys/fs/cgroup/cpu,cpuacct/|grep testdrwxr-xr-x  2 root root 0 Oct  9 02:27 test#将和cpu,cpuacct关联的cgroup树重新mount到另外一个目录dev@ubuntu:~$ mkdir -p ./cgroup/cpu,cpuacct &amp;&amp; cd ./cgroup/dev@ubuntu:~/cgroup$ sudo mount -t cgroup -o cpu,cpuacct new-cpu-cpuacct ./cpu,cpuacct#在新目录中看到的内容和/sys/fs/cgroup/cpu,cpuacct的一样，#说明我们将同一颗cgroup树mount到了系统中的不同两个目录，#这颗cgroup树和subsystem的关联关系不变，#这点类似于mount同一块硬盘到多个目录dev@ubuntu:~/cgroup$ ls -l ./cpu,cpuacct/ |grep testdrwxr-xr-x  2 root root 0 Oct  9 02:27 test#清理dev@ubuntu:~/cgroup$ sudo umount new-cpu-cpuacct</code></pre></li><li><p>挂载一颗cgroup树时，可以指定多个subsystem与之关联，但一个subsystem只能关联到一颗cgroup树，一旦关联并在这颗树上创建了子cgroup，subsystems和这棵cgroup树就成了一个整体，不能再重新组合。以上面ubuntu 16.04为例，由于已经将cpu,cpuacct和一颗cgroup树关联并且他们下面有子cgroup了，所以就不能单独的将cpu和另一颗cgroup树关联。</p><pre><code>#尝试将cpu subsystem重新关联一颗cgroup树并且将这棵树mount到./cpu目录dev@ubuntu:~/cgroup$ mkdir cpudev@ubuntu:~/cgroup$ sudo mount -t cgroup -o cpu new-cpu ./cpumount: new-cpu is already mounted or /home/dev/cgroup/cpu busy#由于cpu和cpuacct已经和一颗cgroup树关联了，所以这里mount失败#尝试将devices和pids关联到同一颗树上，由于他们各自已经关联到了不同的cgroup树，所以mount失败dev@ubuntu:~/cgroup$ mkdir devices,pidsdev@ubuntu:~/cgroup$ sudo mount -t cgroup -o devices,pids new-devices-pids ./devices,pidsmount: new-devices-pids is already mounted or /home/dev/cgroup/devices,pids busy</code></pre><p>但由于/sys/fs/cgroup/hugetlb和/sys/fs/cgroup/perf_event下没有子cgroup，我们可以将他们重新组合。一般情况下不会用到这个功能，一但最开始关联好了之后，就不会去重新修改它，也即我们一般不会去修改systemd给我们设置好的subsystem和cgroup树的关联关系。</p><pre><code>#/sys/fs/cgroup/hugetlb和/sys/fs/cgroup/perf_event里面没有子目录，说明没有子cgroupdev@ubuntu:~$ ls -l /sys/fs/cgroup/hugetlb|grep ^ddev@ubuntu:~$ ls -l /sys/fs/cgroup/perf_event|grep ^d#直接mount不行，因为perf_event,hugetlb已经被系统单独mount过了dev@ubuntu:~$ sudo mount -t cgroup -operf_event,hugetlb xxx /mntmount: xxx is already mounted or /mnt busy#先umountdev@ubuntu:~$ sudo umount /sys/fs/cgroup/perf_eventdev@ubuntu:~$ sudo umount /sys/fs/cgroup/hugetlb#如果系统默认安装了lxcfs的话，lxcfs会将它们挂载在自己的目录，#所以需要umount lxcfs及下面这两个目录，否则就没有真正的umount掉perf_event和hugetlbdev@ubuntu:~$ sudo umount lxcfsdev@ubuntu:~$ sudo umount /run/lxcfs/controllers/hugetlbdev@ubuntu:~$ sudo umount /run/lxcfs/controllers/perf_event#再mount，成功dev@ubuntu:~$ sudo mount -t cgroup -operf_event,hugetlb xxx /mntdev@ubuntu:~$ ls /mnt/cgroup.clone_children  cgroup.sane_behavior  hugetlb.2MB.limit_in_bytes      hugetlb.2MB.usage_in_bytes  release_agentcgroup.procs           hugetlb.2MB.failcnt   hugetlb.2MB.max_usage_in_bytes  notify_on_release           tasks#清理dev@ubuntu:~$ sudo reboot</code></pre></li><li><p>可以创建任意多个不和任何subsystem关联的cgroup树，name是这棵树的唯一标记，当name指定的是一个新的名字时，将创建一颗新的cgroup树，但如果内核中已经存在一颗一样name的cgroup树，那么将mount已存在的这颗cgroup树</p><pre><code>#由于name=test的cgroup树在系统中不存在，所以这里会创建一颗新的name=test的cgroup树dev@ubuntu:~$ mkdir -p cgroup/test &amp;&amp; cd cgroupdev@ubuntu:~/cgroup$ sudo mount -t cgroup -o none,name=test test ./test#系统为新创建的cgroup树的root cgroup生成了默认文件dev@ubuntu:~/cgroup$ ls ./test/cgroup.clone_children  cgroup.procs  cgroup.sane_behavior  notify_on_release  release_agent  tasks#新创建的cgroup树的root cgroup里包含系统中的所有进程dev@ubuntu:~/cgroup$ wc -l ./test/cgroup.procs131 ./test/cgroup.procs#创建子cgroupdev@ubuntu:~/cgroup$ cd test &amp;&amp; sudo mkdir aaaa#系统已经为新的子cgroup生成了默认文件dev@ubuntu:~/cgroup/test$ ls aaaacgroup.clone_children  cgroup.procs  notify_on_release  tasks#新创建的子cgroup中没有任何进程dev@ubuntu:~/cgroup/test$ wc -l aaaa/cgroup.procs0 aaaa/cgroup.procs#重新挂载这棵树到test1，由于mount的时候指定的name=test，所以和上面挂载的是同一颗cgroup树，于是test1目录下的内容和test目录下的内容一样dev@ubuntu:~/cgroup/test$ cd .. &amp;&amp; mkdir test1dev@ubuntu:~/cgroup$ sudo mount -t cgroup -o none,name=test test ./test1dev@ubuntu:~/cgroup$ ls ./test1aaaa  cgroup.clone_children  cgroup.procs  cgroup.sane_behavior  notify_on_release  release_agent  tasks#清理dev@ubuntu:~/cgroup$ sudo umount ./test1dev@ubuntu:~/cgroup$ sudo umount ./testdev@ubuntu:~/cgroup$ cd .. &amp;&amp; rm -r ./cgroup</code></pre></li></ul><h2 id="如何查看当前进程属于哪些cgroup"><a class="header-anchor" href="#如何查看当前进程属于哪些cgroup">¶</a>如何查看当前进程属于哪些cgroup</h2><p>可以通过查看/proc/[pid]/cgroup(since Linux 2.6.24)知道指定进程属于哪些cgroup。</p><pre><code>dev@ubuntu:~$ cat /proc/777/cgroup11:cpuset:/10:freezer:/9:memory:/system.slice/cron.service8:blkio:/system.slice/cron.service7:perf_event:/6:net_cls,net_prio:/5:devices:/system.slice/cron.service4:hugetlb:/3:cpu,cpuacct:/system.slice/cron.service2:pids:/system.slice/cron.service1:name=systemd:/system.slice/cron.service</code></pre><p>每一行包含用冒号隔开的三列，他们的意思分别是</p><ol><li>cgroup树的ID， 和/proc/cgroups文件中的ID一一对应。</li><li>和cgroup树绑定的所有subsystem，多个subsystem之间用逗号隔开。这里name=systemd表示没有和任何subsystem绑定，只是给他起了个名字叫systemd。</li><li>进程在cgroup树中的路径，即进程所属的cgroup，这个路径是相对于挂载点的相对路径。</li></ol><h2 id="所有的subsystems"><a class="header-anchor" href="#所有的subsystems">¶</a>所有的subsystems</h2><p>目前Linux支持下面12种subsystem</p><ul><li><a href="https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt" target="_blank" rel="noopener">cpu</a> (since Linux 2.6.24; CONFIG_CGROUP_SCHED)<br>用来限制cgroup的CPU使用率。</li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cpuacct.txt" target="_blank" rel="noopener">cpuacct</a> (since Linux 2.6.24; CONFIG_CGROUP_CPUACCT)<br>统计cgroup的CPU的使用率。</li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cpusets.txt" target="_blank" rel="noopener">cpuset</a> (since Linux 2.6.24; CONFIG_CPUSETS)<br>绑定cgroup到指定CPUs和NUMA节点。</li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt" target="_blank" rel="noopener">memory</a> (since Linux 2.6.25; CONFIG_MEMCG)<br>统计和限制cgroup的内存的使用率，包括process memory, kernel memory, 和swap。</li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/devices.txt" target="_blank" rel="noopener">devices</a> (since Linux 2.6.26; CONFIG_CGROUP_DEVICE)<br>限制cgroup创建(mknod)和访问设备的权限。</li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/freezer-subsystem.txt" target="_blank" rel="noopener">freezer</a> (since Linux 2.6.28; CONFIG_CGROUP_FREEZER)<br>suspend和restore一个cgroup中的所有进程。</li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/net_cls.txt" target="_blank" rel="noopener">net_cls</a> (since Linux 2.6.29; CONFIG_CGROUP_NET_CLASSID)<br>将一个cgroup中进程创建的所有网络包加上一个classid标记，用于<a href="http://man7.org/linux/man-pages/man8/tc.8.html" target="_blank" rel="noopener">tc</a>和iptables。 只对发出去的网络包生效，对收到的网络包不起作用。</li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/blkio-controller.txt" target="_blank" rel="noopener">blkio</a> (since Linux 2.6.33; CONFIG_BLK_CGROUP)<br>限制cgroup访问块设备的IO速度。</li><li><a href="https://www.kernel.org/doc/Documentation/perf-record.txt" target="_blank" rel="noopener">perf_event</a> (since Linux 2.6.39; CONFIG_CGROUP_PERF)<br>对cgroup进行性能监控</li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/net_prio.txt" target="_blank" rel="noopener">net_prio</a> (since Linux 3.3; CONFIG_CGROUP_NET_PRIO)<br>针对每个网络接口设置cgroup的访问优先级。</li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/hugetlb.txt" target="_blank" rel="noopener">hugetlb</a> (since Linux 3.5; CONFIG_CGROUP_HUGETLB)<br>限制cgroup的huge pages的使用量。</li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/pids.txt" target="_blank" rel="noopener">pids</a> (since Linux 4.3; CONFIG_CGROUP_PIDS)<br>限制一个cgroup及其子孙cgroup中的总进程数。</li></ul><p>上面这些subsystem，有些需要做资源统计，有些需要做资源控制，有些即不统计也不控制。对于cgroup树来说，有些subsystem严重依赖继承关系，有些subsystem完全用不到继承关系，而有些对继承关系没有严格要求。</p><p>不同subsystem的工作方式可能差别较大，对系统性能的影响也不一样，本人不是这方面的专家，后续文章中只会从功能的角度来介绍不同的subsystem，不会涉及到他们内部的实现。</p><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>本文介绍了cgroup的一些概念，包括subsystem和hierarchy，然后介绍了怎么挂载cgroup文件系统以及12个subsystem的功能。从下一篇开始，将介绍cgroup具体的用法和不同的subsystem。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="http://man7.org/linux/man-pages/man7/cgroups.7.html" target="_blank" rel="noopener">cgroups man page</a></li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt" target="_blank" rel="noopener">CGROUPS v1</a></li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v2.txt" target="_blank" rel="noopener">CGROUPS v2</a></li><li><a href="https://lwn.net/Articles/604609/" target="_blank" rel="noopener">Control groups series by Neil Brown</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cgroup </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2、创建并管理cgroup</title>
      <link href="/2020/02/16/linux/cgroup/2-chuang-jian-bing-guan-li-cgroup/"/>
      <url>/2020/02/16/linux/cgroup/2-chuang-jian-bing-guan-li-cgroup/</url>
      
        <content type="html"><![CDATA[<p>本文将创建并挂载一颗不和任何subsystem绑定的cgroup树，用来演示怎么创建、删除子cgroup，以及如何往cgroup中添加和删除进程。</p><p>由于不和任何subsystem绑定，所以这棵树没有任何实际的功能，但这不影响我们的演示，还有一个好处就是我们不会受subsystem功能的影响，可以将精力集中在cgroup树上。</p><blockquote><p>本篇所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="挂载cgroup树"><a class="header-anchor" href="#挂载cgroup树">¶</a>挂载cgroup树</h2><p>开始使用cgroup前需要先挂载cgroup树，下面先看看如何挂载一颗cgroup树，然后再查看其根目录下生成的文件</p><pre><code>#准备需要的目录dev@ubuntu:~$ mkdir cgroup &amp;&amp; cd cgroupdev@ubuntu:~/cgroup$ mkdir demo#由于name=demo的cgroup树不存在，所以系统会创建一颗新的cgroup树，然后挂载到demo目录dev@ubuntu:~/cgroup$ sudo mount -t cgroup -o none,name=demo demo ./demo#挂载点所在目录就是这颗cgroup树的root cgroup，在root cgroup下面，系统生成了一些默认文件dev@ubuntu:~/cgroup$ ls ./demo/cgroup.clone_children  cgroup.procs  cgroup.sane_behavior  notify_on_release  release_agent  tasks#cgroup.procs里包含系统中的所有进程dev@ubuntu:~/cgroup$ wc -l ./demo/cgroup.procs131 ./demo/cgroup.procs</code></pre><p>下面是每个文件的含义：</p><ul><li>cgroup.clone_children<br>这个文件只对cpuset（subsystem）有影响，当该文件的内容为1时，新创建的cgroup将会继承父cgroup的配置，即从父cgroup里面拷贝配置文件来初始化新cgroup，可以参考<a href="https://lkml.org/lkml/2010/7/29/368" target="_blank" rel="noopener">这里</a></li><li>cgroup.procs<br>当前cgroup中的所有进程ID，系统不保证ID是顺序排列的，且ID有可能重复</li><li>cgroup.sane_behavior<br>具体功能不详，可以参考<a href="https://lkml.org/lkml/2014/7/2/684" target="_blank" rel="noopener">这里</a>和<a href="https://lkml.org/lkml/2014/7/2/686" target="_blank" rel="noopener">这里</a></li><li>notify_on_release<br>该文件的内容为1时，当cgroup退出时（不再包含任何进程和子cgroup），将调用release_agent里面配置的命令。新cgroup被创建时将默认继承父cgroup的这项配置。</li><li>release_agent<br>里面包含了cgroup退出时将会执行的命令，系统调用该命令时会将相应cgroup的相对路径当作参数传进去。 注意：这个文件只会存在于root cgroup下面，其他cgroup里面不会有这个文件。</li><li>tasks<br>当前cgroup中的所有线程ID，系统不保证ID是顺序排列的</li></ul><p>后面在介绍如何往cgroup中添加进程时会介绍cgroup.procs和tasks的差别。</p><h2 id="创建和删除cgroup"><a class="header-anchor" href="#创建和删除cgroup">¶</a>创建和删除cgroup</h2><p>挂载好上面的cgroup树之后，就可以在里面建子cgroup了</p><pre><code>#创建子cgroup很简单，新建一个目录就可以了dev@ubuntu:~/cgroup$ cd demodev@ubuntu:~/cgroup/demo$ sudo mkdir cgroup1#在新创建的cgroup里面，系统默认也生成了一些文件，这些文件的意义和root cgroup里面的一样dev@ubuntu:~/cgroup/demo$ ls cgroup1/cgroup.clone_children  cgroup.procs  notify_on_release  tasks#新创建的cgroup里没有任何进程和线程dev@ubuntu:~/cgroup/demo$ wc -l cgroup1/cgroup.procs0 cgroup1/cgroup.procsdev@ubuntu:~/cgroup/demo$ wc -l cgroup1/tasks0 cgroup1/tasks#每个cgroup都可以创建自己的子cgroup，所以我们也可以在cgroup1里面创建子cgroupdev@ubuntu:~/cgroup/demo$ sudo mkdir cgroup1/cgroup11dev@ubuntu:~/cgroup/demo$ ls cgroup1/cgroup11cgroup.clone_children  cgroup.procs  notify_on_release  tasks#删除cgroup也很简单，删除掉相应的目录就可以了dev@ubuntu:~/cgroup/demo$ sudo rmdir cgroup1/rmdir: failed to remove 'cgroup1/': Device or resource busy#这里删除cgroup1失败，是因为它里面包含了子cgroup，所以不能删除，#如果cgroup1包含有进程或者线程，也会删除失败#先删除cgroup11，再删除cgroup1就可以了dev@ubuntu:~/cgroup/demo$ sudo rmdir cgroup1/cgroup11/dev@ubuntu:~/cgroup/demo$ sudo rmdir cgroup1/</code></pre><h2 id="添加进程"><a class="header-anchor" href="#添加进程">¶</a>添加进程</h2><p>创建新的cgroup后，就可以往里面添加进程了。注意下面几点：</p><ul><li>在一颗cgroup树里面，一个进程必须要属于一个cgroup。</li><li>新创建的子进程将会自动加入父进程所在的cgroup。</li><li>从一个cgroup移动一个进程到另一个cgroup时，只要有目的cgroup的写入权限就可以了，系统不会检查源cgroup里的权限。</li><li>用户只能操作属于自己的进程，不能操作其他用户的进程，root账号除外。</li></ul><pre><code>#--------------------------第一个shell窗口----------------------#创建一个新的cgroupdev@ubuntu:~/cgroup/demo$ sudo mkdir testdev@ubuntu:~/cgroup/demo$ cd test#将当前bash加入到上面新创建的cgroup中dev@ubuntu:~/cgroup/demo/test$ echo $$1421dev@ubuntu:~/cgroup/demo/test$ sudo sh -c 'echo 1421 &gt; cgroup.procs'#注意：一次只能往这个文件中写一个进程ID，如果需要写多个的话，需要多次调用这个命令#--------------------------第二个shell窗口----------------------#重新打开一个shell窗口，避免第一个shell里面运行的命令影响输出结果#这时可以看到cgroup.procs里面包含了上面的第一个shell进程dev@ubuntu:~/cgroup/demo/test$ cat cgroup.procs1421#--------------------------第一个shell窗口----------------------#回到第一个窗口，运行top命令dev@ubuntu:~/cgroup/demo/test$ top#这里省略输出内容#--------------------------第二个shell窗口----------------------#这时再在第二个窗口查看，发现top进程自动和它的父进程（1421）属于同一个cgroupdev@ubuntu:~/cgroup/demo/test$ cat cgroup.procs142116515dev@ubuntu:~/cgroup/demo/test$ ps -ef|grep topdev      16515  1421  0 04:02 pts/0    00:00:00 topdev@ubuntu:~/cgroup/demo/test$#在一颗cgroup树里面，一个进程必须要属于一个cgroup，#所以我们不能凭空从一个cgroup里面删除一个进程，只能将一个进程从一个cgroup移到另一个cgroup，#这里我们将1421移动到root cgroupdev@ubuntu:~/cgroup/demo/test$ sudo sh -c 'echo 1421 &gt; ../cgroup.procs'dev@ubuntu:~/cgroup/demo/test$ cat cgroup.procs16515#移动1421到另一个cgroup之后，它的子进程不会随着移动#--------------------------第一个shell窗口----------------------##回到第一个shell窗口，进行清理工作#先用ctrl+c退出top命令dev@ubuntu:~/cgroup/demo/test$ cd ..#然后删除创建的cgroupdev@ubuntu:~/cgroup/demo$ sudo rmdir test</code></pre><h2 id="权限"><a class="header-anchor" href="#权限">¶</a>权限</h2><p>上面我们都是用sudo(root账号)来操作的，但实际上普通账号也可以操作cgroup</p><pre><code>#创建一个新的cgroup，并修改他的ownerdev@ubuntu:~/cgroup/demo$ sudo mkdir permissiondev@ubuntu:~/cgroup/demo$ sudo chown -R dev:dev ./permission/#1421原来属于root cgroup，虽然dev没有root cgroup的权限，但还是可以将1421移动到新的cgroup下，#说明在移动进程的时候，系统不会检查源cgroup里的权限。dev@ubuntu:~/cgroup/demo$ echo 1421 &gt; ./permission/cgroup.procs#由于dev没有root cgroup的权限，再把1421移回root cgroup失败dev@ubuntu:~/cgroup/demo$ echo 1421 &gt; ./cgroup.procs-bash: ./cgroup.procs: Permission denied#找一个root账号的进程dev@ubuntu:~/cgroup/demo$ ps -ef|grep /lib/systemd/systemd-logindroot       839     1  0 01:52 ?        00:00:00 /lib/systemd/systemd-logind#因为该进程属于root，dev没有操作它的权限，所以将该进程加入到permission中失败dev@ubuntu:~/cgroup/demo$ echo 839 &gt;./permission/cgroup.procs-bash: echo: write error: Permission denied#只能由root账号添加dev@ubuntu:~/cgroup/demo$ sudo sh -c 'echo 839 &gt;./permission/cgroup.procs'#dev还可以在permission下创建子cgroupdev@ubuntu:~/cgroup/demo$ mkdir permission/c1dev@ubuntu:~/cgroup/demo$ ls permission/c1cgroup.clone_children  cgroup.procs  notify_on_release  tasks#清理dev@ubuntu:~/cgroup/demo$ sudo sh -c 'echo 839 &gt;./cgroup.procs'dev@ubuntu:~/cgroup/demo$ sudo sh -c 'echo 1421 &gt;./cgroup.procs'dev@ubuntu:~/cgroup/demo$ rmdir permission/c1dev@ubuntu:~/cgroup/demo$ sudo rmdir permission</code></pre><h2 id="cgroup-procs-vs-tasks"><a class="header-anchor" href="#cgroup-procs-vs-tasks">¶</a>cgroup.procs vs tasks</h2><p>上面提到cgroup.procs包含的是进程ID， 而tasks里面包含的是线程ID，那么他们有什么区别呢？</p><pre><code>#创建两个新的cgroup用于演示dev@ubuntu:~/cgroup/demo$ sudo mkdir c1 c2#为了便于操作，先给root账号设置一个密码，然后切换到root账号dev@ubuntu:~/cgroup/demo$ sudo passwd rootdev@ubuntu:~/cgroup/demo$ su rootroot@ubuntu:/home/dev/cgroup/demo##系统中找一个有多个线程的进程root@ubuntu:/home/dev/cgroup/demo# ps -efL|grep /lib/systemd/systemd-timesyncdsystemd+   610     1   610  0    2 01:52 ?        00:00:00 /lib/systemd/systemd-timesyncdsystemd+   610     1   616  0    2 01:52 ?        00:00:00 /lib/systemd/systemd-timesyncd#进程610有两个线程，分别是610和616#将616加入c1/cgroup.procsroot@ubuntu:/home/dev/cgroup/demo# echo 616 &gt; c1/cgroup.procs#由于cgroup.procs存放的是进程ID，所以这里看到的是616所属的进程ID（610）root@ubuntu:/home/dev/cgroup/demo# cat c1/cgroup.procs610#从tasks中的内容可以看出，虽然只往cgroup.procs中加了线程616，#但系统已经将这个线程所属的进程的所有线程都加入到了tasks中，#说明现在整个进程的所有线程已经处于c1中了root@ubuntu:/home/dev/cgroup/demo# cat c1/tasks610616#将616加入c2/tasks中root@ubuntu:/home/dev/cgroup/demo# echo 616 &gt; c2/tasks#这时我们看到虽然在c1/cgroup.procs和c2/cgroup.procs里面都有610，#但c1/tasks和c2/tasks中包含了不同的线程，说明这个进程的两个线程分别属于不同的cgrouproot@ubuntu:/home/dev/cgroup/demo# cat c1/cgroup.procs610root@ubuntu:/home/dev/cgroup/demo# cat c1/tasks610root@ubuntu:/home/dev/cgroup/demo# cat c2/cgroup.procs610root@ubuntu:/home/dev/cgroup/demo# cat c2/tasks616#通过tasks，我们可以实现线程级别的管理，但通常情况下不会这么用，#并且在cgroup V2以后，将不再支持该功能，只能以进程为单位来配置cgroup#清理root@ubuntu:/home/dev/cgroup/demo# echo 610 &gt; ./cgroup.procsroot@ubuntu:/home/dev/cgroup/demo# rmdir c1root@ubuntu:/home/dev/cgroup/demo# rmdir c2root@ubuntu:/home/dev/cgroup/demo# exitexit</code></pre><h2 id="release-agent"><a class="header-anchor" href="#release-agent">¶</a>release_agent</h2><p>当一个cgroup里没有进程也没有子cgroup时，release_agent将被调用来执行cgroup的清理工作。</p><pre><code>#创建新的cgroup用于演示dev@ubuntu:~/cgroup/demo$ sudo mkdir test#先enable release_agentdev@ubuntu:~/cgroup/demo$ sudo sh -c 'echo 1 &gt; ./test/notify_on_release'#然后创建一个脚本/home/dev/cgroup/release_demo.sh，#一般情况下都会利用这个脚本执行一些cgroup的清理工作，但我们这里为了演示简单，仅仅只写了一条日志到指定文件dev@ubuntu:~/cgroup/demo$ cat &gt; /home/dev/cgroup/release_demo.sh &lt;&lt; EOF#!/bin/bashecho \$0:\$1 &gt;&gt; /home/dev/release_demo.logEOF#添加可执行权限dev@ubuntu:~/cgroup/demo$ chmod +x ../release_demo.sh#将该脚本设置进文件release_agentdev@ubuntu:~/cgroup/demo$ sudo sh -c 'echo /home/dev/cgroup/release_demo.sh &gt; ./release_agent'dev@ubuntu:~/cgroup/demo$ cat release_agent/home/dev/cgroup/release_demo.sh#往test里面添加一个进程，然后再移除，这样就会触发release_demo.shdev@ubuntu:~/cgroup/demo$ echo $$27597dev@ubuntu:~/cgroup/demo$ sudo sh -c 'echo 27597 &gt; ./test/cgroup.procs'dev@ubuntu:~/cgroup/demo$ sudo sh -c 'echo 27597 &gt; ./cgroup.procs'#从日志可以看出，release_agent被触发了，/test是cgroup的相对路径dev@ubuntu:~/cgroup/demo$ cat /home/dev/release_demo.log/home/dev/cgroup/release_demo.sh:/test</code></pre><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>本文介绍了如何操作cgroup，由于没有和任何subsystem关联，所以在这颗树上的所有操作都没有实际的功能，不会对系统有影响。从下一篇开始，将介绍具体的subsystem。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt" target="_blank" rel="noopener">CGROUPS v1</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cgroup </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3、限制cgroup的进程数（subsystem之pids）</title>
      <link href="/2020/02/16/linux/cgroup/3-xian-zhi-cgroup-de-jin-cheng-shu-subsystem-zhi-pids/"/>
      <url>/2020/02/16/linux/cgroup/3-xian-zhi-cgroup-de-jin-cheng-shu-subsystem-zhi-pids/</url>
      
        <content type="html"><![CDATA[<p><a href="https://segmentfault.com/a/1190000007241437" target="_blank" rel="noopener">上一篇文章</a>中介绍了如何管理cgroup，从这篇开始将介绍具体的subsystem。</p><p>本篇将介绍一个简单的subsystem，名字叫<a href="https://www.kernel.org/doc/Documentation/cgroup-v1/pids.txt" target="_blank" rel="noopener">pids</a>，功能是限制cgroup及其所有子孙cgroup里面能创建的总的task数量。</p><blockquote><p>注意：这里的task指通过fork和clone函数创建的进程，由于clone函数也能创建线程（在Linux里面，线程是一种特殊的进程），所以这里的task也包含线程，本文统一以进程来代表task，即本文中的进程代表了进程和线程</p><p>本篇所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="创建子cgroup"><a class="header-anchor" href="#创建子cgroup">¶</a>创建子cgroup</h2><p>在ubuntu 16.04里面，systemd已经帮我们将各个subsystem和cgroup树绑定并挂载好了，我们直接用现成的就可以了。</p><pre><code>#从这里的输出可以看到，pids已经被挂载在了/sys/fs/cgroup/pids，这是systemd做的dev@dev:~$ mount|grep pidscgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)</code></pre><p>创建子cgroup，取名为test</p><pre><code>#进入目录/sys/fs/cgroup/pids/并新建一个目录，即创建了一个子cgroupdev@dev:~$ cd /sys/fs/cgroup/pids/dev@dev:/sys/fs/cgroup/pids$ sudo mkdir test#这里将test目录的owner设置成dev账号，这样后续操作就不用每次都敲sudo了，省去麻烦dev@dev:/sys/fs/cgroup/pids$ sudo chown -R dev:dev ./test/</code></pre><p>再来看看test目录下的文件</p><pre><code>#除了上一篇中介绍的那些文件外，多了两个文件dev@dev:/sys/fs/cgroup/pids$ cd testdev@dev:/sys/fs/cgroup/pids/test$ lscgroup.clone_children  cgroup.procs  notify_on_release  pids.current  pids.max  tasks</code></pre><p>下面是这两个文件的含义：</p><ul><li><p>pids.current: 表示当前cgroup及其所有子孙cgroup中现有的总的进程数量</p><pre><code>#由于这是个新创建的cgroup，所以里面还没有任何进程dev@dev:/sys/fs/cgroup/pids/test$ cat pids.current 0</code></pre></li><li><p>pids.max: 当前cgroup及其所有子孙cgroup中所允许创建的总的最大进程数量，在根cgroup下没有这个文件，原因显而易见，因为我们没有必要限制整个系统所能创建的进程数量。</p><pre><code>#max表示没做任何限制dev@dev:/sys/fs/cgroup/pids/test$ cat pids.max max</code></pre></li></ul><h2 id="限制进程数"><a class="header-anchor" href="#限制进程数">¶</a>限制进程数</h2><p>这里我们演示一下如何让限制功能生效</p><pre><code>#--------------------------第一个shell窗口----------------------#将pids.max设置为1，即当前cgroup只允许有一个进程dev@dev:/sys/fs/cgroup/pids/test$ echo 1 &gt; pids.max#将当前bash进程加入到该cgroupdev@dev:/sys/fs/cgroup/pids/test$ echo $$ &gt; cgroup.procs#--------------------------第二个shell窗口----------------------#重新打开一个bash窗口，在里面看看cgroup “test”里面的一些数据#因为这是一个新开的bash，跟cgroup ”test“没有任何关系，所以在这里运行命令不会影响cgroup “test”dev@dev:~$ cd /sys/fs/cgroup/pids/test#设置的最大进程数是1dev@dev:/sys/fs/cgroup/pids/test$ cat pids.max1#目前test里面已经有了一个进程，说明不能在fork或者clone进程了dev@dev:/sys/fs/cgroup/pids/test$ cat pids.current1#这个进程就是第一个窗口的bashdev@dev:/sys/fs/cgroup/pids/test$ cat cgroup.procs3083#--------------------------第一个shell窗口----------------------#回到第一个窗口，随便运行一个命令，由于当前pids.current已经等于pids.max了，#所以创建新进程失败，于是命令运行失败，说明限制生效dev@dev:/sys/fs/cgroup/pids/test$ ls-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: Resource temporarily unavailable</code></pre><h2 id="当前cgroup和子cgroup之间的关系"><a class="header-anchor" href="#当前cgroup和子cgroup之间的关系">¶</a>当前cgroup和子cgroup之间的关系</h2><p>当前cgroup中的pids.current和pids.max代表了当前cgroup及所有子孙cgroup的所有进程，所以子孙cgroup中的pids.max大小不能超过父cgroup中的大小，如果子cgroup中的pids.max设置的大于父cgroup里的大小，会怎么样？请看下面的演示</p><pre><code>#继续使用上面的两个窗口#--------------------------第二个shell窗口----------------------#将pids.max设置成2dev@dev:/sys/fs/cgroup/pids/test$ echo 2 &gt; pids.max#在test下面创建一个子cgroupdev@dev:/sys/fs/cgroup/pids/test$ mkdir subtestdev@dev:/sys/fs/cgroup/pids/test$ cd subtest/#将subtest的pids.max设置为5dev@dev:/sys/fs/cgroup/pids/test/subtest$ echo 5 &gt; pids.max#将当前bash进程加入到subtest中dev@dev:/sys/fs/cgroup/pids/test/subtest$ echo $$ &gt; cgroup.procs#--------------------------第三个shell窗口----------------------#重新打开一个bash窗口，看一下test和subtest里面的数据#test里面的数据如下：dev@dev:~$ cd /sys/fs/cgroup/pids/testdev@dev:/sys/fs/cgroup/pids/test$ cat pids.max2#这里为2表示目前test和subtest里面总的进程数为2dev@dev:/sys/fs/cgroup/pids/test$ cat pids.current2dev@dev:/sys/fs/cgroup/pids/test$ cat cgroup.procs3083#subtest里面的数据如下：dev@dev:/sys/fs/cgroup/pids/test$ cat subtest/pids.max5dev@dev:/sys/fs/cgroup/pids/test$ cat subtest/pids.current1dev@dev:/sys/fs/cgroup/pids/test$ cat subtest/cgroup.procs3185#--------------------------第一个shell窗口----------------------#回到第一个窗口，随便运行一个命令，由于test里面的pids.current已经等于pids.max了，#所以创建新进程失败，于是命令运行失败，说明限制生效dev@dev:/sys/fs/cgroup/pids/test$ ls-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: Resource temporarily unavailable#--------------------------第二个shell窗口----------------------#回到第二个窗口，随便运行一个命令，虽然subtest里面的pids.max还大于pids.current，#但由于其父cgroup “test”里面的pids.current已经等于pids.max了，#所以创建新进程失败，于是命令运行失败，说明子cgroup中的进程数不仅受自己的pids.max的限制，#还受祖先cgroup的限制dev@dev:/sys/fs/cgroup/pids/test/subtest$ ls-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: Resource temporarily unavailable</code></pre><h2 id="pids-current-pids-max的情况"><a class="header-anchor" href="#pids-current-pids-max的情况">¶</a>pids.current &gt; pids.max的情况</h2><p>并不是所有情况下都是pids.max &gt;= pids.current，在下面两种情况下，会出现pids.max &lt; pids.current 的情况：</p><ul><li><p>设置pids.max时，将其值设置的比pids.current小</p><pre><code>#继续使用上面的三个窗口#--------------------------第三个shell窗口----------------------#将test的pids.max设置为1dev@dev:/sys/fs/cgroup/pids/test$ echo 1 &gt; pids.maxdev@dev:/sys/fs/cgroup/pids/test$ cat pids.max1#这个时候就会出现pids.current &gt; pids.max的情况dev@dev:/sys/fs/cgroup/pids/test$ cat pids.current2#--------------------------第一个shell窗口----------------------#回到第一个shell#还是运行失败，说明虽然pids.current &gt; pids.max，但限制创建新进程的功能还是会生效dev@dev:/sys/fs/cgroup/pids/test$ ls-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: Resource temporarily unavailable</code></pre></li><li><p>pids.max只会在当前cgroup中的进程fork、clone的时候生效，将其他进程加入到当前cgroup时，不会检测pids.max，所以将其他进程加入到当前cgroup有可能会导致pids.current &gt; pids.max</p><pre><code>#继续使用上面的三个窗口#--------------------------第三个shell窗口----------------------#将subtest中的进程移动到根cgroup下，然后删除subtestdev@dev:/sys/fs/cgroup/pids/test$ sudo sh -c 'echo 3185 &gt; /sys/fs/cgroup/pids/cgroup.procs'#里面没有进程了，说明移动成功dev@dev:/sys/fs/cgroup/pids/test$ cat subtest/cgroup.procs#移除成功dev@dev:/sys/fs/cgroup/pids/test$ rmdir subtest/#这时候test下的pids.max等于pids.current了dev@dev:/sys/fs/cgroup/pids/test$ cat pids.max1dev@dev:/sys/fs/cgroup/pids/test$ cat pids.current1#--------------------------第二个shell窗口----------------------#将当前bash加入到test中dev@dev:/sys/fs/cgroup/pids/test/subtest$ cd ..dev@dev:/sys/fs/cgroup/pids/test$ echo $$ &gt; cgroup.procs#--------------------------第三个shell窗口----------------------#回到第三个窗口，查看相关信息#第一个和第二个窗口的bash都属于testdev@dev:/sys/fs/cgroup/pids/test$ cat cgroup.procs30833185dev@dev:/sys/fs/cgroup/pids/test$ cat pids.max1#出现了pids.current &gt; pids.max的情况，这是因为我们将第二个窗口的shell加入了testdev@dev:/sys/fs/cgroup/pids/test$ cat pids.current2#--------------------------第二个shell窗口----------------------#对fork调用的限制仍然生效dev@dev:/sys/fs/cgroup/pids/test$ ls-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: retry: No child processes-bash: fork: Resource temporarily unavailable</code></pre></li></ul><p>清理</p><pre><code>#--------------------------第三个shell窗口----------------------dev@dev:/sys/fs/cgroup/pids/test$ sudo sh -c 'echo 3185 &gt; /sys/fs/cgroup/pids/cgroup.procs'dev@dev:/sys/fs/cgroup/pids/test$ sudo sh -c 'echo 3083 &gt; /sys/fs/cgroup/pids/cgroup.procs'dev@dev:/sys/fs/cgroup/pids/test$ cd ..dev@dev:/sys/fs/cgroup/pids$ sudo rmdir test/</code></pre><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>本文介绍了如何利用pids这个subsystem来限制cgroup中的进程数，以及一些要注意的地方，总的来说pids比较简单。下一篇将介绍稍微复杂点的内存控制。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/pids.txt" target="_blank" rel="noopener">Process Number Controller</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cgroup </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5、限制cgroup的CPU使用（subsystem之cpu）</title>
      <link href="/2020/02/16/linux/cgroup/5-xian-zhi-cgroup-de-cpu-shi-yong-subsystem-zhi-cpu/"/>
      <url>/2020/02/16/linux/cgroup/5-xian-zhi-cgroup-de-cpu-shi-yong-subsystem-zhi-cpu/</url>
      
        <content type="html"><![CDATA[<p>在cgroup里面，跟CPU相关的子系统有<a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cpusets.txt" target="_blank" rel="noopener">cpusets</a>、<a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cpuacct.txt" target="_blank" rel="noopener">cpuacct</a>和<a href="https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt" target="_blank" rel="noopener">cpu</a>。</p><p>其中cpuset主要用于设置CPU的亲和性，可以限制cgroup中的进程只能在指定的CPU上运行，或者不能在指定的CPU上运行，同时cpuset还能设置内存的亲和性。设置亲和性一般只在比较特殊的情况才用得着，所以这里不做介绍。</p><p>cpuacct包含当前cgroup所使用的CPU的统计信息，信息量较少，有兴趣可以去看看它的文档，这里不做介绍。</p><p>本篇只介绍cpu子系统，包括怎么限制cgroup的CPU使用上限及相对于其它cgroup的相对值。</p><blockquote><p>本篇所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="创建子cgroup"><a class="header-anchor" href="#创建子cgroup">¶</a>创建子cgroup</h2><p>在ubuntu下，systemd已经帮我们mount好了cpu子系统，我们只需要在相应的目录下创建子目录就可以了</p><pre><code>#从这里的输出可以看到，cpuset被挂载在了/sys/fs/cgroup/cpuset，#而cpu和cpuacct一起挂载到了/sys/fs/cgroup/cpu,cpuacct下面dev@ubuntu:~$ mount|grep cpucgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)#进入/sys/fs/cgroup/cpu,cpuacct并创建子cgroupdev@ubuntu:~$ cd /sys/fs/cgroup/cpu,cpuacctdev@ubuntu:/sys/fs/cgroup/cpu,cpuacct$ sudo mkdir testdev@ubuntu:/sys/fs/cgroup/cpu,cpuacct$ cd testdev@ubuntu:/sys/fs/cgroup/cpu,cpuacct/test$ lscgroup.clone_children  cpuacct.stat   cpuacct.usage_percpu  cpu.cfs_quota_us  cpu.stat           taskscgroup.procs           cpuacct.usage  cpu.cfs_period_us     cpu.shares        notify_on_release</code></pre><p>除了cgroup里面通用的cgroup.clone_children、tasks、cgroup.procs、notify_on_release这几个文件外，以cpuacct.开头的文件跟cpuacct子系统有关，我们这里只需要关注cpu.开头的文件。</p><h4 id="cpu-cfs-period-us-cpu-cfs-quota-us"><a class="header-anchor" href="#cpu-cfs-period-us-cpu-cfs-quota-us">¶</a>cpu.cfs_period_us &amp; cpu.cfs_quota_us</h4><p>cfs_period_us用来配置时间周期长度，cfs_quota_us用来配置当前cgroup在设置的周期长度内所能使用的CPU时间数，两个文件配合起来设置CPU的使用上限。两个文件的单位都是微秒（us），cfs_period_us的取值范围为1毫秒（ms）到1秒（s），cfs_quota_us的取值大于1ms即可，如果cfs_quota_us的值为-1（默认值），表示不受cpu时间的限制。下面是几个例子：</p><pre><code>1.限制只能使用1个CPU（每250ms能使用250ms的CPU时间）    # echo 250000 &gt; cpu.cfs_quota_us /* quota = 250ms */    # echo 250000 &gt; cpu.cfs_period_us /* period = 250ms */2.限制使用2个CPU（内核）（每500ms能使用1000ms的CPU时间，即使用两个内核）    # echo 1000000 &gt; cpu.cfs_quota_us /* quota = 1000ms */    # echo 500000 &gt; cpu.cfs_period_us /* period = 500ms */3.限制使用1个CPU的20%（每50ms能使用10ms的CPU时间，即使用一个CPU核心的20%）    # echo 10000 &gt; cpu.cfs_quota_us /* quota = 10ms */    # echo 50000 &gt; cpu.cfs_period_us /* period = 50ms */</code></pre><h4 id="cpu-shares"><a class="header-anchor" href="#cpu-shares">¶</a>cpu.shares</h4><p>shares用来设置CPU的相对值，并且是针对所有的CPU（内核），默认值是1024，假如系统中有两个cgroup，分别是A和B，A的shares值是1024，B的shares值是512，那么A将获得1024/(1204+512)=66%的CPU资源，而B将获得33%的CPU资源。shares有两个特点：</p><ul><li>如果A不忙，没有使用到66%的CPU时间，那么剩余的CPU时间将会被系统分配给B，即B的CPU使用率可以超过33%</li><li>如果添加了一个新的cgroup C，且它的shares值是1024，那么A的限额变成了1024/(1204+512+1024)=40%，B的变成了20%</li></ul><p>从上面两个特点可以看出：</p><ul><li>在闲的时候，shares基本上不起作用，只有在CPU忙的时候起作用，这是一个优点。</li><li>由于shares是一个绝对值，需要和其它cgroup的值进行比较才能得到自己的相对限额，而在一个部署很多容器的机器上，cgroup的数量是变化的，所以这个限额也是变化的，自己设置了一个高的值，但别人可能设置了一个更高的值，所以这个功能没法精确的控制CPU使用率。</li></ul><h4 id="cpu-stat"><a class="header-anchor" href="#cpu-stat">¶</a>cpu.stat</h4><p>包含了下面三项统计结果</p><ul><li>nr_periods： 表示过去了多少个cpu.cfs_period_us里面配置的时间周期</li><li>nr_throttled： 在上面的这些周期中，有多少次是受到了限制（即cgroup中的进程在指定的时间周期中用光了它的配额）</li><li>throttled_time: cgroup中的进程被限制使用CPU持续了多长时间(纳秒)</li></ul><h2 id="示例"><a class="header-anchor" href="#示例">¶</a>示例</h2><p>这里以cfs_period_us &amp; cfs_quota_us为例，演示一下如何控制CPU的使用率。</p><pre><code>#继续使用上面创建的子cgroup： test#设置只能使用1个cpu的20%的时间dev@ubuntu:/sys/fs/cgroup/cpu,cpuacct/test$ sudo sh -c &quot;echo 50000 &gt; cpu.cfs_period_us&quot;dev@ubuntu:/sys/fs/cgroup/cpu,cpuacct/test$ sudo sh -c &quot;echo 10000 &gt; cpu.cfs_quota_us&quot;#将当前bash加入到该cgroupdev@ubuntu:/sys/fs/cgroup/cpu,cpuacct/test$ echo $$5456dev@ubuntu:/sys/fs/cgroup/cpu,cpuacct/test$ sudo sh -c &quot;echo 5456 &gt; cgroup.procs&quot;#在bash中启动一个死循环来消耗cpu，正常情况下应该使用100%的cpu（即消耗一个内核）dev@ubuntu:/sys/fs/cgroup/cpu,cpuacct/test$ while :; do echo test &gt; /dev/null; done#--------------------------重新打开一个shell窗口----------------------#通过top命令可以看到5456的CPU使用率为20%左右，说明被限制住了#不过这时系统的%us+%sy在10%左右，那是因为我测试的机器上cpu是双核的，#所以系统整体的cpu使用率为10%左右dev@ubuntu:~$ topTasks: 139 total,   2 running, 137 sleeping,   0 stopped,   0 zombie%Cpu(s):  5.6 us,  6.2 sy,  0.0 ni, 88.2 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem :   499984 total,    15472 free,    81488 used,   403024 buff/cacheKiB Swap:        0 total,        0 free,        0 used.   383332 avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND 5456 dev       20   0   22640   5472   3524 R  20.3  1.1   0:04.62 bash#这时可以看到被限制的统计结果dev@ubuntu:~$ cat /sys/fs/cgroup/cpu,cpuacct/test/cpu.statnr_periods 1436nr_throttled 1304throttled_time 51542291833</code></pre><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>使用cgroup限制CPU的使用率比较纠结，用cfs_period_us &amp; cfs_quota_us吧，限制死了，没法充分利用空闲的CPU，用shares吧，又没法配置百分比，极其难控制。总之，使用cgroup的cpu子系统需谨慎。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><p><a href="https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt" target="_blank" rel="noopener">CFS Bandwidth Control</a></p></li><li><p><a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/sec-cpu.html" target="_blank" rel="noopener">cpu</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cgroup </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1、namespace概述</title>
      <link href="/2020/02/16/linux/namespace/1-namespace-gai-shu/"/>
      <url>/2020/02/16/linux/namespace/1-namespace-gai-shu/</url>
      
        <content type="html"><![CDATA[<p>Namespace是对全局系统资源的一种封装隔离，使得处于不同namespace的进程拥有独立的全局系统资源，改变一个namespace中的系统资源只会影响当前namespace里的进程，对其他namespace中的进程没有影响。</p><blockquote><p>下面的所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="Linux内核支持的namespaces"><a class="header-anchor" href="#Linux内核支持的namespaces">¶</a>Linux内核支持的namespaces</h2><p>目前，Linux内核里面实现了7种不同类型的namespace。</p><pre><code>名称        宏定义             隔离内容Cgroup      CLONE_NEWCGROUP   Cgroup root directory (since Linux 4.6)IPC         CLONE_NEWIPC      System V IPC, POSIX message queues (since Linux 2.6.19)Network     CLONE_NEWNET      Network devices, stacks, ports, etc. (since Linux 2.6.24)Mount       CLONE_NEWNS       Mount points (since Linux 2.4.19)PID         CLONE_NEWPID      Process IDs (since Linux 2.6.24)User        CLONE_NEWUSER     User and group IDs (started in Linux 2.6.23 and completed in Linux 3.8)UTS         CLONE_NEWUTS      Hostname and NIS domain name (since Linux 2.6.19)</code></pre><blockquote><p><strong>注意：</strong> 由于Cgroup namespace在4.6的内核中才实现，并且和cgroup v2关系密切，现在普及程度还不高，比如docker现在就还没有用它，所以在namespace这个系列中不会介绍Cgroup namespace。</p></blockquote><h2 id="查看进程所属的namespaces"><a class="header-anchor" href="#查看进程所属的namespaces">¶</a>查看进程所属的namespaces</h2><p>系统中的每个进程都有/proc/[pid]/ns/这样一个目录，里面包含了这个进程所属namespace的信息，里面每个文件的描述符都可以用来作为setns函数(后面会介绍)的参数。</p><pre><code>#查看当前bash进程所属的namespacedev@ubuntu:~$ ls -l /proc/$$/ns     total 0lrwxrwxrwx 1 dev dev 0 7月 7 17:24 cgroup -&gt; cgroup:[4026531835] #(since Linux 4.6)lrwxrwxrwx 1 dev dev 0 7月 7 17:24 ipc -&gt; ipc:[4026531839]       #(since Linux 3.0)lrwxrwxrwx 1 dev dev 0 7月 7 17:24 mnt -&gt; mnt:[4026531840]       #(since Linux 3.8)lrwxrwxrwx 1 dev dev 0 7月 7 17:24 net -&gt; net:[4026531957]       #(since Linux 3.0)lrwxrwxrwx 1 dev dev 0 7月 7 17:24 pid -&gt; pid:[4026531836]       #(since Linux 3.8)lrwxrwxrwx 1 dev dev 0 7月 7 17:24 user -&gt; user:[4026531837]     #(since Linux 3.8)lrwxrwxrwx 1 dev dev 0 7月 7 17:24 uts -&gt; uts:[4026531838]       #(since Linux 3.0)</code></pre><ul><li>上面每种类型的namespace都是在不同的Linux版本被加入到/proc/[pid]/ns/目录里去的，比如pid namespace是在Linux 3.8才被加入到/proc/[pid]/ns/里面，但这并不是说到3.8才支持pid namespace，其实pid namespace在2.6.24的时候就已经加入到内核了，在那个时候就可以用pid namespace了，只是有了/proc/[pid]/ns/pid之后，使得操作pid namespace更方便了</li><li>虽然说cgroup是在Linux 4.6版本才被加入内核，可是在Ubuntu 16.04上，尽管内核版本才4.4，但也支持cgroup namespace，估计应该是Ubuntu将4.6的cgroup namespace这部分代码patch到了他们的4.4内核上。</li><li>以ipc:[4026531839]为例，ipc是namespace的类型，4026531839是inode number，如果两个进程的ipc namespace的inode number一样，说明他们属于同一个namespace。这条规则对其他类型的namespace也同样适用。</li><li>从上面的输出可以看出，对于每种类型的namespace，进程都会与一个namespace ID关联。</li></ul><h2 id="跟namespace相关的API"><a class="header-anchor" href="#跟namespace相关的API">¶</a>跟namespace相关的API</h2><p>和namespace相关的函数只有三个，这里简单的看一下，后面介绍<a href="https://segmentfault.com/a/1190000006908598" target="_blank" rel="noopener">UTS namespace</a>的时候会有详细的示例</p><h3 id="clone：-创建一个新的进程并把他放到新的namespace中"><a class="header-anchor" href="#clone：-创建一个新的进程并把他放到新的namespace中">¶</a><a href="http://man7.org/linux/man-pages/man2/clone.2.html" target="_blank" rel="noopener">clone</a>： 创建一个新的进程并把他放到新的namespace中</h3><pre><code>int clone(int (*child_func)(void *), void *child_stack            , int flags, void *arg);flags：     指定一个或者多个上面的CLONE_NEW*（当然也可以包含跟namespace无关的flags），     这样就会创建一个或多个新的不同类型的namespace，     并把新创建的子进程加入新创建的这些namespace中。</code></pre><h3 id="setns：-将当前进程加入到已有的namespace中"><a class="header-anchor" href="#setns：-将当前进程加入到已有的namespace中">¶</a><a href="http://man7.org/linux/man-pages/man2/setns.2.html" target="_blank" rel="noopener">setns</a>： 将当前进程加入到已有的namespace中</h3><pre><code>int setns(int fd, int nstype);fd：     指向/proc/[pid]/ns/目录里相应namespace对应的文件，    表示要加入哪个namespacenstype：    指定namespace的类型（上面的任意一个CLONE_NEW*）：    1. 如果当前进程不能根据fd得到它的类型，如fd由其他进程创建，    并通过UNIX domain socket传给当前进程，    那么就需要通过nstype来指定fd指向的namespace的类型    2. 如果进程能根据fd得到namespace类型，比如这个fd是由当前进程打开的，    那么nstype设置为0即可</code></pre><h3 id="unshare-使当前进程退出指定类型的namespace，并加入到新创建的namespace（相当于创建并加入新的namespace）"><a class="header-anchor" href="#unshare-使当前进程退出指定类型的namespace，并加入到新创建的namespace（相当于创建并加入新的namespace）">¶</a><a href="http://man7.org/linux/man-pages/man2/unshare.2.html" target="_blank" rel="noopener">unshare</a>: 使当前进程退出指定类型的namespace，并加入到新创建的namespace（相当于创建并加入新的namespace）</h3><pre><code>int unshare(int flags);flags：    指定一个或者多个上面的CLONE_NEW*，    这样当前进程就退出了当前指定类型的namespace并加入到新创建的namespace</code></pre><h3 id="clone和unshare的区别"><a class="header-anchor" href="#clone和unshare的区别">¶</a>clone和unshare的区别</h3><p>clone和unshare的功能都是创建并加入新的namespace， 他们的区别是：</p><ul><li>unshare是使当前进程加入新的namespace</li><li>clone是创建一个新的子进程，然后让子进程加入新的namespace，而当前进程保持不变</li></ul><h2 id="其它"><a class="header-anchor" href="#其它">¶</a>其它</h2><p>当一个namespace中的所有进程都退出时，该namespace将会被销毁。当然还有其他方法让namespace一直存在，假设我们有一个进程号为1000的进程，以ipc namespace为例：</p><ol><li>通过mount --bind命令。例如mount --bind /proc/1000/ns/ipc /other/file，就算属于这个ipc namespace的所有进程都退出了，只要/other/file还在，这个ipc namespace就一直存在，其他进程就可以利用/other/file，通过setns函数加入到这个namespace</li><li>在其他namespace的进程中打开/proc/1000/ns/ipc文件，并一直持有这个文件描述符不关闭，以后就可以用setns函数加入这个namespace。</li></ol><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="http://man7.org/linux/man-pages/man7/namespaces.7.html" target="_blank" rel="noopener">overview of Linux namespaces</a></li><li><a href="https://lwn.net/Articles/531114/" target="_blank" rel="noopener">Namespaces in operation, part 1: namespaces overview</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> namespace </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4、限制cgroup的内存使用（subsystem之memory）</title>
      <link href="/2020/02/16/linux/cgroup/4-xian-zhi-cgroup-de-nei-cun-shi-yong-subsystem-zhi-memory/"/>
      <url>/2020/02/16/linux/cgroup/4-xian-zhi-cgroup-de-nei-cun-shi-yong-subsystem-zhi-memory/</url>
      
        <content type="html"><![CDATA[<p>有了<a href="https://segmentfault.com/a/1190000007468509" target="_blank" rel="noopener">上一篇</a>关于pids的热身之后，我们这篇将介绍稍微复杂点的内存控制。</p><blockquote><p>本篇所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="为什么需要内存控制？"><a class="header-anchor" href="#为什么需要内存控制？">¶</a>为什么需要内存控制？</h2><p>代码总会有bug，有时会有内存泄漏，或者有意想不到的内存分配情况，或者这是个恶意程序，运行起来就是为了榨干系统内存，让其它进程无法分配到足够的内存而出现异常，如果系统配置了交换分区，会导致系统大量使用交换分区，从而系统运行很慢。</p><ul><li>站在一个普通Linux开发者的角度，如果能控制一个或者一组进程所能使用的内存数，那么就算代码有bug，内存泄漏也不会对系统造成影响，因为可以设置内存使用量的上限，当到达这个值之后可以将进程重启。</li><li>站在一个系统管理者的角度，如果能限制每组进程所能使用的内存量，那么不管程序的质量如何，都能将它们对系统的影响降到最低，从而保证整个系统的稳定性。</li></ul><h2 id="内存控制能控制些什么？"><a class="header-anchor" href="#内存控制能控制些什么？">¶</a>内存控制能控制些什么？</h2><ul><li>限制cgroup中所有进程所能使用的物理内存总量</li><li>限制cgroup中所有进程所能使用的物理内存+交换空间总量(CONFIG_MEMCG_SWAP)： 一般在server上，不太会用到swap空间，所以不在这里介绍这部分内容。</li><li>限制cgroup中所有进程所能使用的内核内存总量及其它一些内核资源(CONFIG_MEMCG_KMEM)： 限制内核内存有什么用呢？其实限制内核内存就是限制当前cgroup所能使用的内核资源，比如进程的内核栈空间，socket所占用的内存空间等，通过限制内核内存，当内存吃紧时，可以阻止当前cgroup继续创建进程以及向内核申请分配更多的内核资源。由于这块功能被使用的较少，本篇中也不对它做介绍。</li></ul><h2 id="内核相关的配置"><a class="header-anchor" href="#内核相关的配置">¶</a>内核相关的配置</h2><ul><li><p>由于memory subsystem比较耗资源，所以内核专门添加了一个参数cgroup_disable=memory来禁用整个memory subsystem，这个参数可以通过GRUB在启动系统的时候传给内核，加了这个参数后内核将不再进行memory subsystem相关的计算工作，在系统中也不能挂载memory subsystem。</p></li><li><p>上面提到的CONFIG_MEMCG_SWAP和CONFIG_MEMCG_KMEM都是扩展功能，在使用前请确认当前内核是否支持，下面看看ubuntu 16.04的内核：</p><pre><code>#这里CONFIG_MEMCG_SWAP和CONFIG_MEMCG_KMEM等于y表示内核已经编译了该模块，即支持相关功能dev@dev:~$ cat /boot/config-`uname -r`|grep CONFIG_MEMCGCONFIG_MEMCG=yCONFIG_MEMCG_SWAP=y# CONFIG_MEMCG_SWAP_ENABLED is not setCONFIG_MEMCG_KMEM=y</code></pre></li><li><p>CONFIG_MEMCG_SWAP控制内核是否支持Swap Extension，而<a href="http://cateee.net/lkddb/web-lkddb/MEMCG_SWAP_ENABLED.html" target="_blank" rel="noopener">CONFIG_MEMCG_SWAP_ENABLED</a>（3.6以后的内核新加的参数）控制默认情况下是否使用Swap Extension，由于Swap Extension比较耗资源，所以很多发行版（比如ubuntu）默认情况下会禁用该功能（这也是上面那行被注释掉的原因），当然用户也可以根据实际情况，通过设置内核参数swapaccount=0或者1来手动禁用和启用Swap Extension。</p></li></ul><h2 id="怎么控制？"><a class="header-anchor" href="#怎么控制？">¶</a>怎么控制？</h2><p>在ubuntu 16.04里面，systemd已经帮我们将memory绑定到了/sys/fs/cgroup/memory</p><pre><code>#如果这里发现有多行结果，说明这颗cgroup数被绑定到了多个地方，#不过不要担心，由于它们都是指向同一颗cgroup树，所以它们里面的内容是一模一样的dev@dev:~$ mount|grep memorycgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)</code></pre><h3 id="创建子cgroup"><a class="header-anchor" href="#创建子cgroup">¶</a>创建子cgroup</h3><p>在/sys/fs/cgroup/memory下创建一个子目录即创建了一个子cgroup</p><pre><code>#--------------------------第一个shell窗口----------------------dev@dev:~$ cd /sys/fs/cgroup/memorydev@dev:/sys/fs/cgroup/memory$ sudo mkdir testdev@dev:/sys/fs/cgroup/memory$ ls testcgroup.clone_children  memory.kmem.failcnt             memory.kmem.tcp.limit_in_bytes      memory.max_usage_in_bytes        memory.soft_limit_in_bytes  notify_on_releasecgroup.event_control   memory.kmem.limit_in_bytes      memory.kmem.tcp.max_usage_in_bytes  memory.move_charge_at_immigrate  memory.stat                 taskscgroup.procs           memory.kmem.max_usage_in_bytes  memory.kmem.tcp.usage_in_bytes      memory.numa_stat                 memory.swappinessmemory.failcnt         memory.kmem.slabinfo            memory.kmem.usage_in_bytes          memory.oom_control               memory.usage_in_bytesmemory.force_empty     memory.kmem.tcp.failcnt         memory.limit_in_bytes               memory.pressure_level            memory.use_hierarchy</code></pre><p>从上面ls的输出可以看出，除了每个cgroup都有的那几个文件外，和memory相关的文件还不少（由于ubuntu默认禁用了CONFIG_MEMCG_SWAP，所以这里看不到swap相关的文件），这里先做个大概介绍(kernel相关的文件除外)，后面会详细介绍每个文件的作用</p><pre><code> cgroup.event_control       #用于eventfd的接口 memory.usage_in_bytes      #显示当前已用的内存 memory.limit_in_bytes      #设置/显示当前限制的内存额度 memory.failcnt             #显示内存使用量达到限制值的次数 memory.max_usage_in_bytes  #历史内存最大使用量 memory.soft_limit_in_bytes #设置/显示当前限制的内存软额度 memory.stat                #显示当前cgroup的内存使用情况 memory.use_hierarchy       #设置/显示是否将子cgroup的内存使用情况统计到当前cgroup里面 memory.force_empty         #触发系统立即尽可能的回收当前cgroup中可以回收的内存 memory.pressure_level      #设置内存压力的通知事件，配合cgroup.event_control一起使用 memory.swappiness          #设置和显示当前的swappiness memory.move_charge_at_immigrate #设置当进程移动到其他cgroup中时，它所占用的内存是否也随着移动过去 memory.oom_control         #设置/显示oom controls相关的配置 memory.numa_stat           #显示numa相关的内存</code></pre><p>参考：<a href="http://man7.org/linux/man-pages/man2/eventfd.2.html" target="_blank" rel="noopener">eventfd</a>，<a href="https://en.wikipedia.org/wiki/Non-uniform_memory_access" target="_blank" rel="noopener">numa</a></p><h3 id="添加进程"><a class="header-anchor" href="#添加进程">¶</a>添加进程</h3><p>和<a href="https://segmentfault.com/a/1190000007241437" target="_blank" rel="noopener">“创建并管理cgroup”</a>中介绍的一样，往cgroup中添加进程只要将进程号写入cgroup.procs就可以了</p><blockquote><p>注意：本篇将以进程为单位进行操作，不考虑以线程为单位进行管理（原因见<a href="https://segmentfault.com/a/1190000007241437" target="_blank" rel="noopener">“创建并管理cgroup”</a>中cgroup.pro与tasks的区别），也即只写cgroup.procs文件，不会写tasks文件</p></blockquote><pre><code>#--------------------------第二个shell窗口----------------------#重新打开一个shell窗口，避免相互影响dev@dev:~$ cd /sys/fs/cgroup/memory/test/dev@dev:/sys/fs/cgroup/memory/test$ echo $$4589dev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo $$ &gt;&gt; cgroup.procs&quot;#运行top命令，这样这个cgroup消耗的内存会多点，便于观察dev@dev:/sys/fs/cgroup/memory/test$ top#后续操作不再在这个窗口进行，避免在这个bash中运行进程影响cgropu里面的进程数及相关统计</code></pre><h3 id="设置限额"><a class="header-anchor" href="#设置限额">¶</a>设置限额</h3><p>设置限额很简单，写文件memory.limit_in_bytes就可以了，请仔细看示例</p><pre><code>#--------------------------第一个shell窗口----------------------#回到第一个shell窗口dev@dev:/sys/fs/cgroup/memory$ cd test#这里两个进程id分别时第二个窗口的bash和top进程dev@dev:/sys/fs/cgroup/memory/test$ cat cgroup.procs45894664#开始设置之前，看看当前使用的内存数量，这里的单位是字节dev@dev:/sys/fs/cgroup/memory/test$ cat memory.usage_in_bytes835584#设置1M的限额dev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo 1M &gt; memory.limit_in_bytes&quot;#设置完之后记得要查看一下这个文件，因为内核要考虑页对齐, 所以生效的数量不一定完全等于设置的数量dev@dev:/sys/fs/cgroup/memory/test$ cat memory.limit_in_bytes1048576#如果不再需要限制这个cgroup，写-1到文件memory.limit_in_bytes即可dev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo -1 &gt; memory.limit_in_bytes&quot;#这时可以看到limit被设置成了一个很大的数字dev@dev:/sys/fs/cgroup/memory/test$ cat memory.limit_in_bytes9223372036854771712</code></pre><p>如果设置的限额比当前已经使用的内存少呢？如上面显示当前bash用了800多k，如果我设置limit为400K会怎么样？</p><pre><code>#--------------------------第一个shell窗口----------------------#先用free看下当前swap被用了多少dev@dev:/sys/fs/cgroup/memory/test$ free              total        used        free      shared  buff/cache   availableMem:         500192       45000       34200        2644      420992      424020Swap:        524284          16      524268#设置内存限额为400Kdev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo 400K &gt; memory.limit_in_bytes&quot;#再看当前cgroup的内存使用情况#发现内存占用少了很多，刚好在400K以内，原来用的那些内存都去哪了呢？dev@dev:/sys/fs/cgroup/memory/test$ cat memory.usage_in_bytes401408#再看swap空间的占用情况，和刚开始比，多了500-16=384K，说明内存中的数据被移到了swap上dev@dev:/sys/fs/cgroup/memory/test$ free              total        used        free      shared  buff/cache   availableMem:         500192       43324       35132        2644      421736      425688Swap:        524284         500      523784#这个时候再来看failcnt，发现有453次之多(隔几秒再看这个文件，发现次数在增长)dev@dev:/sys/fs/cgroup/memory/test$ cat memory.failcnt453#再看看memory.stat（这里只显示部分内容），发现物理内存用了400K，#但有很多pgmajfault以及pgpgin和pgpgout，说明发生了很多的swap in和swap outdev@dev:/sys/fs/cgroup/memory/test$ cat memory.statrss 409600total_pgpgin 4166total_pgpgout 4066total_pgfault 7558total_pgmajfault 419#从上面的结果可以看出，当物理内存不够时，就会触发memory.failcnt里面的数量加1，#但进程不会被kill掉，那是因为内核会尝试将物理内存中的数据移动到swap空间中，从而让内存分配成功</code></pre><p>如果设置的限额过小，就算swap out部分内存后还是不够会怎么样？</p><pre><code>#--------------------------第一个shell窗口----------------------dev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo 1K &gt; memory.limit_in_bytes&quot;#进程已经不在了（第二个窗口已经挂掉了）dev@dev:/sys/fs/cgroup/memory/test$ cat cgroup.procsdev@dev:/sys/fs/cgroup/memory/test$ cat memory.usage_in_bytes0#从这里的结果可以看出，第二个窗口的bash和top都被kill掉了</code></pre><p>从上面的这些测试可以看出，一旦设置了内存限制，将立即生效，并且当物理内存使用量达到limit的时候，memory.failcnt的内容会加1，但这时进程不一定就会被kill掉，内核会尽量将物理内存中的数据移到swap空间上去，如果实在是没办法移动了（设置的limit过小，或者swap空间不足），默认情况下，就会kill掉cgroup里面继续申请内存的进程。</p><h3 id="触发控制"><a class="header-anchor" href="#触发控制">¶</a>触发控制</h3><p>当物理内存达到上限后，系统的默认行为是kill掉cgroup中继续申请内存的进程，那么怎么控制这样的行为呢？答案是配置memory.oom_control</p><p>这个文件里面包含了一个控制是否为当前cgroup启动OOM-killer的标识。如果写0到这个文件，将启动OOM-killer，当内核无法给进程分配足够的内存时，将会直接kill掉该进程；如果写1到这个文件，表示不启动OOM-killer，当内核无法给进程分配足够的内存时，将会暂停该进程直到有空余的内存之后再继续运行；同时，memory.oom_control还包含一个只读的under_oom字段，用来表示当前是否已经进入oom状态，也即是否有进程被暂停了。</p><blockquote><p>注意：root cgroup的oom killer是不能被禁用的</p></blockquote><p>为了演示OOM-killer的功能，创建了下面这样一个程序，用来向系统申请内存，它会每秒消耗1M的内存。</p><pre><code>#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#define MB (1024 * 1024)int main(int argc, char *argv[]){    char *p;    int i = 0;    while(1) {        p = (char *)malloc(MB);        memset(p, 0, MB);        printf(&quot;%dM memory allocated\n&quot;, ++i);        sleep(1);    }    return 0;}</code></pre><p>保存上面的程序到文件~/mem-allocate.c，然后编译并测试</p><pre><code>#--------------------------第一个shell窗口----------------------#编译上面的文件dev@dev:/sys/fs/cgroup/memory/test$ gcc ~/mem-allocate.c -o ~/mem-allocate#设置内存限额为5Mdev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo 5M &gt; memory.limit_in_bytes&quot;#将当前bash加入到test中，这样这个bash创建的所有进程都会自动加入到test中dev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo $$ &gt;&gt; cgroup.procs&quot;#默认情况下，memory.oom_control的值为0，即默认启用oom killerdev@dev:/sys/fs/cgroup/memory/test$ cat memory.oom_controloom_kill_disable 0under_oom 0#为了避免受swap空间的影响，设置swappiness为0来禁止当前cgroup使用swapdev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo 0 &gt; memory.swappiness&quot;#当分配第5M内存时，由于总内存量超过了5M，所以进程被kill了dev@dev:/sys/fs/cgroup/memory/test$ ~/mem-allocate1M memory allocated2M memory allocated3M memory allocated4M memory allocatedKilled#设置oom_control为1，这样内存达到限额的时候会暂停dev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo 1 &gt;&gt; memory.oom_control&quot;#跟预期的一样，程序被暂停了dev@dev:/sys/fs/cgroup/memory/test$ ~/mem-allocate1M memory allocated2M memory allocated3M memory allocated4M memory allocated#--------------------------第二个shell窗口----------------------#再打开一个窗口dev@dev:~$ cd /sys/fs/cgroup/memory/test/#这时候可以看到memory.oom_control里面under_oom的值为1，表示当前已经oom了dev@dev:/sys/fs/cgroup/memory/test$ cat memory.oom_controloom_kill_disable 1under_oom 1#修改test的额度为7Mdev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo 7M &gt; memory.limit_in_bytes&quot;#--------------------------第一个shell窗口----------------------#再回到第一个窗口，会发现进程mem-allocate继续执行了两步，然后暂停在6M那里了dev@dev:/sys/fs/cgroup/memory/test$ ~/mem-allocate1M memory allocated2M memory allocated3M memory allocated4M memory allocated5M memory allocated6M memory allocated</code></pre><p>该文件还可以配合cgroup.event_control实现OOM的通知，当OOM发生时，可以收到相关的事件，下面是用于测试的程序，流程大概如下：</p><ol><li>利用函数eventfd()创建一个efd;</li><li>打开文件memory.oom_control，得到ofd;</li><li>往cgroup.event_control中写入这么一串：<code>&lt;efd&gt; &lt;ofd&gt;</code></li><li>通过读efd得到通知，然后打印一句话到终端</li></ol><pre><code>#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/eventfd.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;static inline void die(const char *msg){    fprintf(stderr, &quot;error: %s: %s(%d)\n&quot;, msg, strerror(errno), errno);    exit(EXIT_FAILURE);}#define BUFSIZE 256int main(int argc, char *argv[]){    char buf[BUFSIZE];    int efd, cfd, ofd;    uint64_t u;    if ((efd = eventfd(0, 0)) == -1)        die(&quot;eventfd&quot;);    snprintf(buf, BUFSIZE, &quot;%s/%s&quot;, argv[1], &quot;cgroup.event_control&quot;);    if ((cfd = open(buf, O_WRONLY)) == -1)        die(&quot;cgroup.event_control&quot;);    snprintf(buf, BUFSIZE, &quot;%s/%s&quot;, argv[1], &quot;memory.oom_control&quot;);    if ((ofd = open(buf, O_RDONLY)) == -1)        die(&quot;memory.oom_control&quot;);    snprintf(buf, BUFSIZE, &quot;%d %d&quot;, efd, ofd);    if (write(cfd, buf, strlen(buf)) == -1)        die(&quot;write cgroup.event_control&quot;);    if (close(cfd) == -1)        die(&quot;close cgroup.event_control&quot;);    for (;;) {        if (read(efd, &amp;u, sizeof(uint64_t)) != sizeof(uint64_t))            die(&quot;read eventfd&quot;);        printf(&quot;mem_cgroup oom event received\n&quot;);    }    return 0;}</code></pre><p>将上面的文件保存为~/oom_listen.c，然后测试如下</p><pre><code>#--------------------------第二个shell窗口----------------------#编译程序dev@dev:/sys/fs/cgroup/memory/test$ gcc ~/oom_listen.c -o ~/oom_listen#启用oom killerdev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo 0 &gt;&gt; memory.oom_control&quot;#设置限额为2M，缩短测试周期dev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo 2M &gt; memory.limit_in_bytes&quot;#启动监听程序dev@dev:/sys/fs/cgroup/memory/test$ ~/oom_listen /sys/fs/cgroup/memory/test#--------------------------第一个shell窗口----------------------#连续运行两次mem-allocate，使它触发oom killerdev@dev:/sys/fs/cgroup/memory/test$ ~/mem-allocate1M memory allocatedKilleddev@dev:/sys/fs/cgroup/memory/test$ ~/mem-allocate1M memory allocatedKilled#--------------------------第二个shell窗口----------------------#回到第二个窗口可以看到，收到了两次oom事件dev@dev:/sys/fs/cgroup/memory/test$ ~/oom_listen /sys/fs/cgroup/memory/testmem_cgroup oom event receivedmem_cgroup oom event received</code></pre><h2 id="其他"><a class="header-anchor" href="#其他">¶</a>其他</h2><h3 id="进程迁移（migration）"><a class="header-anchor" href="#进程迁移（migration）">¶</a>进程迁移（migration）</h3><p>当一个进程从一个cgroup移动到另一个cgroup时，默认情况下，该进程已经占用的内存还是统计在原来的cgroup里面，不会占用新cgroup的配额，但新分配的内存会统计到新的cgroup中（包括swap out到交换空间后再swap in到物理内存中的部分）。</p><p>我们可以通过设置memory.move_charge_at_immigrate让进程所占用的内存随着进程的迁移一起迁移到新的cgroup中。</p><pre><code>enable： echo 1 &gt; memory.move_charge_at_immigratedisable：echo 0 &gt; memory.move_charge_at_immigrate</code></pre><blockquote><p>注意: 就算设置为1，但如果不是thread group的leader，这个task占用的内存也不能被迁移过去。换句话说，如果以线程为单位进行迁移，必须是进程的第一个线程，如果以进程为单位进行迁移，就没有这个问题。</p></blockquote><p>当memory.move_charge_at_immigrate被设置成1之后，进程占用的内存将会被统计到目的cgroup中，如果目的cgroup没有足够的内存，系统将尝试回收目的cgroup的部分内存（和系统内存紧张时的机制一样，删除不常用的file backed的内存或者swap out到交换空间上，请参考<a href="https://segmentfault.com/a/1190000008125006" target="_blank" rel="noopener">Linux内存管理</a>），如果回收不成功，那么进程迁移将失败。</p><blockquote><p>注意：迁移内存占用数据是比较耗时的操作。</p></blockquote><h3 id="移除cgroup"><a class="header-anchor" href="#移除cgroup">¶</a>移除cgroup</h3><p>当memory.move_charge_at_immigrate为0时，就算当前cgroup中里面的进程都已经移动到其它cgropu中去了，由于进程已经占用的内存没有被统计过去，当前cgroup有可能还占用很多内存，当移除该cgroup时，占用的内存需要统计到谁头上呢？答案是依赖memory.use_hierarchy的值，如果该值为0，将会统计到root cgroup里；如果值为1，将统计到它的父cgroup里面。</p><h3 id="force-empty"><a class="header-anchor" href="#force-empty">¶</a>force_empty</h3><p>当向memory.force_empty文件写入0时（echo 0 &gt; memory.force_empty），将会立即触发系统尽可能的回收该cgroup占用的内存。该功能主要使用场景是移除cgroup前（cgroup中没有进程），先执行该命令，可以尽可能的回收该cgropu占用的内存，这样迁移内存的占用数据到父cgroup或者root cgroup时会快些。</p><h3 id="memory-swappiness"><a class="header-anchor" href="#memory-swappiness">¶</a>memory.swappiness</h3><p>该文件的值默认和全局的swappiness（/proc/sys/vm/swappiness）一样，修改该文件只对当前cgroup生效，其功能和全局的swappiness一样，请参考<a href="https://segmentfault.com/a/1190000008125116" target="_blank" rel="noopener">Linux交换空间</a>中关于swappiness的介绍。</p><blockquote><p>注意：有一点和全局的swappiness不同，那就是如果这个文件被设置成0，就算系统配置的有交换空间，当前cgroup也不会使用交换空间。</p></blockquote><h3 id="memory-use-hierarchy"><a class="header-anchor" href="#memory-use-hierarchy">¶</a>memory.use_hierarchy</h3><p>该文件内容为0时，表示不使用继承，即父子cgroup之间没有关系；当该文件内容为1时，子cgroup所占用的内存会统计到所有祖先cgroup中。</p><p>如果该文件内容为1，当一个cgroup内存吃紧时，会触发系统回收它以及它所有子孙cgroup的内存。</p><blockquote><p>注意: 当该cgroup下面有子cgroup或者父cgroup已经将该文件设置成了1，那么当前cgroup中的该文件就不能被修改。</p></blockquote><pre><code>#当前cgroup和父cgroup里都是1dev@dev:/sys/fs/cgroup/memory/test$ cat memory.use_hierarchy1dev@dev:/sys/fs/cgroup/memory/test$ cat ../memory.use_hierarchy1#由于父cgroup里面的值为1，所以修改当前cgroup的值失败dev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo 0 &gt; ./memory.use_hierarchy&quot;sh: echo: I/O error#由于父cgroup里面有子cgroup（至少有当前cgroup这么一个子cgroup），#修改父cgroup里面的值也失败dev@dev:/sys/fs/cgroup/memory/test$ sudo sh -c &quot;echo 0 &gt; ../memory.use_hierarchy&quot;sh: echo: I/O error</code></pre><h3 id="memory-soft-limit-in-bytes"><a class="header-anchor" href="#memory-soft-limit-in-bytes">¶</a>memory.soft_limit_in_bytes</h3><p>有了hard limit（memory.limit_in_bytes），为什么还要soft limit呢？hard limit是一个硬性标准，绝对不能超过这个值，而soft limit可以被超越，既然能被超越，要这个配置还有啥用？先看看它的特点</p><ol><li>当系统内存充裕时，soft limit不起任何作用</li><li>当系统内存吃紧时，系统会尽量的将cgroup的内存限制在soft limit值之下（内核会尽量，但不100%保证）</li></ol><p>从它的特点可以看出，它的作用主要发生在系统内存吃紧时，如果没有soft limit，那么所有的cgroup一起竞争内存资源，占用内存多的cgroup不会让着内存占用少的cgroup，这样就会出现某些cgroup内存饥饿的情况。如果配置了soft limit，那么当系统内存吃紧时，系统会让超过soft limit的cgroup释放出超过soft limit的那部分内存（有可能更多），这样其它cgroup就有了更多的机会分配到内存。</p><p>从上面的分析看出，这其实是系统内存不足时的一种妥协机制，给次等重要的进程设置soft limit，当系统内存吃紧时，把机会让给其它重要的进程。</p><blockquote><p>注意： 当系统内存吃紧且cgroup达到soft limit时，系统为了把当前cgroup的内存使用量控制在soft limit下，在收到当前cgroup新的内存分配请求时，就会触发回收内存操作，所以一旦到达这个状态，就会频繁的触发对当前cgroup的内存回收操作，会严重影响当前cgroup的性能。</p></blockquote><h3 id="memory-pressure-level"><a class="header-anchor" href="#memory-pressure-level">¶</a>memory.pressure_level</h3><p>这个文件主要用来监控当前cgroup的内存压力，当内存压力大时（即已使用内存快达到设置的限额），在分配内存之前需要先回收部分内存，从而影响内存分配速度，影响性能，而通过监控当前cgroup的内存压力，可以在有压力的时候采取一定的行动来改善当前cgroup的性能，比如关闭当前cgroup中不重要的服务等。目前有三种压力水平：</p><h4 id="low"><a class="header-anchor" href="#low">¶</a>low</h4><p>意味着系统在开始为当前cgroup分配内存之前，需要先回收内存中的数据了，这时候回收的是在磁盘上有对应文件的内存数据。</p><h4 id="medium"><a class="header-anchor" href="#medium">¶</a>medium</h4><p>意味着系统已经开始频繁为当前cgroup使用交换空间了。</p><h4 id="critical"><a class="header-anchor" href="#critical">¶</a>critical</h4><p>快撑不住了，系统随时有可能kill掉cgroup中的进程。</p><p>如何配置相关的监听事件呢？和memory.oom_control类似，大概步骤如下：</p><ol><li>利用函数eventfd(2)创建一个event_fd</li><li>打开文件memory.pressure_level，得到pressure_level_fd</li><li>往cgroup.event_control中写入这么一串：<code>&lt;event_fd&gt; &lt;pressure_level_fd&gt; &lt;level&gt;</code></li><li>然后通过读event_fd得到通知</li></ol><blockquote><p>注意： 多个level可能要创建多个event_fd，好像没有办法共用一个（本人没有测试过）</p></blockquote><h3 id="Memory-thresholds"><a class="header-anchor" href="#Memory-thresholds">¶</a>Memory thresholds</h3><p>我们可以通过cgroup的事件通知机制来实现对内存的监控，当内存使用量穿过（变得高于或者低于）我们设置的值时，就会收到通知。使用方法和memory.oom_control类似，大概步骤如下：</p><ol><li>利用函数eventfd(2)创建一个event_fd</li><li>打开文件memory.usage_in_bytes，得到usage_in_bytes_fd</li><li>往cgroup.event_control中写入这么一串：<code>&lt;event_fd&gt; &lt;usage_in_bytes_fd&gt; &lt;threshold&gt;</code></li><li>然后通过读event_fd得到通知</li></ol><h3 id="stat-file"><a class="header-anchor" href="#stat-file">¶</a>stat file</h3><p>这个文件包含的统计项比较细，需要一些内核的内存管理知识才能看懂，这里就不介绍了（怕说错）。详细信息可以参考<a href="https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt" target="_blank" rel="noopener">Memory Resource Controller</a>中的“5.2 stat file”。这里有几个需要注意的地方：</p><ul><li>里面total开头的统计项包含了子cgroup的数据（前提条件是memory.use_hierarchy等于1）。</li><li>里面的’rss + file_mapped&quot;才约等于是我们常说的RSS（ps aux命令看到的RSS）</li><li>文件（动态库和可执行文件）及共享内存可以在多个进程之间共享，不过它们只会统计到他们的owner cgroup中的file_mapped去。（不确定是怎么定义owner的，但如果看到当前cgroup的file_mapped值很小，说明共享的数据没有算到它头上，而是其它的cgroup）</li></ul><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>本篇没有介绍swap和kernel相关的内容，不过在实际使用过程中一定要留意swap空间，如果系统使用了交换空间，那么设置限额时一定要注意一点，那就是当cgroup的物理空间不够时，内核会将不常用的内存swap out到交换空间上，从而导致一直不触发oom killer，而是不停的swap out／in，导致cgroup中的进程运行速度很慢。如果一定要用交换空间，最好的办法是限制swap+物理内存的额度，虽然我们在这篇中没有介绍这部分内容，但其使用方法和限制物理内存是一样的，只是换做写文件memory.memsw.limit_in_bytes罢了。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt" target="_blank" rel="noopener">Memory Resource Controller</a></li><li><a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/sec-memory.html" target="_blank" rel="noopener">memory subsystem</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cgroup </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>容器概述</title>
      <link href="/2020/02/16/linux/container/rong-qi-gai-shu/"/>
      <url>/2020/02/16/linux/container/rong-qi-gai-shu/</url>
      
        <content type="html"><![CDATA[<p>在这里尝试简单回答一些常见的关于容器的疑问，仅供参考。</p><h2 id="容器是什么"><a class="header-anchor" href="#容器是什么">¶</a>容器是什么</h2><p>简单点说，容器就是一个或多个进程以及他们所能访问的资源的集合。</p><p>容器技术的本质是对计算机系统资源的隔离和控制，让原来全局的资源变得只能部分进程之间共享，这跟我们常说的虚拟机这种虚拟化技术没有关系，最新的标准在制定过程中，包括镜像的格式，容器运行时的一些规范，具体见<a href="https://www.opencontainers.org/" target="_blank" rel="noopener">Open Container Initiative(OCI)</a>。</p><h2 id="容器和虚拟机的差别"><a class="header-anchor" href="#容器和虚拟机的差别">¶</a>容器和虚拟机的差别</h2><p>从技术角度来看，他们是不同的两种技术，没有任何关系，但由于他们的应用场景有重叠的地方，所以人们经常比较他们两个</p><ul><li>容器目前只能在Linux上运行，容器里面只能跑Linux</li><li>虚拟机可以在所有主流平台上运行，比如Windows，Linux，Mac等，并且能模拟不同的系统平台，如在Windows下安装Linux的虚拟机</li><li>容器是Linux下一组进程以及他们所能访问资源的集合，所有容器共享一个内核，要比虚拟机轻量级，占用系统资源少，并且容器比虚拟机要快，包括启动速度，生成快照速度等</li><li>虚拟机是一整套的虚拟环境，包括BIOS, 虚拟网卡, 磁盘, CPU，以及操作系统等， 启动慢，占用硬件资源多.</li><li>由于虚拟机的和主机只是共享硬件资源，隔离程度要比容器高，所以相对来说虚拟机更安全</li></ul><h2 id="什么时候应该用虚拟机，什么时候应该用容器"><a class="header-anchor" href="#什么时候应该用虚拟机，什么时候应该用容器">¶</a>什么时候应该用虚拟机，什么时候应该用容器</h2><p>打个比方，A准备在网上卖东西，是自己搭建一套电商平台，还是直接在淘宝上开个小店呢？这就得看A的需求，自己搭建平台当然好，完全自己控制，想有什么功能都可以，但缺点是成本太高，淘宝上开店成本小，但要受淘宝的很多限制。想想如果淘宝的店子就能满足需求，为什么还费那么大劲去自己搭建平台呢？</p><p>虚拟机和容器的关系也差不多，虚拟机当然好，完全控制在自己手中的一套系统，没有条条框框的限制，缺点就是启动慢耗资源；容器启动快耗资源少，但受到的限制比较多（后面介绍docker的时候会提到这些限制）。所以一般的原则是如果容器能满足需求，就用容器，如果容器满足不了就用虚拟机。如何判断容器是否满足需求呢？大致原则是如果应用对硬件和内核没有特殊需求，一般都能使用容器，否则需要咨询专家。</p><p>当然这里只是从功能和资源消耗的角度来考虑，实际情况要比这个复杂的多，包括管理是否方便，相关的技术是否成熟等等。</p><h2 id="docker和容器的关系"><a class="header-anchor" href="#docker和容器的关系">¶</a>docker和容器的关系</h2><p>docker是容器管理技术的一种实现，用来管理容器，就像VMware是虚拟机的一种实现一样，除了docker，还有<a href="https://linuxcontainers.org/" target="_blank" rel="noopener">LXC/LXD</a>，<a href="https://coreos.com/rkt/" target="_blank" rel="noopener">Rocket</a>，<a href="https://www.freedesktop.org/software/systemd/man/systemd-nspawn.html" target="_blank" rel="noopener">systemd-nspawn</a>，只是docker做的最好，所以我们一说容器，就想到了docker。</p><h2 id="为什么容器只出现在Linux里面"><a class="header-anchor" href="#为什么容器只出现在Linux里面">¶</a>为什么容器只出现在Linux里面</h2><p>因为Linux中有资源隔离和管理的机制(Namespace,CGroups)，有COW（copy on write）文件系统等容器所需要的基础技术。当然其他平台也有类似的东西，但功能都没有Linux下的完善，不过随着容器技术越来越流行，其他的系统平台也在慢慢的实现和完善类似的这些技术。</p><h2 id="为什么容器里面只能运行Linux"><a class="header-anchor" href="#为什么容器里面只能运行Linux">¶</a>为什么容器里面只能运行Linux</h2><p>因为Linux下的所有容器共享一个Linux内核，所以容器里面只能跑Linux系统</p><h2 id="不同的Linux发行版为什么可以共享内核"><a class="header-anchor" href="#不同的Linux发行版为什么可以共享内核">¶</a>不同的Linux发行版为什么可以共享内核</h2><p>先看一下Linux下启动一个进程的大概过程，当在Shell里面启动一个程序的时候，会发生如下过程：</p><ol><li>Shell运行系统调用，通知内核启动一个指定位置上的程序</li><li>内核加载指定位置上的可执行文件以及它所依赖的动态库</li><li>初始化进程的地址空间，并把可执行文件映射到相应的内存地址（如果文件比较大的话，不会把整个可执行程序一次性加载到内存中，只是映射过去，然后利用内存缺页中断在需要的时候将所需的内容加载到内存中去）</li><li>开始调度进程（简单点说就是内核会让这个进程时不时的运行一会儿）</li></ol><p>从上面的过程可以看出，内核唯一需要和应用层达成一致的是可执行程序的文件格式，不然内核就没法加载程序并调度进程。</p><p>当进程开始运行后，进程和内核的交互就是系统调用，当进程需要访问由内核管理的资源时，采用软件中断的方式和内核交互，每个系统调用都有一个中断号，并且这个号不会随着内核版本变化而变化。</p><blockquote><p>关于内核所支持的系统调用请参考<a href="http://man7.org/linux/man-pages/man2/syscalls.2.html" target="_blank" rel="noopener">这里</a>，系统调用因为涉及到用户态到内核态的切换，所以非常耗时，但Linux里面有一项叫做<a href="http://man7.org/linux/man-pages/man7/vdso.7.html" target="_blank" rel="noopener">VDSO</a>的技术，可以将内核态的一些地址直接映射到所有进程的用户态空间，于是系统调用就跟访问普通的变量一样了，比如我们常用的gettimeofday函数，就不需要切换到内核态，直接读取内核映射到进程内存空间的内容就可以了，非常快。</p></blockquote><p>从上面可以看出，Linux内核和应用层进程之间的关系是松耦合的，只要保证两个条件：</p><ul><li>内核能识别应用层程序的格式</li><li>应用层需要的系统调用内核能支持</li></ul><p>由于Linux下可执行文件和动态库的格式以及系统调用的接口都比较稳定，所以不同的Linux发行版在大部分情况下都可以共享同一个内核。一般来说，新的内核兼容老的Linux发行版，但太老的内核不一定支持新的Linux发行版。如果你的应用对内核有特殊需求，那么应该考虑一下用容器是否是一个明智的选择。</p><h2 id="容器启动为什么那么快？"><a class="header-anchor" href="#容器启动为什么那么快？">¶</a>容器启动为什么那么快？</h2><p>容器的本质是一个或多个进程以及他们所能访问的资源的集合。启动一个容器的步骤大概就是：</p><ol><li>配置好相关资源，如内存、磁盘、网络等<br>配置资源就是往系统中添加一些配置，非常快</li><li>初始化容器所用到的文件目录结构<br>由于Linux下有COW（copy on write）的文件系统，如Btrfs、aufs，所以可以很快的根据镜像生成容器的文件系统目录结构。</li><li>启动进程<br>和启动一个普通的进程没有区别，对Linux内核来说，所有的应用层进程都是一样的</li></ol><p>从上面可以看出启动容器的过程中没有耗时的操作，这也是为什么容器能在毫秒级别启动起来的原因</p><h2 id="启动容器会占用很多资源导致系统变慢吗"><a class="header-anchor" href="#启动容器会占用很多资源导致系统变慢吗">¶</a>启动容器会占用很多资源导致系统变慢吗</h2><p>由于Namespace和CGroups已经是Linux内核的一部分了，所以应用层运行的进程一定会属于某个Namespace和CGroups（如果没有指定，就属于默认的Namespace和CGroups），也就是说，就算我们不用Docker，所有的进程都已经运行在默认容器中了。对内核来说，默认容器中运行的进程和Docker创建的容器中运行的进程没有什么区别，就是他们所属的容器号不一样。</p><p>所以说创建新容器会不会影响主机性能完全取决于容器里面运行什么东西。如果运行的是耗资源的进程，那么肯定会对主机性能造成影响，但这种影响可以在一定程度上由CGroups控制住，不至于对主机带来灾难性的影响。如果容器里面运行的是不耗资源的进程，那么对系统就没有影响，只是容器里面的文件系统可能会占用一些磁盘空间。</p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> container </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2、UTS namespace (CLONE_NEWUTS)</title>
      <link href="/2020/02/16/linux/namespace/2-uts-namespace-clone-newuts/"/>
      <url>/2020/02/16/linux/namespace/2-uts-namespace-clone-newuts/</url>
      
        <content type="html"><![CDATA[<p>UTS namespace用来隔离系统的hostname以及NIS domain name。</p><p>这两个资源可以通过sethostname(2)和setdomainname(2)函数来设置，以及通过uname(2), gethostname(2)和getdomainname(2)函数来获取.（这里括号中的2表示这个函数是system call，具体其他数字的含义请参看man的帮助文件）</p><p>术语UTS来自于调用函数uname()时用到的结构体: struct utsname. 而这个结构体的名字源自于&quot;UNIX Time-sharing System&quot;.</p><p>由于UTS namespace最简单，所以放在最前面介绍，在这篇文章中我们将会熟悉UTS namespace以及和namespace相关的三个系统调用的使用。</p><blockquote><p>注意： NIS domain name和DNS没有关系，关于他的介绍可以看<a href="https://www.freebsd.org/doc/handbook/network-nis.html" target="_blank" rel="noopener">这里</a>，由于本人对它不太了解，所以在本文中不做介绍。</p><p>下面的所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="创建新的UTS-namespace"><a class="header-anchor" href="#创建新的UTS-namespace">¶</a>创建新的UTS namespace</h2><p>多说无益，直接上代码，我尽量将注释写的足够详细，请仔细看代码和输出结果</p><blockquote><p><strong>注意:</strong></p><ol><li>为了代码简单起见，只在clone函数那做了错误处理，关于clone函数的详细介绍请参考<a href="http://man7.org/linux/man-pages/man2/clone.2.html" target="_blank" rel="noopener">man-pages</a></li><li>为了描述方便，某些地方会用hostname来区分UTS namespace，如hostname为container001的namespace，将会被描述成namespace container001。</li></ol></blockquote><pre><code>#define _GNU_SOURCE#include &lt;sched.h&gt;#include &lt;sys/wait.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#define NOT_OK_EXIT(code, msg); {if(code == -1){perror(msg); exit(-1);} }//子进程从这里开始执行static int child_func(void *hostname){    //设置主机名    sethostname(hostname, strlen(hostname));    //用一个新的bash来替换掉当前子进程，    //执行完execlp后，子进程没有退出，也没有创建新的进程,    //只是当前子进程不再运行自己的代码，而是去执行bash的代码,    //详情请参考&quot;man execlp&quot;    //bash退出后，子进程执行完毕    execlp(&quot;bash&quot;, &quot;bash&quot;, (char *) NULL);    //从这里开始的代码将不会被执行到，因为当前子进程已经被上面的bash替换掉了    return 0;}static char child_stack[1024*1024]; //设置子进程的栈空间为1Mint main(int argc, char *argv[]){    pid_t child_pid;    if (argc &lt; 2) {        printf(&quot;Usage: %s &lt;child-hostname&gt;\n&quot;, argv[0]);        return -1;    }    //创建并启动子进程，调用该函数后，父进程将继续往后执行，也就是执行后面的waitpid    child_pid = clone(child_func,  //子进程将执行child_func这个函数                    //栈是从高位向低位增长，所以这里要指向高位地址                    child_stack + sizeof(child_stack),                    //CLONE_NEWUTS表示创建新的UTS namespace，                    //这里SIGCHLD是子进程退出后返回给父进程的信号，跟namespace无关                    CLONE_NEWUTS | SIGCHLD,                    argv[1]);  //传给child_func的参数    NOT_OK_EXIT(child_pid, &quot;clone&quot;);    waitpid(child_pid, NULL, 0); //等待子进程结束    return 0;    //这行执行完之后，父进程结束}</code></pre><p>在上面的代码中：</p><ul><li>父进程创建新的子进程，并且设置CLONE_NEWUTS，这样就会创建新的UTS namespace并且让子进程属于这个新的namespace，然后父进程一直等待子进程退出</li><li>子进程在设置好新的hostname后被bash替换掉</li><li>当bash退出后，子进程退出，接着父进程也退出</li></ul><p>下面看看输出效果</p><pre><code>#------------------------第一个shell窗口------------------------#将上面的代码保存为namespace_uts_demo.c， #然后用gcc将它编译成可执行文件namespace_uts_demodev@ubuntu:~/code$ gcc namespace_uts_demo.c -o namespace_uts_demo   #启动程序，传入参数container001#创建新的UTS namespace需要root权限，所以用到sudodev@ubuntu:~/code$ sudo ./namespace_uts_demo container001#新的bash被启动，从shell的提示符可以看出，hostname已经被改成了container001#这里bash的提示符是‘#’，表示bash有root权限，#这是因为我们是用sudo来运行的程序，于是我们程序创建的子进程有root权限root@container001:~/code##用hostname命令再确认一下root@container001:~/code# hostnamecontainer001#pstree是用来查看系统中进程之间父子关系的工具#下面的输出过滤掉了跟namespace_uts_demo无关的内容#本次操作是通过ssh客户端远程连接到Linux主机进行的，#所以bash(24429)的父进程是一系列的sshd进程，#我们在bash(24429)里面执行了sudo ./namespace_uts_demo container001#所以有了sudo(27332)和我们程序namespace_uts_d(27333)对应的进程，#我们的程序自己clone了一个新的子进程，由于clone的时候指定了参数CLONE_NEWUTS，#所以新的子进程属于一个新的UTS namespace，然后这个新进程调用execlp后被bash替换掉了，#于是有了bash(27334)， 这个bash进程拥有所有当前子进程的属性， #由于我们的pstree命令是在bash(27334)里面运行的，#所以这里pstree(27345)是bash(27334)的子进程root@container001:~/code# pstree -plsystemd(1)───sshd(24351)───sshd(24428)───bash(24429)───sudo(27332)───namespace_uts_d(27333)───bash(27334)───pstree(27345)#验证一下我们运行的bash进程是不是bash(27334)#下面这个命令可以输出当前bash的PIDroot@container001:~/code# echo $$27334#验证一下我们的父进程和子进程是否不在同一个UTS namespaceroot@container001:~/code# readlink /proc/27333/ns/utsuts:[4026531838]root@container001:~/code# readlink /proc/27334/ns/utsuts:[4026532445]#果然不属于同一个UTS namespace，说明新的uts namespace创建成功#默认情况下，子进程应该继承父进程的namespace#systemd(1)是我们程序父进程namespace_uts_d(27333)的祖先进程，#他们应该属于同一个namespaceroot@container001:~/code# readlink /proc/1/ns/utsuts:[4026531838]#所有bash(27334)里面执行的进程应该和bash(27334)属于同样的namespace#self指向当前运行的进程，在这里即readlink进程root@container001:~/code# readlink /proc/self/ns/utsuts:[4026532445]#------------------------第二个shell窗口------------------------#重新打开一个新的shell窗口，确认这个shell和上面的namespace_uts_d(27333)属于同一个namespacedev@ubuntu:~/code$ readlink /proc/$$/ns/utsuts:[4026531838]#老的namespace中的hostname还是原来的，不受新的namespace影响dev@ubuntu:~/code$ hostname     ubuntu#有兴趣的同学可以在两个shell窗口里面分别用命令hostname设置hostname试试，#会发现他们两个之间相互不受影响，这里就不演示了#------------------------第一个shell窗口------------------------#继续回到原来的shell，试试在container001里面再运行一下那个程序会怎样root@container001:~/code# ./namespace_uts_demo container002#创建了一个新的UTS namespace，hostname被改成了container002root@container002:~/code#root@container002:~/code# hostnamecontainer002#新的UTS namespaceroot@container002:~/code# readlink /proc/$$/ns/utsuts:[4026532455]#进程间的关系和上面的差不多，在后面又生成了namespace_uts_d(27354)和bash(27355)root@container002:~/code# pstree -plsystemd(1)───sshd(24351)───sshd(24428)───bash(24429)───sudo(27332)───namespace_uts_d(27333)───bash(27334)───namespace_uts_d(27354)───bash(27355)───pstree(27367)#退出bash(27355)后，它的父进程namespace_uts_d(27354)也接着退出，#于是又回到了进程bash(27334)中，hostname于是也回到了container001#注意： 在bash(27355)退出的过程中，并没有任何进程的namespace发生变化，#只是所有属于namespace container002的进程都执行完退出了root@container002:~/code# exitexitroot@container001:~/code#root@container001:~/code# hostnamecontainer001</code></pre><h2 id="将当前进程加入指定的namespace"><a class="header-anchor" href="#将当前进程加入指定的namespace">¶</a>将当前进程加入指定的namespace</h2><p>还是直接上代码，有了前面的铺垫，这里的代码就非常简单了，请仔细看代码和输出结果</p><pre><code>#define _GNU_SOURCE#include &lt;fcntl.h&gt;#include &lt;sched.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#define NOT_OK_EXIT(code, msg); {if(code == -1){perror(msg); exit(-1);} }int main(int argc, char *argv[]){    int fd, ret;    if (argc &lt; 2) {        printf(&quot;%s /proc/PID/ns/FILE\n&quot;, argv[0]);        return -1;    }    //获取namespace对应文件的描述符    fd = open(argv[1], O_RDONLY);    NOT_OK_EXIT(fd, &quot;open&quot;);    //执行完setns后，当前进程将加入指定的namespace    //这里第二个参数为0，表示由系统自己检测fd对应的是哪种类型的namespace    ret = setns(fd, 0);    NOT_OK_EXIT(ret, &quot;open&quot;);    //用一个新的bash来替换掉当前子进程    execlp(&quot;bash&quot;, &quot;bash&quot;, (char *) NULL);    return 0;}</code></pre><p>在上面的代码中，程序通过setns调用让自己加入到参数指定的namespace中，然后用bash替换掉自己，开始执行bash。</p><p>再来看结果</p><pre><code>#--------------------------第一个shell窗口----------------------#重用上面创建的namespace container001#先确认一下hostname是否正确，root@container001:~/code# hostnamecontainer001#获取bash的PIDroot@container001:~/code# echo $$27334#得到bash所属的UTS namespaceroot@container001:~/code# readlink /proc/27334/ns/utsuts:[4026532445]#--------------------------第二个shell窗口----------------------#重新打开一个shell窗口，将上面的代码保存为文件namespace_join.c并编译dev@ubuntu:~/code$ gcc namespace_join.c -o namespace_join#运行程序前，确认下当前bash不属于namespace container001dev@ubuntu:~/code$ hostnameubuntudev@ubuntu:~/code$ readlink /proc/$$/ns/utsuts:[4026531838]#执行程序，使其加入第一个shell窗口中的bash所在的namespace#27334是第一个shell窗口中bash的piddev@ubuntu:~/code$ sudo ./namespace_join /proc/27334/ns/utsroot@container001:~/code##加入成功，bash提示符里面的hostname以及UTS namespace的inode number和第一个shell窗口的都一样root@container001:~/code# hostnamecontainer001root@container001:~/code# readlink /proc/$$/ns/utsuts:[4026532445]</code></pre><h2 id="退出当前namespace并加入新创建的namespace"><a class="header-anchor" href="#退出当前namespace并加入新创建的namespace">¶</a>退出当前namespace并加入新创建的namespace</h2><p>继续看代码</p><pre><code>#define _GNU_SOURCE#include &lt;sched.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#define NOT_OK_EXIT(code, msg); {if(code == -1){perror(msg); exit(-1);} }static void usage(const char *pname){    char usage[] = &quot;Usage: %s [optins]\n&quot;                   &quot;Options are:\n&quot;                   &quot;    -i   unshare IPC namespace\n&quot;                   &quot;    -m   unshare mount namespace\n&quot;                   &quot;    -n   unshare network namespace\n&quot;                   &quot;    -p   unshare PID namespace\n&quot;                   &quot;    -u   unshare UTS namespace\n&quot;                   &quot;    -U   unshare user namespace\n&quot;;    printf(usage, pname);    exit(0);}int main(int argc, char *argv[]){    int flags = 0, opt, ret;    //解析命令行参数，用来决定退出哪个类型的namespace    while ((opt = getopt(argc, argv, &quot;imnpuUh&quot;)) != -1) {        switch (opt) {            case 'i': flags |= CLONE_NEWIPC;        break;            case 'm': flags |= CLONE_NEWNS;         break;            case 'n': flags |= CLONE_NEWNET;        break;            case 'p': flags |= CLONE_NEWPID;        break;            case 'u': flags |= CLONE_NEWUTS;        break;            case 'U': flags |= CLONE_NEWUSER;       break;            case 'h': usage(argv[0]);               break;            default:  usage(argv[0]);        }    }    if (flags == 0) {        usage(argv[0]);    }    //执行完unshare函数后，当前进程就会退出当前的一个或多个类型的namespace,    //然后进入到一个或多个新创建的不同类型的namespace    ret = unshare(flags);    NOT_OK_EXIT(ret, &quot;unshare&quot;);    //用一个新的bash来替换掉当前子进程    execlp(&quot;bash&quot;, &quot;bash&quot;, (char *) NULL);    return 0;}</code></pre><p>看运行效果：</p><pre><code>#将上面的代码保存为文件namespace_leave.c并编译dev@ubuntu:~/code$ gcc namespace_leave.c -o namespace_leave#查看当前bash所属的UTS namespacedev@ubuntu:~/code$ readlink /proc/$$/ns/utsuts:[4026531838]#执行程序， -u表示退出并加入新的UTS namespacedev@ubuntu:~/code$ sudo ./namespace_leave -uroot@ubuntu:~/code##再次查看UTS namespace，已经变了，说明已经离开原来的namespace并加入了新的namespace#细心的同学可能已经发现这里的inode number刚好和上面namespace container002的相同，#这说明在container002被销毁后，inode number被回收再利用了root@ubuntu:~/code# readlink /proc/$$/ns/utsuts:[4026532455]#反复执行几次，得到类似的结果root@ubuntu:~/code# ./namespace_leave -uroot@ubuntu:~/code# readlink /proc/$$/ns/utsuts:[4026532456]root@ubuntu:~/code# ./namespace_leave -uroot@ubuntu:~/code# readlink /proc/$$/ns/utsuts:[4026532457]root@ubuntu:~/code# ./namespace_leave -uroot@ubuntu:~/code# readlink /proc/$$/ns/utsuts:[4026532458]</code></pre><h2 id="内核中的实现"><a class="header-anchor" href="#内核中的实现">¶</a>内核中的实现</h2><p>上面演示了这三个函数的功能，那么UTS namespace在内核中又是怎么实现的呢？</p><p>在老版本中，UTS相关的信息保存在一个全局变量中，所有进程都共享这个全局变量，gethostname()的实现大概如下</p><pre><code>asmlinkage long sys_gethostname(char __user *name, int len){  ...  if (copy_to_user(name, system_utsname.nodename, i))    errno = -EFAULT;  ...}</code></pre><p>在新的Linux内核中，在每个进程对应的task结构体<a href="https://github.com/torvalds/linux/blob/master/include/linux/sched.h" target="_blank" rel="noopener">struct task_struct</a>中，增加了一个叫nsproxy的字段，类型是<a href="https://github.com/torvalds/linux/blob/master/include/linux/nsproxy.h" target="_blank" rel="noopener">struct nsproxy</a></p><pre><code>struct task_struct {  ...  /* namespaces */  struct nsproxy *nsproxy;  ...}struct nsproxy {  atomic_t count;  struct uts_namespace *uts_ns;  struct ipc_namespace *ipc_ns;  struct mnt_namespace *mnt_ns;  struct pid_namespace *pid_ns_for_children;  struct net       *net_ns;  struct cgroup_namespace *cgroup_ns;};</code></pre><p>于是新的gethostname()的实现大概就是这样</p><pre><code>static inline struct new_utsname *utsname(void){  //current指向当前进程的task结构体  return &amp;current-&gt;nsproxy-&gt;uts_ns-&gt;name;}SYSCALL_DEFINE2(gethostname, char __user *, name, int, len){  struct new_utsname *u;  ...  u = utsname();  if (copy_to_user(name, u-&gt;nodename, i)){    errno = -EFAULT;  }  ...}</code></pre><p>处于不同UTS namespace中的进程，它task结构体里面的nsproxy-&gt;uts_ns所指向的结构体是不一样的，于是达到了隔离UTS的目的。</p><p>其他类型的namespace基本上也是差不多的原理。</p><h2 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h2><ul><li>namespace的本质就是把原来所有进程全局共享的资源拆分成了很多个一组一组进程共享的资源</li><li>当一个namespace里面的所有进程都退出时，namespace也会被销毁，所以抛开进程谈namespace没有意义</li><li>UTS namespace就是进程的一个属性，属性值相同的一组进程就属于同一个namespace，跟这组进程之间有没有亲戚关系无关</li><li>clone和unshare都有创建并加入新的namespace的功能，他们的主要区别是：<ul><li>unshare是使当前进程加入新创建的namespace</li><li>clone是创建一个新的子进程，然后让子进程加入新的namespace</li></ul></li><li>UTS namespace没有嵌套关系，即不存在说一个namespace是另一个namespace的父namespace</li></ul><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://lwn.net/Articles/531114/" target="_blank" rel="noopener">Namespaces in operation, part 2: the namespaces API</a></li><li><a href="http://www.haifux.org/lectures/299/netLec7.pdf" target="_blank" rel="noopener">Resource management:Linux kernel Namespaces and cgroups</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> namespace </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3、IPC namespace (CLONE_NEWIPC)</title>
      <link href="/2020/02/16/linux/namespace/3-ipc-namespace-clone-newipc/"/>
      <url>/2020/02/16/linux/namespace/3-ipc-namespace-clone-newipc/</url>
      
        <content type="html"><![CDATA[<p>IPC namespace用来隔离<a href="http://man7.org/linux/man-pages/man7/svipc.7.html" target="_blank" rel="noopener">System V IPC objects</a>和<a href="http://man7.org/linux/man-pages/man7/mq_overview.7.html" target="_blank" rel="noopener">POSIX message queues</a>。其中System V IPC objects包含Message queues、Semaphore sets和Shared memory segments.</p><p>对于其他几种IPC，下面是我的理解，有可能不对，仅供参考，欢迎指正：</p><ul><li>signal没必要隔离，因为它和pid密切相关，当pid隔离后，signal自然就隔离了，能不能跨pid namespace发送signal则由pid namespace决定</li><li>pipe好像也没必要隔离，对匿名pipe来说，只能在父子进程之间通讯，所以隔离的意义不大，而命名管道和文件系统有关，所以只要做好文件系统的隔离，命名管道也就隔离了</li><li>socket和协议栈有关，而不同的network namespace有不同的协议栈，所以socket就被network namespace隔离了</li></ul><blockquote><p>下面的所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="namespace相关tool"><a class="header-anchor" href="#namespace相关tool">¶</a>namespace相关tool</h2><p>从这篇文章开始，不再像介绍UTS namespace那样自己写代码，而是用ubuntu 16.04中现成的两个工具，他们的实现和上一篇文章中介绍UTS namespace时的代码类似，只是多了一些参数处理</p><ul><li>nsenter：加入指定进程的指定类型的namespace，然后执行参数中指定的命令。详情请参考<a href="http://man7.org/linux/man-pages/man1/nsenter.1.html" target="_blank" rel="noopener">帮助文档</a>和<a href="https://github.com/karelzak/util-linux/blob/master/sys-utils/nsenter.c" target="_blank" rel="noopener">代码</a>。</li><li>unshare：离开当前指定类型的namespace，创建且加入新的namespace，然后执行参数中指定的命令。详情请参考<a href="http://man7.org/linux/man-pages/man1/unshare.1.html" target="_blank" rel="noopener">帮助文档</a>和<a href="https://github.com/karelzak/util-linux/blob/master/sys-utils/unshare.c" target="_blank" rel="noopener">代码</a>。</li></ul><h2 id="示例"><a class="header-anchor" href="#示例">¶</a>示例</h2><p>这里将以消息队列为例，演示一下隔离效果，在本例中将用到两个ipc相关的命令</p><ul><li>ipcmk - 创建shared memory segments, message queues, 和semaphore arrays</li><li>ipcs - 查看shared memory segments, message queues, 和semaphore arrays的相关信息</li></ul><p>为了使演示更直观，我们在创建新的ipc namespace的时候，同时也创建新的uts namespace，然后为新的utsnamespace设置新hostname，这样就能通过shell提示符一眼看出这是属于新的namespace的bash，后面的文章中也采取这种方式启动新的bash。</p><p>在这个示例中，我们将用到两个shell窗口</p><pre><code>#--------------------------第一个shell窗口----------------------#记下默认的uts和ipc namespace numberdev@ubuntu:~$ readlink /proc/$$/ns/uts /proc/$$/ns/ipcuts:[4026531838]ipc:[4026531839]#确认hostnamedev@ubuntu:~$ hostnameubuntu#查看现有的ipc Message Queues，默认情况下没有message queuedev@ubuntu:~$ ipcs -q------ Message Queues --------key        msqid      owner      perms      used-bytes   messages#创建一个message queuedev@ubuntu:~$ ipcmk -QMessage queue id: 0dev@ubuntu:~$ ipcs -q------ Message Queues --------key        msqid      owner      perms      used-bytes   messages0x12aa0de5 0          dev        644        0            0#--------------------------第二个shell窗口----------------------#重新打开一个shell窗口，确认和上面的shell是在同一个namespace，#能看到上面创建的message queuedev@ubuntu:~$ readlink /proc/$$/ns/uts /proc/$$/ns/ipcuts:[4026531838]ipc:[4026531839]dev@ubuntu:~$ ipcs -q------ Message Queues --------key        msqid      owner      perms      used-bytes   messages0x12aa0de5 0          dev        644        0            0#运行unshare创建新的ipc和uts namespace，并且在新的namespace中启动bash#这里-i表示启动新的ipc namespace，-u表示启动新的utsnamespacedev@ubuntu:~$ sudo unshare -iu /bin/bashroot@ubuntu:~##确认新的bash已经属于新的ipc和uts namespace了root@ubuntu:~# readlink /proc/$$/ns/uts /proc/$$/ns/ipcuts:[4026532455]ipc:[4026532456]#设置新的hostname以便和第一个shell里面的bash做区分root@ubuntu:~# hostname container001root@ubuntu:~# hostnamecontainer001#当hostname改变后，bash不会自动修改它的命令行提示符#所以运行exec bash重新加载bashroot@ubuntu:~# exec bashroot@container001:~#root@container001:~# hostnamecontainer001#现在各个bash进程间的关系如下#bash(24429)是shell窗口打开时的bash#bash(27668)是运行sudo unshare创建的bash，和bash(24429)不在同一个namespaceroot@container001:~# pstree -pl├──sshd(24351)───sshd(24428)───bash(24429)───sudo(27667)───bash(27668)───pstree(27695)#查看message queues，看不到原来namespace里面的消息，说明已经被隔离了root@container001:~# ipcs -q------ Message Queues --------key        msqid      owner      perms      used-bytes   messages#创建一条新的message queueroot@container001:~# ipcmk -QMessage queue id: 0root@container001:~# ipcs -q------ Message Queues --------key        msqid      owner      perms      used-bytes   messages0x54b08fc2 0          root       644        0            0#--------------------------第一个shell窗口----------------------#回到第一个shell窗口，看看有没有受到新namespace的影响dev@ubuntu:~$ ipcs -q------ Message Queues --------key        msqid      owner      perms      used-bytes   messages0x12aa0de5 0          dev        644        0            0#完全无影响，还是原来的信息#试着加入第二个shell窗口里面bash的uts和ipc namespace#-t后面跟pid用来指定加入哪个进程所在的namespace#这里27668是第二个shell中正在运行的bash的pid#加入成功后将运行/bin/bashdev@ubuntu:~$ sudo nsenter -t 27668 -u -i /bin/bash#加入成功，bash的提示符也自动变过来了root@container001:~# readlink /proc/$$/ns/uts /proc/$$/ns/ipcuts:[4026532455]ipc:[4026532456]#显示的是新namespace里的message queuesroot@container001:~# ipcs -q------ Message Queues --------key        msqid      owner      perms      used-bytes   messages0x54b08fc2 0          root       644        0            0</code></pre><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>上面介绍了IPC namespace和两个常用的跟namespace相关的工具，从演示过程可以看出，IPC namespace差不多和UTS namespace一样简单，没有太复杂的逻辑，也没有父子namespace关系。不过后续将要介绍的其他namespace就要比这个复杂多了。</p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> namespace </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4、mount namespaces (CLONE_NEWNS)</title>
      <link href="/2020/02/16/linux/namespace/4-mount-namespaces-clone-newns/"/>
      <url>/2020/02/16/linux/namespace/4-mount-namespaces-clone-newns/</url>
      
        <content type="html"><![CDATA[<p>Mount namespace用来隔离文件系统的挂载点, 使得不同的mount namespace拥有自己独立的挂载点信息，不同的namespace之间不会相互影响，这对于构建用户或者容器自己的文件系统目录非常有用。</p><p>当前进程所在mount namespace里的所有挂载信息可以在/proc/[pid]/mounts、/proc/[pid]/mountinfo和/proc/[pid]/mountstats里面找到。</p><p>Mount namespaces是第一个被加入Linux的namespace，由于当时没想到还会引入其它的namespace，所以取名为CLONE_NEWNS，而没有叫CLONE_NEWMOUNT。</p><p>每个mount namespace都拥有一份自己的挂载点列表，当用clone或者unshare函数创建新的mount namespace时，新创建的namespace将拷贝一份老namespace里的挂载点列表，但从这之后，他们就没有关系了，通过mount和umount增加和删除各自namespace里面的挂载点都不会相互影响。</p><blockquote><p>本篇所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="演示"><a class="header-anchor" href="#演示">¶</a>演示</h2><pre><code>#--------------------------第一个shell窗口----------------------#先准备两个iso文件，用于后面的mount测试dev@ubuntu:~$ mkdir isodev@ubuntu:~$ cd iso/dev@ubuntu:~/iso$ mkdir -p iso01/subdir01dev@ubuntu:~/iso$ mkdir -p iso02/subdir02dev@ubuntu:~/iso$ mkisofs -o ./001.iso ./iso01dev@ubuntu:~/iso$ mkisofs -o ./002.iso ./iso02dev@ubuntu:~/iso$ ls001.iso  002.iso  iso01  iso02#准备目录用于mountdev@ubuntu:~/iso$ sudo mkdir /mnt/iso1 /mnt/iso2#查看当前所在的mount namespacedev@ubuntu:~/iso$ readlink /proc/$$/ns/mntmnt:[4026531840]#mount 001.iso 到 /mnt/iso1/dev@ubuntu:~/iso$ sudo mount ./001.iso /mnt/iso1/mount: /dev/loop1 is write-protected, mounting read-only#mount成功dev@ubuntu:~/iso$ mount |grep /001.iso/home/dev/iso/001.iso on /mnt/iso1 type iso9660 (ro,relatime)#创建并进入新的mount和uts namespacedev@ubuntu:~/iso$ sudo unshare --mount --uts /bin/bash#更改hostname并重新加载bashroot@ubuntu:~/iso# hostname container001root@ubuntu:~/iso# exec bashroot@container001:~/iso##查看新的mount namespaceroot@container001:~/iso# readlink /proc/$$/ns/mntmnt:[4026532455]#老namespace里的挂载点的信息已经拷贝到新的namespace里面来了root@container001:~/iso# mount |grep /001.iso/home/dev/iso/001.iso on /mnt/iso1 type iso9660 (ro,relatime)#在新namespace中mount 002.isoroot@container001:~/iso# mount ./002.iso /mnt/iso2/mount: /dev/loop0 is write-protected, mounting read-onlyroot@container001:~/iso# mount |grep iso/home/dev/iso/001.iso on /mnt/iso1 type iso9660 (ro,relatime)/home/dev/iso/002.iso on /mnt/iso2 type iso9660 (ro,relatime)#umount 001.isoroot@container001:~/iso# umount /mnt/iso1root@container001:~/iso# mount |grep iso/home/dev/iso/002.iso on /mnt/iso2 type iso9660 (ro,relatime)#/mnt/iso1目录变为空root@container001:~/iso# ls /mnt/iso1root@container001:~/iso##--------------------------第二个shell窗口----------------------#打开新的shell窗口，老namespace中001.iso的挂载信息还在#而在新namespace里面mount的002.iso这里看不到dev@ubuntu:~$ mount |grep iso/home/dev/iso/001.iso on /mnt/iso1 type iso9660 (ro,relatime)#iso1目录里面也有内容dev@ubuntu:~$ ls /mnt/iso1subdir01#说明两个namespace中的mount信息是隔离的</code></pre><h2 id="Shared-subtrees"><a class="header-anchor" href="#Shared-subtrees">¶</a>Shared subtrees</h2><p>在某些情况下，比如系统添加了一个新的硬盘，这个时候如果mount namespace是完全隔离的，想要在各个namespace里面用这个硬盘，就需要在每个namespace里面手动mount这个硬盘，这个是很麻烦的，这时<a href="https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt" target="_blank" rel="noopener">Shared subtrees</a>就可以帮助我们解决这个问题。</p><p>关于Shared subtrees的详细介绍请参考<a href="https://segmentfault.com/a/1190000006899213" target="_blank" rel="noopener">Linux mount (第二部分)</a>，里面有他的详细介绍以及bind nount的例子。</p><h3 id="演示-v2"><a class="header-anchor" href="#演示-v2">¶</a>演示</h3><p>对Shared subtrees而言，mount namespace和bind mount的情况差不多，这里就简单演示一下shared和private两种类型</p><pre><code>#--------------------------第一个shell窗口----------------------#准备4个虚拟的disk，并在上面创建ext2文件系统，用于后续的mount测试dev@ubuntu:~/iso$ cd &amp;&amp; mkdir disks &amp;&amp; cd disksdev@ubuntu:~/disks$ dd if=/dev/zero bs=1M count=32 of=./disk1.imgdev@ubuntu:~/disks$ dd if=/dev/zero bs=1M count=32 of=./disk2.imgdev@ubuntu:~/disks$ dd if=/dev/zero bs=1M count=32 of=./disk3.imgdev@ubuntu:~/disks$ dd if=/dev/zero bs=1M count=32 of=./disk4.imgdev@ubuntu:~/disks$ mkfs.ext2 ./disk1.imgdev@ubuntu:~/disks$ mkfs.ext2 ./disk2.imgdev@ubuntu:~/disks$ mkfs.ext2 ./disk3.imgdev@ubuntu:~/disks$ mkfs.ext2 ./disk4.img#准备两个目录用于挂载上面创建的diskdev@ubuntu:~/disks$ mkdir disk1 disk2dev@ubuntu:~/disks$ lsdisk1  disk1.img  disk2  disk2.img  disk3.img  disk4.img#显式的分别以shared和private方式挂载disk1和disk2dev@ubuntu:~/disks$ sudo mount --make-shared ./disk1.img ./disk1dev@ubuntu:~/disks$ sudo mount --make-private ./disk2.img ./disk2dev@ubuntu:~/disks$ cat /proc/self/mountinfo |grep disk| sed 's/ - .*//'164 24 7:1 / /home/dev/disks/disk1 rw,relatime shared:105173 24 7:2 / /home/dev/disks/disk2 rw,relatime#查看mount namespace编号dev@ubuntu:~/disks$ readlink /proc/$$/ns/mntmnt:[4026531840]#--------------------------第二个shell窗口----------------------#重新打开一个新的shell窗口dev@ubuntu:~$ cd ./disks#创建新的mount namespace#默认情况下，unshare会将新namespace里面的所有挂载点的类型设置成private，#所以这里用到了参数--propagation unchanged，#让新namespace里的挂载点的类型和老namespace里保持一致。#--propagation参数还支持private|shared|slave类型，#和mount命令的那些--make-private参数一样，#他们的背后都是通过调用mount（...）函数传入不同的参数实现的dev@ubuntu:~/disks$ sudo unshare --mount --uts --propagation unchanged /bin/bashroot@ubuntu:~/disks# hostname container001root@ubuntu:~/disks# exec bashroot@container001:~/disks# #确认已经是在新的mount namespace里面了root@container001:~/disks# readlink /proc/$$/ns/mntmnt:[4026532463]#由于前面指定了--propagation unchanged，#所以新namespace里面的/home/dev/disks/disk1也是shared，#且和老namespace里面的/home/dev/disks/disk1属于同一个peer group 105#因为在不同的namespace里面，所以这里挂载点的ID和原来namespace里的不一样了root@container001:~/disks# cat /proc/self/mountinfo |grep disk| sed 's/ - .*//'221 177 7:1 / /home/dev/disks/disk1 rw,relatime shared:105222 177 7:2 / /home/dev/disks/disk2 rw,relatime#分别在disk1和disk2目录下创建disk3和disk4，然后挂载disk3，disk4到这两个目录root@container001:~/disks# mkdir ./disk1/disk3 ./disk2/disk4root@container001:~/disks# mount ./disk3.img ./disk1/disk3/root@container001:~/disks# mount ./disk4.img ./disk2/disk4/root@container001:~/disks# cat /proc/self/mountinfo |grep disk| sed 's/ - .*//'221 177 7:1 / /home/dev/disks/disk1 rw,relatime shared:105222 177 7:2 / /home/dev/disks/disk2 rw,relatime223 221 7:3 / /home/dev/disks/disk1/disk3 rw,relatime shared:107227 222 7:4 / /home/dev/disks/disk2/disk4 rw,relatime#--------------------------第一个shell窗口----------------------#回到第一个shell窗口#可以看出由于/home/dev/disks/disk1是shared，且两个namespace里的这个挂载点都属于peer group 105，#所以在新namespace里面挂载的disk3，在老的namespace里面也看的到#但是看不到disk4的挂载信息，那是因为/home/dev/disks/disk2是private的dev@ubuntu:~/disks$ cat /proc/self/mountinfo |grep disk| sed 's/ - .*//'164 24 7:1 / /home/dev/disks/disk1 rw,relatime shared:105173 24 7:2 / /home/dev/disks/disk2 rw,relatime224 164 7:3 / /home/dev/disks/disk1/disk3 rw,relatime shared:107#我们可以随时修改挂载点的propagation type#这里我们通过mount命令将disk3改成了private类型dev@ubuntu:~/disks$ sudo mount --make-private /home/dev/disks/disk1/disk3dev@ubuntu:~/disks$ cat /proc/self/mountinfo |grep disk3| sed 's/ - .*//'224 164 7:3 / /home/dev/disks/disk1/disk3 rw,relatime#--------------------------第二个shell窗口----------------------#回到第二个shell窗口，disk3的propagation type还是shared，#表明在老的namespace里面对propagation type的修改不会影响新namespace里面的挂载点root@container001:~/disks# cat /proc/self/mountinfo |grep disk3| sed 's/ - .*//'223 221 7:3 / /home/dev/disks/disk1/disk3 rw,relatime shared:107</code></pre><p>关于mount命令和mount namespace的配合，里面有很多技巧，后面如果需要用到更复杂的用法，会再做详细的介绍。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt" target="_blank" rel="noopener">kernel:Shared Subtrees</a></li><li><a href="https://lwn.net/Articles/159077/" target="_blank" rel="noopener">lwn:Shared subtrees</a></li><li><a href="https://lwn.net/Articles/690679/" target="_blank" rel="noopener">lwn:Mount namespaces, mount propagation, and unbindable mounts</a></li><li><a href="https://lwn.net/Articles/689856/" target="_blank" rel="noopener">lwn:Mount namespaces and shared subtrees</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> namespace </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5、pid namespace (CLONE_NEWPID)</title>
      <link href="/2020/02/16/linux/namespace/5-pid-namespace-clone-newpid/"/>
      <url>/2020/02/16/linux/namespace/5-pid-namespace-clone-newpid/</url>
      
        <content type="html"><![CDATA[<p>PID namespaces用来隔离进程的ID空间，使得不同pid namespace里的进程ID可以重复且相互之间不影响。</p><p>PID namespace可以嵌套，也就是说有父子关系，在当前namespace里面创建的所有新的namespace都是当前namespace的子namespace。父namespace里面可以看到所有子孙后代namespace里的进程信息，而子namespace里看不到祖先或者兄弟namespace里的进程信息。</p><p>目前PID namespace最多可以嵌套32层，由内核中的宏MAX_PID_NS_LEVEL来定义</p><p>Linux下的每个进程都有一个对应的/proc/PID目录，该目录包含了大量的有关当前进程的信息。 对一个PID namespace而言，/proc目录只包含当前namespace和它所有子孙后代namespace里的进程的信息。</p><p>在Linux系统中，进程ID从1开始往后不断增加，并且不能重复（当然进程退出后，ID会被回收再利用），进程ID为1的进程是内核启动的第一个应用层进程，一般是init进程（现在采用systemd的系统第一个进程是systemd），具有特殊意义，当系统中一个进程的父进程退出时，内核会指定init进程成为这个进程的新父进程，而当init进程退出时，系统也将退出。</p><p>除了在init进程里指定了handler的信号外，内核会帮init进程屏蔽掉其他任何信号，这样可以防止其他进程不小心kill掉init进程导致系统挂掉。不过有了PID namespace后，可以通过在父namespace中发送SIGKILL或者SIGSTOP信号来终止子namespace中的ID为1的进程。</p><p>由于ID为1的进程的特殊性，所以每个PID namespace的第一个进程的ID都是1。当这个进程运行停止后，内核将会给这个namespace里的所有其他进程发送SIGKILL信号，致使其他所有进程都停止，于是namespace被销毁掉。</p><blockquote><p>本篇所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="简单示例"><a class="header-anchor" href="#简单示例">¶</a>简单示例</h2><pre><code>#查看当前pid namespace的IDdev@ubuntu:~$ readlink /proc/self/ns/pidpid:[4026531836]#启动新的pid namespace#这里同时也启动了新的uts和mount namespace#新的uts是为了设置一个新的hostname，便于和老的namespace区分#新的mount namespace是为了方便我们修改新namespace里面的mount信息，#因为这样不会对老namespace造成影响#这里--fork是为了让unshare进程fork一个新的进程出来，然后再用bash替换掉新的进程#这是pid namespace本身的限制，进程所属的pid namespace在它创建的时候就确定了，不能更改，#所以调用unshare和nsenter后，原来的进程还是属于老的namespace，#而新fork出来的进程才属于新的namespacedev@ubuntu:~$ sudo unshare --uts --pid --mount --fork /bin/bashroot@ubuntu:~# hostname container001root@ubuntu:~# exec bashroot@container001:~##查看进程间关系，当前bash(31646)确实是unshare的子进程root@container001:~# pstree -pl├─sshd(955)─┬─sshd(17810)───sshd(17891)───bash(17892)───sudo(31644)───unshare(31645)───bash(31646)───pstree(31677)#他们属于不同的pid namespaceroot@container001:~# readlink /proc/31645/ns/pidpid:[4026531836]root@container001:~# readlink /proc/31646/ns/pidpid:[4026532469]#但为什么通过这种方式查看到的namespace还是老的呢？root@container001:~# readlink /proc/$$/ns/pidpid:[4026531836]#由于我们实际上已经是在新的namespace里了，并且当前bash是当前namespace的第一个进程#所以在新的namespace里看到的他的进程ID是1root@container001:~# echo $$1#但由于我们新的namespace的挂载信息是从老的namespace拷贝过来的，#所以这里看到的还是老namespace里面的进程号为1的信息root@container001:~# readlink /proc/1/ns/pidpid:[4026531836]#ps命令依赖/proc目录，所以ps的输出还是老namespace的视图root@container001:~# ps efUID        PID  PPID  C STIME TTY          TIME CMDroot         1     0  0 7月07 ?       00:00:06 /sbin/initroot         2     0  0 7月07 ?       00:00:00 [kthreadd] ...root     31644 17892  0 7月14 pts/0   00:00:00 sudo unshare --uts --pid --mount --fork /bin/bashroot     31645 31644  0 7月14 pts/0   00:00:00 unshare --uts --pid --mount --fork /bin/bash#所以我们需要重新挂载我们的/proc目录root@container001:~# mount -t proc proc /proc#重新挂载后，能看到我们新的pid namespace ID了root@container001:~# readlink /proc/$$/ns/pidpid:[4026532469]#ps的输出也正常了root@container001:~# ps -efUID        PID  PPID  C STIME TTY          TIME CMDroot         1     0  0 7月14 pts/0   00:00:00 bashroot        44     1  0 00:06 pts/0    00:00:00 ps -ef</code></pre><h2 id="PID-namespace嵌套"><a class="header-anchor" href="#PID-namespace嵌套">¶</a>PID namespace嵌套</h2><ul><li>调用unshare或者setns函数后，当前进程的namespace不会发生变化，不会加入到新的namespace，而它的子进程会加入到新的namespace。也就是说进程属于哪个namespace是在进程创建的时候决定的，并且以后再也无法更改。</li><li>在一个PID namespace里的进程，它的父进程可能不在当前namespace中，而是在外面的namespace里面（这里外面的namespace指当前namespace的祖先namespace），这类进程的ppid都是0。比如新namespace里面的第一个进程，他的父进程就在外面的namespace里。通过setns的方式加入到新namespace中的进程的父进程也在外面的namespace中。</li><li>可以在祖先namespace中看到子namespace的所有进程信息，且可以发信号给子namespace的进程，但进程在不同namespace中的PID是不一样的。</li></ul><h3 id="嵌套示例"><a class="header-anchor" href="#嵌套示例">¶</a>嵌套示例</h3><pre><code>#--------------------------第一个shell窗口----------------------#记下最外层的namespace IDdev@ubuntu:~$ readlink /proc/$$/ns/pidpid:[4026531836]#创建新的pid namespace， 这里--mount-proc参数是让unshare自动重新mount /proc目录dev@ubuntu:~$ sudo unshare --uts --pid --mount --fork --mount-proc /bin/bashroot@ubuntu:~# hostname container001root@ubuntu:~# exec bashroot@container001:~# readlink /proc/$$/ns/pidpid:[4026532469]#再创建新的pid namespaceroot@container001:~# unshare --uts --pid --mount --fork --mount-proc /bin/bashroot@container001:~# hostname container002root@container001:~# exec bashroot@container002:~# readlink /proc/$$/ns/pidpid:[4026532472]#再创建新的pid namespaceroot@container002:~# unshare --uts --pid --mount --fork --mount-proc /bin/bashroot@container002:~# hostname container003root@container002:~# exec bashroot@container003:~# readlink /proc/$$/ns/pidpid:[4026532475]#目前namespace container003里面就一个bash进程root@container003:~# pstree -pbash(1)───pstree(22)#这样我们就有了三层pid namespace，#他们的父子关系为container001-&gt;container002-&gt;container003#--------------------------第二个shell窗口----------------------#在最外层的namespace中查看上面新创建的三个namespace中的bash进程#从这里可以看出，这里显示的bash进程的PID和上面container003里看到的bash(1)不一样dev@ubuntu:~$ pstree -pl|grep bash|grep unshare|-sshd(955)-+-sshd(17810)---sshd(17891)---bash(17892)---sudo(31814)---unshare(31815)---bash(31816)---unshare(31842)---bash(31843)---unshare(31864)---bash(31865)#各个unshare进程的子bash进程分别属于上面的三个pid namespacedev@ubuntu:~$ sudo readlink /proc/31816/ns/pidpid:[4026532469]dev@ubuntu:~$ sudo readlink /proc/31843/ns/pidpid:[4026532472]dev@ubuntu:~$ sudo readlink /proc/31865/ns/pidpid:[4026532475]#PID在各个namespace里的映射关系可以通过/proc/[pid]/status查看到#这里31865是在最外面namespace中看到的pid#45，23，1分别是在container001，container002和container003中的piddev@ubuntu:~$ grep pid /proc/31865/statusNSpid:  31865   45     23      1#创建一个新的bash并加入container002dev@ubuntu:~$ sudo nsenter --uts --mount --pid -t 31843 /bin/bashroot@container002:/##这里bash（23）就是container003里面的pid 1对应的bashroot@container002:/# pstree -pbash(1)───unshare(22)───bash(23)#unshare(22)属于container002root@container002:/# readlink /proc/22/ns/pidpid:[4026532472]#bash（23）属于container003root@container002:/# readlink /proc/23/ns/pidpid:[4026532475]#为什么上面pstree的结果里面没看到nsenter加进来的bash呢？#通过ps命令我们发现，我们新加进来的那个/bin/bash的ppid是0，难怪pstree里面显示不出来#从这里可以看出，跟最外层namespace不一样的地方就是，这里可以有多个进程的ppid为0#从这里的TTY也可以看出哪些命令是在哪些窗口执行的，#pts/0对应第一个shell窗口，pts/1对应第二个shell窗口root@container002:/# ps -efUID        PID  PPID  C STIME TTY          TIME CMDroot         1     0  0 04:39 pts/0    00:00:00 bashroot        22     1  0 04:39 pts/0    00:00:00 unshare --uts --pid --mount --fork --mount-proc /bin/bashroot        23    22  0 04:39 pts/0    00:00:00 bashroot        46     0  0 04:52 pts/1    00:00:00 /bin/bashroot        59    46  0 04:53 pts/1    00:00:00 ps -ef#--------------------------第三个shell窗口----------------------#创建一个新的bash并加入container001dev@ubuntu:~$ sudo nsenter --uts --mount --pid -t 31816 /bin/bashroot@container001:/##通过pstree和ps -ef我们可看到所有三个namespace中的进程及他们的关系#bash(1)───unshare(22)属于container001#bash(23)───unshare(44)属于container002#bash(45)属于container003，而68和84两个进程分别是上面两次通过nsenter加进来的bash#同上面ps的结果比较我们可以看出，同样的进程在不同的namespace里面拥有不同的PIDroot@container001:/# pstree -plbash(1)───unshare(22)───bash(23)───unshare(44)───bash(45)root@container001:/# ps -efUID        PID  PPID  C STIME TTY          TIME CMDroot         1     0  0 04:37 pts/0    00:00:00 bashroot        22     1  0 04:39 pts/0    00:00:00 unshare --uts --pid --mount --fork --mount-proc /bin/bashroot        23    22  0 04:39 pts/0    00:00:00 bashroot        44    23  0 04:39 pts/0    00:00:00 unshare --uts --pid --mount --fork --mount-proc /bin/bashroot        45    44  0 04:39 pts/0    00:00:00 bashroot        68     0  0 04:52 pts/1    00:00:00 /bin/bashroot        84     0  0 05:00 pts/2    00:00:00 /bin/bashroot        95    84  0 05:00 pts/2    00:00:00 ps -ef#发送信号给contain002中的bashroot@container001:/# kill 68#--------------------------第二个shell窗口----------------------#回到第二个窗口，发现bash已经被kill掉了，说明父namespace是可以发信号给子namespace中的进程的root@container002:/# exitdev@ubuntu:~$</code></pre><h2 id="“init”示例"><a class="header-anchor" href="#“init”示例">¶</a>“init”示例</h2><p>当一个进程的父进程被kill掉后，该进程将会被当前namespace中pid为1的进程接管，而不是被最外层的系统级别的init进程接管。</p><p>当pid为1的进程停止运行后，内核将会给这个namespace及其子孙namespace里的所有其他进程发送SIGKILL信号，致使其他所有进程都停止，于是当前namespace及其子孙后代的namespace都被销毁掉。</p><pre><code>#还是继续以上面三个namespace为例#--------------------------第一个shell窗口----------------------#在003里面启动两个新的bash，使他们的继承关系如下root@container003:~# bashroot@container003:~# bashroot@container003:~# pstreebash───bash───bash───pstree#利用unshare、nohup和sleep的组合，模拟出我们想要的父子进程#unshare --fork会使unshare创建一个子进程#nohup sleep sleep 3600&amp;会让这个子进程在后台运行并且sleep一小时root@container003:~# unshare --fork nohup sleep 3600&amp;[1] 77#于是我们得到了我们想要的进程间关系结构root@container003:~# pstree -pbash(1)───bash(26)───bash(36)─┬─pstree(80)                              └─unshare(77)───sleep(78)#如我们所期望的，kill掉unshare(77)后， sleep就被当前pid namespace的bash(1)接管了root@container003:~# kill 77root@container003:~# pstree -pbash(1)─┬─bash(26)───bash(36)───pstree(82)        └─sleep(78)#重新回到刚才的状态，后面将尝试在第三个窗口中kill掉这里的unshare进程root@container003:~# kill 78root@container003:~# unshare --fork nohup sleep 3600&amp;root@container003:~# pstree -pbash(1)───bash(26)───bash(36)─┬─pstree(85)                              └─unshare(83)───sleep(84)#--------------------------第三个shell窗口----------------------#来到第三个窗口root@container001:/# pstree -pbash(1)───unshare(22)───bash(23)───unshare(44)───bash(45)───bash(113)───bash(123)───unshare(170)───sleep(171)#kill掉sleep(171)的父近程unshare(170)，root@container001:/# kill 170#结果显示sleep（171）被bash(45)接管了，而不是bash(1)，#进一步说明container003里的进程只会被container003里的pid 1进程接管，#而不会被外面container001的pid 1进程接管root@container001:/# pstree -pbash(1)───unshare(22)───bash(23)───unshare(44)───bash(45)─┬─bash(113)───bash(123)          └─sleep(171)#kill掉container002中pid 1的bash进程，在container001中，对应的是bash(23)root@container001:/# kill 23#根本没反应，说明bash不接收TERM信号（kill默认发送SIGTERM信号）root@container001:/# pstree -pbash(1)───unshare(22)───bash(23)───unshare(44)───bash(45)─┬─bash(113)───bash(123)          └─sleep(171)#试试SIGSTOP，貌似也不行      root@container001:/# kill -SIGSTOP 23root@container001:/# pstree -pbash(1)───unshare(22)───bash(23)───unshare(44)───bash(45)─┬─bash(113)───bash(123)          └─sleep(171)#最后试试杀手锏SIGKILL，马到成功root@container001:/# kill -SIGKILL 23root@container001:/# pstree -pbash(1)#--------------------------第一个shell窗口----------------------#container003和container002的bash退出了，#第一个shell窗口直接退到了container001的bashroot@container003:~# Killedroot@container001:~##--------------------------第二个shell窗口----------------------#通过nsenter方式加入到container002的bash也被kill掉了root@container002:/# Killeddev@ubuntu:~$#从结果可以看出，container002的“init”进程被杀死后，#内核将会发送SIGKILL给container002里的所有进程，#这样导致container002及它所有子孙namespace里的进程都杀死，#同时container002和container003也被销毁</code></pre><p><a href="http://man7.org/linux/man-pages/man7/pid_namespaces.7.html" target="_blank" rel="noopener">man-pages</a>里面说SIGSTOP也可以kill掉子namespace里的“init”进程，但我在上面试了下，没效果，具体原因未知。</p><h2 id="其他"><a class="header-anchor" href="#其他">¶</a>其他</h2><ul><li>通常情况下，如果PID namespace中的进程都退出了，这个namespace将会被销毁，但就如在前面<a href="https://segmentfault.com/a/1190000006908272" target="_blank" rel="noopener">“Namespace概述”</a>里介绍的，有两种情况会导致就算进程都退出了，这个namespace还会存在。但对于PID namespace来说，就算namespace还在，由于里面没有“init”进程，Kernel不允许其它进程加入到这个namespace，所以这个存在的namespace没有意义</li><li>当一个PID通过UNIX domain socket在不同的PID namespace中传输时（请参考<a href="http://man7.org/linux/man-pages/man7/unix.7.html" target="_blank" rel="noopener">unix(7)</a>里面的SCM_CREDENTIALS），PID将会自动转换成目的namespace中的PID.</li></ul><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://lwn.net/Articles/531419/" target="_blank" rel="noopener">Namespaces in operation, part 3: PID namespaces</a></li><li><a href="https://lwn.net/Articles/532748/" target="_blank" rel="noopener">Namespaces in operation, part 4: more on PID namespaces</a></li><li><a href="http://man7.org/linux/man-pages/man7/pid_namespaces.7.html" target="_blank" rel="noopener">overview of Linux PID namespaces</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> namespace </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6、network namespace (CLONE_NEWNET)</title>
      <link href="/2020/02/16/linux/namespace/6-network-namespace-clone-newnet/"/>
      <url>/2020/02/16/linux/namespace/6-network-namespace-clone-newnet/</url>
      
        <content type="html"><![CDATA[<p>network namespace用来隔离网络设备, IP地址, 端口等. 每个namespace将会有自己独立的网络栈，路由表，防火墙规则，socket等。</p><p>每个新的network namespace默认有一个本地环回接口，除了lo接口外，所有的其他网络设备（物理/虚拟网络接口，网桥等）只能属于一个network namespace。每个socket也只能属于一个network namespace。</p><p>当新的network namespace被创建时，lo接口默认是关闭的，需要自己手动启动起</p><p>标记为&quot;local devices&quot;的设备不能从一个namespace移动到另一个namespace，比如loopback, bridge, ppp等，我们可以通过ethtool -k命令来查看设备的netns-local属性。</p><pre><code>#这里“on”表示该设备不能被移动到其他network namespacedev@ubuntu:~$ ethtool -k lo|grep netns-localnetns-local: on [fixed]</code></pre><blockquote><p>本篇所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="示例"><a class="header-anchor" href="#示例">¶</a>示例</h2><p>本示例将演示如何创建新的network namespace并同外面的namespace进行通信。</p><pre><code>#--------------------------第一个shell窗口----------------------#记录默认network namespace IDdev@ubuntu:~$ readlink /proc/$$/ns/netnet:[4026531957]#创建新的network namespacedev@ubuntu:~$ sudo unshare --uts --net /bin/bashroot@ubuntu:~# hostname container001root@ubuntu:~# exec bashroot@container001:~# readlink /proc/$$/ns/netnet:[4026532478]#运行ifconfig啥都没有root@container001:~# ifconfigroot@container001:~##启动lo （这里不详细介绍ip这个tool的用法，请参考man ip）root@container001:~# ip link set lo uproot@container001:~# ifconfiglo        Link encap:Local Loopback          inet addr:127.0.0.1  Mask:255.0.0.0          inet6 addr: ::1/128 Scope:Host          UP LOOPBACK RUNNING  MTU:65536  Metric:1          RX packets:0 errors:0 dropped:0 overruns:0 frame:0          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)root@container001:~# ping 127.0.0.1PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.070 ms64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.015 ms#获取当前bash进程的PIDroot@container001:~# echo $$15812#--------------------------第二个shell窗口----------------------#创建新的虚拟以太网设备，让两个namespace能通讯dev@ubuntu:~$ sudo ip link add veth0 type veth peer name veth1#将veth1移动到上面第一个窗口中的namespace#这里15812是上面bash的PIDdev@ubuntu:~$ sudo ip link set veth1 netns 15812#为veth0分配IP并启动veth0dev@ubuntu:~$ sudo ip address add dev veth0 192.168.8.1/24dev@ubuntu:~$ sudo ip link set veth0 updev@ubuntu:~$ ifconfig veth0veth0     Link encap:Ethernet  HWaddr 9a:4d:d5:96:b5:36          inet addr:192.168.8.1  Bcast:0.0.0.0  Mask:255.255.255.0          inet6 addr: fe80::984d:d5ff:fe96:b536/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:8 errors:0 dropped:0 overruns:0 frame:0          TX packets:8 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000          RX bytes:648 (648.0 B)  TX bytes:648 (648.0 B)#--------------------------第一个shell窗口----------------------#为veth1分配IP地址并启动它root@container001:~# ip address add dev veth1 192.168.8.2/24root@container001:~# ip link set veth1 uproot@container001:~# ifconfig veth1veth1     Link encap:Ethernet  HWaddr 6a:dc:59:79:3c:8b          inet addr:192.168.8.2  Bcast:0.0.0.0  Mask:255.255.255.0          inet6 addr: fe80::68dc:59ff:fe79:3c8b/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:8 errors:0 dropped:0 overruns:0 frame:0          TX packets:8 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000          RX bytes:648 (648.0 B)  TX bytes:648 (648.0 B)#连接成功root@container001:~# ping 192.168.8.1PING 192.168.8.1 (192.168.8.1) 56(84) bytes of data.64 bytes from 192.168.8.1: icmp_seq=1 ttl=64 time=0.098 ms64 bytes from 192.168.8.1: icmp_seq=2 ttl=64 time=0.023 ms</code></pre><p>到目前为止，两个namespace之间可以网络通信了，但在container001里还是不能访问外网。下面将通过NAT的方式让container001能够上外网。这部分内容完全是网络相关的知识，跟namespace已经没什么关系了。</p><pre><code>#--------------------------第二个shell窗口----------------------#回到上面示例中的第二个窗口#确认IP forward是否已经开通，这里1表示开通了#如果你的机器上是0，请运行这个命令将它改为1： sudo sysctl -w net.ipv4.ip_forward=1dev@ubuntu:~$ cat /proc/sys/net/ipv4/ip_forward1#添加NAT规则，这里ens32是机器上连接外网的网卡#关于iptables和nat都比较复杂，这里不做解释dev@ubuntu:~$ sudo iptables -t nat -A POSTROUTING -o ens32 -j MASQUERADE#--------------------------第一个shell窗口----------------------#回到第一个窗口，添加默认网关root@container001:~# ip route add default via 192.168.8.1root@container001:~# route -nKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Iface0.0.0.0         192.168.8.1     0.0.0.0         UG    0      0        0 veth1192.168.8.0     0.0.0.0         255.255.255.0   U     0      0        0 veth1#这样就可以访问外网了#由于测试环境的限制，所以采用下面的方式检测网络是否畅通#如果网络没有什么限制的话，随便ping一个外部的IP测试就可以了root@container001:~# curl -I www.google.comHTTP/1.1 200 OKDate: Fri, 15 Jul 2016 08:12:03 GMT</code></pre><p>network namespace的概念比较简单，但如何做好网络的隔离和连通却比较难，包括性能和安全相关的考虑，需要很好的Linux网络知识。后续在介绍docker网络管理的时候会对Linux网络做一个更详细的介绍。</p><h2 id="ip-netns"><a class="header-anchor" href="#ip-netns">¶</a>ip netns</h2><p>在单独操作network namespace时，ip netns是一个很方便的工具，并且它可以给namespace取一个名字，然后根据名字来操作namespace。那么给namespace取名字并且根据名字来管理namespace里面的进程是怎么实现的呢？请看下面的脚本(也可以直接看它的<a href="https://github.com/shemminger/iproute2/blob/master/ip/ipnetns.c" target="_blank" rel="noopener">源代码</a>)：</p><pre><code>#开始之前，获取一下默认network namespace的IDdev@ubuntu:~$ readlink /proc/$$/ns/netnet:[4026531957]#创建一个用于绑定network namespace的文件，#ip netns将所有的文件放到了目录/var/run/netns下，#所以我们这里重用这个目录，并且创建一个我们自己的文件netnamespace1dev@ubuntu:~$ sudo mkdir -p /var/run/netnsdev@ubuntu:~$ sudo touch /var/run/netns/netnamespace1#创建新的network namespace，并在新的namespace中启动新的bashdev@ubuntu:~$ sudo unshare --net bash#查看新的namespace IDroot@ubuntu:~# readlink /proc/$$/ns/netnet:[4026532448]#bind当前bash的namespace文件到上面创建的文件上root@ubuntu:~# mount --bind /proc/$$/ns/net /var/run/netns/netnamespace1#通过ls -i命令可以看到文件netnamespace1的inode号和namespace的编号相同，说明绑定成功root@ubuntu:~# ls -i /var/run/netns/netnamespace14026532448 /var/run/netns/netnamespace1#退出新创建的bashroot@ubuntu:~# exitexit#可以看出netnamespace1的inode没变，说明我们使用了bind mount后#虽然新的namespace中已经没有进程了，但这个新的namespace还存在dev@ubuntu:~$ ls -i /var/run/netns/netnamespace14026532448 /var/run/netns/netnamespace1#上面的这一系列操作等同于执行了命令： ip netns add netnamespace1#下面的nsenter命令等同于执行了命令： ip netns exec netnamespace1 bash#我们可以通过nsenter命令再创建一个新的bash，并将它加入netnamespace1所关联的namespace（net:[4026532448]）dev@ubuntu:~$ sudo nsenter --net=/var/run/netns/netnamespace1 bashroot@ubuntu:~# readlink /proc/$$/ns/netnet:[4026532448]</code></pre><p>从上面可以看出，给namespace取名字其实就是创建一个文件，然后通过mount --bind将新创建的namespace文件和该文件绑定，就算该namespace里的所有进程都退出了，内核还是会保留该namespace，以后我们还可以通过这个绑定的文件来加入该namespace。</p><p>通过这种办法，我们也可以给其他类型的namespace取名字（有些类型的 namespace可能有些特殊，本人没有一个一个的试过）。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://lwn.net/Articles/580893/" target="_blank" rel="noopener">Namespaces in operation, part 7: Network namespaces</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> namespace </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7、user namespace (CLONE_NEWUSER) (第一部分)</title>
      <link href="/2020/02/16/linux/namespace/7-user-namespace-clone-newuser-di-yi-bu-fen/"/>
      <url>/2020/02/16/linux/namespace/7-user-namespace-clone-newuser-di-yi-bu-fen/</url>
      
        <content type="html"><![CDATA[<p>User namespace用来隔离user权限相关的Linux资源，包括<a href="http://man7.org/linux/man-pages/man7/credentials.7.html" target="_blank" rel="noopener">user IDs and group IDs</a>，<a href="http://man7.org/linux/man-pages/man2/keyctl.2.html" target="_blank" rel="noopener">keys</a> , 和<a href="http://man7.org/linux/man-pages/man7/capabilities.7.html" target="_blank" rel="noopener">capabilities</a>.</p><p>这是目前实现的namespace中最复杂的一个，因为user和权限息息相关，而权限又事关容器的安全，所以稍有不慎，就会出安全问题。</p><p>user namespace可以嵌套（目前内核控制最多32层），除了系统默认的user namespace外，所有的user namespace都有一个父user namespace，每个user namespace都可以有零到多个子user namespace。 当在一个进程中调用unshare或者clone创建新的user namespace时，当前进程原来所在的user namespace为父user namespace，新的user namespace为子user namespace.</p><p>在不同的user namespace中，同样一个用户的user ID 和group ID可以不一样，换句话说，一个用户可以在父user namespace中是普通用户，在子user namespace中是超级用户（超级用户只相对于子user namespace所拥有的资源，无法访问其他user namespace中需要超级用户才能访问资源）。</p><p>从Linux 3.8开始，创建新的user namespace不需要root权限。</p><blockquote><p>本篇所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="创建user-namespace"><a class="header-anchor" href="#创建user-namespace">¶</a>创建user namespace</h2><pre><code>#--------------------------第一个shell窗口----------------------#先记录下目前的id，gid和user namespacedev@ubuntu:~$ iduid=1000(dev) gid=1000(dev) groups=1000(dev),4(adm),24(cdrom),27(sudo)dev@ubuntu:~$ readlink /proc/$$/ns/useruser:[4026531837]#创建新的user namespacedev@ubuntu:~$ unshare --user /bin/bashnobody@ubuntu:~$ readlink /proc/$$/ns/useruser:[4026532464]nobody@ubuntu:~$ iduid=65534(nobody) gid=65534(nogroup) groups=65534(nogroup)</code></pre><p>很奇怪，为什么上面例子中显示的用户名是nobody，它的id和gid都是65534？</p><p>这是因为我们还没有映射父user namespace的user ID和group ID到子user namespace中来，这一步是必须的，因为这样系统才能控制一个user namespace里的用户在其他user namespace中的权限。（比如给其他user namespace中的进程发送信号，或者访问属于其他user namespace挂载的文件）</p><p>如果没有映射的话，当在新的user namespace中用getuid()和getgid()获取user id和group id时，系统将返回文件/proc/sys/kernel/overflowuid中定义的user ID以及proc/sys/kernel/overflowgid中定义的group ID，它们的默认值都是65534。也就是说如果没有指定映射关系的话，会默认映射到ID65534。</p><p>下面看看这个user能干些什么</p><pre><code>#--------------------------第一个shell窗口----------------------#ls的结果显示/root目录属于nobodynobody@ubuntu:~$ ls -l /|grep rootdrwx------   3 nobody nogroup  4096 7月   8 18:39 root#但是当前的nobody账号访问不了，说明这两个nobody不是一个ID，他们之间没有映射关系nobody@ubuntu:~$ ls /rootls: cannot open directory '/root': Permission denied#这里显示/home/dev目录属于nobodynobody@ubuntu:~$ ls -l /home/drwxr-xr-x 11 nobody nogroup 4096 7月   8 18:40 dev#touch成功，说明虽然没有显式的映射ID，但还是能访问父user namespace里dev账号拥有的资源#说明他们背后还是有映射关系nobody@ubuntu:~$ touch /home/dev/temp01nobody@ubuntu:~$</code></pre><h2 id="映射user-ID和group-ID"><a class="header-anchor" href="#映射user-ID和group-ID">¶</a>映射user ID和group ID</h2><p>通常情况下，创建新的user namespace后，第一件事就是映射user和group ID. 映射ID的方法是添加配置到/proc/PID/uid_map和/proc/PID/gid_map（这里的PID是新user namespace中的进程ID，刚开始时这两个文件都是空的）.</p><p>这两个文件里面的配置格式如下（可以有多条）：</p><pre><code>ID-inside-ns ID-outside-ns length</code></pre><p>举个例子, 0 1000 256这条配置就表示父user namespace中的1000~1256映射到新user namespace中的0~256。</p><blockquote><p>系统默认的user namespace没有父user namespace，但为了保持一致，kernel提供了一个虚拟的uid和gid map文件，看起来是这样子的:<br>dev@ubuntu:~cat /proc/<em>c<strong>a</strong>t</em>/<em>p<strong>r</strong>o**c</em>/$/uid_map<br>0 0 4294967295</p></blockquote><p>那么谁可以向这个文件中写配置呢？</p><p>/proc/PID/uid_map和/proc/PID/gid_map的拥有者是创建新user namespace的这个user，所以和这个user在一个user namespace的root账号可以写。但这个user自己有没有写map文件权限还要看它有没有CAP_SETUID和CAP_SETGID的capability。</p><blockquote><p><strong>注意</strong>：只能向map文件写一次数据，但可以一次写多条，并且最多只能5条</p></blockquote><p>关于capability的详细介绍可以参考<a href="http://man7.org/linux/man-pages/man7/capabilities.7.html" target="_blank" rel="noopener">这里</a>，简单点说，原来的Linux就分root和非root，很多操作只能root完成，比如修改一个文件的owner，后来Linux将root的一些权限分解了，变成了各种capability，只要拥有了相应的capability，就能做相应的操作，不需要root账户的权限。</p><p>下面我们来看看如何用dev账号映射uid和gid</p><pre><code>#--------------------------第一个shell窗口----------------------#获取当前bash的pidnobody@ubuntu:~$ echo $$24126#--------------------------第二个shell窗口----------------------#dev是map文件的ownerdev@ubuntu:~$ ls -l /proc/24126/uid_map /proc/24126/gid_map-rw-r--r-- 1 dev dev 0 7月  24 23:11 /proc/24126/gid_map-rw-r--r-- 1 dev dev 0 7月  24 23:11 /proc/24126/uid_map#但还是没有权限写这个文件dev@ubuntu:~$ echo '0 1000 100' &gt; /proc/24126/uid_mapbash: echo: write error: Operation not permitteddev@ubuntu:~$ echo '0 1000 100' &gt; /proc/24126/gid_mapbash: echo: write error: Operation not permitted#当前用户运行的bash进程没有CAP_SETUID和CAP_SETGID的权限dev@ubuntu:~$ cat /proc/$$/status | egrep 'Cap(Inh|Prm|Eff)'CapInh: 0000000000000000CapPrm: 0000000000000000CapEff: 0000000000000000#为/binb/bash设置capability，dev@ubuntu:~$ sudo setcap cap_setgid,cap_setuid+ep /bin/bash#重新加载bash以后我们看到相应的capability已经有了dev@ubuntu:~$ exec bashdev@ubuntu:~$ cat /proc/$$/status | egrep 'Cap(Inh|Prm|Eff)'CapInh: 0000000000000000CapPrm: 00000000000000c0CapEff: 00000000000000c0#再试一次写map文件，成功了dev@ubuntu:~$ echo '0 1000 100' &gt; /proc/24126/uid_mapdev@ubuntu:~$ echo '0 1000 100' &gt; /proc/24126/gid_mapdev@ubuntu:~$#再写一次就失败了，因为这个文件只能写一次dev@ubuntu:~$ echo '0 1000 100' &gt; /proc/24126/uid_mapbash: echo: write error: Operation not permitteddev@ubuntu:~$ echo '0 1000 100' &gt; /proc/24126/gid_mapbash: echo: write error: Operation not permitted#后续测试不需要CAP_SETUID了，将/bin/bash的capability恢复到原来的设置dev@ubuntu:~$ sudo setcap cap_setgid,cap_setuid-ep /bin/bashdev@ubuntu:~$ getcap /bin/bash/bin/bash =#--------------------------第一个shell窗口----------------------#回到第一个窗口，id已经变成0了，说明映射成功nobody@ubuntu:~$ iduid=0(root) gid=0(root) groups=0(root),65534(nogroup)#--------------------------第二个shell窗口----------------------#回到第二个窗口，确认map文件的owner，这里24126是新user namespace中的bashdev@ubuntu:~$ ls -l /proc/24126/......-rw-r--r-- 1 dev dev 0 7月  24 23:13 gid_mapdr-x--x--x 2 dev dev 0 7月  24 23:10 ns-rw-r--r-- 1 dev dev 0 7月  24 23:13 uid_map......#--------------------------第一个shell窗口----------------------#重新加载bash，提示有root权限了nobody@ubuntu:~$ exec bashroot@ubuntu:~##0000003fffffffff表示当前运行的bash拥有所有的capabilityroot@ubuntu:~# cat /proc/$$/status | egrep 'Cap(Inh|Prm|Eff)'CapInh: 0000000000000000CapPrm: 0000003fffffffffCapEff: 0000003fffffffff#--------------------------第二个shell窗口----------------------#回到第二个窗口，发现owner已经变了，变成了root#目前还不清楚为什么有这样的机制dev@ubuntu:~$ ls -l /proc/24126/......-rw-r--r-- 1 root root 0 7月  24 23:13 gid_mapdr-x--x--x 2 root root 0 7月  24 23:10 ns-rw-r--r-- 1 root root 0 7月  24 23:13 uid_map......#虽然不能看目录里有哪些文件，但是可以读里面文件的内容dev@ubuntu:~$ ls -l /proc/24126/nsls: cannot open directory '/proc/24126/ns': Permission denieddev@ubuntu:~$ readlink /proc/24126/ns/useruser:[4026532464]#--------------------------第一个shell窗口----------------------#和第二个窗口一样的结果root@ubuntu:~# ls -l /proc/24126/nsls: cannot open directory '/proc/24126/ns': Permission deniedroot@ubuntu:~# readlink /proc/24126/ns/useruser:[4026532464]#仍然不能访问/root目录，因为他的拥有着是nobodyroot@ubuntu:~# ls -l /|grep rootdrwx------   3 nobody nogroup  4096 7月   8 18:39 rootroot@ubuntu:~# ls /rootls: cannot open directory '/root': Permission denied#对于原来/home/dev下的内容，显示的owner已经映射过来了，由dev变成了新namespace中的root，#当前root用户可以访问他里面的内容root@ubuntu:~# ls -l /homedrwxr-xr-x 8 root root 4096 7月  21 18:35 devroot@ubuntu:~# touch /home/dev/temp01root@ubuntu:~##试试设置主机名称root@ubuntu:~# hostname container001hostname: you must be root to change the host name#修改失败，说明这个新user namespace中的root账号在父user namespace里面不好使#这也正是user namespace所期望达到的效果，当访问其他user namespace里的资源时，#是以其他user namespace中的相应账号的权限来执行的，#比如这里root对应父user namespace的账号是dev，所以改不了系统的hostname</code></pre><p>那是不是把系统默认user namespace的root账号映射到新的user namespace中，新user namespace的root就可以修改默认user namespace中的hostname呢？</p><pre><code>#--------------------------第三个shell窗口----------------------#重新打开一个窗口#这里不再手动映射uid和gid，而是利用unshare命令的-r参数来帮我们完成映射，#指定-r参数后，unshare将会帮助我们将当前运行unshare的账号映射成新user namesapce的root账号#这里用了sudo，目的是让root账号来运行unshare命令，#这样就将外面的root账号映射成新user namespace的root账号dev@ubuntu:~$ sudo unshare --user -r /bin/bashroot@ubuntu:~# iduid=0(root) gid=0(root) groups=0(root)#确认是用root映射rootroot@ubuntu:~# echo $$24283root@ubuntu:~# cat /proc/24283/uid_map         0          0          1root@ubuntu:~# cat /proc/24283/gid_map         0          0          1#可以访问/root目录下的东西，但无法操作/home/dev/下的文件root@ubuntu:~# ls -l / |grep root$drwx------   6 root root  4096 8月  14 23:11 rootroot@ubuntu:~# touch /root/temp01root@ubuntu:~# ls -l /homedrwxr-xr-x 11 nobody nogroup 4096 8月  14 23:13 devroot@ubuntu:~# touch /home/dev/temp01touch: cannot touch '/home/dev/temp01': Permission denied#尝试修改hostname，还是失败root@ubuntu:~# hostname container001hostname: you must be root to change the host name</code></pre><p>上面的例子中虽然是将root账号映射到了新user namespace的root账号上，但修改hostname、访问/home/dev下的文件依然失败，那是因为不管怎么映射，当用子user namespace的账号访问父user namespace的资源的时候，它启动的进程的capability都为空，所以这里子user namespace的root账号到父namespace中就相当于一个普通的账号。</p><p>**注意：**对于map文件来说，在父user namespace和子user namespac中打开子user namespace中进程的这个文件看到的都是同样的内容，但如果是在其他的user namespace中打开这个map文件，‘ID-outside-ns’表示的就是映射到当前user namespace的ID.这里听起来有点绕，看下面的例子</p><pre><code>#--------------------------打开一个新窗口----------------------#创建一个新的user namespace，并取名container001dev@ubuntu:~$ unshare --user --uts -r /bin/bashroot@ubuntu:~# hostname container001root@ubuntu:~# exec bash#记下bash的pidroot@container001:~# echo $$27898#在container001里面创建新的namespace container002root@container001:~# unshare --user --uts -r /bin/bashroot@container001:~# hostname container002root@container001:~# exec bash#记下bash的pidroot@container002:~# echo $$28066#查看自己namespace中进程的uid map文件#这里表示父user namespace的0映射到了当前namespace的0root@container002:~# cat /proc/28066/uid_map         0          0          1#--------------------------再打开一个新窗口----------------------#在系统默认namespace中查看同样这个文件，发现和上面的显示的不一样#因为默认namespace是container002的爷爷，所以他们两个里面看到的东西有可能不一样#这里表示当前user namespace的账号1000映射到了进程28066所在user namespace的账号0#当然如果上面是用root账号创建的container001，这里显示的内容就和上面一样了dev@ubuntu:~$ cat /proc/28066/uid_map         0       1000          1#我们再进入到container001，在里面看看这个文件，发现和在ontainer002看到的结果一样#说明对于进程28066来说，在他自己所在的user namespace和他的父user namespace看到的map文件内容是一样的dev@ubuntu:~$ nsenter --user --uts -t 27898 --preserve-credentials bashroot@container001:~# cat /proc/28066/uid_map         0          0          1#默认情况下，nsenter会调用setgroups函数去掉root group的权限，#这里--preserve-credentials是为了让nsenter不调用setgroups函数，因为调用这个函数需要root权限#测试完成后可以关闭这两个窗口，后面不会再用到了</code></pre><h2 id="user-namespace的owner"><a class="header-anchor" href="#user-namespace的owner">¶</a>user namespace的owner</h2><p>当一个用户创建一个新的user namespace的时候，这个用户就是这个新user namespace的owner，在父user namespace的这个用户就会拥有新user namespace及其所有子孙user namespace的所有capabilities.</p><pre><code>#--------------------------第四个shell窗口----------------------#新建用户test用于测试dev@ubuntu:~$ sudo useradd testdev@ubuntu:~$ sudo passwd testEnter new UNIX password:Retype new UNIX password:passwd: password updated successfully#切换到test账户并创建新的user namespace#为了便于区分，同时创建新的uts namespacedev@ubuntu:~$ su testPassword:test@ubuntu:/home/dev$ unshare --user --uts -r /bin/bash#设置一个容易区分的hostnameroot@ubuntu:/home/dev# hostname container001root@ubuntu:/home/dev# exec bashroot@container001:/home/dev# readlink /proc/$$/ns/useruser:[4026532463]root@container001:/home/dev# echo $$24419#--------------------------第五个shell窗口----------------------#使用dev账号新建一个user namespacedev@ubuntu:~$ unshare --user --uts -r /bin/bashroot@ubuntu:~# hostname container002root@ubuntu:~# exec bashroot@container002:~# readlink /proc/$$/ns/useruser:[4026532464]root@container002:~# echo $$24435#--------------------------第六个shell窗口----------------------#用dev账号往container002中加入新的进程/bin/bash成功，因为dev是container002的ownerdev@ubuntu:~$ nsenter --user -t 24435 --preserve-credentials --uts /bin/bashroot@container002:~# iduid=0(root) gid=0(root) groups=0(root),65534(nogroup)root@container002:~# readlink /proc/$$/ns/useruser:[4026532464]#回到默认user namespaceroot@container002:~# exitexitdev@ubuntu:~$#因为container001的owner是test，用dev账号往container001中加入新的进程/bin/bash失败dev@ubuntu:~$ nsenter --user -t 24419 --preserve-credentials --uts /bin/bashnsenter: cannot open /proc/24419/ns/user: Permission denied#用root账号往container001中加入新的进程/bin/bash成功dev@ubuntu:~$ sudo nsenter --user -t 24419 --preserve-credentials --uts /bin/bashnobody@container001:~$ readlink /proc/$$/ns/useruser:[4026532463]#由于root账号没有映射到container001中，所以这里在container001中看到的账号是nobodynobody@container001:~$ iduid=65534(nobody) gid=65534(nogroup) groups=65534(nogroup)#退出container001，便于后续测试nobody@container001:~$ exitdev@ubuntu:~$#--------------------------第五个shell窗口----------------------#回到第5个窗口，继续创建一个新的user namespaceroot@container002:~# unshare --user --uts -r /bin/bashroot@container002:~# hostname container003root@container002:~# exec bashroot@container003:~# readlink /proc/$$/ns/useruser:[4026532471]root@container003:~# echo $$24533#--------------------------第六个shell窗口----------------------#回到第6个窗口，用dev账号往container003（孙子user namespace）中加入新的bash进程，成功，#说明dev拥有孙子user namespace的capabilitiesdev@ubuntu:~$ nsenter --user -t 24533 --preserve-credentials --uts /bin/bashroot@container003:~# readlink /proc/$$/ns/useruser:[4026532471]</code></pre><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>本文先介绍了user namespace的一些概念，然后介绍如何配置mapping文件，最后介绍了user namespace的owner。从上面的介绍中可以看出，user namespace还是比较复杂的，要了解user namespace，需要对Linux下的权限有一个基本的了解。下一篇中将继续介绍user namespace和其他namespace的关系，以及一些其他的注意事项。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="http://man7.org/linux/man-pages/man7/user_namespaces.7.html" target="_blank" rel="noopener">user namespaces man page</a></li><li><a href="https://lwn.net/Articles/532593/" target="_blank" rel="noopener">Namespaces in operation, part 5: User namespaces</a></li><li><a href="https://lwn.net/Articles/540087/" target="_blank" rel="noopener">Namespaces in operation, part 6: more on user namespaces</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> namespace </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux网络-数据包接收过程</title>
      <link href="/2020/02/16/linux/network/linux-wang-luo-shu-ju-bao-jie-shou-guo-cheng/"/>
      <url>/2020/02/16/linux/network/linux-wang-luo-shu-ju-bao-jie-shou-guo-cheng/</url>
      
        <content type="html"><![CDATA[<p>本文将介绍在Linux系统中，数据包是如何一步一步从网卡传到进程手中的。</p><p>如果英文没有问题，强烈建议阅读后面参考里的两篇文章，里面介绍的更详细。</p><p>本文只讨论以太网的物理网卡，不涉及虚拟设备，并且以一个UDP包的接收过程作为示例.</p><blockquote><p>本示例里列出的函数调用关系来自于kernel 3.13.0，如果你的内核不是这个版本，函数名称和相关路径可能不一样，但背后的原理应该是一样的（或者有细微差别）</p></blockquote><h2 id="网卡到内存"><a class="header-anchor" href="#网卡到内存">¶</a>网卡到内存</h2><p>网卡需要有驱动才能工作，驱动是加载到内核中的模块，负责衔接网卡和内核的网络模块，驱动在加载的时候将自己注册进网络模块，当相应的网卡收到数据包时，网络模块会调用相应的驱动程序处理数据。</p><p>下图展示了数据包（packet）如何进入内存，并被内核的网络模块开始处理：</p><pre><code>                   +-----+                   |     |                            Memroy+--------+   1     |     |  2  DMA     +--------+--------+--------+--------+| Packet |--------&gt;| NIC |------------&gt;| Packet | Packet | Packet | ...... |+--------+         |     |             +--------+--------+--------+--------+                   |     |&lt;--------+                   +-----+         |                      |            +---------------+                      |                            |                    3 | Raise IRQ                  | Disable IRQ                      |                          5 |                      |                            |                      ↓                            |                   +-----+                   +------------+                   |     |  Run IRQ handler  |            |                   | CPU |------------------&gt;| NIC Driver |                   |     |       4           |            |                   +-----+                   +------------+                                                   |                                                6  | Raise soft IRQ                                                   |                                                   ↓</code></pre><ul><li><strong>1：</strong> 数据包从外面的网络进入物理网卡。如果目的地址不是该网卡，且该网卡没有开启混杂模式，该包会被网卡丢弃。</li><li><strong>2：</strong> 网卡将数据包通过<a href="https://en.wikipedia.org/wiki/Direct_memory_access" target="_blank" rel="noopener">DMA</a>的方式写入到指定的内存地址，该地址由网卡驱动分配并初始化。注： 老的网卡可能不支持DMA，不过新的网卡一般都支持。</li><li><strong>3：</strong> 网卡通过硬件中断（IRQ）通知CPU，告诉它有数据来了</li><li><strong>4：</strong> CPU根据中断表，调用已经注册的中断函数，这个中断函数会调到驱动程序（NIC Driver）中相应的函数</li><li><strong>5：</strong> 驱动先禁用网卡的中断，表示驱动程序已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知CPU了，这样可以提高效率，避免CPU不停的被中断。</li><li><strong>6：</strong> 启动软中断。这步结束后，硬件中断处理函数就结束返回了。由于硬中断处理程序执行的过程中不能被中断，所以如果它执行时间过长，会导致CPU没法响应其它硬件的中断，于是内核引入软中断，这样可以将硬中断处理函数中耗时的部分移到软中断处理函数里面来慢慢处理。</li></ul><h2 id="内核的网络模块"><a class="header-anchor" href="#内核的网络模块">¶</a>内核的网络模块</h2><p>软中断会触发内核网络模块中的软中断处理函数，后续流程如下</p><pre><code>                                                     +-----+                                             17      |     |                                        +-----------&gt;| NIC |                                        |            |     |                                        |Enable IRQ  +-----+                                        |                                        |                                  +------------+                                      Memroy                                  |            |        Read           +--------+--------+--------+--------+                 +---------------&gt;| NIC Driver |&lt;--------------------- | Packet | Packet | Packet | ...... |                 |                |            |          9            +--------+--------+--------+--------+                 |                +------------+                 |                      |    |        skb            Poll | 8      Raise softIRQ | 6  +-----------------+                 |                      |             10       |                 |                      ↓                      ↓         +---------------+  Call  +-----------+        +------------------+        +--------------------+  12  +---------------------+         | net_rx_action |&lt;-------| ksoftirqd |        | napi_gro_receive |-------&gt;| enqueue_to_backlog |-----&gt;| CPU input_pkt_queue |         +---------------+   7    +-----------+        +------------------+   11   +--------------------+      +---------------------+                                                               |                                                      | 13                                                            14 |        + - - - - - - - - - - - - - - - - - - - - - - +                                                               ↓        ↓                                                    +--------------------------+    15      +------------------------+                                                    | __netif_receive_skb_core |-----------&gt;| packet taps(AF_PACKET) |                                                    +--------------------------+            +------------------------+                                                               |                                                               | 16                                                               ↓                                                      +-----------------+                                                      | protocol layers |                                                      +-----------------+</code></pre><ul><li><strong>7：</strong> 内核中的ksoftirqd进程专门负责软中断的处理，当它收到软中断后，就会调用相应软中断所对应的处理函数，对于上面第6步中是网卡驱动模块抛出的软中断，ksoftirqd会调用网络模块的net_rx_action函数</li><li><strong>8：</strong> net_rx_action调用网卡驱动里的poll函数来一个一个的处理数据包</li><li><strong>9：</strong> 在pool函数中，驱动会一个接一个的读取网卡写到内存中的数据包，内存中数据包的格式只有驱动知道</li><li><strong>10：</strong> 驱动程序将内存中的数据包转换成内核网络模块能识别的skb格式，然后调用napi_gro_receive函数</li><li><strong>11：</strong> napi_gro_receive会处理<a href="https://lwn.net/Articles/358910/" target="_blank" rel="noopener">GRO</a>相关的内容，也就是将可以合并的数据包进行合并，这样就只需要调用一次协议栈。然后判断是否开启了<a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/scaling.txt#L99-L222" target="_blank" rel="noopener">RPS</a>，如果开启了，将会调用enqueue_to_backlog</li><li><strong>12：</strong> 在enqueue_to_backlog函数中，会将数据包放入CPU的softnet_data结构体的input_pkt_queue中，然后返回，如果input_pkt_queue满了的话，该数据包将会被丢弃，queue的大小可以通过net.core.netdev_max_backlog来配置</li><li><strong>13：</strong> CPU会接着在自己的软中断上下文中处理自己input_pkt_queue里的网络数据（调用__netif_receive_skb_core）</li><li><strong>14：</strong> 如果没开启<a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/scaling.txt#L99-L222" target="_blank" rel="noopener">RPS</a>，napi_gro_receive会直接调用__netif_receive_skb_core</li><li><strong>15：</strong> 看是不是有AF_PACKET类型的socket（也就是我们常说的原始套接字），如果有的话，拷贝一份数据给它。tcpdump抓包就是抓的这里的包。</li><li><strong>16：</strong> 调用协议栈相应的函数，将数据包交给协议栈处理。</li><li><strong>17：</strong> 待内存中的所有数据包被处理完成后（即poll函数执行完成），启用网卡的硬中断，这样下次网卡再收到数据的时候就会通知CPU</li></ul><blockquote><p>enqueue_to_backlog函数也会被netif_rx函数调用，而netif_rx正是lo设备发送数据包时调用的函数</p></blockquote><h2 id="协议栈"><a class="header-anchor" href="#协议栈">¶</a>协议栈</h2><h3 id="IP层"><a class="header-anchor" href="#IP层">¶</a>IP层</h3><p>由于是UDP包，所以第一步会进入IP层，然后一级一级的函数往下调：</p><pre><code>          |          |          ↓         promiscuous mode &amp;&amp;      +--------+    PACKET_OTHERHOST (set by driver)   +-----------------+      | ip_rcv |--------------------------------------&gt;| drop this packet|      +--------+                                       +-----------------+          |          |          ↓+---------------------+| NF_INET_PRE_ROUTING |+---------------------+          |          |          ↓      +---------+      |         | enabled ip forword  +------------+        +----------------+      | routing |--------------------&gt;| ip_forward |-------&gt;| NF_INET_FORWARD |      |         |                     +------------+        +----------------+      +---------+                                                   |          |                                                         |          | destination IP is local                                 ↓          ↓                                                 +---------------+ +------------------+                                       | dst_output_sk | | ip_local_deliver |                                       +---------------+ +------------------+          |          |          ↓ +------------------+ | NF_INET_LOCAL_IN | +------------------+          |          |          ↓    +-----------+    | UDP layer |    +-----------+</code></pre><ul><li><strong>ip_rcv：</strong> ip_rcv函数是IP模块的入口函数，在该函数里面，第一件事就是将垃圾数据包（目的mac地址不是当前网卡，但由于网卡设置了混杂模式而被接收进来）直接丢掉，然后调用注册在NF_INET_PRE_ROUTING上的函数</li><li><strong>NF_INET_PRE_ROUTING：</strong> netfilter放在协议栈中的钩子，可以通过iptables来注入一些数据包处理函数，用来修改或者丢弃数据包，如果数据包没被丢弃，将继续往下走</li><li><strong>routing：</strong> 进行路由，如果是目的IP不是本地IP，且没有开启ip forward功能，那么数据包将被丢弃，如果开启了ip forward功能，那将进入ip_forward函数</li><li><strong>ip_forward：</strong> ip_forward会先调用netfilter注册的NF_INET_FORWARD相关函数，如果数据包没有被丢弃，那么将继续往后调用dst_output_sk函数</li><li><strong>dst_output_sk：</strong> 该函数会调用IP层的相应函数将该数据包发送出去，同下一篇要介绍的数据包发送流程的后半部分一样。</li><li><strong>ip_local_deliver</strong>：如果上面<strong>routing</strong>的时候发现目的IP是本地IP，那么将会调用该函数，在该函数中，会先调用NF_INET_LOCAL_IN相关的钩子程序，如果通过，数据包将会向下发送到UDP层</li></ul><h3 id="UDP层"><a class="header-anchor" href="#UDP层">¶</a>UDP层</h3><pre><code>          |          |          ↓      +---------+            +-----------------------+      | udp_rcv |-----------&gt;| __udp4_lib_lookup_skb |      +---------+            +-----------------------+          |          |          ↓ +--------------------+      +-----------+ | sock_queue_rcv_skb |-----&gt;| sk_filter | +--------------------+      +-----------+          |          |          ↓ +------------------+ | __skb_queue_tail | +------------------+          |          |          ↓  +---------------+  | sk_data_ready |  +---------------+</code></pre><ul><li><strong>udp_rcv：</strong> udp_rcv函数是UDP模块的入口函数，它里面会调用其它的函数，主要是做一些必要的检查，其中一个重要的调用是__udp4_lib_lookup_skb，该函数会根据目的IP和端口找对应的socket，如果没有找到相应的socket，那么该数据包将会被丢弃，否则继续</li><li><strong>sock_queue_rcv_skb：</strong> 主要干了两件事，一是<strong>检查这个socket的receive buffer是不是满了，如果满了的话，丢弃该数据包</strong>，然后就是调用sk_filter看这个包是否是满足条件的包，<strong>如果当前socket上设置了<a href="https://www.kernel.org/doc/Documentation/networking/filter.txt" target="_blank" rel="noopener">filter</a>，且该包不满足条件的话，这个数据包也将被丢弃</strong>（在Linux里面，每个socket上都可以像tcpdump里面一样定义<a href="https://www.kernel.org/doc/Documentation/networking/filter.txt" target="_blank" rel="noopener">filter</a>，不满足条件的数据包将会被丢弃）</li><li><strong>__skb_queue_tail：</strong> 将数据包放入socket接收队列的末尾</li><li><strong>sk_data_ready：</strong> 通知socket数据包已经准备好</li></ul><blockquote><p>调用完sk_data_ready之后，一个数据包处理完成，等待应用层程序来读取，上面所有函数的执行过程都在软中断的上下文中。</p></blockquote><h2 id="socket"><a class="header-anchor" href="#socket">¶</a>socket</h2><p>应用层一般有两种方式接收数据，一种是recvfrom函数阻塞在那里等着数据来，这种情况下当socket收到通知后，recvfrom就会被唤醒，然后读取接收队列的数据；另一种是通过epoll或者select监听相应的socket，当收到通知后，再调用recvfrom函数去读取接收队列的数据。两种情况都能正常的接收到相应的数据包。</p><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>了解数据包的接收流程有助于帮助我们搞清楚我们可以在哪些地方监控和修改数据包，哪些情况下数据包可能被丢弃，为我们处理网络问题提供了一些参考，同时了解netfilter中相应钩子的位置，对于了解iptables的用法有一定的帮助，同时也会帮助我们后续更好的理解Linux下的网络虚拟设备。</p><p>在接下来的几篇文章中，将会介绍Linux下的网络虚拟设备和iptables。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><p><a href="https://blog.packagecloud.io/eng/2016/06/22/monitoring-tuning-linux-networking-stack-receiving-data/" target="_blank" rel="noopener">Monitoring and Tuning the Linux Networking Stack: Receiving Data</a><br><a href="https://blog.packagecloud.io/eng/2016/10/11/monitoring-tuning-linux-networking-stack-receiving-data-illustrated/" target="_blank" rel="noopener">Illustrated Guide to Monitoring and Tuning the Linux Networking Stack: Receiving Data</a><br><a href="https://wiki.linuxfoundation.org/networking/napi" target="_blank" rel="noopener">NAPI</a></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux网络-数据包发送过程</title>
      <link href="/2020/02/16/linux/network/linux-wang-luo-shu-ju-bao-fa-song-guo-cheng/"/>
      <url>/2020/02/16/linux/network/linux-wang-luo-shu-ju-bao-fa-song-guo-cheng/</url>
      
        <content type="html"><![CDATA[<p>继上一篇介绍了<a href="https://segmentfault.com/a/1190000008836467" target="_blank" rel="noopener">数据包的接收过程</a>后，本文将介绍在Linux系统中，数据包是如何一步一步从应用程序到网卡并最终发送出去的。</p><p>如果英文没有问题，强烈建议阅读后面参考里的文章，里面介绍的更详细。</p><blockquote><p>本文只讨论以太网的物理网卡，并且以一个UDP包的发送过程作为示例，由于本人对协议栈的代码不熟，有些地方可能理解有误，欢迎指正</p></blockquote><h2 id="socket层"><a class="header-anchor" href="#socket层">¶</a>socket层</h2><pre><code>               +-------------+               | Application |               +-------------+                     |                     |                     ↓+------------------------------------------+| socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP) |+------------------------------------------+                     |                     |                     ↓           +-------------------+           | sendto(sock, ...) |           +-------------------+                     |                     |                     ↓              +--------------+              | inet_sendmsg |              +--------------+                     |                     |                     ↓             +---------------+             | inet_autobind |             +---------------+                     |                     |                     ↓               +-----------+               | UDP layer |               +-----------+</code></pre><ul><li><strong>socket(…)：</strong> 创建一个socket结构体，并初始化相应的操作函数，由于我们定义的是UDP的socket，所以里面存放的都是跟UDP相关的函数</li><li><strong>sendto(sock, …)：</strong> 应用层的程序（Application）调用该函数开始发送数据包，该函数数会调用后面的inet_sendmsg</li><li><strong>inet_sendmsg：</strong> 该函数主要是检查当前socket有没有绑定源端口，如果没有的话，调用inet_autobind分配一个，然后调用UDP层的函数</li><li><strong>inet_autobind：</strong> 该函数会调用socket上绑定的get_port函数获取一个可用的端口，由于该socket是UDP的socket，所以get_port函数会调到UDP代码里面的相应函数。</li></ul><h2 id="UDP层"><a class="header-anchor" href="#UDP层">¶</a>UDP层</h2><pre><code>                     |                     |                     ↓              +-------------+              | udp_sendmsg |              +-------------+                     |                     |                     ↓          +----------------------+          | ip_route_output_flow |          +----------------------+                     |                     |                     ↓              +-------------+              | ip_make_skb |              +-------------+                     |                     |                     ↓         +------------------------+         | udp_send_skb(skb, fl4) |         +------------------------+                     |                     |                     ↓                +----------+                | IP layer |                +----------+</code></pre><ul><li><strong>udp_sendmsg：</strong> udp模块发送数据包的入口，该函数较长，在该函数中会先调用ip_route_output_flow获取路由信息（主要包括源IP和网卡），然后调用ip_make_skb构造skb结构体，最后将网卡的信息和该skb关联。</li><li><strong>ip_route_output_flow：</strong> 该函数会根据路由表和目的IP，找到这个数据包应该从哪个设备发送出去，如果该socket没有绑定源IP，该函数还会根据路由表找到一个最合适的源IP给它。 如果该socket已经绑定了源IP，但根据路由表，从这个源IP对应的网卡没法到达目的地址，则该包会被丢弃，于是数据发送失败，sendto函数将返回错误。该函数最后会将找到的设备和源IP塞进flowi4结构体并返回给udp_sendmsg</li><li><strong>ip_make_skb：</strong> 该函数的功能是构造skb包，构造好的skb包里面已经分配了IP包头，并且初始化了部分信息（IP包头的源IP就在这里被设置进去），同时该函数会调用__ip_append_dat，如果需要分片的话，会在__ip_append_data函数中进行分片，同时还会在该函数中检查socket的send buffer是否已经用光，如果被用光的话，返回ENOBUFS</li><li><strong>udp_send_skb(skb, fl4)</strong> 主要是往skb里面填充UDP的包头，同时处理checksum，然后调用IP层的相应函数。</li></ul><h2 id="IP层"><a class="header-anchor" href="#IP层">¶</a>IP层</h2><pre><code>          |          |          ↓   +-------------+   | ip_send_skb |   +-------------+          |          |          ↓  +-------------------+       +-------------------+       +---------------+  | __ip_local_out_sk |------&gt;| NF_INET_LOCAL_OUT |------&gt;| dst_output_sk |  +-------------------+       +-------------------+       +---------------+                                                                  |                                                                  |                                                                  ↓ +------------------+        +----------------------+       +-----------+ | ip_finish_output |&lt;-------| NF_INET_POST_ROUTING |&lt;------| ip_output | +------------------+        +----------------------+       +-----------+          |          |          ↓  +-------------------+      +------------------+       +----------------------+  | ip_finish_output2 |-----&gt;| dst_neigh_output |------&gt;| neigh_resolve_output |  +-------------------+      +------------------+       +----------------------+                                                                   |                                                                   |                                                                   ↓                                                           +----------------+                                                           | dev_queue_xmit |                                                           +----------------+</code></pre><ul><li><strong>ip_send_skb：</strong> IP模块发送数据包的入口，该函数只是简单的调用一下后面的函数</li><li><strong>__ip_local_out_sk：</strong> 设置IP报文头的长度和checksum，然后调用下面netfilter的钩子</li><li><strong>NF_INET_LOCAL_OUT：</strong> netfilter的钩子，可以通过iptables来配置怎么处理该数据包，如果该数据包没被丢弃，则继续往下走</li><li><strong>dst_output_sk：</strong> 该函数根据skb里面的信息，调用相应的output函数，在我们UDP IPv4这种情况下，会调用ip_output</li><li><strong>ip_output：</strong> 将上面udp_sendmsg得到的网卡信息写入skb，然后调用NF_INET_POST_ROUTING的钩子</li><li><strong>NF_INET_POST_ROUTING：</strong> 在这里，用户有可能配置了SNAT，从而导致该skb的路由信息发生变化</li><li><strong>ip_finish_output：</strong> 这里会判断经过了上一步后，路由信息是否发生变化，如果发生变化的话，需要重新调用dst_output_sk（重新调用这个函数时，可能就不会再走到ip_output，而是走到被netfilter指定的output函数里，这里有可能是xfrm4_transport_output），否则往下走</li><li><strong>ip_finish_output2：</strong> 根据目的IP到路由表里面找到下一跳(nexthop)的地址，然后调用__ipv4_neigh_lookup_noref去arp表里面找下一跳的neigh信息，没找到的话会调用__neigh_create构造一个空的neigh结构体</li><li><strong>dst_neigh_output：</strong> 在该函数中，如果上一步ip_finish_output2没得到neigh信息，那么将会走到函数neigh_resolve_output中，否则直接调用neigh_hh_output，在该函数中，会将neigh信息里面的mac地址填到skb中，然后调用dev_queue_xmit发送数据包</li><li><strong>neigh_resolve_output：</strong> 该函数里面会发送arp请求，得到下一跳的mac地址，然后将mac地址填到skb中并调用dev_queue_xmit</li></ul><h2 id="netdevice子系统"><a class="header-anchor" href="#netdevice子系统">¶</a>netdevice子系统</h2><pre><code>                          |                          |                          ↓                   +----------------+  +----------------| dev_queue_xmit |  |                +----------------+  |                       |  |                       |  |                       ↓  |              +-----------------+  |              | Traffic Control |  |              +-----------------+  | loopback              |  |   or                  +--------------------------------------------------------------+  | IP tunnels            ↓                                                              |  |                       ↓                                                              |  |            +---------------------+  Failed   +----------------------+         +---------------+  +-----------&gt;| dev_hard_start_xmit |----------&gt;| raise NET_TX_SOFTIRQ |- - - - &gt;| net_tx_action |               +---------------------+           +----------------------+         +---------------+                          |                          +----------------------------------+                          |                                  |                          ↓                                  ↓                  +----------------+              +------------------------+                  | ndo_start_xmit |              | packet taps(AF_PACKET) |                  +----------------+              +------------------------+</code></pre><ul><li><strong>dev_queue_xmit：</strong> netdevice子系统的入口函数，在该函数中，会先获取设备对应的qdisc，如果没有的话（如loopback或者IP tunnels），就直接调用dev_hard_start_xmit，否则数据包将经过<a href="http://tldp.org/HOWTO/Traffic-Control-HOWTO/intro.html" target="_blank" rel="noopener">Traffic Control</a>模块进行处理</li><li><strong>Traffic Control：</strong> 这里主要是进行一些过滤和优先级处理，在这里，如果队列满了的话，数据包会被丢掉，详情请参考<a href="http://tldp.org/HOWTO/Traffic-Control-HOWTO/intro.html" target="_blank" rel="noopener">文档</a>，这步完成后也会走到dev_hard_start_xmit</li><li><strong>dev_hard_start_xmit：</strong> 该函数中，首先是拷贝一份skb给“packet taps”，tcpdump就是从这里得到数据的，然后调用ndo_start_xmit。如果dev_hard_start_xmit返回错误的话（大部分情况可能是NETDEV_TX_BUSY），调用它的函数会把skb放到一个地方，然后抛出软中断NET_TX_SOFTIRQ，交给软中断处理程序net_tx_action稍后重试（如果是loopback或者IP tunnels的话，失败后不会有重试的逻辑）</li><li><strong>ndo_start_xmit：</strong> 这是一个函数指针，会指向具体驱动发送数据的函数</li></ul><h2 id="Device-Driver"><a class="header-anchor" href="#Device-Driver">¶</a>Device Driver</h2><p>ndo_start_xmit会绑定到具体网卡驱动的相应函数，到这步之后，就归网卡驱动管了，不同的网卡驱动有不同的处理方式，这里不做详细介绍，其大概流程如下：</p><ol><li>将skb放入网卡自己的发送队列</li><li>通知网卡发送数据包</li><li>网卡发送完成后发送中断给CPU</li><li>收到中断后进行skb的清理工作</li></ol><p>在网卡驱动发送数据包过程中，会有一些地方需要和netdevice子系统打交道，比如网卡的队列满了，需要告诉上层不要再发了，等队列有空闲的时候，再通知上层接着发数据。</p><h2 id="其它"><a class="header-anchor" href="#其它">¶</a>其它</h2><ul><li><strong>SO_SNDBUF:</strong> 从上面的流程中可以看出来，对于UDP来说，没有一个对应send buffer存在，SO_SNDBUF只是一个限制，当这个socket分配的skb占用的内存超过这个值的时候，会返回ENOBUFS，所以说只要不出现ENOBUFS错误，把这个值调大没有意义。从sendto函数的帮助文件里面看到这样一句话：(Normally, this does not occur in Linux. Packets are just silently dropped when a device queue overflows.)。这里的device queue应该指的是Traffic Control里面的queue，说明在linux里面，默认的SO_SNDBUF值已经够queue用了，疑问的地方是，queue的长度和个数是可以配置的，如果配置太大的话，按道理应该有可能会出现ENOBUFS的情况。</li><li><strong>txqueuelen:</strong> 很多地方都说这个是控制qdisc里queue的长度的，但貌似只是部分类型的qdisc用了该配置，如linux默认的pfifo_fast。</li><li><strong>hardware RX:</strong> 一般网卡都有一个自己的ring queue，这个queue的大小可以通过ethtool来配置，当驱动收到发送请求时，一般是放到这个queue里面，然后通知网卡发送数据，当这个queue满的时候，会给上层调用返回NETDEV_TX_BUSY</li><li><strong>packet taps(AF_PACKET):</strong> 当第一次发送数据包和重试发送数据包时，都会经过这里，如果发生重试的情况的话，不确定tcpdump是否会抓到两次包，按道理应该不会，可能是我哪里没看懂</li></ul><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://blog.packagecloud.io/eng/2017/02/06/monitoring-tuning-linux-networking-stack-sending-data/" target="_blank" rel="noopener">Monitoring and Tuning the Linux Networking Stack: Sending Data</a></li><li><a href="https://www.coverfire.com/articles/queueing-in-the-linux-network-stack/" target="_blank" rel="noopener">queueing in the linux network stack</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux虚拟网络设备之bridge(桥)</title>
      <link href="/2020/02/16/linux/network/linux-xu-ni-wang-luo-she-bei-zhi-bridge-qiao/"/>
      <url>/2020/02/16/linux/network/linux-xu-ni-wang-luo-she-bei-zhi-bridge-qiao/</url>
      
        <content type="html"><![CDATA[<p>继前两篇介绍了<a href="https://segmentfault.com/a/1190000009249039" target="_blank" rel="noopener">tun/tap</a>和<a href="https://segmentfault.com/a/1190000009251098" target="_blank" rel="noopener">veth</a>之后，本篇将介绍Linux下常用的一种虚拟网络设备，那就是bridge(桥)。</p><p>本篇将通过实际的例子来一步一步解释bridge是如何工作的。</p><h2 id="什么是bridge？"><a class="header-anchor" href="#什么是bridge？">¶</a>什么是bridge？</h2><p>首先，bridge是一个虚拟网络设备，所以具有网络设备的特征，可以配置IP、MAC地址等；其次，bridge是一个虚拟交换机，和物理交换机有类似的功能。</p><p>对于普通的网络设备来说，只有两端，从一端进来的数据会从另一端出去，如物理网卡从外面网络中收到的数据会转发给内核协议栈，而从协议栈过来的数据会转发到外面的物理网络中。</p><p>而bridge不同，bridge有多个端口，数据可以从任何端口进来，进来之后从哪个口出去和物理交换机的原理差不多，要看mac地址。</p><h2 id="创建bridge"><a class="header-anchor" href="#创建bridge">¶</a>创建bridge</h2><p>我们先用iproute2创建一个bridge：</p><pre><code>dev@debian:~$ sudo ip link add name br0 type bridgedev@debian:~$ sudo ip link set br0 up</code></pre><p>当刚创建一个bridge时，它是一个独立的网络设备，只有一个端口连着协议栈，其它的端口啥都没连，这样的bridge没有任何实际功能，如下图所示：</p><pre><code>+----------------------------------------------------------------+|                                                                ||       +------------------------------------------------+       ||       |             Newwork Protocol Stack             |       ||       +------------------------------------------------+       ||              ↑                                ↑                ||..............|................................|................||              ↓                                ↓                ||        +----------+                     +------------+         ||        |   eth0   |                     |     br0    |         ||        +----------+                     +------------+         || 192.168.3.21 ↑                                                 ||              |                                                 ||              |                                                 |+--------------|-------------------------------------------------+               ↓         Physical Network</code></pre><blockquote><p>这里假设eth0是我们的物理网卡，IP地址是192.168.3.21，网关是192.168.3.1</p></blockquote><h2 id="将bridge和veth设备相连"><a class="header-anchor" href="#将bridge和veth设备相连">¶</a>将bridge和veth设备相连</h2><p>创建一对veth设备，并配置上IP</p><pre><code>dev@debian:~$ sudo ip link add veth0 type veth peer name veth1dev@debian:~$ sudo ip addr add 192.168.3.101/24 dev veth0dev@debian:~$ sudo ip addr add 192.168.3.102/24 dev veth1dev@debian:~$ sudo ip link set veth0 updev@debian:~$ sudo ip link set veth1 up</code></pre><p>将veth0连上br0</p><pre><code>dev@debian:~$ sudo ip link set dev veth0 master br0#通过bridge link命令可以看到br0上连接了哪些设备dev@debian:~$ sudo bridge link6: veth0 state UP : &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 master br0 state forwarding priority 32 cost 2</code></pre><p>这时候，网络就变成了这个样子:</p><pre><code>+----------------------------------------------------------------+|                                                                ||       +------------------------------------------------+       ||       |             Newwork Protocol Stack             |       ||       +------------------------------------------------+       ||            ↑            ↑              |            ↑          ||............|............|..............|............|..........||            ↓            ↓              ↓            ↓          ||        +------+     +--------+     +-------+    +-------+      ||        | .3.21|     |        |     | .3.101|    | .3.102|      ||        +------+     +--------+     +-------+    +-------+      ||        | eth0 |     |   br0  |&lt;---&gt;| veth0 |    | veth1 |      ||        +------+     +--------+     +-------+    +-------+      ||            ↑                           ↑            ↑          ||            |                           |            |          ||            |                           +------------+          ||            |                                                   |+------------|---------------------------------------------------+             ↓     Physical Network</code></pre><blockquote><p>这里为了画图方便，省略了IP地址前面的192.168，比如.3.21就表示192.168.3.21</p></blockquote><p>br0和veth0相连之后，发生了几个变化：</p><ul><li>br0和veth0之间连接起来了，并且是双向的通道</li><li>协议栈和veth0之间变成了单通道，协议栈能发数据给veth0，但veth0从外面收到的数据不会转发给协议栈</li><li>br0的mac地址变成了veth0的mac地址</li></ul><p>相当于bridge在veth0和协议栈之间插了一脚，在veth0上面做了点小动作，将veth0本来要转发给协议栈的数据给拦截了，全部转发给bridge了，同时bridge也可以向veth0发数据。</p><p>下面来检验一下是不是这样的：</p><p>通过veth0 ping veth1失败：</p><pre><code>dev@debian:~$ ping -c 1 -I veth0 192.168.3.102PING 192.168.2.1 (192.168.2.1) from 192.168.2.11 veth0: 56(84) bytes of data.From 192.168.2.11 icmp_seq=1 Destination Host Unreachable--- 192.168.2.1 ping statistics ---1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0ms</code></pre><p>为什么veth0加入了bridge之后，就ping不通veth2了呢？ 先抓包看看：</p><pre><code>#由于veth0的arp缓存里面没有veth1的mac地址，所以ping之前先发arp请求#从veth1上抓包来看，veth1收到了arp请求，并且返回了应答dev@debian:~$ sudo tcpdump -n -i veth1tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytes21:43:48.353509 ARP, Request who-has 192.168.3.102 tell 192.168.3.101, length 2821:43:48.353518 ARP, Reply 192.168.3.102 is-at 26:58:a2:57:37:e9, length 28#从veth0上抓包来看，数据包也发出去了，并且也收到了返回dev@debian:~$ sudo tcpdump -n -i veth0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth0, link-type EN10MB (Ethernet), capture size 262144 bytes21:44:09.775392 ARP, Request who-has 192.168.3.102 tell 192.168.3.101, length 2821:44:09.775400 ARP, Reply 192.168.3.102 is-at 26:58:a2:57:37:e9, length 28#再看br0上的数据包，发现只有应答dev@debian:~$ sudo tcpdump -n -i br0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on br0, link-type EN10MB (Ethernet), capture size 262144 bytes21:45:48.225459 ARP, Reply 192.168.3.102 is-at 26:58:a2:57:37:e9, length 28</code></pre><p>从上面的抓包可以看出，去和回来的流程都没有问题，问题就出在veth0收到应答包后没有给协议栈，而是给了br0，于是协议栈得不到veth1的mac地址，从而通信失败。</p><h2 id="给bridge配上IP"><a class="header-anchor" href="#给bridge配上IP">¶</a>给bridge配上IP</h2><p>通过上面的分析可以看出，给veth0配置IP没有意义，因为就算协议栈传数据包给veth0，应答包也回不来。这里我们就将veth0的IP让给bridge。</p><pre><code>dev@debian:~$ sudo ip addr del 192.168.3.101/24 dev veth0dev@debian:~$ sudo ip addr add 192.168.3.101/24 dev br0</code></pre><p>于是网络变成了这样子：</p><pre><code>+----------------------------------------------------------------+|                                                                ||       +------------------------------------------------+       ||       |             Newwork Protocol Stack             |       ||       +------------------------------------------------+       ||            ↑            ↑                           ↑          ||............|............|...........................|..........||            ↓            ↓                           ↓          ||        +------+     +--------+     +-------+    +-------+      ||        | .3.21|     | .3.101 |     |       |    | .3.102|      ||        +------+     +--------+     +-------+    +-------+      ||        | eth0 |     |   br0  |&lt;---&gt;| veth0 |    | veth1 |      ||        +------+     +--------+     +-------+    +-------+      ||            ↑                           ↑            ↑          ||            |                           |            |          ||            |                           +------------+          ||            |                                                   |+------------|---------------------------------------------------+             ↓     Physical Network</code></pre><blockquote><p>其实veth0和协议栈之间还是有联系的，但由于veth0没有配置IP，所以协议栈在路由的时候不会将数据包发给veth0，就算强制要求数据包通过veth0发送出去，但由于veth0从另一端收到的数据包只会给br0，所以协议栈还是没法收到相应的arp应答包，导致通信失败。<br>这里为了表达更直观，将协议栈和veth0之间的联系去掉了，veth0相当于一根网线。</p></blockquote><p>再通过br0 ping一下veth1，结果成功</p><pre><code>dev@debian:~$ ping -c 1 -I br0 192.168.3.102PING 192.168.3.102 (192.168.3.102) from 192.168.3.101 br0: 56(84) bytes of data.64 bytes from 192.168.3.102: icmp_seq=1 ttl=64 time=0.121 ms--- 192.168.3.102 ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 0.121/0.121/0.121/0.000 ms</code></pre><p>但ping网关还是失败，因为这个bridge上只有两个网络设备，分别是192.168.3.101和192.168.3.102，br0不知道192.168.3.1在哪。</p><pre><code>dev@debian:~$ ping -c 1 -I br0 192.168.3.1PING 192.168.3.1 (192.168.3.1) from 192.168.3.101 br0: 56(84) bytes of data.From 192.168.3.101 icmp_seq=1 Destination Host Unreachable--- 192.168.3.1 ping statistics ---1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0ms</code></pre><h2 id="将物理网卡添加到bridge"><a class="header-anchor" href="#将物理网卡添加到bridge">¶</a>将物理网卡添加到bridge</h2><p>将eth0添加到br0上：</p><pre><code>dev@debian:~$ sudo ip link set dev eth0 master br0dev@debian:~$ sudo bridge link2: eth0 state UP : &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 master br0 state forwarding priority 32 cost 46: veth0 state UP : &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 master br0 state forwarding priority 32 cost 2</code></pre><p>br0根本不区分接入进来的是物理设备还是虚拟设备，对它来说都一样的，都是网络设备，所以当eth0加入br0之后，落得和上面veth0一样的下场，从外面网络收到的数据包将无条件的转发给br0，自己变成了一根网线。</p><p>这时通过eth0来ping网关失败，但由于br0通过eth0这根网线连上了外面的物理交换机，所以连在br0上的设备都能ping通网关，这里连上的设备就是veth1和br0自己，veth1是通过veth0这根网线连上去的，而br0可以理解为自己有一块自带的网卡。</p><pre><code>#通过eth0来ping网关失败dev@debian:~$ ping -c 1 -I eth0 192.168.3.1PING 192.168.3.1 (192.168.3.1) from 192.168.3.21 eth0: 56(84) bytes of data.From 192.168.3.21 icmp_seq=1 Destination Host Unreachable--- 192.168.3.1 ping statistics ---1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0ms#通过br0来ping网关成功dev@debian:~$ ping -c 1 -I br0 192.168.3.1PING 192.168.3.1 (192.168.3.1) from 192.168.3.101 br0: 56(84) bytes of data.64 bytes from 192.168.3.1: icmp_seq=1 ttl=64 time=27.5 ms--- 192.168.3.1 ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 27.518/27.518/27.518/0.000 ms#通过veth1来ping网关成功dev@debian:~$ ping -c 1 -I veth1 192.168.3.1PING 192.168.3.1 (192.168.3.1) from 192.168.3.102 veth1: 56(84) bytes of data.64 bytes from 192.168.3.1: icmp_seq=1 ttl=64 time=68.8 ms--- 192.168.3.1 ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 68.806/68.806/68.806/0.000 ms</code></pre><p>由于eth0已经变成了和网线差不多的功能，所以在eth0上配置IP已经没有什么意义了，并且还会影响协议栈的路由选择，比如如果上面ping的时候不指定网卡的话，协议栈有可能优先选择eth0，导致ping不通，所以这里需要将eth0上的IP去掉。</p><pre><code>#在本人的测试机器上，由于eth0上有IP，#访问192.168.3.0/24网段时，会优先选择eth0dev@debian:~$ sudo route -vKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Ifacedefault         192.168.3.1     0.0.0.0         UG    0      0        0 eth0link-local      *               255.255.0.0     U     1000   0        0 eth0192.168.3.0     *               255.255.255.0   U     0      0        0 eth0192.168.3.0     *               255.255.255.0   U     0      0        0 veth1192.168.3.0     *               255.255.255.0   U     0      0        0 br0#由于eth0已结接入了br0，所有它收到的数据包都会转发给br0，#于是协议栈收不到arp应答包，导致ping失败dev@debian:~$ ping -c 1 192.168.3.1PING 192.168.3.1 (192.168.3.1) 56(84) bytes of data.From 192.168.3.21 icmp_seq=1 Destination Host Unreachable--- 192.168.3.1 ping statistics ---1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0ms#将eth0上的IP删除掉dev@debian:~$ sudo ip addr del 192.168.3.21/24 dev eth0#再ping一次，成功dev@debian:~$ ping -c 1 192.168.3.1PING 192.168.3.1 (192.168.3.1) 56(84) bytes of data.64 bytes from 192.168.3.1: icmp_seq=1 ttl=64 time=3.91 ms--- 192.168.3.1 ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 3.916/3.916/3.916/0.000 ms#这是因为eth0没有IP之后，路由表里面就没有它了，于是数据包会从veth1出去dev@debian:~$ sudo route -vKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Iface192.168.3.0     *               255.255.255.0   U     0      0        0 veth1192.168.3.0     *               255.255.255.0   U     0      0        0 br0#从这里也可以看出，由于原来的默认路由走的是eth0，所以当eth0的IP被删除之后，#默认路由不见了，想要连接192.168.3.0/24以外的网段的话，需要手动将默认网关加回来#添加默认网关，然后再ping外网成功dev@debian:~$ sudo ip route add default via 192.168.3.1dev@debian:~$ ping -c 1 baidu.comPING baidu.com (111.13.101.208) 56(84) bytes of data.64 bytes from 111.13.101.208: icmp_seq=1 ttl=51 time=30.6 ms--- baidu.com ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 30.690/30.690/30.690/0.000 ms</code></pre><p>经过上面一系列的操作后，网络变成了这个样子：</p><pre><code>+----------------------------------------------------------------+|                                                                ||       +------------------------------------------------+       ||       |             Newwork Protocol Stack             |       ||       +------------------------------------------------+       ||                         ↑                           ↑          ||.........................|...........................|..........||                         ↓                           ↓          ||        +------+     +--------+     +-------+    +-------+      ||        |      |     | .3.101 |     |       |    | .3.102|      ||        +------+     +--------+     +-------+    +-------+      ||        | eth0 |&lt;---&gt;|   br0  |&lt;---&gt;| veth0 |    | veth1 |      ||        +------+     +--------+     +-------+    +-------+      ||            ↑                           ↑            ↑          ||            |                           |            |          ||            |                           +------------+          ||            |                                                   |+------------|---------------------------------------------------+             ↓     Physical Network</code></pre><p>上面的操作中有几点需要注意：</p><ul><li><p>如果是在虚拟机上做上述操作，记得打开网卡的混杂模式（不是在Linux里面，而是在虚拟机的配置上面，如VirtualBox上相应虚拟机的网卡配置项里面），不然veth1的网络会不通，因为eth0不在混杂模式的话，会丢掉目的mac地址是veth1的数据包</p></li><li><p>上面虽然通了，但由于<a href="https://lwn.net/Articles/45373/" target="_blank" rel="noopener">Linux下arp的特性</a>，当协议栈收到外面的arp请求时，不管是问101还是102，都会回复两个arp应答，分别包含br0和veth1的mac地址，也即Linux觉得外面发给101和102的数据包从br0和veth1进协议栈都一样，没有区别。由于回复了两个arp应答，而外面的设备只会用其中的一个，并且具体用哪个会随着时间发生变化，于是导致一个问题，就是外面回复给102的数据包可能从101的br0上进来，即通过102 ping外面时，可能在veth1抓不到回复包，而在br0上能抓到回复包。说明数据流在交换机那层没有完全的隔离开，br0和veth1会收到对方的IP应答包。为了解决上述问题，可以配置rp_filter, arp_filter, arp_ignore, arp_announce等参数，但不建议这么做，容易出错，调试比较麻烦。</p></li><li><p>在无线网络环境中，情况会变得比较复杂，因为无线网络需要登录，登陆后无线路由器只认一个mac地址，所有从这台机器出去的mac地址都必须是那一个，于是通过无线网卡上网的机器上的所有虚拟机想要上网的话，都必须依赖虚拟机管理软件（如VirtualBox）将每个虚拟机的网卡mac地址转成出口的mac地址（即无线网卡的mac地址），数据包回来的时候还要转回来，所以如果一个IP有两个ARP应答包的话，有可能导致mac地址的转换有问题，导致网络不通，或者有时通有时不通。解决办法就是将连接进br0的所有设备的mac地址都改成和eth0一样的mac地址，因为eth0的mac地址会被虚拟机正常的做转换。在上面的例子中，执行下面的命令即可：</p><pre><code>dev@debian:~$ sudo ip link set dev veth1 down#08:00:27:3b:0d:b9是eth0的mac地址dev@debian:~$ sudo ip link set dev veth1 address 08:00:27:3b:0d:b9dev@debian:~$ sudo ip link set dev veth1 up</code></pre></li></ul><h2 id="bridge必须要配置IP吗？"><a class="header-anchor" href="#bridge必须要配置IP吗？">¶</a>bridge必须要配置IP吗？</h2><p>在我们常见的物理交换机中，有可以配置IP和不能配置IP两种，不能配置IP的交换机一般通过com口连上去做配置（更简单的交换机连com口的没有，不支持任何配置），而能配置IP的交换机可以在配置好IP之后，通过该IP远程连接上去做配置，从而更方便。</p><p>bridge就属于后一种交换机，自带虚拟网卡，可以配置IP，该虚拟网卡一端连在bridge上，另一端跟协议栈相连。和物理交换机一样，bridge的工作不依赖于该虚拟网卡，但bridge工作不代表机器能连上网，要看组网方式。</p><p>删除br0上的IP:</p><pre><code>dev@debian:~$ sudo ip addr del 192.168.3.101/24 dev br0</code></pre><p>于是网络变成了这样子，相当于br0的一个端口通过eth0连着交换机，另一个端口通过veth0连着veth1：</p><pre><code>+----------------------------------------------------------------+|                                                                ||       +------------------------------------------------+       ||       |             Newwork Protocol Stack             |       ||       +------------------------------------------------+       ||                                                     ↑          ||.....................................................|..........||                                                     ↓          ||        +------+     +--------+     +-------+    +-------+      ||        |      |     |        |     |       |    | .3.102|      ||        +------+     +--------+     +-------+    +-------+      ||        | eth0 |&lt;---&gt;|   br0  |&lt;---&gt;| veth0 |    | veth1 |      ||        +------+     +--------+     +-------+    +-------+      ||            ↑                           ↑            ↑          ||            |                           |            |          ||            |                           +------------+          ||            |                                                   |+------------|---------------------------------------------------+             ↓     Physical Network</code></pre><p>ping网关成功，说明这种情况下br0不配置IP对通信没有影响，数据包还能从veth1出去：</p><pre><code>dev@debian:~$ ping -c 1 192.168.3.1PING 192.168.3.1 (192.168.3.1) 56(84) bytes of data.64 bytes from 192.168.3.1: icmp_seq=1 ttl=64 time=1.24 ms--- 192.168.3.1 ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 1.242/1.242/1.242/0.000 ms</code></pre><blockquote><p>上面如果没有veth0和veth1的话，删除br0上的IP后，网络将会不通，因为没有设备和协议栈完全相连</p></blockquote><h3 id="bridge常用场景"><a class="header-anchor" href="#bridge常用场景">¶</a>bridge常用场景</h3><p>上面通过例子展示了bridge的功能，但例子中的那种部署方式没有什么实际用途，还不如在一个网卡上配置多个IP地址来的直接。这里来介绍两种常见的部署方式。</p><h4 id="虚拟机"><a class="header-anchor" href="#虚拟机">¶</a>虚拟机</h4><p>虚拟机通过tun/tap或者其它类似的虚拟网络设备，将虚拟机内的网卡同br0连接起来，这样就达到和真实交换机一样的效果，虚拟机发出去的数据包先到达br0，然后由br0交给eth0发送出去，数据包都不需要经过host机器的协议栈，效率高。</p><pre><code>+----------------------------------------------------------------+-----------------------------------------+-----------------------------------------+|                          Host                                  |              VirtualMachine1            |              VirtualMachine2            ||                                                                |                                         |                                         ||       +------------------------------------------------+       |       +-------------------------+       |       +-------------------------+       ||       |             Newwork Protocol Stack             |       |       |  Newwork Protocol Stack |       |       |  Newwork Protocol Stack |       ||       +------------------------------------------------+       |       +-------------------------+       |       +-------------------------+       ||                          ↑                                     |                   ↑                     |                    ↑                    ||..........................|.....................................|...................|.....................|....................|....................||                          ↓                                     |                   ↓                     |                    ↓                    ||                     +--------+                                 |               +-------+                 |                +-------+                ||                     | .3.101 |                                 |               | .3.102|                 |                | .3.103|                ||        +------+     +--------+     +-------+                   |               +-------+                 |                +-------+                ||        | eth0 |&lt;---&gt;|   br0  |&lt;---&gt;|tun/tap|                   |               | eth0  |                 |                | eth0  |                ||        +------+     +--------+     +-------+                   |               +-------+                 |                +-------+                ||            ↑             ↑             ↑                       |                   ↑                     |                    ↑                    ||            |             |             +-------------------------------------------+                     |                    |                    ||            |             ↓                                     |                                         |                    |                    ||            |         +-------+                                 |                                         |                    |                    ||            |         |tun/tap|                                 |                                         |                    |                    ||            |         +-------+                                 |                                         |                    |                    ||            |             ↑                                     |                                         |                    |                    ||            |             +-------------------------------------------------------------------------------|--------------------+                    ||            |                                                   |                                         |                                         ||            |                                                   |                                         |                                         ||            |                                                   |                                         |                                         |+------------|---------------------------------------------------+-----------------------------------------+-----------------------------------------+             ↓     Physical Network  (192.168.3.0/24)</code></pre><h4 id="docker"><a class="header-anchor" href="#docker">¶</a>docker</h4><p>由于容器运行在自己单独的network namespace里面，所以都有自己单独的协议栈，情况和上面的虚拟机差不多，但它采用了另一种方式来和外界通信：</p><pre><code>+----------------------------------------------------------------+-----------------------------------------+-----------------------------------------+|                          Host                                  |              Container 1                |              Container 2                ||                                                                |                                         |                                         ||       +------------------------------------------------+       |       +-------------------------+       |       +-------------------------+       ||       |             Newwork Protocol Stack             |       |       |  Newwork Protocol Stack |       |       |  Newwork Protocol Stack |       ||       +------------------------------------------------+       |       +-------------------------+       |       +-------------------------+       ||            ↑             ↑                                     |                   ↑                     |                    ↑                    ||............|.............|.....................................|...................|.....................|....................|....................||            ↓             ↓                                     |                   ↓                     |                    ↓                    ||        +------+     +--------+                                 |               +-------+                 |                +-------+                ||        |.3.101|     |  .9.1  |                                 |               |  .9.2 |                 |                |  .9.3 |                ||        +------+     +--------+     +-------+                   |               +-------+                 |                +-------+                ||        | eth0 |     |   br0  |&lt;---&gt;|  veth |                   |               | eth0  |                 |                | eth0  |                ||        +------+     +--------+     +-------+                   |               +-------+                 |                +-------+                ||            ↑             ↑             ↑                       |                   ↑                     |                    ↑                    ||            |             |             +-------------------------------------------+                     |                    |                    ||            |             ↓                                     |                                         |                    |                    ||            |         +-------+                                 |                                         |                    |                    ||            |         |  veth |                                 |                                         |                    |                    ||            |         +-------+                                 |                                         |                    |                    ||            |             ↑                                     |                                         |                    |                    ||            |             +-------------------------------------------------------------------------------|--------------------+                    ||            |                                                   |                                         |                                         ||            |                                                   |                                         |                                         ||            |                                                   |                                         |                                         |+------------|---------------------------------------------------+-----------------------------------------+-----------------------------------------+             ↓     Physical Network  (192.168.3.0/24)</code></pre><p>容器中配置网关为.9.1，发出去的数据包先到达br0，然后交给host机器的协议栈，由于目的IP是外网IP，且host机器开启了IP forward功能，于是数据包会通过eth0发送出去，由于.9.1是内网IP，所以一般发出去之前会先做NAT转换（NAT转换和IP forward功能都需要自己配置）。由于要经过host机器的协议栈，并且还要做NAT转换，所以性能没有上面虚拟机那种方案好，优点是容器处于内网中，安全性相对要高点。（由于数据包统一由IP层从eth0转发出去，所以不存在mac地址的问题，在无线网络环境下也工作良好）</p><blockquote><p>上面两种部署方案中，同一网段的每个网卡都有自己单独的协议栈，所以不存在上面说的多个ARP的问题</p></blockquote><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://www.ibm.com/developerworks/cn/linux/1310_xiawc_networkdevice/" target="_blank" rel="noopener">Linux 上的基础网络设备详解</a></li><li><a href="https://lwn.net/Articles/45373/" target="_blank" rel="noopener">Harping on ARP</a></li><li><a href="https://wiki.archlinux.org/index.php/MAC_address_spoofing" target="_blank" rel="noopener">MAC address spoofing</a></li><li><a href="https://wiki.linuxfoundation.org/networking/bridge#it-doesn-t-work-with-my-wireless-card" target="_blank" rel="noopener">It doesn’t work with my Wireless card!</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux虚拟网络设备之veth</title>
      <link href="/2020/02/16/linux/network/linux-xu-ni-wang-luo-she-bei-zhi-veth/"/>
      <url>/2020/02/16/linux/network/linux-xu-ni-wang-luo-she-bei-zhi-veth/</url>
      
        <content type="html"><![CDATA[<p>有了上一篇关于<a href="https://segmentfault.com/a/1190000009249039" target="_blank" rel="noopener">tun/tap的介绍</a>之后，大家应该对虚拟网络设备有了一定的了解，本篇将接着介绍另一种虚拟网络设备veth。</p><h2 id="veth设备的特点"><a class="header-anchor" href="#veth设备的特点">¶</a>veth设备的特点</h2><ul><li>veth和其它的网络设备都一样，一端连接的是内核协议栈。</li><li>veth设备是成对出现的，另一端两个设备彼此相连</li><li>一个设备收到协议栈的数据发送请求后，会将数据发送到另一个设备上去。</li></ul><p>下面这张关系图很清楚的说明了veth设备的特点：</p><pre><code>+----------------------------------------------------------------+|                                                                ||       +------------------------------------------------+       ||       |             Newwork Protocol Stack             |       ||       +------------------------------------------------+       ||              ↑               ↑               ↑                 ||..............|...............|...............|.................||              ↓               ↓               ↓                 ||        +----------+    +-----------+   +-----------+           ||        |   eth0   |    |   veth0   |   |   veth1   |           ||        +----------+    +-----------+   +-----------+           ||192.168.1.11  ↑               ↑               ↑                 ||              |               +---------------+                 ||              |         192.168.2.11     192.168.2.1            |+--------------|-------------------------------------------------+               ↓         Physical Network</code></pre><p>上图中，我们给物理网卡eth0配置的IP为192.168.1.11， 而veth0和veth1的IP分别是192.168.2.11和192.168.2.1。</p><h2 id="示例"><a class="header-anchor" href="#示例">¶</a>示例</h2><p>我们通过示例的方式来一步一步的看看veth设备的特点。</p><h3 id="只给一个veth设备配置IP"><a class="header-anchor" href="#只给一个veth设备配置IP">¶</a>只给一个veth设备配置IP</h3><p>先通过ip link命令添加veth0和veth1，然后配置veth0的IP，并将两个设备都启动起来</p><pre><code>dev@debian:~$ sudo ip link add veth0 type veth peer name veth1dev@debian:~$ sudo ip addr add 192.168.2.11/24 dev veth0dev@debian:~$ sudo ip link set veth0 updev@debian:~$ sudo ip link set veth1 up</code></pre><p>这里不给veth1设备配置IP的原因就是想看看在veth1没有IP的情况下，veth0收到协议栈的数据后会不会转发给veth1。</p><p>ping一下192.168.2.1，由于veth1还没配置IP，所以肯定不通</p><pre><code>dev@debian:~$ ping -c 4 192.168.2.1PING 192.168.2.1 (192.168.2.1) 56(84) bytes of data.From 192.168.2.11 icmp_seq=1 Destination Host UnreachableFrom 192.168.2.11 icmp_seq=2 Destination Host UnreachableFrom 192.168.2.11 icmp_seq=3 Destination Host UnreachableFrom 192.168.2.11 icmp_seq=4 Destination Host Unreachable--- 192.168.2.1 ping statistics ---4 packets transmitted, 0 received, +4 errors, 100% packet loss, time 3015mspipe 3</code></pre><p>但为什么ping不通呢？是到哪一步失败的呢？</p><p>先看看抓包的情况，从下面的输出可以看出，veth0和veth1收到了同样的ARP请求包，但没有看到ARP应答包：</p><pre><code>dev@debian:~$ sudo tcpdump -n -i veth0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth0, link-type EN10MB (Ethernet), capture size 262144 bytes20:20:18.285230 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:19.282018 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:20.282038 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:21.300320 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:22.298783 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:23.298923 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 28dev@debian:~$ sudo tcpdump -n -i veth1tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytes20:20:48.570459 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:49.570012 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:50.570023 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:51.570023 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:52.569988 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:53.570833 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 28</code></pre><p>为什么会这样呢？了解ping背后发生的事情后就明白了：</p><ol><li>ping进程构造ICMP echo请求包，并通过socket发给协议栈，</li><li>协议栈根据目的IP地址和系统路由表，知道去192.168.2.1的数据包应该要由192.168.2.11口出去</li><li>由于是第一次访问192.168.2.1，且目的IP和本地IP在同一个网段，所以协议栈会先发送ARP出去，询问192.168.2.1的mac地址</li><li>协议栈将ARP包交给veth0，让它发出去</li><li>由于veth0的另一端连的是veth1，所以ARP请求包就转发给了veth1</li><li>veth1收到ARP包后，转交给另一端的协议栈</li><li>协议栈一看自己的设备列表，发现本地没有192.168.2.1这个IP，于是就丢弃了该ARP请求包，这就是为什么只能看到ARP请求包，看不到应答包的原因</li></ol><h3 id="给两个veth设备都配置IP"><a class="header-anchor" href="#给两个veth设备都配置IP">¶</a>给两个veth设备都配置IP</h3><p>给veth1也配置上IP</p><pre><code>dev@debian:~$ sudo ip addr add 192.168.2.1/24 dev veth1</code></pre><p>再ping 192.168.2.1成功（由于192.168.2.1是本地IP，所以默认会走lo设备，为了避免这种情况，这里使用ping命令带上了-I参数，指定数据包走指定设备）</p><pre><code>dev@debian:~$ ping -c 4 192.168.2.1 -I veth0PING 192.168.2.1 (192.168.2.1) from 192.168.2.11 veth0: 56(84) bytes of data.64 bytes from 192.168.2.1: icmp_seq=1 ttl=64 time=0.032 ms64 bytes from 192.168.2.1: icmp_seq=2 ttl=64 time=0.048 ms64 bytes from 192.168.2.1: icmp_seq=3 ttl=64 time=0.055 ms64 bytes from 192.168.2.1: icmp_seq=4 ttl=64 time=0.050 ms--- 192.168.2.1 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3002msrtt min/avg/max/mdev = 0.032/0.046/0.055/0.009 ms</code></pre><blockquote><p>注意：对于非debian系统，这里有可能ping不通，主要是因为内核中的一些ARP相关配置导致veth1不返回ARP应答包，如ubuntu上就会出现这种情况，解决办法如下：<br>root@ubuntu:~# echo 1 &gt; /proc/sys/net/ipv4/conf/veth1/accept_local<br>root@ubuntu:~# echo 1 &gt; /proc/sys/net/ipv4/conf/veth0/accept_local<br>root@ubuntu:~# echo 0 &gt; /proc/sys/net/ipv4/conf/all/rp_filter<br>root@ubuntu:~# echo 0 &gt; /proc/sys/net/ipv4/conf/veth0/rp_filter<br>root@ubuntu:~# echo 0 &gt; /proc/sys/net/ipv4/conf/veth1/rp_filter</p></blockquote><p>再来看看抓包情况，我们在veth0和veth1上都看到了ICMP echo的请求包，但为什么没有应答包呢？上面不是显示ping进程已经成功收到了应答包吗？</p><pre><code>dev@debian:~$ sudo tcpdump -n -i veth0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth0, link-type EN10MB (Ethernet), capture size 262144 bytes20:23:43.113062 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24169, seq 1, length 6420:23:44.112078 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24169, seq 2, length 6420:23:45.111091 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24169, seq 3, length 6420:23:46.110082 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24169, seq 4, length 64dev@debian:~$ sudo tcpdump -n -i veth1tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytes20:24:12.221372 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24174, seq 1, length 6420:24:13.222089 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24174, seq 2, length 6420:24:14.224836 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24174, seq 3, length 6420:24:15.223826 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24174, seq 4, length 64</code></pre><p>看看数据包的流程就明白了：</p><ol><li>ping进程构造ICMP echo请求包，并通过socket发给协议栈，</li><li>由于ping程序指定了走veth0，并且本地ARP缓存里面已经有了相关记录，所以不用再发送ARP出去，协议栈就直接将该数据包交给了veth0</li><li>由于veth0的另一端连的是veth1，所以ICMP echo请求包就转发给了veth1</li><li>veth1收到ICMP echo请求包后，转交给另一端的协议栈</li><li>协议栈一看自己的设备列表，发现本地有192.168.2.1这个IP，于是构造ICMP echo应答包，准备返回</li><li>协议栈查看自己的路由表，发现回给192.168.2.11的数据包应该走lo口，于是将应答包交给lo设备</li><li>lo接到协议栈的应答包后，啥都没干，转手又把数据包还给了协议栈（相当于协议栈通过发送流程把数据包给lo，然后lo再将数据包交给协议栈的接收流程）</li><li>协议栈收到应答包后，发现有socket需要该包，于是交给了相应的socket</li><li>这个socket正好是ping进程创建的socket，于是ping进程收到了应答包</li></ol><p>抓一下lo设备上的数据，发现应答包确实是从lo口回来的：</p><pre><code>dev@debian:~$ sudo tcpdump -n -i lotcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on lo, link-type EN10MB (Ethernet), capture size 262144 bytes20:25:49.590273 IP 192.168.2.1 &gt; 192.168.2.11: ICMP echo reply, id 24177, seq 1, length 6420:25:50.590018 IP 192.168.2.1 &gt; 192.168.2.11: ICMP echo reply, id 24177, seq 2, length 6420:25:51.590027 IP 192.168.2.1 &gt; 192.168.2.11: ICMP echo reply, id 24177, seq 3, length 6420:25:52.590030 IP 192.168.2.1 &gt; 192.168.2.11: ICMP echo reply, id 24177, seq 4, length 64</code></pre><h3 id="试着ping下其它的IP"><a class="header-anchor" href="#试着ping下其它的IP">¶</a>试着ping下其它的IP</h3><p>ping 192.168.2.0/24网段的其它IP失败，ping一个公网的IP也失败：</p><pre><code>dev@debian:~$ ping -c 1 -I veth0 192.168.2.2PING 192.168.2.2 (192.168.2.2) from 192.168.2.11 veth0: 56(84) bytes of data.From 192.168.2.11 icmp_seq=1 Destination Host Unreachable--- 192.168.2.2 ping statistics ---1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0msdev@debian:~$ ping -c 1 -I veth0 baidu.comPING baidu.com (111.13.101.208) from 192.168.2.11 veth0: 56(84) bytes of data.From 192.168.2.11 icmp_seq=1 Destination Host Unreachable--- baidu.com ping statistics ---1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0ms</code></pre><p>从抓包来看，和上面第一种veth1没有配置IP的情况是一样的，ARP请求没人处理</p><pre><code>dev@debian:~$ sudo tcpdump -i veth1tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytes02:25:23.223947 ARP, Request who-has 192.168.2.2 tell 192.168.2.11, length 2802:25:24.224352 ARP, Request who-has 192.168.2.2 tell 192.168.2.11, length 2802:25:25.223471 ARP, Request who-has 192.168.2.2 tell 192.168.2.11, length 2802:25:27.946539 ARP, Request who-has 123.125.114.144 tell 192.168.2.11, length 2802:25:28.946633 ARP, Request who-has 123.125.114.144 tell 192.168.2.11, length 2802:25:29.948055 ARP, Request who-has 123.125.114.144 tell 192.168.2.11, length 28</code></pre><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>从上面的介绍中可以看出，从veth0设备出去的数据包，会转发到veth1上，如果目的地址是veth1的IP的话，就能被协议栈处理，否则连ARP那关都过不了，IP forward啥的都用不上，所以不借助其它虚拟设备的话，这样的数据包只能在本地协议栈里面打转转，没法走到eth0上去，即没法发送到外面的网络中去。</p><p>下一篇将介绍Linux下的网桥，到时候veth设备就有用武之地了。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><p><a href="http://www.opencloudblog.com/?p=66" target="_blank" rel="noopener">Linux Switching – Interconnecting Namespaces</a>有了上一篇关于<a href="https://segmentfault.com/a/1190000009249039" target="_blank" rel="noopener">tun/tap的介绍</a>之后，大家应该对虚拟网络设备有了一定的了解，本篇将接着介绍另一种虚拟网络设备veth。</p><h2 id="veth设备的特点-v2"><a class="header-anchor" href="#veth设备的特点-v2">¶</a>veth设备的特点</h2><ul><li>veth和其它的网络设备都一样，一端连接的是内核协议栈。</li><li>veth设备是成对出现的，另一端两个设备彼此相连</li><li>一个设备收到协议栈的数据发送请求后，会将数据发送到另一个设备上去。</li></ul><p>下面这张关系图很清楚的说明了veth设备的特点：</p><pre><code>+----------------------------------------------------------------+|                                                                ||       +------------------------------------------------+       ||       |             Newwork Protocol Stack             |       ||       +------------------------------------------------+       ||              ↑               ↑               ↑                 ||..............|...............|...............|.................||              ↓               ↓               ↓                 ||        +----------+    +-----------+   +-----------+           ||        |   eth0   |    |   veth0   |   |   veth1   |           ||        +----------+    +-----------+   +-----------+           ||192.168.1.11  ↑               ↑               ↑                 ||              |               +---------------+                 ||              |         192.168.2.11     192.168.2.1            |+--------------|-------------------------------------------------+               ↓         Physical Network</code></pre><p>上图中，我们给物理网卡eth0配置的IP为192.168.1.11， 而veth0和veth1的IP分别是192.168.2.11和192.168.2.1。</p><h2 id="示例-v2"><a class="header-anchor" href="#示例-v2">¶</a>示例</h2><p>我们通过示例的方式来一步一步的看看veth设备的特点。</p><h3 id="只给一个veth设备配置IP-v2"><a class="header-anchor" href="#只给一个veth设备配置IP-v2">¶</a>只给一个veth设备配置IP</h3><p>先通过ip link命令添加veth0和veth1，然后配置veth0的IP，并将两个设备都启动起来</p><pre><code>dev@debian:~$ sudo ip link add veth0 type veth peer name veth1dev@debian:~$ sudo ip addr add 192.168.2.11/24 dev veth0dev@debian:~$ sudo ip link set veth0 updev@debian:~$ sudo ip link set veth1 up</code></pre><p>这里不给veth1设备配置IP的原因就是想看看在veth1没有IP的情况下，veth0收到协议栈的数据后会不会转发给veth1。</p><p>ping一下192.168.2.1，由于veth1还没配置IP，所以肯定不通</p><pre><code>dev@debian:~$ ping -c 4 192.168.2.1PING 192.168.2.1 (192.168.2.1) 56(84) bytes of data.From 192.168.2.11 icmp_seq=1 Destination Host UnreachableFrom 192.168.2.11 icmp_seq=2 Destination Host UnreachableFrom 192.168.2.11 icmp_seq=3 Destination Host UnreachableFrom 192.168.2.11 icmp_seq=4 Destination Host Unreachable--- 192.168.2.1 ping statistics ---4 packets transmitted, 0 received, +4 errors, 100% packet loss, time 3015mspipe 3</code></pre><p>但为什么ping不通呢？是到哪一步失败的呢？</p><p>先看看抓包的情况，从下面的输出可以看出，veth0和veth1收到了同样的ARP请求包，但没有看到ARP应答包：</p><pre><code>dev@debian:~$ sudo tcpdump -n -i veth0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth0, link-type EN10MB (Ethernet), capture size 262144 bytes20:20:18.285230 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:19.282018 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:20.282038 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:21.300320 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:22.298783 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:23.298923 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 28dev@debian:~$ sudo tcpdump -n -i veth1tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytes20:20:48.570459 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:49.570012 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:50.570023 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:51.570023 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:52.569988 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 2820:20:53.570833 ARP, Request who-has 192.168.2.1 tell 192.168.2.11, length 28</code></pre><p>为什么会这样呢？了解ping背后发生的事情后就明白了：</p><ol><li>ping进程构造ICMP echo请求包，并通过socket发给协议栈，</li><li>协议栈根据目的IP地址和系统路由表，知道去192.168.2.1的数据包应该要由192.168.2.11口出去</li><li>由于是第一次访问192.168.2.1，且目的IP和本地IP在同一个网段，所以协议栈会先发送ARP出去，询问192.168.2.1的mac地址</li><li>协议栈将ARP包交给veth0，让它发出去</li><li>由于veth0的另一端连的是veth1，所以ARP请求包就转发给了veth1</li><li>veth1收到ARP包后，转交给另一端的协议栈</li><li>协议栈一看自己的设备列表，发现本地没有192.168.2.1这个IP，于是就丢弃了该ARP请求包，这就是为什么只能看到ARP请求包，看不到应答包的原因</li></ol><h3 id="给两个veth设备都配置IP-v2"><a class="header-anchor" href="#给两个veth设备都配置IP-v2">¶</a>给两个veth设备都配置IP</h3><p>给veth1也配置上IP</p><pre><code>dev@debian:~$ sudo ip addr add 192.168.2.1/24 dev veth1</code></pre><p>再ping 192.168.2.1成功（由于192.168.2.1是本地IP，所以默认会走lo设备，为了避免这种情况，这里使用ping命令带上了-I参数，指定数据包走指定设备）</p><pre><code>dev@debian:~$ ping -c 4 192.168.2.1 -I veth0PING 192.168.2.1 (192.168.2.1) from 192.168.2.11 veth0: 56(84) bytes of data.64 bytes from 192.168.2.1: icmp_seq=1 ttl=64 time=0.032 ms64 bytes from 192.168.2.1: icmp_seq=2 ttl=64 time=0.048 ms64 bytes from 192.168.2.1: icmp_seq=3 ttl=64 time=0.055 ms64 bytes from 192.168.2.1: icmp_seq=4 ttl=64 time=0.050 ms--- 192.168.2.1 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3002msrtt min/avg/max/mdev = 0.032/0.046/0.055/0.009 ms</code></pre><blockquote><p>注意：对于非debian系统，这里有可能ping不通，主要是因为内核中的一些ARP相关配置导致veth1不返回ARP应答包，如ubuntu上就会出现这种情况，解决办法如下：<br>root@ubuntu:~# echo 1 &gt; /proc/sys/net/ipv4/conf/veth1/accept_local<br>root@ubuntu:~# echo 1 &gt; /proc/sys/net/ipv4/conf/veth0/accept_local<br>root@ubuntu:~# echo 0 &gt; /proc/sys/net/ipv4/conf/all/rp_filter<br>root@ubuntu:~# echo 0 &gt; /proc/sys/net/ipv4/conf/veth0/rp_filter<br>root@ubuntu:~# echo 0 &gt; /proc/sys/net/ipv4/conf/veth1/rp_filter</p></blockquote><p>再来看看抓包情况，我们在veth0和veth1上都看到了ICMP echo的请求包，但为什么没有应答包呢？上面不是显示ping进程已经成功收到了应答包吗？</p><pre><code>dev@debian:~$ sudo tcpdump -n -i veth0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth0, link-type EN10MB (Ethernet), capture size 262144 bytes20:23:43.113062 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24169, seq 1, length 6420:23:44.112078 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24169, seq 2, length 6420:23:45.111091 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24169, seq 3, length 6420:23:46.110082 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24169, seq 4, length 64dev@debian:~$ sudo tcpdump -n -i veth1tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytes20:24:12.221372 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24174, seq 1, length 6420:24:13.222089 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24174, seq 2, length 6420:24:14.224836 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24174, seq 3, length 6420:24:15.223826 IP 192.168.2.11 &gt; 192.168.2.1: ICMP echo request, id 24174, seq 4, length 64</code></pre><p>看看数据包的流程就明白了：</p><ol><li>ping进程构造ICMP echo请求包，并通过socket发给协议栈，</li><li>由于ping程序指定了走veth0，并且本地ARP缓存里面已经有了相关记录，所以不用再发送ARP出去，协议栈就直接将该数据包交给了veth0</li><li>由于veth0的另一端连的是veth1，所以ICMP echo请求包就转发给了veth1</li><li>veth1收到ICMP echo请求包后，转交给另一端的协议栈</li><li>协议栈一看自己的设备列表，发现本地有192.168.2.1这个IP，于是构造ICMP echo应答包，准备返回</li><li>协议栈查看自己的路由表，发现回给192.168.2.11的数据包应该走lo口，于是将应答包交给lo设备</li><li>lo接到协议栈的应答包后，啥都没干，转手又把数据包还给了协议栈（相当于协议栈通过发送流程把数据包给lo，然后lo再将数据包交给协议栈的接收流程）</li><li>协议栈收到应答包后，发现有socket需要该包，于是交给了相应的socket</li><li>这个socket正好是ping进程创建的socket，于是ping进程收到了应答包</li></ol><p>抓一下lo设备上的数据，发现应答包确实是从lo口回来的：</p><pre><code>dev@debian:~$ sudo tcpdump -n -i lotcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on lo, link-type EN10MB (Ethernet), capture size 262144 bytes20:25:49.590273 IP 192.168.2.1 &gt; 192.168.2.11: ICMP echo reply, id 24177, seq 1, length 6420:25:50.590018 IP 192.168.2.1 &gt; 192.168.2.11: ICMP echo reply, id 24177, seq 2, length 6420:25:51.590027 IP 192.168.2.1 &gt; 192.168.2.11: ICMP echo reply, id 24177, seq 3, length 6420:25:52.590030 IP 192.168.2.1 &gt; 192.168.2.11: ICMP echo reply, id 24177, seq 4, length 64</code></pre><h3 id="试着ping下其它的IP-v2"><a class="header-anchor" href="#试着ping下其它的IP-v2">¶</a>试着ping下其它的IP</h3><p>ping 192.168.2.0/24网段的其它IP失败，ping一个公网的IP也失败：</p><pre><code>dev@debian:~$ ping -c 1 -I veth0 192.168.2.2PING 192.168.2.2 (192.168.2.2) from 192.168.2.11 veth0: 56(84) bytes of data.From 192.168.2.11 icmp_seq=1 Destination Host Unreachable--- 192.168.2.2 ping statistics ---1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0msdev@debian:~$ ping -c 1 -I veth0 baidu.comPING baidu.com (111.13.101.208) from 192.168.2.11 veth0: 56(84) bytes of data.From 192.168.2.11 icmp_seq=1 Destination Host Unreachable--- baidu.com ping statistics ---1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0ms</code></pre><p>从抓包来看，和上面第一种veth1没有配置IP的情况是一样的，ARP请求没人处理</p><pre><code>dev@debian:~$ sudo tcpdump -i veth1tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytes02:25:23.223947 ARP, Request who-has 192.168.2.2 tell 192.168.2.11, length 2802:25:24.224352 ARP, Request who-has 192.168.2.2 tell 192.168.2.11, length 2802:25:25.223471 ARP, Request who-has 192.168.2.2 tell 192.168.2.11, length 2802:25:27.946539 ARP, Request who-has 123.125.114.144 tell 192.168.2.11, length 2802:25:28.946633 ARP, Request who-has 123.125.114.144 tell 192.168.2.11, length 2802:25:29.948055 ARP, Request who-has 123.125.114.144 tell 192.168.2.11, length 28</code></pre><h2 id="结束语-v2"><a class="header-anchor" href="#结束语-v2">¶</a>结束语</h2><p>从上面的介绍中可以看出，从veth0设备出去的数据包，会转发到veth1上，如果目的地址是veth1的IP的话，就能被协议栈处理，否则连ARP那关都过不了，IP forward啥的都用不上，所以不借助其它虚拟设备的话，这样的数据包只能在本地协议栈里面打转转，没法走到eth0上去，即没法发送到外面的网络中去。</p><p>下一篇将介绍Linux下的网桥，到时候veth设备就有用武之地了。</p><h2 id="参考-v2"><a class="header-anchor" href="#参考-v2">¶</a>参考</h2><ul><li><a href="http://www.opencloudblog.com/?p=66" target="_blank" rel="noopener">Linux Switching – Interconnecting Namespaces</a></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux虚拟网络设备之tuntap</title>
      <link href="/2020/02/16/linux/network/linux-xu-ni-wang-luo-she-bei-zhi-tuntap/"/>
      <url>/2020/02/16/linux/network/linux-xu-ni-wang-luo-she-bei-zhi-tuntap/</url>
      
        <content type="html"><![CDATA[<p>在现在的云时代，到处都是虚拟机和容器，它们背后的网络管理都离不开虚拟网络设备，所以了解虚拟网络设备有利于我们更好的理解云时代的网络结构。从本篇开始，将介绍Linux下的虚拟网络设备。</p><h2 id="虚拟设备和物理设备的区别"><a class="header-anchor" href="#虚拟设备和物理设备的区别">¶</a>虚拟设备和物理设备的区别</h2><p>在<a href="https://segmentfault.com/a/1190000008836467" target="_blank" rel="noopener">Linux网络数据包的接收过程</a>和<a href="https://segmentfault.com/a/1190000008926093" target="_blank" rel="noopener">数据包的发送过程</a>这两篇文章中，介绍了数据包的收发流程，知道了Linux内核中有一个网络设备管理层，处于网络设备驱动和协议栈之间，负责衔接它们之间的数据交互。驱动不需要了解协议栈的细节，协议栈也不需要了解设备驱动的细节。</p><p>对于一个网络设备来说，就像一个管道（pipe）一样，有两端，从其中任意一端收到的数据将从另一端发送出去。</p><p>比如一个物理网卡eth0，它的两端分别是内核协议栈（通过内核网络设备管理模块间接的通信）和外面的物理网络，从物理网络收到的数据，会转发给内核协议栈，而应用程序从协议栈发过来的数据将会通过物理网络发送出去。</p><p>那么对于一个虚拟网络设备呢？首先它也归内核的网络设备管理子系统管理，对于Linux内核网络设备管理模块来说，虚拟设备和物理设备没有区别，都是网络设备，都能配置IP，从网络设备来的数据，都会转发给协议栈，协议栈过来的数据，也会交由网络设备发送出去，至于是怎么发送出去的，发到哪里去，那是设备驱动的事情，跟Linux内核就没关系了，所以说虚拟网络设备的一端也是协议栈，而另一端是什么取决于虚拟网络设备的驱动实现。</p><h2 id="tun-tap的另一端是什么？"><a class="header-anchor" href="#tun-tap的另一端是什么？">¶</a>tun/tap的另一端是什么？</h2><p>先看图再说话：</p><pre><code>+----------------------------------------------------------------+|                                                                ||  +--------------------+      +--------------------+            ||  | User Application A |      | User Application B |&lt;-----+     ||  +--------------------+      +--------------------+      |     ||               | 1                    | 5                 |     ||...............|......................|...................|.....||               ↓                      ↓                   |     ||         +----------+           +----------+              |     ||         | socket A |           | socket B |              |     ||         +----------+           +----------+              |     ||                 | 2               | 6                    |     ||.................|.................|......................|.....||                 ↓                 ↓                      |     ||             +------------------------+                 4 |     ||             | Newwork Protocol Stack |                   |     ||             +------------------------+                   |     ||                | 7                 | 3                   |     ||................|...................|.....................|.....||                ↓                   ↓                     |     ||        +----------------+    +----------------+          |     ||        |      eth0      |    |      tun0      |          |     ||        +----------------+    +----------------+          |     ||    10.32.0.11  |                   |   192.168.3.11      |     ||                | 8                 +---------------------+     ||                |                                               |+----------------|-----------------------------------------------+                 ↓         Physical Network</code></pre><p>上图中有两个应用程序A和B，都在用户层，而其它的socket、协议栈（Newwork Protocol Stack）和网络设备（eth0和tun0）部分都在内核层，其实socket是协议栈的一部分，这里分开来的目的是为了看的更直观。</p><p>tun0是一个Tun/Tap虚拟设备，从上图中可以看出它和物理设备eth0的差别，它们的一端虽然都连着协议栈，但另一端不一样，eth0的另一端是物理网络，这个物理网络可能就是一个交换机，而tun0的另一端是一个用户层的程序，协议栈发给tun0的数据包能被这个应用程序读取到，并且应用程序能直接向tun0写数据。</p><p>这里假设eth0配置的IP是10.32.0.11，而tun0配置的IP是192.168.3.11.</p><blockquote><p>这里列举的是一个典型的tun/tap设备的应用场景，发到192.168.3.0/24网络的数据通过程序B这个隧道，利用10.32.0.11发到远端网络的10.33.0.1，再由10.33.0.1转发给相应的设备，从而实现VPN。</p></blockquote><p>下面来看看数据包的流程：</p><ol><li>应用程序A是一个普通的程序，通过socket A发送了一个数据包，假设这个数据包的目的IP地址是192.168.3.1</li><li>socket将这个数据包丢给协议栈</li><li>协议栈根据数据包的目的IP地址，匹配本地路由规则，知道这个数据包应该由tun0出去，于是将数据包交给tun0</li><li>tun0收到数据包之后，发现另一端被进程B打开了，于是将数据包丢给了进程B</li><li>进程B收到数据包之后，做一些跟业务相关的处理，然后构造一个新的数据包，将原来的数据包嵌入在新的数据包中，最后通过socket B将数据包转发出去，这时候新数据包的源地址变成了eth0的地址，而目的IP地址变成了一个其它的地址，比如是10.33.0.1.</li><li>socket B将数据包丢给协议栈</li><li>协议栈根据本地路由，发现这个数据包应该要通过eth0发送出去，于是将数据包交给eth0</li><li>eth0通过物理网络将数据包发送出去</li></ol><p>10.33.0.1收到数据包之后，会打开数据包，读取里面的原始数据包，并转发给本地的192.168.3.1，然后等收到192.168.3.1的应答后，再构造新的应答包，并将原始应答包封装在里面，再由原路径返回给应用程序B，应用程序B取出里面的原始应答包，最后返回给应用程序A</p><blockquote><p>这里不讨论Tun/Tap设备tun0是怎么和用户层的进程B进行通信的，对于Linux内核来说，有很多种办法来让内核空间和用户空间的进程交换数据。</p></blockquote><p>从上面的流程中可以看出，数据包选择走哪个网络设备完全由路由表控制，所以如果我们想让某些网络流量走应用程序B的转发流程，就需要配置路由表让这部分数据走tun0。</p><h2 id="tun-tap设备有什么用？"><a class="header-anchor" href="#tun-tap设备有什么用？">¶</a>tun/tap设备有什么用？</h2><p>从上面介绍过的流程可以看出来，tun/tap设备的用处是将协议栈中的部分数据包转发给用户空间的应用程序，给用户空间的程序一个处理数据包的机会。于是比较常用的数据压缩，加密等功能就可以在应用程序B里面做进去，tun/tap设备最常用的场景是VPN，包括tunnel以及应用层的IPSec等，比较有名的项目是<a href="http://vtun.sourceforge.net/" target="_blank" rel="noopener">VTun</a>，有兴趣可以去了解一下。</p><h2 id="tun和tap的区别"><a class="header-anchor" href="#tun和tap的区别">¶</a>tun和tap的区别</h2><p>用户层程序通过tun设备只能读写IP数据包，而通过tap设备能读写链路层数据包，类似于普通socket和raw socket的差别一样，处理数据包的格式不一样。</p><h2 id="示例"><a class="header-anchor" href="#示例">¶</a>示例</h2><h3 id="示例程序"><a class="header-anchor" href="#示例程序">¶</a>示例程序</h3><p>这里写了一个程序，它收到tun设备的数据包之后，只打印出收到了多少字节的数据包，其它的什么都不做，如何编程请参考后面的参考链接。</p><pre><code>#include &lt;net/if.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;string.h&gt;#include &lt;sys/types.h&gt;#include &lt;linux/if_tun.h&gt;#include&lt;stdlib.h&gt;#include&lt;stdio.h&gt;int tun_alloc(int flags){    struct ifreq ifr;    int fd, err;    char *clonedev = &quot;/dev/net/tun&quot;;    if ((fd = open(clonedev, O_RDWR)) &lt; 0) {        return fd;    }    memset(&amp;ifr, 0, sizeof(ifr));    ifr.ifr_flags = flags;    if ((err = ioctl(fd, TUNSETIFF, (void *) &amp;ifr)) &lt; 0) {        close(fd);        return err;    }    printf(&quot;Open tun/tap device: %s for reading...\n&quot;, ifr.ifr_name);    return fd;}int main(){    int tun_fd, nread;    char buffer[1500];    /* Flags: IFF_TUN   - TUN device (no Ethernet headers)     *        IFF_TAP   - TAP device     *        IFF_NO_PI - Do not provide packet information     */    tun_fd = tun_alloc(IFF_TUN | IFF_NO_PI);    if (tun_fd &lt; 0) {        perror(&quot;Allocating interface&quot;);        exit(1);    }    while (1) {        nread = read(tun_fd, buffer, sizeof(buffer));        if (nread &lt; 0) {            perror(&quot;Reading from interface&quot;);            close(tun_fd);            exit(1);        }        printf(&quot;Read %d bytes from tun/tap device\n&quot;, nread);    }    return 0;}</code></pre><h3 id="演示"><a class="header-anchor" href="#演示">¶</a>演示</h3><pre><code>#--------------------------第一个shell窗口----------------------#将上面的程序保存成tun.c，然后编译dev@debian:~$ gcc tun.c -o tun#启动tun程序，程序会创建一个新的tun设备，#程序会阻塞在这里，等着数据包过来dev@debian:~$ sudo ./tunOpen tun/tap device tun1 for reading...Read 84 bytes from tun/tap deviceRead 84 bytes from tun/tap deviceRead 84 bytes from tun/tap deviceRead 84 bytes from tun/tap device#--------------------------第二个shell窗口----------------------#启动抓包程序，抓经过tun1的包# tcpdump -i tun1tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on tun1, link-type RAW (Raw IP), capture size 262144 bytes19:57:13.473101 IP 192.168.3.11 &gt; 192.168.3.12: ICMP echo request, id 24028, seq 1, length 6419:57:14.480362 IP 192.168.3.11 &gt; 192.168.3.12: ICMP echo request, id 24028, seq 2, length 6419:57:15.488246 IP 192.168.3.11 &gt; 192.168.3.12: ICMP echo request, id 24028, seq 3, length 6419:57:16.496241 IP 192.168.3.11 &gt; 192.168.3.12: ICMP echo request, id 24028, seq 4, length 64#--------------------------第三个shell窗口----------------------#./tun启动之后，通过ip link命令就会发现系统多了一个tun设备，#在我的测试环境中，多出来的设备名称叫tun1，在你的环境中可能叫tun0#新的设备没有ip，我们先给tun1配上IP地址dev@debian:~$ sudo ip addr add 192.168.3.11/24 dev tun1#默认情况下，tun1没有起来，用下面的命令将tun1启动起来dev@debian:~$ sudo ip link set tun1 up#尝试ping一下192.168.3.0/24网段的IP，#根据默认路由，该数据包会走tun1设备，#由于我们的程序中收到数据包后，啥都没干，相当于把数据包丢弃了，#所以这里的ping根本收不到返回包，#但在前两个窗口中可以看到这里发出去的四个icmp echo请求包，#说明数据包正确的发送到了应用程序里面，只是应用程序没有处理该包dev@debian:~$ ping -c 4 192.168.3.12PING 192.168.3.12 (192.168.3.12) 56(84) bytes of data.--- 192.168.3.12 ping statistics ---4 packets transmitted, 0 received, 100% packet loss, time 3023ms</code></pre><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>平时我们用到tun/tap设备的机会不多，不过由于其结构比较简单，拿它来了解一下虚拟网络设备还不错，为后续理解Linux下更复杂的虚拟网络设备（比如网桥）做个铺垫。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://www.kernel.org/doc/Documentation/networking/tuntap.txt" target="_blank" rel="noopener">Universal TUN/TAP device driver</a></li><li><a href="http://backreference.org/2010/03/26/tuntap-interface-tutorial/" target="_blank" rel="noopener">Tun/Tap interface tutorial</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rabbit mq 学习总结记录</title>
      <link href="/2020/02/16/mq/rabbitmq/untitled/"/>
      <url>/2020/02/16/mq/rabbitmq/untitled/</url>
      
        <content type="html"><![CDATA[<ol><li>多个 process 可以复用一个连接建立多信道进行多路复用发布消息</li><li>rabbit mq 背压基于 TCP 拥塞控制窗口通知实现，所以一个背压将会对一个 socket 即一个连接上所有信道产生影响</li></ol><blockquote><p>背压(Backpressurre)：</p><p><a href="https://www.zhihu.com/question/49618581" target="_blank" rel="noopener">https://www.zhihu.com/question/49618581</a></p><p><a href="https://lotabout.me/2020/Back-Pressure/#fnref1" target="_blank" rel="noopener">https://lotabout.me/2020/Back-Pressure/#fnref1</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> rabbit mq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mq </tag>
            
            <tag> rabbit mq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>netfilteriptables简介</title>
      <link href="/2020/02/16/linux/network/netfilteriptables-jian-jie/"/>
      <url>/2020/02/16/linux/network/netfilteriptables-jian-jie/</url>
      
        <content type="html"><![CDATA[<p>netfilter和iptables是什么关系？常说的iptables里面的表(table)、链(chain)、规则(rule)都是什么东西？本篇将带着这些疑问介绍netfilter/iptables的结构和相关概念，帮助有需要的同学更好的理解netfilter/iptables，为进一步学习使用iptables做准备。</p><h2 id="什么是netfilter和iptables"><a class="header-anchor" href="#什么是netfilter和iptables">¶</a>什么是netfilter和iptables</h2><p>用通俗点的话来讲:</p><ul><li>netfilter指整个项目，不然官网就不会叫www.netfilter.org了。</li><li>在这个项目里面，netfilter特指内核中的netfilter框架，iptables指用户空间的配置工具。</li><li>netfilter在协议栈中添加了5个钩子，允许内核模块在这些钩子的地方注册回调函数，这样经过钩子的所有数据包都会被注册在相应钩子上的函数所处理，包括修改数据包内容、给数据包打标记或者丢掉数据包等。</li><li>netfilter框架负责维护钩子上注册的处理函数或者模块，以及它们的优先级。</li><li>iptables是用户空间的一个程序，通过netlink和内核的netfilter框架打交道，负责往钩子上配置回调函数。</li><li>netfilter框架负责在需要的时候动态加载其它的内核模块，比如 ip_conntrack、nf_conntrack、NAT subsystem等。</li></ul><blockquote><p>在应用者的眼里，可能iptables代表了整个项目，代表了防火墙，但在开发者眼里，可能netfilter更能代表这个项目。</p></blockquote><h2 id="netfilter钩子（hooks）"><a class="header-anchor" href="#netfilter钩子（hooks）">¶</a>netfilter钩子（hooks）</h2><p>在内核协议栈中，有5个跟netfilter有关的钩子，数据包经过每个钩子时，都会检查上面是否注册有函数，如果有的话，就会调用相应的函数处理该数据包，它们的位置见下图：</p><pre><code>         |         | Incoming         ↓+-------------------+| NF_IP_PRE_ROUTING |+-------------------+         |         |         ↓+------------------+|                  |         +----------------+| routing decision |--------&gt;| NF_IP_LOCAL_IN ||                  |         +----------------++------------------+                 |         |                           |         |                           ↓         |                  +-----------------+         |                  | local processes |         |                  +-----------------+         |                           |         |                           |         ↓                           ↓ +---------------+          +-----------------+ | NF_IP_FORWARD |          | NF_IP_LOCAL_OUT | +---------------+          +-----------------+         |                           |         |                           |         ↓                           |+------------------+                 ||                  |                 || routing decision |&lt;----------------+|                  |+------------------+         |         |         ↓+--------------------+| NF_IP_POST_ROUTING |+--------------------+         |         | Outgoing         ↓</code></pre><ul><li>NF_IP_PRE_ROUTING: 接收的数据包刚进来，还没有经过路由选择，即还不知道数据包是要发给本机还是其它机器。</li><li>NF_IP_LOCAL_IN: 已经经过路由选择，并且该数据包的目的IP是本机，进入本地数据包处理流程。</li><li>NF_IP_FORWARD: 已经经过路由选择，但该数据包的目的IP不是本机，而是其它机器，进入forward流程。</li><li>NF_IP_LOCAL_OUT: 本地程序要发出去的数据包刚到IP层，还没进行路由选择。</li><li>NF_IP_POST_ROUTING: 本地程序发出去的数据包，或者转发（forward）的数据包已经经过了路由选择，即将交由下层发送出去。</li></ul><blockquote><p>关于这些钩子更具体的位置，请参考<a href="https://segmentfault.com/a/1190000008836467" target="_blank" rel="noopener">Linux网络数据包的接收过程</a>和<a href="https://segmentfault.com/a/1190000008926093" target="_blank" rel="noopener">数据包的发送过程</a></p></blockquote><p>从上面的流程中，我们还可以看出，不考虑特殊情况的话，一个数据包只会经过下面三个路径中的一个：</p><ul><li>本机收到目的IP是本机的数据包: NF_IP_PRE_ROUTING -&gt; NF_IP_LOCAL_IN</li><li>本机收到目的IP不是本机的数据包: NF_IP_PRE_ROUTING -&gt; NF_IP_FORWARD -&gt; NF_IP_POST_ROUTING</li><li>本机发出去的数据包: NF_IP_LOCAL_OUT -&gt; NF_IP_POST_ROUTING</li></ul><blockquote><p>注意： netfilter所有的钩子（hooks）都是在内核协议栈的IP层，由于IPv4和IPv6用的是不同的IP层代码，所以iptables配置的rules只会影响IPv4的数据包，而IPv6相关的配置需要使用ip6tables。</p></blockquote><h2 id="iptables中的表（tables）"><a class="header-anchor" href="#iptables中的表（tables）">¶</a>iptables中的表（tables）</h2><p>iptables用表（table）来分类管理它的规则（rule），根据rule的作用分成了好几个表，比如用来过滤数据包的rule就会放到filter表中，用于处理地址转换的rule就会放到nat表中，其中rule就是应用在netfilter钩子上的函数，用来修改数据包的内容或过滤数据包。目前iptables支持的表有下面这些：</p><h4 id="Filter"><a class="header-anchor" href="#Filter">¶</a>Filter</h4><p>从名字就可以看出，这个表里面的rule主要用来过滤数据，用来控制让哪些数据可以通过，哪些数据不能通过，它是最常用的表。</p><h4 id="NAT"><a class="header-anchor" href="#NAT">¶</a>NAT</h4><p>里面的rule都是用来处理网络地址转换的，控制要不要进行地址转换，以及怎样修改源地址或目的地址，从而影响数据包的路由，达到连通的目的，这是家用路由器必备的功能。</p><h4 id="Mangle"><a class="header-anchor" href="#Mangle">¶</a>Mangle</h4><p>里面的rule主要用来修改IP数据包头，比如修改TTL值，同时也用于给数据包添加一些标记，从而便于后续其它模块对数据包进行处理（这里的添加标记是指往内核skb结构中添加标记，而不是往真正的IP数据包上加东西）。</p><h4 id="Raw"><a class="header-anchor" href="#Raw">¶</a>Raw</h4><p>在netfilter里面有一个叫做connection tracking的功能（后面会介绍到），主要用来追踪所有的连接，而raw表里的rule的功能是给数据包打标记，从而控制哪些数据包不被connection tracking所追踪。</p><h4 id="Security"><a class="header-anchor" href="#Security">¶</a>Security</h4><p>里面的rule跟SELinux有关，主要是在数据包上设置一些SELinux的标记，便于跟SELinux相关的模块来处理该数据包。</p><h2 id="chains"><a class="header-anchor" href="#chains">¶</a>chains</h2><p>上面我们根据不同功能将rule放到了不同的表里面之后，这些rule会注册到哪些钩子上呢？于是iptables将表中的rule继续分类，让rule属于不同的链（chain），由chain来决定什么时候触发chain上的这些rule。</p><p>iptables里面有5个内置的chains，分别对应5个钩子：</p><ul><li>PREROUTING: 数据包经过NF_IP_PRE_ROUTING时会触发该chain上的rule.</li><li>INPUT: 数据包经过NF_IP_LOCAL_IN时会触发该chain上的rule.</li><li>FORWARD: 数据包经过NF_IP_FORWARD时会触发该chain上的rule.</li><li>OUTPUT: 数据包经过NF_IP_LOCAL_OUT时会触发该chain上的rule.</li><li>POSTROUTING: 数据包经过NF_IP_POST_ROUTING时会触发该chain上的rule.</li></ul><p>每个表里面都可以包含多个chains，但并不是每个表都能包含所有的chains，因为某些表在某些chain上没有意义或者有些多余，比如说raw表，它只有在connection tracking之前才有意义，所以它里面包含connection tracking之后的chain就没有意义。（connection tracking的位置会在后面介绍到）</p><p>多个表里面可以包含同样的chain，比如在filter和raw表里面，都有OUTPUT chain，那应该先执行哪个表的OUTPUT chain呢？这就涉及到后面会介绍的优先级的问题。</p><blockquote><p>提示：可以通过命令<code>iptables -L -t nat|grep policy|grep Chain</code>查看到nat表所支持的chain，其它的表也可以用类似的方式查看到，比如修改nat为raw即可看到raw表所支持的chain。</p></blockquote><h2 id="每个表（table）都包含哪些chain，表之间的优先级是怎样的？"><a class="header-anchor" href="#每个表（table）都包含哪些chain，表之间的优先级是怎样的？">¶</a>每个表（table）都包含哪些chain，表之间的优先级是怎样的？</h2><p>下图在上面那张图的基础上，详细的标识出了各个表的rule可以注册在哪个钩子上（即各个表里面支持哪些chain），以及它们的优先级。</p><blockquote><ol><li>图中每个钩子关联的表按照优先级高低，从上到下排列；</li><li>图中将nat分成了SNAT和DNAT，便于区分；</li><li>图中标出了connection tracking（可以简单的把connection tracking理解成一个不能配置chain和rule的表，它必须放在指定位置，只能enable和disable）。</li></ol></blockquote><pre><code>                                    |                                    | Incoming             ++---------------------++                                    ↓                      || raw                 ||                           +-------------------+           || connection tracking ||                           | NF_IP_PRE_ROUTING |= = = = = =|| mangle              ||                           +-------------------+           || nat (DNAT)          ||                                    |                      ++---------------------++                                    |                                    ↓                                                ++------------++                           +------------------+                                      || mangle     ||                           |                  |         +----------------+           || filter     ||                           | routing decision |--------&gt;| NF_IP_LOCAL_IN |= = = = = =|| security   ||                           |                  |         +----------------+           || nat (SNAT) ||                           +------------------+                 |                    ++------------++                                    |                           |                                    |                           ↓                                    |                  +-----------------+                                    |                  | local processes |                                    |                  +-----------------+                                    |                           |                                    |                           |                    ++---------------------++ ++------------++                   ↓                           ↓                    || raw                 || || mangle     ||           +---------------+          +-----------------+           || connection tracking || || filter     ||= = = = = =| NF_IP_FORWARD |          | NF_IP_LOCAL_OUT |= = = = = =|| mangle              || || security   ||           +---------------+          +-----------------+           || nat (DNAT)          || ++------------++                   |                           |                    || filter              ||                                    |                           |                    || security            ||                                    ↓                           |                    ++---------------------++                           +------------------+                 |                           |                  |                 |                           | routing decision |&lt;----------------+                           |                  |                           +------------------+                                    |                                    |                                    ↓                           +--------------------+           ++------------++                           | NF_IP_POST_ROUTING |= = = = = =|| mangle     ||                           +--------------------+           || nat (SNAT) ||                                    |                       ++------------++                                    | Outgoing                                    ↓</code></pre><ul><li>以NF_IP_PRE_ROUTING为例，数据包到了这个点之后，会先执行raw表中PREROUTING(chain)里的rule，然后执行connection tracking，接着再执行mangle表中PREROUTING(chain)里的rule，最后执行nat (DNAT)表中PREROUTING(chain)里的rule。</li><li>以filter表为例，它只能注册在NF_IP_LOCAL_IN、NF_IP_FORWARD和NF_IP_LOCAL_OUT上，所以它只支持INPUT、FORWARD和OUTPUT这三个chain。</li><li>以收到目的IP是本机的数据包为例，它的传输路径为：NF_IP_PRE_ROUTING -&gt; NF_IP_LOCAL_IN，那么它首先要依次经过NF_IP_PRE_ROUTING上注册的raw、connection tracking 、mangle和nat (DNAT)，然后经过NF_IP_LOCAL_IN上注册的mangle、filter、security和nat (SNAT)。</li></ul><h2 id="iptables中的规则（Rules）"><a class="header-anchor" href="#iptables中的规则（Rules）">¶</a>iptables中的规则（Rules）</h2><p>rule存放在特定表的特定chain上，每条rule包含下面两部分信息：</p><h4 id="Matching"><a class="header-anchor" href="#Matching">¶</a>Matching</h4><p>Matching就是如何匹配一个数据包，匹配条件很多，比如协议类型、源/目的IP、源/目的端口、in/out接口、包头里面的数据以及连接状态等，这些条件可以任意组合从而实现复杂情况下的匹配。详情请参考<a href="https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html#MATCHES" target="_blank" rel="noopener">Iptables matches</a></p><h4 id="Targets"><a class="header-anchor" href="#Targets">¶</a>Targets</h4><p>Targets就是找到匹配的数据包之后怎么办，常见的有下面几种：</p><ul><li>DROP：直接将数据包丢弃，不再进行后续的处理</li><li>RETURN： 跳出当前chain，该chain里后续的rule不再执行</li><li>QUEUE： 将数据包放入用户空间的队列，供用户空间的程序处理</li><li>ACCEPT： 同意数据包通过，继续执行后续的rule</li><li>跳转到其它用户自定义的chain继续执行</li></ul><p>当然iptables包含的targets很多很多，但并不是每个表都支持所有的targets，<br>rule所支持的target由它所在的表和chain以及所开启的扩展功能来决定，具体每个表支持的targets请参考<a href="https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html#TARGETS" target="_blank" rel="noopener">Iptables targets and jumps</a>。</p><h2 id="用户自定义Chains"><a class="header-anchor" href="#用户自定义Chains">¶</a>用户自定义Chains</h2><p>除了iptables预定义的5个chain之外，用户还可以在表中定义自己的chain，用户自定义的chain中的rule和预定义chain里的rule没有区别，不过由于自定义的chain没有和netfilter里面的钩子进行绑定，所以它不会自动触发，只能从其它chain的rule中跳转过来。</p><h2 id="连接追踪（Connection-Tracking）"><a class="header-anchor" href="#连接追踪（Connection-Tracking）">¶</a>连接追踪（Connection Tracking）</h2><p>Connection Tracking发生在NF_IP_PRE_ROUTING和NF_IP_LOCAL_OUT这两个地方，一旦开启该功能，Connection Tracking模块将会追踪每个数据包（被raw表中的rule标记过的除外），维护所有的连接状态，然后这些状态可以供其它表中的rule引用，用户空间的程序也可以通过/proc/net/ip_conntrack来获取连接信息。下面是所有的连接状态：</p><blockquote><p>这里的连接不仅仅是TCP的连接，两台设备的进程用UDP和ICMP（ping）通信也会被认为是一个连接</p></blockquote><ul><li>NEW: 当检测到一个不和任何现有连接关联的新包时，如果该包是一个合法的建立连接的数据包（比如TCP的sync包或者任意的UDP包），一个新的连接将会被保存，并且标记为状态NEW。</li><li>ESTABLISHED: 对于状态是NEW的连接，当检测到一个相反方向的包时，连接的状态将会由NEW变成ESTABLISHED，表示连接成功建立。对于TCP连接，意味着收到了一个SYN/ACK包， 对于UDP和ICMP，任何反方向的包都可以。</li><li>RELATED: 数据包不属于任何现有的连接，但它跟现有的状态为ESTABLISHED的连接有关系，对于这种数据包，将会创建一个新的连接，且状态被标记为RELATED。这种连接一般是辅助连接，比如FTP的数据传输连接（FTP有两个连接，另一个是控制连接），或者和某些连接有关的ICMP报文。</li><li>INVALID: 数据包不和任何现有连接关联，并且不是一个合法的建立连接的数据包，对于这种连接，将会被标记为INVALID，一般这种都是垃圾数据包，比如收到一个TCP的RST包，但实际上没有任何相关的TCP连接，或者别的地方误发过来的ICMP包。</li><li>UNTRACKED: 被raw表里面的rule标记为不需要tracking的数据包，这种连接将会标记成UNTRACKED。</li></ul><h2 id="结束语"><a class="header-anchor" href="#结束语">¶</a>结束语</h2><p>本篇介绍了netfilter/iptables的基本结构和一些相关概念，了解这些只是一个开始，要想熟练的配置iptables规则，还需要对计算机网络知识非常熟悉，下次有机会的话再介绍如何使用iptables。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html" target="_blank" rel="noopener">Iptables Tutorial</a></li><li><a href="https://www.digitalocean.com/community/tutorials/a-deep-dive-into-iptables-and-netfilter-architecture" target="_blank" rel="noopener">A Deep Dive into Iptables and Netfilter Architecture</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis Sentinel(哨兵) 文档</title>
      <link href="/2020/02/16/redis/redis-guan-fang-wen-dang/shao-bing/"/>
      <url>/2020/02/16/redis/redis-guan-fang-wen-dang/shao-bing/</url>
      
        <content type="html"><![CDATA[<h3 id="Redis-Sentinel-哨兵-文档"><a class="header-anchor" href="#Redis-Sentinel-哨兵-文档">¶</a>Redis Sentinel(哨兵) 文档</h3><p>Redis Sentinel提供了 redis 的高可用方案。即你可以使用 Sentinel 实施一个 redis 部署从而在一些灾难发生的时候不用人为地进行故障转移(failover)。</p><p>Redis Sentinel还提供了一些相关的能力如：监控、通知、作为客户端的配置供给者。以下是 Sentinel 的所有能力的一个概述：</p><ul><li>**监控(Monitoring)。**Sentinel 周期地检查你的主从(master and replicas)实例是否在正常地运行。</li><li>**通知(Notification)。**当某个被监控的 redis 实例发生异常的时候，Sentinel 可以通过一个 API 通知系统管理员或者其他计算机程序。</li><li>**自动故障转移(Automatic failover)。**当一个主节点不能正常工作的时候，Sentinel 会开始一个故障转移处理：将一个从节点提升为主节点，其他从节点被指令复制新的主节点，那些正在连接着 redis 服务的程序将被通知连接新的主节点。</li><li>**配置供给者(Configuration provider)。**Sentinel 作为客户端的服务发现中心：客户端连接到 Sentinels 以获取当前可用的 redis 主节点的地址。如果一个故障转移发生，Sentinels 会返回新的地址。</li></ul><h4 id="天然支持分布式的-Sentinel"><a class="header-anchor" href="#天然支持分布式的-Sentinel">¶</a>天然支持分布式的 Sentinel</h4><p>Redis Sentinel 是一个分布式系统：</p><p>Sentinel 本身的设计出发点就是有多个 Sentinel 进程同时在合作运行的。以下是有多个 Sentinel 实例进行合作的优点：</p><ol><li>当有多个 Sentinels 同时认为一个主节点不再可用的时候才会认为一个故障发生了。降低误报的可能性。</li><li>即使有一些 Sentinel 进程出现故障 Sentinel 也能正常工作，提高系统的健壮性。毕竟，拥有故障转移系统本身就是一个单点故障，这没有任何乐趣？（这句翻译软件翻的，看不太懂：There is no fun in having a failover system which is itself a single point of failure, after all.）</li></ol><p>所有的 Sentinel 节点、Redis 实例(所有主从节点)以及那些连接着 Sentinel 和 Redis 的客户端，也是一个拥有特定属性的大分布式系统。本文档将从一些为了理解 Sentinel 的基本属性而必要的基础信息，到那些为了深入理解 Sentinel 工作机制的更复杂的信息(非必要)，渐进地对一些概念进行介绍。</p><h3 id="快速开始"><a class="header-anchor" href="#快速开始">¶</a>快速开始</h3><h4 id="获取-Sentinel"><a class="header-anchor" href="#获取-Sentinel">¶</a>获取 Sentinel</h4><p>Sentinel 的当前版本是 Sentinel 2。它使用了更强大、易于预测的算法对 Sentinel 的原始版本进行了重写(本文档将会进行介绍)。</p><p>它的稳定版本从 Redis 2.8 开始提供。</p><p>新的开发在<code>unstable</code>(不稳定)分支中开发，新特性一旦被认为是稳定的将会被移到最新的稳定分支中。Redis Sentinel 版本1，从 Redis 2.6开始发布，现在已经被废弃，不建议使用。</p><h4 id="运行-Sentinel"><a class="header-anchor" href="#运行-Sentinel">¶</a>运行 Sentinel</h4><p>如果你正在使用可运行的<code>redis-sentinel</code>程序(或者你有一个可运行<code>redis-server</code>程序的<a href="https://blog.csdn.net/qq_28897525/article/details/80657465" target="_blank" rel="noopener">软链接</a>)，你可以使用以下命令来运行 Sentinel：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">redis-sentinel /path/to/sentinel.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>或者你可以直接使用<code>redis-server</code> 可执行程序以 Sentinel 的模式启动：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">redis-server /path/to/sentinel.conf --sentinel<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>以上的两种方式其实工作机制是一样的。</p><p>当要启动 Sentinel 的时候一定要指定一个配置文件，因为系统在重启时需要将当时的系统状态进行保存以及重载的时候使用这个配置文件。如果没有指定配置文件或者文件路径不可写，Sentinel 会拒绝启动。</p><p>Sentinels 默认监听 TCP 26379 端口，所以为了 Sentinels 正常工作，你的服务器的 26379 端口一定要打开以接收其他 Sentinel 实例的连接。(可以修改？)否则 Sentinels 无法沟通，无法投票，故而故障转移将无法进行。</p><h4 id="部署-Sentinel-须知"><a class="header-anchor" href="#部署-Sentinel-须知">¶</a>部署 Sentinel 须知</h4><ol><li>你至少需要3个 Sentinel 实例才会使得部署具备健壮性。</li><li>这3个 Sentinel 实例的部署位置如服务器或者虚拟机应该保证它们的故障不会互相影响。例如不同的物理机或者运行在不同可用分区上的虚拟机。</li><li>Sentinel+Redis分布式系统并不能保证在故障期间保留已确认的写入，因为Redis使用异步复制。然而有一些部署Sentinel的方法，使得丢失写入的窗口限制在某些时刻，同时还有其他不太安全的部署方式。</li><li>你的客户端需要支持 Sentinel。受欢迎的客户端的库对 Sentinel 进行了支持，但不是所有都支持。</li><li>你需要在开发环境中不时地测试你的 HA (高可用 High Availability)配置(如果允许的话，尽量在生产环境也要测试)是否可行，不然无法保证该配置是否安全。你可能只有在为时已晚的时候才发现配置错误（凌晨3点你的主节点宕掉了）</li><li>Sentinel、Docker、或者其他形式的 NAT(Network Address Translation) 或者端口映射(Port Mapping)同时使用的时候需要注意：Docker 使用了端口映射，阻断了 Sentinel 自动发现其他 Sentinel 进程和主节点的从节点们。请参考下面的关于 Sentinel 和 Dcoker 的章节。</li></ol><h4 id="配置-Sentinel"><a class="header-anchor" href="#配置-Sentinel">¶</a>配置 Sentinel</h4><p>Redis 源码发行版包含一个名为<code>sentinel.conf</code>的文件，它是一个带有解释的配置文件示例，你可以使用它来配置 Sentinel。一个典型的最小的配置文件如下所示：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 60000sentinel failover-timeout mymaster 180000sentinel parallel-syncs mymaster 1sentinel monitor resque 192.168.1.3 6380 4sentinel down-after-milliseconds resque 10000sentinel failover-timeout resque 180000sentinel parallel-syncs resque 5<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>你只需要定义需要监控的 master 节点们，为每个不同的主实例 (可能拥有一些从实例)提供一个唯一的名字。你无需定义从实例，Sentinel 会根据主实例自动发现从实例。Sentinel 将会自动地在配置中更新关于从服务器的这些额外信息(为了在重启的时候保存信息)。该配置在每次故障转移中从实例提升为主实例以及每次一个新 Sentinel 进程被发现的时候都会被重写。</p><p>上面的配置示例简单地监控着两组 Redis 实例，每组由一个主实例和未知数量的从实例组成。其中一组实例被命名为<code>mymaster</code>，另外一组为<code>resque</code>。<code>sentinel monitor</code> 语句的各个参数的意义如下所示：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">sentinel monitor <master-group-name> <ip> <port> <quorum><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>为了清晰起见，让我们逐行地来解析配置选项地意义：</p><p>第一行是用来指示 Redis 监控一个主实例，命名为<code>mymaster</code>，其地址为<code>127.0.0.1</code>，端口为<code>6379</code>，<code>quorum</code>为2。除了<code>quorum</code> 参数之外其他都是清晰明了的：</p><ul><li><code>quorum</code>表示：当前 Sentinel 将一个主实例定义为故障(也称客观下线，同时每个 Sentinel 进程都有自己的一个判断主实例是否主观下线的条件) 需要<code>quorum</code>个 Sentines 实例同时认同该主实例已经下线的事实(即需要<code>quorum</code>个 Sentinels 同时主观地认为该实例已经下线，<strong>当前</strong> Sentinel 才会认为该实例已经客观下线)。</li><li>不过<code>quorum</code>仅仅被用来判定故障。为了实际地执行一次故障转移，其中一个 Sentinel 需要被选举成本次故障转移的领袖并被授权于执行故障转移。而这只有获得了大多数(N/2+1) Sentinel 进程的投票才会进行。</li></ul><p>例如如果你拥有5个 Sentinel 进程， 某个主实例的<code>quorum</code>设置为2（So for example if you have 5 Sentinel processes, and the quorum for a given master set to the value of 2, this is what happens:）：</p><ul><li>如果2个 Sentinels 同时(主观)认为该主实例已经下线，它们两个之一就会发起一次故障转移。(If two Sentinels agree at the same time about the master being unreachable, one of the two will try to start a failover. 这里应该有问题，实际上每个 Sentinel 进程对于每个主实例设置的<code>quorum</code>都可能不一样，而<code>quorum</code>是某个 Sentinel 认为某个主实例客观下线的条件，而发起故障转移的 Sentinel 应该由所有认为该实例已经客观下线的 Sentinels 中诞生。所以如果这里是将所有 Sentinel 中该主实例的<code>quorum</code>都设置为2，那么就应该是5个 Sentinels 之一而不是 one of two；只有当前提条件是2个 Sentinels 进程设置<code>quorum</code>为2这句话才成立，上面给的前提不太清晰)。</li><li>如果至少总计有3个 Sentinels 可访问，该故障转移将会被授权并执行。</li></ul><p>实际上这意味着在故障期间如果大多数的 Sentinel 进程无法通信故障转移将不会进行（也称在少数分区不会执行故障转移）。</p><h4 id="其他-Sentinel-选项"><a class="header-anchor" href="#其他-Sentinel-选项">¶</a>其他 Sentinel 选项</h4><p>其他的选项几乎都是这样的形式：</p><pre class="line-numbers language-language-shell"><code class="language-language-shell">sentinel <option_name> <master_name> <option_value><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>以及被用在以下场景：</p><ul><li><code>down-after-milliseconds</code>：当一个 Sentinel 经过了<code>down-after-milliseconds</code>个毫秒也无法和一个实例进行通信（无论是该实例没有恢复我们的<code>PING</code>命令还是回复了一个错误），该 Sentinel 就会主观地认为该实例已经下线。（之后会进入判断客观下线阶段，即向其他 Sentinels 确认它们是否也认为该实例主观下线，有<code>quorum</code>个 Sentinels 同意，当前 Sentinel 将会认为该实例已经客观下线）。</li><li><code>parallel-syncs</code>：该数值表示在一次故障转移之后可以并行复制新主实例的从实例数量(即新主实例同时向多个从实例同步数据，这会产生并行复制从实例数量的带宽占用)。这个数值越小，故障转移处理完成需要的时间越长(数量为1时，表示同一时间只同步一个从实例，同步动作完全串行)，但是如果从实例被配置为服务旧数据，你可能不想所有的从实例同时与主实例进行数据重同步。虽然复制过程(数据同步)几乎不会阻塞一个从实例，但是在其停止从主实例加载批量数据 (buik data) 之后的小段时间会阻塞。你可能会想限制同一时间确切地只有一个从实例无法访问，此时可以设置该选项为1。</li></ul><p>其他选项在下面进行介绍，同时在 Redis 发行版中携带的<code>sentinel.conf</code>文件也进行了描述。</p><p>所有的配置参数都可以在运行时通过<code>sentinel set</code>命令进行修改。请参考<strong>在运行时修改 Sentinel 配置</strong>章节。</p><h4 id="Sentinel-部署方案示例"><a class="header-anchor" href="#Sentinel-部署方案示例">¶</a>Sentinel 部署方案示例</h4><p>现在你已经了解了 Sentinel 的基本信息，你可能会对于你应该将 Sentinel 进程部署在哪里、应该部署多少个 Sentinel 进程等等问题产生疑惑。本章节展示了几个部示例。我们使用 ASCII 码以图形的形式向你展示配置的样例，以下我们对一些图案进行了定义：</p><pre><code>+--------------------+| This is a computer || or VM that fails   || independently. We  || call it a &quot;box&quot;    |+--------------------+</code></pre><p>我们在盒子中写的内容正在其中运行：</p><pre><code>+-------------------+| Redis master M1   || Redis Sentinel S1 |+-------------------+</code></pre><p>不同的盒子使用线条进行连接，表示它们是可以通信的：</p><pre><code>+-------------+               +-------------+| Sentinel S1 |---------------| Sentinel S2 |+-------------+               +-------------+</code></pre><p>网络分区(Network partitions)以两个斜杠断开线条来表示：</p><pre><code>+-------------+                +-------------+| Sentinel S1 |------ // ------| Sentinel S2 |+-------------+                +-------------+</code></pre><p>以及：</p><ul><li>Masters（主实例）被命名为 M1，M2，M3，…，Mn。</li><li>Replicas（从实例）被命名为 R1，R2，R3，…，Rn。</li><li>Sentinels 被命名为 S1，S2，S3，…，Sn。</li><li>Clients 被命名为 C1，C2，C3，…，Cn。</li><li>当一个实例由于 Seneinel 的一系列动作发生了角色变更，我们使用中括号将其包裹起来，所以 [M1] 表示一个实例现在由于 Sentinel 的干涉称为了一个主实例。</li></ul><h4 id="示例1：仅部署两个-Sentinels，不要这样做！"><a class="header-anchor" href="#示例1：仅部署两个-Sentinels，不要这样做！">¶</a>示例1：仅部署两个 Sentinels，<strong>不要这样做！</strong></h4><pre><code>+----+         +----+| M1 |---------| R1 || S1 |         | S2 |+----+         +----+Configuration: quorum = 1</code></pre><ul><li>在该配置中，如果主实例 M1 故障，在两个 Sentinels 可以通信并认为其已经客观下线（<code>quorum</code>被设置为1）的情况下，R1 将被提升为主实例并可以被授权进行故障转移，因为2个Sentinel 都可以进行通信(并进行故障转移领头 Sentinel 选举)。所以目前看来它是可行的，但是请看下面的描述介绍了该配置为什么不可行。</li><li>如果 M1 所在的盒子故障了，当然 S1 也就故障了。运行在另外一个盒子中的 Sentinel S2将不能被授权(2/2+1=2，至少2个 Sentinel 才是&quot;大多数&quot;)发起故障转移，所以整个系统将无法访问(无法选举出新的 master，整个 redis 系统无法提供正常服务)。</li></ul><p>请注意多数投票对于不同的故障转移动作是必须的，并在之后会传播最新的配置到所有的 Sentinels。同时还要注意基于上面的配置，如果允许不经过多数投票的单点故障转移，将是非常危险的：</p><pre><code>+----+           +------+| M1 |----//-----| [M1] || S1 |           | S2   |+----+           +------+</code></pre><p>在以上的配置我们以非常对称的方式创建了两个主实例（假设 S2 可以在未经授权的情况进行故障转移）。客户端们分别向这两个主实例一直写入数据，然后在分区恢复的时候将无法判断出哪个才是主实例（以及哪边才是正确的配置）。所以为了<em>防止永久脑裂</em>，请至少分别在3个不同的盒子中部署3个 Sentinels。</p><h4 id="示例2：基于3个盒子的基本配置"><a class="header-anchor" href="#示例2：基于3个盒子的基本配置">¶</a>示例2：基于3个盒子的基本配置</h4><p>这是一个非常简单的配置，它拥有</p><h4 id="在运行时修改-Sentinel-配置"><a class="header-anchor" href="#在运行时修改-Sentinel-配置">¶</a>在运行时修改 Sentinel 配置</h4>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 哨兵 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《redis实战》读书笔记</title>
      <link href="/2020/02/16/redis/redis-shi-zhan/001-chu-shi-redis/"/>
      <url>/2020/02/16/redis/redis-shi-zhan/001-chu-shi-redis/</url>
      
        <content type="html"><![CDATA[<h1>Redis 简介</h1><p>Redis是一个速度非常快的非关系数 据库(non-relational database)，它可以存储键(key)与 5 种不同类型的值(value)之间的映射(mapping)，可以将存储在内存的键值对数据持久化到硬盘，可以使用复制特性来扩 展读性能，还可以使用客户端分片来扩展写性能。</p><h3 id><a class="header-anchor" href="#">¶</a></h3>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>8、user namespace (CLONE_NEWUSER) (第二部分)</title>
      <link href="/2020/02/16/linux/namespace/8-user-namespace-clone-newuser-di-er-bu-fen/"/>
      <url>/2020/02/16/linux/namespace/8-user-namespace-clone-newuser-di-er-bu-fen/</url>
      
        <content type="html"><![CDATA[<p>本篇将主要介绍user namespace和其他类型的namespace的关系。</p><p>权限涉及的范围非常广，所以导致user namespace比其他的namespace要复杂； 同时权限也是容器安全的基础，所以user namespace非常重要。</p><blockquote><p>本篇所有例子都在ubuntu-server-x86_64 16.04下执行通过</p></blockquote><h2 id="和其他类型的namespace一起使用"><a class="header-anchor" href="#和其他类型的namespace一起使用">¶</a>和其他类型的namespace一起使用</h2><p>除了user namespace外，创建其它类型的namespace都需要CAP_SYS_ADMIN的capability。当新的user namespace创建并映射好uid、gid了之后， 这个user namespace的第一个进程将拥有完整的所有capabilities，意味着它就可以创建新的其它类型namespace</p><pre><code>#先记下默认的user namespace编号dev@ubuntu:~$ readlink /proc/$$/ns/useruser:[4026531837]#用非root账号创建新的user namespacedev@ubuntu:~$ unshare --user -r /bin/bashroot@ubuntu:~# readlink /proc/$$/ns/useruser:[4026532463]#虽然新user namespace的root账号映射到外面的dev账号#但还是能创建新的ipc namespace，因为当前bash进程拥有全部的capabilitiesroot@ubuntu:~# cat /proc/$$/status | egrep 'Cap(Inh|Prm|Eff)'CapInh: 0000000000000000CapPrm: 0000003fffffffffCapEff: 0000003fffffffffroot@ubuntu:~# readlink /proc/$$/ns/ipcipc:[4026531839]root@ubuntu:~# unshare --ipc /bin/bashroot@ubuntu:~# readlink /proc/$$/ns/ipcipc:[4026532469]</code></pre><p>当然我们也可以不用这么一步一步的创建，而是一步到位</p><pre><code>dev@ubuntu:~$ readlink /proc/$$/ns/useruser:[4026531837]dev@ubuntu:~$ readlink /proc/$$/ns/ipcipc:[4026531839]dev@ubuntu:~$ unshare --user -r --ipc /bin/bashroot@ubuntu:~# readlink /proc/$$/ns/useruser:[4026532463]root@ubuntu:~# readlink /proc/$$/ns/ipcipc:[4026532469]</code></pre><p>在unshare的实现中，就是传入了CLONE_NEWUSER | CLONE_NEWIPC，大致如下</p><pre><code>unshare(CLONE_NEWUSER | CLONE_NEWIPC);</code></pre><p>在上面这种情况下，内核会保证CLONE_NEWUSER先被执行，然后执行剩下的其他CLONE_NEW*，这样就使得不用root账号而创建新的容器成为可能，这条规则对于clone函数也同样适用。</p><h2 id="和其他类型namespace的关系"><a class="header-anchor" href="#和其他类型namespace的关系">¶</a>和其他类型namespace的关系</h2><p>Linux下的每个namespace，都有一个user namespace和他关联，这个user namespace就是创建相应namespace时进程所属的user namespace，相当于每个namespace都有一个owner（user namespace），这样保证对任何namespace的操作都受到user namespace权限的控制。这也是上一篇中为什么sethostname失败的原因，因为要修改的uts namespace属于的父user namespace，而新user namespace的进程没有老user namespace的任何capabilities。</p><p>这里可以看看uts namespace的结构体，里面有一个指向user namespace的指针，指向他所属于的user namespace，其他类型的namespace也类似。</p><pre><code>struct uts_namespace {  struct kref kref;  struct new_utsname name;  struct user_namespace *user_ns;  struct ns_common ns;};</code></pre><h2 id="不和任何user-namespace关联的资源"><a class="header-anchor" href="#不和任何user-namespace关联的资源">¶</a>不和任何user namespace关联的资源</h2><p>在系统中，有些需要特权操作的资源没有跟任何user namespace关联，比如修改系统时间（需要CAP_SYS_MODULE）、创建设备（需要CAP_MKNOD），这些操作只能由initial user namespace里有相应权限的进程来操作（这里initial user namespace就是系统启动后的默认user namespace）。</p><h2 id="和mount-namespace的关系"><a class="header-anchor" href="#和mount-namespace的关系">¶</a>和mount namespace的关系</h2><ul><li>当和mount namespace一起用时，不能挂载基于块设备的文件系统，但是可以挂载下面这些文件系统</li></ul><pre><code>     #摘自user namespaces帮助文件：      #http://man7.org/linux/man-pages/man7/user_namespaces.7.html     * /proc (since Linux 3.8)       * /sys (since Linux 3.8)      * devpts (since Linux 3.9)     * tmpfs (since Linux 3.9)     * ramfs (since Linux 3.9)     * mqueue (since Linux 3.9)     * bpf (since Linux 4.4)</code></pre><p>示例</p><pre><code>#创建新的user和mount namespacedev@ubuntu:~$ unshare --user -r --mount bashroot@ubuntu:~# mkdir ./mnt#查找挂载到根目录的设备root@ubuntu:~#  mount|grep &quot; / &quot;/dev/mapper/ubuntu--vg-root on / type ext4 (rw,relatime,errors=remount-ro,data=ordered)#确认这个设备肯定是块设备root@ubuntu:~# ls -l /dev/mapper/ubuntu--vg-rootlrwxrwxrwx 1 nobody nogroup 7 7月  30 11:22 /dev/mapper/ubuntu--vg-root -&gt; ../dm-0root@ubuntu:~# file /dev/dm-0/dev/dm-0: block special (252/0)#尝试把他挂载到其他目录，结果挂载失败，说明在新的user namespace下没法挂载块设备root@ubuntu:~# mount /dev/mapper/ubuntu--vg-root ./mntmount: /dev/mapper/ubuntu--vg-root is write-protected, mounting read-onlymount: cannot mount /dev/mapper/ubuntu--vg-root read-only#即使是root账号映射过去也不行（这里mount的错误提示的好像不太准确）root@ubuntu:~$ exitexitdev@ubuntu:~$ sudo unshare --user -r --mount bashroot@ubuntu:~# mount /dev/mapper/ubuntu--vg-root ./mntmount: /dev/mapper/ubuntu--vg-root is already mounted or /home/dev/mnt busy       /dev/mapper/ubuntu--vg-root is already mounted on /#由于当前pid namespace不属于当前的user namespace，所以挂载/proc失败root@ubuntu:~# mount -t proc none ./mntmount: permission denied#创建新的pid namespace，然后挂载成功root@ubuntu:~# unshare --pid --fork bashroot@ubuntu:~# mount -t proc none ./mntroot@ubuntu:~# mount |grep mnt|grep procnone on /home/dev/mnt type proc (rw,nodev,relatime)root@ubuntu:~# exitexit#只能通过bind方式挂载devpts，直接mount报错root@ubuntu:~# mount -t devpts devpts ./mntmount: wrong fs type, bad option, bad superblock on devpts,       missing codepage or helper program, or other error       In some cases useful info is found in syslog - try       dmesg | tail or so.root@ubuntu:~# mount --bind /dev/pts ./mntroot@ubuntu:~# mount|grep mnt|grep devptsdevpts on /home/dev/mnt type devpts (rw,nosuid,noexec,relatime,mode=600,ptmxmode=000)#sysfs直接mount和bind mount都不行root@ubuntu:~# mount -t sysfs sysfs ./mntmount: permission deniedroot@ubuntu:~# mount --bind /sys ./mntmount: wrong fs type, bad option, bad superblock on /sys,       missing codepage or helper program, or other error       In some cases useful info is found in syslog - try       dmesg | tail or so.#TODO: 对于sysfs和devpts，和帮助文件中描述的对不上，不确定是我理解有问题，还是测试环境有问题，等以后有新的理解后再来更新# 挂载tmpfs成功root@ubuntu:~# mount -t tmpfs tmpfs ./mntroot@ubuntu:~# mount|grep mnt|grep tmpfstmpfs on /home/dev/mnt type tmpfs (rw,nodev,relatime,uid=1000,gid=1000)#ramfs和tmpfs类似，都是内存文件系统，这里就不演示了#对mqueue和bpf不太熟悉，在这里也不演示了</code></pre><ul><li>当mount namespace和user namespace一起用时，就算老mount namespace中的mount point是shared并且用unshare命令时指定了–propagation shared，新mount namespace里面的挂载点的propagation type还是slave。这样就防止了在新user namespace里面mount的东西被外面父user namespace中的进程看到。</li></ul><pre><code>#准备目录和diskdev@ubuntu:~$ mkdir -p disks/disk1dev@ubuntu:~$ dd if=/dev/zero bs=1M count=32 of=./disks/disk1.imgdev@ubuntu:~$ mkfs.ext2 ./disks/disk1.img#mount好disk，确认是shareddev@ubuntu:~$ sudo mount /home/dev/disks/disk1.img /home/dev/disks/disk1dev@ubuntu:~$ cat /proc/self/mountinfo |grep disk| sed 's/ - .*//'164 24 7:1 / /home/dev/disks/disk1 rw,relatime shared:105#先不创建user namespace，看看效果，便于和后面的结果比较，#当不和user namespace一起用时，新mount namespace中的挂载点为shareddev@ubuntu:~$ sudo unshare --mount --propagation shared /bin/bashroot@ubuntu:~# cat /proc/self/mountinfo |grep disk| sed 's/ - .*//'220 174 7:1 / /home/dev/disks/disk1 rw,relatime shared:105root@ubuntu:~# exitexit#创建mount namesapce的同时，创建user namespace，#可以看出，虽然指定的是--propagation shared，但得到的结果还是slave（master:105）#由于指定了--propagation shared， 系统为我们新创建了一个peer group（shared:154），#并让新mount namespace中的挂载点属于它，#这里同时也说明一个挂载点可以属于多个peer group。dev@ubuntu:~$ unshare --user -r --mount --propagation shared /bin/bashroot@ubuntu:~# cat /proc/self/mountinfo |grep disk| sed 's/ - .*//'220 174 7:1 / /home/dev/disks/disk1 rw,relatime shared:154 master:105</code></pre><h2 id="其他可以写map文件的情况"><a class="header-anchor" href="#其他可以写map文件的情况">¶</a>其他可以写map文件的情况</h2><ol><li>在有一种情况下，没有CAP_SETUID的权限也可以写uid_map和gid_map，那就是在父user namespace中用新user namespace的owner来写，但是限制条件是只能在里面映射自己的账号，不能映射其他的账号。</li><li>在新user namespace中用有CAP_SETUID权限的账号可以来写map文件，但跟上面的情况一样，只能映射自己。细心的朋友可能觉察到了，那就是都还没有映射，新user namespace里的账号怎么有CAP_SETUID的权限呢？关于这个问题请参考下一节（创建新user namespace时capabilities的变迁）的内容。</li></ol><p>由于演示第二种情况需要写代码（可以参考unshare的实现），这里就只演示第一种情况：</p><pre><code>#--------------------------第一个shell窗口----------------------#创建新的user namespace并记下当前shell的piddev@ubuntu:~$ unshare --user /bin/bashnobody@ubuntu:~$ echo $$25430#--------------------------第二个shell窗口----------------------#映射多个失败dev@ubuntu:~$ echo '0 1000 100' &gt; /proc/25430/uid_map-bash: echo: write error: Operation not permitted#只映射自己成功，1000是dev账号的IDdev@ubuntu:~$ echo '0 1000 1' &gt; /proc/25430/uid_map#设置setgroups为&quot;deny&quot;后，设置gid_map成功dev@ubuntu:~$ echo '0 1000 1' &gt; /proc/25430/gid_map-bash: echo: write error: Operation not permitteddev@ubuntu:~$ cat /proc/25430/setgroupsallowdev@ubuntu:~$ echo &quot;deny&quot; &gt; /proc/25430/setgroupsdev@ubuntu:~$ cat /proc/25430/setgroupsdenydev@ubuntu:~$ echo '0 1000 1' &gt; /proc/25430/gid_mapdev@ubuntu:~$#--------------------------第一个shell窗口----------------------#回到第一个窗口后重新加载bash，显示当前账号已经是root了nobody@ubuntu:~$ exec bashroot@ubuntu:~# iduid=0(root) gid=0(root) groups=0(root),65534(nogroup)</code></pre><p>上面写了&quot;deny&quot;到文件/proc/[pid]/setgroups， 是为了限制在新user namespace里面调用setgroups函数来设置groups，这个主要是基于安全考虑。考虑这样一种情况，一个文件的权限为&quot;rwx—rwx&quot;，意味着other group比自己group有更大的权限，当用setgroups(2)去掉自己所属的相应group后，会获得更大的权限，这个在没有user namespace之前不是个问题，因为调用setgroups需要CAP_SETGID权限，但有了user namespace之后，一个普通的账号在新的user namespace中就有了所有的capabilities，于是他可以通过调用setgroups的方式让自己获得更大的权限。</p><h2 id="创建新user-namespace时capabilities的变迁"><a class="header-anchor" href="#创建新user-namespace时capabilities的变迁">¶</a>创建新user namespace时capabilities的变迁</h2><pre><code>              clone函数                              unshare函数+----------------------------------+    +----------------------------------+|   父进程        |    子进程       |    |              当前进程             ||----------------------------------+    |----------------------------------+|   启动                           |    |               启动                ||    | ①                           |    |                | ①               ||    ↓                             |    |                ↓                 ||  clone  ----------→  启动        |    |              unshare             ||    |                  | ②        |    |                | ②               ||    |                  ↓          |    |                ↓                 ||    | ④               exec        |    |               exec               ||    |                  | ③        |    |                | ③               ||    ↓                  ↓          |    |                ↓                 ||   结束               结束         |    |               结束               |+----------------------------------+    +----------------------------------+</code></pre><p>上面描述了进程在调用不同函数后所处的不同阶段，clone函数会创建新的进程，unshare不会。</p><ul><li>①： 处于父user namespace中，进程拥有的capabilities由调用该进程的user决定</li><li>②： 处于子user namespace中，这个时候进程拥有所在子user namespace的所有capabilities，所以在这里可以写当前进程的uid/gid map文件，但只能映射当前账号，不能映射任意账号。这里就回答了上一节中为什么没有映射账号但在子user namespace有CAP_SETUID权限的问题。</li><li>③： 处于子user namespace中，调用exec后，由于没有映射，系统会去掉当前进程的所有capabilities（这个是exec的机制），所以到这个位置的时候当前进程已经没有任何capabilities了</li><li>④： 处于父user namespace中，和①一样。但这里是一个很好的点来设置子user namespace的map文件，如果能在exec执行之前设置好子进程的map文件，exec执行完后当前进程还是有相应的capabilities。但是如果没有在exec执行之前设置好，而是exec之后设置，当前进程还是没有capabilities，就需要再次调用exec后才有。如何在④这个地方设置子进程的map文件需要一点点技巧，可以参考<a href="http://man7.org/linux/man-pages/man7/user_namespaces.7.html" target="_blank" rel="noopener">帮助文件</a>最后面的示例代码。</li></ul><p>对于unshare来说，由于没有④，所有没法映射任意账号到子user namespace，这也是为什么unshare命令只能映射当前账号的原因。</p><h2 id="其它"><a class="header-anchor" href="#其它">¶</a>其它</h2><p>和pid namespace类似，当在程序中用UNIX domain sokcet将一个user namespace的uid或者gid发送给另一个user namespace中的进程时，内核会自动映射成目的user namespace中对应的uid或者gid。</p><h2 id="参考"><a class="header-anchor" href="#参考">¶</a>参考</h2><ul><li><a href="http://man7.org/linux/man-pages/man7/user_namespaces.7.html" target="_blank" rel="noopener">user namespaces man page</a></li><li><a href="https://lwn.net/Articles/532593/" target="_blank" rel="noopener">Namespaces in operation, part 5: User namespaces</a></li><li><a href="https://lwn.net/Articles/540087/" target="_blank" rel="noopener">Namespaces in operation, part 6: more on user namespaces</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> namespace </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
